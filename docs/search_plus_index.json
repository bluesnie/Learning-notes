{"./":{"url":"./","title":"Introduction","keywords":"","body":"datetime:2019/6/14 9:04 author:nzb 笔记格式：{ { } } 写成 { { } } ， { % % } 写成 { % % }，空格隔开 gitbook 生成文档 注意：SUMMARY.md 目录中有的 markdown 才会转成静态 html, 并且才能全局搜索得到 电子书 学习笔记 Linux 入门基础 Linux系统简介 Linux系统安装 Linux使用注意事项 Linux各目录的作用 服务器注意事项 Linux常用命令 强大的文本编辑器Vim Linux软件包管理 Linux中的用户管理 Linux权限管理 Linux的文件系统管理 Shell Linux的服务管理 Linux系统管理 Linux日志管理 Linux启动管理 Linux备份与恢复 命令指北 strace ps和pstree top py-spy Python Python语言基础 Python PEP8编码规范 | 初识Python | 语言元素 分支结构 | 循环结构 | 构造程序逻辑 | 函数和模块的使用 字符串和常用数据结构 | 面向对象编程基础 | 面向对象编程进阶 图形用户界面和游戏开发 | 文件和异常 | 字符串和正则表达式 进程和线程 | 网络编程入门 | 网络应用开发 | 图像和文档处理 | logging日志模块 单元测试unittest基础 | 单元测试unittest进阶 | 单元测试unittest集成篇 Python语言进阶 常用数据结构 函数的高级用法 - “一等公民” / 高阶函数 / Lambda函数 / 作用域和闭包 / 装饰器 面向对象高级知识 - “三大支柱” / 类与类之间的关系 / 垃圾回收 / 魔术属性和方法 / 混入 / 元类 / 面向对象设计原则 / GoF设计模式 迭代器和生成器 - 相关魔术方法 / 创建生成器的两种方式 / 并发和异步编程 - 多线程 / 多进程 / 异步IO / async和await asynico异步编程 GIL全局解释器锁 线程池ThreadPoolExecutor Python 第三方库 Django 快速上手 | 深入模型 | 静态资源和Ajax请求 | Django模板系统 Django的View(视图) | Django的路由系统 | Django ORM相关操作 Cookie、Session和分页 | Form、ModelForm组件 | 中间件 Django-REST-framework Django生命周期) | Django中间件 Django-Rest-framework组件: 认证 | 权限 | 频率控制(节流) | 版本(全局配置就行) | 解析器(全局配置就行) 序列化 | 分页 | 视图 | 路由 | 渲染器 | django组件：content-type Django项目开发经验 登录相关 | 异常处理手柄 | 过滤相关 | 存储类重写 | 序列化相关 | 自动化测试 | 接口加速缓存 FastAPI 基础 pydantic hello_world 请求参数和验证 响应处理和FastAPI配置 FastAPI的依赖注入系统 安全、认证和授权 FastAPI的数据库操作和多应用的目录结构设计 中间件、CORS、后台任务、测试用例 示例新冠病毒疫情跟踪器API apSheduler动态定时任务 入口文件、全局配置 PyQt5 导航 窗口 / 按钮 / 垂直布局和水平布局 / 栅格布局 / 布局添加标签和背景图 单选框 / 复选框 / 键盘提示 / 行编辑器 / 按钮组 / 布局组 / 无边框窗口 框架 / 分离器 / 滑动条 / 滚动条 / 刻度盘 / 上下拨号 / 生成随机数 进度条 / 工具框 / 菜单栏工具栏 / 文档编辑框 / 字体文本框 / 颜色文本框 打印 / 打印预览 / 打印PDF / 消息提示框 / 右键菜单 / 选项卡 / 堆叠小部件 可停靠的窗口小部件 / 日历 / 单选下拉框 / 首字母模糊填充 / 打开更多窗口 时间编辑 / 列表部件 / PySide Qt简介 界面设计师QtDesigner 发布程序 常用控件1 常用控件2 常用控件3 常用控件4 OpenCV 图像基本操作 图像处理 Pyinstaller pyInstaller打包基础 ZeroMQ zmq基础 GoLang GoLang简明教程 Go语言简明教程 Gin-简明教程 Go2新特性简明教程 Protobuf简明教程 RPC&TLS鉴权简明教程 WebAssembly(Wasm)简明教程 Test单元测试简明教程 Mock(gomock)简明教程 Mmap-文件内存映射简明教程 Context并发编程简明教程 GoLang基础 GoLang发展史 打印输出 变量和常量 数据类型 运算符 流程控制 数组 切片 map 函数 time包日期函数 指针 结构体 GoMod及包 接口 协程 反射 文件和目录操作 7daysGoLang 目录 7天用Go从零实现Web框架 - Gee 第一天：前置知识(http.Handler接口) 第二天：上下文设计(Context) 第三天：Trie树路由(Router) 第四天：分组控制(Group) 第五天：中间件(Middleware) 第六天：HTML模板(Template) 第七天：错误恢复(Panic Recover) C++ C++基础 C++初始 | 数据类型 | 运算符 流程控制 | 数组 | 函数 指针 | 结构体 | 内存分区模型 引用 | 函数进阶 | 类和对象 | 文件操作 C++进阶 模板 | STL初识 | STL函数对象 STL常用容器string | vector | deque | stack | queue | list | set-multiset | map-multimap STL常用算法遍历 | 查找 | 排序 | 拷贝替换 | 算术生成 | 集合算法 Linux环境编程 gdb调试 | make和Makefile | CMakeLists入门 | CMakeLists进阶find_package的用法 | 静态库和动态库的制作和使用 网络通信socket socket概述 | 数据类型和相关库函数 | 网络字节序与主机字节序 | 程序封装成类 | 多进程网络服务端 TCP长连接和短连接 | 多线程网络服务端 | 性能测试 | IO复用-select | IO复用-poll | IO复用-epoll 多进程 进程概述 | 孤儿进程和僵尸进程 | 守护进程 | 进程间通信-管道 | 进程间通信-信号 | 进程间通信-共享内存 | 进程间通信-信号量 多线程 多线程基础 | 线程同步 | 多线程并发的网络服务 | 线程同步案例 BehaviorTree 入门 初始行为树 行为树的基本知识点：xml文件、tick()、节点种类：ControlNode、DecoratorNode、ConditionNode 、ActionNode 基本类型Tree和TreeNode 基本类型Factory和Blackboard BehaviorTreeFactory | NodeBuilder | Blackboard | Port DecoratorNodes源码解析 DecoratorNode基类 | BlackboardPreconditionNode | DelayNode | ForceFailureNode | InverterNode KeepRunningUntilFailureNode | RepeatNode | RetryNode | SubtreeNode | SubtreePlusNode | TimeoutNode ControlNodes源码解析 ControlNode基类 | FallbackNode | ReactiveFallback | ParallelNode IfThenElseNode | WhileDoElseNode | SwitchNode | ManualSelectorNode ControlNodes源码解析之Sequence SequenceNode | SequenceStarNode | ReactiveSequence ActionNode及同步和异步 ActionNodeBase | SyncActionNode | SimpleActionNode | AsyncActionNode | StatefulActionNode | CoroActionNode 各种调试工具介绍 Groot | StdCoutLogger | FileLogger | MinitraceLogger | PublisherZMQ | printTreeRecursively()内置函数 | debugMessage()内置函数 Logger类实现原理解析-单例与观察者模式 行为树内外的数据传输 树内即ports之间：Blackboard、getInput、setOutput、SetBlackboard | subtree之间 | 树与调用方之间 从xml创建加载行为树的过程分析 自定义的用于枚举类型的SwitchNode registerSimpleNode相关数据传输 数据库基础和进阶 关系型数据库MySQL 关系型数据库概述 MySQL的安装和使用 SQL的使用 DDL - 数据定义语言 - create / drop / alter DML - 数据操作语言 - insert / delete / update / select DCL - 数据控制语言 - grant / revoke 相关知识 范式理论 - 设计二维表的指导思想 数据完整性 数据一致性 在Python中操作MySQL 计算机二级 | 数据库三大范式 | MySQL主从复制 NoSQL入门 NoSQL概述 | Redis概述 | Mongo概述 Redeis Redis安装与配置文件 Redis基础 Redis键 | Redis字符串 | Redis哈希 | Redis列表 | Redis集合 | Redis有序集合 | Redis发布订阅 Redis多数据库 | Redis事务 | Redis数据淘汰策略 | Redis持久化 | Redis缓存与数据库Mysql一致性方案 Redis开发规范 数据分析 数学基础 高等数学 | 概率论 | 微积分 | SVD | 似然函数 | 后验概率估计 | 拉格朗日乘子法 | 核函数 梯度 | 概率分布与概率密度 | 泰勒公式 | 激活函数 | 熵 | 特征值与特征向量 | 矩阵 数据分析库 numpy基础 | pandas基础 | pandas连接合并追加 | matplotlib基础 Web前端 Web前端入门 | HTML5 | CSS | JavaScript jQuery | jQuery-UI | Vue.js | RESTful规范 ROS ROS1 基础 Windows安装rospy 什么是ROS Catkin工作空间编译系统 ROS通信架构上 ROS通信架构下 常用工具 roscpp rospy 进阶 源码分析 ros-logs roscore与Master启动 roslaunch process_monitoring topic service ROS2 ROS2入门篇 ROS2介绍与安装 基础 ROS2介绍与安装 在虚拟机中安装Ubuntu 玩转Ubuntu之常用指令 玩转Ubuntu之编程工具 玩转Ubuntu之常用软件 入门 ROS2的前世今生 安装ROS2-初体验 进阶 ROS2系统架构 ROS2第一个节点 基础 cplus python 入门 节点介绍-工作空间-构建工具Colcon 使用RCLCPP和RCLPY编写节点 进阶 面向对象编程思想 Colcon使用进阶 ROS2节点发现与多机通信 ROS2节点通信之话题与服务 基础 从底层理解通信及通信中间件ZMQ 入门 topic topic-rclcpp topic-rclpy service service-rclcpp service-rclpy interface interface-rclcpp interface-rclpy 进阶 原始数据类型与包装类型 通信质量Qos配置指南 DDS进阶之Fast-DDS环境搭建 使用DDS进行订阅发布 ROS2节点通信之参数与动作 基础 开环控制与闭环控制 入门 param param-rclcpp param-rclpy action action-rclcpp action-rclpy 通信机制对比总结 进阶 ROS参数通信原理介绍 生命周期节点 ROS2常用工具 启动管理工具-Launch ROS2命令行工具 RVIZ2 RQT工具 时光记录仪之rosbag2 兼容仿真工具-Gazebo 机器人学篇 运动学基础 基础-数学基础 矩阵与矩阵运算 MiniConda与Jupyter介绍安装 矩阵运算实战 入门-机器人运动学 空间坐标描述 空间坐标描述实战 姿态的不同表示 姿态转换实战 齐次坐标变换 齐次坐标变换实战 机器人运动学介绍 ROS2运动学 TF2介绍及RVIZ-TF组件 坐标变换发布监听Python和Cpp实现 建模仿真篇 机器人建模 URDF统一机器人建模语言 RVIZ2可视化移动机器人模型 创建一个两轮差速模型 通过JointStates控制RVIZ2关节 机器人仿真 入门 机器人仿真介绍 为机器人URDF模型注入物理属性 常见几何物体URDF仿真惯性参数怎么配 在Gazebo加载机器人模型 Gazebo仿真插件之两轮差速 Gazebo仿真插件之IMU Gazebo仿真插件之超声波 Gazebo仿真插件之超声波 Gazebo仿真环境搭建 进阶 Gazebo仿真进阶教程之传感器高斯噪声 Nav2导航篇 SLAM建图 基础 图像常见格式及存储 入门 SLAM前世今生 Carto介绍及安装 配置FishBot进行建图 进阶 ROS2地图加载与编辑 使用纯雷达定位建图 Nav2导航仿真实战 基础 入门 Nav2导航框架介绍 为FishBot配置Nav2 使用FishBot进行自主导航 使用Nav2导航API进行导航 进阶 使用EKF融合里程计和IMU Nav2进阶实践 ROS2硬件控制篇 嵌入式开发之从点灯开始 基础 嵌入式开发介绍与环境搭建 HelloWord-串口通信-接收实验 入门 看懂LED驱动电路-GPIO-ADC 进阶 学会安装第三方开源库 使用开源库驱动IMU 面向对象封装IMU驱动 使用开源库驱动OLED I2C通信-点亮OLED 接入ROS2-MicroROS 基础 MicroROS介绍与服务安装 第一个MicroROS节点 入门 话题订阅-控制LED MicroROS话题发布实现 MicroROS服务通信服务端实现 进阶 控制OLED自定义消息接口 做个时钟-系统时间同步 无线通讯-了解传输原理 使用双核运行MicroROS ROS2硬件实战-自制简易雷达 测量距离学会超声波传感器 控制舵机学会使用执行器 舵机和超声波循环扫描 可视化点云雷达消息合成 两轮差速移动机器人开发篇 移动机器人控制系统搭建 移动机器人底盘结构介绍 从H桥说起-电机驱动原理 电机控制之正反转实验 电机控制之速度控制实验 电机控制之使用开源库驱动多路电机 做个遥控车订阅ROS2Twist 速度测量-编码器-脉冲测量与校准 速度转换-机器人最大速度测量 控制速度-PID控制器实现 两轮差速运动学正逆解 里程计计算-速度积分 采用MicroROS发布里程计 项目总结与扩展-源码编译Agent 建图与导航 slam 学会驱动雷达 了解ROS标准REP105 发布odom的TF 准备URDF 使用SLAM_TOOLBOX完成建图 navigation Nav2安装与配置 启动导航和单点与路点导航 ROS2常用代码模板 rclcpp rclpy urdf Navigation2 源码分析 核心定义 通用插件系统管理 行为树及节点 地图和定位 工具 Docker 基础 docker-history container-diff 制作容器镜像的最佳实践 制作Python_Docker镜像的最佳实践 Docker入门PDF Docker部署Django Uwsgi+Nginx+MySQL+Redis Docker简单部署Django的FastDFS Git 帮助信息 / git配置(全局配置) / 初始化项目 / 查看状态 / 添加文件 / 提交文件 / 查看提交日志 查看文件修改前后的区别 / git跟踪rename文件和移动文件 / 删除文件 / 恢复文件 / 恢复提交 重置提交指针 / 查看、创建、切换分支 / 查看两个分支的区别 / 合并分支 / 解决合并冲突 / 重命名和删除分支 保存修改进度 / 添加别名 / 全局忽略跟踪文件 / 项目级忽略文件 / 创建远程版本库 / 推送版本库 修改远程仓库地址 / 克隆版本库到本地 / 更新本地版本库 / 基于版本库开发自己的版本库 / 添加pull request / 添加贡献者 Nginx 基础 进阶 工作所学技能或知识 福建路阳有限公司 上海快仓自动化有限公司 面试 技术面试必备基础知识 操作系统 网络 数据库 系统设计 数据结构与算法 算法 基础 算法 选择、冒泡和插入排序 归并、快速排序 堆和桶排序以及排序总结 链表 二叉树 图 前缀树和贪心算法 暴力递归 算法图解 基础提升 哈希函数和哈希表 字符串匹配算法 滑动窗口-单调栈 Morris遍历 大数据题目-资源限制类 位运算 暴力递归到动态规划 有序表 数据结构 线性表 栈 队列 特殊矩阵压缩存储 串 树与二叉树 面试题 2020 理财 基金 基金基础 纯债基金 股票型基金 大数据指数基金 ETF基金 LOF基金 四大行业指数 基金进价 分级基金 避险基金 量化基金 QDII基金 FOF基金 其他 基金定投 基金投资术语 投资误区 全球配置 场外基金开户和买卖实操 场内基金开户和买卖实操 看懂股票行情 基金套牢怎么办 股票 股票市场常用名称解释 看盘 早盘 盘后 大盘分时图分析技巧 K线图 "},"Linux/Linux.html":{"url":"Linux/Linux.html","title":"入门基础","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux Linux系统简介 UNIX和Linux发展史 1965年，贝尔实验室：MULTICS计划 69年，贝尔实验室的肯汤普森：为了游戏开发UNICS/UNIX系统 62年，美国军方：ARPA：阿帕网，NCP协议——》TCP/IP协议 71年，可汤普森和丹尼斯里奇发明C语言，重写UNIX UNIX主要发行版本：AIX(IBM)、HP-UX(HP)、Solaris(Sun)、Linux(Intel,AMD……)、BSD 1991年，芬兰大学生Linus Torvalds开发linux内核。大学教授开发minix，但是不接受外来代码，所以李纳斯独自开发，由社区共同维护。 Linux内核版本号：主版本.次版本.末版本 linux内核官网 Linux发行版本：两大派系redhat和debian 开源软件简介 商业软件和开源软件（开源≠免费） 开源软件：apache、NGINX、MySQL、php、mongoDB、python、Ruby、Perl、Go、Rust、Swift、Java 开源软件的特点：使用自由（绝大多数免费）、研究自由（源代码）、散步和改良的自由 支撑互联网的开源技术（LAMP）：Linux，Apache，MySQL，PHP Linux应用领域 基于Linux的企业服务器 踩点网站：发数据包根据相应嗅探服务器 世界前500服务器 嵌入式应用 手机，平板：Android底层是Linux 智能家电，航空系统，银行系统…… 在电影娱乐业 特效，图形处理渲染 Linux学习方法 Linux只考虑应用性和稳定性 善于观察提示信息，查找文档，自己解决问题 学习英文：Command not found和No Such file or directory 忘掉Windows的操作习惯 计划，专注，坚持，练习 Linux系统安装 VMware虚拟机安装 VMware官网下载，不推荐安装双系统 特点： 不需要分区就能在物理机上使用两种以上的操作系统 物理机和虚拟机能实现网络通信 可以设定并随时修改虚拟机操作系统的硬件环境 要求： CPU：主频1GHz以上 内存：1GB以上 硬盘：8GB以上 镜像下载：官网下载: 几个版本：DVD版本，Everything版本，minimal版本，LiveGnome版本，KdeLive版本，livecd版本，NetInstall版本 系统分区 主分区：最多只能有4个 扩展分区：最多只能有一个；主分区加扩展分区最多有4个；不能写入数据，只能包含逻辑分区 逻辑分区：可以和主分区一样正确的写入数据和格式化 注意：兄弟连这套视频录制时间较为久远，当时的硬盘分区形式是MBR的，所以上述的分区限制也只 是针对MBR分区形式，对于GPT分区形式而言，则没有上述限制了。 电脑根据主板的不同（BOIS或者UEFI），会决定硬盘选择MBR分区方案还是GPT分区方案： BIOS + MBR UEFI + GPT 两者区别： 也就是说，电脑使用传统BIOS主板，建议使用MBR分区方案；电脑使用UEFI主板，建议使用GPT分区方案 MBR分区表最多只能识别2TB左右的空间，大于2TB的容量将无法识别从而导致硬盘空间浪费；GPT分区表则能够识别2TB以上的硬盘空间。 MBR分区表最多只能支持4个主分区或三个主分区+1个扩展分区(逻辑分区不限制)；GPT分区表在Windows系统下可以支持128个主分区。 在MBR中，分区表的大小是固定的；在GPT分区表头中可自定义分区数量的最大值，也就是说GPT分区表的大小不是固定的。 硬盘分区的作用： 把一块大硬盘分成几块 格式化的作用： 写入文件系统（1.把硬盘分成一个个等大小的数据块 同时2.建立一个inode列表） Linux中的所有硬件都是文件： 硬盘文件名： IDE硬盘：/dev/hd[a-d] SCSI/SATA/USB硬盘：/dev/sd[a-p] 光驱：/dev/cdrom或/dev/sr0 鼠标：/dev/mouse 分区文件名： /dev/hda[数字] /dev/sda[数字] 挂载： 给分区分配挂载点 /根分区 swap交换分区（内存两倍，最大不超多2GB） /boot启动分区（200MB足够） 总结： 分区：把大硬盘分为小的分区 格式化：写入文件系统，同时会清空数据 分区设备文件名：给每个分区定义设备文件名 挂在：给每个分区分配挂载点，这个挂在点必须是空目录 Linux系统安装 把镜像加进去，点击启动，然后用图形界面配置分区和其他的自定义选项，确定定义root用户的密码和普通用户的账号和密码。然后等待安装完成即可。 远程登陆管理工具 三种网络连接方式： 桥接模式：虚拟机使用物理网卡 NAT模式：虚拟机使用vmnet8虚拟网卡 Host-only模式：虚拟机使用vmnet1虚拟网卡，并且只能和本机通信 临时配置ip：ifconfig ens33 192.168.XXX.XXX 永久配置ip： 查看网络接口：ifconfig 去网络接口的配置文件进行修改 [root@bogon ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33/ ens33是网卡接口 配置文件 TYPE=“Ethernet” PROXY_METHOD=“none” BROWSER_ONLY=“no” BOOTPROTO=“none” //dhcp是自动获取 DEFROUTE=“yes” IPV4_FAILURE_FATAL=“no” IPV6INIT=“yes” IPV6_AUTOCONF=“yes” IPV6_DEFROUTE=“yes” IPV6_FAILURE_FATAL=“no” IPV6_ADDR_GEN_MODE=“stable-privacy” NAME=“ens33” UUID=“d8ee940a-1a27-4417-9ae8-88a5364ee4d1” DEVICE=“ens33” ONBOOT=“yes” //引导激活 IPADDR=172.16.10.188 //ip地址 NETMASK=255.255.255.0 //子网掩码 GATEWAY=172.16.10.254 //网关 DNS1=222.88.88.88 //DNS Linux使用注意事项（新手必看） Linux 严格区分大小写 和 Windows 不同，Linux 是严格区分大小写的，包括文件名和目录名、命令、命令选项、配置文件设置选项等。 例如，Windows 系统桌面上有一个名为 Demo 的文件夹，当我们在桌面上再新建一个名为 demo 的文件夹时，系统会提示文件夹命名冲突；而 Linux 系统不会，Linux 系统认为 Demo 文件和 demo 文件不是同一个文件，因此在 Linux 系统中，Demo 文件和 demo 文件可以位于同一目录下。 因此，初学者在操作 Linux 系统时要注意区分大小写的不同。 Linux 中所有内容（包括硬件设备）以文件形式保存 Linux 中所有内容都是以文件的形式保存和管理的（硬件设备也是文件），这和 Windows 完全不同，Windows 是通过设备管理器来管理硬件的。比如说，Linux 的设备文件保存在 /dev/ 目录中，硬盘文件是 /dev/sd[a-p]，光盘文件是 /dev/hdc 等。 Linux 不靠扩展名区分文件类型 我们都知道，Windows 是依赖扩展名区分文件类型的，比如，\".txt\" 是文本文件、\".exe\" 是执行文件、\".ini\" 是配置文件、\".mp4\" 是小电影等。但 Linux 不是。 Linux 系统通过权限位标识来确定文件类型，且文件类型的种类也不像 Windows 下那么多，常见的文件类型只有普通文件、目录、链接文件、块设备文件、字符设备文件等几种。Linux 的可执行文件不过就是普通文件被赋予了可执行权限而已。 Linux 中的一些特殊文件还是要求写 \"扩展名\" 的，但大家小心，并不是 Linux 一定要靠扩展名来识别文件类型，写这些扩展名是为了帮助管理员来区分不同的文件类型。这样的文件扩展名主要有以下几种： 压缩包：Linux 下常见的压缩文件名有 .gz、.bz2、.zip、.tar.gz、.tar.bz2、.tgz 等。为什么压缩包一定要写扩展名呢？很简单，如果不写清楚扩展名，那么管理员不容易判断压缩包的格式，虽然有命令可以帮助判断，但是直观一点更加方便。另外，就算没写扩展名，在 Linux 中一样可以解压缩，不影响使用。 二进制软件包：CentOS 中所使用的二进制安装包是 RPM 包，所有的 RPM 包都用\".rpm\"扩展名结尾，目的同样是让管理员一目了然。 程序文件：Shell 脚本一般用 \".sh\" 扩展名结尾，其他还有用 \".c\" 扩展名结尾的 C 语言文件等。 网页文件：网页文件一般使用 \"*.php\" 等结尾，不过这是网页服务器的要求，而不是 Linux 的要求。 在此不一一列举了，还有如日常使用较多的图片文件、视频文件、Office 文件等，也是如此。 Linux中所有存储设备都必须在挂载之后才能使用 Linux 中所有的存储设备都有自己的设备文件名，这些设备文件必须在挂载之后才能使用，包括硬盘、U 盘和光盘。 挂载其实就是给这些存储设备分配盘符，只不过 Windows 中的盘符用英文字母表示，而 Linux 中的盘符则是一个已经建立的空目录。我们把这些空目录叫作挂载点（可以理解为 Windows 的盘符），把设备文件（如 /dev/sdb）和挂载点（已经建立的空目录）连接的过程叫作挂载。这个过程是通过挂载命令实现的，具体的挂载命令后续会讲。 Windows 下的程序不能直接在 Linux 中使用 Linux 和 Windows 是不同的操作系统，两者的安装软件不能混用。例如，Windows 系统上的 QQ 软件安装包无法直接放到 Linux 上使用。 系统之间存在的这一差异，有弊也有利。弊端很明显，就是所有的软件要想安装在 Linux 系统上，必须单独开发针对 Linux 系统的版本（也可以依赖模拟器软件运行）；好处则是能感染 Windows 系统的病毒（或木马）对 Linux 无效。 Linux各目录的作用 /bin/：存放系统命令 /sbin/：存放系统目录，只有超级用户能用 /usr/bin/：存放系统命令，单用户模式不能执行 /usr/sbin/ ：存放系统命令，只有超级用户能用，单用户模式不能执行 /boot/ ：系统启动目录，内核和启动引导程序 /dev/ ：硬件设备文件目录 /etc/ ：linux默认的配置文件保存目录 /home/：普通用户家目录 /root/：超级用户家目录 /lib/：系统调用的函数库 /lost+found/：当系统意外崩溃时，每个分区都含有的存放的文件碎片用来修复 /media/：挂载目录，挂载媒体设备 /mnt/：挂载目录，挂载U盘，移动硬盘，和其他操作系统的分区 /misc/：挂载目录，挂载NFS服务的共享目录 /opt/：第三方安装的软件的保存目录，也可以放到 /usr/local/ 下 /proc/：存放在内存里面，存放系统的内核，进程，外部设备 /sys/：存放在内存里面，存放系统的内核相关的东西 /srv/ ：服务数据目录 /tmp/ ：临时目录，可以清空 /usr/：系统资源目录 /var/：动态资源保存目录，日志，邮件，数据库 服务器注意事项 远程服务器不允许关机，只能重启 重启时应该关闭服务 不要在服务器访问高峰运行高负载命令 远程配置防火墙（过滤不是防病毒，比如允许某个端口运行访问）时不要把自己踢出服务器 指定合理的密码规范和定期更新 合理分配权限 定期备份重要数据和日志（系统备份：etc、boot、usr等目录） Linux常用命令 文件处理命令 ls（list） ls [参数] [路径] ls -l：查看文件所有属性 ls -d：查看目录本身（而不是查看目录下的信息） ls -i：查看文件的inode号 ls -h：人性化显示（文件大小以K, M显示） ls -s：显示文件占用的块的数量 ls -a：查看隐藏文件 mkdir（make directories）创建目录：mkdir [参数] [目录] mkdir -p：递归创建目录 cd（change directories） 切换目录：cd [路径] pwd（print work directories） 查看完整工作路径 rmdir （remove empty directories） 删除空目录：rmdir [目录名] cp（copy） 复制文件或目录：cp -rp [原文件或目录] [目标目录] cp -r：复制目录 cp -p：原文件和新文件属性完全一致 注：复制的同时可以改名 mv（move） 剪切文件、改名：mv [原文件或目录] [目标目录] 注：移动的同时可以改名 rm（remove） 删除文件或目录：rm -rf [文件或目录] rm -r：文件夹递归删除（删除目录） rm -f：强制删除，不询问 注： 删除之前做好备份 误删除之后对硬盘少做读写操作 touch 创建空文件：touch [文件名] cat 显示文件内容：cat [文件名] cat -n：显示行号 tac 显示文件内容（反向查看）：tac[文件名] more 分页显示文件：空格翻页，回车换行，q退出 查看命令帮助信息时就是使用more来查看 less 分页显示文件（可向上翻页）：空格翻页，回车换行，q退出，还可以pageup回翻页，上箭头网上翻一行，还可以搜索：/关 键词，再按n搜索下一个匹配的 head 显示文件前面几行：head [参数] [文件名] head -m：指定看前几行，默认前10行 tail 显示文件后面几行：tail [参数] [文件名] tail -n：指定看后几行，默认后10行 tail -f：动态看文件动态变化 ln（link） 生成链接文件：ln [原文件] [目标文件] ln -s：生成软链接 软连接特征：类似Windows快捷方式 lrwxrwxrwx：软连接的权限不起作用，还是要看源文件权限 文件大小：很小，只是符号链接 箭头指向源文件 什么时候需要用到软连接？Windows时你什么时候需要用到快捷方式时就用 ln：生成硬链接 硬链接特征 拷贝cp -p + 同步更新：cp -p的区别是硬链接文件和原文件可以同步更新 硬链接通过inode号来区分 不能跨分区 不能针对目录 硬链接和软连接的区别 1.硬链接不能跨分区 2.硬链接不能针对目录 权限管理命令 chmod（change the permissions mode of a life） 改变文件或目录权限：chmod [参数] [文件或目录] chmod [u/g/o/a] [+/-/=] [r/w/x] u：所有者；g：所属组；a：所有人；举例：chmod u+w；chmod u+x, o-wr chmod 三位数XXX：r—4，w—2，x—1：举例：rwxr-xr-x：755 （最常用） chmod -R：递归修改目录及目录下的权限 注释：深入理解文件的wrx和目录的wrx的意义 删除一个文件的权限不是对这个文件有写权限，而是对这个文件的目录有写权限 一个目录往往都是同时有r和x权限，可进入目录和查看目录下的文件 chown（change file ownership） 改变文件或目录所有者：chown [用户名] [文件或目录]：只有管理员root能执行 例：chown root:testgroup /test/ chgrp（change file group ownership） 改变文件或目录所属组：chgrp [组名] [文件或目录]：只有管理员root能执行 注：每个文件都只有一个user和一个group，某些others拥有拥有共同的权限，这些others在一个组里，也就是group所属组。所属者user可以不在所属组group里面，并且一个用户可以在不同的组里。 相关的命令是： groupadd YYY //创建组 useradd -g YYY XXX //创建用户并将YYY设置为其主要组 usermod -g ZZZ XXX //修改用户XXX的主要组为ZZZ umask（the user file-creation mask） 显示、设置文件的缺省权限 umask -S：人性化显示默认权限，以rwx形式显示新建文件缺省权限 umask：显示掩码（非人性化） 比如：0022，权限 实际上为：777 - 022 = 755 注：Linux中，默认创建的文件是没有可执行权限的（touch 创建的文件），所以文件是666，目录是777 umask 三位数：修改掩码，使默认权限变化umask 023；中文修改户的掩码为0023，权限为：754，并不建议修改 文件搜索命令 尽量少搜索，特别是在高峰期时 find 文件精准搜索：find [搜索范围] [匹配条件] find [搜索范围] -name：根据文件名搜索 find [搜索范围] -iname：根据文件名搜索，不区分大小写 注：通配符：*，？，[] *：匹配多个字符；举例：find /ete -name init（模糊搜索，包含即可） ？：匹配单个字符；举例：find /ete -name init???（搜索以init开头后面还有3个字符的文件） find [搜索范围] -size [+/-]n： +n：大于； -n：小于，只有数据块（0.5KB）个数； n：等于 find [搜索范围] -user：根据所有者查找 find [搜索范围] -group：根据所属组查找 find [搜索范围] -amin [-/+]分钟数：查找指定时间内或者超过该时间被修改过访问时间的文件(access) find [搜索范围] -cmin [-/+]分钟数：查找指定时间内或者超过该时间被修改过文件属性的文件(change) find [搜索范围] -mmin [-/+]分钟数：查找指定时间内或者超过该时间被修改过文件内容的文件(modify) 还可以在两个查找条件之间加上 -a ：一个是同时满足(and) -o ：一个是满足任意一个即可(or) 或者-exec/-ok 命令 [空格] {} [空格] \\； 对搜索结果执行操作 示例：find ./ -name test.txt -exec ls -l {} \\; -ok：是对后面的命令逐个询问 find [搜索范围] -type：根据文件类型查找 find [搜索范围] -inum：根据inode号查找 locate 模糊查找：locate 文件名 系统里所有的文件都会定期收录到/var/lib/mlocate.db这个文件库里，locate就是在这个里去找，但是新的文件没别收录进去，所以就找不到，需要手动更新文件资料库updatedb （但是tmp目录下不收录进去） locate -i：不区分大小写 which 查找命令的地址和别名alias：which 命令名 whereis 查找命令地址和其帮助文档的位置：whereis 命令名 grep 在文件里面查找字串匹配的行并输出：grep [-iv] [指定字串] [文件] grep -i：不区分大小写，查找指定字串所在的行 grep -v：排除指定字串所在的行 指定字串前面加个 ^ 表示以什么字串开头 帮助命令 man （manual）或 info （information） 查看命令和配置文件的帮助信息，浏览和more操作一样：man 命令名/配置文件名 帮助类型里1是命令的帮助，5是配置文件的帮助 For Example：man 1 passwd，man 5 passwd whatis 更加简单的命令查询，查看命令作用 apropos 更加简单的配置文件查询 –-help 得到信息更加简单：命令 ––help help 获得shell的内置命令的帮助，比如：cd，pwd，umask，if等 用户管理命令 useradd和passwd 新建用户和修改密码 who和w 查看当前登录用户名：tty是本地登录，pts表示远程登录 who简单信息 w 其中第一行：当前时间，已经运行的时间（服务器），多少个用户登录，服务器负载均衡（CPU，内存等负载情况）这行类型也可以 通过uptime获得 IDLE：表示用户空闲时间（多久没操作了） JCPU：累计占用的CPU时间 PCPU ：当前用户登录后占用CPU的时间 WHAT：当前执行的操作 压缩解压命令 几种压缩格式 .gz .zip .bz2 gzip（GNU zip）和 gunzip/gzip -d （GNU unzip） 压缩/解压文件：gzip/gunzip [文件] 解压缩：gunzip[文件] 或 gzip -d [文件] 只能压缩文件，不能压缩目录，并且不保留原文件 压缩文件后缀：.gz tar 打包目录：tar [选项] [压缩后文件名] [目录（可以多个空格隔开）] tar -c：打包 tar -x：解包 tar -v：显示详细信息 tar -f：指定文件名 tar -z：打包的同时压缩，或者解包的时候解压缩,适用于压缩解压gz tar -j：同-z，适用于压缩解压bz2 举例：tar -cvf XXX.tar YYY gzip XXX.tar ，最后生成XXX.tar.gz 。或者直接tar -zcvf打包压缩一部合成，反向是tar -zxvf 压缩文件后缀：.tar.gz zip和unzip 压缩文件或目录：zip [选项] [压缩后文件名] [文件或目录]，压缩比不高 压缩后能保留原文件 zip -r：压缩目录 压缩文件后缀：.zip bzip2和bunzip2 bzip2 /bunzip2 [选项] [文件] bzip2 -k：压缩的同时保留原文件 bunzip -k：解压的同时保留原文件 gzip的升级版本，压缩比较好 用tar生成.tar.bz2文件：tar -cjf xxx.tar.bz2 xxx 压缩文件后缀：.bz2 网络命令 write 给在线用户发信息，以ctrl+D保存结束：write wall （write all） 给当前在线的所有用户发送信息：wall [信息内容] ping 测试网络连通性：ping 选项 [IP地址] 网络踩点，Linux会一直ping下去 ping -c 次数：定义ping的次数 ifconfig （interface configure） 查看当前系统网卡信息和设置网卡信息（临时的）：ifconfig 网卡名称 IP地址 mail 查看和发送邮件：mail [用户名] 不一定要在线 mail 用户名：发送 mail：查看的子命令： q：退出 help(帮助)， 数字(查看指定邮件)， 列表：h(列表)， 删除：d 数字(删) last 日志查询命令，统计系统的所有登录信息： lastlog 查看用户最后登录的信息 lastlog -u uid：查看指定用户上次登录的信息 traceroute 跟踪节点的路径：traceroute ip地址 netstat 显示网络相关信息：netstat [选项] netstat -t：TCP协议（有3次握手） netstat -u：UDP协议（无3次握手，快，但是不保证数据收到） netstat -l：监听 netstat -r：路由 netstat -n：显示ip地址和端口号 最常用的三种组合命令： netstat -tlun：查看本机监听的端口 1：标志协议：TCP/UDP 2：数据包接收队列：0代表网络通畅，表示收到的数据已经在本地接收缓冲，但是还有多少没有被进程取走，recv()如果接收队列Recv-Q一直处于阻塞状态，可能是遭受了拒绝服务 denial-of-service 攻击。 3：数据包发送队列：0代表网络通畅，对方没有收到的数据或者说没有Ack的,还是本地缓冲区. 如果发送队列Send-Q不能很快的清零，可能是有应用向外发送数据包过快，或者是对方接收数据包不够快。 4：本机IP地址和端口（主要查看的内容） 5：监测状态：TCP才有，UDP没有（你可以直接发送，不管在不在线，不需要监听） netstat -an：查看本机所有的网络连接 跟-tlun的区别是可以查看正在连接的服务 netstat -rn：查看本机路由表 setup redhat系linux独有 配置网络的工具：永久生效 配置玩需要重启网络服务：service network restart 挂载命令 mount mount [-t 文件系统] 设备文件名 挂载点 举例：mount -t iso9660 /dev/sr0 /mnt/cdrom /dev/sr0：设备文件名，系统默认的 umount 卸载：umount 设备文件名 关机重启命令 shutdown shutdown [选项] 时间 shutdown -h 时间（new）：关机 shutdown -r 时间：重启 shutdown -c：取消前一个关机命令 谨慎操作 其他关机命令：halt,poweroff,init 0 其他重启命令：reboot,init 6 init 系统运行级别： 0：关机， 1：单用户， 2：不含NFS服务的多用户， 3：完全多用户， 4：未分配， 5：图形界面， 6：重启 /etc/inittab配置文件里面有运行级别的信息，方便查询，也可以改运行级别 init 数字：设置系统运行级别，临时更改 runlevel：查询系统运行级别 logout和exit 都是退出登录：logout退出是把因为你注销了登陆机而把你踢出的退出，exit是你直接退出连接的机器。 强大的文本编辑器:Vim 概述 Vim是linux中的一款使用最广的文本编辑器，全屏幕编辑器。 可以建立，编辑，显示文本文件。 它没有菜单只有命令. 三种模式 命令模式：输的东西都会当做命令处理 插入模式 后：a/A（行末） 前：i/I（行首） 行：o（光标下）/O（光标上）进入 退出模式：ESC键 常用操作 :set ic————搜索时不区分大小写 行号相关： :set nu————显示行号 :set nonu————关闭行号 定位相关 gg————快速定位到第一行 G————快速定位到最后一行 nG————快速定位到第n行 :n————快速定位到第n行 $————快速定位到行尾 0————快速定位到行首 删除相关 x————删除光标后字符 X————删除光标前字符 nx————删除光标后n个字符 dd————删除一行 dd————删除当前行，ndd删除当前行和下面的n-1行 dG————删除当前行到文件末尾 D————删除光标到行尾 :2,8d————删除第2行到第8行 复制粘贴替换相关 yy————复制当前行 nyy————复制当前行和下面的n-1行 p————粘贴到光标上一行 P————粘贴到光标下一行 dd/ndd 和 p/P ————剪切（删除和粘贴组合） r————替换当前字符 R————从当前位置一直往后替换（进入替换模式，esc退出模式） u————恢复 ctrl+r————撤销恢复 /string————搜索命令，按n找下一个 :%s/old/new/g————全文替换old为new :n1,n2s/old/new/g————n1到n2行替换old为new 退出保存相关 :w————保存（相当于Windows的ctrl+r） :w filename————另存为 :wq————保存并退出 ZZ————保存并退出 :q!————不保存退出 :wq!————强制保存退出，针对只读文件可以强行保存(只有文件所有者和root才可以) 使用技巧 查看命令的执行结果：:!命令 查看命令的地址：:!which 命令名 导入内容到文件中 导入文件内容：:r 导入文件地址(路径) 导入命令执行结果：:r !命令 导入命令的地址：:r !which 命令 导入当前时间：:r !date 定义快捷键 :map 快捷键（Ctrl + v + 自己想要的数字或字母） 触发命令 关键词自动替换 :ab mymail XXXXXXX@gmail.com 输入mymail是自动替换为你的邮箱地址 多行注释与取消注释 方法一 注释：Ctrl + v 行首选择多行，I（大写的i，shift + i），插入# ，ESC退出命令模式 取消注释：Ctrl + v 行首选择多行，d 方法二 :n,n+10s/^/#/g：注释n行到n+10行 :n,n+10s/^#//g：取消注释（注意行首尖叫号 ^） 所有配置都是临时的，要永久需要写入配置文件里，存放在用户的家目录下，.vimrc，如果没有的话就自己新建一个也ok Linux软件包管理 软件包管理简介 软件包分类： 源码包：包括脚本安装包 二进制包：RPM包，系统默认包（ubuntu中是deb包），源码包编译后的包 源码包的优点 开源 可以自由选择所需的功能 软件是便宜安装，所以更加是个自己的系统，更加稳定也效率更高 卸载方便（直接把目录删除） 源码包的缺点 安装步骤多 编译并安装时间过长 因为是编译安装，安装过程中一旦报错新手很难解决 RPM包优点 包管理系统简单，只需要几个命令就可以实现软件包的安装，升级，查询和卸载 安装速度比源码包快很多 RPM包缺点 不能看见原代码 功能选择不如源码包灵活 依赖性 RPM包管理 rpm命令管理 RPM包名和包全名 RPM包的依赖性：树形依赖，环形依赖，模块依赖(以.iso.数组结束的就是模块依赖，也叫库文件依赖模块依赖查询网站) 安装和升级使用包全名，卸载和查询使用包名（在/var/lib/rpm/中的数据库总搜索） RPM安装：rpm -ivh 包全名 -i（install）：安装 -v（verbose）：显示详细信息 -h（hash）：显示进度 --nodeps：不检测依赖性（该选项不用） RPM升级：rpm -Uvh 包全名 -U（upgrade）：升级 RPM卸载：rpm -e 包名,也要考虑依赖性，当有包被依赖时，此时这个包不能删掉 -e（erase）：卸载 RPM查询包：查询包还是用RPM，yum没有查询功能 查询包是否安装：rpm -q 包名 -q（query） 查询所有安装的包：rpm -qa -a（all） RPM查询包详细信息：rpm -qi 包名 -i（information） RPM查询未安装包的详细信息：rpm -qip 包全名 -p（package） RPM查询文件安装位置：rpm -ql 包名 -l（list） RPM查询未安装包的文件安装的默认位置：rpm -qlp 包名 RPM查询系统文件属于哪个rpm包：rpm -qf 系统文件名 -f（file） RPM查询软件包的依赖性：rpm -qR 包名 -R（requires） RPM查询未安装软件包的依赖性：rpm -qRp 包全名 RPM包校验：rpm -V 包名 -V（verify） RPM包中文件提取（用来修复系统）： rpm2cpio 包全名 | cpio -idv . 包中的文件绝对路径 -i（copy-in模式）：还原 -d：还原时自动新建目录 -v：显示还原过程 yum在线管理 既可以用在线yum源文件服务器，也可以用本地光盘作为yum源文件服务器。 会自动解决依赖性问题 更换yum源：保存在/etc/yum.repos.d/目录下 查询：yum list 搜索：yum search 包名 安装：yum -y install 包名 -y（yes） 升级：yum -y update 包名 yum -y update：不写包名，直接升级全部（包括Linux内核，远程升级了的话不能开机，需要本地配置文件），慎用 卸载，会卸载所有依赖的包：yum -y remove 包名 Linux服务器应该采用最小化安装的原则，用什么装什么 装完了最好不要用yum卸载，也不要随便升级 yum的软件组管理： 查询所有可用的软件组列表：yum grouplist 安装指定软件组：yum groupinstall 软件包组名 卸载指定软件组：yum groupremove 软件包组名 用光盘做yum源：修改/etc/yum.repos.d/下的media配置文件，该源为关盘挂载点，注意：配置文件的格式要求很严格，注释应该顶头写。 源码包管理 区别： 安装前的区别：概念上的区别，见上述 安装后的区别：安装位置的区别 RPM包（一个软件）的默认安装位置： /etc/：配置文件 /usr/bin/：可执行的命令 /usr/lib/：程序所使用的函数库 /usr/share/doc/：基本的软件使用手册 /usr/share/man/：版主文档 /var/www/html/：服务器类软件的默认网页位置 源码包的安装位置： 需要手动指定安装目录：一般推荐/usr/local/软件名/ RPM包和源码包安装软件带来的影响：启动服务的方式不同 RPM包在/etc/rc.d/init.d/下有执行文件，采用两种方式启动： /etc/rc.d/init.d/httpd start service httpd start 源码包的服务启动方式不能用系统服务管理命令例如service来管理 只能在/usr/local/软件名/bin/执行软件码 start 目录下启动服务 Apache源码包的具体安装步骤： 安装C语言编译器：gcc 下载apache的源码包：path 确认源码保存位置/usr/local/src/ 确认软件安装位置：/usr/local/ 如何确认安装过程报错安装过程停止并出现error，warning，no等提示语言 解压缩下载的源码包：tar -zxvf 源码包名 进入解压缩目录：INSTALL和README时安装说明和使用说明 执行./configure --prefix=默认安装目录：编译前准备 定义需要的功能选项 检测系统环境是否符合安装要求 把定义好的的功能选项和检测系统环境的信息都写入Makefile文件（./configure过程会生成），用于后续的编译 执行make：编译 如果前两步报错，执行make clean，清空过程中生成的临时文件。 执行make install：安装 删除源码包安装的软件：直接rm -rf /usr/local/软件名/ 脚本安装包与软件包管理 脚本安装包不是独立的软件包类型，常见安装的是源码包 人为包安装过程写成额自动安装的脚本，只要执行脚本，定义简单的参数，就可以完成安装 非常类似于windows下软件的安装方式 Webmin是一个基于Web的Linux系统管理界面，可以通过图形化的方式设置用户账号、Apache、DNS、文件共享等服务。下载软件，下载后解压缩，并进入解压缩目录，执行.sh安装脚本,最后登录ip地址的自己配置的端口号进入该网站即可 如何选择包安装？ 如果对外服务，选择源码包安装，例如：Apache 如果本机使用，RPM包安装，例如：gcc编译器 Linux中的用户管理 用户配置文件 越是安全性要求高的服务器越需要对用户权限等级制度和服务器操作规范有很高的要求，linux中主要通过用户配置文件来查看和修改用户信息 主要有四个配置文件：/etc/passwd，/etc/shadow，/etc/group，/etc/gshadow /etc/passwd：用户信息文件 格式（7个字段） 用户名称； 密码标志； UID：用户ID 0：超级用户 1—499：系统用户:不能登录，不能删除 500—65535：普通用户 GID：组ID：这里是初始组ID不是附加组ID 用户说明：备注 家目录； 普通用户：/home/用户名/ 超级用户：/root/ Shell 命令解释器类型，默认是bash /etc/shadow：影子文件 是passwd的影子，默认权限：000 格式（9个字段） 用户名称； 加密密码； SHA512加密，可以暴力破解 如果密码是：“!!”和 “*”，表示没有密码，不能登录 密码最后一此修改时间；时间戳表示：使用1970年1月一日作为标准时间，每过一天时间戳加1 两次密码修改间隔（天）； 密码时效天数（-1永不失效）； 密码修改到期前的警告天数； 密码到期后的宽限天数； 账号失效时间；时间戳表示 保留字段 时间戳换算： 时间戳—>日期：date -d \"1970-01-01 16066 days\" 日期—>时间戳：echo$(($(date --date=\"2014/01/06\" +%s)/86400+1)) /etc/group&/etc/gshadow：组信息文件&组密码文件 /etc/group格式（4个字段） 组名， 组密码标志， GID， 组中附加用户 /etc/gshadow格式（4个字段） 组名， 组密码(默认没有，也不推荐使用)， 组管理员用户名， 组中附加用户 Linux中查看用户的初始组的方法：查询etc/passwd和/etc/group，两两对照查看 用户管理相关文件 用户的家目录：（会自动生成） 普通用户：/home/用户名/：权限700 超级用户：/root/：权限550 用户的邮箱： /var/spool/mail/用户名/ 用户模板目录：就是母板，新建用户会默认创建在用户家目录下 把/etc/skel/目录下的文件复制到用户家目录下 /etc/skel/ 用户管理命令 useradd 创建用户：useradd [选项] 用户名 新建一个用户实际上就是在上述六个地方生成了默认信息，所以手工修改上述六个地方就可以手工添加用户 useradd -u UID：指定自定义UID useradd -d 家目录：指定自定义家目录 useradd -c 用户说明：指定自定义用户说明 useradd -g 组名：指定自定义初始组组名 不建议修改 useradd -G 组名1,组名2：指定自定义附加组组名 useradd -s shell：指定自定义登录shell，默认是/bin/bash 用户默认值配置文件：/etc/default/useradd 和 /etc/login.defs passwd 修改用户密码：passwd [选项] 用户名 超级用户可以改任意用户密码 普通用户只能给自己设密码passwd whoami：查看当前用户 passwd -S 用户名 ：查看密码状态，就是shadow里面的信息，仅root用户可用 passwd -l 用户名 ：锁定用户，实际是在shadow中的密码前面加了“!”，仅root用户可用 passwd -u 用户名 ：解锁用户 passwd --stdin 用户名 ：使用字符串作为用户密码 例如：echo \"123\" | passwd --stdin 用户名，shell编程添加多个用户时使用 usermod 修改用户信息：usermod [选项] 用户名 usermod -u UID：修改UID usermod -c 用户说明：修改用户说明 usermod -G 组名1,组名2：修改附加组 usermod -g 组名：修改初始组（不推荐） usermod -L：锁定用户（Lock） usermod -U：解锁用户（Unlock） chage 修改用户密码状态：chage [选项] 用户名 chage -l：查询密码详细状态 chage -d 日期：修改密码最后一次更改日期 chage -m 天数：修改两次密码修改间隔 chage -M 天数：修改密码有效期 chage -W 天数：修改密码过期前警告天数 chage -I 天数：修改宽限天数 chage -E 日期：修改账号失效时间 注意：实际是对shadow文件里面的信息进行修改，chage -d 0 用户名 使用最多，把用户的修改密码时间归零，强制用户第一次登陆系统必须修改密码 userdel 删除用户：userdel [选项] 用户名 userdel -r 用户名：删除用户的同时删掉家目录 不推荐手工创建用户，但是可以手工删除用户的相关信息： etc/passwd etc/shadow etc/group etc/gshadow var/spool/mail/用户名 /home/用户名/ 手工把上面6个位置和要删除的用户的相关信息删除就可以了 id 查询用户uid，gid和附加组：id 用户名 su 用户切换：su [选项] 用户名 su - 用户名 ：连带用户的环境变量一起切换，中间减号绝对不能省去，省去就不会切换环境变量 su - root -c 命令名：不切换root，只是执行root权限才能执行的命令 用户组管理命令 groupadd 添加用户组：groupadd [选项] 组名 groupadd -g（GID）组名：指定组ID groupmod groupmod -g 新组id 旧组id groupmod -n 新组名 旧组名 尽量不修改 groupdel groupdel 组名：要想删除一个组，这个组中不允许有初始用户存在 gpasswd 把用户添入组或者从组中删除：gpasswd [选项] 组名 gpasswd -a 用户名：把用户加入组 gpasswd -a 用户名 组名 gpasswd -d 用户名：把用户从组中删除 gpasswd -d 用户名 组名 注：也可以直接在/etc/group文件里添加附加组(不推荐改初始组) 总结： Linux中用户和用户组的关系是： Linux权限管理 ACL权限 ACL权限的简介和开启方式 任何一个文件在一个时刻只能有一个所有者和所属组 ACL权限用来解决文件的权限身份不够用的情况 ACL权限需要分区支持： dumpe2fs -h /dev/sda5/ 查看是否支持acl选项，如果不支持。 /dev/sda5/ 为df -h 查看根分区对应的文件系统 可以临时开启：mount -o remount,acl / 重新挂载根分区，并挂载加入acl权限 或者永久开启：vim /etc/fstab，然后重启系统 在根分区的defaults后面加个：,act 慎用：任何错误都会导致挂载失败 ACL权限类似于windows的权限设置方法，就是不考虑user，group和others的权限设置，单独添加一个用户或者一个用户组对一个文件或者目录的权限 查看与设定ACL权限 getfacl 查看ACL的权限：getfacle 文件名 setfacl 设置ACL的权限：setfacl [选项 ] 文件名 setfacl -m u/g/m：用户名/组名/不写权限 文件名：设定文件的ACL权限 setfacl -m u:用户名:权限 文件名：设定文件用户的ACL权限 为用户分配ACL权限，使用“u:用户名:权限”格式 例：setfacl -m u:user1:rwx /test/ setfacl -m g:组名:不写权限 文件名：设定文件用户组的ACL权限 为组分配ACL权限，使用“g:组名:权限”格式 setfacl -x ：删除指定的ACL权限 setfacl -b ：删除所有的ACL权限 setfacl -d ：设定默认ACL权限 setfacl -k ：删除默认ACL权限 setfacl -R ：递归设定ACL权限 最大有效权限与删除ACL权限 最大有效权限mask：可以通过getfacl 文件名来查看ACL的权限，里面有mask，可以通过控制mask的值来修改默认最大有效权限。 需要注意的是mask权限不会影响当前文件所有者，只会影响ACL权限和所属组的权限 setfacl -x u/g:用户名/组名 文件名：删除文件指定的ACL权限 setfacl -b 文件名：删除文件所有ACL权限 默认ACL和递归ACL权限（只能针对目录） setfacl -m d:u/g: 用户名/组名:权限 文件名：设定父目录的默认ACL权限，父目录里所有的新建文件都会继承父目录的ACL权限 d参数就是设置默认的ACL权限 setfacl -k：删除父目录的默认ACL权限 setfacl -m [选项] -R 文件名：递归设定文件夹的ACL权限 setfacl -m u:test:rx -R 文件名 文件特殊权限 SetUID：在所有者的x位置上变成了s针对二进制文件 passwd命令拥有SetUID权限，所以普通用户能修改自己密码 四个条件缺一不可： 只有二进制文件（例如命令和脚本文件）才能设定SUID权限 命令执行者必须对该程序有x权限 命令执行者会在执行的时候获得该程序文件的属主身份 SUID权限只在该程序执行过程中生效，也就是身份改变旨在程序执行过程中有效 我们通常会看到4777，2777，1777的权限标识，依次是加了SUID，SGID，SBIT权限 4代表SUID 2代表SGID 1代表SBIT 设定SetUID的方法 4代表SUID chmod 4755 文件名 chmod u+s 文件名 取消SetUID的方法 chmod 755 文件名 chmod u-s 文件名 可以用chmod来赋予和删除SUID SetUID是非常危险的，一个命令只要有了s权限，例如passwd命令，普通用户就可以通过执行这个命令获得passwd的属主身份，也就是进入root权限。 比如：给vim加了SetUID后，普通用户就会有root权限，例如：修改/etc/passwd文件，非常危险。 关键目录应严格控制写权限（普通写权限，不是SetUID权限）。比如“/”、“/usr”等 用户的密码设置要严格遵守密码三原则 对系统中默认应该具有SetUID权限的文件作出备份，定时检查有没有这之外的文件被设置了SetUID权限 SetGID：在所属组的x位置上变成了s 针对二进制文件和目录 针对二进制文件，四个条件缺一不可： 只有可执行的二进制文件才能设置 命令执行者必须对该程序有x权限 命令执行者会在执行的时候获得该程序文件的所属组身份 SUID权限只在该程序执行过程中生效，也就是所属组身份改变旨在程序执行过程中有效 注：例如/usr/bin/locate命令 针对目录，三个条件缺一不可： 普通用户必须对此目录拥有r和x权限，才能进入该目录 普通用户在此目录中的有效组会变成此目录的所属组 若普通用户对此目录拥有w权限时，新建的文件的默认组不是文件自己的初始组，而是这个目录自己的所属组 可以用chmod来赋予和删除SGID 设定SetGID的方法 2代表SGID chmod 2755 文件名/二进制文件 chmod g+s 文件名/二进制文件 取消SetGID的方法 chmod 2755 文件名/二进制文件 chmod g-s 文件名/二进制文件 Sticky BIT(黏着位)：在其他人的x位置上变成了t 针对目录 三个条件缺一不可： 只有目录才能设定SBIT权限 普通用户必须对该目录有x和w权限 有了SBIT，普通用户即使有目录的w权限，也不能删除其他用户建立的文件 设定SBIT的方法 1代表SBIT chmod 1755 文件名 chmod o+s 文件名 取消SBIT的方法 chmod 1755 文件名 chmod o-s 文件名 需要注意的安全性： 需要定期对系统中含有SUID或者SGID权限的文件进行检查，如果有异常多出来的含有该权限的文件，如果多出来了，是一个极大的安全隐患，需要手工清除。 文件系统属性chattr权限 chattr（change file attributes on a linux file system） 格式：chattr [+-=] [选项] 文件或目录名 符号 +：增加权限 -：删除权限 =：等于某权限 选项 i： 1.对文件：不允许任何用户（包括root用户）对文件进行任何修改，只能读 2.对目录：任何用户（包括root用户）只能在目录下修改文件内容，但是不能删除和创建文件 a： 1.对文件：任何用户（包括root用户）只能对文件增加数据，但是不能删除和修改现有数据 2.对目录：任何用户（包括root用户）只能在目录中建立和修改文件里的内容，但是不能删除文件 lsattr 查看文件系统属性：lsattr 选项 文件名 lsattr -a 文件名：显示所有文件和目录 lsattr -d 文件名：若文件时目录，仅列出目录自己的属性 系统命令sudo权限 之前学的是对文件的操作权限，sudo是对系统命令的权限。 sudo权限是root把本来只能超级用户执行的命令赋予普通用户的执行 root权限先执行命令visudo命令 实际修改的是：/etc/sudoers文件 在这一行root ALL=(ALL) ALL下面添加 root ALL=(ALL) ALL 给用户 格式：用户名 被管理主机的地址 = （可使用的身份）授权命令（绝对路径） 第一个ALL：允许在命令在哪台计算机上执行 第二个ALL：把前面的用户转变成这个身份，一般不用 第三个ALL：所有命令，应该写具体权限 %wheel ALL=(ALL) ALL 给组 %组名 被管理主机的地址=（可使用的身份）授权命令 （绝对路径） 例如：jack ALL=/sbin/shutdown -r now：授权jack能重启服务器的权限 sudo -l：查看自己能用那些sudo命令 sudo：执行sudo命令：sudo [绝对路径命令] 注意：vim命令不用设置sudo给普通用户，否则会拥有root的所有权限，非常危险 Linux的文件系统管理 分区和系统文件 分区类型 对于硬盘分区形式是MBR的 分区图 一： 二： 规定了：1、2、3、4只能分配给主分区（主分区最多4个），所以逻辑分区从5开始 主分区：总共最多只能分4个 扩展分区： 包含逻辑分区 只能有一个 也算作主分区的一种 主分区+扩展分区 不能存储数据和格式化 必须再分成逻辑分区才能使用 如果是IDE硬盘，Linux最多支持59个逻辑分区 如果是SCSI硬盘，Linux最多支持11个逻辑分区 对于GPT分区形式而言，没有上述限制 文件系统 Linux的文件系统可分为 ext2：是ext文件系统的升级版本，最大支持16TB的分区和最大2TB的文件（1TB=1024G=1024*1024KB） ext3：是ext2文件系统的升级版本，最大的区别就是带日志功能，以在系统突然停止时提高文件系统的可靠性，最大支持16TB的分区和最大2TB的文件（1TB=1024G=1024*1024KB） ext4：是ext3文件系统的升级版本，ext4在性能、伸缩性和可靠性方面进行了大量改进。 向下兼容EXT3 最大1EB文件文件系统和16TB文件（1EB=1024PB=1024*1024TB） 无限数量子目录 Extents连续数据块概念 多块分配 延迟分配 持久预分配 快速FSCK 日志校验 无日志模式 在线碎片整理 inode增强 默认弃用barrier等，默认CentOS 6.3的默认文件系统 swap： vfat： Windows文件系统为：FAT16、FAT32、FAT64和NTFS。而格式化的目的就是写入文件系统 文件系统常用命令 df命令，du命令，fsck命令，dumpe2fs命令 df df [选项] df -a： 显示所有分区 df -h：人性化显示。(一般用来统计系统空间大小) du du [选项] [目录或文件名] du -a：显示每个子文件的磁盘占用量。默认只统计子目录的磁盘占用量 du -h ：人性化显示 du -s：弥补ls命令的不足，可以统计文件夹包括里面的内容的大小而不是单单文件夹的大小。(一般用来统计文件大小)，避免服务器高运载下使用 df和du的区别 du只是面向文件的，只会计算文件或目录占用的空间； df是从文件系统角度考虑的，不光要考虑文件占用的空间，还要统计被命令或程序占用的空间（最常见的就是文件已经删除但是程序并没有释放空间）， 所以df看到的才是真正的可以使用的空间 fsck 文件系统修复命令，不需要自己手动执行：fsck [选项] 分区设备文件名 系统会自动执行，除非需要手动去执行，否则不用管 fsck -a 分区设备文件名：不用显示用户提示，自动修复文件系统 fsck -y 分区设备文件名：自动修复，和-a作用一致，不过有些文件系统只支持-y dumpe2fs 显示磁盘状态：dumpe2fs 分区设备文件名 显示ext2、ext3、ext4文件系统的超级块和块组信息 挂载命令 将设备文件名和绑定到盘符(挂载点)上，Windows是自动，Linux默认是手动分配 mount -l：查询异已挂载的设备，加-l会显示卷标名 mount -a：依据配置文件/etc/fstab中的内容，自动挂载 mount 挂载命令格式：mount [-t 文件系统] [-L 卷标名] [-o 特殊选项] 设备文件名 挂载点 -t：文件系统：加入文件系统类型来指定挂载的类型，可以ext3、ext4、iso9660等文件系统 -L：卷标名：挂载指定卷标的分区，而不是安装设备文件名挂载 -o：特殊选项：可以制度挂载的额外选项 没特殊需求不需要加特殊选项 挂载光盘和U盘 Linux中的分区时开机自动挂载，但是光盘和U盘时手动挂载，系统准备了/mnt/和/media/来挂载 /mnt：挂载U盘 /media：挂载光盘 挂载光盘步骤 sr0和cdrom都可以作为设备文件名 建立挂载点：mkdir /mnt/cdrom/ 挂载：mount -t iso9660 /dev/cdrom /mnt/cdrom/或者mount /dev/sr0 /mnt/cdrom 设备文件名：/dev/cdrom和/dev/sr0是固定的 去挂载点访问：cd /mnt/cdrom/ 在拿走光盘之前需要先卸载光盘：umount 设备文件名或挂载点 挂载U盘步骤 U盘的设备文件名是自动识别的，用fdisk -l查看 建立挂载点：mkdir /mnt/usb/ 挂载：mount -t vfat /dev/sdb1 /mnt/usb/ /dev/sdb1：fdisk -l 查看的 去挂载点访问：cd /mnt/usb/ 在拔U盘之前需要先卸载光盘：umount 设备文件名或挂载点 注意： 挂载U盘只能用本机或者虚拟机，不能用远程工具 Linux默认是不支持NTFS文件系统的外设的，U盘只能FAT格式的 Linux如何支持NTFS文件系统 Linux系统的内核中已经把市面上常见的驱动包括了，所以安装系统后一般不需要安装驱动，Linux会自动匹配识别，如果Linux默认没有把一个文件系统的驱动加载进来，我们就需要手动去安装驱动。 几种让Linux支持NTFS文件系统的方法： 内核重新编译 第三方的插件：ntfs-3g 内核编译太麻烦，太高端，一般选择“ntfs-3g插件”来实现 安装步骤： 解压：tar -zxvf ntfs-3g_ntfsprogs-2013.1.13.tgz 进入解压目录：cd ntfs-3g_ntfsprogs-2013.1.13 编译前准备：./configure 编译：make 编译安装：make install 挂载NTFS分区的硬盘：mount -t ntfs-3g 设备文件名 挂载点 fdisk分区 fdisk命令分区过程 虚拟机添加新硬盘，并用fdisk -l查询新硬盘是否被识别 若已识别新硬盘/dev/sdb/，就开始为新硬盘分区 进入fdisk交互模式：fdisk /dev/sdb/ partprobe 分完区后必须执行这个命令，重新读取分区表信息 然后格式化分区 mkfs -t ext4 /dev/sdb1 mkfs -t ext4 /dev/sdb5 最后创建挂载点并挂载 mkdir /disk1 mkdir /disk5 mount /dev/sdb1 /disk1/ mount /dev/sdb1 /disk5/ fdisk -l：查看，两个分区挂载完毕 分区自动挂载和/etc/fstab文件修复 上面的mount命令挂载只能临时生效，每次重启都要手动挂载硬盘，要想永久生效，就要修改/etc/fstab配置文件的内容。 添加了挂载信息后，执行mount -a，依据配置文件/etc/fstab中的内容，自动挂载 万一/etc/fstab文件写错了，会导致系统崩溃 /etc/fstab文件修复 出错后按提示进入root操作界面，发现/etc/fstab文件是只读 执行：mount -o remount,rw / 就可以修改/etc/fstab文件了，就可以修复了。 分配swap分区 free 查看内存与swap分区使用状况 新建swap分区 fdisk /dev/sdb 进入分区交互模式 记得修改分区ID号为82 使用t修改分区ID号 l：查看分区类型 partprobe mkswap /dev/sdb6 格式化 swapon /dev/sdb6 加入swap分区 swapoff /dev/sdb6 取消swap分区 swap分区开机自动挂载 Shell Shell基础 Shell概述 shell就是Linux中的命令解释器，说白了，就是一个命令行的交互界面。 与Linux不同Windows中就是图形的交互界面。 shell还是一个强大的编程语言，因为它可以直接调用Linux的系统命令。 Shell的种类： Bourne Shell语法类：sh，ksh，Bash，psh，zsh C Shell语法类（只要同于BSD的Linux版本中）：csh，tcsh Bash Shell：Bash与sh兼容，是目前的主流 在文件/etc/shells中，可以查看Linux中默认支持的Shell类型，在命令行下输入shell的名字就可以切换shell类型 Shell脚本的执行方式 echo 输出指定内容：echo [选项] [输出内容] echo -e：支持反斜线的字符转换 支持颜色输出 First Script # ！bin/bash：表示以下代码为shell 执行方法 第一种： chmod 755 hello.sh ./hello.sh 第二种： bash hello.sh 注意：如果一个shell脚本在Windows中编辑完成，在Linux中发现运行出错，这是因为Windows和Linux格式不同，你可以用cat -A [文件名] 来验证，换行符不同。解决方法就是用命令dos2unix将Windows格式转化为Linux格式 Bash的基本功能 历史命令与命令补全 history 历史命令：history [选项] [历史命令保存文件] history n：显示最近的n条命令 history -d n：删除第n条命令 history -c：清空历史命令 history -w：把缓存中的历史命令写入每个用户的缓存文件~/.bash_history 历史命令默认会保存1000条，可以在环境变量配置文件/etc/profile中进行修改 使用 使用上，下箭头的方式调用历史命令， 使用“!n”重复执行第n条历史命令 使用“!!”重复执行上一条命令 使用“!字符串”重复执行最后一条以该字符串开头的命令 命令与文件补全 在Bash中，命令与文件补全是非常方便与实用的功能，我们只要在输入命令或文件时，按“Tab”键就会自动进行补全 命令别名与常用快捷键 命令别名 alias 查询命令别名，实际就是查看~/.bashrc文件的内容 alias 别名=\"原命令\" 设定命令别名；For Example：alias vi='vim' unalias 删除别名：unalias 别名 命令执行的顺序： 第一顺位执行用绝对路径或相对路径的命令 第二顺位执行别名 第三顺位执行Bash的内部命令（内部命令就时用whereis找不到的Linux自带命令） 第四顺位执行按照$PATH环境变量定义的目录查找顺序找到的第一的命令（外部命令） 让别名永久生效：写入~/.bashrc配置文件 常用快捷键 Ctrl+下列的字母 c：强制终止当前命令 l：清屏 u：剪切光标之前的内容 k：剪切光标后的内容 y：粘贴 r：搜索历史 d：退出当前终端，相当于logout z：暂停进程，放入后台 建议别用 s：暂停屏幕输出 q：恢复屏幕输出 输入输出重定向 标准输入输出设备 键盘：/dev/stdin：标准输入：0文件描述符 显示器：/dev/sdtout：标准输出：1文件描述符 显示器：/dev/sdterr：标准错误输出：2文件描述符 输出重定向 改变输出方向，把命令的正确或者输出结果输出到指定的文件中 正确输出和错误输出同时保存进一个文件中： 以覆盖的方式： 命令 > 文件 2>&1 > ：覆盖 2>&1 ：是标准格式 命令 &> 文件 以追加的方式： 命令 >> 文件 2>&1 >> ：追加 2>>&1 ：是标准格式 命令 &>> 文件 比较简洁 把正确的输出保存进文件A，错误的输出保存进文件B： 命令 >>文件A 2>>文件B 输入重定向： 后面既可以直接加文件名，也可以将输入重定向作为输入，不过后者在结果中不会显示文件名，因为它指挥识别输入的文件内容流 wc wc [选项] [文件名]，用得不多 wc -c：统计字节数 wc -w：统计单词数 wc -l：统计行数 多命令顺序执行与管道符 多命令顺序执行 ;：两个命令都会执行 命令1;命令2 &&：命令1正确执行，命令2才会执行 命令1 && 命令2，例子：源码安装的时候，make && make install ||：命令1错误执行，命令2才会执行 命令1 || 命令2 dd命令 磁盘复制命令，和cp命令不同，dd可以复制特殊文件，分区甚至整个硬盘。主要的作用就是磁盘复制 dd if=输入文件 of=输出文件 bs=多少字节数作为一个块 count=块的个数 if=输入文件 ：指定源文件或源设备 of=输出文件：指定目标文件或目标设备 bs=字节数：指定一次输入/输出多少字节，即把这些字节看做一个数据块 count=个数：指定输入/输出多少个数据块 例子：date;dd if=/dev/zero of=/root/testfile bs=1k count=100000;date 用来显示磁盘复制的时间 命令 && echo yes || echo no shell编程里面应用判断命令是否执行成功：如果命令执行成功，输出yes，执行失败，输出no 管道符 命令1的正确输出作为命令2的操作对象：命令1 | 命令2 grep 在文件中搜索符合条件的字符串：grep [选项] \"搜索内容\" grep -i：忽略大小写 grep -n：输出行号 grep -v：反向查找 grep –color=auto：搜索出的关键字用颜色显示 netstat -an | grep ESTABLISHED 通配符与其他特殊符号 通配符 ?：匹配一个任意字符 *：匹配任何内容（0个或任意多个字符） []：匹配中括号中的任意一个 [-]：匹配中括号中范围内任意一个 [^]：逻辑非，表示匹配任意一个不是中括号内的一个字符0-9表示任意一个不是数字的字符 通配符是用来匹配文件名的，通配符通常会用来删除指定范围的文件 特殊符号 单引号中的所有符号都是符号 echo '$SHELL' 双引号中的符号可能会有特殊意义 echo \"$SHELL\" 反引号和$() 符号中的内容是系统命令 反引号：`` $()：推荐使用 echo \"$(ls)\"和echo '$(ls)' echo \"$(ls)\"：双引号输出ls查询的结果 echo '$(ls)'：单引号输出$(ls) # ：开头时注释 $：用来调用变量 \\：用来将特殊符号变成普通符号 Bash的变量 变量分类 用户自定义变量 环境变量 主要保存的是和系统操作环境相关的数据，允许新建 位置参数变量 主要用来向脚本当中传递参数或数据的，变量名不能自定义，变量作用是固定的，是预定义变量的一种 预定义变量 是Bash中已经定义好的变量，变量名不能自定义，变量作用也是固定的 变量命名规则 由字母、数字和下划线组成，但是变量名不能用数字开头 bash中，变量的默认类型都是字符串型，如果要进行数值运算，需要指定变量类型为数值型 变量用等号连接值，等号左右两侧不能有空格 变量名若有空格，需要单引号或双引号包括 变量值中可以用转义符\\让特殊字符失去特殊含义 变量值可以进行叠加，不过变量需要用双引号包括“$变量名”或${变量名}包括 如果是把命令的结果作为变量值赋予变量，则需要使用反引号或$()包含命令 环境变量名建议大写 用户自定义变量 用户自定义变量（本地变量） name=”jack” 可以叠加： newname=\"$name\"yang newname=${name}yang $ 调用变量：$变量名 set 查看系统中所有的变量 unset 删除变量：unset 变量名 环境变量 本地变量只在当前的shell中生效 环境变量会在当前和这个shell的所有子shell中生效，如果把环境变量写入相关的文件，那么这个环境变量会在所有的shell中生效 用pstree可以查看shell的父子关系 export 申明普通变量为环境变量：export 变量名=变量值 env 专门查看环境变量 unset 删除变量：unset 变量名 常用系统环境变量 PATH 查找系统命令的变量 tab键补全和外部命令的查找都是根据$PATH来的 可以用变量叠加的方式把自己的命令加到$PATH中，PATH=\"$PATH\":/root/test.sh PS1 定义系统提示符的变量 echo $PS1 查看 PS1='格式' 自定义命令提示符 位置参数变量 不建议写位置参数脚本，其他人不知道各个位置参数的用处 $n：$0表示命令本身，之后就是命令行参数 $*：所有参数，把所有参数当作一个整体 $@：所有参数，把参数区别对待 $#：所有参数的个数 举例 ./test.sh 11 22 预定义变量 $?：返回上一次执行结果正确与否 $$：当前进程的PID $!：后台运行的最后一个进程的PID read 接收键盘输入：read [选项] [变量名] -p “提示信息”：在等待read输入时，输出提示信息 必须携带 -t 秒数：限定时间，指定等待时间 必须携带 -n 字符数：限定字符数，不加-n就要回车键结束 -s：隐藏输入的信息，适用于输入密码时 举例 Bash的运算 数值运算与运算符 数值运算 Linux中变量默认类型时字符串 declare 声明变量类型：declare [+/-][选项] 变量名 -：给变量设定类型属性 -i：将变量声明为整数类型 -x：将变量声明为环境变量 +：取消变量的类型属性 -p：显示指定变量的被声明的类型 举例:（四种计算格式，最常用的是第三种） aa=11；bb=22 declare -i cc=$aa+$bb cc=$(expr $aa + $bb) cc的值是aa和bb的和，注意“+”好左右两侧必须有空格 cc=$(($aa+$bb)) 双小括号：运算；单小括号：系统命令 cc=$[$aa+$bb] 运算符 越靠上的优先级越高 示例 变量测试与内容替换 需要的时候对照使用 环境变量配置文件 环境变量配置文件简介 source 不需要重新登录，让修改后的配置文件直接生效 source 配置文件 . 配置文件 `“.” 就是source的缩写，注意“.”后面有个空格` 环境变量配置文件中主要就是定义对系统的操作环境生效的系统默认环境变量，比如PATH，HISTSIZE，PS1，HOSTNAME等 主要的5个配置文件 /etc/profile：针对所有用户 /etc/profile.d/*.sh：针对所有用户 ~/.bash_profile：针对单个用户 ~/.bashrc：针对单个用户 /etc/bashrc：针对所有用户 环境变量配置文件作用 环境变量配置文件调用的顺序 /etc/profile：针对所有用户 USER变量 LOGNAME变量 MAIL变量 PATH变量 HOSTNAME变量 HISTNAME变量 HISTSIZE变量 umask 调用/etc/profile.d/*.sh文件 /etc/profile.d/*.sh：针对所有用户 执行profile.d目录下所有sh文件 ~/.bash_profile：针对单个用户 追加PATH：在PATH变量后面加上了:$HOME/bin这个目录 调用~/.bashrc ~/.bashrc：针对单个用户 定义别名 /etc/bashrc：针对所有用户 定义别名和PS1（登录提示符） 会重复调用PATH，umask啥的，但是只针对no login shell的情况，就是直接敲sh进入一个shell的情况 其他配置文件和登录信息 注销时的配置文件：~/.bash_logout 可以清空一些环境变量等 历史命令的保存文件：~/.bash_history 排错依据 登录信息 本地终端欢迎信息：/etc/issue 远程终端欢迎信息：/etc/issue.net 转义符在该文件中不能使用，只能纯文本登录 是否生效由ssh的配置文件/etc/ssh/sshd/config决定，要加入Banner /etc/issue.net，重启ssh服务生效：service sshd restart 登陆后的欢迎信息：/etc/motd（本地和远程都适用） 推荐特效字符定制网站ASCII Generator Shell编程 基础正则表达式 正则表达式和通配符区别 通配符：在系统中搜索匹配文件名，是完全匹配。支持命令ls，find，cp，他们不认识正则表达式 正则表达式：用来在文件中匹配符合条件的字符串，是包含匹配。支持命令：grep，awk，sed *：前一个字符匹配0次或者任意多次 .：匹配任意一个字符（换行符除外） ^：匹配以后面字符作为行首的行 $：匹配以后面字符作为行尾的行 ^$：匹配空白行 []：匹配中括号中的指定的任意一个字符 ：匹配除中括号中的字符外的任意一个字符 \\：转义符 {n}：表示其前面的字符恰好出现n次 {n,}：表示其前面的字符出现不少于n次 {n,m}：表示其前面的字符至少出现n次，最多出现m次 字符截取命令 grep 提取符合条件的行 -c：只输出匹配行的计数 -i：不区分大小写 -v：显示不包含匹配文本的所有行 cut 提取符合条件的列：cut [选项] 文件名 -f 列号：提取第几列 -d 分隔符：按照指定分隔符分割列，默认是制表符tab 示例 cat/etc/passwd | grep /bin/bash | grep -v root | cut -d \":\" -f 1：用来提取出普通用户名 df -h | grep \"sda5\" | cut -f 5：用来提取硬盘的使用率 如果是空格，则不能很好使用，需要更复杂的awk命令 printf 按找类型输出格式输出内容，使用awk时格式化输出：printf \"输出类型输出格式\" 输出内容 %ns：输出字符串 n是数字代指输出几个字符 %ni：输出整数 n是数字代指输出几个数字 %m.nf：输出浮点数 m和n是数字，指代输出的整数位数和小数位数。如%8.2f代表共输出8位数，其中2位是小数，6位是整数。 \\n，\\r，\\t：换行，回车，tab键 printf '%s %s %s' 1 2 3 4 5 6：最后输出结果按照%s %s %s格式分为两组 printf命令不能用管道符，只能printf %s $(cat XXX.txt) 在awk命令的输出中支持print和printf命令 print：print会在每个输出之后自动加入一个换行符（Linux默认没有print命令） printf：printf是标准格式输出命令，并不会自动加入换行符，如果需要换行，需要手工加入换行符 awk 截取列： cut可以截取字符时，使用cut，否则使用awk 很强大的命令，可以说是一门编程语言 格式：awk ’条件1{动作1} 条件2{动作2} 条件3{动作3}‘ 文件名 前面可以加管道符 动作 格式化输出：printf 流程控制语句 示例 awk ‘{printf $2 “\\t” $6 “\\n”}’ XXX.txt df -h | awk '{printf $1 \"\\t\" $5 \"\\t\" $6}'：可以处理空格，弥补了cut的不足，但是awk很多命令很复杂 df -h | grep sda5 | awk ’{print $5}‘ | cut -d \"%\" -f 1 print可以在awk里面使用默认结尾加个换行符 BEGIN：在所有命令执行之前先执行BEGIN后面的语句块,awk默认是先读入一行再执行后面的语句 END：在所有语句处理完后执行 FS：指定分隔符，awk ’{FS=\":\"}‘ awk ‘{FS=\":\"} {print $1 \"\\t\" $3}’ /etc/passwd awk ‘BEGIN{FS=\":\"} {print $1 \"\\t\" $3}’ /etc/passwd awk还支持条件判断：awk ’$6>=87 {printf $2 \"\\n\"}‘： sed 数据的流编辑器，主要是用来将数据进行选取、替换、删除、新增的命令 vim只能修改文件，sed还可以直接修改管道符传过来的流 格式：sed [选项] ‘[动作]’ 文件名 选项： -n：sed默认把所有数据都输出到屏幕，加上-n表示只把经过sed修改过后的行输出到屏幕 -e：允许对输入数据应用多条sed命令编辑 -i：用sed的修改结果直接修改读取数据的文件，而不是由屏幕输出 会改变源文件，比较危险，不建议使用 动作： a：行后追加（多行时，行尾要加\\） sed ‘2a hello’ XXX.txt c：替换（多行时，行尾要加\\） sed ‘4c no the line’ XXX.txt：替换第二行 i：行前插入（多行时，行尾要加\\） sed ‘2i hello \\ world’ XXX.txt：在第二行前面插入 d：删除 sed ‘2,4d’ XXX.txt：删除第二行（没加-i选项不会修改源文件，只是删除输出的结果） p：打印 sed ‘2p’ XXX.txt：打印第二行 s：字串替换 sed ‘4s old/new/g’ XXX.txt：替换第四行的旧字符串替换为新字符串 字符处理命令 sort 排序（可接收管道符数据）：sort [选项] 文件名 -f：忽略大小写 -r：反向排序 -t ：指定分隔符，默认分隔符是制表符 -n：按照数值大小来排，默认使用字符串型排序 -k n[,m]：按照指定的字段范围排序，从第n字段开始，m字段结束（默认到行尾） wc： 统计字符（可接收管道符数据）：wc [选项] 文件名 -l：只统计行数 -c：只统计字符数 -w：只统计单词数 条件判断 两种判断格式 test -e XXX.txt [ -e XXX.txt ]：注意首尾各有一个空格 shell中常用 示例 [ -d /root ] && echo \"yes\" || echo \"no\"：如果是目录yes，否则no 按照文件类型判断 -e：判断文件是否存在（存在为真） -b：判断文件是否存在，并且是否是块设备文件 -c：判断文件是否存在，并且是否是字符设备文件 -d：判断文件是否存在，并且是否是目录文件 -f：判断文件是否存在，并且是否是普通文件 -L：判断文件是否存在，并且是否是链接文件 -p：判断文件是否存在，并且是否是管道文件 -S：判断文件是否存在，并且是否是套接字文件 -s：判断文件是否存在，并且是否是非空 按照文件权限进行判断 -r：判断文件是否存在，并且是否该文件有读权限，u，g，o中任意一个有都为真 -w：判断文件是否存在，并且是否该文件有写权限，u，g，o中任意一个有都为真 -x：判断文件是否存在，并且是否该文件有执行权限，u，g，o中任意一个有都为真 -u：判断文件是否存在，并且是否该文件有SUID权限，u，g，o中任意一个有都为真 -g：判断文件是否存在，并且是否该文件有SGID权限，u，g，o中任意一个有都为真 -k：判断文件是否存在，并且是否该文件有SBIT权限，u，g，o中任意一个有都为真 两个文件之间进行比较 文件1 -nt 文件2：判断文件1的修改时间是否比文件2新 文件1 -ot 文件2：判断文件1的修改时间是否比文件2旧 文件1 -ef 文件2：判断文件1的inode号是否和文件2一致，可以用来判断两个文件是不是互为硬链接 两个整数之间比较 整数1 -eq 整数2：相等 整数1 -ne 整数2：不等 整数1 -gt 整数2：大于 整数1 -lt 整数2：小于 整数1 -ge 整数2：大于等于 整数1 -le 整数2：小于等于 示例：[ 3 -lt 2 ] && echo yes || echo no 字符串的判断 -z：判断是否为空 判断变量是否为空：[ -z \"$name\" ] && echo yes || echo no -n：判断是否为非空 字串1 == 字串2：判断是否相等 字串1 != 字串2：判断是否不等 多重条件判断 判断1 -a 判断2：逻辑与 示例： aa = 10 [ -n \"$aa\" -a \"$aa\" -gt 9 ] && echo yes || echo no 判断1 -o 判断2：逻辑或 ! 判断：逻辑非 注意!后面有空格 流程判断 if语句 和[-d /root] && echo \"yes\" || echo \"no\"作用一样，但更直观 单分支if 实例 双分支if 多分支if case语句 for循环 第一种语法 示例 第二种语法 示例 while循环和until编程 while循环 示例 until循环 示例 Linux的服务管理 服务简介与分类 Linux服务分类 RPM包默认安装的服务 独立的服务 基于xinetd（超级守护进程）服务 源码包安装的服务（第三方源码包） 服务的启动与自启动 查询已安装的服务 RPM包安装的服务：chkconfig --list 查看RPM包安装的服务按照运行级别的自启动状态。 查看是否在系统下次启动时自启动，而不是查看服务是否当前已启动 查询当前启动的服务 ps aux netstat service --status-all 源码包安装的服务：没有命令，只能去服务安装位置查看，一般在/usr/local/下 其实源码包和RPM包安装的服务在Linux中的区别就是安装位置不同 源码包安装在指定位置，一般是/usr/local/下 RPM包安装在默认位置中，配置文件在/etc/下，启动命令在/etc/rc.d/init.d/下，分散到很多文件夹下 RPM包安装服务的管理 RPM包安装的服务默认保存位置：(特殊文件有自己的默认保存位置) 独立服务的管理 启动方式 /etc/init.d/ 独立服务名 start | stop | status | restart 推荐使用 service 独立服务名 start | stop | restart | status rea hat独有，service 相当于/etc/inin.d 自启动方式 方式一：打开自启动：chkconfig [--level 运行级别] [独立服务名] on 不支持源码包安装的服务 关闭自启动：chkconfig 独立服务名 off 默认就是：2345 方式二：修改/etc/rc.d/rc.local文件，加入需要自启动的服务名 推荐 方式三：使用ntsysv命令管理自启动，图形界面很直观 red hat专有 基于xinetd(超级守护进程)服务的管理 默认情况下Linux是没有xinted的，需要手动安装yum -y install xinetd 然后用chkconfig --list查看，基于xinetd的服务不占用内存，但是需要的响应时间更长 基于xinetd的服务的启动，修改/etc/xinetd.d/下对应的服务的配置文件,然后service xinetd restart 基于xinetd的服务的自启动： chkconfig 服务名 on和chkconfig 服务名 off 图形界面工具：ntsysv 基于xinetd的启动和自启动是通用的，两者区分不是很严格，这种设置不利于管理，所以现在基于xinetd的服务越来越少了 自启动关闭，服务也会关闭，2者相通 源码包安装服务的管理 源码包安装的服务默认保存位置：/usr/local/ 源码包安装服务的启动和关闭(用绝对路径的启动脚本启动)：/usr/local/apache2/bin/apachectl start|stop 一般每一个源码包都有安装说明INSTALL，应该查看里面的启动方法 源码包安装服务的自启动： vim /etc/rc.d/rc.local加入/usr/local/apache2/bin/apachectl start 把源码包服务的启动脚本软连接到/etc/init.d/目录下和chkconfig --add 服务名，就可以实现service，chkconfig和ntsysv命令管理源码包安装服务，但是并不推荐，容易混乱。 总结 Linux系统管理 进程管理 进程管理的作用：（下面优先级由高到低） 判断服务器的健康状态（CPU、内存的占用情况） 常用命令：top 查看系统中的所有进程 命令：ps aux 和 ps -el 和 pstree 杀死进程 不常用，尽可能正常操作结束服务，不能正常关闭时再用 进程查看 ps aux 查看系统中所有进程，查看BSD操作系统格式 ps -le 查看系统中所有进程，Linux格式 输出格式的作用 ps aux top 查看系统健康状态：top [选项] 需要的时候使用，top命令比较耗资源 -d 秒数：默认每3秒更新一次，可指定 ？或h：显示交互模式的帮助 P：以CPU使用率排序，默认选项 M：以内存使用率排序 N：以PID排序 q：退出top top命令的显示 重点关注最后一个平均负载(除以 Cpu 核数，如果大于 1.5，表示超出负荷，小于 1.5 基本正常) 重点关注第4个CPU的空闲率 重点关注第3个内存的空闲率 pstree 查看进程树：pstree [选项] -p：显示进程的PID -u：显示进程的所属用户 进程终止 正常命令不能终止服务时才使用 kill kill [信号] PID -l：查看kill支持的信号 小写l -1 PID：重启进程 -9 PID：终止进程 killall 按照进程名杀死，选项和kill通用：killall [选项] [信号] 进程名 -i：有询问 -I：忽略进程名的大小写 大写的i pkill 按照进程名杀死，选项和kill通用：pkill [选项] [信号] 进程名 也可以加t选项跟终端号：pkill -t 终端号：按照终端号踢出用户，用 w 命令查询系统中登录的用户，然后用终端号来踢 工作管理 类似Windows的最小化 把进程放入后台 命令后面加&：后台继续运行 在命令执行过程中，按下ctrl+z快捷键：放入后台即暂停 jobs 查看后台的工作：jobs [-l] -l：显示工作的PID 注意：“+”号代表最近一个放入后台的工作，也是工作恢复时，默认恢复的工作；“-”号代表倒数第二个放入后台的工作。 fg 恢复后台暂停的工作恢复到前台运行：fg %工作号 %工作号：%号可以省略，但是注意工作号和PID的区别 bg 恢复后台暂停的工作恢复到后台运行：bg %工作号 %工作号：%号可以省略，但是注意工作号和PID的区别 但是不能恢复和前台有交互的命令比如top命令和vim命令，因为就是给用户展示，后台运行没意义 注意：工作号≠PID 系统资源查看 vmstat 监视系统资源使用情况： vmstat [刷新延时(s) 刷新次数] 和top内容差不多，但更简洁 dmesg 开机时内核检测，一般结合grep使用 free 查看内存使用情况：free [选项] -b：以字节为单位显示 -k：以KB为单位显示（默认就是） -m：以MB为单位显示 -g：以GB为单位显示 查看CPU信息： cat /proc/cupinfo：每次开机都会更新 dmesg | grep CPU uptime：实际就是top命令第一行，跟w看到的一样 uname 查看系统与内核相关信息：uname [选项] -a：查看系统所有相关信息 -r：查看内核版本 -s：查看内核名称 file /bin/ls 判断当前系统的位数（通过系统外部命令的位数来推测） lsb_release -a 查询Linux系统的发行版本 lsof 列出进程打开或使用的文件信息：lsof [选项] -s 字符串：只列出以字符串开头的进程打开的文件 -u 用户名：只列出某个用户的进程打开的文件 -p pid：列出某个PID进程打开的文件 系统定时任务 前提：必须启动crond服务：service crond restart，并且chkconfig crond on，Linux系统都是默认启动和自启动的 crontab 设置系统定时任务：crontab [选项] -e：编辑crontab定时任务 打开文件编辑的格式是： * command或执行脚本 第一个*：分钟（0-59） 第二个*：小时（0-23） 第三个*：天（1-31） 第四个*：月（1-12） 第五个*：星期（0-7，0和7都代表星期日） 特殊符号： 示例 定期脚本里面的日期输出需要加“\\”转义符，原本：date +%y%m%d，定时任务里的脚本：date +\\%y\\%m\\%d -l：查询crontab任务 -r：删除当前用户所有的crontab任务 删一个任务，进去编辑删除需要删除的任务（vim操作） Linux日志管理 日志管理简介 百度百科简介：系统日志是记录系统中硬件、软件和系统问题的信息，同时还可以监视系统中发生的事件。用户可以通过它来检查错误发生的原因，或者寻找受到攻击时攻击者留下的痕迹。系统日志包括系统日志、应用程序日志和安全日志。 服务器出现问题先查看日志，才能找准原因 CentOS7中原来的日志服务syslogd被rsyslogd取代，两者兼容 确认服务是否启动和自启动： ps aux | grep rsyslogd chkconfig --list | grep rsylog 常见的日志的作用 RPM包安装的服务日志也会在/var/log/目录下 源码包安装的服务日志在源码包指定目录（一般是/usr/local）中，这些日志不是有rsyslogd服务来管理的，而是由各个服务使用自己的日志管理文档来记录自身日志 你安装了这些服务就会有 rsyslogd日志服务 日志文件格式 事件产生的时间 产生事件的服务器的主机名 产生事件的服务名或程序名 事件的具体信息 /etc/rsyslog.conf配置文件 格式 * authpriv.* /var/log/secure * 服务名称 [连接符号] 日志等级 日志记录位置 `authpriv：服务名称 .：连接符号 *：日志等级` * 服务名称，连接符，日志等级，日志记录位置都有多个，内容很多，自行百度。 常见的服务 连接符号 “*”不是连接符号，是所有日志等级 日志等级 从低等级到高等级（上到下） 日志记录位置 日志轮替 如果日志都记录在一个文件中，那么可能会占据大量存储空间，纯文本文档打开会非常慢，所以日志需要处理：切割（把大日志按天切割成小的）+轮换（删除旧的，保存新的） 日志文件的命名规则 如果配置文件中有“dateext”参数，那么日志会用日期作为后缀，例如：“secure-20200603”，只需要保存指定的日志个数，删除多余的日志文件即可 推荐使用 如果没有“dateext”参数，那么日志文件就需要改名了，当第一次使用日志轮替时，当前的“secure”日志会自动改名为“secure.1”，然后新建“secure”日志。第二次时，1变2，0变1，又新建0，以此类推 配置文件 /etc/logrotate.conf 只要是RPM包安装的服务，它默认已经支持轮替，但是源码包安装的服务需要vim /etc/logrotate.conf，然后手动加入轮替 示例 logrotate logrotate [选项] 配置文件名 如果此命令没有选项，则会按照配置文件中的条件进行日志轮替 logrotate -v /etc/logrotate.conf：显示日志轮替过程 logrotate -f /etc/logrotate.conf：强制轮替，不管日志轮替的条件是否已经满足 Linux启动管理 CentOS 6.x的启动管理 运行级别：7个级别 runlevel：查看运行级别 init 运行级别：改变当前运行级别 vim /etc/inittab：永久修改系统默认运行级别，写上id:3:initdefault 不要把0和6设为默认级别 CentOS6系统启动过程：针对MBR模式 initramfs内存文件系统 CentOS 6.x中使用initramfs内存文件系统去嗲了Centos5.x中的initrd RAM Disk。他们的作用类似，可以通过启动引导程序加载到内存中，然后加载启动过程中所需要的的内核模块，比如USB、SATA、SCSI硬盘的驱动和LVM、PAID文件系统的驱动 查看 不能在boot目录下做操作 调用/etc/init/rcS.conf配置文件 主要功能是两个 先调用/etc/rc.d/rc.sysinit，然后又/etc/rc.d/rc.sysinit配置文件进行Linux系统初始化 然后再调用/etc/inittab，然后由/etc/inittab配置文件确定系统的默认运行级别 调用/etc/rc.d/rc文件 启动引导程序grub Grub配置文件：/boot/grub/grub.conf 格式： default=0： 默认启动第一个系统 timeout=5： 等待时间，默认是5秒 splashimage=(hd0,0)/grub/splash.xpm.gz：指定grub启动时的背景图像文件的保存位置 hiddenmenu： 隐藏菜单 title CentOS(2.6.32-279.el6.i686)： 标题 root (hd0,0)： 指启动程序的保存分区 kernel /vmlinuz-2.6.32-279.el6.i686 ro： 定义了内核加载时的选项 initrd /initramfs-2.6.32-279.el6.i686.img： initramfs内存文件系统镜像文件的所在位置 系统修复模式 单用户模式常见的错误修复 遗忘root密码 修改系统默认运行级别 光盘修复模式 这些是后门，说的Linux针对的是网络安全 Linux备份与恢复 备份概述 Linux中需要备份的数据：/root/目录，/home/目录，/var/spool/mail/目录，/etc/目录，其他目录 安装的服务的数据也需要备份 apache需要备份的数据：配置文件，网页主目录，日志文件 mysql需要备份的数据 源码包安装的：/usr/local/mysql/data/ RPM包安装的：/var/lib/mysql 备份策略 完全备份：效果最高，但需要更大的硬盘空间 增量备份：每次备份只备份新的数据，占用空间少，但是恢复起来麻烦 差异备份：每次备份都只备份完全备份中不存在的，折中方法 备份命令 完全备份完全可以用tar打包压缩来做，但是如果是差异备份就会非常麻烦，这时就需要用到Linux为数据备份量是打造的备份和恢复命令dump命令和restore命令 dump dump [选项] 备份之后的文件名 原文件名或目录 -级别：0到9个备份级别 0是完全备份，1就是第一次增量备份，以此类推9就是第9次增量备份 -f 文件名：指定备份之后的文件名 -u：把备份时间记录在/etc/dumpdates文件中 -v：显示备份过程 -j：把备份文件压缩为.bz2格式 -W：查看详情，显示允许被dump的分区的备份等级及备份时间 注意：dump命令只有在备份分区的时候才能增量备份，备份普通目录或文件只能完全备份 示例 restore restore [模式选项] [选项] 四个模式 不能混用 -C：比较备份数据和实际数据的变化 -i：交互模式，手工选择需要恢复的文件 -t：查看模式，用于查看备份文件中拥有哪些数据 -r：还原模式，用于数据还原 一个选项 -f：指定备份文件的文件名 "},"Linux/基础/01-Linux系统简介.html":{"url":"Linux/基础/01-Linux系统简介.html","title":"Linux系统简介","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux系统简介 UNIX和Linux发展史 1965年，贝尔实验室：MULTICS计划 69年，贝尔实验室的肯汤普森：为了游戏开发UNICS/UNIX系统 62年，美国军方：ARPA：阿帕网，NCP协议——》TCP/IP协议 71年，可汤普森和丹尼斯里奇发明C语言，重写UNIX UNIX主要发行版本：AIX(IBM)、HP-UX(HP)、Solaris(Sun)、Linux(Intel,AMD……)、BSD 1991年，芬兰大学生Linus Torvalds开发linux内核。大学教授开发minix，但是不接受外来代码，所以李纳斯独自开发，由社区共同维护。 Linux内核版本号：主版本.次版本.末版本 linux内核官网 Linux发行版本：两大派系redhat和debian 开源软件简介 商业软件和开源软件（开源≠免费） 开源软件：apache、NGINX、MySQL、php、mongoDB、python、Ruby、Perl、Go、Rust、Swift、Java 开源软件的特点：使用自由（绝大多数免费）、研究自由（源代码）、散步和改良的自由 支撑互联网的开源技术（LAMP）：Linux，Apache，MySQL，PHP Linux应用领域 基于Linux的企业服务器 踩点网站：发数据包根据相应嗅探服务器 世界前500服务器 嵌入式应用 手机，平板：Android底层是Linux 智能家电，航空系统，银行系统…… 在电影娱乐业 特效，图形处理渲染 Linux学习方法 Linux只考虑应用性和稳定性 善于观察提示信息，查找文档，自己解决问题 学习英文：Command not found和No Such file or directory 忘掉Windows的操作习惯 计划，专注，坚持，练习 "},"Linux/基础/02-Linux系统安装.html":{"url":"Linux/基础/02-Linux系统安装.html","title":"Linux系统安装","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux系统安装 VMware虚拟机安装 VMware官网下载，不推荐安装双系统 特点： 不需要分区就能在物理机上使用两种以上的操作系统 物理机和虚拟机能实现网络通信 可以设定并随时修改虚拟机操作系统的硬件环境 要求： CPU：主频1GHz以上 内存：1GB以上 硬盘：8GB以上 镜像下载：官网下载: 几个版本：DVD版本，Everything版本，minimal版本，LiveGnome版本，KdeLive版本，livecd版本，NetInstall版本 系统分区 主分区：最多只能有4个 扩展分区：最多只能有一个；主分区加扩展分区最多有4个；不能写入数据，只能包含逻辑分区 逻辑分区：可以和主分区一样正确的写入数据和格式化 注意：兄弟连这套视频录制时间较为久远，当时的硬盘分区形式是MBR的，所以上述的分区限制也只 是针对MBR分区形式，对于GPT分区形式而言，则没有上述限制了。 电脑根据主板的不同（BOIS或者UEFI），会决定硬盘选择MBR分区方案还是GPT分区方案： BIOS + MBR UEFI + GPT 两者区别： 也就是说，电脑使用传统BIOS主板，建议使用MBR分区方案；电脑使用UEFI主板，建议使用GPT分区方案 MBR分区表最多只能识别2TB左右的空间，大于2TB的容量将无法识别从而导致硬盘空间浪费；GPT分区表则能够识别2TB以上的硬盘空间。 MBR分区表最多只能支持4个主分区或三个主分区+1个扩展分区(逻辑分区不限制)；GPT分区表在Windows系统下可以支持128个主分区。 在MBR中，分区表的大小是固定的；在GPT分区表头中可自定义分区数量的最大值，也就是说GPT分区表的大小不是固定的。 硬盘分区的作用： 把一块大硬盘分成几块 格式化的作用： 写入文件系统（1.把硬盘分成一个个等大小的数据块 同时2.建立一个inode列表） Linux中的所有硬件都是文件： 硬盘文件名： IDE硬盘：/dev/hd[a-d] SCSI/SATA/USB硬盘：/dev/sd[a-p] 光驱：/dev/cdrom或/dev/sr0 鼠标：/dev/mouse 分区文件名： /dev/hda[数字] /dev/sda[数字] 挂载： 给分区分配挂载点 /根分区 swap交换分区（内存两倍，最大不超多2GB） /boot启动分区（200MB足够） 总结： 分区：把大硬盘分为小的分区 格式化：写入文件系统，同时会清空数据 分区设备文件名：给每个分区定义设备文件名 挂在：给每个分区分配挂载点，这个挂在点必须是空目录 Linux系统安装 把镜像加进去，点击启动，然后用图形界面配置分区和其他的自定义选项，确定定义root用户的密码和普通用户的账号和密码。然后等待安装完成即可。 远程登陆管理工具 三种网络连接方式： 桥接模式：虚拟机使用物理网卡 NAT模式：虚拟机使用vmnet8虚拟网卡 Host-only模式：虚拟机使用vmnet1虚拟网卡，并且只能和本机通信 临时配置ip：ifconfig ens33 192.168.XXX.XXX 永久配置ip： 查看网络接口：ifconfig 去网络接口的配置文件进行修改 [root@bogon ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33/ ens33是网卡接口 配置文件 TYPE=“Ethernet” PROXY_METHOD=“none” BROWSER_ONLY=“no” BOOTPROTO=“none” //dhcp是自动获取 DEFROUTE=“yes” IPV4_FAILURE_FATAL=“no” IPV6INIT=“yes” IPV6_AUTOCONF=“yes” IPV6_DEFROUTE=“yes” IPV6_FAILURE_FATAL=“no” IPV6_ADDR_GEN_MODE=“stable-privacy” NAME=“ens33” UUID=“d8ee940a-1a27-4417-9ae8-88a5364ee4d1” DEVICE=“ens33” ONBOOT=“yes” //引导激活 IPADDR=172.16.10.188 //ip地址 NETMASK=255.255.255.0 //子网掩码 GATEWAY=172.16.10.254 //网关 DNS1=222.88.88.88 //DNS "},"Linux/基础/03-Linux使用注意事项-新手必看.html":{"url":"Linux/基础/03-Linux使用注意事项-新手必看.html","title":"Linux使用注意事项","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux使用注意事项（新手必看） Linux 严格区分大小写 和 Windows 不同，Linux 是严格区分大小写的，包括文件名和目录名、命令、命令选项、配置文件设置选项等。 例如，Windows 系统桌面上有一个名为 Demo 的文件夹，当我们在桌面上再新建一个名为 demo 的文件夹时，系统会提示文件夹命名冲突；而 Linux 系统不会，Linux 系统认为 Demo 文件和 demo 文件不是同一个文件，因此在 Linux 系统中，Demo 文件和 demo 文件可以位于同一目录下。 因此，初学者在操作 Linux 系统时要注意区分大小写的不同。 Linux 中所有内容（包括硬件设备）以文件形式保存 Linux 中所有内容都是以文件的形式保存和管理的（硬件设备也是文件），这和 Windows 完全不同，Windows 是通过设备管理器来管理硬件的。比如说，Linux 的设备文件保存在 /dev/ 目录中，硬盘文件是 /dev/sd[a-p]，光盘文件是 /dev/hdc 等。 Linux 不靠扩展名区分文件类型 我们都知道，Windows 是依赖扩展名区分文件类型的，比如，\".txt\" 是文本文件、\".exe\" 是执行文件、\".ini\" 是配置文件、\".mp4\" 是小电影等。但 Linux 不是。 Linux 系统通过权限位标识来确定文件类型，且文件类型的种类也不像 Windows 下那么多，常见的文件类型只有普通文件、目录、链接文件、块设备文件、字符设备文件等几种。Linux 的可执行文件不过就是普通文件被赋予了可执行权限而已。 Linux 中的一些特殊文件还是要求写 \"扩展名\" 的，但大家小心，并不是 Linux 一定要靠扩展名来识别文件类型，写这些扩展名是为了帮助管理员来区分不同的文件类型。这样的文件扩展名主要有以下几种： 压缩包：Linux 下常见的压缩文件名有 .gz、.bz2、.zip、.tar.gz、.tar.bz2、.tgz 等。为什么压缩包一定要写扩展名呢？很简单，如果不写清楚扩展名，那么管理员不容易判断压缩包的格式，虽然有命令可以帮助判断，但是直观一点更加方便。另外，就算没写扩展名，在 Linux 中一样可以解压缩，不影响使用。 二进制软件包：CentOS 中所使用的二进制安装包是 RPM 包，所有的 RPM 包都用\".rpm\"扩展名结尾，目的同样是让管理员一目了然。 程序文件：Shell 脚本一般用 \".sh\" 扩展名结尾，其他还有用 \".c\" 扩展名结尾的 C 语言文件等。 网页文件：网页文件一般使用 \"*.php\" 等结尾，不过这是网页服务器的要求，而不是 Linux 的要求。 在此不一一列举了，还有如日常使用较多的图片文件、视频文件、Office 文件等，也是如此。 Linux中所有存储设备都必须在挂载之后才能使用 Linux 中所有的存储设备都有自己的设备文件名，这些设备文件必须在挂载之后才能使用，包括硬盘、U 盘和光盘。 挂载其实就是给这些存储设备分配盘符，只不过 Windows 中的盘符用英文字母表示，而 Linux 中的盘符则是一个已经建立的空目录。我们把这些空目录叫作挂载点（可以理解为 Windows 的盘符），把设备文件（如 /dev/sdb）和挂载点（已经建立的空目录）连接的过程叫作挂载。这个过程是通过挂载命令实现的，具体的挂载命令后续会讲。 Windows 下的程序不能直接在 Linux 中使用 Linux 和 Windows 是不同的操作系统，两者的安装软件不能混用。例如，Windows 系统上的 QQ 软件安装包无法直接放到 Linux 上使用。 系统之间存在的这一差异，有弊也有利。弊端很明显，就是所有的软件要想安装在 Linux 系统上，必须单独开发针对 Linux 系统的版本（也可以依赖模拟器软件运行）；好处则是能感染 Windows 系统的病毒（或木马）对 Linux 无效。 "},"Linux/基础/04-Linux各目录的作用.html":{"url":"Linux/基础/04-Linux各目录的作用.html","title":"Linux各目录的作用","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux各目录的作用 /bin/：存放系统命令 /sbin/：存放系统目录，只有超级用户能用 /usr/bin/：存放系统命令，单用户模式不能执行 /usr/sbin/ ：存放系统命令，只有超级用户能用，单用户模式不能执行 /boot/ ：系统启动目录，内核和启动引导程序 /dev/ ：硬件设备文件目录 /etc/ ：linux默认的配置文件保存目录 /home/：普通用户家目录 /root/：超级用户家目录 /lib/：系统调用的函数库 /lost+found/：当系统意外崩溃时，每个分区都含有的存放的文件碎片用来修复 /media/：挂载目录，挂载媒体设备 /mnt/：挂载目录，挂载U盘，移动硬盘，和其他操作系统的分区 /misc/：挂载目录，挂载NFS服务的共享目录 /opt/：第三方安装的软件的保存目录，也可以放到 /usr/local/ 下 /proc/：存放在内存里面，存放系统的内核，进程，外部设备 /sys/：存放在内存里面，存放系统的内核相关的东西 /srv/ ：服务数据目录 /tmp/ ：临时目录，可以清空 /usr/：系统资源目录 /var/：动态资源保存目录，日志，邮件，数据库 "},"Linux/基础/05-服务器注意事项.html":{"url":"Linux/基础/05-服务器注意事项.html","title":"服务器注意事项","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb 服务器注意事项 远程服务器不允许关机，只能重启 重启时应该关闭服务 不要在服务器访问高峰运行高负载命令 远程配置防火墙（过滤不是防病毒，比如允许某个端口运行访问）时不要把自己踢出服务器 指定合理的密码规范和定期更新 合理分配权限 定期备份重要数据和日志（系统备份：etc、boot、usr等目录） "},"Linux/基础/06-Linux常用命令.html":{"url":"Linux/基础/06-Linux常用命令.html","title":"Linux常用命令","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux常用命令 文件处理命令 ls（list） ls [参数] [路径] ls -l：查看文件所有属性 ls -d：查看目录本身（而不是查看目录下的信息） ls -i：查看文件的inode号 ls -h：人性化显示（文件大小以K, M显示） ls -s：显示文件占用的块的数量 ls -a：查看隐藏文件 mkdir（make directories）创建目录：mkdir [参数] [目录] mkdir -p：递归创建目录 cd（change directories） 切换目录：cd [路径] pwd（print work directories） 查看完整工作路径 rmdir （remove empty directories） 删除空目录：rmdir [目录名] cp（copy） 复制文件或目录：cp -rp [原文件或目录] [目标目录] cp -r：复制目录 cp -p：原文件和新文件属性完全一致 注：复制的同时可以改名 mv（move） 剪切文件、改名：mv [原文件或目录] [目标目录] 注：移动的同时可以改名 rm（remove） 删除文件或目录：rm -rf [文件或目录] rm -r：文件夹递归删除（删除目录） rm -f：强制删除，不询问 注： 删除之前做好备份 误删除之后对硬盘少做读写操作 touch 创建空文件：touch [文件名] cat 显示文件内容：cat [文件名] cat -n：显示行号 tac 显示文件内容（反向查看）：tac[文件名] more 分页显示文件：空格翻页，回车换行，q退出 查看命令帮助信息时就是使用more来查看 less 分页显示文件（可向上翻页）：空格翻页，回车换行，q退出，还可以pageup回翻页，上箭头网上翻一行，还可以搜索：/关 键词，再按n搜索下一个匹配的 head 显示文件前面几行：head [参数] [文件名] head -m：指定看前几行，默认前10行 tail 显示文件后面几行：tail [参数] [文件名] tail -n：指定看后几行，默认后10行 tail -f：动态看文件动态变化 ln（link） 生成链接文件：ln [原文件] [目标文件] ln -s：生成软链接 软连接特征：类似Windows快捷方式 lrwxrwxrwx：软连接的权限不起作用，还是要看源文件权限 文件大小：很小，只是符号链接 箭头指向源文件 什么时候需要用到软连接？Windows时你什么时候需要用到快捷方式时就用 ln：生成硬链接 硬链接特征 拷贝cp -p + 同步更新：cp -p的区别是硬链接文件和原文件可以同步更新 硬链接通过inode号来区分 不能跨分区 不能针对目录 硬链接和软连接的区别 1.硬链接不能跨分区 2.硬链接不能针对目录 权限管理命令 chmod（change the permissions mode of a life） 改变文件或目录权限：chmod [参数] [文件或目录] chmod [u/g/o/a] [+/-/=] [r/w/x] u：所有者；g：所属组；a：所有人；举例：chmod u+w；chmod u+x, o-wr chmod 三位数XXX：r—4，w—2，x—1：举例：rwxr-xr-x：755 （最常用） chmod -R：递归修改目录及目录下的权限 注释：深入理解文件的wrx和目录的wrx的意义 删除一个文件的权限不是对这个文件有写权限，而是对这个文件的目录有写权限 一个目录往往都是同时有r和x权限，可进入目录和查看目录下的文件 chown（change file ownership） 改变文件或目录所有者：chown [用户名] [文件或目录]：只有管理员root能执行 例：chown root:testgroup /test/ chgrp（change file group ownership） 改变文件或目录所属组：chgrp [组名] [文件或目录]：只有管理员root能执行 注：每个文件都只有一个user和一个group，某些others拥有拥有共同的权限，这些others在一个组里，也就是group所属组。所属者user可以不在所属组group里面，并且一个用户可以在不同的组里。 相关的命令是： groupadd YYY //创建组 useradd -g YYY XXX //创建用户并将YYY设置为其主要组 usermod -g ZZZ XXX //修改用户XXX的主要组为ZZZ umask（the user file-creation mask） 显示、设置文件的缺省权限 umask -S：人性化显示默认权限，以rwx形式显示新建文件缺省权限 umask：显示掩码（非人性化） 比如：0022，权限 实际上为：777 - 022 = 755 注：Linux中，默认创建的文件是没有可执行权限的（touch 创建的文件），所以文件是666，目录是777 umask 三位数：修改掩码，使默认权限变化umask 023；中文修改户的掩码为0023，权限为：754，并不建议修改 文件搜索命令 尽量少搜索，特别是在高峰期时 find 文件精准搜索：find [搜索范围] [匹配条件] find [搜索范围] -name：根据文件名搜索 find [搜索范围] -iname：根据文件名搜索，不区分大小写 注：通配符：*，？，[] *：匹配多个字符；举例：find /ete -name init（模糊搜索，包含即可） ？：匹配单个字符；举例：find /ete -name init???（搜索以init开头后面还有3个字符的文件） find [搜索范围] -size [+/-]n： +n：大于； -n：小于，只有数据块（0.5KB）个数； n：等于 find [搜索范围] -user：根据所有者查找 find [搜索范围] -group：根据所属组查找 find [搜索范围] -amin [-/+]分钟数：查找指定时间内或者超过该时间被修改过访问时间的文件(access) find [搜索范围] -cmin [-/+]分钟数：查找指定时间内或者超过该时间被修改过文件属性的文件(change) find [搜索范围] -mmin [-/+]分钟数：查找指定时间内或者超过该时间被修改过文件内容的文件(modify) 还可以在两个查找条件之间加上 -a ：一个是同时满足(and) -o ：一个是满足任意一个即可(or) 或者-exec/-ok 命令 [空格] {} [空格] \\； 对搜索结果执行操作 示例：find ./ -name test.txt -exec ls -l {} \\; -ok：是对后面的命令逐个询问 find [搜索范围] -type：根据文件类型查找 find [搜索范围] -inum：根据inode号查找 locate 模糊查找：locate 文件名 系统里所有的文件都会定期收录到/var/lib/mlocate.db这个文件库里，locate就是在这个里去找，但是新的文件没别收录进去，所以就找不到，需要手动更新文件资料库updatedb （但是tmp目录下不收录进去） locate -i：不区分大小写 which 查找命令的地址和别名alias：which 命令名 whereis 查找命令地址和其帮助文档的位置：whereis 命令名 grep 在文件里面查找字串匹配的行并输出：grep [-iv] [指定字串] [文件] grep -i：不区分大小写，查找指定字串所在的行 grep -v：排除指定字串所在的行 指定字串前面加个 ^ 表示以什么字串开头 帮助命令 man （manual）或 info （information） 查看命令和配置文件的帮助信息，浏览和more操作一样：man 命令名/配置文件名 帮助类型里1是命令的帮助，5是配置文件的帮助 For Example：man 1 passwd，man 5 passwd whatis 更加简单的命令查询，查看命令作用 apropos 更加简单的配置文件查询 –-help 得到信息更加简单：命令 ––help help 获得shell的内置命令的帮助，比如：cd，pwd，umask，if等 用户管理命令 useradd和passwd 新建用户和修改密码 who和w 查看当前登录用户名：tty是本地登录，pts表示远程登录 who简单信息 w 其中第一行：当前时间，已经运行的时间（服务器），多少个用户登录，服务器负载均衡（CPU，内存等负载情况）这行类型也可以 通过uptime获得 IDLE：表示用户空闲时间（多久没操作了） JCPU：累计占用的CPU时间 PCPU ：当前用户登录后占用CPU的时间 WHAT：当前执行的操作 压缩解压命令 几种压缩格式 .gz .zip .bz2 gzip（GNU zip）和 gunzip/gzip -d （GNU unzip） 压缩/解压文件：gzip/gunzip [文件] 解压缩：gunzip[文件] 或 gzip -d [文件] 只能压缩文件，不能压缩目录，并且不保留原文件 压缩文件后缀：.gz tar 打包目录：tar [选项] [压缩后文件名] [目录（可以多个空格隔开）] tar -c：打包 tar -x：解包 tar -v：显示详细信息 tar -f：指定文件名 tar -z：打包的同时压缩，或者解包的时候解压缩,适用于压缩解压gz tar -j：同-z，适用于压缩解压bz2 举例：tar -cvf XXX.tar YYY gzip XXX.tar ，最后生成XXX.tar.gz 。或者直接tar -zcvf打包压缩一部合成，反向是tar -zxvf 压缩文件后缀：.tar.gz zip和unzip 压缩文件或目录：zip [选项] [压缩后文件名] [文件或目录]，压缩比不高 压缩后能保留原文件 zip -r：压缩目录 压缩文件后缀：.zip bzip2和bunzip2 bzip2 /bunzip2 [选项] [文件] bzip2 -k：压缩的同时保留原文件 bunzip -k：解压的同时保留原文件 gzip的升级版本，压缩比较好 用tar生成.tar.bz2文件：tar -cjf xxx.tar.bz2 xxx 压缩文件后缀：.bz2 网络命令 write 给在线用户发信息，以ctrl+D保存结束：write wall （write all） 给当前在线的所有用户发送信息：wall [信息内容] ping 测试网络连通性：ping 选项 [IP地址] 网络踩点，Linux会一直ping下去 ping -c 次数：定义ping的次数 ifconfig （interface configure） 查看当前系统网卡信息和设置网卡信息（临时的）：ifconfig 网卡名称 IP地址 mail 查看和发送邮件：mail [用户名] 不一定要在线 mail 用户名：发送 mail：查看的子命令： q：退出 help(帮助)， 数字(查看指定邮件)， 列表：h(列表)， 删除：d 数字(删) last 日志查询命令，统计系统的所有登录信息： lastlog 查看用户最后登录的信息 lastlog -u uid：查看指定用户上次登录的信息 traceroute 跟踪节点的路径：traceroute ip地址 netstat 显示网络相关信息：netstat [选项] netstat -t：TCP协议（有3次握手） netstat -u：UDP协议（无3次握手，快，但是不保证数据收到） netstat -l：监听 netstat -r：路由 netstat -n：显示ip地址和端口号 最常用的三种组合命令： netstat -tlun：查看本机监听的端口 1：标志协议：TCP/UDP 2：数据包接收队列：0代表网络通畅，表示收到的数据已经在本地接收缓冲，但是还有多少没有被进程取走，recv()如果接收队列Recv-Q一直处于阻塞状态，可能是遭受了拒绝服务 denial-of-service 攻击。 3：数据包发送队列：0代表网络通畅，对方没有收到的数据或者说没有Ack的,还是本地缓冲区. 如果发送队列Send-Q不能很快的清零，可能是有应用向外发送数据包过快，或者是对方接收数据包不够快。 4：本机IP地址和端口（主要查看的内容） 5：监测状态：TCP才有，UDP没有（你可以直接发送，不管在不在线，不需要监听） netstat -an：查看本机所有的网络连接 跟-tlun的区别是可以查看正在连接的服务 netstat -rn：查看本机路由表 setup redhat系linux独有 配置网络的工具：永久生效 配置玩需要重启网络服务：service network restart 挂载命令 mount mount [-t 文件系统] 设备文件名 挂载点 举例：mount -t iso9660 /dev/sr0 /mnt/cdrom /dev/sr0：设备文件名，系统默认的 umount 卸载：umount 设备文件名 关机重启命令 shutdown shutdown [选项] 时间 shutdown -h 时间（new）：关机 shutdown -r 时间：重启 shutdown -c：取消前一个关机命令 谨慎操作 其他关机命令：halt,poweroff,init 0 其他重启命令：reboot,init 6 init 系统运行级别： 0：关机， 1：单用户， 2：不含NFS服务的多用户， 3：完全多用户， 4：未分配， 5：图形界面， 6：重启 /etc/inittab配置文件里面有运行级别的信息，方便查询，也可以改运行级别 init 数字：设置系统运行级别，临时更改 runlevel：查询系统运行级别 logout和exit 都是退出登录：logout退出是把因为你注销了登陆机而把你踢出的退出，exit是你直接退出连接的机器。 "},"Linux/基础/07-强大的文本编辑器Vim.html":{"url":"Linux/基础/07-强大的文本编辑器Vim.html","title":"强大的文本编辑器Vim","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb 强大的文本编辑器:Vim 概述 Vim是linux中的一款使用最广的文本编辑器，全屏幕编辑器。 可以建立，编辑，显示文本文件。 它没有菜单只有命令. 三种模式 命令模式：输的东西都会当做命令处理 插入模式 后：a/A（行末） 前：i/I（行首） 行：o（光标下）/O（光标上）进入 退出模式：ESC键 常用操作 :set ic————搜索时不区分大小写 行号相关： :set nu————显示行号 :set nonu————关闭行号 定位相关 gg————快速定位到第一行 G————快速定位到最后一行 nG————快速定位到第n行 :n————快速定位到第n行 $————快速定位到行尾 0————快速定位到行首 删除相关 x————删除光标后字符 X————删除光标前字符 nx————删除光标后n个字符 dd————删除一行 dd————删除当前行，ndd删除当前行和下面的n-1行 dG————删除当前行到文件末尾 D————删除光标到行尾 :2,8d————删除第2行到第8行 复制粘贴替换相关 yy————复制当前行 nyy————复制当前行和下面的n-1行 p————粘贴到光标上一行 P————粘贴到光标下一行 dd/ndd 和 p/P ————剪切（删除和粘贴组合） r————替换当前字符 R————从当前位置一直往后替换（进入替换模式，esc退出模式） u————恢复 ctrl+r————撤销恢复 /string————搜索命令，按n找下一个 :%s/old/new/g————全文替换old为new :n1,n2s/old/new/g————n1到n2行替换old为new 退出保存相关 :w————保存（相当于Windows的ctrl+r） :w filename————另存为 :wq————保存并退出 ZZ————保存并退出 :q!————不保存退出 :wq!————强制保存退出，针对只读文件可以强行保存(只有文件所有者和root才可以) 使用技巧 查看命令的执行结果：:!命令 查看命令的地址：:!which 命令名 导入内容到文件中 导入文件内容：:r 导入文件地址(路径) 导入命令执行结果：:r !命令 导入命令的地址：:r !which 命令 导入当前时间：:r !date 定义快捷键 :map 快捷键（Ctrl + v + 自己想要的数字或字母） 触发命令 关键词自动替换 :ab mymail XXXXXXX@gmail.com 输入mymail是自动替换为你的邮箱地址 多行注释与取消注释 方法一 注释：Ctrl + v 行首选择多行，I（大写的i，shift + i），插入# ，ESC退出命令模式 取消注释：Ctrl + v 行首选择多行，d 方法二 :n,n+10s/^/#/g：注释n行到n+10行 :n,n+10s/^#//g：取消注释（注意行首尖叫号 ^） 所有配置都是临时的，要永久需要写入配置文件里，存放在用户的家目录下，.vimrc，如果没有的话就自己新建一个也ok "},"Linux/基础/08-Linux软件包管理.html":{"url":"Linux/基础/08-Linux软件包管理.html","title":"Linux软件包管理","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux软件包管理 软件包管理简介 软件包分类： 源码包：包括脚本安装包 二进制包：RPM包，系统默认包（ubuntu中是deb包），源码包编译后的包 源码包的优点 开源 可以自由选择所需的功能 软件是便宜安装，所以更加是个自己的系统，更加稳定也效率更高 卸载方便（直接把目录删除） 源码包的缺点 安装步骤多 编译并安装时间过长 因为是编译安装，安装过程中一旦报错新手很难解决 RPM包优点 包管理系统简单，只需要几个命令就可以实现软件包的安装，升级，查询和卸载 安装速度比源码包快很多 RPM包缺点 不能看见原代码 功能选择不如源码包灵活 依赖性 RPM包管理 rpm命令管理 RPM包名和包全名 RPM包的依赖性：树形依赖，环形依赖，模块依赖(以.iso.数组结束的就是模块依赖，也叫库文件依赖模块依赖查询网站) 安装和升级使用包全名，卸载和查询使用包名（在/var/lib/rpm/中的数据库总搜索） RPM安装：rpm -ivh 包全名 -i（install）：安装 -v（verbose）：显示详细信息 -h（hash）：显示进度 --nodeps：不检测依赖性（该选项不用） RPM升级：rpm -Uvh 包全名 -U（upgrade）：升级 RPM卸载：rpm -e 包名,也要考虑依赖性，当有包被依赖时，此时这个包不能删掉 -e（erase）：卸载 RPM查询包：查询包还是用RPM，yum没有查询功能 查询包是否安装：rpm -q 包名 -q（query） 查询所有安装的包：rpm -qa -a（all） RPM查询包详细信息：rpm -qi 包名 -i（information） RPM查询未安装包的详细信息：rpm -qip 包全名 -p（package） RPM查询文件安装位置：rpm -ql 包名 -l（list） RPM查询未安装包的文件安装的默认位置：rpm -qlp 包名 RPM查询系统文件属于哪个rpm包：rpm -qf 系统文件名 -f（file） RPM查询软件包的依赖性：rpm -qR 包名 -R（requires） RPM查询未安装软件包的依赖性：rpm -qRp 包全名 RPM包校验：rpm -V 包名 -V（verify） RPM包中文件提取（用来修复系统）： rpm2cpio 包全名 | cpio -idv . 包中的文件绝对路径 -i（copy-in模式）：还原 -d：还原时自动新建目录 -v：显示还原过程 yum在线管理 既可以用在线yum源文件服务器，也可以用本地光盘作为yum源文件服务器。 会自动解决依赖性问题 更换yum源：保存在/etc/yum.repos.d/目录下 查询：yum list 搜索：yum search 包名 安装：yum -y install 包名 -y（yes） 升级：yum -y update 包名 yum -y update：不写包名，直接升级全部（包括Linux内核，远程升级了的话不能开机，需要本地配置文件），慎用 卸载，会卸载所有依赖的包：yum -y remove 包名 Linux服务器应该采用最小化安装的原则，用什么装什么 装完了最好不要用yum卸载，也不要随便升级 yum的软件组管理： 查询所有可用的软件组列表：yum grouplist 安装指定软件组：yum groupinstall 软件包组名 卸载指定软件组：yum groupremove 软件包组名 用光盘做yum源：修改/etc/yum.repos.d/下的media配置文件，该源为关盘挂载点，注意：配置文件的格式要求很严格，注释应该顶头写。 源码包管理 区别： 安装前的区别：概念上的区别，见上述 安装后的区别：安装位置的区别 RPM包（一个软件）的默认安装位置： /etc/：配置文件 /usr/bin/：可执行的命令 /usr/lib/：程序所使用的函数库 /usr/share/doc/：基本的软件使用手册 /usr/share/man/：版主文档 /var/www/html/：服务器类软件的默认网页位置 源码包的安装位置： 需要手动指定安装目录：一般推荐/usr/local/软件名/ RPM包和源码包安装软件带来的影响：启动服务的方式不同 RPM包在/etc/rc.d/init.d/下有执行文件，采用两种方式启动： /etc/rc.d/init.d/httpd start service httpd start 源码包的服务启动方式不能用系统服务管理命令例如service来管理 只能在/usr/local/软件名/bin/执行软件码 start 目录下启动服务 Apache源码包的具体安装步骤： 安装C语言编译器：gcc 下载apache的源码包：path 确认源码保存位置/usr/local/src/ 确认软件安装位置：/usr/local/ 如何确认安装过程报错安装过程停止并出现error，warning，no等提示语言 解压缩下载的源码包：tar -zxvf 源码包名 进入解压缩目录：INSTALL和README时安装说明和使用说明 执行./configure --prefix=默认安装目录：编译前准备 定义需要的功能选项 检测系统环境是否符合安装要求 把定义好的的功能选项和检测系统环境的信息都写入Makefile文件（./configure过程会生成），用于后续的编译 执行make：编译 如果前两步报错，执行make clean，清空过程中生成的临时文件。 执行make install：安装 删除源码包安装的软件：直接rm -rf /usr/local/软件名/ 脚本安装包与软件包管理 脚本安装包不是独立的软件包类型，常见安装的是源码包 人为包安装过程写成额自动安装的脚本，只要执行脚本，定义简单的参数，就可以完成安装 非常类似于windows下软件的安装方式 Webmin是一个基于Web的Linux系统管理界面，可以通过图形化的方式设置用户账号、Apache、DNS、文件共享等服务。下载软件，下载后解压缩，并进入解压缩目录，执行.sh安装脚本,最后登录ip地址的自己配置的端口号进入该网站即可 如何选择包安装？ 如果对外服务，选择源码包安装，例如：Apache 如果本机使用，RPM包安装，例如：gcc编译器 "},"Linux/基础/09-Linux中的用户管理.html":{"url":"Linux/基础/09-Linux中的用户管理.html","title":"Linux中的用户管理","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux中的用户管理 用户配置文件 越是安全性要求高的服务器越需要对用户权限等级制度和服务器操作规范有很高的要求，linux中主要通过用户配置文件来查看和修改用户信息 主要有四个配置文件：/etc/passwd，/etc/shadow，/etc/group，/etc/gshadow /etc/passwd：用户信息文件 格式（7个字段） 用户名称； 密码标志； UID：用户ID 0：超级用户 1—499：系统用户:不能登录，不能删除 500—65535：普通用户 GID：组ID：这里是初始组ID不是附加组ID 用户说明：备注 家目录； 普通用户：/home/用户名/ 超级用户：/root/ Shell 命令解释器类型，默认是bash /etc/shadow：影子文件 是passwd的影子，默认权限：000 格式（9个字段） 用户名称； 加密密码； SHA512加密，可以暴力破解 如果密码是：“!!”和 “*”，表示没有密码，不能登录 密码最后一此修改时间；时间戳表示：使用1970年1月一日作为标准时间，每过一天时间戳加1 两次密码修改间隔（天）； 密码时效天数（-1永不失效）； 密码修改到期前的警告天数； 密码到期后的宽限天数； 账号失效时间；时间戳表示 保留字段 时间戳换算： 时间戳—>日期：date -d \"1970-01-01 16066 days\" 日期—>时间戳：echo$(($(date --date=\"2014/01/06\" +%s)/86400+1)) /etc/group&/etc/gshadow：组信息文件&组密码文件 /etc/group格式（4个字段） 组名， 组密码标志， GID， 组中附加用户 /etc/gshadow格式（4个字段） 组名， 组密码(默认没有，也不推荐使用)， 组管理员用户名， 组中附加用户 Linux中查看用户的初始组的方法：查询etc/passwd和/etc/group，两两对照查看 用户管理相关文件 用户的家目录：（会自动生成） 普通用户：/home/用户名/：权限700 超级用户：/root/：权限550 用户的邮箱： /var/spool/mail/用户名/ 用户模板目录：就是母板，新建用户会默认创建在用户家目录下 把/etc/skel/目录下的文件复制到用户家目录下 /etc/skel/ 用户管理命令 useradd 创建用户：useradd [选项] 用户名 新建一个用户实际上就是在上述六个地方生成了默认信息，所以手工修改上述六个地方就可以手工添加用户 useradd -u UID：指定自定义UID useradd -d 家目录：指定自定义家目录 useradd -c 用户说明：指定自定义用户说明 useradd -g 组名：指定自定义初始组组名 不建议修改 useradd -G 组名1,组名2：指定自定义附加组组名 useradd -s shell：指定自定义登录shell，默认是/bin/bash 用户默认值配置文件：/etc/default/useradd 和 /etc/login.defs passwd 修改用户密码：passwd [选项] 用户名 超级用户可以改任意用户密码 普通用户只能给自己设密码passwd whoami：查看当前用户 passwd -S 用户名 ：查看密码状态，就是shadow里面的信息，仅root用户可用 passwd -l 用户名 ：锁定用户，实际是在shadow中的密码前面加了“!”，仅root用户可用 passwd -u 用户名 ：解锁用户 passwd --stdin 用户名 ：使用字符串作为用户密码 例如：echo \"123\" | passwd --stdin 用户名，shell编程添加多个用户时使用 usermod 修改用户信息：usermod [选项] 用户名 usermod -u UID：修改UID usermod -c 用户说明：修改用户说明 usermod -G 组名1,组名2：修改附加组 usermod -g 组名：修改初始组（不推荐） usermod -L：锁定用户（Lock） usermod -U：解锁用户（Unlock） chage 修改用户密码状态：chage [选项] 用户名 chage -l：查询密码详细状态 chage -d 日期：修改密码最后一次更改日期 chage -m 天数：修改两次密码修改间隔 chage -M 天数：修改密码有效期 chage -W 天数：修改密码过期前警告天数 chage -I 天数：修改宽限天数 chage -E 日期：修改账号失效时间 注意：实际是对shadow文件里面的信息进行修改，chage -d 0 用户名 使用最多，把用户的修改密码时间归零，强制用户第一次登陆系统必须修改密码 userdel 删除用户：userdel [选项] 用户名 userdel -r 用户名：删除用户的同时删掉家目录 不推荐手工创建用户，但是可以手工删除用户的相关信息： etc/passwd etc/shadow etc/group etc/gshadow var/spool/mail/用户名 /home/用户名/ 手工把上面6个位置和要删除的用户的相关信息删除就可以了 id 查询用户uid，gid和附加组：id 用户名 su 用户切换：su [选项] 用户名 su - 用户名 ：连带用户的环境变量一起切换，中间减号绝对不能省去，省去就不会切换环境变量 su - root -c 命令名：不切换root，只是执行root权限才能执行的命令 用户组管理命令 groupadd 添加用户组：groupadd [选项] 组名 groupadd -g（GID）组名：指定组ID groupmod groupmod -g 新组id 旧组id groupmod -n 新组名 旧组名 尽量不修改 groupdel groupdel 组名：要想删除一个组，这个组中不允许有初始用户存在 gpasswd 把用户添入组或者从组中删除：gpasswd [选项] 组名 gpasswd -a 用户名：把用户加入组 gpasswd -a 用户名 组名 gpasswd -d 用户名：把用户从组中删除 gpasswd -d 用户名 组名 注：也可以直接在/etc/group文件里添加附加组(不推荐改初始组) 总结： Linux中用户和用户组的关系是： "},"Linux/基础/10-Linux权限管理.html":{"url":"Linux/基础/10-Linux权限管理.html","title":"Linux权限管理","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux权限管理 ACL权限 ACL权限的简介和开启方式 任何一个文件在一个时刻只能有一个所有者和所属组 ACL权限用来解决文件的权限身份不够用的情况 ACL权限需要分区支持： dumpe2fs -h /dev/sda5/ 查看是否支持acl选项，如果不支持。 /dev/sda5/ 为df -h 查看根分区对应的文件系统 可以临时开启：mount -o remount,acl / 重新挂载根分区，并挂载加入acl权限 或者永久开启：vim /etc/fstab，然后重启系统 在根分区的defaults后面加个：,act 慎用：任何错误都会导致挂载失败 ACL权限类似于windows的权限设置方法，就是不考虑user，group和others的权限设置，单独添加一个用户或者一个用户组对一个文件或者目录的权限 查看与设定ACL权限 getfacl 查看ACL的权限：getfacle 文件名 setfacl 设置ACL的权限：setfacl [选项 ] 文件名 setfacl -m u/g/m：用户名/组名/不写权限 文件名：设定文件的ACL权限 setfacl -m u:用户名:权限 文件名：设定文件用户的ACL权限 为用户分配ACL权限，使用“u:用户名:权限”格式 例：setfacl -m u:user1:rwx /test/ setfacl -m g:组名:不写权限 文件名：设定文件用户组的ACL权限 为组分配ACL权限，使用“g:组名:权限”格式 setfacl -x ：删除指定的ACL权限 setfacl -b ：删除所有的ACL权限 setfacl -d ：设定默认ACL权限 setfacl -k ：删除默认ACL权限 setfacl -R ：递归设定ACL权限 最大有效权限与删除ACL权限 最大有效权限mask：可以通过getfacl 文件名来查看ACL的权限，里面有mask，可以通过控制mask的值来修改默认最大有效权限。 需要注意的是mask权限不会影响当前文件所有者，只会影响ACL权限和所属组的权限 setfacl -x u/g:用户名/组名 文件名：删除文件指定的ACL权限 setfacl -b 文件名：删除文件所有ACL权限 默认ACL和递归ACL权限（只能针对目录） setfacl -m d:u/g: 用户名/组名:权限 文件名：设定父目录的默认ACL权限，父目录里所有的新建文件都会继承父目录的ACL权限 d参数就是设置默认的ACL权限 setfacl -k：删除父目录的默认ACL权限 setfacl -m [选项] -R 文件名：递归设定文件夹的ACL权限 setfacl -m u:test:rx -R 文件名 文件特殊权限 SetUID：在所有者的x位置上变成了s针对二进制文件 passwd命令拥有SetUID权限，所以普通用户能修改自己密码 四个条件缺一不可： 只有二进制文件（例如命令和脚本文件）才能设定SUID权限 命令执行者必须对该程序有x权限 命令执行者会在执行的时候获得该程序文件的属主身份 SUID权限只在该程序执行过程中生效，也就是身份改变旨在程序执行过程中有效 我们通常会看到4777，2777，1777的权限标识，依次是加了SUID，SGID，SBIT权限 4代表SUID 2代表SGID 1代表SBIT 设定SetUID的方法 4代表SUID chmod 4755 文件名 chmod u+s 文件名 取消SetUID的方法 chmod 755 文件名 chmod u-s 文件名 可以用chmod来赋予和删除SUID SetUID是非常危险的，一个命令只要有了s权限，例如passwd命令，普通用户就可以通过执行这个命令获得passwd的属主身份，也就是进入root权限。 比如：给vim加了SetUID后，普通用户就会有root权限，例如：修改/etc/passwd文件，非常危险。 关键目录应严格控制写权限（普通写权限，不是SetUID权限）。比如“/”、“/usr”等 用户的密码设置要严格遵守密码三原则 对系统中默认应该具有SetUID权限的文件作出备份，定时检查有没有这之外的文件被设置了SetUID权限 SetGID：在所属组的x位置上变成了s 针对二进制文件和目录 针对二进制文件，四个条件缺一不可： 只有可执行的二进制文件才能设置 命令执行者必须对该程序有x权限 命令执行者会在执行的时候获得该程序文件的所属组身份 SUID权限只在该程序执行过程中生效，也就是所属组身份改变旨在程序执行过程中有效 注：例如/usr/bin/locate命令 针对目录，三个条件缺一不可： 普通用户必须对此目录拥有r和x权限，才能进入该目录 普通用户在此目录中的有效组会变成此目录的所属组 若普通用户对此目录拥有w权限时，新建的文件的默认组不是文件自己的初始组，而是这个目录自己的所属组 可以用chmod来赋予和删除SGID 设定SetGID的方法 2代表SGID chmod 2755 文件名/二进制文件 chmod g+s 文件名/二进制文件 取消SetGID的方法 chmod 2755 文件名/二进制文件 chmod g-s 文件名/二进制文件 Sticky BIT(黏着位)：在其他人的x位置上变成了t 针对目录 三个条件缺一不可： 只有目录才能设定SBIT权限 普通用户必须对该目录有x和w权限 有了SBIT，普通用户即使有目录的w权限，也不能删除其他用户建立的文件 设定SBIT的方法 1代表SBIT chmod 1755 文件名 chmod o+s 文件名 取消SBIT的方法 chmod 1755 文件名 chmod o-s 文件名 需要注意的安全性： 需要定期对系统中含有SUID或者SGID权限的文件进行检查，如果有异常多出来的含有该权限的文件，如果多出来了，是一个极大的安全隐患，需要手工清除。 文件系统属性chattr权限 chattr（change file attributes on a linux file system） 格式：chattr [+-=] [选项] 文件或目录名 符号 +：增加权限 -：删除权限 =：等于某权限 选项 i： 1.对文件：不允许任何用户（包括root用户）对文件进行任何修改，只能读 2.对目录：任何用户（包括root用户）只能在目录下修改文件内容，但是不能删除和创建文件 a： 1.对文件：任何用户（包括root用户）只能对文件增加数据，但是不能删除和修改现有数据 2.对目录：任何用户（包括root用户）只能在目录中建立和修改文件里的内容，但是不能删除文件 lsattr 查看文件系统属性：lsattr 选项 文件名 lsattr -a 文件名：显示所有文件和目录 lsattr -d 文件名：若文件时目录，仅列出目录自己的属性 系统命令sudo权限 之前学的是对文件的操作权限，sudo是对系统命令的权限。 sudo权限是root把本来只能超级用户执行的命令赋予普通用户的执行 root权限先执行命令visudo命令 实际修改的是：/etc/sudoers文件 在这一行root ALL=(ALL) ALL下面添加 root ALL=(ALL) ALL 给用户 格式：用户名 被管理主机的地址 = （可使用的身份）授权命令（绝对路径） 第一个ALL：允许在命令在哪台计算机上执行 第二个ALL：把前面的用户转变成这个身份，一般不用 第三个ALL：所有命令，应该写具体权限 %wheel ALL=(ALL) ALL 给组 %组名 被管理主机的地址=（可使用的身份）授权命令 （绝对路径） 例如：jack ALL=/sbin/shutdown -r now：授权jack能重启服务器的权限 sudo -l：查看自己能用那些sudo命令 sudo：执行sudo命令：sudo [绝对路径命令] 注意：vim命令不用设置sudo给普通用户，否则会拥有root的所有权限，非常危险 "},"Linux/基础/11-Linux的文件系统管理.html":{"url":"Linux/基础/11-Linux的文件系统管理.html","title":"Linux的文件系统管理","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux的文件系统管理 分区和系统文件 分区类型 对于硬盘分区形式是MBR的 分区图 一： 二： 规定了：1、2、3、4只能分配给主分区（主分区最多4个），所以逻辑分区从5开始 主分区：总共最多只能分4个 扩展分区： 包含逻辑分区 只能有一个 也算作主分区的一种 主分区+扩展分区 不能存储数据和格式化 必须再分成逻辑分区才能使用 如果是IDE硬盘，Linux最多支持59个逻辑分区 如果是SCSI硬盘，Linux最多支持11个逻辑分区 对于GPT分区形式而言，没有上述限制 文件系统 Linux的文件系统可分为 ext2：是ext文件系统的升级版本，最大支持16TB的分区和最大2TB的文件（1TB=1024G=1024*1024KB） ext3：是ext2文件系统的升级版本，最大的区别就是带日志功能，以在系统突然停止时提高文件系统的可靠性，最大支持16TB的分区和最大2TB的文件（1TB=1024G=1024*1024KB） ext4：是ext3文件系统的升级版本，ext4在性能、伸缩性和可靠性方面进行了大量改进。 向下兼容EXT3 最大1EB文件文件系统和16TB文件（1EB=1024PB=1024*1024TB） 无限数量子目录 Extents连续数据块概念 多块分配 延迟分配 持久预分配 快速FSCK 日志校验 无日志模式 在线碎片整理 inode增强 默认弃用barrier等，默认CentOS 6.3的默认文件系统 swap： vfat： Windows文件系统为：FAT16、FAT32、FAT64和NTFS。而格式化的目的就是写入文件系统 文件系统常用命令 df命令，du命令，fsck命令，dumpe2fs命令 df df [选项] df -a： 显示所有分区 df -h：人性化显示。(一般用来统计系统空间大小) du du [选项] [目录或文件名] du -a：显示每个子文件的磁盘占用量。默认只统计子目录的磁盘占用量 du -h ：人性化显示 du -s：弥补ls命令的不足，可以统计文件夹包括里面的内容的大小而不是单单文件夹的大小。(一般用来统计文件大小)，避免服务器高运载下使用 df和du的区别 du只是面向文件的，只会计算文件或目录占用的空间； df是从文件系统角度考虑的，不光要考虑文件占用的空间，还要统计被命令或程序占用的空间（最常见的就是文件已经删除但是程序并没有释放空间）， 所以df看到的才是真正的可以使用的空间 fsck 文件系统修复命令，不需要自己手动执行：fsck [选项] 分区设备文件名 系统会自动执行，除非需要手动去执行，否则不用管 fsck -a 分区设备文件名：不用显示用户提示，自动修复文件系统 fsck -y 分区设备文件名：自动修复，和-a作用一致，不过有些文件系统只支持-y dumpe2fs 显示磁盘状态：dumpe2fs 分区设备文件名 显示ext2、ext3、ext4文件系统的超级块和块组信息 挂载命令 将设备文件名和绑定到盘符(挂载点)上，Windows是自动，Linux默认是手动分配 mount -l：查询异已挂载的设备，加-l会显示卷标名 mount -a：依据配置文件/etc/fstab中的内容，自动挂载 mount 挂载命令格式：mount [-t 文件系统] [-L 卷标名] [-o 特殊选项] 设备文件名 挂载点 -t：文件系统：加入文件系统类型来指定挂载的类型，可以ext3、ext4、iso9660等文件系统 -L：卷标名：挂载指定卷标的分区，而不是安装设备文件名挂载 -o：特殊选项：可以制度挂载的额外选项 没特殊需求不需要加特殊选项 挂载光盘和U盘 Linux中的分区时开机自动挂载，但是光盘和U盘时手动挂载，系统准备了/mnt/和/media/来挂载 /mnt：挂载U盘 /media：挂载光盘 挂载光盘步骤 sr0和cdrom都可以作为设备文件名 建立挂载点：mkdir /mnt/cdrom/ 挂载：mount -t iso9660 /dev/cdrom /mnt/cdrom/或者mount /dev/sr0 /mnt/cdrom 设备文件名：/dev/cdrom和/dev/sr0是固定的 去挂载点访问：cd /mnt/cdrom/ 在拿走光盘之前需要先卸载光盘：umount 设备文件名或挂载点 挂载U盘步骤 U盘的设备文件名是自动识别的，用fdisk -l查看 建立挂载点：mkdir /mnt/usb/ 挂载：mount -t vfat /dev/sdb1 /mnt/usb/ /dev/sdb1：fdisk -l 查看的 去挂载点访问：cd /mnt/usb/ 在拔U盘之前需要先卸载光盘：umount 设备文件名或挂载点 注意： 挂载U盘只能用本机或者虚拟机，不能用远程工具 Linux默认是不支持NTFS文件系统的外设的，U盘只能FAT格式的 Linux如何支持NTFS文件系统 Linux系统的内核中已经把市面上常见的驱动包括了，所以安装系统后一般不需要安装驱动，Linux会自动匹配识别，如果Linux默认没有把一个文件系统的驱动加载进来，我们就需要手动去安装驱动。 几种让Linux支持NTFS文件系统的方法： 内核重新编译 第三方的插件：ntfs-3g 内核编译太麻烦，太高端，一般选择“ntfs-3g插件”来实现 安装步骤： 解压：tar -zxvf ntfs-3g_ntfsprogs-2013.1.13.tgz 进入解压目录：cd ntfs-3g_ntfsprogs-2013.1.13 编译前准备：./configure 编译：make 编译安装：make install 挂载NTFS分区的硬盘：mount -t ntfs-3g 设备文件名 挂载点 fdisk分区 fdisk命令分区过程 虚拟机添加新硬盘，并用fdisk -l查询新硬盘是否被识别 若已识别新硬盘/dev/sdb/，就开始为新硬盘分区 进入fdisk交互模式：fdisk /dev/sdb/ partprobe 分完区后必须执行这个命令，重新读取分区表信息 然后格式化分区 mkfs -t ext4 /dev/sdb1 mkfs -t ext4 /dev/sdb5 最后创建挂载点并挂载 mkdir /disk1 mkdir /disk5 mount /dev/sdb1 /disk1/ mount /dev/sdb1 /disk5/ fdisk -l：查看，两个分区挂载完毕 分区自动挂载和/etc/fstab文件修复 上面的mount命令挂载只能临时生效，每次重启都要手动挂载硬盘，要想永久生效，就要修改/etc/fstab配置文件的内容。 添加了挂载信息后，执行mount -a，依据配置文件/etc/fstab中的内容，自动挂载 万一/etc/fstab文件写错了，会导致系统崩溃 /etc/fstab文件修复 出错后按提示进入root操作界面，发现/etc/fstab文件是只读 执行：mount -o remount,rw / 就可以修改/etc/fstab文件了，就可以修复了。 分配swap分区 free 查看内存与swap分区使用状况 新建swap分区 fdisk /dev/sdb 进入分区交互模式 记得修改分区ID号为82 使用t修改分区ID号 l：查看分区类型 partprobe mkswap /dev/sdb6 格式化 swapon /dev/sdb6 加入swap分区 swapoff /dev/sdb6 取消swap分区 swap分区开机自动挂载 "},"Linux/基础/12-Shell.html":{"url":"Linux/基础/12-Shell.html","title":"Shell","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Shell Shell基础 Shell概述 shell就是Linux中的命令解释器，说白了，就是一个命令行的交互界面。 与Linux不同Windows中就是图形的交互界面。 shell还是一个强大的编程语言，因为它可以直接调用Linux的系统命令。 Shell的种类： Bourne Shell语法类：sh，ksh，Bash，psh，zsh C Shell语法类（只要同于BSD的Linux版本中）：csh，tcsh Bash Shell：Bash与sh兼容，是目前的主流 在文件/etc/shells中，可以查看Linux中默认支持的Shell类型，在命令行下输入shell的名字就可以切换shell类型 Shell脚本的执行方式 echo 输出指定内容：echo [选项] [输出内容] echo -e：支持反斜线的字符转换 支持颜色输出 First Script # ！bin/bash：表示以下代码为shell 执行方法 第一种： chmod 755 hello.sh ./hello.sh 第二种： bash hello.sh 注意：如果一个shell脚本在Windows中编辑完成，在Linux中发现运行出错，这是因为Windows和Linux格式不同，你可以用cat -A [文件名] 来验证，换行符不同。解决方法就是用命令dos2unix将Windows格式转化为Linux格式 Bash的基本功能 历史命令与命令补全 history 历史命令：history [选项] [历史命令保存文件] history n：显示最近的n条命令 history -d n：删除第n条命令 history -c：清空历史命令 history -w：把缓存中的历史命令写入每个用户的缓存文件~/.bash_history 历史命令默认会保存1000条，可以在环境变量配置文件/etc/profile中进行修改 使用 使用上，下箭头的方式调用历史命令， 使用“!n”重复执行第n条历史命令 使用“!!”重复执行上一条命令 使用“!字符串”重复执行最后一条以该字符串开头的命令 命令与文件补全 在Bash中，命令与文件补全是非常方便与实用的功能，我们只要在输入命令或文件时，按“Tab”键就会自动进行补全 命令别名与常用快捷键 命令别名 alias 查询命令别名，实际就是查看~/.bashrc文件的内容 alias 别名=\"原命令\" 设定命令别名；For Example：alias vi='vim' unalias 删除别名：unalias 别名 命令执行的顺序： 第一顺位执行用绝对路径或相对路径的命令 第二顺位执行别名 第三顺位执行Bash的内部命令（内部命令就时用whereis找不到的Linux自带命令） 第四顺位执行按照$PATH环境变量定义的目录查找顺序找到的第一的命令（外部命令） 让别名永久生效：写入~/.bashrc配置文件 常用快捷键 Ctrl+下列的字母 c：强制终止当前命令 l：清屏 u：剪切光标之前的内容 k：剪切光标后的内容 y：粘贴 r：搜索历史 d：退出当前终端，相当于logout z：暂停进程，放入后台 建议别用 s：暂停屏幕输出 q：恢复屏幕输出 输入输出重定向 标准输入输出设备 键盘：/dev/stdin：标准输入：0文件描述符 显示器：/dev/sdtout：标准输出：1文件描述符 显示器：/dev/sdterr：标准错误输出：2文件描述符 输出重定向 改变输出方向，把命令的正确或者输出结果输出到指定的文件中 正确输出和错误输出同时保存进一个文件中： 以覆盖的方式： 命令 > 文件 2>&1 > ：覆盖 2>&1 ：是标准格式 命令 &> 文件 以追加的方式： 命令 >> 文件 2>&1 >> ：追加 2>>&1 ：是标准格式 命令 &>> 文件 比较简洁 把正确的输出保存进文件A，错误的输出保存进文件B： 命令 >>文件A 2>>文件B 输入重定向： 后面既可以直接加文件名，也可以将输入重定向作为输入，不过后者在结果中不会显示文件名，因为它指挥识别输入的文件内容流 wc wc [选项] [文件名]，用得不多 wc -c：统计字节数 wc -w：统计单词数 wc -l：统计行数 多命令顺序执行与管道符 多命令顺序执行 ;：两个命令都会执行 命令1;命令2 &&：命令1正确执行，命令2才会执行 命令1 && 命令2，例子：源码安装的时候，make && make install ||：命令1错误执行，命令2才会执行 命令1 || 命令2 dd命令 磁盘复制命令，和cp命令不同，dd可以复制特殊文件，分区甚至整个硬盘。主要的作用就是磁盘复制 dd if=输入文件 of=输出文件 bs=多少字节数作为一个块 count=块的个数 if=输入文件 ：指定源文件或源设备 of=输出文件：指定目标文件或目标设备 bs=字节数：指定一次输入/输出多少字节，即把这些字节看做一个数据块 count=个数：指定输入/输出多少个数据块 例子：date;dd if=/dev/zero of=/root/testfile bs=1k count=100000;date 用来显示磁盘复制的时间 命令 && echo yes || echo no shell编程里面应用判断命令是否执行成功：如果命令执行成功，输出yes，执行失败，输出no 管道符 命令1的正确输出作为命令2的操作对象：命令1 | 命令2 grep 在文件中搜索符合条件的字符串：grep [选项] \"搜索内容\" grep -i：忽略大小写 grep -n：输出行号 grep -v：反向查找 grep –color=auto：搜索出的关键字用颜色显示 netstat -an | grep ESTABLISHED 通配符与其他特殊符号 通配符 ?：匹配一个任意字符 *：匹配任何内容（0个或任意多个字符） []：匹配中括号中的任意一个 [-]：匹配中括号中范围内任意一个 [^]：逻辑非，表示匹配任意一个不是中括号内的一个字符0-9表示任意一个不是数字的字符 通配符是用来匹配文件名的，通配符通常会用来删除指定范围的文件 特殊符号 单引号中的所有符号都是符号 echo '$SHELL' 双引号中的符号可能会有特殊意义 echo \"$SHELL\" 反引号和$() 符号中的内容是系统命令 反引号：`` $()：推荐使用 echo \"$(ls)\"和echo '$(ls)' echo \"$(ls)\"：双引号输出ls查询的结果 echo '$(ls)'：单引号输出$(ls) # ：开头时注释 $：用来调用变量 \\：用来将特殊符号变成普通符号 Bash的变量 变量分类 用户自定义变量 环境变量 主要保存的是和系统操作环境相关的数据，允许新建 位置参数变量 主要用来向脚本当中传递参数或数据的，变量名不能自定义，变量作用是固定的，是预定义变量的一种 预定义变量 是Bash中已经定义好的变量，变量名不能自定义，变量作用也是固定的 变量命名规则 由字母、数字和下划线组成，但是变量名不能用数字开头 bash中，变量的默认类型都是字符串型，如果要进行数值运算，需要指定变量类型为数值型 变量用等号连接值，等号左右两侧不能有空格 变量名若有空格，需要单引号或双引号包括 变量值中可以用转义符\\让特殊字符失去特殊含义 变量值可以进行叠加，不过变量需要用双引号包括“$变量名”或${变量名}包括 如果是把命令的结果作为变量值赋予变量，则需要使用反引号或$()包含命令 环境变量名建议大写 用户自定义变量 用户自定义变量（本地变量） name=”jack” 可以叠加： newname=\"$name\"yang newname=${name}yang $ 调用变量：$变量名 set 查看系统中所有的变量 unset 删除变量：unset 变量名 环境变量 本地变量只在当前的shell中生效 环境变量会在当前和这个shell的所有子shell中生效，如果把环境变量写入相关的文件，那么这个环境变量会在所有的shell中生效 用pstree可以查看shell的父子关系 export 申明普通变量为环境变量：export 变量名=变量值 env 专门查看环境变量 unset 删除变量：unset 变量名 常用系统环境变量 PATH 查找系统命令的变量 tab键补全和外部命令的查找都是根据$PATH来的 可以用变量叠加的方式把自己的命令加到$PATH中，PATH=\"$PATH\":/root/test.sh PS1 定义系统提示符的变量 echo $PS1 查看 PS1='格式' 自定义命令提示符 位置参数变量 不建议写位置参数脚本，其他人不知道各个位置参数的用处 $n：$0表示命令本身，之后就是命令行参数 $*：所有参数，把所有参数当作一个整体 $@：所有参数，把参数区别对待 $#：所有参数的个数 举例 ./test.sh 11 22 预定义变量 $?：返回上一次执行结果正确与否 $$：当前进程的PID $!：后台运行的最后一个进程的PID read 接收键盘输入：read [选项] [变量名] -p “提示信息”：在等待read输入时，输出提示信息 必须携带 -t 秒数：限定时间，指定等待时间 必须携带 -n 字符数：限定字符数，不加-n就要回车键结束 -s：隐藏输入的信息，适用于输入密码时 举例 Bash的运算 数值运算与运算符 数值运算 Linux中变量默认类型时字符串 declare 声明变量类型：declare [+/-][选项] 变量名 -：给变量设定类型属性 -i：将变量声明为整数类型 -x：将变量声明为环境变量 +：取消变量的类型属性 -p：显示指定变量的被声明的类型 举例:（四种计算格式，最常用的是第三种） aa=11；bb=22 declare -i cc=$aa+$bb cc=$(expr $aa + $bb) cc的值是aa和bb的和，注意“+”好左右两侧必须有空格 cc=$(($aa+$bb)) 双小括号：运算；单小括号：系统命令 cc=$[$aa+$bb] 运算符 越靠上的优先级越高 示例 变量测试与内容替换 需要的时候对照使用 环境变量配置文件 环境变量配置文件简介 source 不需要重新登录，让修改后的配置文件直接生效 source 配置文件 . 配置文件 `“.” 就是source的缩写，注意“.”后面有个空格` 环境变量配置文件中主要就是定义对系统的操作环境生效的系统默认环境变量，比如PATH，HISTSIZE，PS1，HOSTNAME等 主要的5个配置文件 /etc/profile：针对所有用户 /etc/profile.d/*.sh：针对所有用户 ~/.bash_profile：针对单个用户 ~/.bashrc：针对单个用户 /etc/bashrc：针对所有用户 环境变量配置文件作用 环境变量配置文件调用的顺序 /etc/profile：针对所有用户 USER变量 LOGNAME变量 MAIL变量 PATH变量 HOSTNAME变量 HISTNAME变量 HISTSIZE变量 umask 调用/etc/profile.d/*.sh文件 /etc/profile.d/*.sh：针对所有用户 执行profile.d目录下所有sh文件 ~/.bash_profile：针对单个用户 追加PATH：在PATH变量后面加上了:$HOME/bin这个目录 调用~/.bashrc ~/.bashrc：针对单个用户 定义别名 /etc/bashrc：针对所有用户 定义别名和PS1（登录提示符） 会重复调用PATH，umask啥的，但是只针对no login shell的情况，就是直接敲sh进入一个shell的情况 其他配置文件和登录信息 注销时的配置文件：~/.bash_logout 可以清空一些环境变量等 历史命令的保存文件：~/.bash_history 排错依据 登录信息 本地终端欢迎信息：/etc/issue 远程终端欢迎信息：/etc/issue.net 转义符在该文件中不能使用，只能纯文本登录 是否生效由ssh的配置文件/etc/ssh/sshd/config决定，要加入Banner /etc/issue.net，重启ssh服务生效：service sshd restart 登陆后的欢迎信息：/etc/motd（本地和远程都适用） 推荐特效字符定制网站ASCII Generator Shell编程 基础正则表达式 正则表达式和通配符区别 通配符：在系统中搜索匹配文件名，是完全匹配。支持命令ls，find，cp，他们不认识正则表达式 正则表达式：用来在文件中匹配符合条件的字符串，是包含匹配。支持命令：grep，awk，sed *：前一个字符匹配0次或者任意多次 .：匹配任意一个字符（换行符除外） ^：匹配以后面字符作为行首的行 $：匹配以后面字符作为行尾的行 ^$：匹配空白行 []：匹配中括号中的指定的任意一个字符 ：匹配除中括号中的字符外的任意一个字符 \\：转义符 {n}：表示其前面的字符恰好出现n次 {n,}：表示其前面的字符出现不少于n次 {n,m}：表示其前面的字符至少出现n次，最多出现m次 字符截取命令 grep 提取符合条件的行 -c：只输出匹配行的计数 -i：不区分大小写 -v：显示不包含匹配文本的所有行 cut 提取符合条件的列：cut [选项] 文件名 -f 列号：提取第几列 -d 分隔符：按照指定分隔符分割列，默认是制表符tab 示例 cat/etc/passwd | grep /bin/bash | grep -v root | cut -d \":\" -f 1：用来提取出普通用户名 df -h | grep \"sda5\" | cut -f 5：用来提取硬盘的使用率 如果是空格，则不能很好使用，需要更复杂的awk命令 printf 按找类型输出格式输出内容，使用awk时格式化输出：printf \"输出类型输出格式\" 输出内容 %ns：输出字符串 n是数字代指输出几个字符 %ni：输出整数 n是数字代指输出几个数字 %m.nf：输出浮点数 m和n是数字，指代输出的整数位数和小数位数。如%8.2f代表共输出8位数，其中2位是小数，6位是整数。 \\n，\\r，\\t：换行，回车，tab键 printf '%s %s %s' 1 2 3 4 5 6：最后输出结果按照%s %s %s格式分为两组 printf命令不能用管道符，只能printf %s $(cat XXX.txt) 在awk命令的输出中支持print和printf命令 print：print会在每个输出之后自动加入一个换行符（Linux默认没有print命令） printf：printf是标准格式输出命令，并不会自动加入换行符，如果需要换行，需要手工加入换行符 awk 截取列： cut可以截取字符时，使用cut，否则使用awk 很强大的命令，可以说是一门编程语言 格式：awk ’条件1{动作1} 条件2{动作2} 条件3{动作3}‘ 文件名 前面可以加管道符 动作 格式化输出：printf 流程控制语句 示例 awk ‘{printf $2 “\\t” $6 “\\n”}’ XXX.txt df -h | awk '{printf $1 \"\\t\" $5 \"\\t\" $6}'：可以处理空格，弥补了cut的不足，但是awk很多命令很复杂 df -h | grep sda5 | awk ’{print $5}‘ | cut -d \"%\" -f 1 print可以在awk里面使用默认结尾加个换行符 BEGIN：在所有命令执行之前先执行BEGIN后面的语句块,awk默认是先读入一行再执行后面的语句 END：在所有语句处理完后执行 FS：指定分隔符，awk ’{FS=\":\"}‘ awk ‘{FS=\":\"} {print $1 \"\\t\" $3}’ /etc/passwd awk ‘BEGIN{FS=\":\"} {print $1 \"\\t\" $3}’ /etc/passwd awk还支持条件判断：awk ’$6>=87 {printf $2 \"\\n\"}‘： sed 数据的流编辑器，主要是用来将数据进行选取、替换、删除、新增的命令 vim只能修改文件，sed还可以直接修改管道符传过来的流 格式：sed [选项] ‘[动作]’ 文件名 选项： -n：sed默认把所有数据都输出到屏幕，加上-n表示只把经过sed修改过后的行输出到屏幕 -e：允许对输入数据应用多条sed命令编辑 -i：用sed的修改结果直接修改读取数据的文件，而不是由屏幕输出 会改变源文件，比较危险，不建议使用 动作： a：行后追加（多行时，行尾要加\\） sed ‘2a hello’ XXX.txt c：替换（多行时，行尾要加\\） sed ‘4c no the line’ XXX.txt：替换第二行 i：行前插入（多行时，行尾要加\\） sed ‘2i hello \\ world’ XXX.txt：在第二行前面插入 d：删除 sed ‘2,4d’ XXX.txt：删除第二行（没加-i选项不会修改源文件，只是删除输出的结果） p：打印 sed ‘2p’ XXX.txt：打印第二行 s：字串替换 sed ‘4s old/new/g’ XXX.txt：替换第四行的旧字符串替换为新字符串 字符处理命令 sort 排序（可接收管道符数据）：sort [选项] 文件名 -f：忽略大小写 -r：反向排序 -t ：指定分隔符，默认分隔符是制表符 -n：按照数值大小来排，默认使用字符串型排序 -k n[,m]：按照指定的字段范围排序，从第n字段开始，m字段结束（默认到行尾） wc： 统计字符（可接收管道符数据）：wc [选项] 文件名 -l：只统计行数 -c：只统计字符数 -w：只统计单词数 条件判断 两种判断格式 test -e XXX.txt [ -e XXX.txt ]：注意首尾各有一个空格 shell中常用 示例 [ -d /root ] && echo \"yes\" || echo \"no\"：如果是目录yes，否则no 按照文件类型判断 -e：判断文件是否存在（存在为真） -b：判断文件是否存在，并且是否是块设备文件 -c：判断文件是否存在，并且是否是字符设备文件 -d：判断文件是否存在，并且是否是目录文件 -f：判断文件是否存在，并且是否是普通文件 -L：判断文件是否存在，并且是否是链接文件 -p：判断文件是否存在，并且是否是管道文件 -S：判断文件是否存在，并且是否是套接字文件 -s：判断文件是否存在，并且是否是非空 按照文件权限进行判断 -r：判断文件是否存在，并且是否该文件有读权限，u，g，o中任意一个有都为真 -w：判断文件是否存在，并且是否该文件有写权限，u，g，o中任意一个有都为真 -x：判断文件是否存在，并且是否该文件有执行权限，u，g，o中任意一个有都为真 -u：判断文件是否存在，并且是否该文件有SUID权限，u，g，o中任意一个有都为真 -g：判断文件是否存在，并且是否该文件有SGID权限，u，g，o中任意一个有都为真 -k：判断文件是否存在，并且是否该文件有SBIT权限，u，g，o中任意一个有都为真 两个文件之间进行比较 文件1 -nt 文件2：判断文件1的修改时间是否比文件2新 文件1 -ot 文件2：判断文件1的修改时间是否比文件2旧 文件1 -ef 文件2：判断文件1的inode号是否和文件2一致，可以用来判断两个文件是不是互为硬链接 两个整数之间比较 整数1 -eq 整数2：相等 整数1 -ne 整数2：不等 整数1 -gt 整数2：大于 整数1 -lt 整数2：小于 整数1 -ge 整数2：大于等于 整数1 -le 整数2：小于等于 示例：[ 3 -lt 2 ] && echo yes || echo no 字符串的判断 -z：判断是否为空 判断变量是否为空：[ -z \"$name\" ] && echo yes || echo no -n：判断是否为非空 字串1 == 字串2：判断是否相等 字串1 != 字串2：判断是否不等 多重条件判断 判断1 -a 判断2：逻辑与 示例： aa = 10 [ -n \"$aa\" -a \"$aa\" -gt 9 ] && echo yes || echo no 判断1 -o 判断2：逻辑或 ! 判断：逻辑非 注意!后面有空格 流程判断 if语句 和[-d /root] && echo \"yes\" || echo \"no\"作用一样，但更直观 单分支if 实例 双分支if 多分支if case语句 for循环 第一种语法 示例 第二种语法 示例 while循环和until编程 while循环 示例 until循环 示例 "},"Linux/基础/13-Linux的服务管理.html":{"url":"Linux/基础/13-Linux的服务管理.html","title":"Linux的服务管理","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux的服务管理 服务简介与分类 Linux服务分类 RPM包默认安装的服务 独立的服务 基于xinetd（超级守护进程）服务 源码包安装的服务（第三方源码包） 服务的启动与自启动 查询已安装的服务 RPM包安装的服务：chkconfig --list 查看RPM包安装的服务按照运行级别的自启动状态。 查看是否在系统下次启动时自启动，而不是查看服务是否当前已启动 查询当前启动的服务 ps aux netstat service --status-all 源码包安装的服务：没有命令，只能去服务安装位置查看，一般在/usr/local/下 其实源码包和RPM包安装的服务在Linux中的区别就是安装位置不同 源码包安装在指定位置，一般是/usr/local/下 RPM包安装在默认位置中，配置文件在/etc/下，启动命令在/etc/rc.d/init.d/下，分散到很多文件夹下 RPM包安装服务的管理 RPM包安装的服务默认保存位置：(特殊文件有自己的默认保存位置) 独立服务的管理 启动方式 /etc/init.d/ 独立服务名 start | stop | status | restart 推荐使用 service 独立服务名 start | stop | restart | status rea hat独有，service 相当于/etc/inin.d 自启动方式 方式一：打开自启动：chkconfig [--level 运行级别] [独立服务名] on 不支持源码包安装的服务 关闭自启动：chkconfig 独立服务名 off 默认就是：2345 方式二：修改/etc/rc.d/rc.local文件，加入需要自启动的服务名 推荐 方式三：使用ntsysv命令管理自启动，图形界面很直观 red hat专有 基于xinetd(超级守护进程)服务的管理 默认情况下Linux是没有xinted的，需要手动安装yum -y install xinetd 然后用chkconfig --list查看，基于xinetd的服务不占用内存，但是需要的响应时间更长 基于xinetd的服务的启动，修改/etc/xinetd.d/下对应的服务的配置文件,然后service xinetd restart 基于xinetd的服务的自启动： chkconfig 服务名 on和chkconfig 服务名 off 图形界面工具：ntsysv 基于xinetd的启动和自启动是通用的，两者区分不是很严格，这种设置不利于管理，所以现在基于xinetd的服务越来越少了 自启动关闭，服务也会关闭，2者相通 源码包安装服务的管理 源码包安装的服务默认保存位置：/usr/local/ 源码包安装服务的启动和关闭(用绝对路径的启动脚本启动)：/usr/local/apache2/bin/apachectl start|stop 一般每一个源码包都有安装说明INSTALL，应该查看里面的启动方法 源码包安装服务的自启动： vim /etc/rc.d/rc.local加入/usr/local/apache2/bin/apachectl start 把源码包服务的启动脚本软连接到/etc/init.d/目录下和chkconfig --add 服务名，就可以实现service，chkconfig和ntsysv命令管理源码包安装服务，但是并不推荐，容易混乱。 总结 "},"Linux/基础/14-Linux系统管理.html":{"url":"Linux/基础/14-Linux系统管理.html","title":"Linux系统管理","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux系统管理 进程管理 进程管理的作用：（下面优先级由高到低） 判断服务器的健康状态（CPU、内存的占用情况） 常用命令：top 查看系统中的所有进程 命令：ps aux 和 ps -el 和 pstree 杀死进程 不常用，尽可能正常操作结束服务，不能正常关闭时再用 进程查看 ps aux 查看系统中所有进程，查看BSD操作系统格式 ps -xH 列出所有线程 ps -le 查看系统中所有进程，Linux格式 输出格式的作用 ps aux top 查看系统健康状态：top [选项] 需要的时候使用，top命令比较耗资源 -d 秒数：默认每3秒更新一次，可指定 ？或h：显示交互模式的帮助 P：以CPU使用率排序，默认选项 M：以内存使用率排序 N：以PID排序 q：退出top top命令的显示 重点关注最后一个平均负载(除以 Cpu 核数，如果大于 1.5，表示超出负荷，小于 1.5 基本正常) 重点关注第4个CPU的空闲率 重点关注第3个内存的空闲率 pstree 查看进程树：pstree [选项] -p：显示进程的PID -u：显示进程的所属用户 进程终止 正常命令不能终止服务时才使用 kill kill [信号] PID -l：查看kill支持的信号 小写l -1 PID：重启进程 -9 PID：终止进程 killall 按照进程名杀死，选项和kill通用：killall [选项] [信号] 进程名 -i：有询问 -I：忽略进程名的大小写 大写的i pkill 按照进程名杀死，选项和kill通用：pkill [选项] [信号] 进程名 也可以加t选项跟终端号：pkill -t 终端号：按照终端号踢出用户，用 w 命令查询系统中登录的用户，然后用终端号来踢 工作管理 类似Windows的最小化 把进程放入后台 命令后面加&：后台继续运行 在命令执行过程中，按下ctrl+z快捷键：放入后台即暂停 jobs 查看后台的工作：jobs [-l] -l：显示工作的PID 注意：“+”号代表最近一个放入后台的工作，也是工作恢复时，默认恢复的工作；“-”号代表倒数第二个放入后台的工作。 fg 恢复后台暂停的工作恢复到前台运行：fg %工作号 %工作号：%号可以省略，但是注意工作号和PID的区别 bg 恢复后台暂停的工作恢复到后台运行：bg %工作号 %工作号：%号可以省略，但是注意工作号和PID的区别 但是不能恢复和前台有交互的命令比如top命令和vim命令，因为就是给用户展示，后台运行没意义 注意：工作号≠PID 系统资源查看 vmstat 监视系统资源使用情况： vmstat [刷新延时(s) 刷新次数] 和top内容差不多，但更简洁 dmesg 开机时内核检测，一般结合grep使用 free 查看内存使用情况：free [选项] -b：以字节为单位显示 -k：以KB为单位显示（默认就是） -m：以MB为单位显示 -g：以GB为单位显示 查看CPU信息： cat /proc/cupinfo：每次开机都会更新 dmesg | grep CPU uptime：实际就是top命令第一行，跟w看到的一样 uname 查看系统与内核相关信息：uname [选项] -a：查看系统所有相关信息 -r：查看内核版本 -s：查看内核名称 file /bin/ls 判断当前系统的位数（通过系统外部命令的位数来推测） lsb_release -a 查询Linux系统的发行版本 lsof 列出进程打开或使用的文件信息：lsof [选项] -s 字符串：只列出以字符串开头的进程打开的文件 -u 用户名：只列出某个用户的进程打开的文件 -p pid：列出某个PID进程打开的文件 系统定时任务 前提：必须启动crond服务：service crond restart，并且chkconfig crond on，Linux系统都是默认启动和自启动的 crontab 设置系统定时任务：crontab [选项] -e：编辑crontab定时任务 打开文件编辑的格式是： * command或执行脚本 第一个*：分钟（0-59） 第二个*：小时（0-23） 第三个*：天（1-31） 第四个*：月（1-12） 第五个*：星期（0-7，0和7都代表星期日） 特殊符号： 示例 定期脚本里面的日期输出需要加“\\”转义符，原本：date +%y%m%d，定时任务里的脚本：date +\\%y\\%m\\%d -l：查询crontab任务 -r：删除当前用户所有的crontab任务 删一个任务，进去编辑删除需要删除的任务（vim操作） "},"Linux/基础/15-Linux日志管理.html":{"url":"Linux/基础/15-Linux日志管理.html","title":"Linux日志管理","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux日志管理 日志管理简介 百度百科简介：系统日志是记录系统中硬件、软件和系统问题的信息，同时还可以监视系统中发生的事件。用户可以通过它来检查错误发生的原因，或者寻找受到攻击时攻击者留下的痕迹。系统日志包括系统日志、应用程序日志和安全日志。 服务器出现问题先查看日志，才能找准原因 CentOS7中原来的日志服务syslogd被rsyslogd取代，两者兼容 确认服务是否启动和自启动： ps aux | grep rsyslogd chkconfig --list | grep rsylog 常见的日志的作用 RPM包安装的服务日志也会在/var/log/目录下 源码包安装的服务日志在源码包指定目录（一般是/usr/local）中，这些日志不是有rsyslogd服务来管理的，而是由各个服务使用自己的日志管理文档来记录自身日志 你安装了这些服务就会有 rsyslogd日志服务 日志文件格式 事件产生的时间 产生事件的服务器的主机名 产生事件的服务名或程序名 事件的具体信息 /etc/rsyslog.conf配置文件 格式 * authpriv.* /var/log/secure * 服务名称 [连接符号] 日志等级 日志记录位置 `authpriv：服务名称 .：连接符号 *：日志等级` * 服务名称，连接符，日志等级，日志记录位置都有多个，内容很多，自行百度。 常见的服务 连接符号 “*”不是连接符号，是所有日志等级 日志等级 从低等级到高等级（上到下） 日志记录位置 日志轮替 如果日志都记录在一个文件中，那么可能会占据大量存储空间，纯文本文档打开会非常慢，所以日志需要处理：切割（把大日志按天切割成小的）+轮换（删除旧的，保存新的） 日志文件的命名规则 如果配置文件中有“dateext”参数，那么日志会用日期作为后缀，例如：“secure-20200603”，只需要保存指定的日志个数，删除多余的日志文件即可 推荐使用 如果没有“dateext”参数，那么日志文件就需要改名了，当第一次使用日志轮替时，当前的“secure”日志会自动改名为“secure.1”，然后新建“secure”日志。第二次时，1变2，0变1，又新建0，以此类推 配置文件 /etc/logrotate.conf 只要是RPM包安装的服务，它默认已经支持轮替，但是源码包安装的服务需要vim /etc/logrotate.conf，然后手动加入轮替 示例 logrotate logrotate [选项] 配置文件名 如果此命令没有选项，则会按照配置文件中的条件进行日志轮替 logrotate -v /etc/logrotate.conf：显示日志轮替过程 logrotate -f /etc/logrotate.conf：强制轮替，不管日志轮替的条件是否已经满足 "},"Linux/基础/16-Linux启动管理.html":{"url":"Linux/基础/16-Linux启动管理.html","title":"Linux启动管理","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux启动管理 CentOS 6.x的启动管理 运行级别：7个级别 runlevel：查看运行级别 init 运行级别：改变当前运行级别 vim /etc/inittab：永久修改系统默认运行级别，写上id:3:initdefault 不要把0和6设为默认级别 CentOS6系统启动过程：针对MBR模式 initramfs内存文件系统 CentOS 6.x中使用initramfs内存文件系统去嗲了Centos5.x中的initrd RAM Disk。他们的作用类似，可以通过启动引导程序加载到内存中，然后加载启动过程中所需要的的内核模块，比如USB、SATA、SCSI硬盘的驱动和LVM、PAID文件系统的驱动 查看 不能在boot目录下做操作 调用/etc/init/rcS.conf配置文件 主要功能是两个 先调用/etc/rc.d/rc.sysinit，然后又/etc/rc.d/rc.sysinit配置文件进行Linux系统初始化 然后再调用/etc/inittab，然后由/etc/inittab配置文件确定系统的默认运行级别 调用/etc/rc.d/rc文件 启动引导程序grub Grub配置文件：/boot/grub/grub.conf 格式： default=0： 默认启动第一个系统 timeout=5： 等待时间，默认是5秒 splashimage=(hd0,0)/grub/splash.xpm.gz：指定grub启动时的背景图像文件的保存位置 hiddenmenu： 隐藏菜单 title CentOS(2.6.32-279.el6.i686)： 标题 root (hd0,0)： 指启动程序的保存分区 kernel /vmlinuz-2.6.32-279.el6.i686 ro： 定义了内核加载时的选项 initrd /initramfs-2.6.32-279.el6.i686.img： initramfs内存文件系统镜像文件的所在位置 系统修复模式 单用户模式常见的错误修复 遗忘root密码 修改系统默认运行级别 光盘修复模式 这些是后门，说的Linux针对的是网络安全 "},"Linux/基础/17-Linux备份与恢复.html":{"url":"Linux/基础/17-Linux备份与恢复.html","title":"Linux备份与恢复","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Linux备份与恢复 备份概述 Linux中需要备份的数据：/root/目录，/home/目录，/var/spool/mail/目录，/etc/目录，其他目录 安装的服务的数据也需要备份 apache需要备份的数据：配置文件，网页主目录，日志文件 mysql需要备份的数据 源码包安装的：/usr/local/mysql/data/ RPM包安装的：/var/lib/mysql 备份策略 完全备份：效果最高，但需要更大的硬盘空间 增量备份：每次备份只备份新的数据，占用空间少，但是恢复起来麻烦 差异备份：每次备份都只备份完全备份中不存在的，折中方法 备份命令 完全备份完全可以用tar打包压缩来做，但是如果是差异备份就会非常麻烦，这时就需要用到Linux为数据备份量是打造的备份和恢复命令dump命令和restore命令 dump dump [选项] 备份之后的文件名 原文件名或目录 -级别：0到9个备份级别 0是完全备份，1就是第一次增量备份，以此类推9就是第9次增量备份 -f 文件名：指定备份之后的文件名 -u：把备份时间记录在/etc/dumpdates文件中 -v：显示备份过程 -j：把备份文件压缩为.bz2格式 -W：查看详情，显示允许被dump的分区的备份等级及备份时间 注意：dump命令只有在备份分区的时候才能增量备份，备份普通目录或文件只能完全备份 示例 restore restore [模式选项] [选项] 四个模式 不能混用 -C：比较备份数据和实际数据的变化 -i：交互模式，手工选择需要恢复的文件 -t：查看模式，用于查看备份文件中拥有哪些数据 -r：还原模式，用于数据还原 一个选项 -f：指定备份文件的文件名 "},"Linux/命令指北/01-strace.html":{"url":"Linux/命令指北/01-strace.html","title":"strace","keywords":"","body":"datetime:2022-12-09 15:42:00 author:nzb strace 命令详解 一、strace 是什么？ 按照 strace 官网的描述，strace 是一个可用于诊断、调试和教学的 Linux 用户空间跟踪器。我们用它来监控用户空间进程和内核的交互，比如系统调用、信号传递、进程状态变更等。 strace 底层使用内核的 ptrace 特性来实现其功能。 在运维的日常工作中，故障处理和问题诊断是个主要的内容，也是必备的技能。strace 作为一种动态跟踪工具，能够帮助运维高效地定位进程和服务故障。它像是一个侦探，通过系统调用的蛛丝马迹，告诉你异常的真相。 二、strace 能做什么？ 运维工程师都是实践派的人，我们还是先来个例子吧。 我们从别的机器 copy 了个叫做 some_server 的软件包过来，开发说直接启动就行，啥都不用改。可是尝试启动时却报错，根本起不来！ 启动命令： ./some_server ../conf/some_server.conf 输出: FATAL: InitLogFile failed iRet: -1! Init error: -1655 为什么起不来呢？从日志看，似乎是初始化日志文件失败，真相到底怎样呢？我们用 strace 来看看。 strace -tt -f ./some_server ../conf/some_server.conf 我们注意到，在输出 InitLogFile failed 错误的前一行，有个 open 系统调用: 23:14:24.448034 open(\"/usr/local/apps/some_server/log//server_agent.log\", O_RDWR|O_CREAT|O_APPEND|O_LARGEFILE, 0666) = -1 ENOENT (No such file or directory) 它尝试打开文件 /usr/local/apps/some_server/log//server_agent.log 来写(不存在则创建)，可是却出错了，返回码是 -1 , 系统错误号 errorno 为 ENOENT。 查下 open 系统调用的手册页：man 2 open 搜索 ENOENT 这个错误号 errno 的解释 ENOENT O_CREAT is not set and the named file does not exist. Or, a directory component in pathname does not exist or is a dangling symbolic link. 这里说得比较清楚，因为我们例子中的 open 选项指定了 O_CREAT 选项，这里 errno 为 ENOENT 的原因是日志路径中某个部分不存在或者是一个失效的符号链接。我们来一级一级看下路径中的哪部分不存在： ls -l /usr/local/apps/some_server/log ls: cannot access /usr/local/apps/some_server/log: No such file or directory ls -l /usr/local/apps/some_server total 8 drwxr-xr-x 2 root users 4096 May 14 23:13 bin drwxr-xr-x 2 root users 4096 May 14 22:48 conf 原来是 log 子目录不存在！上层目录都是存在的。手工创建 log 子目录后，服务就能正常启动了。 回过头来， strace 究竟能做什么呢？ 它能够打开应用进程的这个黑盒，通过系统调用的线索，告诉你进程大概在干嘛。 三、strace怎么用？ strace 有两种运行模式。 一种是通过它启动要跟踪的进程。用法很简单，在原本的命令前加上 strace 即可。比如我们要跟踪 \"ls -lh /var/log/messages\" 这个命令的执行，可以这样： strace ls -lh /var/log/messages 另外一种运行模式，是跟踪已经在运行的进程，在不中断进程执行的情况下，理解它在干嘛。 这种情况，给 strace 传递个 -p pid 选项即可。比如，有个在运行的 some_server 服务，第一步，查看 pid: pidof some_server 17553 # 查看进程中线程的CPU占用情况，在top中加入`-H`参数，查看该进程中线程的cpu占用情况 top -H -p 17553 得到其 pid 17553 然后就可以用 strace 跟踪其执行: strace -p 17553 完成跟踪时，按 Ctrl + C 结束 strace 即可。 strace 有一些选项可以调整其行为，我们这里介绍下其中几个比较常用的，然后通过示例讲解其实际应用效果。 strace 常用选项： 从一个示例命令来看： strace -tt -T -v -f -e trace=file -o /data/log/strace.log -s 1024 -p 23489 -tt：在每行输出的前面，显示毫秒级别的时间 -T：显示每次系统调用所花费的时间 -v：对于某些相关调用，把完整的环境变量，文件 stat 结构等打出来。 -f：跟踪目标进程，以及目标进程创建的所有子进程 -e：控制要跟踪的事件和跟踪行为，比如指定要跟踪的系统调用名称 -e trace=file 跟踪和文件访问相关的调用(参数中有文件名) -e trace=process 和进程管理相关的调用，比如fork/exec/exit_group -e trace=network 和网络通信相关的调用，比如socket/sendto/connect -e trace=signal 信号发送和处理相关，比如kill/sigaction -e trace=desc 和文件描述符相关，比如write/read/select/epoll等 -e trace=ipc 跟踪所有与进程通讯有关的系统调用，比如shmget等 -e signal= 指定跟踪的系统信号.默认为all.如 signal=!SIGIO(或者signal=!io),表示不跟踪SIGIO信号. -e trace= 只跟踪指定的系统 调用.例如:-e trace=open,close,read,write表示只跟踪这四个系统调用.默认的为set=all. -o：把 strace 的输出单独写到指定的文件 -s：当系统调用的某个参数是字符串时，最多输出指定长度的内容，默认是 32 个字节 -p：指定要跟踪的进程 pid，要同时跟踪多个 pid，重复多次 -p 选项即可。 -x：打印十六进制非ascii字符串 # 下位机串口数据 # 命令：strace -s 1024 -p 214 -e trace=read -x read(64, \"R\", 1) = 1 read(64, \"U\", 1) = 1 // 帧尾 read(64, \"\\xaa\", 1) = 1 // 帧头 read(64, \"L\", 1) = 1 read(64, \"M\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"u\", 1) = 1 read(64, \"6\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x84\", 1) = 1 read(64, \"\\xc1\", 1) = 1 read(64, \"#\", 1) = 1 read(64, \"\\x86\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x0e\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"d\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x04\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"R\", 1) = 1 read(64, \"U\", 1) = 1 // 帧尾 read(64, \"\\xaa\", 1) = 1 // 帧头 read(64, \"L\", 1) = 1 read(64, \"M\", 1) = 1 -xx：打印十六进制ascii字符串（可读性高点） # 下位机串口数据 # 命令：strace -s 1024 -p 214 -e trace=read -xx read(64, \"\\x52\", 1) = 1 read(64, \"\\x55\", 1) = 1 // 帧尾 read(64, \"\\xaa\", 1) = 1 // 帧头 read(64, \"\\x4c\", 1) = 1 read(64, \"\\x4d\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x75\", 1) = 1 read(64, \"\\x36\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x84\", 1) = 1 read(64, \"\\xc1\", 1) = 1 read(64, \"\\x23\", 1) = 1 read(64, \"\\x86\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x01\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x0e\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x64\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x04\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x00\", 1) = 1 read(64, \"\\x53\", 1) = 1 read(64, \"\\x55\", 1) = 1 // 帧尾 read(64, \"\\xaa\", 1) = 1 // 帧头 read(64, \"\\x4c\", 1) = 1 read(64, \"\\x4d\", 1) = 1 -c：将进程所有系统调用做一个统计分析并返回 # strace -f -c -p 126 % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 55.87 9.992260 363 27527 1649 futex 19.84 3.547689 8717 407 pselect6 11.15 1.994709 1471 1356 ppoll 6.01 1.074210 5838 184 epoll_pwait 3.89 0.695708 88 7934 625 recvfrom 1.45 0.260006 54 4772 fcntl 0.66 0.117486 474 248 read 0.65 0.117000 58500 2 accept 0.19 0.033846 54 626 sendto 0.07 0.013000 813 16 fsync 0.06 0.011512 27 421 newfstatat 0.05 0.008677 7 1327 getpid 0.04 0.006500 22 298 munmap 0.03 0.004798 51 94 write 0.02 0.004247 18 241 mmap 0.01 0.002207 130 17 openat 0.01 0.002000 56 36 fstat 0.00 0.000000 0 19 close 0.00 0.000000 0 19 lseek 0.00 0.000000 0 1 mprotect ------ ----------- ----------- --------- --------- ---------------- 100.00 17.885855 45545 2274 total 四、strace问题定位案例 1、定位进程异常退出 问题：机器上有个叫做run.sh的常驻脚本，运行一分钟后会死掉。需要查出死因。 定位：进程还在运行时，通过ps命令获取其pid, 假设我们得到的pid是24298 strace -o strace.log -tt -p 24298 查看 strace.log，我们在最后 2 行看到如下内容: 22:47:42.803937 wait4(-1, 22:47:43.228422 +++ killed by SIGKILL +++ 这里可以看出，进程是被其他进程用 KILL 信号杀死的。 实际上，通过分析，我们发现机器上别的服务有个监控脚本，它监控一个也叫做 run.sh 的进程，当发现 run.sh 进程数大于 2 时，就会把它杀死重启。结果导致我们这个 run.sh 脚本被误杀。 进程被杀退出时，strace 会输出 killed by SIGX（SIGX 代表发送给进程的信号）等，那么，进程自己退出时会输出什么呢？ 这里有个叫做 test_exit 的程序，其代码如下: #include #include int main(int argc, char **argv) { exit(1); } 我们 strace 看下它退出时 strace 上能看到什么痕迹。 strace -tt -e trace=process -f ./test_exit 说明: -e trace=process 表示只跟踪和进程管理相关的系统调用。 输出： 23:07:24.672849 execve(\"./test_exit\", [\"./test_exit\"], [/* 35 vars */]) = 0 23:07:24.674665 arch_prctl(ARCH_SET_FS, 0x7f1c0eca7740) = 0 23:07:24.675108 exit_group(1) = ? 23:07:24.675259 +++ exited with 1 +++ 可以看出，进程自己退出时（调用 exit 函数，或者从 main 函数返回）, 最终调用的是 exit_group 系统调用， 并且 strace 会输出 exited with X（X为退出码）。 可能有人会疑惑，代码里面明明调用的是 exit，怎么显示为 exit_group? 这是因为这里的 exit 函数不是系统调用，而是 glibc 库提供的一个函数，exit 函数的调用最终会转化为 exit_group 系统调用，它会退出当前进程的所有线程。实际上，有一个叫做 _exit()的系统调用（注意 exit 前面的下划线)，线程退出时最终会调用它。 2、定位共享内存异常 有个服务启动时报错： shmget 267264 30097568: Invalid argument Can not get shm...exit! 错误日志大概告诉我们是获取共享内存出错，通过 strace 看下： strace -tt -f -e trace=ipc ./a_mon_svr ../conf/a_mon_svr.conf 输出： 22:46:36.351798 shmget(0x5feb, 12000, 0666) = 0 22:46:36.351939 shmat(0, 0, 0) = ? Process 21406 attached 22:46:36.355439 shmget(0x41400, 30097568, 0666) = -1 EINVAL (Invalid argument) shmget 267264 30097568: Invalid argument Can not get shm...exit! 这里，我们通过 -e trace=ipc 选项，让 strace 只跟踪和进程通信相关的系统调用。 从 strace 输出，我们知道是 shmget 系统调用出错了，errno 是 EINVAL。同样， 查询下 shmget 手册页，搜索 EINVAL 的错误码的说明: EINVAL A new segment was to be created and size SHMMAX, or no new segment was to be created, a segment with given key existed, but size is greater than the size of that segment 翻译下，shmget 设置 EINVAL 错误码的原因为下列之一： 要创建的共享内存段比 SHMMIN 小 (一般是1个字节) 要创建的共享内存段比 SHMMAX 大 (内核参数 kernel.shmmax 配置) 指定 key 的共享内存段已存在，其大小和调用 shmget 时传递的值不同。 从 strace 输出看，我们要连的共享内存 key 0x41400，指定的大小是 30097568 字节，明显与第1、2 种情况不匹配。那只剩下第三种情况。使用 ipcs 看下是否真的是大小不匹配： ipcs -m | grep 41400 key shmid owner perms bytes nattch status 0x00041400 1015822 root 666 30095516 1 可以看到，已经 0x41400 这个 key 已经存在，并且其大小为 30095516 字节，和我们调用参数中的 30097568 不匹配，于是产生了这个错误。 在我们这个案例里面，导致共享内存大小不一致的原因，是一组程序中，其中一个编译为32位，另外一个编译为64位,代码里面使用了long这个变长int数据类型。 把两个程序都编译为64解决了这个问题。 这里特别说下 strace 的 -e trace 选项。 要跟踪某个具体的系统调用，-e trace=xxx 即可。但有时候我们要跟踪一类系统调用，比如所有和文件名有关的调用、所有和内存分配有关的调用。 如果人工输入每一个具体的系统调用名称，可能容易遗漏。于是strace提供了几类常用的系统调用组合名字。 -e trace=file 跟踪和文件访问相关的调用(参数中有文件名) -e trace=process 和进程管理相关的调用，比如fork/exec/exit_group -e trace=network 和网络通信相关的调用，比如socket/sendto/connect -e trace=signal 信号发送和处理相关，比如kill/sigaction -e trace=desc 和文件描述符相关，比如write/read/select/epoll等 -e trace=ipc 进程见同学相关，比如shmget等 绝大多数情况，我们使用上面的组合名字就够了。实在需要跟踪具体的系统调用时，可能需要注意C 库实现的差异。 比如我们知道创建进程使用的是 fork 系统调用，但在 glibc 里面，fork 的调用实际上映射到了更底层的 clone 系统调用。使用 strace 时，得指定 -e trace=clone，指定 -e trace=fork 什么也匹配不上。 3、 性能分析 假如有个需求，统计 Linux 4.5.4 版本内核中的代码行数（包含汇编和 C 代码）。这里提供两个Shell 脚本实现： poor_script.sh: #!/bin/bash total_line=0 while read filename; do line=$(wc -l $filename | awk '{print $1}') (( total_line += line )) done good_script.sh: #!/bin/bash find linux-4.5.4 -type f ( -iname '.c' -o -iname '.h' -o -iname '*.S' ) -print0 | wc -l —files0-from - | tail -n 1 两段代码实现的目的是一样的。 我们通过 strace 的 -c 选项来分别统计两种版本的系统调用情况和其所花的时间（使用 -f 同时统计子进程的情况） 从两个输出可以看出，good_script.sh 只需要 2 秒就可以得到结果：19613114 行。它大部分的调用（calls）开销是文件操作（read/open/write/close）等，统计代码行数本来就是干这些事情。 而 poor_script.sh 完成同样的任务则花了 539 秒。它大部分的调用开销都在进程和内存管理上(wait4/mmap/getpid…)。 实际上，从两个图中 clone 系统调用的次数，我们可以看出 good_script.sh 只需要启动 3 个进程，而 poor_script.sh 完成整个任务居然启动了 126335 个进程！ 而进程创建和销毁的代价是相当高的，性能不差才怪。 五、总结 当发现进程或服务异常时，我们可以通过 strace 来跟踪其系统调用，“看看它在干啥”，进而找到异常的原因。熟悉常用系统调用，能够更好地理解和使用strace。 当然，万能的 strace 也不是真正的万能。当目标进程卡死在用户态时，strace 就没有输出了。 这个时候我们需要其他的跟踪手段，比如 gdb / perf / SystemTap 等。 备注： 1、perf 原因 kernel 支持 2、ftrace kernel 支持可编程 3、systemtap 功能强大，RedHat 系统支持，对用户态，内核态逻辑都能探查，使用范围更广。 "},"Linux/命令指北/02-ps和pstree.html":{"url":"Linux/命令指北/02-ps和pstree.html","title":"ps和pstree","keywords":"","body":"datetime:2023-02-02 14:20:00 author:nzb ps 和 pstree 命令 Linux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps 命令列出的是当前那些进程的快照，就是执行ps 命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。 ps 为我们提供了进程的一次性的查看，它所提供的查看结果并不动态连续的；如果想对进程时间监控，应该用 top 工具。 kill 命令用于杀死进程。 一、命令格式 ps [参数] 二、命令功能 用于显示当前进程 (process) 的状态。 三、命令参数 ps 的参数非常多, 在此仅列出几个常用的参数并大略介绍含义 参数 描述 -A 列出所有的行程 -e 等于“-A” -a 显示现行终端机下的所有进程，包括其他用户的进程； -u 以用户为主的进程状态 ； x 通常与 a 这个参数一起使用，可列出较完整信息。 -w 显示加宽可以显示较多的资讯 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -f 做一个更为完整的输出。 四、使用实例 1、显示所有进程信息 命令：ps -A 输出： [root@localhost autoAweme]# ps -A PID TTY TIME CMD 1 ? 00:00:15 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:56 ksoftirqd/0 5 ? 00:00:00 kworker/0:0H 7 ? 00:01:01 migration/0 8 ? 00:00:00 rcu_bh 9 ? 00:18:57 rcu_sched 10 ? 00:00:00 lru-add-drain 11 ? 00:00:03 watchdog/0 12 ? 00:00:02 watchdog/1 13 ? 00:01:01 migration/1 14 ? 00:00:56 ksoftirqd/1 16 ? 00:00:00 kworker/1:0H ……省略部分结果 2、显示指定用户信息 命令：ps -u root 输出： [root@localhost autoAweme]# ps -u root PID TTY TIME CMD 1 ? 00:00:15 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:56 ksoftirqd/0 5 ? 00:00:00 kworker/0:0H 7 ? 00:01:01 migration/0 8 ? 00:00:00 rcu_bh 9 ? 00:18:57 rcu_sched 10 ? 00:00:00 lru-add-drain 11 ? 00:00:03 watchdog/0 12 ? 00:00:02 watchdog/1 13 ? 00:01:01 migration/1 14 ? 00:00:56 ksoftirqd/1 16 ? 00:00:00 kworker/1:0H 18 ? 00:00:00 kdevtmpfs 19 ? 00:00:00 netns 20 ? 00:00:00 khungtaskd ……省略部分结果 说明：显示root进程用户信息 3、显示所有进程信息，连带命令行 命令：ps -ef 输出： [root@localhost autoAweme]# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 11月30 ? 00:00:15 /usr/lib/systemd/systemd --swi root 2 0 0 11月30 ? 00:00:00 [kthreadd] root 3 2 0 11月30 ? 00:00:56 [ksoftirqd/0] root 5 2 0 11月30 ? 00:00:00 [kworker/0:0H] root 7 2 0 11月30 ? 00:01:01 [migration/0] ……省略部分结果 4、ps 与grep 常用组合用法，查找特定进程 命令：ps -ef|grep uwsgi 输出： [root@localhost autoAweme]# ps -ef|grep uwsgi root 30568 795 0 12月01 ? 00:00:19 /home/hc/project/envs/pgc/bin/uwsgi --ini /home/hc/project/pgc.ini root 30578 30568 0 12月01 ? 00:00:00 /home/hc/project/envs/pgc/bin/uwsgi --ini /home/hc/project/pgc.ini root 66069 795 1 12:07 ? 00:04:29 /home/hc/project/envs/autoAweme/bin/uwsgi --ini /home/hc/project/autoAweme.ini root 66096 66069 0 12:07 ? 00:00:01 /home/hc/project/envs/autoAweme/bin/uwsgi --ini /home/hc/project/autoAweme.ini root 80022 86053 0 16:06 pts/1 00:00:00 grep --color=auto uwsgi 5、将目前属于您自己这次登入的 PID 与相关信息列示出来 命令：ps -l 输出： [root@localhost autoAweme]# ps -l F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 0 85984 80319 0 80 0 - 58596 do_wai pts/1 00:00:00 su 4 S 0 86053 85984 0 80 0 - 29208 do_wai pts/1 00:00:01 bash 0 R 0 107795 86053 0 80 0 - 38300 - pts/1 00:00:00 ps 各相关信息的意义 标志 意义 F 代表这个程序的旗标 (flag)， 4 代表使用者为 super user S 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍 UID 程序被该 UID 所拥有 PID 就是这个程序的 ID ！ PPID 则是其上级父程序的ID C CPU 使用的资源百分比 PRI 指进程的执行优先权(Priority的简写)，其值越小越早被执行； NI 这个进程的nice值，其表示进程可被执行的优先级的修正数值。 ADDR 这个是内核函数，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 \"-\" SZ 使用掉的内存大小 WCHAN 目前这个程序是否正在运作当中，若为 - 表示正在运作 TTY 登入者的终端机位置 TIME 使用掉的 CPU 时间。 CMD 所下达的指令为何 在预设的情况下， ps 仅会列出与目前所在的 bash shell 有关的 PID 而已，所以， 当我使用 ps -l 的时候，只有三个 PID。 6、列出目前所有的正在内存当中的程序 命令：ps aux 输出： [root@localhost autoAweme]# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.1 125804 4260 ? Ss 11月30 0:15 /usr/lib/systemd/systemd --switched-root --system --deserialize 22 root 2 0.0 0.0 0 0 ? S 11月30 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S 11月30 0:56 [ksoftirqd/0] root 5 0.0 0.0 0 0 ? S 说明： 标志 意义 USER 该 process 属于那个使用者账号的 PID 该 process 的号码 %CPU 该 process 使用掉的 CPU 资源百分比 %MEM 该 process 所占用的物理内存百分比 VSZ 该 process 使用掉的虚拟内存量 (Kbytes) RSS 该 process 占用的固定的内存量 (Kbytes) TTY 该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。 STAT 该程序目前的状态 START 该 process 被触发启动的时间 TIME 该 process 实际使用 CPU 运作的时间 COMMAND 该程序的实际指令 STAT：该程序目前的状态，ps工具标识进程的5种状态码 D ：不可中断 uninterruptible sleep (usually IO) R ：该程序目前正在运作，或者是可被运作 S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。 T ：该程序目前正在侦测或者是停止了 Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态 7、以类似进程树的结构显示 命令：ps -axjf 输出： [root@localhost autoAweme]# ps -axjf PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 0 2 0 0 ? -1 S 0 0:00 [kthreadd] 2 3 0 0 ? -1 S 0 0:57 \\_ [ksoftirqd/0] 2 5 0 0 ? -1 S 8、pstree命令更优雅的树状显示 pstree命令以树状图显示进程间的关系（display a tree of processes）。ps命令可以显示当前正在运行的那些进程的信息，但是对于它们之间的关系却显示得不够清晰。在Linux系统中，系统调用fork 可以创建子进程， 通过子shell也可以创建子进程，Linux系统中进程之间的关系天生就是一棵树，树的根就是进程PID为1的init进程。 以树状图只显示进程的名字，且相同进程合并显示 命令：pstree 输出： [root@localhost autoAweme]# pstree systemd─┬─ModemManager───2*[{ModemManager}] ├─NetworkManager───2*[{NetworkManager}] ├─VGAuthService ├─2*[abrt-watch-log] ├─abrtd ├─accounts-daemon───2*[{accounts-daemon}] ├─alsactl ├─at-spi-bus-laun─┬─dbus-daemon │ └─3*[{at-spi-bus-laun}] ├─at-spi2-registr───2*[{at-spi2-registr}] ├─atd ├─auditd─┬─audispd─┬─sedispatch │ │ └─{audispd} │ └─{auditd} ├─avahi-daemon───avahi-daemon ……省略部分结果 以树状图显示进程同时还显示PID 命令：pstree -p 输出： [root@localhost autoAweme]# pstree -p systemd(1)─┬─ModemManager(686)─┬─{ModemManager}(722) │ └─{ModemManager}(744) ├─NetworkManager(796)─┬─{NetworkManager}(807) │ └─{NetworkManager}(811) ├─VGAuthService(677) ├─abrt-watch-log(698) ├─abrt-watch-log(703) ├─abrtd(684) ├─accounts-daemon(680)─┬─{accounts-daemon}(699) │ └─{accounts-daemon}(742) ├─alsactl(679) ├─at-spi-bus-laun(2636)─┬─dbus-daemon(2641) │ ├─{at-spi-bus-laun}(2637) │ ├─{at-spi-bus-laun}(2638) │ └─{at-spi-bus-laun}(2640) ├─at-spi2-registr(2643)─┬─{at-spi2-registr}(2648) │ └─{at-spi2-registr}(2649) ├─atd(1171) ……省略部分结果 以树状图显示进程PID为的进程以及子孙进程，如果有-p参数则同时显示每个进程的PID 命令： pstree [-p] 输出：[root@localhost autoAweme]# pstree 1244 mysqld_safe───mysqld───19*[{mysqld}] [root@localhost autoAweme]# pstree -p 1244 mysqld_safe(1244)───mysqld(1869)─┬─{mysqld}(1906) ├─{mysqld}(1911) ├─{mysqld}(1912) ├─{mysqld}(1913) ├─{mysqld}(1914) ├─{mysqld}(1915) ├─{mysqld}(1916) ├─{mysqld}(1917) ├─{mysqld}(1918) ├─{mysqld}(1919) ├─{mysqld}(1920) ├─{mysqld}(1926) ├─{mysqld}(1927) ├─{mysqld}(1928) ├─{mysqld}(1929) ├─{mysqld}(1930) ├─{mysqld}(1931) ├─{mysqld}(2081) └─{mysqld}(77714) 以树状图显示进程，相同名称的进程不合并显示，并且会显示命令行参数，如果有-p参数则同时显示每个进程的PID 命令：pstree -a 输出： [root@localhost autoAweme]# pstree -a systemd --switched-root --system --deserialize 22 ├─ModemManager │ └─2*[{ModemManager}] ├─NetworkManager --no-daemon │ └─2*[{NetworkManager}] ├─VGAuthService -s ├─supervisord /usr/bin/supervisord -c /etc/supervisord.conf │ ├─celery /home/hc/project//envs/autoAweme/bin/celery worker -A celery_worker.celery -l info │ │ ├─celery /home/hc/project//envs/autoAweme/bin/celery worker -A celery_worker.celery -l info │ │ │ └─{celery} │ │ ├─celery /home/hc/project//envs/autoAweme/bin/celery worker -A celery_worker.celery -l info │ │ │ └─{celery} │ │ └─2*[{celery}] │ ├─uwsgi --ini /home/hc/project/pgc.ini │ │ └─uwsgi --ini /home/hc/project/pgc.ini │ └─uwsgi --ini /home/hc/project/autoAweme.ini │ ├─uwsgi --ini /home/hc/project/autoAweme.ini │ └─2*[{uwsgi}] ……省略部分结果 注：因为pstree输出的信息可能比较多，所以最好与more/less配合使用,使用上下箭头查看，按q退出。 pstree -p | less 9、其他实例 可以用 | 管道和 more 连接起来分页查看 命令：ps -aux |more 把所有进程显示出来，并输出到ps001.txt文件 命令：ps -aux > ps001.txt 输出指定的字段 命令：ps -o pid,ppid,pgrp,session,tpgid,comm Linux上进程的几种状态 R（TASK_RUNNING），可执行状态&运行状态（在run_queue队列里的状态） 只有在该状态的进程才可能在CPU上运行，同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应的CPU的可执行队列中 （一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。 一般将正在CPU上执行的进程定义为RUNNING状态，而将可执行但是尚未被调度执行的进程定义为READY状态，这两种状态在linux下同一为TASK_RUNNING状态。 只要可执行队列不为空，其对应的CPU就不能偷懒，就要执行其中某个进程。一般称此时的CPU“忙碌”。对应的，CPU“空闲”就是指其对应的可执行队列为空， 以致于CPU无事可做。 有人问，为什么死循环程序会导致CPU占用高呢？因为死循环程序基本上总是处于TASK_RUNNING状态（进程处于可执行队列中）。 S（TASK_INTERRUPTIBLE）,可中断的睡眠状态，可处理signal 处于这个状态的进程因为等待某个事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。 当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程被唤醒。通过ps命令我们会看到，一般情况下， 进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE 状态（除非机器的负载很高）。毕竟CPU就那么几个，而进程动辄几十上百个， 如果不是绝大多数进程都在睡眠，CPU又怎么响应的过来。 D（TASK_UNINTERRUPTIBLE），不可中断的睡眠状态，可处理signal，有延迟 与TASK_INTERRUPTIBLE状态类似，进程也处于睡眠状态，但是此刻的进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断， 而是指进程不响应异步信号 。绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。否则你将惊奇的发现，kill -9竟然杀不死一个正在睡眠的进程了！ 于是我们也很好理解，为什么ps命令看到的进程几乎不会出现TASK_UNINTERRUPTIBLE 状态，而总是TASK_INTERRUPTIBLE状态。 而TASK_UNINTERRUPTIBLE状态存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号， 程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程被中断了。 （参见《linux内核异步中断浅析》）在进程对某些硬件进行操作时（比如进程调用read 系统调用对某个设备文件进行读操作， 而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护， 以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到。 T（TASK_STOPPED or TASK_TRACED）,暂停状态或跟踪状态，不可处理signal,因为根本没有时间片运行代码 向进程发送一个SIGSTOP信号，它就会因响应信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。 (SIGSTOP与SIGKILL信号一样，是非强制的。不允许用户进程通过signal系统的系统调用重新设置对应的信号处理函数)向进程发送一个SIGCONT信号， 可以让其从TASK_STOPPED 状态恢复到TASK_RUNNING状态。 当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。 比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED 状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。 对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。而TASK_TRACED 状态相当于在TASK_STOPPED之上多了一层保护， 处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作 （通过ptrace 系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。 Z（TASK_DEAD-EXIT_ZOMBIE）退出状态，进程称为僵尸进程，不可被kill，即不相应任务信号，无法用SIGKILL杀死 在退出过程中，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外。于是进程就只剩下task_struct这么个空壳，故称为僵尸。 之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在shell中， $?变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。当然，内核也可以将这些信息保存在别的地方， 而将task_struct释放掉，以节省一些空间。但是使用task_struct 结构更为方便，因为内核中已经建立了从pid到task_struct查找关系， 还有进程间的父子关系。释放掉task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。 父进程可以通过wait系列的系统调用（如wait4,waitid）来等待某个或某些子进程的退出，并获取它的退出信息。 然后wait系列的系统调用会顺便将子进程的尸体(task_struct)也释放掉 。子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来收尸。 这个信号默认是SIGCHLD，但是在通过clone系统调用创建子进程时，可以设置这个信号。只要父进程不退出，这个僵尸状态的子进程就一直存在。 那么如果父进程退出了呢，谁又来给子进程“收尸”？当进程退出的时候，会将它的所有子进程都托管给别的进程（使之成为别的进程的子进程）。 托管给谁呢？可能是退出进程所在进程组的下一个进程（如果存在的话），或者是1号进程。所以每个进程、每时每刻都有父进程存在。除非它是1号进程。 1号进程，pid为1的进程，又称init进程。 linux系统启动后，第一个被创建的用户态进程就是init进程。它有两项使命： 1、执行系统初始化脚本，创建一系列的进程（它们都是init进程的子孙）； 2、在一个死循环中等待其子进程的退出事件，并调用waitid系统调用来完成“收尸”工作； init进程不会被暂停、也不会被杀死（这是由内核来保证的）。 它在等待子进程退出的过程中处于TASK_INTERRUPTIBLE状态， “收尸”过程中则处于TASK_RUNNING状态。 X（TASK_DEAD-EXIT_DEAD），退出状态，进程即将被销毁 而进程在退出过程中也可能不会保留它的task_struct。比如这个进程是多线程程序中被detach过的进程（进程？线程？参见《linux线程浅析》）。 或者父进程通过设置SIGCHLD信号的handler 为SIG_IGN，显式的忽略了SIGCHLD信号。（这是posix的规定， 尽管子进程的退出信号可以被设置为SIGCHLD以外的其他信号。）此时，进程将被置于EXIT_DEAD 退出状态，这意味着接下来的代码立即就会将该进程彻底释放。 所以EXIT_DEAD状态是非常短暂的，几乎不可能通过ps命令捕捉到。 进程的初始状态 进程是通过fork系列的系统调用（fork、clone、vfork）来创建的，内核（或内核模块）也可以通过kernel_thread函数创建内核进程。 这些创建子进程的函数本质上都完成了相同的功能——将调用进程复制一份，得到子进程。（可以通过选项参数来决定各种资源是共享、还是私有。） 那么既然调用进程处于TASK_RUNNING 状态（否则，它若不是正在运行，又怎么进行调用？），则子进程默认也处于TASK_RUNNING状态。 另外，在系统调用调用clone和内核函数kernel_thread也接受CLONE_STOPPED 选项，从而将子进程的初始状态置为TASK_STOPPED。 进程状态变迁 进程自创建以后，状态可能发生一系列的变化，直到进程退出。而尽管进程状态有好几种，但是进程状态的变迁却只有两个方向——从TASK_RUNNING状态变为非TASK_RUNNING状态、 或者从非TASK_RUNNING 状态变为TASK_RUNNING状态。也就是说，如果给一个TASK_INTERRUPTIBLE状态的进程发送SIGKILL信号，这个进程将先被唤醒（进入TASK_RUNNING状态）， 然后再响应SIGKILL 信号而退出（变为TASK_DEAD状态）。并不会从TASK_INTERRUPTIBLE状态直接退出（至少发送一个SIGCHLD信号需要活着吧）。 进程从非TASK_RUNNING状态变为TASK_RUNNING状态，是由别的进程（也可能是中断处理程序）执行唤醒操作来实现的。 执行唤醒的进程设置被唤醒进程的状态为TASK_RUNNING，然后将其task_struct 结构加入到某个CPU的可执行队列中。于是被唤醒的进程将有机会被调度执行。 而进程从TASK_RUNNING状态变为非TASK_RUNNING状态，则有两种途径： 1、响应信号而进入TASK_STOPED状态、或TASK_DEAD状态； 2、执行系统调用主动进入TASK_INTERRUPTIBLE状态（如nanosleep系统调用）、或TASK_DEAD状态（如exit系统调用）；或由于执行系统调用需要的资源得不到满足， 而进入TASK_INTERRUPTIBLE状态或TASK_UNINTERRUPTIBLE状态（如select系统调用）。显然，这两种情况都只能发生在进程正在CPU上执行的情况下。 "},"Linux/命令指北/03-top.html":{"url":"Linux/命令指北/03-top.html","title":"top","keywords":"","body":"datetime:2023-02-03 10:50:00 author:nzb top 命令 命令格式 top [参数] 命令功能 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 命令参数 参数 描述 -b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i 设置间隔时间 -u 指定用户名 -p 指定进程 -n 循环显示的次数 使用实例 1、显示进程信息 命令：top 输出： [hc@localhost ~]$ top top - 09:22:56 up 6 days, 1:40, 3 users, load average: 0.22, 0.31, 0.71 Tasks: 231 total, 1 running, 230 sleeping, 0 stopped, 0 zombie %Cpu(s): 10.6 us, 12.1 sy, 0.0 ni, 77.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 3863568 total, 473100 free, 1651284 used, 1739184 buff/cache KiB Swap: 3145724 total, 3120012 free, 25712 used. 1837920 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2676 hc 20 0 3627652 339496 22160 S 16.3 8.8 17:50.00 gnome-she+ 689 polkitd 20 0 649880 17144 4636 S 10.3 0.4 678:56.95 polkitd 2051 root 20 0 358552 50640 6600 S 6.6 1.3 4:44.68 X 101038 hc 20 0 771640 27384 17392 S 2.7 0.7 0:01.21 gnome-ter+ 721 dbus 20 0 61996 3708 1648 S 2.0 0.1 186:05.55 dbus-daem+ 680 root 20 0 396404 3816 3124 S 1.7 0.1 154:18.42 accounts-+ 86929 root 20 0 457956 51100 6944 S 1.3 1.3 15:59.97 uwsgi 113983 hc 20 0 161972 2400 1620 R 0.7 0.1 0:00.11 top 9 root 20 0 0 0 0 S 0.3 0.0 28:14.62 rcu_sched 405 root 20 0 0 0 0 S 0.3 0.0 7:43.36 xfsaild/d+ 681 root 20 0 13216 600 572 S 0.3 0.0 0:31.09 rngd 1304 mongod 20 0 1025840 81704 4160 S 0.3 2.1 51:29.25 mongod 1869 mysql 20 0 1263256 112036 4784 S 0.3 2.9 10:32.82 mysqld 2909 hc 20 0 611472 7256 3592 S 0.3 0.2 54:46.85 gsd-accou+ 30239 root 20 0 453640 54536 3420 S 0.3 1.4 12:21.71 celery 1 root 20 0 125804 3544 2120 S 0.0 0.1 0:16.95 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.44 kthreadd 说明 统计信息区： 前五行是当前系统情况整体的统计信息区。下面我们看每一行信息的具体意义。 第一行，任务队列信息，同 uptime 命令的执行结果，具体参数说明情况如下： 09:22:56 -- 当前系统时间 up 6 days, 1:40 -- 系统已经运行了6天1小时40分钟（在这期间系统没有重启过） 3 users -- 当前有2个用户登录系统 load average: 0.22, 0.31, 0.71 -- load average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 第二行，Tasks — 任务（进程），具体信息说明如下：系统现在共有231个进程，其中处于运行中的有1个，230个在休眠（sleep），stoped状态的有0个，zombie状态（僵尸）的有0个。 第三行，cpu状态信息，具体属性说明如下 10.6 us -- 用户态占用CPU的百分比 12.1 sy -- 内核态占用CPU的百分比 0.0 ni -- 用做nice加权的进程分配的用户态cpu占用CPU的百分比 77.3 id -- 空闲的cpu百分比 0.0 wa -- cpu等待磁盘写入占用CPU的百分比 0.0 hi -- 硬中断（Hardware IRQ）占用CPU的百分比 0.0 si -- 软中断（Software Interrupts）占用CPU的百分比 0.0 st 备注：在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识！ 第四行,内存状态，具体信息如下： 3863568 total -- 物理内存总量 473100 free -- 空闲内存总量 1651284 used -- 使用中的内存总量 1739184 buff/cache -- 缓存的内存量 第五行，swap交换分区信息，具体信息说明如下： 3145724 total -- 交换区总量 3120012 free -- 空闲交换区总量 25712 used -- 使用的交换区总量 1837920 avail Mem -- 表示可用于进程下一次分配的物理内存数量 第六行，空行 第七行以下各进程（任务）的状态监控，项目列信息说明如下： 列名 说明 PID 进程id USER 进程所有者 PR 进程优先级 NI nice值。负值表示高优先级，正值表示低优先级 VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR 共享内存大小，单位kb S 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU 上次更新到现在的CPU时间占用百分比 %MEM 进程使用的物理内存百分比 TIME+ 进程使用的CPU时间总计，单位1/100秒 COMMAND 进程名称（命令名/命令行） 备注： 第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。 纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去， 因此在linux上free内存会越来越少，但不用为此担心。 如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buff/cache，按这个公式此台服务器的可用内存。 对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。 2、显示完整命令 命令：top -c 输出： [hc@localhost ~]$ top -c top - 10:01:50 up 6 days, 2:19, 3 users, load average: 0.01, 0.04, 0.10 Tasks: 233 total, 1 running, 232 sleeping, 0 stopped, 0 zombie %Cpu(s): 5.3 us, 10.8 sy, 0.0 ni, 83.8 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 3863568 total, 451416 free, 1665668 used, 1746484 buff/cache KiB Swap: 3145724 total, 3120012 free, 25712 used. 1823504 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 689 polkitd 20 0 649880 17144 4636 S 10.0 0.4 682:30.53 /usr/lib/polkit-1/polkitd --no-debug 2676 hc 20 0 3646940 359304 22308 S 6.0 9.3 18:02.04 /usr/bin/gnome-shell 2051 root 20 0 352052 44092 6600 S 3.3 1.1 4:50.20 /usr/bin/X :0 -background none -nor+ 721 dbus 20 0 61996 3708 1648 S 2.3 0.1 187:04.96 /usr/bin/dbus-daemon --system --add+ 680 root 20 0 396404 3816 3124 S 2.0 0.1 155:06.59 /usr/libexec/accounts-daemon 101038 hc 20 0 772056 27784 17528 S 1.3 0.7 0:03.61 /usr/libexec/gnome-terminal-server 86929 root 20 0 457956 51100 6944 S 1.0 1.3 16:30.76 /home/hc/project/envs/autoAweme/bin+ 1869 mysql 20 0 1263256 112036 4784 S 0.7 2.9 10:35.24 /usr/libexec/mysqld --basedir=/usr + 2909 hc 20 0 611472 7256 3592 S 0.7 0.2 55:04.22 /usr/libexec/gsd-account 9 root 20 0 0 0 0 S 0.3 0.0 28:22.21 [rcu_sched] 405 root 20 0 0 0 0 S 0.3 0.0 7:45.11 [xfsaild/dm-0] 2641 hc 20 0 60172 2152 1580 S 0.3 0.1 0:00.27 /bin/dbus-daemon --config-file=/usr+ 2889 hc 20 0 797116 12812 6428 S 0.3 0.3 4:06.38 /usr/libexec/gsd-color 71994 hc 20 0 162116 2504 1704 R 0.3 0.1 0:00.03 top -c 1 root 20 0 125804 3544 2120 S 0.0 0.1 0:16.97 /usr/lib/systemd/systemd --switched+ 2 root 20 0 0 0 0 S 0.0 0.0 0:00.44 [kthreadd] 3 root 20 0 0 0 0 S 0.0 0.0 1:26.89 [ksoftirqd/0] 3、以批处理模式显示程序信息 命令：top -b 4、以累积模式显示程序信息 命令：top -S 5、设置信息更新次数 命令：top -n 2 说明：表示更新两次后终止更新显示 6、设置信息更新时间 命令：top -d 3 说明：表示更新周期为3秒 7、显示指定的进程信息 命令：top -p 30568 输出： [hc@localhost ~]$ top -p 30568 top - 10:04:42 up 6 days, 2:22, 3 users, load average: 0.26, 0.09, 0.11 Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie %Cpu(s): 9.7 us, 12.3 sy, 0.0 ni, 77.9 id, 0.0 wa, 0.0 hi, 0.2 si, 0.0 st KiB Mem : 3863568 total, 451040 free, 1665892 used, 1746636 buff/cache KiB Swap: 3145724 total, 3120012 free, 25712 used. 1823304 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 30568 root 20 0 310244 52392 3652 S 0.0 1.4 0:29.02 uwsgi 其他使用技巧 1、多U多核CPU监控 在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况： 输出： top - 09:52:33 up 6 days, 2:10, 3 users, load average: 0.00, 0.01, 0.11 Tasks: 233 total, 2 running, 230 sleeping, 0 stopped, 1 zombie %Cpu0 : 2.7 us, 9.2 sy, 0.0 ni, 88.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 : 3.4 us, 10.3 sy, 0.0 ni, 86.2 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 3863568 total, 458724 free, 1659276 used, 1745568 buff/cache KiB Swap: 3145724 total, 3120012 free, 25712 used. 1829944 avail Mem 说明：观察上图，服务器有2个逻辑CPU，实际上是1个物理CPU。再按数字键1，就会返回到top基本视图界面。 2、高亮显示当前运行进程 在top基本视图中，敲击键盘“b”（打开/关闭加亮效果） 可以通过敲击“y”键关闭或打开运行态进程的加亮效果。 3、进程字段排序 默认进入top时，各进程是按照CPU的占用量来排序的， 敲击键盘“x”（打开/关闭排序列的加亮效果） 4、通过”shift + >”或”shift + ”可以向右或左改变排序列 5、top交互命令 在top 命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了s选项， 其中一些命令可能会被屏蔽。 命令 说明 h 显示帮助画面，给出一些简短的命令总结说明 k 终止一个进程。 i 忽略闲置和僵死进程。这是一个开关式命令。 q 退出程序 r 重新安排一个进程的优先级别 S 切换到累计模式 s 改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5s f或者F 从当前显示中添加或者删除项目 o或者O 改变显示项目的顺序 l 切换显示平均负载和启动时间信息 m 切换显示内存信息 t 切换显示进程和CPU状态信息 c 切换显示命令名称和完整命令行 e 切换显示内存信息以M、G、T等方式显示 M 根据驻留内存大小进行排序 P 根据CPU使用百分比大小进行排序 T 根据时间/累计时间进行排序 W 将当前设置写入~/.toprc文件中 "},"Linux/命令指北/04-性能分析工具-py-spy.html":{"url":"Linux/命令指北/04-性能分析工具-py-spy.html","title":"py-spy","keywords":"","body":"datetime:2023-04-25 10:46:00 author:nzb py-spy GitHub 安装 pip install py-spy 参数 record：将堆栈跟踪信息记录到火焰图、速度范围或原始文件中 top：可以展示哪些函数被调用执行的次数最多（显示消耗CPU最多的函数） dump：将目标程序的堆栈跟踪转储到stdout record 命令：py-spy record 参数 -p, --pid ：指定进程(线程)PID --full-filenames：显示文件全名（包括路径） -o, --output ：输出文件 -f, --format ：输出文件的格式[默认: flamegraph] [其他选项: flamegraph, raw, speedscope] -d, --duration ：采样的秒数 [默认: 无限制] -r, --rate ：要采样的秒数每秒要采集的样本数 [默认: 100] -s, --subprocesses：配置原始流程的子流程 -F, --function：按函数的第一个行号而不是当前行号聚合样本 --nolineno：不显示行号 -t, --threads：在输出中显示线程ID -g, --gil：仅包括保留在GIL上的跟踪 -i, --idle：包括空闲线程的堆栈跟踪 --nonblocking：收集样本时不要暂停python进程。设置此选项将减少采样对性能的影响，但可能导致不准确的结果 示例 top 命令：py-spy top 参数 -p, --pid ：指定进程(线程)PID -r, --rate ：要采样的秒数每秒要采集的样本数 [默认: 100] -s, --subprocesses：配置原始流程的子流程 --full-filenames：显示文件全名（包括路径） -g, --gil：仅包括保留在GIL上的跟踪 -i, --idle：包括空闲线程的堆栈跟踪 --nonblocking：收集样本时不要暂停python进程。设置此选项将减少采样对性能的影响，但可能导致不准确的结果 Collecting samples from 'python /upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py' (python v2.7.17) Total Samples 5183 GIL: 22.00%, Active: 2600.00%, Threads: 28 %Own %Total OwnTime TotalTime Function (filename:line) 1477.00% 1477.00% 766.3s 766.3s recv_buff (rospy/impl/tcpros_base.py:104) 200.00% 200.00% 103.7s 103.7s __clear (script/ros_center/LogUtil.py:66) 200.00% 200.00% 103.7s 103.7s _eintr_retry (SocketServer.py:150) 100.00% 100.00% 51.83s 51.83s compress_slam_map (script/ros_center/RosCenter_zmq.py:439) 100.00% 100.00% 51.83s 51.83s recv_string (zmq/sugar/socket.py:592) 100.00% 100.00% 51.83s 51.83s compress_slam_landmark (script/ros_center/RosCenter_zmq.py:376) 100.00% 100.00% 51.83s 51.83s accept (socket.py:206) 100.00% 100.00% 51.83s 51.83s wallsleep (rospy/rostime.py:277) 100.00% 100.00% 51.83s 51.83s print_self_dict (script/ros_center/RosCenter_zmq.py:203) 99.00% 99.00% 51.53s 51.53s run (gevent/hub.py:639) 5.00% 5.00% 2.06s 2.06s iterencode (json/encoder.py:270) 1.00% 1.00% 1.67s 1.91s deserialize (sensor_msgs/msg/_PointCloud.py:194) 3.00% 6.00% 1.08s 1.78s deserialize (sensor_msgs/msg/_PointCloud.py:190) 2.00% 2.00% 0.730s 0.730s meth (socket.py:228) 0.00% 1488.00% 0.410s 772.4s receive_loop (rospy/impl/tcpros_base.py:797) 2.00% 2.00% 0.370s 0.370s deserialize (sensor_msgs/msg/_PointCloud.py:195) 0.00% 0.00% 0.300s 0.300s encode (json/encoder.py:210) 0.00% 0.00% 0.260s 0.260s send (zmq/sugar/socket.py:400) 0.00% 0.00% 0.250s 0.250s _retryable_call (redis/_compat.py:53) Press Control-C to quit, or ? for help. 说明 ％Own（当前在该函数中花费的时间的百分比） ％Total（函数及其子级中当前的时间百分比） OwnTime（函数中花费的总时间） — TotalTime（该函数及其子项花费的总时间） dump 命令：py-spy dump 参数 -p, --pid ：指定进程(线程)PID -s, --subprocesses：配置原始流程的子流程 --nonblocking：收集样本时不要暂停python进程。设置此选项将减少采样对性能的影响，但可能导致不准确的结果 --full-filenames：显示文件全名（包括路径） -l, --locals：显示每个帧的局部变量。多次传递（-ll）会增加冗长程度 -j, --json：JSON格式化输出 Format output as JSON 说明 Arguments：函数运行参数 Locals：局部变量 Process 149: python /upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py Python v2.7.17 (/usr/bin/python2.7) Thread 0x7F8F028BD0 (active) wallsleep (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/rostime.py:277) Arguments: duration: 0.5 spin (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/client.py:129) (/upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py:92) Thread 0x7F8D9171F0 (active) __clear (/upper_computer/upper_main/upper_computer_ros/script/ros_center/LogUtil.py:66) Arguments: self: Locals: file_list: [\"/logs/ros_log/ros_2023-05-09_11_34_05\", \"/logs/ros_log/ros_2023-05-09_01_01_36\", ...] file_: \"/logs/ros_log/ros_obstacles_timeout_2023-05-08_18_49_03\" run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F8D1161F0 (active) __clear (/upper_computer/upper_main/upper_computer_ros/script/ros_center/LogUtil.py:66) Arguments: self: Locals: file_list: [\"/logs/ros_log/ros_obstacles_timeout_2023-05-08_18_49_03\"] run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F87FFF1F0 (active) _eintr_retry (/usr/lib/python2.7/SocketServer.py:150) Arguments: func: Locals: args: ([], [], [], 0.5) serve_forever (/usr/lib/python2.7/SocketServer.py:231) Arguments: self: poll_interval: 0.5 Locals: r: [] w: [] e: [] _run (/opt/ros/melodic/lib/python2.7/dist-packages/rosgraph/xmlrpc.py:297) Arguments: self: run (/opt/ros/melodic/lib/python2.7/dist-packages/rosgraph/xmlrpc.py:225) Arguments: self: Thread 0x7F877FE1F0 (idle) wait (/usr/lib/python2.7/threading.py:359) Arguments: self: timeout: 0.5 Locals: waiter: saved_state: (1, 547734151664) endtime: 1683613820.420009 delay: 0.05 gotit: False remaining: 0.33446288108825684 run (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/registration.py:298) Arguments: self: Locals: cond: topic: None uris: None x: (\"/error_msg\", [\"http://192.168.111.111:43381/\", \"http://192.168.111.111:41241/\", \"http://192.168.111.111:37035/\", ...]) uri: \"http://192.168.111.111:33045/\" t: start (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/registration.py:276) Arguments: self: uri: \"http://192.168.111.111:44309/\" master_uri: \"http://192.168.111.111:11311\" Locals: first: True tm: sm: ns: \"/\" caller_id: \"/UpperComputerRosCenter\" registered: True master: pub: [] sub: [] srv: [] run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F86FFD1F0 (active) accept (/usr/lib/python2.7/socket.py:206) Arguments: self: run (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:154) Arguments: self: Locals: client_sock: client_addr: (\"192.168.111.111\", 52982) run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F84FF91F0 (active) _eintr_retry (/usr/lib/python2.7/SocketServer.py:150) Arguments: func: Locals: args: ([], [], [], 0.5) serve_forever (/usr/lib/python2.7/SocketServer.py:231) Arguments: self: poll_interval: 0.5 Locals: r: [] w: [] e: [] __init_xmlrpc_server (/upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py:90) Arguments: self: run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F527FC1F0 (active) run (/usr/local/lib/python2.7/dist-packages/gevent/hub.py:639) Arguments: self: Locals: loop: Thread 0x7F50FF91F0 (active) recv_string (/usr/local/lib/python2.7/dist-packages/zmq/sugar/socket.py:592) Arguments: self: flags: 0 encoding: \"utf-8\" __init_topic_zmq_response (/upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py:294) Arguments: self: Locals: resp_context: resp_socket: run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F42FFD1F0 (active) print_self_dict (/upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py:203) Arguments: self: run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F1E7FC1F0 (active) compress_slam_landmark (/upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py:376) Arguments: self: Locals: slam_mode: 1 landmark_data: dict run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F07FFF1F0 (active) compress_slam_map (/upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py:439) Arguments: self: Locals: has_compress_slam_map: True slam_mode: 1 data: dict data2: dict sleep_time: 10 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F077FE1F0 (idle) wait (/usr/lib/python2.7/threading.py:340) Arguments: self: timeout: None Locals: waiter: saved_state: None _run (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:429) Arguments: self: Locals: queue: [] run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F057FA1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 40779 pub_uri: \"http://192.168.111.111:33045/\" receive_cb: resolved_topic_name: \"/obstacle_detection_all_sensors/sensor_states\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F1D7FA1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 46071 pub_uri: \"http://192.168.111.111:43381/\" receive_cb: resolved_topic_name: \"/cur_pose\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F427FC1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 1 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 36627 pub_uri: \"http://192.168.111.111:36281/\" receive_cb: resolved_topic_name: \"/map\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F06FFD1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 39983 pub_uri: \"http://192.168.111.111:37035/\" receive_cb: resolved_topic_name: \"/cold_start_status\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F1F7FE1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 39983 pub_uri: \"http://192.168.111.111:37035/\" receive_cb: resolved_topic_name: \"/error_msg\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F1CFF91F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 46071 pub_uri: \"http://192.168.111.111:43381/\" receive_cb: resolved_topic_name: \"/error_msg\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F1EFFD1F0 (active+gil) can_read (/usr/local/lib/python2.7/dist-packages/redis/connection.py:229) Arguments: self: timeout: 0 can_read (/usr/local/lib/python2.7/dist-packages/redis/connection.py:321) Arguments: self: timeout: 0 can_read (/usr/local/lib/python2.7/dist-packages/redis/connection.py:734) Arguments: self: timeout: 0 Locals: sock: get_connection (/usr/local/lib/python2.7/dist-packages/redis/connection.py:1198) Arguments: self: command_name: ? Locals: keys: () options: dict connection: execute_command (/usr/local/lib/python2.7/dist-packages/redis/client.py:898) Arguments: self: Locals: args: ? options: dict pool: command_name: ? set (/usr/local/lib/python2.7/dist-packages/redis/client.py:1801) Arguments: self: name: \"slam/scan\" value: ? ex: None px: None nx: False xx: False keepttl: False Locals: pieces: ? set (/upper_computer/upper_main/upper_computer_ros/script/ros_center/RedisConn.py:40) Arguments: self: key: \"slam/scan\" value: ? timeout: 3 slam_scan_data_callback (/upper_computer/upper_main/upper_computer_ros/script/ros_center/RosCenter_zmq.py:592) Arguments: self: msg: _invoke_callback (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/topics.py:750) Arguments: self: msg: cb: cb_args: None receive_callback (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/topics.py:769) Arguments: self: msgs: [] connection: Locals: callbacks: [(, None)] msg: cb: cb_args: None receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:799) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 37155 pub_uri: \"http://192.168.111.111:41241/\" receive_cb: resolved_topic_name: \"/scan_matched_points2\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F41FFB1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 37155 pub_uri: \"http://192.168.111.111:41241/\" receive_cb: resolved_topic_name: \"/error_msg\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F1DFFB1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 46071 pub_uri: \"http://192.168.111.111:43381/\" receive_cb: resolved_topic_name: \"/robot_mode\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F067FC1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 37155 pub_uri: \"http://192.168.111.111:41241/\" receive_cb: resolved_topic_name: \"/robot_mode\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F1FFFF1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 37155 pub_uri: \"http://192.168.111.111:41241/\" receive_cb: resolved_topic_name: \"/map_cloud\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7EE3FFF1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 40779 pub_uri: \"http://192.168.111.111:33045/\" receive_cb: resolved_topic_name: \"/error_msg\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7EE37FE1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 40779 pub_uri: \"http://192.168.111.111:33045/\" receive_cb: resolved_topic_name: \"/new_obstacles\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F867FC1F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 33389 pub_uri: \"http://192.168.111.111:36401/\" receive_cb: resolved_topic_name: \"/barcode\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: Thread 0x7F40FF91F0 (active) recv_buff (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:104) Arguments: sock: b: buff_size: 65536 receive_once (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:737) Arguments: self: Locals: sock: b: msg_queue: [] p: receive_loop (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.py:797) Arguments: self: msgs_callback: Locals: msgs: [] robust_connect_subscriber (/opt/ros/melodic/lib/python2.7/dist-packages/rospy/impl/tcpros_pubsub.py:185) Arguments: conn: dest_addr: \"192.168.111.111\" dest_port: 41197 pub_uri: \"http://192.168.111.111:35359/\" receive_cb: resolved_topic_name: \"/dsp_pos\" Locals: interval: 0.5 run (/usr/lib/python2.7/threading.py:754) Arguments: self: __bootstrap_inner (/usr/lib/python2.7/threading.py:801) Arguments: self: __bootstrap (/usr/lib/python2.7/threading.py:774) Arguments: self: "},"Python/PEP8.html":{"url":"Python/PEP8.html","title":"Python PEP8编码规范 ","keywords":"","body":"Python编码规范指南 详情参考：https://www.python.org/dev/peps/pep-0008/ 缩进 每级缩进使用4个空格。 连续行应该对齐折叠元素，无论是垂直的Python的隐式行连接圆括号内的，中括号内的，大括号内的，还是使用悬挂缩进[5]。 使用悬挂缩进应注意以下几点； 1、第一行没有参数并且使用更多的缩进来区别它本身和连续行。 风格良好： # 与分界符对齐。 foo = long_function_name(var_one, var_two, var_three, var_four) # 包括更多的缩进以区别于其他的。 def long_function_name( var_one, var_two, var_three, var_four): print(var_one) # 悬挂缩进应增加一个级别 foo = long_function_name( var_one, var_two, var_three, var_four) 风格不良： # 第一行参数禁止不使用垂直对齐 foo = long_function_name(var_one, var_two, var_three, var_four) # 当无法区分缩进时，需要进一步缩进 def long_function_name( var_one, var_two, var_three, var_four): print(var_one) 2、对于连续行，4个空格规则是可选的。 可选的： # 悬挂缩进可能缩进不是4个空格 foo = long_function_name( var_one, var_two, var_three, var_four) 3、if语句条件块足够长时需要编写多行，值得注意的是两个字符组成的关键字（例如if），加上一个空格，加上开括号为多行条件的后续行创建一个4个空格的缩进。 这可以给嵌入if内的缩进语句产生视觉冲突，这也自然被缩进4个空格。这个PEP没有明确如何（是否）进一步区分条件行和if语句内的嵌入行。 这种情况下，可以接受的选项包括，但不仅限于： # 没有额外的缩进 if (this_is_one_thing and that_is_another_thing): do_something() # 添加一行注释，这将为编辑器支持语法高亮提供一些区分。 # supporting syntax highlighting. if (this_is_one_thing and that_is_another_thing): # Since both conditions are true, we can frobnicate. do_something() # 在条件连接行，增加额外的缩进 if (this_is_one_thing and that_is_another_thing): do_something() 4、多行结构中的结束花括号/中括号/圆括号是最后一行的第一个非空白字符， 如： my_list = [ 1, 2, 3, 4, 5, 6, ] result = some_function_that_takes_arguments( 'a', 'b', 'c', 'd', 'e', 'f', ) 或者是最后一行的第一个字符， 如： my_list = [ 1, 2, 3, 4, 5, 6, ] result = some_function_that_takes_arguments( 'a', 'b', 'c', 'd', 'e', 'f', ) 制表符还是空格？ 空格是缩进方法的首选。 制表符仅用于与已经用制表符做缩进的代码保持一致。 Python3不允许混用制表符和空格来缩进。 Python2代码混用制表符和空格缩进，将被转化为只使用空格。 调用Python2命令行解释器时使用-t选项，可对代码中非法混用制表符和空格发出警告。当使用-tt选项，警告将变成错误。这些选项是高度推荐的！ 行的最大长度 限制所有行最多79个字符。 下垂的长块结构限制为更少的文本（文档字符串或注释），行的长度应该限制在72个字符。 限制编辑器窗口宽度使得并排打开多个文件成为可能，并且使用代码审查工具显示相邻列的两个版本工作正常。 绝大多数工具的默认折叠会破坏代码的可视化结构，使其更难以理解。编辑器中的窗口宽度设置为80个字符。即使该工具将在最后一列中标记 字形。一些基于网络的工具可能不会提供动态的自动换行。 有些团队强烈喜欢较长的行长度。对于代码维护完全或主要由一个团队的，可以在这个问题上达成协议，象征性的将行长度从80个字符增加到 100个字符（有效地增加最大长度到99个字符）也是可以的，提供注释和文档字符串仍是72个字符。 Python标准库采取保守做法，要求行限制到79个字符（文档字符串/注释到72个字符）。 折叠长行的首选方法是在小括号，中括号，大括号中使用Python隐式换行。长行可以在表达式外面使用小括号来变成多行。连续行使用反斜杠更好。 反斜杠有时可能仍然是合适的。例如，长的多行的with语句不能用隐式续行，可以用反斜杠： with open('/path/to/some/file/you/want/to/read') as file_1, \\ open('/path/to/some/file/being/written', 'w') as file_2: file_2.write(file_1.read()) （为进一步思考With语句的多行缩进，见前面多行if语句的讨论。） 另一个这样的例子是assert语句。 确保适当的连续行缩进。 换行应该在二元操作符的前面还是后面？ 风格良好： # 好的做法：很容易看出二元操作符和被操作对象的关系 income = (gross_wages + taxable_interest + (dividends - qualified_dividends) - ira_deduction - student_loan_interest) 风格不良： # 不好的做法：操作符和被操作符的对象是分离的 income = (gross_wages + taxable_interest + (dividends - qualified_dividends) - ira_deduction - student_loan_interest) 空行 顶级函数和类的定义之间有两行空行。 类内部的函数定义之间有一行空行。 额外的空行用来（谨慎地）分离相关的功能组。相关的行（例如：一组虚拟实现）之间不使用空行。 在函数中谨慎地使用空行来表示逻辑部分。 Python接受control-L（即^L）换页符作为空白符；许多工具把这些字符作为分页符，所以你可以使用它们为文件中的相关部分分页。 注意，一些编辑器和基于Web的代码查看器可能不能识别control-L是换页，将显示另外的字形。 源文件编码 在源文件中一直使用utf-8编码，在python2中使用ascll编码。 文件，在python2 中使用ascll编码，在python3中使用utf-8编码 导入 导入通常是单独一行，例如： 风格良好： import os import sys from subprocess import Popen, PIPE 风格不良： import sys, os 导入常常位于文件顶部，在模块注释和字符串文档之后，在模块的全局变量和常量之前。 导入应该按照以下顺序分组： 1. 标准库导入 2. 相关的第三方导入 3. 特定的本地应用/库导入 在每个导入组之间放一行空行。 把任何相关__all__规范放在导入之后。 推荐绝对导入，因为它们更易读，并且如果导入系统配置的不正确（例如当包中的一个目录结束于sys.path） 它们有更好的表现（至少给出更好的错误信息）： import mypkg.sibling from mypkg import sibling from mypkg.sibling import example 明确的相对导入可以用来接受替代绝对导入，特别是处理复杂包布局时，绝对导入过于冗长。 from . import sibling from .sibling import example 标准库代码应该避免复杂包布局并使用绝对导入。 隐式的相对导入应该永远不被使用，并且在Python3中已经移除。 从一个包含类的模块中导入类时，通常下面这样是好的写法： from myclass import MyClass from foo.bar.yourclass import YourClass 如果这种写法导致本地名字冲突，那么就这样写： import myclass import foo.bar.yourclass 并使用“myclass.MyClass”和“foo.bar.yourclass.YourClass”来访问。 避免使用通配符导入（from import *），因为它们使哪些名字出现在命名空间变得不清楚，这混淆了读者和许多自动化工具。 通配符导入有一种合理的使用情况，重新发布一个内部接口作为一个公共API的一部分（例如，重写一个纯Python实现的接口， 该接口定义从一个可选的加速器模块并且哪些定义将被重写提前并不知道）。 用这种方式重新命名，下面的有关公共和内部接口的指南仍适用。 模块级别的内置属性 模块级别的内置属性（名字有前后双下划线的），例如__all__, __author__, __version__，应该放置在模块的文档字符串后， 任意import语句之前，from __future__导入除外。Python强制要求from __future__导入必须在任何代码之前，只能在模块级文档字符串之后。 \"\"\"This is the example module. This module does stuff. \"\"\" from __future__ import barry_as_FLUFL __all__ = ['a', 'b', 'c'] __version__ = '0.1' __author__ = 'Cardinal Biggles' import os import sys 字符串引号 Python中，单引号字符串和双引号字符串是一样的。本PEP不建议如此。建议选择一条规则并坚持下去。当一个字符串包含单引号字符或双引号字符时，使用另一种字符串引号来避免字符串中使用反斜杠。这提高可读性。 三引号字符串，与PEP 257 文档字符串规范一致总是使用双引号字符。 表达式和语句中的空格 以下情况避免使用多余的空格： 紧挨着小括号，中括号或大括号。 Yes: spam(ham[1], {eggs: 2}) No: spam( ham[ 1 ], { eggs: 2 } ) 紧挨在逗号，分号或冒号前： Yes: if x == 4: print x, y; x, y = y, x No: if x == 4 : print x , y ; x , y = y , x 在切片中冒号像一个二元操作符，冒号两侧的有相等数量空格（把它看作最低优先级的操作符）。在一个扩展切片中，两个冒号必须有相等数量的空格。 例外：当一个切片参数被省略时，该空格被省略。 风格良好： ham[1:9], ham[1:9:3], ham[:9:3], ham[1::3], ham[1:9:] ham[lower:upper], ham[lower:upper:], ham[lower::step] ham[lower+offset : upper+offset] ham[: upper_fn(x) : step_fn(x)], ham[:: step_fn(x)] ham[lower + offset : upper + offset] 风格不良： ham[lower + offset:upper + offset] ham[1: 9], ham[1 :9], ham[1:9 :3] ham[lower : : upper] ham[ : upper] 紧挨着左括号之前，函数调用的参数列表的开始处： Yes: spam(1) No: spam (1) 紧挨着索引或切片开始的左括号之前： Yes: dct['key'] = lst[index] No: dct ['key'] = lst [index] 为了与另外的赋值（或其它）操作符对齐，不止一个空格。 Yes: x = 1 y = 2 long_variable = 3 No: x = 1 y = 2 long_variable = 3 其它建议 始终避免行尾空白。因为它们通常不可见，容易导致困惑：如果\\后面跟了一个空格，它就不是一个有效的续行符了。 很多编辑器不保存行尾空白，CPython项目中也设置了commit前检查以拒绝行尾空白的存在。 始终在这些二元操作符的两边放置一个空格：赋值（= ），增强赋值（+= ，-= 等）， 比较（== ， ， != ， <> ， = ，in ， not in ，is ，is not ），布尔（and ，or ，not ）。 如果使用了不同优先级的操作符，在低优先级操作符周围增加空格（一个或多个）。不要使用多于一个空格，二元运算符两侧空格数量相等。 Yes: i = i + 1 submitted += 1 x = x*2 - 1 hypot2 = x*x + y*y c = (a+b) * (a-b) No: i=i+1 submitted +=1 x = x * 2 - 1 hypot2 = x * x + y * y c = (a + b) * (a - b) 当=符号用于指示关键字参数或默认参数值时，它周围不要使用空格。 Yes: def complex(real, imag=0.0): return magic(r=real, i=imag) No: def complex(real, imag = 0.0): return magic(r = real, i = imag) 带注解的函数使用正常的冒号规则，并且在->两侧增加一个空格： Yes: def munge(input: AnyStr): ... def munge() -> AnyStr: ... No: def munge(input:AnyStr): ... def munge()->PosInt: ... 如果参数既有注释又有默认值，在等号两边增加一个空格（仅在既有注释又有默认值时才加这个空格）。 Yes: def munge(sep: AnyStr = None): ... def munge(input: AnyStr, sep: AnyStr = None, limit=1000): ... No: def munge(input: AnyStr=None): ... def munge(input: AnyStr, limit = 1000): ... 不鼓励使用复合语句（同一行有多条语句）。 风格良好: if foo == 'blah': do_blah_thing() do_one() do_two() do_three() 最好不要: if foo == 'blah': do_blah_thing() do_one(); do_two(); do_three() 尽管有时if/for/while的同一行跟一小段代码，在一个多条子句的语句中不要如此。避免折叠长行！ 最好不要: if foo == 'blah': do_blah_thing() for x in lst: total += x while t 什么时候使用尾部逗号？ 尾部逗号通常都是可选的，除了一些强制的场景，比如元组在只有一个元素的时候需要一个尾部逗号。 为了代码更加清晰，元组只有一个元素时请务必用括号括起来（语法上没有强制要求）： Yes: FILES = ('setup.cfg',) OK, but confusing: FILES = 'setup.cfg', 当尾部逗号不是必须时，如果你用了版本控制系统那么它将很有用。当列表元素、参数、导入项未来可能不断增加时，留一个尾部逗号是一个很好的选择。 通常的用法是（比如列表）每个元素独占一行，然后尾部都有逗号，在最后一个元素的下一行写闭标签。如果你的数据结构都是写在同一行的，就没有必要保留尾部逗号了。 Yes: FILES = [ 'setup.cfg', 'tox.ini', ] initialize(FILES, error=True, ) No: FILES = ['setup.cfg', 'tox.ini',] initialize(FILES, error=True,) 注释 同代码相矛盾的注释比没有注释更差。当代码修改时，始终优先更新注释！ 注释应该是完整的句子。如果注释是一个短语或句子，它的第一个单词的首字母应该大写，除非它是一个以小写字母开头的标识符（不更改标识符的情况下！）。 如果注释很短，末尾可以不加句号。注释块通常由一个或多个段落组成，这些段落由完整的句子组成，并且每个句子都应该以句号结尾。 在句尾的句号后边使用两个空格。 写英语注释时，遵循断词和空格。 非英语国家的Python程序员：请用英语书写注释，除非你120%的确定，所有看你代码的人都和你说一样的语言。 非英语国家的Python程序员：请写下你的意见，在英语中，除非你是120%肯定，代码将不会被不讲你的语言的人阅读。 注释块 注释块通常适用于一些（或全部）紧跟其后的代码，并且那些代码应使用相同级别的缩进。注释块的每行以一个#和一个空格开始（除非注释里面的文本有缩进）。 注释块内的段落之间由仅包含#的行隔开。 行内注释 谨慎地使用行内注释。 行内注释就是注释和代码在同一行，它与代码之间至少用两个空格隔开。并且它以#和一个空格开始。 如果行内注释指出的是显而易见，那么它就是不必要的。不要使用无效注释，主要是说明其目的 不要这样做： x = x + 1 # Increment x But sometimes, this is useful: x = x + 1 # Compensate for border 文档字符串 编写好的文档字符串（即“代码”）约定在PEP 257中是永存的。 为所有公共模块，函数，类和方法书写文档字符串。对非公开的方法书写文档字符串是没有必要的，但应该写注释描述这个方法是做什么的。 这些注释应该写在def行后面。 PEP 257描述了好的文档字符串约定。最重要的是，多行文档字符串以一行\"\"\"结束，例如： yes: \"\"\"Return a foobang Optional plotz says to frobnicate the bizbaz first. \"\"\" 对于只有一行的文档字符串，\"\"\"同一行上。 命名规范 使用单独的小写字母（b） 使用单独的大写字母（B） 使用小写字母（lowercase） 使用小写字母和下划线（lower_case_with_underscores） 使用大写字母（UPPERCASE） 使用大写字母和下划线（UPPER_CASE_WITH_UPPERCASE） 驼峰式写法（CamelCase）：在使用缩写的时候，大写优于小写例如HTTPServer优于HttpServer 首字母大写，然后使用下划线是一种丑陋的写法 1、避免使用的名称 在写变量的时候，尽量避免小写的l和大写字母O和大写字母I，主要原因是容易和数字中1,0相混淆。当想使用‘l’时，用‘L’代替。 2、包名和模块名 模块尽量使用简短的全部小写的名称，如果可以增加可读性那么可以使用下划线，python的包不推荐使用下划线， 但是在引用其他语言写的扩展包中可以使用下划线来表示区分 3、类名称 类名称主要遵循为CapWords约定，表示为首字母大写 4、类型变量名称 类型变量名称应该首字母大写，并且尽量短，比如：T, AnyStr, Num。对于协变量和有协变行为的变量，建议添加后缀__co或者__contra。 5、异常名 因为异常应该是类，所以类的命名规则在这里也同样适用。然而，异常名（如果这个异常确实是一个错误）应该使用后缀“Error”。 6、全局变量名 （希望这些变量是在一个模块内使用。）这些规则和那些有关函数的规则是相同的。 模块设计为通过from M import *来使用，应使用__all__机制防止导出全局变量，或使用加前缀的旧规则，为全局变量加下划线（可能你像表明这些全局变量是“非公开模块”）。 7、函数名 函数名应该是小写字母，必要时单词用下划线分开以提高可读性。 混合大小写仅用于这种风格已经占主导地位的上下文（例如threading.py），以保持向后兼容性。 8、函数和方法参数 使用self做实例化方法的第一个参数。 使用cls做类方法的第一个参数。 如果函数的参数名与保留关键字冲突，最好是为参数名添加一个后置下划线而不是使用缩写或拼写错误。 因此class_ 比clss好。（也许使用同义词来避免更好。）。 9、常量 常量通常定义于模块级别并且所有的字母都是大写，单词用下划线分开。例如MAX_OVERFLOW和TOTAL。 "},"Python/Python语言基础/00-初识Python.html":{"url":"Python/Python语言基础/00-初识Python.html","title":"初识Python","keywords":"","body":"datetime:2019/6/29 9:04 author:nzb 初识Python Python简介 Python的历史 1989年圣诞节：Guido von Rossum开始写Python语言的编译器。 1991年2月：第一个Python编译器（同时也是解释器）诞生，它是用C语言实现的（后面又出现了Java和C#实现的版本Jython和IronPython，以及PyPy、Brython、Pyston等其他实现），可以调用C语言的库函数。在最早的版本中，Python已经提供了对“类”，“函数”，“异常处理”等构造块的支持，同时提供了“列表”和“字典”等核心数据类型，同时支持以模块为基础来构造应用程序。 1994年1月：Python 1.0正式发布。 2000年10月16日：Python 2.0发布，增加了实现完整的垃圾回收)，提供了对Unicode的支持。与此同时，Python的整个开发过程更加透明，社区对开发进度的影响逐渐扩大，生态圈开始慢慢形成。 2008年12月3日：Python 3.0发布，它并不完全兼容之前的Python代码，不过因为目前还有不少公司在项目和运维中使用Python 2.x版本，所以Python 3.x的很多新特性后来也被移植到Python 2.6/2.7版本中。 目前我们使用的Python 3.7.x的版本是在2018年发布的，Python的版本号分为三段，形如A.B.C。其中A表示大版本号，一般当整体重写，或出现不向后兼容的改变时，增加A；B表示功能更新，出现新功能时增加B；C表示小的改动（如修复了某个Bug），只要有修改就增加C。如果对Python的历史感兴趣，可以查看一篇名为《Python简史》的博文。 Python的优缺点 Python的优点很多，简单的可以总结为以下几点。 简单和明确，做一件事只有一种方法。 学习曲线低，跟其他很多语言相比，Python更容易上手。 开放源代码，拥有强大的社区和生态圈。 解释型语言，天生具有平台可移植性。 支持两种主流的编程范式（面向对象编程和函数式编程）都提供了支持。 可扩展性和可嵌入性，可以调用C/C++代码，也可以在C/C++中调用Python。 代码规范程度高，可读性强，适合有代码洁癖和强迫症的人群。 Python的缺点主要集中在以下几点。 执行效率稍低，因此计算密集型任务可以由C/C++编写。 代码无法加密，但是现在很多公司都不销售卖软件而是销售服务，这个问题会被淡化。 在开发时可以选择的框架太多（如Web框架就有100多个），有选择的地方就有错误。 Python的应用领域 目前Python在Web应用开发、云基础设施、DevOps、网络爬虫开发、数据分析挖掘、机器学习等领域都有着广泛的应用，因此也产生了Web后端开发、数据接口开发、自动化运维、自动化测试、科学计算和可视化、数据分析、量化交易、机器人开发、图像识别和处理等一系列的职位。 搭建编程环境 Windows环境 可以在Python官方网站下载到Python的Windows安装程序（exe文件），需要注意的是如果在Windows 7环境下安装Python 3.x，需要先安装Service Pack 1补丁包（可以通过一些工具软件自动安装系统补丁的功能来安装），安装过程建议勾选“Add Python 3.6 to PATH”（将Python 3.6添加到PATH环境变量）并选择自定义安装，在设置“Optional Features”界面最好将“pip”、“tcl/tk”、“Python test suite”等项全部勾选上。强烈建议使用自定义的安装路径并保证路径中没有中文。安装完成会看到“Setup was successful”的提示。如果稍后运行Python程序时，出现因为缺失一些动态链接库文件而导致Python解释器无法工作的问题，可以按照后面说的方法加以解决。如果系统显示api-ms-win-crt*.dll文件缺失，可以参照《api-ms-win-crt*.dll缺失原因分析和解决方法》一文讲解的方法进行处理或者直接在微软官网下载Visual C++ Redistributable for Visual Studio 2015文件进行修复；如果是因为更新Windows的DirectX之后导致某些动态链接库文件缺失问题，可以下载一个DirectX修复工具进行修复。 Linux环境 Linux环境自带了Python 2.x版本，但是如果要更新到3.x的版本，可以在Python的官方网站下载Python的源代码并通过源代码构建安装的方式进行安装，具体的步骤如下所示。 安装依赖库（因为没有这些依赖库可能在源代码构件安装时因为缺失底层依赖库而失败）。 yum -y install wget gcc zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel 下载Python源代码并解压缩到指定目录。 wget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz xz -d Python-3.7.3.tar.xz tar -xvf Python-3.7.3.tar 切换至Python源代码目录并执行下面的命令进行配置和安装。 cd Python-3.7.3 ./configure --prefix=/usr/local/python37 --enable-optimizations make && make install 修改用户主目录下名为.bash_profile的文件，配置PATH环境变量并使其生效。 cd ~ vim .bash_profile # ... 此处省略上面的代码 ... export PATH=$PATH:/usr/local/python37/bin # ... 此处省略下面的代码 ... source .bash_profile macOS环境 macOS也自带了Python 2.x版本，可以通过Python的官方网站提供的安装文件（pkg文件）安装Python 3.x的版本。默认安装完成后，可以通过在终端执行python命令来启动2.x版本的Python解释器，可以通过执行python3命令来启动3.x版本的Python解释器。 从终端运行Python程序 确认Python的版本 可以Windows的命令行提示符中键入下面的命令。 python --version 或者是在Linux或macOS系统的终端中键入下面的命令。 python3 --version 当然也可以先输入python或python3进入交互式环境，再执行以下的代码检查Python的版本。 import sys print(sys.version_info) print(sys.version) 编写Python源代码 可以用文本编辑工具（推荐使用Sublime、TextMate、Visual Studio Code等高级文本编辑工具）编写Python源代码并用py作为后缀名保存该文件，代码内容如下所示。 print('hello, world!') 运行程序 切换到源代码所在的目录并执行下面的命令，看看屏幕上是否输出了\"hello, world!\"。 python hello.py 或 python3 hello.py 代码中的注释 注释是编程语言的一个重要组成部分，用于在源代码中解释代码的作用从而增强程序的可读性和可维护性，当然也可以将源代码中不需要参与运行的代码段通过注释来去掉，这一点在调试程序的时候经常用到。注释在随源代码进入预处理器或编译时会被移除，不会在目标代码中保留也不会影响程序的执行结果。 单行注释 - 以#和空格开头的部分 多行注释 - 三个引号开头，三个引号结尾 \"\"\" 第一个Python程序 - hello, world! 向伟大的Dennis M. Ritchie先生致敬 Version: 0.1 Author: 骆昊 \"\"\" print('hello, world!') # print(\"你好,世界！\") print('你好', '世界') print('hello', 'world', sep=', ', end='!') print('goodbye, world', end='!\\n') 其他工具介绍 IDLE - 自带的集成开发工具 IDLE是安装Python环境时自带的集成开发工具，如下图所示。但是由于IDLE的用户体验并不是那么好所以很少在实际开发中被采用。 IPython - 更好的交互式编程工具 IPython是一种基于Python的交互式解释器。相较于原生的Python交互式环境，IPython提供了更为强大的编辑和交互功能。可以通过Python的包管理工具pip安装IPython和Jupyter，具体的操作如下所示。 pip install ipython 或 pip3 install ipython 安装成功后，可以通过下面的ipython命令启动IPython，如下图所示。 当然，我们也可以通过安装Jupyter工具并运行名为notebook的程序在浏览器窗口中进行交互式代码编写操作。 pip install jupyter 或 pip3 intall jupyter 然后执行下面的命令： jupyter notebook Sublime - 文本编辑神器 首先可以通过官方网站下载安装程序安装Sublime 3或Sublime 2。 安装包管理工具。 通过快捷键Ctrl+`或者在View菜单中选择Show Console打开控制台，输入下面的代码。 Sublime 3 import urllib.request,os;pf='Package Control.sublime-package';ipp=sublime.installed_packages_path();urllib.request.install_opener(urllib.request.build_opener(urllib.request.ProxyHandler()));open(os.path.join(ipp,pf),'wb').write(urllib.request.urlopen('http://sublime.wbond.net/'+pf.replace(' ','%20')).read()) Sublime 2 import urllib2,os;pf='Package Control.sublime-package';ipp=sublime.installed_packages_path();os.makedirs(ipp)ifnotos.path.exists(ipp)elseNone;urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler()));open(os.path.join(ipp,pf),'wb').write(urllib2.urlopen('http://sublime.wbond.net/'+pf.replace(' ','%20')).read());print('Please restart Sublime Text to finish installation') 手动安装浏览器输入 https://sublime.wbond.net/Package%20Control.sublime-package 下载这个文件 下载好以后，打开sublime text，选择菜单Preferences->Browse Packages... 打开安装目录 此时会进入到一个叫做Packages的目录下，点击进入上一层目录Sublime Text3，在此目录下有一个文件夹叫做Installed Packages，把刚才下载的文件放到这里就可以了。然后重启sublime text3，观察Preferences菜单最下边是否有Package Settings 和Package Control两个选项，如果有，则代表安装成功了。 安装插件。通过Preference菜单的Package Control或快捷键Ctrl+Shift+P打开命令面板，在面板中输入Install Package就可以找到安装插件的工具，然后再查找需要的插件。我们推荐大家安装以下几个插件： SublimeCodeIntel - 代码自动补全工具插件。 Emmet - 前端开发代码模板插件。 Git - 版本控制工具插件。 Python PEP8 Autoformat - PEP8规范自动格式化插件。 ConvertToUTF8 - 将本地编码转换为UTF-8。 说明：事实上Visual Studio Code可能是更好的选择，它不用花钱并提供了更为完整和强大的功能。 PyCharm - Python开发神器 PyCharm的安装、配置和使用在《玩转PyCharm》进行了介绍，有兴趣的读者可以选择阅读。 练习 在Python交互环境中查看下面的代码结果，并试着将这些内容翻译成中文。 import this 说明：当前键入上面的命令后会在交互式环境中看到如下所示的输出，这段内容被称为“Python之禅”，里面讲述的道理不仅仅适用于Python，也适用于其他编程语言。 Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! 学习使用turtle在屏幕上绘制图形。 说明：turtle是Python内置的一个非常有趣的模块，特别适用于让小朋友体会什么是编程，它最早是Logo语言的一部分，Logo语言是Wally Feurzig和Seymour Papert在1966发明的编程语言. import turtle turtle.pensize(4) turtle.pencolor('red') turtle.forward(100) turtle.right(90) turtle.forward(100) turtle.right(90) turtle.forward(100) turtle.right(90) turtle.forward(100) turtle.mainloop() "},"Python/Python语言基础/01-语言元素.html":{"url":"Python/Python语言基础/01-语言元素.html","title":"语言元素","keywords":"","body":"datetime:2019/5/14 9:38 author:nzb 语言元素 指令和程序 计算机的硬件系统通常由五大部件构成，包括：运算器、控制器、存储器、输入设备和输出设备。其中，运算器和控制器放在一起就是我们通常所说的中央处理器，它的功能是执行各种运算和控制指令以及处理计算机软件中的数据。我们通常所说的程序实际上就是指令的集合，我们程序就是将一系列的指令按照某种方式组织到一起，然后通过这些指令去控制计算机做我们想让它做的事情。今天我们使用的计算机虽然器件做工越来越精密，处理能力越来越强大，但究其本质来说仍然属于“冯·诺依曼结构”的计算机。“冯·诺依曼结构”有两个关键点，一是指出要将存储设备与中央处理器分开，二是提出了将数据以二进制方式编码。二进制是一种“逢二进一”的计数法，跟我们人类使用的“逢十进一”的计数法没有实质性的区别，人类因为有十根手指所以使用了十进制（因为在数数时十根手指用完之后就只能进位了，当然凡事都有例外，玛雅人可能是因为长年光着脚的原因把脚趾头也算上了，于是他们使用了二十进制的计数法，在这种计数法的指导下玛雅人的历法就与我们平常使用的历法不一样，而按照玛雅人的历法，2012年是上一个所谓的“太阳纪”的最后一年，而2013年则是新的“太阳纪”的开始，后来这件事情被以讹传讹的方式误传为”2012年是玛雅人预言的世界末日“这种荒诞的说法，今天我们可以大胆的猜测，玛雅文明之所以发展缓慢估计也与使用了二十进制有关）。对于计算机来说，二进制在物理器件上来说是最容易实现的（高电压表示1，低电压表示0），于是在“冯·诺依曼结构”的计算机都使用了二进制。虽然我们并不需要每个程序员都能够使用二进制的思维方式来工作，但是了解二进制以及它与我们生活中的十进制之间的转换关系，以及二进制与八进制和十六进制的转换关系还是有必要的。如果你对这一点不熟悉，可以自行使用维基百科或者百度百科科普一下。 变量和类型 在程序设计中，变量是一种存储数据的载体。计算机中的变量是实际存在的数据或者说是存储器中存储数据的一块内存空间，变量的值可以被读取和修改，这是所有计算和控制的基础。计算机能处理的数据有很多中类型，除了数值之外还可以处理文本、图形、音频、视频等各种各样的数据，那么不同的数据就需要定义不同的存储类型。Python中的数据类型很多，而且也允许我们自定义新的数据类型（这一点在后面会讲到），我们先介绍几种常用的数据类型。 整型：Python中可以处理任意大小的整数（Python 2.x中有int和long两种类型的整数，但这种区分对Python来说意义不大，因此在Python 3.x中整数只有int这一种了），而且支持二进制（如0b100，换算成十进制是4）、八进制（如0o100，换算成十进制是64）、十进制（100）和十六进制（0x100，换算成十进制是256）的表示法。 浮点型：浮点数也就是小数，之所以称为浮点数，是因为按照科学记数法表示时，一个浮点数的小数点位置是可变的，浮点数除了数学写法（如123.456）之外还支持科学计数法（如1.23456e2）。 字符串型：字符串是以单引号或双引号括起来的任意文本，比如'hello'和\"hello\",字符串还有原始字符串表示法、字节字符串表示法、Unicode字符串表示法，而且可以书写成多行的形式（用三个单引号或三个双引号开头，三个单引号或三个双引号结尾）。 布尔型：布尔值只有True、False两种值，要么是True，要么是False，在Python中，可以直接用True、False表示布尔值（请注意大小写），也可以通过布尔运算计算出来（例如3 会产生布尔值True，而2 == 1会产生布尔值False）。 复数型：形如3+5j，跟数学上的复数表示一样，唯一不同的是虚部的i换成了j。 变量命名 需要符合PEP8要求 在对变量类型进行转换时可以使用Python的内置函数（准确的说下面列出的并不是真正意义上的函数，而是后面我们要讲到的创建对象的构造方法）。 int()：将一个数值或字符串转换成整数，可以指定进制。 float()：将一个字符串转换成浮点数。 str()：将指定的对象转换成字符串形式，可以指定编码。 chr()：将整数转换成该编码对应的字符串（一个字符）。 ord()：将字符串（一个字符）转换成对应的编码（整数）。 运算符 Python支持多种运算符，下表大致按照优先级从高到低的顺序列出了所有的运算符，我们会陆续使用到它们。 运算符 描述 [] [:] 下标，切片 ** 指数 ~ + - 按位取反, 正负号 * / % // 乘，除，模，整除 + - 加，减 >> 右移，左移 & 按位与 ^ ` ` 按位异或，按位或 > >= 小于等于，小于，大于，大于等于 == != 等于，不等于 is is not 身份运算符 in not in 成员运算符 not or and 逻辑运算符 = += -= *= /= %= //= **= &= ` =`^= >>= （复合）赋值运算符 说明：在实际开发中，如果搞不清楚优先级可以使用括号来确保运算的执行顺序。 练习 练习1：华氏温度转摄氏温度。 \"\"\" 将华氏温度转换为摄氏温度 F = 1.8C + 32 \"\"\" f = float(input('请输入华氏温度: ')) c = (f - 32) / 1.8 print('%.1f华氏度 = %.1f摄氏度' % (f, c)) 练习2：输入圆的半径计算计算周长和面积。 \"\"\" 输入半径计算圆的周长和面积 \"\"\" import math radius = float(input('请输入圆的半径: ')) perimeter = 2 * math.pi * radius area = math.pi * radius * radius print('周长: %.2f' % perimeter) print('面积: %.2f' % area) 练习3：输入年份判断是不是闰年。 \"\"\" 输入年份 如果是闰年输出True 否则输出False \"\"\" year = int(input('请输入年份: ')) # 如果代码太长写成一行不便于阅读 可以使用\\或()折行 is_leap = (year % 4 == 0 and year % 100 != 0 or year % 400 == 0) print(is_leap) "},"Python/Python语言基础/02-分支结构.html":{"url":"Python/Python语言基础/02-分支结构.html","title":"分支结构","keywords":"","body":"datetime:2019/5/14 9:38 author:nzb 分支结构 分支结构的应用场景 迄今为止，我们写的Python代码都是一条一条语句顺序执行，这种结构的代码我们称之为顺序结构。然而仅有顺序结构并不能解决所有的问题，比如我们设计一个游戏，游戏第一关的通关条件是玩家获得1000分，那么在完成本局游戏后我们要根据玩家得到分数来决定究竟是进入第二关还是告诉玩家“Game Over”，这里就会产生两个分支，而且这两个分支只有一个会被执行，这就是程序中分支结构。类似的场景还有很多，给大家一分钟的时间，你应该可以想到至少5个以上这样的例子，赶紧试一试。 if语句的使用 在Python中，要构造分支结构可以使用if、elif和else关键字。所谓关键字就是有特殊含义的单词，像if和else就是专门用于构造分支结构的关键字，很显然你不能够使用它作为变量名（事实上，用作其他的标识符也是不可以）。下面的例子中演示了如何构造一个分支结构。 \"\"\" 用户身份验证 \"\"\" username = input('请输入用户名: ') password = input('请输入口令: ') # 如果希望输入口令时 终端中没有回显 可以使用getpass模块的getpass函数 # import getpass # password = getpass.getpass('请输入口令: ') if username == 'admin' and password == '123456': print('身份验证成功!') else: print('身份验证失败!') 唯一需要说明的是和C/C++、Java等语言不同，Python中没有用花括号来构造代码块而是使用了缩进的方式来设置代码的层次结构，如果if条件成立的情况下需要执行多条语句，只要保持多条语句具有相同的缩进就可以了，换句话说连续的代码如果又保持了相同的缩进那么它们属于同一个代码块，相当于是一个执行的整体。 当然如果要构造出更多的分支，可以使用if…elif…else…结构，例如下面的分段函数求值。 \"\"\" 分段函数求值 3x - 5 (x > 1) f(x) = x + 2 (-1 1: y = 3 * x - 5 elif x >= -1: y = x + 2 else: y = 5 * x + 3 print('f(%.2f) = %.2f' % (x, y)) 当然根据实际开发的需要，分支结构是可以嵌套的，例如判断是否通关以后还要根据你获得的宝物或者道具的数量对你的表现给出等级（比如点亮两颗或三颗星星），那么我们就需要在if的内部构造出一个新的分支结构，同理elif和else中也可以再构造新的分支，我们称之为嵌套的分支结构，也就是说上面的代码也可以写成下面的样子。 \"\"\" 分段函数求值 3x - 5 (x > 1) f(x) = x + 2 (-1 1: y = 3 * x - 5 else: if x >= -1: y = x + 2 else: y = 5 * x + 3 print('f(%.2f) = %.2f' % (x, y)) 说明：大家可以自己感受一下这两种写法到底是哪一种更好。在之前我们提到的Python之禅中有这么一句话“Flat is better than nested.”，之所以提出这个观点是因为嵌套结构的嵌套层次多了之后会严重的影响代码的可读性，如果可以使用扁平化的结构就不要去用嵌套，因此之前的写法是更好的做法。 练习 练习1：英制单位与公制单位互换 \"\"\" 英制单位英寸和公制单位厘米互换 \"\"\" value = float(input('请输入长度: ')) unit = input('请输入单位: ') if unit == 'in' or unit == '英寸': print('%f英寸 = %f厘米' % (value, value * 2.54)) elif unit == 'cm' or unit == '厘米': print('%f厘米 = %f英寸' % (value, value / 2.54)) else: print('请输入有效的单位') 练习2：掷骰子决定做什么 \"\"\" 掷骰子决定做什么事情 \"\"\" from random import randint face = randint(1, 6) if face == 1: result = '唱首歌' elif face == 2: result = '跳个舞' elif face == 3: result = '学狗叫' elif face == 4: result = '做俯卧撑' elif face == 5: result = '念绕口令' else: result = '讲冷笑话' print(result) 说明：上面的代码中使用了random模块的randint函数生成指定范围的随机数来模拟掷骰子。 练习3：百分制成绩转等级制 \"\"\" 百分制成绩转等级制成绩 90分以上 --> A 80分~89分 --> B 70分~79分 --> C 60分~69分 --> D 60分以下 --> E \"\"\" score = float(input('请输入成绩: ')) if score >= 90: grade = 'A' elif score >= 80: grade = 'B' elif score >= 70: grade = 'C' elif score >= 60: grade = 'D' else: grade = 'E' print('对应的等级是:', grade) 练习4：输入三条边长如果能构成三角形就计算周长和面积 \"\"\" 判断输入的边长能否构成三角形 如果能则计算出三角形的周长和面积 \"\"\" import math a = float(input('a = ')) b = float(input('b = ')) c = float(input('c = ')) if a + b > c and a + c > b and b + c > a: print('周长: %f' % (a + b + c)) p = (a + b + c) / 2 area = math.sqrt(p * (p - a) * (p - b) * (p - c)) print('面积: %f' % (area)) else: print('不能构成三角形') 说明：上面的代码中使用了math模块的sqrt函数来计算平方根。用边长计算三角形面积的公式叫做海伦公式。 练习5：个人所得税计算器。 \"\"\" 输入月收入和五险一金计算个人所得税 \"\"\" salary = float(input('本月收入: ')) insurance = float(input('五险一金: ')) diff = salary - insurance - 3500 if diff 说明：上面的代码中使用了Python内置的abs()函数取绝对值来处理-0的问题。 "},"Python/Python语言基础/03-循环结构.html":{"url":"Python/Python语言基础/03-循环结构.html","title":"循环结构","keywords":"","body":"datetime:2019/5/14 9:49 author:nzb 循环结构 循环结构的应用场景 如果在程序中我们需要重复的执行某条或某些指令，例如用程序控制机器人踢足球，如果机器人持球而且还没有进入射门范围，那么我们就要一直发出让机器人向球门方向奔跑的指令。当然你可能已经注意到了，刚才的描述中其实不仅仅有需要重复的动作，还有我们上一个章节讲到的分支结构。再举一个简单的例子，比如在我们的程序中要实现每隔1秒中在屏幕上打印一个\"hello, world\"这样的字符串并持续一个小时，我们肯定不能够将print('hello, world')这句代码写上3600遍，如果真的需要这样做那么编程的工作就太无聊了。因此，我们需要了解一下循环结构，有了循环结构我们就可以轻松的控制某件事或者某些事重复、重复、再重复的发生。在Python中构造循环结构有两种做法，一种是for-in循环，一种是while循环。 for-in循环 如果明确的知道循环执行的次数或者是要对一个容器进行迭代（后面会讲到），那么我们推荐使用for-in循环，例如下面代码中计算$\\sum_{n=1}^{100}n$。 \"\"\" 用for循环实现1~100求和 \"\"\" sum = 0 for x in range(101): sum += x print(sum) 需要说明的是上面代码中的range类型，range可以用来产生一个不变的数值序列，而且这个序列通常都是用在循环中的，例如： range(101)可以产生一个0到100的整数序列。 range(1, 100)可以产生一个1到99的整数序列。 range(1, 100, 2)可以产生一个1到99的奇数序列，其中的2是步长，即数值序列的增量。 知道了这一点，我们可以用下面的代码来实现1~100之间的偶数求和。 \"\"\" 用for循环实现1~100之间的偶数求和 \"\"\" sum = 0 for x in range(2, 101, 2): sum += x print(sum) 也可以通过在循环中使用分支结构的方式来实现相同的功能，代码如下所示。 \"\"\" 用for循环实现1~100之间的偶数求和 \"\"\" sum = 0 for x in range(1, 101): if x % 2 == 0: sum += x print(sum) while循环 如果要构造不知道具体循环次数的循环结构，我们推荐使用while循环，while循环通过一个能够产生或转换出bool值的表达式来控制循环，表达式的值为True循环继续，表达式的值为False循环结束。下面我们通过一个“猜数字”的小游戏（计算机出一个1~100之间的随机数，人输入自己猜的数字，计算机给出对应的提示信息，直到人猜出计算机出的数字）来看看如何使用while循环。 \"\"\" 猜数字游戏 计算机出一个1~100之间的随机数由人来猜 计算机根据人猜的数字分别给出提示大一点/小一点/猜对了 \"\"\" import random answer = random.randint(1, 100) counter = 0 while True: counter += 1 number = int(input('请输入: ')) if number answer: print('小一点') else: print('恭喜你猜对了!') break print('你总共猜了%d次' % counter) if counter > 7: print('你的智商余额明显不足') 说明：上面的代码中使用了break关键字来提前终止循环，需要注意的是break只能终止它所在的那个循环，这一点在使用嵌套的循环结构（下面会讲到）需要引起注意。除了break之外，还有另一个关键字是continue，它可以用来放弃本次循环后续的代码直接让循环进入下一轮。 和分支结构一样，循环结构也是可以嵌套的，也就是说在循环中还可以构造循环结构。下面的例子演示了如何通过嵌套的循环来输出一个九九乘法表。 \"\"\" 输出乘法口诀表(九九表) \"\"\" for i in range(1, 10): for j in range(1, i + 1): print('%d*%d=%d' % (i, j, i * j), end='\\t') print() 练习 练习1：输入一个数判断是不是素数。 \"\"\" 输入一个正整数判断它是不是素数 \"\"\" from math import sqrt num = int(input('请输入一个正整数: ')) end = int(sqrt(num)) is_prime = True for x in range(2, end + 1): if num % x == 0: is_prime = False break if is_prime and num != 1: print('%d是素数' % num) else: print('%d不是素数' % num) 练习2：输入两个正整数，计算最大公约数和最小公倍数。 \"\"\" 输入两个正整数计算最大公约数和最小公倍数 \"\"\" x = int(input('x = ')) y = int(input('y = ')) if x > y: x, y = y, x for factor in range(x, 0, -1): if x % factor == 0 and y % factor == 0: print('%d和%d的最大公约数是%d' % (x, y, factor)) print('%d和%d的最小公倍数是%d' % (x, y, x * y // factor)) break 练习3：打印三角形图案。 \"\"\" 打印各种三角形图案 * ** *** **** ***** * ** *** **** ***** * *** ***** ******* ********* \"\"\" row = int(input('请输入行数: ')) for i in range(row): for _ in range(i + 1): print('*', end='') print() for i in range(row): for j in range(row): if j "},"Python/Python语言基础/04-练习.html":{"url":"Python/Python语言基础/04-练习.html","title":"构造程序逻辑","keywords":"","body":"datetime:2019/5/14 9:51 author:nzb 练习 练习清单 寻找“水仙花数”。 寻找“完美数”。 “百钱百鸡”问题。 生成“斐波拉切数列”。 Craps赌博游戏。 "},"Python/Python语言基础/05-函数和模块的使用.html":{"url":"Python/Python语言基础/05-函数和模块的使用.html","title":"函数和模块的使用","keywords":"","body":"datetime:2019/5/14 9:54 author:nzb 函数和模块的使用 在讲解本章节的内容之前，我们先来研究一道数学题，请说出下面的方程有多少组正整数解。 x_1 + x_2 + x_3 + x_4 = 8 事实上，上面的问题等同于将8个苹果分成四组每组至少一个苹果有多少种方案。想到这一点问题的答案就呼之欲出了。 C_M^N =\\frac{M!}{N!(M-N)!}, \\text{(M=7, N=3)} 可以用Python的程序来计算出这个值，代码如下所示。 \"\"\" 输入M和N计算C(M,N) \"\"\" m = int(input('m = ')) n = int(input('n = ')) fm = 1 for num in range(1, m + 1): fm *= num fn = 1 for num in range(1, n + 1): fn *= num fmn = 1 for num in range(1, m - n + 1): fmn *= num print(fm // fn // fmn) 函数的作用 不知道大家是否注意到，在上面的代码中，我们做了3次求阶乘，这样的代码实际上就是重复代码。编程大师Martin Fowler先生曾经说过：“代码有很多种坏味道，重复是最坏的一种！”，要写出高质量的代码首先要解决的就是重复代码的问题。对于上面的代码来说，我们可以将计算阶乘的功能封装到一个称之为“函数”的功能模块中，在需要计算阶乘的地方，我们只需要“调用”这个“函数”就可以了。 定义函数 在Python中可以使用def关键字来定义函数，和变量一样每个函数也有一个响亮的名字，而且命名规则跟变量的命名规则是一致的。在函数名后面的圆括号中可以放置传递给函数的参数，这一点和数学上的函数非常相似，程序中函数的参数就相当于是数学上说的函数的自变量，而函数执行完成后我们可以通过return关键字来返回一个值，这相当于数学上说的函数的因变量。 在了解了如何定义函数后，我们可以对上面的代码进行重构，所谓重构就是在不影响代码执行结果的前提下对代码的结构进行调整，重构之后的代码如下所示。 def factorial(num): \"\"\" 求阶乘 :param num: 非负整数 :return: num的阶乘 \"\"\" result = 1 for n in range(1, num + 1): result *= n return result m = int(input('m = ')) n = int(input('n = ')) # 当需要计算阶乘的时候不用再写循环求阶乘而是直接调用已经定义好的函数 print(factorial(m) // factorial(n) // factorial(m - n)) 说明：Python的math模块中其实已经有一个factorial函数了，事实上要计算阶乘可以直接使用这个现成的函数而不用自己定义。下面例子中的某些函数其实Python中也是内置了，我们这里是为了讲解函数的定义和使用才把它们又实现了一遍，实际开发中不建议做这种低级的重复性的工作。 函数的参数 函数是绝大多数编程语言中都支持的一个代码的“构建块”，但是Python中的函数与其他语言中的函数还是有很多不太相同的地方，其中一个显著的区别就是Python对函数参数的处理。在Python中，函数的参数可以有默认值，也支持使用可变参数，所以Python并不需要像其他语言一样支持函数的重载，因为我们在定义一个函数的时候可以让它有多种不同的使用方式，下面是两个小例子。 from random import randint def roll_dice(n=2): \"\"\" 摇色子 :param n: 色子的个数 :return: n颗色子点数之和 \"\"\" total = 0 for _ in range(n): total += randint(1, 6) return total def add(a=0, b=0, c=0): return a + b + c # 如果没有指定参数那么使用默认值摇两颗色子 print(roll_dice()) # 摇三颗色子 print(roll_dice(3)) print(add()) print(add(1)) print(add(1, 2)) print(add(1, 2, 3)) # 传递参数时可以不按照设定的顺序进行传递 print(add(c=50, a=100, b=200)) 我们给上面两个函数的参数都设定了默认值，这也就意味着如果在调用函数的时候如果没有传入对应参数的值时将使用该参数的默认值，所以在上面的代码中我们可以用各种不同的方式去调用add函数，这跟其他很多语言中函数重载的效果是一致的。 其实上面的add函数还有更好的实现方案，因为我们可能会对0个或多个参数进行加法运算，而具体有多少个参数是由调用者来决定，我们作为函数的设计者对这一点是一无所知的，因此在不确定参数个数的时候，我们可以使用可变参数，代码如下所示。 # 在参数名前面的*表示args是一个可变参数 # 即在调用add函数时可以传入0个或多个参数 def add(*args): total = 0 for val in args: total += val return total print(add()) print(add(1)) print(add(1, 2)) print(add(1, 2, 3)) print(add(1, 3, 5, 7, 9)) 用模块管理函数 对于任何一种编程语言来说，给变量、函数这样的标识符起名字都是一个让人头疼的问题，因为我们会遇到命名冲突这种尴尬的情况。最简单的场景就是在同一个.py文件中定义了两个同名函数，由于Python没有函数重载的概念，那么后面的定义会覆盖之前的定义，也就意味着两个函数同名函数实际上只有一个是存在的。 def foo(): print('hello, world!') def foo(): print('goodbye, world!') # 下面的代码会输出什么呢？ foo() 当然上面的这种情况我们很容易就能避免，但是如果项目是由多人协作进行团队开发的时候，团队中可能有多个程序员都定义了名为foo的函数，那么怎么解决这种命名冲突呢？答案其实很简单，Python中每个文件就代表了一个模块（module），我们在不同的模块中可以有同名的函数，在使用函数的时候我们通过import关键字导入指定的模块就可以区分到底要使用的是哪个模块中的foo函数，代码如下所示。 module1.py def foo(): print('hello, world!') module2.py def foo(): print('goodbye, world!') test.py from module1 import foo # 输出hello, world! foo() from module2 import foo # 输出goodbye, world! foo() 也可以按照如下所示的方式来区分到底要使用哪一个foo函数。 test.py import module1 as m1 import module2 as m2 m1.foo() m2.foo() 但是如果将代码写成了下面的样子，那么程序中调用的是最后导入的那个foo，因为后导入的foo覆盖了之前导入的foo。 test.py from module1 import foo from module2 import foo # 输出goodbye, world! foo() test.py from module2 import foo from module1 import foo # 输出hello, world! foo() 需要说明的是，如果我们导入的模块除了定义函数之外还中有可以执行代码，那么Python解释器在导入这个模块时就会执行这些代码，事实上我们可能并不希望如此，因此如果我们在模块中编写了执行代码，最好是将这些执行代码放入如下所示的条件中，这样的话除非直接运行该模块，if条件下的这些代码是不会执行的，因为只有直接执行的模块的名字才是“__main__”。 module3.py def foo(): pass def bar(): pass # __name__是Python中一个隐含的变量它代表了模块的名字 # 只有被Python解释器直接执行的模块的名字才是__main__ if __name__ == '__main__': print('call foo()') foo() print('call bar()') bar() test.py import module3 # 导入module3时 不会执行模块中if条件成立时的代码 因为模块的名字是module3而不是__main__ 练习 练习1：实现计算求最大公约数和最小公倍数的函数。 def gcd(x, y): (x, y) = (y, x) if x > y else (x, y) for factor in range(x, 0, -1): if x % factor == 0 and y % factor == 0: return factor def lcm(x, y): return x * y // gcd(x, y) 练习2：实现判断一个数是不是回文数的函数。 def is_palindrome(num): temp = num total = 0 while temp > 0: total = total * 10 + temp % 10 temp //= 10 return total == num 练习3：实现判断一个数是不是素数的函数。 def is_prime(num): for factor in range(2, num): if num % factor == 0: return False return True if num != 1 else False 练习4：写一个程序判断输入的正整数是不是回文素数。 if __name__ == '__main__': num = int(input('请输入正整数: ')) if is_palindrome(num) and is_prime(num): print('%d是回文素数' % num) 通过上面的程序可以看出，当我们将代码中重复出现的和相对独立的功能抽取成函数后，我们可以组合使用这些函数来解决更为复杂的问题，这也是我们为什么要定义和使用函数的一个非常重要的原因。 最后，我们来讨论一下Python中有关变量作用域的问题。 def foo(): b = 'hello' def bar(): # Python中可以在函数内部再定义函数 c = True print(a) print(b) print(c) bar() # print(c) # NameError: name 'c' is not defined if __name__ == '__main__': a = 100 # print(b) # NameError: name 'b' is not defined foo() 上面的代码能够顺利的执行并且打印出100和“hello”，但我们注意到了，在bar函数的内部并没有定义a和b两个变量，那么a和b是从哪里来的。我们在上面代码的if分支中定义了一个变量a，这是一个全局变量（global variable），属于全局作用域，因为它没有定义在任何一个函数中。在上面的foo函数中我们定义了变量b，这是一个定义在函数中的局部变量（local variable），属于局部作用域，在foo函数的外部并不能访问到它；但对于foo函数内部的bar函数来说，变量b属于嵌套作用域，在bar函数中我们是可以访问到它的。bar函数中的变量c属于局部作用域，在bar函数之外是无法访问的。事实上，Python查找一个变量时会按照“局部作用域”、“嵌套作用域”、“全局作用域”和“内置作用域”的顺序进行搜索，前三者我们在上面的代码中已经看到了，所谓的“内置作用域”就是Python内置的那些隐含标识符min、len等都属于内置作用域）。 再看看下面这段代码，我们希望通过函数调用修改全局变量a的值，但实际上下面的代码是做不到的。 def foo(): a = 200 print(a) # 200 if __name__ == '__main__': a = 100 foo() print(a) # 100 在调用foo函数后，我们发现a的值仍然是100，这是因为当我们在函数foo中写a = 200的时候，是重新定义了一个名字为a的局部变量，它跟全局作用域的a并不是同一个变量，因为局部作用域中有了自己的变量a，因此foo函数不再搜索全局作用域中的a。如果我们希望在foo函数中修改全局作用域中的a，代码如下所示。 def foo(): global a a = 200 print(a) # 200 if __name__ == '__main__': a = 100 foo() print(a) # 200 我们可以使用global关键字来指示foo函数中的变量a来自于全局作用域，如果全局作用域中没有a，那么下面一行的代码就会定义变量a并将其置于全局作用域。同理，如果我们希望函数内部的函数能够修改嵌套作用域中的变量，可以使用nonlocal关键字来指示变量来自于嵌套作用域，请大家自行试验。 在实际开发中，我们应该尽量减少对全局变量的使用，因为全局变量的作用域和影响过于广泛，可能会发生意料之外的修改和使用，除此之外全局变量比局部变量拥有更长的生命周期，可能导致对象占用的内存长时间无法被垃圾回收)。事实上，减少对全局变量的使用，也是降低代码之间耦合度的一个重要举措，同时也是对迪米特法则的践行。减少全局变量的使用就意味着我们应该尽量让变量的作用域在函数的内部，但是如果我们希望将一个局部变量的生命周期延长，使其在函数调用结束后依然可以访问，这时候就需要使用闭包)，这个我们在后续的内容中进行讲解。 说明：很多人经常会将“闭包”一词和“匿名函数”混为一谈，但实际上它们是不同的概念，如果想提前了解这个概念，推荐看看维基百科或者知乎上对这个概念的讨论。 说了那么多，其实结论很简单，从现在开始我们可以将Python代码按照下面的格式进行书写，这一点点的改进其实就是在我们理解了函数和作用域的基础上跨出的巨大的一步。 def main(): # Todo: Add your code here pass if __name__ == '__main__': main() "},"Python/Python语言基础/06-字符串和常用数据结构.html":{"url":"Python/Python语言基础/06-字符串和常用数据结构.html","title":"字符串和常用数据结构","keywords":"","body":"datetime:2019/5/14 9:57 author:nzb 字符串和常用数据结构 使用字符串 第二次世界大战促使了现代电子计算机的诞生，当初的想法很简单，就是用计算机来计算导弹的弹道，因此在计算机刚刚诞生的那个年代，计算机处理的信息主要是数值，而世界上的第一台电子计算机ENIAC每秒钟能够完成约5000次浮点运算。随着时间的推移，虽然对数值运算仍然是计算机日常工作中最为重要的事情之一，但是今天的计算机处理得更多的数据都是以文本信息的方式存在的，而Python表示文本信息的方式我们在很早以前就说过了，那就是字符串类型。所谓字符串，就是由零个或多个字符组成的有限序列，一般记为{\\displaystyle s=a_{1}a_{2}\\dots a_{n}(0\\leq n \\leq \\infty)}。 我们可以通过下面的代码来了解字符串的使用。 def main(): str1 = 'hello, world!' # 通过len函数计算字符串的长度 print(len(str1)) # 13 # 获得字符串首字母大写的拷贝 print(str1.capitalize()) # Hello, world! # 获得字符串变大写后的拷贝 print(str1.upper()) # HELLO, WORLD! # 从字符串中查找子串所在位置 print(str1.find('or')) # 8 print(str1.find('shit')) # -1 # 与find类似但找不到子串时会引发异常 # print(str1.index('or')) # print(str1.index('shit')) # 检查字符串是否以指定的字符串开头 print(str1.startswith('He')) # False print(str1.startswith('hel')) # True # 检查字符串是否以指定的字符串结尾 print(str1.endswith('!')) # True # 将字符串以指定的宽度居中并在两侧填充指定的字符 print(str1.center(50, '*')) # 将字符串以指定的宽度靠右放置左侧填充指定的字符 print(str1.rjust(50, ' ')) str2 = 'abc123456' # 从字符串中取出指定位置的字符(下标运算) print(str2[2]) # c # 字符串切片(从指定的开始索引到指定的结束索引) print(str2[2:5]) # c12 print(str2[2:]) # c123456 print(str2[2::2]) # c246 print(str2[::2]) # ac246 print(str2[::-1]) # 654321cba print(str2[-3:-1]) # 45 # 检查字符串是否由数字构成 print(str2.isdigit()) # False # 检查字符串是否以字母构成 print(str2.isalpha()) # False # 检查字符串是否以数字和字母构成 print(str2.isalnum()) # True str3 = ' jackfrued@126.com ' print(str3) # 获得字符串修剪左右两侧空格的拷贝 print(str3.strip()) if __name__ == '__main__': main() 除了字符串，Python还内置了多种类型的数据结构，如果要在程序中保存和操作数据，绝大多数时候可以利用现有的数据结构来实现，最常用的包括列表、元组、集合和字典。 使用列表 下面的代码演示了如何定义列表、使用下标访问列表元素以及添加和删除元素的操作。 def main(): list1 = [1, 3, 5, 7, 100] print(list1) list2 = ['hello'] * 5 print(list2) # 计算列表长度(元素个数) print(len(list1)) # 下标(索引)运算 print(list1[0]) print(list1[4]) # print(list1[5]) # IndexError: list index out of range print(list1[-1]) print(list1[-3]) list1[2] = 300 print(list1) # 添加元素 list1.append(200) list1.insert(1, 400) list1 += [1000, 2000] print(list1) print(len(list1)) # 删除元素 list1.remove(3) if 1234 in list1: list1.remove(1234) del list1[0] print(list1) # 清空列表元素 list1.clear() print(list1) if __name__ == '__main__': main() 和字符串一样，列表也可以做切片操作，通过切片操作我们可以实现对列表的复制或者将列表中的一部分取出来创建出新的列表，代码如下所示。 def main(): fruits = ['grape', 'apple', 'strawberry', 'waxberry'] fruits += ['pitaya', 'pear', 'mango'] # 循环遍历列表元素 for fruit in fruits: print(fruit.title(), end=' ') print() # 列表切片 fruits2 = fruits[1:4] print(fruits2) # fruit3 = fruits # 没有复制列表只创建了新的引用 # 可以通过完整切片操作来复制列表 fruits3 = fruits[:] print(fruits3) fruits4 = fruits[-3:-1] print(fruits4) # 可以通过反向切片操作来获得倒转后的列表的拷贝 fruits5 = fruits[::-1] print(fruits5) if __name__ == '__main__': main() 下面的代码实现了对列表的排序操作。 def main(): list1 = ['orange', 'apple', 'zoo', 'internationalization', 'blueberry'] list2 = sorted(list1) # sorted函数返回列表排序后的拷贝不会修改传入的列表 # 函数的设计就应该像sorted函数一样尽可能不产生副作用 list3 = sorted(list1, reverse=True) # 通过key关键字参数指定根据字符串长度进行排序而不是默认的字母表顺序 list4 = sorted(list1, key=len) print(list1) print(list2) print(list3) print(list4) # 给列表对象发出排序消息直接在列表对象上进行排序 list1.sort(reverse=True) print(list1) if __name__ == '__main__': main() 我们还可以使用列表的生成式语法来创建列表，代码如下所示。 import sys def main(): f = [x for x in range(1, 10)] print(f) f = [x + y for x in 'ABCDE' for y in '1234567'] print(f) # 用列表的生成表达式语法创建列表容器 # 用这种语法创建列表之后元素已经准备就绪所以需要耗费较多的内存空间 f = [x ** 2 for x in range(1, 1000)] print(sys.getsizeof(f)) # 查看对象占用内存的字节数 print(f) # 请注意下面的代码创建的不是一个列表而是一个生成器对象 # 通过生成器可以获取到数据但它不占用额外的空间存储数据 # 每次需要数据的时候就通过内部的运算得到数据(需要花费额外的时间) f = (x ** 2 for x in range(1, 1000)) print(sys.getsizeof(f)) # 相比生成式生成器不占用存储数据的空间 print(f) for val in f: print(val) if __name__ == '__main__': main() 除了上面提到的生成器语法，Python中还有另外一种定义生成器的方式，就是通过yield关键字将一个普通函数改造成生成器函数。下面的代码演示了如何实现一个生成斐波拉切数列的生成器。所谓斐波拉切数列可以通过下面递归的方法来进行定义： {\\displaystyle F_{0}=0} {\\displaystyle F_{1}=1} {\\displaystyle F_{n}=F_{n-1}+F_{n-2} }({n}\\geq{2}) def fib(n): a, b = 0, 1 for _ in range(n): a, b = b, a + b yield a def main(): for val in fib(20): print(val) if __name__ == '__main__': main() 使用元组 Python 的元组与列表类似，不同之处在于元组的元素不能修改，在前面的代码中我们已经不止一次使用过元组了。顾名思义，我们把多个元素组合到一起就形成了一个元组，所以它和列表一样可以保存多条数据。下面的代码演示了如何定义和使用元组。 def main(): # 定义元组 t = ('骆昊', 38, True, '四川成都') print(t) # 获取元组中的元素 print(t[0]) print(t[3]) # 遍历元组中的值 for member in t: print(member) # 重新给元组赋值 # t[0] = '王大锤' # TypeError # 变量t重新引用了新的元组原来的元组将被垃圾回收 t = ('王大锤', 20, True, '云南昆明') print(t) # 将元组转换成列表 person = list(t) print(person) # 列表是可以修改它的元素的 person[0] = '李小龙' person[1] = 25 print(person) # 将列表转换成元组 fruits_list = ['apple', 'banana', 'orange'] fruits_tuple = tuple(fruits_list) print(fruits_tuple) if __name__ == '__main__': main() 这里有一个非常值得探讨的问题，我们已经有了列表这种数据结构，为什么还需要元组这样的类型呢？ 元组中的元素是无法修改的，事实上我们在项目中尤其是多线程环境（后面会讲到）中可能更喜欢使用的是那些不变对象（一方面因为对象状态不能修改，所以可以避免由此引起的不必要的程序错误，简单的说就是一个不变的对象要比可变的对象更加容易维护；另一方面因为没有任何一个线程能够修改不变对象的内部状态，一个不变对象自动就是线程安全的，这样就可以省掉处理同步化的开销。一个不变对象可以方便的被共享访问）。所以结论就是：如果不需要对元素进行添加、删除、修改的时候，可以考虑使用元组，当然如果一个方法要返回多个值，使用元组也是不错的选择。 元组在创建时间和占用的空间上面都优于列表。我们可以使用sys模块的getsizeof函数来检查存储同样的元素的元组和列表各自占用了多少内存空间，这个很容易做到。我们也可以在ipython中使用魔法指令%timeit来分析创建同样内容的元组和列表所花费的时间，下图是我的macOS系统上测试的结果。 使用集合 Python中的集合跟数学上的集合是一致的，不允许有重复元素，而且可以进行交集、并集、差集等运算。 def main(): set1 = {1, 2, 3, 3, 3, 2} print(set1) print('Length =', len(set1)) set2 = set(range(1, 10)) print(set2) set1.add(4) set1.add(5) set2.update([11, 12]) print(set1) print(set2) set2.discard(5) # remove的元素如果不存在会引发KeyError if 4 in set2: set2.remove(4) print(set2) # 遍历集合容器 for elem in set2: print(elem ** 2, end=' ') print() # 将元组转换成集合 set3 = set((1, 2, 3, 3, 2, 1)) print(set3.pop()) print(set3) # 集合的交集、并集、差集、对称差运算 print(set1 & set2) # print(set1.intersection(set2)) print(set1 | set2) # print(set1.union(set2)) print(set1 - set2) # print(set1.difference(set2)) print(set1 ^ set2) # print(set1.symmetric_difference(set2)) # 判断子集和超集 print(set2 = set2) # print(set1.issuperset(set2)) print(set1 >= set3) # print(set1.issuperset(set3)) if __name__ == '__main__': main() 说明：Python中允许通过一些特殊的方法来为某种类型或数据结构自定义运算符（后面的章节中会讲到），上面的代码中我们对集合进行运算的时候可以调用集合对象的方法，也可以直接使用对应的运算符，例如&运算符跟intersection方法的作用就是一样的，但是使用运算符让代码更加直观。 使用字典 字典是另一种可变容器模型，类似于我们生活中使用的字典，它可以存储任意类型对象，与列表、集合不同的是，字典的每个元素都是由一个键和一个值组成的“键值对”，键和值通过冒号分开。下面的代码演示了如何定义和使用字典。 def main(): scores = {'骆昊': 95, '白元芳': 78, '狄仁杰': 82} # 通过键可以获取字典中对应的值 print(scores['骆昊']) print(scores['狄仁杰']) # 对字典进行遍历(遍历的其实是键再通过键取对应的值) for elem in scores: print('%s\\t--->\\t%d' % (elem, scores[elem])) # 更新字典中的元素 scores['白元芳'] = 65 scores['诸葛王朗'] = 71 scores.update(冷面=67, 方启鹤=85) print(scores) if '武则天' in scores: print(scores['武则天']) print(scores.get('武则天')) # get方法也是通过键获取对应的值但是可以设置默认值 print(scores.get('武则天', 60)) # 删除字典中的元素 print(scores.popitem()) print(scores.popitem()) print(scores.pop('骆昊', 100)) # 清空字典 scores.clear() print(scores) if __name__ == '__main__': main() 练习 练习1：在屏幕上显示跑马灯文字 import os import time def main(): content = '北京欢迎你为你开天辟地…………' while True: # 清理屏幕上的输出 os.system('cls') # os.system('clear') print(content) # 休眠200毫秒 time.sleep(0.2) content = content[1:] + content[0] if __name__ == '__main__': main() 练习2：设计一个函数产生指定长度的验证码，验证码由大小写字母和数字构成。 import random def generate_code(code_len=4): \"\"\" 生成指定长度的验证码 :param code_len: 验证码的长度(默认4个字符) :return: 由大小写英文字母和数字构成的随机验证码 \"\"\" all_chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' last_pos = len(all_chars) - 1 code = '' for _ in range(code_len): index = random.randint(0, last_pos) code += all_chars[index] return code 练习3：设计一个函数返回给定文件名的后缀名。 def get_suffix(filename, has_dot=False): \"\"\" 获取文件名的后缀名 :param filename: 文件名 :param has_dot: 返回的后缀名是否需要带点 :return: 文件的后缀名 \"\"\" pos = filename.rfind('.') if 0 练习4：设计一个函数返回传入的列表中最大和第二大的元素的值。 def max2(x): m1, m2 = (x[0], x[1]) if x[0] > x[1] else (x[1], x[0]) for index in range(2, len(x)): if x[index] > m1: m2 = m1 m1 = x[index] elif x[index] > m2: m2 = x[index] return m1, m2 练习5：计算指定的年月日是这一年的第几天 def is_leap_year(year): \"\"\" 判断指定的年份是不是闰年 :param year: 年份 :return: 闰年返回True平年返回False \"\"\" return year % 4 == 0 and year % 100 != 0 or year % 400 == 0 def which_day(year, month, date): \"\"\" 计算传入的日期是这一年的第几天 :param year: 年 :param month: 月 :param date: 日 :return: 第几天 \"\"\" days_of_month = [ [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31], [31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31] ][is_leap_year(year)] total = 0 for index in range(month - 1): total += days_of_month[index] return total + date def main(): print(which_day(1980, 11, 28)) print(which_day(1981, 12, 31)) print(which_day(2018, 1, 1)) print(which_day(2016, 3, 1)) if __name__ == '__main__': main() 练习6：打印杨辉三角。 def main(): num = int(input('Number of rows: ')) yh = [[]] * num for row in range(len(yh)): yh[row] = [None] * (row + 1) for col in range(len(yh[row])): if col == 0 or col == row: yh[row][col] = 1 else: yh[row][col] = yh[row - 1][col] + yh[row - 1][col - 1] print(yh[row][col], end='\\t') print() if __name__ == '__main__': main() 综合案例 案例1：双色球选号 from random import randrange, randint, sample def display(balls): \"\"\" 输出列表中的双色球号码 \"\"\" for index, ball in enumerate(balls): if index == len(balls) - 1: print('|', end=' ') print('%02d' % ball, end=' ') print() def random_select(): \"\"\" 随机选择一组号码 \"\"\" red_balls = [x for x in range(1, 34)] selected_balls = [] selected_balls = sample(red_balls, 6) selected_balls.sort() selected_balls.append(randint(1, 16)) return selected_balls def main(): n = int(input('机选几注: ')) for _ in range(n): display(random_select()) if __name__ == '__main__': main() 说明：上面使用random模块的sample函数来实现从列表中选择不重复的n个元素。 综合案例2：约瑟夫环问题 \"\"\" 《幸运的基督徒》 有15个基督徒和15个非基督徒在海上遇险，为了能让一部分人活下来不得不将其中15个人扔到海里面去，有个人想了个办法就是大家围成一个圈，由某个人开始从1报数，报到9的人就扔到海里面，他后面的人接着从1开始报数，报到9的人继续扔到海里面，直到扔掉15个人。由于上帝的保佑，15个基督徒都幸免于难，问这些人最开始是怎么站的，哪些位置是基督徒哪些位置是非基督徒。 \"\"\" def main(): persons = [True] * 30 counter, index, number = 0, 0, 0 while counter 综合案例3：井字棋游戏 import os def print_board(board): print(board['TL'] + '|' + board['TM'] + '|' + board['TR']) print('-+-+-') print(board['ML'] + '|' + board['MM'] + '|' + board['MR']) print('-+-+-') print(board['BL'] + '|' + board['BM'] + '|' + board['BR']) def main(): init_board = { 'TL': ' ', 'TM': ' ', 'TR': ' ', 'ML': ' ', 'MM': ' ', 'MR': ' ', 'BL': ' ', 'BM': ' ', 'BR': ' ' } begin = True while begin: curr_board = init_board.copy() begin = False turn = 'x' counter = 0 os.system('clear') print_board(curr_board) while counter 说明：最后这个案例来自《Python编程快速上手:让繁琐工作自动化》一书（这本书对有编程基础想迅速使用Python将日常工作自动化的人来说还是不错的选择），对代码做了一点点的调整。 "},"Python/Python语言基础/07-面向对象编程基础.html":{"url":"Python/Python语言基础/07-面向对象编程基础.html","title":"面向对象编程基础","keywords":"","body":"datetime:2019/5/14 10:11 author:nzb 面向对象编程基础 活在当下的程序员应该都听过“面向对象编程”一词，也经常有人问能不能用一句话解释下什么是“面向对象编程”，我们先来看看比较正式的说法。 把一组数据结构和处理它们的方法组成对象（object），把相同行为的对象归纳为类（class），通过类的封装（encapsulation）隐藏内部细节，通过继承（inheritance）实现类的特化（specialization）和泛化（generalization），通过多态（polymorphism）实现基于对象类型的动态分派。 这样一说是不是更不明白了。所以我们还是看看更通俗易懂的说法，下面这段内容来自于知乎。 说明：以上的内容来自于网络，不代表作者本人的观点和看法，与作者本人立场无关，相关责任不由作者承担。 之前我们说过“程序是指令的集合”，我们在程序中书写的语句在执行时会变成一条或多条指令然后由CPU去执行。当然为了简化程序的设计，我们引入了函数的概念，把相对独立且经常重复使用的代码放置到函数中，在需要使用这些功能的时候只要调用函数即可；如果一个函数的功能过于复杂和臃肿，我们又可以进一步将函数继续切分为子函数来降低系统的复杂性。但是说了这么多，不知道大家是否发现，所谓编程就是程序员按照计算机的工作方式控制计算机完成各种任务。但是，计算机的工作方式与正常人类的思维模式是不同的，如果编程就必须得抛弃人类正常的思维方式去迎合计算机，编程的乐趣就少了很多，“每个人都应该学习编程”这样的豪言壮语就只能说说而已。当然，这些还不是最重要的，最重要的是当我们需要开发一个复杂的系统时，代码的复杂性会让开发和维护工作都变得举步维艰，所以在上世纪60年代末期，“软件危机”、“软件工程”等一系列的概念开始在行业中出现。 当然，程序员圈子内的人都知道，现实中并没有解决上面所说的这些问题的“银弹”，真正让软件开发者看到希望的是上世纪70年代诞生的Smalltalk编程语言中引入的面向对象的编程思想（面向对象编程的雏形可以追溯到更早期的Simula语言）。按照这种编程理念，程序中的数据和操作数据的函数是一个逻辑上的整体，我们称之为“对象”，而我们解决问题的方式就是创建出需要的对象并向对象发出各种各样的消息，多个对象的协同工作最终可以让我们构造出复杂的系统来解决现实中的问题。 说明：当然面向对象也不是解决软件开发中所有问题的最后的“银弹”，所以今天的高级程序设计语言几乎都提供了对多种编程范式的支持，Python也不例外。 类和对象 简单的说，类是对象的蓝图和模板，而对象是类的实例。这个解释虽然有点像用概念在解释概念，但是从这句话我们至少可以看出，类是抽象的概念，而对象是具体的东西。在面向对象编程的世界中，一切皆为对象，对象都有属性和行为，每个对象都是独一无二的，而且对象一定属于某个类（型）。当我们把一大堆拥有共同特征的对象的静态特征（属性）和动态特征（行为）都抽取出来后，就可以定义出一个叫做“类”的东西。 定义类 在Python中可以使用class关键字定义类，然后在类中通过之前学习过的函数来定义方法，这样就可以将对象的动态特征描述出来，代码如下所示。 class Student(object): # __init__是一个特殊方法用于在创建对象时进行初始化操作 # 通过这个方法我们可以为学生对象绑定name和age两个属性 def __init__(self, name, age): self.name = name self.age = age def study(self, course_name): print('%s正在学习%s.' % (self.name, course_name)) # PEP 8要求标识符的名字用全小写多个单词用下划线连接 # 但是很多程序员和公司更倾向于使用驼峰命名法(驼峰标识) def watch_av(self): if self.age 说明：写在类中的函数，我们通常称之为（对象的）方法，这些方法就是对象可以接收的消息。 创建和使用对象 当我们定义好一个类之后，可以通过下面的方式来创建对象并给对象发消息。 def main(): # 创建学生对象并指定姓名和年龄 stu1 = Student('骆昊', 38) # 给对象发study消息 stu1.study('Python程序设计') # 给对象发watch_av消息 stu1.watch_av() stu2 = Student('王大锤', 15) stu2.study('思想品德') stu2.watch_av() if __name__ == '__main__': main() 访问可见性问题 对于上面的代码，有C++、Java、C#等编程经验的程序员可能会问，我们给Student对象绑定的name和age属性到底具有怎样的访问权限（也称为可见性）。因为在很多面向对象编程语言中，我们通常会将对象的属性设置为私有的（private）或受保护的（protected），简单的说就是不允许外界访问，而对象的方法通常都是公开的（public），因为公开的方法就是对象能够接受的消息。在Python中，属性和方法的访问权限只有两种，也就是公开的和私有的，如果希望属性是私有的，在给属性命名时可以用两个下划线作为开头，下面的代码可以验证这一点。 class Test: def __init__(self, foo): self.__foo = foo def __bar(self): print(self.__foo) print('__bar') def main(): test = Test('hello') # AttributeError: 'Test' object has no attribute '__bar' test.__bar() # AttributeError: 'Test' object has no attribute '__foo' print(test.__foo) if __name__ == \"__main__\": main() 但是，Python并没有从语法上严格保证私有属性或方法的私密性，它只是给私有的属性和方法换了一个名字来“妨碍”对它们的访问，事实上如果你知道更换名字的规则仍然可以访问到它们，下面的代码就可以验证这一点。之所以这样设定，可以用这样一句名言加以解释，就是“We are all consenting adults here”。因为绝大多数程序员都认为开放比封闭要好，而且程序员要自己为自己的行为负责。 class Test: def __init__(self, foo): self.__foo = foo def __bar(self): print(self.__foo) print('__bar') def main(): test = Test('hello') test._Test__bar() print(test._Test__foo) if __name__ == \"__main__\": main() 在实际开发中，我们并不建议将属性设置为私有的，因为这会导致子类无法访问（后面会讲到）。所以大多数Python程序员会遵循一种命名惯例就是让属性名以单下划线开头来表示属性是受保护的，本类之外的代码在访问这样的属性时应该要保持慎重。这种做法并不是语法上的规则，单下划线开头的属性和方法外界仍然是可以访问的，所以更多的时候它是一种暗示或隐喻，关于这一点可以看看我的《Python - 那些年我们踩过的那些坑》文章中的讲解。 面向对象的支柱 面向对象有三大支柱：封装、继承和多态。后面两个概念在下一个章节中进行详细的说明，这里我们先说一下什么是封装。我自己对封装的理解是“隐藏一切可以隐藏的实现细节，只向外界暴露（提供）简单的编程接口”。我们在类中定义的方法其实就是把数据和对数据的操作封装起来了，在我们创建了对象之后，只需要给对象发送一个消息（调用方法）就可以执行方法中的代码，也就是说我们只需要知道方法的名字和传入的参数（方法的外部视图），而不需要知道方法内部的实现细节（方法的内部视图）。 练习 练习1：定义一个类描述数字时钟 class Clock(object): \"\"\"数字时钟\"\"\" def __init__(self, hour=0, minute=0, second=0): \"\"\"初始化方法 :param hour: 时 :param minute: 分 :param second: 秒 \"\"\" self._hour = hour self._minute = minute self._second = second def run(self): \"\"\"走字\"\"\" self._second += 1 if self._second == 60: self._second = 0 self._minute += 1 if self._minute == 60: self._minute = 0 self._hour += 1 if self._hour == 24: self._hour = 0 def show(self): \"\"\"显示时间\"\"\" return '%02d:%02d:%02d' % \\ (self._hour, self._minute, self._second) def main(): clock = Clock(23, 59, 58) while True: print(clock.show()) sleep(1) clock.run() if __name__ == '__main__': main() 练习2：定义一个类描述平面上的点并提供移动点和计算到另一个点距离的方法。 from math import sqrt class Point(object): def __init__(self, x=0, y=0): \"\"\"初始化方法 :param x: 横坐标 :param y: 纵坐标 \"\"\" self.x = x self.y = y def move_to(self, x, y): \"\"\"移动到指定位置 :param x: 新的横坐标 \"param y: 新的纵坐标 \"\"\" self.x = x self.y = y def move_by(self, dx, dy): \"\"\"移动指定的增量 :param dx: 横坐标的增量 \"param dy: 纵坐标的增量 \"\"\" self.x += dx self.y += dy def distance_to(self, other): \"\"\"计算与另一个点的距离 :param other: 另一个点 \"\"\" dx = self.x - other.x dy = self.y - other.y return sqrt(dx ** 2 + dy ** 2) def __str__(self): return '(%s, %s)' % (str(self.x), str(self.y)) def main(): p1 = Point(3, 5) p2 = Point() print(p1) print(p2) p2.move_by(-1, 2) print(p2) print(p1.distance_to(p2)) if __name__ == '__main__': main() 说明：本章中的插图来自于Grady Booch等著作的《面向对象分析与设计》一书，该书是讲解面向对象编程的经典著作，有兴趣的读者可以购买和阅读这本书来了解更多的面向对象的相关知识。 "},"Python/Python语言基础/08-面向对象编程进阶.html":{"url":"Python/Python语言基础/08-面向对象编程进阶.html","title":"面向对象编程进阶","keywords":"","body":"datetime:2019/5/14 10:30 author:nzb 面向对象进阶 在前面的章节我们已经了解了面向对象的入门知识，知道了如何定义类，如何创建对象以及如何给对象发消息。为了能够更好的使用面向对象编程思想进行程序开发，我们还需要对Python中的面向对象编程进行更为深入的了解。 @property装饰器 之前我们讨论过Python中属性和方法访问权限的问题，虽然我们不建议将属性设置为私有的，但是如果直接将属性暴露给外界也是有问题的，比如我们没有办法检查赋给属性的值是否有效。我们之前的建议是将属性命名以单下划线开头，通过这种方式来暗示属性是受保护的，不建议外界直接访问，那么如果想访问属性可以通过属性的getter（访问器）和setter（修改器）方法进行对应的操作。如果要做到这点，就可以考虑使用@property包装器来包装getter和setter方法，使得对属性的访问既安全又方便，代码如下所示。 class Person(object): def __init__(self, name, age): self._name = name self._age = age # 访问器 - getter方法 @property def name(self): return self._name # 访问器 - getter方法 @property def age(self): return self._age # 修改器 - setter方法 @age.setter def age(self, age): self._age = age def play(self): if self._age __slots__魔法 我们讲到这里，不知道大家是否已经意识到，Python是一门动态语言。通常，动态语言允许我们在程序运行时给对象绑定新的属性或方法，当然也可以对已经绑定的属性和方法进行解绑定。但是如果我们需要限定自定义类型的对象只能绑定某些属性，可以通过在类中定义__slots__变量来进行限定。需要注意的是__slots__的限定只对当前类的对象生效，对子类并不起任何作用。 class Person(object): # 限定Person对象只能绑定_name, _age和_gender属性 __slots__ = ('_name', '_age', '_gender') def __init__(self, name, age): self._name = name self._age = age @property def name(self): return self._name @property def age(self): return self._age @age.setter def age(self, age): self._age = age def play(self): if self._age 静态方法和类方法 之前，我们在类中定义的方法都是对象方法，也就是说这些方法都是发送给对象的消息。实际上，我们写在类中的方法并不需要都是对象方法，例如我们定义一个“三角形”类，通过传入三条边长来构造三角形，并提供计算周长和面积的方法，但是传入的三条边长未必能构造出三角形对象，因此我们可以先写一个方法来验证三条边长是否可以构成三角形，这个方法很显然就不是对象方法，因为在调用这个方法时三角形对象尚未创建出来（因为都不知道三条边能不能构成三角形），所以这个方法是属于三角形类而并不属于三角形对象的。我们可以使用静态方法来解决这类问题，代码如下所示。 from math import sqrt class Triangle(object): def __init__(self, a, b, c): self._a = a self._b = b self._c = c @staticmethod def is_valid(a, b, c): return a + b > c and b + c > a and a + c > b def perimeter(self): return self._a + self._b + self._c def area(self): half = self.perimeter() / 2 return sqrt(half * (half - self._a) * (half - self._b) * (half - self._c)) def main(): a, b, c = 3, 4, 5 # 静态方法和类方法都是通过给类发消息来调用的 if Triangle.is_valid(a, b, c): t = Triangle(a, b, c) print(t.perimeter()) # 也可以通过给类发消息来调用对象方法但是要传入接收消息的对象作为参数 # print(Triangle.perimeter(t)) print(t.area()) # print(Triangle.area(t)) else: print('无法构成三角形.') if __name__ == '__main__': main() 和静态方法比较类似，Python还可以在类中定义类方法，类方法的第一个参数约定名为cls，它代表的是当前类相关的信息的对象（类本身也是一个对象，有的地方也称之为类的元数据对象），通过这个参数我们可以获取和类相关的信息并且可以创建出类的对象，代码如下所示。 from time import time, localtime, sleep class Clock(object): \"\"\"数字时钟\"\"\" def __init__(self, hour=0, minute=0, second=0): self._hour = hour self._minute = minute self._second = second @classmethod def now(cls): ctime = localtime(time()) return cls(ctime.tm_hour, ctime.tm_min, ctime.tm_sec) def run(self): \"\"\"走字\"\"\" self._second += 1 if self._second == 60: self._second = 0 self._minute += 1 if self._minute == 60: self._minute = 0 self._hour += 1 if self._hour == 24: self._hour = 0 def show(self): \"\"\"显示时间\"\"\" return '%02d:%02d:%02d' % \\ (self._hour, self._minute, self._second) def main(): # 通过类方法创建对象并获取系统时间 clock = Clock.now() while True: print(clock.show()) sleep(1) clock.run() if __name__ == '__main__': main() 类之间的关系 简单的说，类和类之间的关系有三种：is-a、has-a和use-a关系。 is-a关系也叫继承或泛化，比如学生和人的关系、手机和电子产品的关系都属于继承关系。 has-a关系通常称之为关联，比如部门和员工的关系，汽车和引擎的关系都属于关联关系；关联关系如果是整体和部分的关联，那么我们称之为聚合关系；如果整体进一步负责了部分的生命周期（整体和部分是不可分割的，同时同在也同时消亡），那么这种就是最强的关联关系，我们称之为合成关系。 use-a关系通常称之为依赖，比如司机有一个驾驶的行为（方法），其中（的参数）使用到了汽车，那么司机和汽车的关系就是依赖关系。 我们可以使用一种叫做UML（统一建模语言）的东西来进行面向对象建模，其中一项重要的工作就是把类和类之间的关系用标准化的图形符号描述出来。关于UML我们在这里不做详细的介绍，有兴趣的读者可以自行阅读《UML面向对象设计基础》一书。 利用类之间的这些关系，我们可以在已有类的基础上来完成某些操作，也可以在已有类的基础上创建新的类，这些都是实现代码复用的重要手段。复用现有的代码不仅可以减少开发的工作量，也有利于代码的管理和维护，这是我们在日常工作中都会使用到的技术手段。 继承和多态 刚才我们提到了，可以在已有类的基础上创建新类，这其中的一种做法就是让一个类从另一个类那里将属性和方法直接继承下来，从而减少重复代码的编写。提供继承信息的我们称之为父类，也叫超类或基类；得到继承信息的我们称之为子类，也叫派生类或衍生类。子类除了继承父类提供的属性和方法，还可以定义自己特有的属性和方法，所以子类比父类拥有的更多的能力，在实际开发中，我们经常会用子类对象去替换掉一个父类对象，这是面向对象编程中一个常见的行为，对应的原则称之为里氏替换原则。下面我们先看一个继承的例子。 class Person(object): \"\"\"人\"\"\" def __init__(self, name, age): self._name = name self._age = age @property def name(self): return self._name @property def age(self): return self._age @age.setter def age(self, age): self._age = age def play(self): print('%s正在愉快的玩耍.' % self._name) def watch_av(self): if self._age >= 18: print('%s正在观看爱情动作片.' % self._name) else: print('%s只能观看《熊出没》.' % self._name) class Student(Person): \"\"\"学生\"\"\" def __init__(self, name, age, grade): super().__init__(name, age) self._grade = grade @property def grade(self): return self._grade @grade.setter def grade(self, grade): self._grade = grade def study(self, course): print('%s的%s正在学习%s.' % (self._grade, self._name, course)) class Teacher(Person): \"\"\"老师\"\"\" def __init__(self, name, age, title): super().__init__(name, age) self._title = title @property def title(self): return self._title @title.setter def title(self, title): self._title = title def teach(self, course): print('%s%s正在讲%s.' % (self._name, self._title, course)) def main(): stu = Student('王大锤', 15, '初三') stu.study('数学') stu.watch_av() t = Teacher('骆昊', 38, '老叫兽') t.teach('Python程序设计') t.watch_av() if __name__ == '__main__': main() 子类在继承了父类的方法后，可以对父类已有的方法给出新的实现版本，这个动作称之为方法重写（override）。通过方法重写我们可以让父类的同一个行为在子类中拥有不同的实现版本，当我们调用这个经过子类重写的方法时，不同的子类对象会表现出不同的行为，这个就是多态（poly-morphism）。 from abc import ABCMeta, abstractmethod class Pet(object, metaclass=ABCMeta): \"\"\"宠物\"\"\" def __init__(self, nickname): self._nickname = nickname @abstractmethod def make_voice(self): \"\"\"发出声音\"\"\" pass class Dog(Pet): \"\"\"狗\"\"\" def make_voice(self): print('%s: 汪汪汪...' % self._nickname) class Cat(Pet): \"\"\"猫\"\"\" def make_voice(self): print('%s: 喵...喵...' % self._nickname) def main(): pets = [Dog('旺财'), Cat('凯蒂'), Dog('大黄')] for pet in pets: pet.make_voice() if __name__ == '__main__': main() 在上面的代码中，我们将Pet类处理成了一个抽象类，所谓抽象类就是不能够创建对象的类，这种类的存在就是专门为了让其他类去继承它。Python从语法层面并没有像Java或C#那样提供对抽象类的支持，但是我们可以通过abc模块的ABCMeta元类和abstractmethod包装器来达到抽象类的效果，如果一个类中存在抽象方法那么这个类就不能够实例化（创建对象）。上面的代码中，Dog和Cat两个子类分别对Pet类中的make_voice抽象方法进行了重写并给出了不同的实现版本，当我们在main函数中调用该方法时，这个方法就表现出了多态行为（同样的方法做了不同的事情）。 综合案例 案例1：奥特曼打小怪兽 from abc import ABCMeta, abstractmethod from random import randint, randrange class Fighter(object, metaclass=ABCMeta): \"\"\"战斗者\"\"\" # 通过__slots__魔法限定对象可以绑定的成员变量 __slots__ = ('_name', '_hp') def __init__(self, name, hp): \"\"\"初始化方法 :param name: 名字 :param hp: 生命值 \"\"\" self._name = name self._hp = hp @property def name(self): return self._name @property def hp(self): return self._hp @hp.setter def hp(self, hp): self._hp = hp if hp >= 0 else 0 @property def alive(self): return self._hp > 0 @abstractmethod def attack(self, other): \"\"\"攻击 :param other: 被攻击的对象 \"\"\" pass class Ultraman(Fighter): \"\"\"奥特曼\"\"\" __slots__ = ('_name', '_hp', '_mp') def __init__(self, name, hp, mp): \"\"\"初始化方法 :param name: 名字 :param hp: 生命值 :param mp: 魔法值 \"\"\" super().__init__(name, hp) self._mp = mp def attack(self, other): other.hp -= randint(15, 25) def huge_attack(self, other): \"\"\"究极必杀技(打掉对方至少50点或四分之三的血) :param other: 被攻击的对象 :return: 使用成功返回True否则返回False \"\"\" if self._mp >= 50: self._mp -= 50 injury = other.hp * 3 // 4 injury = injury if injury >= 50 else 50 other.hp -= injury return True else: self.attack(other) return False def magic_attack(self, others): \"\"\"魔法攻击 :param others: 被攻击的群体 :return: 使用魔法成功返回True否则返回False \"\"\" if self._mp >= 20: self._mp -= 20 for temp in others: if temp.alive: temp.hp -= randint(10, 15) return True else: return False def resume(self): \"\"\"恢复魔法值\"\"\" incr_point = randint(1, 10) self._mp += incr_point return incr_point def __str__(self): return '~~~%s奥特曼~~~\\n' % self._name + \\ '生命值: %d\\n' % self._hp + \\ '魔法值: %d\\n' % self._mp class Monster(Fighter): \"\"\"小怪兽\"\"\" __slots__ = ('_name', '_hp') def attack(self, other): other.hp -= randint(10, 20) def __str__(self): return '~~~%s小怪兽~~~\\n' % self._name + \\ '生命值: %d\\n' % self._hp def is_any_alive(monsters): \"\"\"判断有没有小怪兽是活着的\"\"\" for monster in monsters: if monster.alive > 0: return True return False def select_alive_one(monsters): \"\"\"选中一只活着的小怪兽\"\"\" monsters_len = len(monsters) while True: index = randrange(monsters_len) monster = monsters[index] if monster.alive > 0: return monster def display_info(ultraman, monsters): \"\"\"显示奥特曼和小怪兽的信息\"\"\" print(ultraman) for monster in monsters: print(monster, end='') def main(): u = Ultraman('骆昊', 1000, 120) m1 = Monster('狄仁杰', 250) m2 = Monster('白元芳', 500) m3 = Monster('王大锤', 750) ms = [m1, m2, m3] fight_round = 1 while u.alive and is_any_alive(ms): print('========第%02d回合========' % fight_round) m = select_alive_one(ms) # 选中一只小怪兽 skill = randint(1, 10) # 通过随机数选择使用哪种技能 if skill 0: # 如果选中的小怪兽没有死就回击奥特曼 print('%s回击了%s.' % (m.name, u.name)) m.attack(u) display_info(u, ms) # 每个回合结束后显示奥特曼和小怪兽的信息 fight_round += 1 print('\\n========战斗结束!========\\n') if u.alive > 0: print('%s奥特曼胜利!' % u.name) else: print('小怪兽胜利!') if __name__ == '__main__': main() 案例2：扑克游戏 import random class Card(object): \"\"\"一张牌\"\"\" def __init__(self, suite, face): self._suite = suite self._face = face @property def face(self): return self._face @property def suite(self): return self._suite def __str__(self): if self._face == 1: face_str = 'A' elif self._face == 11: face_str = 'J' elif self._face == 12: face_str = 'Q' elif self._face == 13: face_str = 'K' else: face_str = str(self._face) return '%s%s' % (self._suite, face_str) def __repr__(self): return self.__str__() class Poker(object): \"\"\"一副牌\"\"\" def __init__(self): self._cards = [Card(suite, face) for suite in '♠♥♣♦' for face in range(1, 14)] self._current = 0 @property def cards(self): return self._cards def shuffle(self): \"\"\"洗牌(随机乱序)\"\"\" self._current = 0 random.shuffle(self._cards) @property def next(self): \"\"\"发牌\"\"\" card = self._cards[self._current] self._current += 1 return card @property def has_next(self): \"\"\"还有没有牌\"\"\" return self._current 说明：大家可以自己尝试在上面代码的基础上写一个简单的扑克游戏，例如21点(Black Jack)，游戏的规则可以自己在网上找一找。 案例3：工资结算系统 \"\"\" 某公司有三种类型的员工 分别是部门经理、程序员和销售员 需要设计一个工资结算系统 根据提供的员工信息来计算月薪 部门经理的月薪是每月固定15000元 程序员的月薪按本月工作时间计算 每小时150元 销售员的月薪是1200元的底薪加上销售额5%的提成 \"\"\" from abc import ABCMeta, abstractmethod class Employee(object, metaclass=ABCMeta): \"\"\"员工\"\"\" def __init__(self, name): \"\"\" 初始化方法 :param name: 姓名 \"\"\" self._name = name @property def name(self): return self._name @abstractmethod def get_salary(self): \"\"\" 获得月薪 :return: 月薪 \"\"\" pass class Manager(Employee): \"\"\"部门经理\"\"\" def get_salary(self): return 15000.0 class Programmer(Employee): \"\"\"程序员\"\"\" def __init__(self, name, working_hour=0): super().__init__(name) self._working_hour = working_hour @property def working_hour(self): return self._working_hour @working_hour.setter def working_hour(self, working_hour): self._working_hour = working_hour if working_hour > 0 else 0 def get_salary(self): return 150.0 * self._working_hour class Salesman(Employee): \"\"\"销售员\"\"\" def __init__(self, name, sales=0): super().__init__(name) self._sales = sales @property def sales(self): return self._sales @sales.setter def sales(self, sales): self._sales = sales if sales > 0 else 0 def get_salary(self): return 1200.0 + self._sales * 0.05 def main(): emps = [ Manager('刘备'), Programmer('诸葛亮'), Manager('曹操'), Salesman('荀彧'), Salesman('吕布'), Programmer('张辽'), Programmer('赵云') ] for emp in emps: if isinstance(emp, Programmer): emp.working_hour = int(input('请输入%s本月工作时间: ' % emp.name)) elif isinstance(emp, Salesman): emp.sales = float(input('请输入%s本月销售额: ' % emp.name)) # 同样是接收get_salary这个消息但是不同的员工表现出了不同的行为(多态) print('%s本月工资为: ￥%s元' % (emp.name, emp.get_salary())) if __name__ == '__main__': main() "},"Python/Python语言基础/09-图形用户界面和游戏开发.html":{"url":"Python/Python语言基础/09-图形用户界面和游戏开发.html","title":"图形用户界面和游戏开发","keywords":"","body":"datetime:2019/5/14 11:44 author:nzb 图形用户界面和游戏开发 基于tkinter模块的GUI GUI是图形用户界面的缩写，图形化的用户界面对使用过计算机的人来说应该都不陌生，在此也无需进行赘述。Python默认的GUI开发模块是tkinter（在Python 3以前的版本中名为Tkinter），从这个名字就可以看出它是基于Tk的，Tk是一个工具包，最初是为Tcl设计的，后来被移植到很多其他的脚本语言中，它提供了跨平台的GUI控件。当然Tk并不是最新和最好的选择，也没有功能特别强大的GUI控件，事实上，开发GUI应用并不是Python最擅长的工作，如果真的需要使用Python开发GUI应用，wxPython、PyQt、PyGTK等模块都是不错的选择。 基本上使用tkinter来开发GUI应用需要以下5个步骤： 导入tkinter模块中我们需要的东西。 创建一个顶层窗口对象并用它来承载整个GUI应用。 在顶层窗口对象上添加GUI组件。 通过代码将这些GUI组件的功能组织起来。 进入主事件循环(main loop)。 下面的代码演示了如何使用tkinter做一个简单的GUI应用。 import tkinter import tkinter.messagebox def main(): flag = True # 修改标签上的文字 def change_label_text(): nonlocal flag flag = not flag color, msg = ('red', 'Hello, world!')\\ if flag else ('blue', 'Goodbye, world!') label.config(text=msg, fg=color) # 确认退出 def confirm_to_quit(): if tkinter.messagebox.askokcancel('温馨提示', '确定要退出吗?'): top.quit() # 创建顶层窗口 top = tkinter.Tk() # 设置窗口大小 top.geometry('240x160') # 设置窗口标题 top.title('小游戏') # 创建标签对象并添加到顶层窗口 label = tkinter.Label(top, text='Hello, world!', font='Arial -32', fg='red') label.pack(expand=1) # 创建一个装按钮的容器 panel = tkinter.Frame(top) # 创建按钮对象 指定添加到哪个容器中 通过command参数绑定事件回调函数 button1 = tkinter.Button(panel, text='修改', command=change_label_text) button1.pack(side='left') button2 = tkinter.Button(panel, text='退出', command=confirm_to_quit) button2.pack(side='right') panel.pack(side='bottom') # 开启主事件循环 tkinter.mainloop() if __name__ == '__main__': main() 需要说明的是，GUI应用通常是事件驱动式的，之所以要进入主事件循环就是要监听鼠标、键盘等各种事件的发生并执行对应的代码对事件进行处理，因为事件会持续的发生，所以需要这样的一个循环一直运行着等待下一个事件的发生。另一方面，Tk为控件的摆放提供了三种布局管理器，通过布局管理器可以对控件进行定位，这三种布局管理器分别是：Placer（开发者提供控件的大小和摆放位置）、Packer（自动将控件填充到合适的位置）和Grid（基于网格坐标来摆放控件），此处不进行赘述。 使用Pygame进行游戏开发 Pygame是一个开源的Python模块，专门用于多媒体应用（如电子游戏）的开发，其中包含对图像、声音、视频、事件、碰撞等的支持。Pygame建立在SDL的基础上，SDL是一套跨平台的多媒体开发库，用C语言实现，被广泛的应用于游戏、模拟器、播放器等的开发。而Pygame让游戏开发者不再被底层语言束缚，可以更多的关注游戏的功能和逻辑。 下面我们来完成一个简单的小游戏，游戏的名字叫“大球吃小球”，当然完成这个游戏并不是重点，学会使用Pygame也不是重点，最重要的我们要在这个过程中体会如何使用前面讲解的面向对象程序设计，学会用这种编程思想去解决现实中的问题。 制作游戏窗口 import pygame def main(): # 初始化导入的pygame中的模块 pygame.init() # 初始化用于显示的窗口并设置窗口尺寸 screen = pygame.display.set_mode((800, 600)) # 设置当前窗口的标题 pygame.display.set_caption('大球吃小球') running = True # 开启一个事件循环处理发生的事件 while running: # 从消息队列中获取事件并对事件进行处理 for event in pygame.event.get(): if event.type == pygame.QUIT: running = False if __name__ == '__main__': main() 在窗口中绘图 可以通过pygame中draw模块的函数在窗口上绘图，可以绘制的图形包括：线条、矩形、多边形、圆、椭圆、圆弧等。需要说明的是，屏幕坐标系是将屏幕左上角设置为坐标原点(0, 0)，向右是x轴的正向，向下是y轴的正向，在表示位置或者设置尺寸的时候，我们默认的单位都是像素。所谓像素就是屏幕上的一个点，你可以用浏览图片的软件试着将一张图片放大若干倍，就可以看到这些点。pygame中表示颜色用的是色光三原色表示法，即通过一个元组或列表来指定颜色的RGB值，每个值都在0~255之间，因为是每种原色都用一个8位（bit）的值来表示，三种颜色相当于一共由24位构成，这也就是常说的“24位颜色表示法”。 import pygame def main(): # 初始化导入的pygame中的模块 pygame.init() # 初始化用于显示的窗口并设置窗口尺寸 screen = pygame.display.set_mode((800, 600)) # 设置当前窗口的标题 pygame.display.set_caption('大球吃小球') # 设置窗口的背景色(颜色是由红绿蓝三原色构成的元组) screen.fill((242, 242, 242)) # 绘制一个圆(参数分别是: 屏幕, 颜色, 圆心位置, 半径, 0表示填充圆) pygame.draw.circle(screen, (255, 0, 0,), (100, 100), 30, 0) # 刷新当前窗口(渲染窗口将绘制的图像呈现出来) pygame.display.flip() running = True # 开启一个事件循环处理发生的事件 while running: # 从消息队列中获取事件并对事件进行处理 for event in pygame.event.get(): if event.type == pygame.QUIT: running = False if __name__ == '__main__': main() 加载图像 如果需要直接加载图像到窗口上，可以使用pygame中image模块的函数来加载图像，再通过之前获得的窗口对象的blit方法渲染图像，代码如下所示。 import pygame def main(): # 初始化导入的pygame中的模块 pygame.init() # 初始化用于显示的窗口并设置窗口尺寸 screen = pygame.display.set_mode((800, 600)) # 设置当前窗口的标题 pygame.display.set_caption('大球吃小球') # 设置窗口的背景色(颜色是由红绿蓝三原色构成的元组) screen.fill((255, 255, 255)) # 通过指定的文件名加载图像 ball_image = pygame.image.load('./res/ball.png') # 在窗口上渲染图像 screen.blit(ball_image, (50, 50)) # 刷新当前窗口(渲染窗口将绘制的图像呈现出来) pygame.display.flip() running = True # 开启一个事件循环处理发生的事件 while running: # 从消息队列中获取事件并对事件进行处理 for event in pygame.event.get(): if event.type == pygame.QUIT: running = False if __name__ == '__main__': main() 实现动画效果 说到动画这个词大家都不会陌生，事实上要实现动画效果，本身的原理也非常简单，就是将不连续的图片连续的播放，只要每秒钟达到了一定的帧数，那么就可以做出比较流畅的动画效果。如果要让上面代码中的小球动起来，可以将小球的位置用变量来表示，并在循环中修改小球的位置再刷新整个窗口即可。 import pygame def main(): # 初始化导入的pygame中的模块 pygame.init() # 初始化用于显示的窗口并设置窗口尺寸 screen = pygame.display.set_mode((800, 600)) # 设置当前窗口的标题 pygame.display.set_caption('大球吃小球') # 定义变量来表示小球在屏幕上的位置 x, y = 50, 50 running = True # 开启一个事件循环处理发生的事件 while running: # 从消息队列中获取事件并对事件进行处理 for event in pygame.event.get(): if event.type == pygame.QUIT: running = False screen.fill((255, 255, 255)) pygame.draw.circle(screen, (255, 0, 0,), (x, y), 30, 0) pygame.display.flip() # 每隔50毫秒就改变小球的位置再刷新窗口 pygame.time.delay(50) x, y = x + 5, y + 5 if __name__ == '__main__': main() 碰撞检测 通常一个游戏中会有很多对象出现，而这些对象之间的“碰撞”在所难免，比如炮弹击中了飞机、箱子撞到了地面等。碰撞检测在绝大多数的游戏中都是一个必须得处理的至关重要的问题，pygame的sprite（动画精灵）模块就提供了对碰撞检测的支持，这里我们暂时不介绍sprite模块提供的功能，因为要检测两个小球有没有碰撞其实非常简单，只需要检查球心的距离有没有小于两个球的半径之和。为了制造出更多的小球，我们可以通过对鼠标事件的处理，在点击鼠标的位置创建颜色、大小和移动速度都随机的小球，当然要做到这一点，我们可以把之前学习到的面向对象的知识应用起来。 from enum import Enum, unique from math import sqrt from random import randint import pygame @unique class Color(Enum): \"\"\"颜色\"\"\" RED = (255, 0, 0) GREEN = (0, 255, 0) BLUE = (0, 0, 255) BLACK = (0, 0, 0) WHITE = (255, 255, 255) GRAY = (242, 242, 242) @staticmethod def random_color(): \"\"\"获得随机颜色\"\"\" r = randint(0, 255) g = randint(0, 255) b = randint(0, 255) return (r, g, b) class Ball(object): \"\"\"球\"\"\" def __init__(self, x, y, radius, sx, sy, color=Color.RED): \"\"\"初始化方法\"\"\" self.x = x self.y = y self.radius = radius self.sx = sx self.sy = sy self.color = color self.alive = True def move(self, screen): \"\"\"移动\"\"\" self.x += self.sx self.y += self.sy if self.x - self.radius = screen.get_width(): self.sx = -self.sx if self.y - self.radius = screen.get_height(): self.sy = -self.sy def eat(self, other): \"\"\"吃其他球\"\"\" if self.alive and other.alive and self != other: dx, dy = self.x - other.x, self.y - other.y distance = sqrt(dx ** 2 + dy ** 2) if distance other.radius: other.alive = False self.radius = self.radius + int(other.radius * 0.146) def draw(self, screen): \"\"\"在窗口上绘制球\"\"\" pygame.draw.circle(screen, self.color, (self.x, self.y), self.radius, 0) 事件处理 可以在事件循环中对鼠标事件进行处理，通过事件对象的type属性可以判定事件类型，再通过pos属性就可以获得鼠标点击的位置。如果要处理键盘事件也是在这个地方，做法与处理鼠标事件类似。 def main(): # 定义用来装所有球的容器 balls = [] # 初始化导入的pygame中的模块 pygame.init() # 初始化用于显示的窗口并设置窗口尺寸 screen = pygame.display.set_mode((800, 600)) # 设置当前窗口的标题 pygame.display.set_caption('大球吃小球') running = True # 开启一个事件循环处理发生的事件 while running: # 从消息队列中获取事件并对事件进行处理 for event in pygame.event.get(): if event.type == pygame.QUIT: running = False # 处理鼠标事件的代码 if event.type == pygame.MOUSEBUTTONDOWN and event.button == 1: # 获得点击鼠标的位置 x, y = event.pos radius = randint(10, 100) sx, sy = randint(-10, 10), randint(-10, 10) color = Color.random_color() # 在点击鼠标的位置创建一个球(大小、速度和颜色随机) ball = Ball(x, y, radius, sx, sy, color) # 将球添加到列表容器中 balls.append(ball) screen.fill((255, 255, 255)) # 取出容器中的球 如果没被吃掉就绘制 被吃掉了就移除 for ball in balls: if ball.alive: ball.draw(screen) else: balls.remove(ball) pygame.display.flip() # 每隔50毫秒就改变球的位置再刷新窗口 pygame.time.delay(50) for ball in balls: ball.move(screen) # 检查球有没有吃到其他的球 for other in balls: ball.eat(other) if __name__ == '__main__': main() 上面的两段代码合在一起，我们就完成了“大球吃小球”的游戏（如下图所示），准确的说它算不上一个游戏，但是做一个小游戏的基本知识我们已经通过这个例子告诉大家了，有了这些知识已经可以开始你的小游戏开发之旅了。其实上面的代码中还有很多值得改进的地方，比如刷新窗口以及让球移动起来的代码并不应该放在事件循环中，等学习了多线程的知识后，用一个后台线程来处理这些事可能是更好的选择。如果希望获得更好的用户体验，我们还可以在游戏中加入背景音乐以及在球与球发生碰撞时播放音效，利用pygame的mixer和music模块，我们可以很容易的做到这一点，大家可以自行了解这方面的知识。事实上，想了解更多的关于pygame的知识，最好的教程是pygame的官方网站，如果英语没毛病就可以赶紧去看看啦。 如果想开发3D游戏，pygame就显得力不从心了，对3D游戏开发如果有兴趣的读者不妨看看Panda3D。 "},"Python/Python语言基础/10-文件和异常.html":{"url":"Python/Python语言基础/10-文件和异常.html","title":"文件和异常","keywords":"","body":"datetime:2019/5/14 13:49 author:nzb 文件和异常 在实际开发中，常常需要对程序中的数据进行持久化操作，而实现数据持久化最直接简单的方式就是将数据保存到文件中。说到“文件”这个词，可能需要先科普一下关于文件系统的知识，对于这个概念，维基百科上给出了很好的诠释，这里不再浪费笔墨。 在Python中实现文件的读写操作其实非常简单，通过Python内置的open函数，我们可以指定文件名、操作模式、编码信息等来获得操作文件的对象，接下来就可以对文件进行读写操作了。这里所说的操作模式是指要打开什么样的文件（字符文件还是二进制文件）以及做什么样的操作（读、写还是追加），具体的如下表所示。 操作模式 具体含义 'r' 读取 （默认） 'w' 写入（会先截断之前的内容） 'x' 写入，如果文件已经存在会产生异常 'a' 追加，将内容写入到已有文件的末尾 'b' 二进制模式 't' 文本模式（默认） '+' 更新（既可以读又可以写） 下面这张图来自于菜鸟教程网站，它展示了如果根据应用程序的需要来设置操作模式。 读写文本文件 读取文本文件时，需要在使用open函数时指定好带路径的文件名（可以使用相对路径或绝对路径）并将文件模式设置为'r'（如果不指定，默认值也是'r'），然后通过encoding参数指定编码（如果不指定，默认值是None，那么在读取文件时使用的是操作系统默认的编码），如果不能保证保存文件时使用的编码方式与encoding参数指定的编码方式是一致的，那么就可能因无法解码字符而导致读取失败。下面的例子演示了如何读取一个纯文本文件。 def main(): f = open('致橡树.txt', 'r', encoding='utf-8') print(f.read()) f.close() if __name__ == '__main__': main() 请注意上面的代码，如果open函数指定的文件并不存在或者无法打开，那么将引发异常状况导致程序崩溃。为了让代码有一定的健壮性和容错性，我们可以使用Python的异常机制对可能在运行时发生状况的代码进行适当的处理，如下所示。 def main(): f = None try: f = open('致橡树.txt', 'r', encoding='utf-8') print(f.read()) except FileNotFoundError: print('无法打开指定的文件!') except LookupError: print('指定了未知的编码!') except UnicodeDecodeError: print('读取文件时解码错误!') finally: if f: f.close() if __name__ == '__main__': main() 在Python中，我们可以将那些在运行时可能会出现状况的代码放在try代码块中，在try代码块的后面可以跟上一个或多个except来捕获可能出现的异常状况。例如在上面读取文件的过程中，文件找不到会引发FileNotFoundError，指定了未知的编码会引发LookupError，而如果读取文件时无法按指定方式解码会引发UnicodeDecodeError，我们在try后面跟上了三个except分别处理这三种不同的异常状况。最后我们使用finally代码块来关闭打开的文件，释放掉程序中获取的外部资源，由于finally块的代码不论程序正常还是异常都会执行到（甚至是调用了sys模块的exit函数退出Python环境，finally块都会被执行，因为exit函数实质上是引发了SystemExit异常），因此我们通常把finally块称为“总是执行代码块”，它最适合用来做释放外部资源的操作。如果不愿意在finally代码块中关闭文件对象释放资源，也可以使用上下文语法，通过with关键字指定文件对象的上下文环境并在离开上下文环境时自动释放文件资源，代码如下所示。 def main(): try: with open('致橡树.txt', 'r', encoding='utf-8') as f: print(f.read()) except FileNotFoundError: print('无法打开指定的文件!') except LookupError: print('指定了未知的编码!') except UnicodeDecodeError: print('读取文件时解码错误!') if __name__ == '__main__': main() 除了使用文件对象的read方法读取文件之外，还可以使用for-in循环逐行读取或者用readlines方法将文件按行读取到一个列表容器中，代码如下所示。 import time def main(): # 一次性读取整个文件内容 with open('致橡树.txt', 'r', encoding='utf-8') as f: print(f.read()) # 通过for-in循环逐行读取 with open('致橡树.txt', mode='r') as f: for line in f: print(line, end='') time.sleep(0.5) print() # 读取文件按行读取到列表中 with open('致橡树.txt') as f: lines = f.readlines() print(lines) if __name__ == '__main__': main() 要将文本信息写入文件文件也非常简单，在使用open函数时指定好文件名并将文件模式设置为'w'即可。注意如果需要对文件内容进行追加式写入，应该将模式设置为'a'。如果要写入的文件不存在会自动创建文件而不是引发异常。下面的例子演示了如何将1-9999直接的素数分别写入三个文件中（1-99之间的素数保存在a.txt中，100-999之间的素数保存在b.txt中，1000-9999之间的素数保存在c.txt中）。 from math import sqrt def is_prime(n): \"\"\"判断素数的函数\"\"\" assert n > 0 for factor in range(2, int(sqrt(n)) + 1): if n % factor == 0: return False return True if n != 1 else False def main(): filenames = ('a.txt', 'b.txt', 'c.txt') fs_list = [] try: for filename in filenames: fs_list.append(open(filename, 'w', encoding='utf-8')) for number in range(1, 10000): if is_prime(number): if number 读写二进制文件 知道了如何读写文本文件要读写二进制文件也就很简单了，下面的代码实现了复制图片文件的功能。 def main(): try: with open('guido.jpg', 'rb') as fs1: data = fs1.read() print(type(data)) # with open('吉多.jpg', 'wb') as fs2: fs2.write(data) except FileNotFoundError as e: print('指定的文件无法打开.') except IOError as e: print('读写文件时出现错误.') print('程序执行结束.') if __name__ == '__main__': main() 读写JSON文件 通过上面的讲解，我们已经知道如何将文本数据和二进制数据保存到文件中，那么这里还有一个问题，如果希望把一个列表或者一个字典中的数据保存到文件中又该怎么做呢？答案是将数据以JSON格式进行保存。JSON是“JavaScript Object Notation”的缩写，它本来是JavaScript语言中创建对象的一种字面量语法，现在已经被广泛的应用于跨平台跨语言的数据交换，原因很简单，因为JSON也是纯文本，任何系统任何编程语言处理纯文本都是没有问题的。目前JSON基本上已经取代了XML作为异构系统间交换数据的事实标准。关于JSON的知识，更多的可以参考JSON的官方网站，从这个网站也可以了解到每种语言处理JSON数据格式可以使用的工具或三方库，下面是一个JSON的简单例子。 { 'name': '骆昊', 'age': 38, 'qq': 957658, 'friends': ['王大锤', '白元芳'], 'cars': [ {'brand': 'BYD', 'max_speed': 180}, {'brand': 'Audi', 'max_speed': 280}, {'brand': 'Benz', 'max_speed': 320} ] } 可能大家已经注意到了，上面的JSON跟Python中的字典其实是一样一样的，事实上JSON的数据类型和Python的数据类型是很容易找到对应关系的，如下面两张表所示。 JSON Python object dict array list string str number (int / real) int / float true / false True / False null None Python JSON dict object list, tuple array str string int, float, int- & float-derived Enums number True / False true / false None null 我们使用Python中的json模块就可以将字典或列表以JSON格式保存到文件中，代码如下所示。 import json def main(): mydict = { 'name': '骆昊', 'age': 38, 'qq': 957658, 'friends': ['王大锤', '白元芳'], 'cars': [ {'brand': 'BYD', 'max_speed': 180}, {'brand': 'Audi', 'max_speed': 280}, {'brand': 'Benz', 'max_speed': 320} ] } try: with open('data.json', 'w', encoding='utf-8') as fs: json.dump(mydict, fs) except IOError as e: print(e) print('保存数据完成!') if __name__ == '__main__': main() json模块主要有四个比较重要的函数，分别是： dump - 将Python对象按照JSON格式序列化到文件中 dumps - 将Python对象处理成JSON格式的字符串 load - 将文件中的JSON数据反序列化成对象 loads - 将字符串的内容反序列化成Python对象 这里出现了两个概念，一个叫序列化，一个叫反序列化。自由的百科全书维基百科上对这两个概念是这样解释的：“序列化（serialization）在计算机科学的数据处理中，是指将数据结构或对象状态转换为可以存储或传输的形式，这样在需要的时候能够恢复到原先的状态，而且通过序列化的数据重新获取字节时，可以利用这些字节来产生原始对象的副本（拷贝）。与这个过程相反的动作，即从一系列字节中提取数据结构的操作，就是反序列化（deserialization）”。 目前绝大多数网络数据服务（或称之为网络API）都是基于HTTP协议提供JSON格式的数据，关于HTTP协议的相关知识，可以看看阮一峰老师的《HTTP协议入门》，如果想了解国内的网络数据服务，可以看看聚合数据和阿凡达数据等网站，国外的可以看看{API}Search网站。下面的例子演示了如何使用requests模块（封装得足够好的第三方网络访问模块）访问网络API获取国内新闻，如何通过json模块解析JSON数据并显示新闻标题，这个例子使用了天行数据提供的国内新闻数据接口，其中的APIKey需要自己到该网站申请。 import requests import json def main(): resp = requests.get('http://api.tianapi.com/guonei/?key=APIKey&num=10') data_model = json.loads(resp.text) for news in data_model['newslist']: print(news['title']) if __name__ == '__main__': main() 在Python中要实现序列化和反序列化除了使用json模块之外，还可以使用pickle和shelve模块，但是这两个模块是使用特有的序列化协议来序列化数据，因此序列化后的数据只能被Python识别。关于这两个模块的相关知识可以自己看看网络上的资料。另外，如果要了解更多的关于Python异常机制的知识，可以看看segmentfault上面的文章《总结：Python中的异常处理》，这篇文章不仅介绍了Python中异常机制的使用，还总结了一系列的最佳实践，很值得一读。 "},"Python/Python语言基础/11-字符串和正则表达式.html":{"url":"Python/Python语言基础/11-字符串和正则表达式.html","title":"字符串和正则表达式","keywords":"","body":"datetime:2019/5/14 14:14 author:nzb 使用正则表达式 正则表达式相关知识 在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要，正则表达式就是用于描述这些规则的工具，换句话说正则表达式是一种工具，它定义了字符串的匹配模式（如何检查一个字符串是否有跟某种模式匹配的部分或者从一个字符串中将与模式匹配的部分提取出来或者替换掉）。如果你在Windows操作系统中使用过文件查找并且在指定文件名时使用过通配符（*和?），那么正则表达式也是与之类似的用来进行文本匹配的工具，只不过比起通配符正则表达式更强大，它能更精确地描述你的需求（当然你付出的代价是书写一个正则表达式比打出一个通配符要复杂得多，要知道任何给你带来好处的东西都是有代价的，就如同学习一门编程语言一样），比如你可以编写一个正则表达式，用来查找所有以0开头，后面跟着2-3个数字，然后是一个连字号“-”，最后是7或8位数字的字符串（像028-12345678或0813-7654321），这不就是国内的座机号码吗。最初计算机是为了做数学运算而诞生的，处理的信息基本上都是数值，而今天我们在日常工作中处理的信息基本上都是文本数据，我们希望计算机能够识别和处理符合某些模式的文本，正则表达式就显得非常重要了。今天几乎所有的编程语言都提供了对正则表达式操作的支持，Python通过标准库中的re模块来支持正则表达式操作。 我们可以考虑下面一个问题：我们从某个地方（可能是一个文本文件，也可能是网络上的一则新闻）获得了一个字符串，希望在字符串中找出手机号和座机号。当然我们可以设定手机号是11位的数字（注意并不是随机的11位数字，因为你没有见过“25012345678”这样的手机号吧）而座机号跟上一段中描述的模式相同，如果不使用正则表达式要完成这个任务就会很麻烦。 关于正则表达式的相关知识，大家可以阅读一篇非常有名的博客叫《正则表达式30分钟入门教程》，读完这篇文章后你就可以看懂下面的表格，这是我们对正则表达式中的一些基本符号进行的扼要总结。 符号 解释 示例 说明 . 匹配任意字符 b.t 可以匹配bat / but / b#t / b1t等 \\w 匹配字母/数字/下划线 b\\wt 可以匹配bat / b1t / b_t等但不能匹配b#t \\s 匹配空白字符（包括\\r、\\n、\\t等） love\\syou 可以匹配love you \\d 匹配数字 \\d\\d 可以匹配01 / 23 / 99等 \\b 匹配单词的边界 \\bThe\\b ^ 匹配字符串的开始 ^The 可以匹配The开头的字符串 $ 匹配字符串的结束 .exe$ 可以匹配.exe结尾的字符串 \\W 匹配非字母/数字/下划线 b\\Wt 可以匹配b#t / b@t等但不能匹配but / b1t / b_t等 \\S 匹配非空白字符 love\\Syou 可以匹配love#you等但不能匹配love you \\D 匹配非数字 \\d\\D 可以匹配9a / 3# / 0F等 \\B 匹配非单词边界 \\Bio\\B [] 匹配来自字符集的任意单一字符 [aeiou] 可以匹配任一元音字母字符 匹配不在字符集中的任意单一字符 aeiou 可以匹配任一非元音字母字符 * 匹配0次或多次 \\w* + 匹配1次或多次 \\w+ ? 匹配0次或1次 \\w? {N} 匹配N次 \\w{3} {M,} 匹配至少M次 \\w{3,} {M,N} 匹配至少M次至多N次 \\w{3,6} \\ 分支 foo\\ bar 可以匹配foo或者bar (?#) 注释 (exp) 匹配exp并捕获到自动命名的组中 (?exp) 匹配exp并捕获到名为name的组中 (?:exp) 匹配exp但是不捕获匹配的文本 (?=exp) 匹配exp前面的位置 \\b\\w+(?=ing) 可以匹配I'm dancing中的danc (? 匹配exp后面的位置 (? 可以匹配I love dancing and reading中的第一个ing (?!exp) 匹配后面不是exp的位置 (? 匹配前面不是exp的位置 *? 重复任意次，但尽可能少重复 a.*ba.*?b 将正则表达式应用于aabab，前者会匹配整个字符串aabab，后者会匹配aab和ab两个字符串 +? 重复1次或多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {M,N}? 重复M到N次，但尽可能少重复 {M,}? 重复M次以上，但尽可能少重复 说明：如果需要匹配的字符是正则表达式中的特殊字符，那么可以使用\\进行转义处理，例如想匹配小数点可以写成\\.就可以了，因为直接写.会匹配任意字符；同理，想匹配圆括号必须写成\\(和\\)，否则圆括号被视为正则表达式中的分组。 Python对正则表达式的支持 Python提供了re模块来支持正则表达式相关操作，下面是re模块中的核心函数。 函数 说明 compile(pattern, flags=0) 编译正则表达式返回正则表达式对象 match(pattern, string, flags=0) 用正则表达式匹配字符串 成功返回匹配对象 否则返回None search(pattern, string, flags=0) 搜索字符串中第一次出现正则表达式的模式 成功返回匹配对象 否则返回None split(pattern, string, maxsplit=0, flags=0) 用正则表达式指定的模式分隔符拆分字符串 返回列表 sub(pattern, repl, string, count=0, flags=0) 用指定的字符串替换原字符串中与正则表达式匹配的模式 可以用count指定替换的次数 fullmatch(pattern, string, flags=0) match函数的完全匹配（从字符串开头到结尾）版本 findall(pattern, string, flags=0) 查找字符串所有与正则表达式匹配的模式 返回字符串的列表 finditer(pattern, string, flags=0) 查找字符串所有与正则表达式匹配的模式 返回一个迭代器 purge() 清除隐式编译的正则表达式的缓存 re.I / re.IGNORECASE 忽略大小写匹配标记 re.M / re.MULTILINE 多行匹配标记 说明：上面提到的re模块中的这些函数，实际开发中也可以用正则表达式对象的方法替代对这些函数的使用，如果一个正则表达式需要重复的使用，那么先通过compile函数编译正则表达式并创建出正则表达式对象无疑是更为明智的选择。 下面我们通过一系列的例子来告诉大家在Python中如何使用正则表达式。 例子1：验证输入用户名和QQ号是否有效并给出对应的提示信息。 \"\"\" 验证输入用户名和QQ号是否有效并给出对应的提示信息 要求：用户名必须由字母、数字或下划线构成且长度在6~20个字符之间，QQ号是5~12的数字且首位不能为0 \"\"\" import re def main(): username = input('请输入用户名: ') qq = input('请输入QQ号: ') # match函数的第一个参数是正则表达式字符串或正则表达式对象 # 第二个参数是要跟正则表达式做匹配的字符串对象 m1 = re.match(r'^[0-9a-zA-Z_]{6,20}$', username) if not m1: print('请输入有效的用户名.') m2 = re.match(r'^[1-9]\\d{4,11}$', qq) if not m2: print('请输入有效的QQ号.') if m1 and m2: print('你输入的信息是有效的!') if __name__ == '__main__': main() 提示：上面在书写正则表达式时使用了“原始字符串”的写法（在字符串前面加上了r），所谓“原始字符串”就是字符串中的每个字符都是它原始的意义，说得更直接一点就是字符串中没有所谓的转义字符啦。因为正则表达式中有很多元字符和需要进行转义的地方，如果不使用原始字符串就需要将反斜杠写作\\\\，例如表示数字的\\d得书写成\\\\d，这样不仅写起来不方便，阅读的时候也会很吃力。 例子2：从一段文字中提取出国内手机号码。 下面这张图是截止到2017年底，国内三家运营商推出的手机号段。 import re def main(): # 创建正则表达式对象 使用了前瞻和回顾来保证手机号前后不应该出现数字 pattern = re.compile(r'(? 说明：上面匹配国内手机号的正则表达式并不够好，因为像14开头的号码只有145或147，而上面的正则表达式并没有考虑这种情况，要匹配国内手机号，更好的正则表达式的写法是：(?，国内最近好像有19和16开头的手机号了，但是这个暂时不在我们考虑之列。 例子3：替换字符串中的不良内容 import re def main(): sentence = '你丫是傻叉吗? 我操你大爷的. Fuck you.' purified = re.sub('[操肏艹]|fuck|shit|傻[比屄逼叉缺吊屌]|煞笔', '*', sentence, flags=re.IGNORECASE) print(purified) # 你丫是*吗? 我*你大爷的. * you. if __name__ == '__main__': main() 说明：re模块的正则表达式相关函数中都有一个flags参数，它代表了正则表达式的匹配标记，可以通过该标记来指定匹配时是否忽略大小写、是否进行多行匹配、是否显示调试信息等。如果需要为flags参数指定多个值，可以使用按位或运算符进行叠加，如flags=re.I | re.M。 例子4：拆分长字符串 import re def main(): poem = '窗前明月光，疑是地上霜。举头望明月，低头思故乡。' sentence_list = re.split(r'[，。, .]', poem) while '' in sentence_list: sentence_list.remove('') print(sentence_list) # ['窗前明月光', '疑是地上霜', '举头望明月', '低头思故乡'] if __name__ == '__main__': main() 后话 如果要从事爬虫类应用的开发，那么正则表达式一定是一个非常好的助手，因为它可以帮助我们迅速的从网页代码中发现某种我们指定的模式并提取出我们需要的信息，当然对于初学者来收，要编写一个正确的适当的正则表达式可能并不是一件容易的事情（当然有些常用的正则表达式可以直接在网上找找），所以实际开发爬虫应用的时候，有很多人会选择Beautiful Soup或Lxml来进行匹配和信息的提取，前者简单方便但是性能较差，后者既好用性能也好，但是安装稍嫌麻烦，这些内容我们会在后期的爬虫专题中为大家介绍。 "},"Python/Python语言基础/12-进程和线程.html":{"url":"Python/Python语言基础/12-进程和线程.html","title":"进程和线程","keywords":"","body":"datetime:2019/5/14 16:42 author:nzb 进程和线程 今天我们使用的计算机早已进入多CPU或多核时代，而我们使用的操作系统都是支持“多任务”的操作系统，这使得我们可以同时运行多个程序，也可以将一个程序分解为若干个相对独立的子任务，让多个子任务并发的执行，从而缩短程序的执行时间，同时也让用户获得更好的体验。因此在当下不管是用什么编程语言进行开发，实现让程序同时执行多个任务也就是常说的“并发编程”，应该是程序员必备技能之一。为此，我们需要先讨论两个概念，一个叫进程，一个叫线程。 概念 进程就是操作系统中执行的一个程序，操作系统以进程为单位分配存储空间，每个进程都有自己的地址空间、数据栈以及其他用于跟踪进程执行的辅助数据，操作系统管理所有进程的执行，为它们合理的分配资源。进程可以通过fork或spawn的方式来创建新的进程来执行其他的任务，不过新的进程也有自己独立的内存空间，因此必须通过进程间通信机制（IPC，Inter-Process Communication）来实现数据共享，具体的方式包括管道、信号、套接字、共享内存区等。 一个进程还可以拥有多个并发的执行线索，简单的说就是拥有多个可以获得CPU调度的执行单元，这就是所谓的线程。由于线程在同一个进程下，它们可以共享相同的上下文，因此相对于进程而言，线程间的信息共享和通信更加容易。当然在单核CPU系统中，真正的并发是不可能的，因为在某个时刻能够获得CPU的只有唯一的一个线程，多个线程共享了CPU的执行时间。使用多线程实现并发编程为程序带来的好处是不言而喻的，最主要的体现在提升程序的性能和改善用户体验，今天我们使用的软件几乎都用到了多线程技术，这一点可以利用系统自带的进程监控工具（如macOS中的“活动监视器”、Windows中的“任务管理器”）来证实，如下图所示。 当然多线程也并不是没有坏处，站在其他进程的角度，多线程的程序对其他程序并不友好，因为它占用了更多的CPU执行时间，导致其他程序无法获得足够的CPU执行时间；另一方面，站在开发者的角度，编写和调试多线程的程序都对开发者有较高的要求，对于初学者来说更加困难。 Python既支持多进程又支持多线程，因此使用Python实现并发编程主要有3种方式：多进程、多线程、多进程+多线程。 Python中的多进程 进程：程序运行在操作系统上的一个实例，就称之为进程。进程需要相应的系统资源：内存、时间片、pid。 Unix和Linux操作系统上提供了fork()系统调用来创建进程，调用fork()函数的是父进程，创建出的是子进程，子进程是父进程的一个拷贝，但是子进程拥有自己的PID。fork() 函数非常特殊它会返回两次，父进程中可以通过fork()函数的返回值得到子进程的PID，而子进程中的返回值永远都是0。Python的os模块提供了fork()函数。由于Windows系统没有fork() 调用，因此要实现跨平台的多进程编程，可以使用multiprocessing模块的Process类来创建子进程，而且该模块还提供了更高级的封装，例如批量启动进程的进程池（Pool）、用于进程间通信的队列（Queue ）和管道（Pipe）等。 下面用一个下载文件的例子来说明使用多进程和不使用多进程到底有什么差别，先看看下面的代码。 from random import randint from time import time, sleep def download_task(filename): print('开始下载%s...' % filename) time_to_download = randint(5, 10) sleep(time_to_download) print('%s下载完成! 耗费了%d秒' % (filename, time_to_download)) def main(): start = time() download_task('Python从入门到住院.pdf') download_task('Peking Hot.avi') end = time() print('总共耗费了%.2f秒.' % (end - start)) if __name__ == '__main__': main() 下面是运行程序得到的一次运行结果。 开始下载Python从入门到住院.pdf... Python从入门到住院.pdf下载完成! 耗费了6秒 开始下载Peking Hot.avi... Peking Hot.avi下载完成! 耗费了7秒 总共耗费了13.01秒. 从上面的例子可以看出，如果程序中的代码只能按顺序一点点的往下执行，那么即使执行两个毫不相关的下载任务，也需要先等待一个文件下载完成后才能开始下一个下载任务，很显然这并不合理也没有效率。接下来我们使用多进程的方式将两个下载任务放到不同的进程中，代码如下所示。 from multiprocessing import Process from os import getpid from random import randint from time import time, sleep def download_task(filename): print('启动下载进程，进程号[%d].' % getpid()) print('开始下载%s...' % filename) time_to_download = randint(5, 10) sleep(time_to_download) print('%s下载完成! 耗费了%d秒' % (filename, time_to_download)) def main(): start = time() p1 = Process(target=download_task, args=('Python从入门到住院.pdf',)) p1.start() p2 = Process(target=download_task, args=('Peking Hot.avi',)) p2.start() p1.join() p2.join() end = time() print('总共耗费了%.2f秒.' % (end - start)) if __name__ == '__main__': main() 在上面的代码中，我们通过Process类创建了进程对象，通过target参数我们传入一个函数来表示进程启动后要执行的代码，后面的args是一个元组，它代表了传递给函数的参数。Process对象的start 方法用来启动进程，而join方法表示等待进程执行结束。运行上面的代码可以明显发现两个下载任务“同时”启动了，而且程序的执行时间将大大缩短，不再是两个任务的时间总和。下面是程序的一次执行结果。 启动下载进程，进程号[1530]. 开始下载Python从入门到住院.pdf... 启动下载进程，进程号[1531]. 开始下载Peking Hot.avi... Peking Hot.avi下载完成! 耗费了7秒 Python从入门到住院.pdf下载完成! 耗费了10秒 总共耗费了10.01秒. 我们也可以使用subprocess模块中的类和函数来创建和启动子进程，然后通过管道来和子进程通信，这些内容我们不在此进行讲解，有兴趣的读者可以自己了解这些知识。接下来我们将重点放在如何实现两个进程间的通信。我们启动两个进程，一个输出Ping，一个输出Pong，两个进程输出的Ping和Pong加起来一共10个。听起来很简单吧，但是如果这样写可是错的哦。 from multiprocessing import Process from time import sleep counter = 0 def sub_task(string): global counter while counter 看起来没毛病，但是最后的结果是Ping和Pong各输出了10个，Why？当我们在程序中创建进程的时候，子进程复制了父进程及其所有的数据结构，每个子进程有自己独立的内存空间，这也就意味着两个子进程中各有一个counter 变量，所以结果也就可想而知了。要解决这个问题比较简单的办法是使用multiprocessing模块中的Queue类，它是可以被多个进程共享的队列，底层是通过管道和信号量（semaphore） 机制来实现的，有兴趣的读者可以自己尝试一下。 父进程和子进程 注意：进程间不共享全局变量 进程之间的通信-Queue 在初始化Queue()对象时（例如 q=Queue(),若在括号中没有指定最大可接受的消息数量，获数量为负值时，那么就代表可接受的消息数量没有上限一直到内存尽头） Queue.qsize()：返回当前队列包含的消息数量 Queue.empty()：如果队列为空，返回True，反之False Queue.full()：如果队列满了，返回True,反之False Queue.get([block[,timeout]])：获取队列中的一条消息，然后将其从队列中移除， block默认值为True。如果block使用默认值，且没有设置 timeout（单位秒）,消息队列如果为空， 此时程序将被阻塞（停在读中状态），直到消息队列读到消息为止，如果设置了 timeout，则会等待 timeout 秒， 若还没读取到任何消息，则抛出 Queue.Empty 异常： Queue.get_nowait() 相当于 Queue.get(False) Queue.put(item,[block[,timeout]])：将 item 消息写入队列，block 默认值为 True; 如果block使用默认值，且没有设置timeout（单位秒），消息队列如果已经没有空间可写入，此时程序将被阻塞（停在写入状态）， 直到从消息队列腾出空间为止，如果设置了 timeout，则会等待 timeout 秒，若还没空间，则抛出 Queue.Full 异常 如果block值为 False，消息队列如果没有空间可写入，则会立刻抛出 Queue.Full 异常; Queue.put_nowait(item)：相当 Queue.put(item,False) from multiprocessing import Process, Queue import os, time, random # 写数据进程执行的代码： def write(q): for value in ['A', 'B', 'C']: print(\"Put {} to queue...\".format(value)) q.put(value) time.sleep(0.5) # 读数据进程执行的代码 def read(q): while True: if not q.empty(): value = q.get(True) print(\"Get {} from queue.\".format(value)) time.sleep(0.5) else: break if __name__ == '__main__': # 父进程创建Queue，并传给各个子进程 q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw ，写入： pw.start() # 等待pw结束 pw.join() # 启动子进程pr，读取： pr.start() pr.join() # pr 进程里是死循环，无法等待其结束，只能强行终止: print('') print(os.getpid()) print('所有数据都写入并且读完') 进程池 from multiprocessing import Pool import os import time import random def worker(msg): t_start = time.time() print(\"%s开始执行,进程号为%d\" % (msg, os.getpid())) # random.random()随机生成0~1之间的浮点数 time.sleep(random.random() * 2) t_stop = time.time() print(msg, \"执行完毕，耗时%0.2f\" % (t_stop - t_start)) if __name__ == \"__main__\": po = Pool(3) # 定义一个进程池，最大进程数3 for i in range(0, 8): # Pool().apply_async(要调用的目标,(传递给目标的参数元祖,)) # 每次循环将会用空闲出来的子进程去调用目标 po.apply_async(worker, (i,)) print(\"----start----\") # 关闭进程池，关闭后po不再接收新的请求 po.close() # 等待po中所有子进程执行完成，必须放在close语句之后 po.join() print(\"-----end-----\") 进程池中使用 Queue 如果要使用 Pool 创建进程，就需要使用 multiprocessing.Manager() 中的 Queue() ,而不是 multiprocessing.Queue() ,否则会得到如下的错误信息： RuntimeError： Queue objects should only be shared between processs through inheritance from multiprocessing import Manager, Pool import os, time, random def reader(q): print(\"reader 启动(%s),父进程为（%s)\" % (os.getpid(), os.getpid())) for i in range(q.qsize()): print(\"reader 从Queue获取到消息:%s\" % q.get(True)) def writer(q): print(\"writer 启动（%s),父进程为(%s)\" % (os.getpid(), os.getpid())) for i in \"itcast\": q.put(i) if __name__ == \"__main__\": print(\"(%s)start\" % os.getpid()) q = Manager().Queue() # 使用Manager中的Queue po = Pool() po.apply_async(writer, (q,)) time.sleep(1) po.apply_async(reader, (q,)) po.close() po.join() print(\"(%s)End\" % os.getpid()) Python中的多线程 在Python早期的版本中就引入了thread模块（现在名为_ thread）来实现多线程编程，然而该模块过于底层，而且很多功能都没有提供，因此目前的多线程开发我们推荐使用threading模块，该模块对多线程编程提供了更好的面向对象的封装。我们把刚才下载文件的例子用多线程的方式来实现一遍。 from random import randint from threading import Thread from time import time, sleep def download(filename): print('开始下载%s...' % filename) time_to_download = randint(5, 10) sleep(time_to_download) print('%s下载完成! 耗费了%d秒' % (filename, time_to_download)) def main(): start = time() t1 = Thread(target=download, args=('Python从入门到住院.pdf',)) t1.start() t2 = Thread(target=download, args=('Peking Hot.avi',)) t2.start() t1.join() t2.join() end = time() print('总共耗费了%.3f秒' % (end - start)) if __name__ == '__main__': main() 我们可以直接使用threading模块的Thread类来创建线程，但是我们之前讲过一个非常重要的概念叫“继承”，我们可以从已有的类创建新类，因此也可以通过继承Thread 类的方式来创建自定义的线程类，然后再创建线程对象并启动线程。代码如下所示。 from random import randint from threading import Thread from time import time, sleep class DownloadTask(Thread): def __init__(self, filename): super().__init__() self._filename = filename def run(self): print('开始下载%s...' % self._filename) time_to_download = randint(5, 10) sleep(time_to_download) print('%s下载完成! 耗费了%d秒' % (self._filename, time_to_download)) def main(): start = time() # 将多个下载任务放到多个线程中执行 # 通过自定义的线程类创建线程对象 线程启动后会回调执行run方法 t1 = DownloadTask('Python从入门到住院.pdf') t1.start() t2 = DownloadTask('Peking Hot.avi') t2.start() t1.join() t2.join() end = time() print('总共耗费了%.2f秒.' % (end - start)) if __name__ == '__main__': main() 因为多个线程可以共享进程的内存空间，因此要实现多个线程间的通信相对简单，大家能想到的最直接的办法就是设置一个全局变量，多个线程共享这个全局变量即可。但是当多个线程共享同一个变量（我们通常称之为“资源”）的时候，很有可能产生不可控的结果从而导致程序失效甚至崩溃。如果一个资源被多个线程竞争使用，那么我们通常称之为“临界资源”，对“临界资源”的访问需要加上保护，否则资源会处于“混乱”的状态。下面的例子演示了100个线程向同一个银行账户转账（转入1元钱）的场景，在这个例子中，银行账户就是一个临界资源，在没有保护的情况下我们很有可能会得到错误的结果。 from time import sleep from threading import Thread class Account(object): def __init__(self): self._balance = 0 def deposit(self, money): # 计算存款后的余额 new_balance = self._balance + money # 模拟受理存款业务需要0.01秒的时间 sleep(0.01) # 修改账户余额 self._balance = new_balance @property def balance(self): return self._balance class AddMoneyThread(Thread): def __init__(self, account, money): super().__init__() self._account = account self._money = money def run(self): self._account.deposit(self._money) def main(): account = Account() threads = [] # 创建100个存款的线程向同一个账户中存钱 for _ in range(100): t = AddMoneyThread(account, 1) threads.append(t) t.start() # 等所有存款的线程都执行完毕 for t in threads: t.join() print('账户余额为: ￥%d元' % account.balance) if __name__ == '__main__': main() 运行上面的程序，结果让人大跌眼镜，100个线程分别向账户中转入1元钱，结果居然远远小于100元。之所以出现这种情况是因为我们没有对银行账户这个“临界资源”加以保护，多个线程同时向账户中存钱时，会一起执行到new_balance = self._balance + money 这行代码，多个线程得到的账户余额都是初始状态下的0，所以都是0 上面做了+1的操作，因此得到了错误的结果。在这种情况下，“锁”就可以派上用场了。我们可以通过“锁”来保护“临界资源”，只有获得“锁”的线程才能访问“临界资源”，而其他没有得到“锁”的线程只能被阻塞起来，直到获得“锁”的线程释放了“锁”，其他线程才有机会获得“锁”，进而访问被保护的“临界资源”。下面的代码演示了如何使用“锁”来保护对银行账户的操作，从而获得正确的结果。 from time import sleep from threading import Thread, Lock class Account(object): def __init__(self): self._balance = 0 self._lock = Lock() def deposit(self, money): # 先获取锁才能执行后续的代码 self._lock.acquire() try: new_balance = self._balance + money sleep(0.01) self._balance = new_balance finally: # 在finally中执行释放锁的操作保证正常异常锁都能释放 self._lock.release() @property def balance(self): return self._balance class AddMoneyThread(Thread): def __init__(self, account, money): super().__init__() self._account = account self._money = money def run(self): self._account.deposit(self._money) def main(): account = Account() threads = [] for _ in range(100): t = AddMoneyThread(account, 1) threads.append(t) t.start() for t in threads: t.join() print('账户余额为: ￥%d元' % account.balance) if __name__ == '__main__': main() 比较遗憾的一件事情是Python的多线程并不能发挥CPU的多核特性，这一点只要启动几个执行死循环的线程就可以得到证实了。之所以如此，是因为Python的解释器有一个“全局解释器锁”（GIL）的东西，任何线程执行前必须先获得GIL锁，然后每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行，这是一个历史遗留问题，但是即便如此，就如我们之前举的例子，使用多线程在提升执行效率和改善用户体验方面仍然是有积极意义的。 多进程还是多线程 无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？我们打个比方，假设你不幸正在准备中考，每天晚上需要做语文、数学、英语、物理、化学这5科的作业，每项作业耗时1小时。如果你先花1小时做语文作业，做完了，再花1小时做数学作业，这样，依次全部做完，一共花5小时，这种方式称为单任务模型。如果你打算切换到多任务模型，可以先做1分钟语文，再切换到数学作业，做1分钟，再切换到英语，以此类推，只要切换速度足够快，这种方式就和单核CPU执行多任务是一样的了，以旁观者的角度来看，你就正在同时写5科作业。 但是，切换作业是有代价的，比如从语文切到数学，要先收拾桌子上的语文书本、钢笔（这叫保存现场），然后，打开数学课本、找出圆规直尺（这叫准备新环境），才能开始做数学作业。操作系统在切换进程或者线程时也是一样的，它需要先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。所以，多任务一旦多到一个限度，反而会使得系统性能急剧下降，最终导致所有任务都做不好。 是否采用多任务的第二个考虑是任务的类型，可以把任务分为计算密集型和I/O密集型。计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如对视频进行编码解码或者格式转换等等，这种任务全靠CPU的运算能力，虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低。计算密集型任务由于主要消耗CPU资源，这类任务用Python这样的脚本语言去执行效率通常很低，最能胜任这类任务的是C语言，我们之前提到了Python中有嵌入C/C++代码的机制。 除了计算密集型任务，其他的涉及到网络、存储介质I/O的任务都可以视为I/O密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待I/O操作完成（因为I/O的速度远远低于CPU和内存的速度）。对于I/O密集型任务，如果启动多任务，就可以减少I/O等待时间从而让CPU高效率的运转。有一大类的任务都属于I/O密集型任务，这其中包括了我们很快会涉及到的网络应用和Web应用。 说明：上面的内容和例子来自于廖雪峰官方网站的《Python教程》，因为对作者文中的某些观点持有不同的看法，对原文的文字描述做了适当的调整。 单线程+异步I/O 现代操作系统对I/O操作的改进中最为重要的就是支持异步I/O。如果充分利用操作系统提供的异步I/O支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型。Nginx就是支持异步I/O的Web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务。在多核CPU上，可以运行多个进程（数量与CPU核心数相同），充分利用多核CPU。用Node.js开发的服务器端程序也使用了这种工作模式，这也是当下实现多任务编程的一种趋势。 在Python语言中，单线程+异步I/O的编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。协程最大的优势就是极高的执行效率，因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销。协程的第二个优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不用加锁，只需要判断状态就好了，所以执行效率比多线程高很多。如果想要充分利用CPU的多核特性，最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。关于这方面的内容，我稍后会做一个专题来进行讲解。 应用案例 例子1：将耗时间的任务放到线程中以获得更好的用户体验。 如下所示的界面中，有“下载”和“关于”两个按钮，用休眠的方式模拟点击“下载”按钮会联网下载文件需要耗费10秒的时间，如果不使用“多线程”，我们会发现，当点击“下载”按钮后整个程序的其他部分都被这个耗时间的任务阻塞而无法执行了，这显然是非常糟糕的用户体验，代码如下所示。 import time import tkinter import tkinter.messagebox def download(): # 模拟下载任务需要花费10秒钟时间 time.sleep(10) tkinter.messagebox.showinfo('提示', '下载完成!') def show_about(): tkinter.messagebox.showinfo('关于', '作者: 骆昊(v1.0)') def main(): top = tkinter.Tk() top.title('单线程') top.geometry('200x150') top.wm_attributes('-topmost', True) panel = tkinter.Frame(top) button1 = tkinter.Button(panel, text='下载', command=download) button1.pack(side='left') button2 = tkinter.Button(panel, text='关于', command=show_about) button2.pack(side='right') panel.pack(side='bottom') tkinter.mainloop() if __name__ == '__main__': main() 如果使用多线程将耗时间的任务放到一个独立的线程中执行，这样就不会因为执行耗时间的任务而阻塞了主线程，修改后的代码如下所示。 import time import tkinter import tkinter.messagebox from threading import Thread def main(): class DownloadTaskHandler(Thread): def run(self): time.sleep(10) tkinter.messagebox.showinfo('提示', '下载完成!') # 启用下载按钮 button1.config(state=tkinter.NORMAL) def download(): # 禁用下载按钮 button1.config(state=tkinter.DISABLED) # 通过daemon参数将线程设置为守护线程(主程序退出就不再保留执行) # 在线程中处理耗时间的下载任务 DownloadTaskHandler(daemon=True).start() def show_about(): tkinter.messagebox.showinfo('关于', '作者: 骆昊(v1.0)') top = tkinter.Tk() top.title('单线程') top.geometry('200x150') top.wm_attributes('-topmost', 1) panel = tkinter.Frame(top) button1 = tkinter.Button(panel, text='下载', command=download) button1.pack(side='left') button2 = tkinter.Button(panel, text='关于', command=show_about) button2.pack(side='right') panel.pack(side='bottom') tkinter.mainloop() if __name__ == '__main__': main() 例子2：使用多进程对复杂任务进行“分而治之”。 我们来完成1~100000000求和的计算密集型任务，这个问题本身非常简单，有点循环的知识就能解决，代码如下所示。 from time import time def main(): total = 0 number_list = [x for x in range(1, 100000001)] start = time() for number in number_list: total += number print(total) end = time() print('Execution time: %.3fs' % (end - start)) if __name__ == '__main__': main() 在上面的代码中，我故意先去创建了一个列表容器然后填入了100000000个数，这一步其实是比较耗时间的，所以为了公平起见，当我们将这个任务分解到8个进程中去执行的时候，我们暂时也不考虑列表切片操作花费的时间，只是把做运算和合并运算结果的时间统计出来，代码如下所示。 from multiprocessing import Process, Queue from random import randint from time import time def task_handler(curr_list, result_queue): total = 0 for number in curr_list: total += number result_queue.put(total) def main(): processes = [] number_list = [x for x in range(1, 100000001)] result_queue = Queue() index = 0 # 启动8个进程将数据切片后进行运算 for _ in range(8): p = Process(target=task_handler, args=(number_list[index:index + 12500000], result_queue)) index += 12500000 processes.append(p) p.start() # 开始记录所有进程执行完成花费的时间 start = time() for p in processes: p.join() # 合并执行结果 total = 0 while not result_queue.empty(): total += result_queue.get() print(total) end = time() print('Execution time: ', (end - start), 's', sep='') if __name__ == '__main__': main() 比较两段代码的执行结果（在我目前使用的MacBook上，上面的代码需要大概6秒左右的时间，而下面的代码只需要不到1秒的时间，再强调一次我们只是比较了运算的时间，不考虑列表创建及切片操作花费的时间），使用多进程后由于获得了更多的CPU执行时间以及更好的利用了CPU的多核特性，明显的减少了程序的执行时间，而且计算量越大效果越明显。当然，如果愿意还可以将多个进程部署在不同的计算机上，做成分布式进程，具体的做法就是通过multiprocessing.managers模块中提供的管理器将Queue 对象通过网络共享出来（注册到网络上让其他计算机可以访问），这部分内容也留到爬虫的专题再进行讲解。 示例代码： 异步I/O操作 - asyncio模块 import asyncio import threading # import time @asyncio.coroutine def hello(): print('%s: hello, world!' % threading.current_thread()) # 休眠不会阻塞主线程因为使用了异步I/O操作 # 注意有yield from才会等待休眠操作执行完成 yield from asyncio.sleep(2) # asyncio.sleep(1) # time.sleep(1) print('%s: goodbye, world!' % threading.current_thread()) loop = asyncio.get_event_loop() tasks = [hello(), hello()] # 等待两个异步I/O操作执行结束 loop.run_until_complete(asyncio.wait(tasks)) print('game over!') loop.close() 异步I/O操作 - async和await import asyncio import threading # 通过async修饰的函数不再是普通函数而是一个协程 # 注意async和await将在Python 3.7中作为关键字出现 async def hello(): print('%s: hello, world!' % threading.current_thread()) await asyncio.sleep(2) print('%s: goodbye, world!' % threading.current_thread()) loop = asyncio.get_event_loop() tasks = [hello(), hello()] # 等待两个异步I/O操作执行结束 loop.run_until_complete(asyncio.wait(tasks)) loop.close() 异步I/O操作 - asyncio模块 import asyncio async def wget(host): print('wget %s...' % host) connect = asyncio.open_connection(host, 80) # 异步方式等待连接结果 reader, writer = await connect header = 'GET / HTTP/1.0\\r\\nHost: %s\\r\\n\\r\\n' % host writer.write(header.encode('utf-8')) # 异步I/O方式执行写操作 await writer.drain() while True: # 异步I/O方式执行读操作 line = await reader.readline() if line == b'\\r\\n': break print('%s header > %s' % (host, line.decode('utf-8').rstrip())) writer.close() loop = asyncio.get_event_loop() # 通过生成式语法创建一个装了三个协程的列表 hosts_list = ['www.sina.com.cn', 'www.sohu.com', 'www.163.com'] tasks = [wget(host) for host in hosts_list] # 下面的方法将异步I/O操作放入EventLoop直到执行完毕 loop.run_until_complete(asyncio.wait(tasks)) loop.close() 使用协程 - 模拟快递中心派发快递 from time import sleep from random import random def build_deliver_man(man_id): total = 0 while True: total += 1 print('%d号快递员准备接今天的第%d单.' % (man_id, total)) pkg = yield print('%d号快递员收到编号为%s的包裹.' % (man_id, pkg)) sleep(random() * 3) def package_center(deliver_man, max_per_day): num = 1 deliver_man.send(None) # next(deliver_man) while num 使用协程 - 查看协程的状态 from time import sleep from inspect import getgeneratorstate def build_deliver_man(man_id): total = 0 while True: total += 1 print('%d号快递员准备接今天的第%d单.' % (man_id, total)) pkg = yield print('%d号快递员收到编号为%s的包裹.' % (man_id, pkg)) sleep(0.5) def package_center(deliver_man, max_per_day): num = 1 # 创建状态(GEN_CREATED) - 等待开始执行 print(getgeneratorstate(deliver_man)) deliver_man.send(None) # 挂起状态(GEN_SUSPENDED) - 在yield表达式处暂停 print(getgeneratorstate(deliver_man)) # next(deliver_man) while num 使用Process类创建多个进程 # 通过下面程序的执行结果可以证实 父进程在创建子进程时复制了进程及其数据结构 # 每个进程都有自己独立的内存空间 所以进程之间共享数据只能通过IPC的方式 from multiprocessing import Process, Queue from time import sleep def sub_task(string, q): number = q.get() while number: print('%d: %s' % (number, string)) sleep(0.001) number = q.get() def main(): q = Queue(10) for number in range(1, 11): q.put(number) Process(target=sub_task, args=('Ping', q)).start() Process(target=sub_task, args=('Pong', q)).start() if __name__ == '__main__': main() 实现进程间的通信 import multiprocessing import os def sub_task(queue): print('子进程进程号:', os.getpid()) counter = 0 while counter 创建进程调用其他程序 import subprocess import sys def main(): # 通过sys.argv获取命令行参数 if len(sys.argv) > 1: # 第一个命令行参数是程序本身所以从第二个开始取 for index in range(1, len(sys.argv)): try: # 通过subprocess模块的call函数启动子进程 status = subprocess.call(sys.argv[index]) except FileNotFoundError: print('不能执行%s命令' % sys.argv[index]) else: print('请使用命令行参数指定要执行的进程') if __name__ == '__main__': main() 使用多线程的情况 - 模拟多个下载任务 from random import randint from time import time, sleep import atexit import _thread def download_task(filename): print('开始下载%s...' % filename) time_to_download = randint(5, 10) print('剩余时间%d秒.' % time_to_download) sleep(time_to_download) print('%s下载完成!' % filename) def shutdown_hook(start): end = time() print('总共耗费了%.3f秒.' % (end - start)) def main(): start = time() # 将多个下载任务放到多个线程中执行 thread1 = _thread.start_new_thread(download_task, ('Python从入门到住院.pdf',)) thread2 = _thread.start_new_thread(download_task, ('Peking Hot.avi',)) # 注册关机钩子在程序执行结束前计算执行时间 atexit.register(shutdown_hook, start) if __name__ == '__main__': main() # 执行这里的代码会引发致命错误(不要被这个词吓到) 因为主线程结束后下载线程再想执行就会出问题 # 需要说明一下 由于_thread模块属于比较底层的线程操作而且不支持守护线程的概念 # 在实际开发中会有诸多不便 因此我们推荐使用threading模块提供的高级操作进行多线程编程 "},"Python/Python语言基础/13-网络编程入门.html":{"url":"Python/Python语言基础/13-网络编程入门.html","title":"网络编程入门","keywords":"","body":"datetime:2019/5/14 17:35 author:nzb 网络编程入门 计算机网络基础 计算机网络是独立自主的计算机互联而成的系统的总称，组建计算机网络最主要的目的是实现多台计算机之间的通信和资源共享。今天计算机网络中的设备和计算机网络的用户已经多得不可计数，而计算机网络也可以称得上是一个“复杂巨系统”，对于这样的系统，我们不可能用一两篇文章把它讲清楚，有兴趣的读者可以自行阅读Andrew S.Tanenbaum老师的经典之作《计算机网络》或Kurose和Ross老师合著的《计算机网络:自顶向下方法》来了解计算机网络的相关知识。 计算机网络发展史 1960s - 美国国防部ARPANET项目问世，奠定了分组交换网络的基础。 1980s - 国际标准化组织（ISO）发布OSI/RM，奠定了网络技术标准化的基础。 1990s - 英国人蒂姆·伯纳斯-李发明了图形化的浏览器，浏览器的简单易用性使得计算机网络迅速被普及。 在没有浏览器的年代，上网是这样的。 有了浏览器以后，上网是这样的。 TCP/IP模型 实现网络通信的基础是网络通信协议，这些协议通常是由互联网工程任务组 （IETF）制定的。所谓“协议”就是通信计算机双方必须共同遵从的一组约定，例如怎样建立连接、怎样互相识别等，网络协议的三要素是：语法、语义和时序。构成我们今天使用的Internet的基础的是TCP/IP协议族，所谓协议族就是一系列的协议及其构成的通信模型，我们通常也把这套东西称为TCP/IP模型。与国际标准化组织发布的OSI/RM这个七层模型不同，TCP/IP是一个四层模型，也就是说，该模型将我们使用的网络从逻辑上分解为四个层次，自底向上依次是：网络接口层、网络层、传输层和应用层，如下图所示。 IP通常被翻译为网际协议，它服务于网络层，主要实现了寻址和路由的功能。接入网络的每一台主机都需要有自己的IP地址，IP地址就是主机在计算机网络上的身份标识。当然由于IPv4地址的匮乏，我们平常在家里、办公室以及其他可以接入网络的公共区域上网时获得的IP地址并不是全球唯一的IP地址，而是一个局域网（LAN）中的内部IP地址，通过网络地址转换（NAT）服务我们也可以实现对网络的访问。计算机网络上有大量的被我们称为“路由器”的网络中继设备，它们会存储转发我们发送到网络上的数据分组，让从源头发出的数据最终能够找到传送到目的地通路，这项功能就是所谓的路由。 TCP全称传输控制协议，它是基于IP提供的寻址和路由服务而建立起来的负责实现端到端可靠传输的协议，之所以将TCP称为可靠的传输协议是因为TCP向调用者承诺了三件事情： 数据不传丢不传错（利用握手、校验和重传机制可以实现）。 流量控制（通过滑动窗口匹配数据发送者和接收者之间的传输速度）。 拥塞控制（通过RTT时间以及对滑动窗口的控制缓解网络拥堵）。 网络应用模式 C/S模式和B/S模式。这里的C指的是Client（客户端），通常是一个需要安装到某个宿主操作系统上的应用程序；而B指的是Browser（浏览器），它几乎是所有图形化操作系统都默认安装了的一个应用软件；通过C或B都可以实现对S（服务器）的访问。关于二者的比较和讨论在网络上有一大堆的文章，在此我们就不再浪费笔墨了。 去中心化的网络应用模式。不管是B/S还是C/S都需要服务器的存在，服务器就是整个应用模式的中心，而去中心化的网络应用通常没有固定的服务器或者固定的客户端，所有应用的使用者既可以作为资源的提供者也可以作为资源的访问者。 基于HTTP协议的网络资源访问 HTTP（超文本传输协议） HTTP是超文本传输协议（Hyper-Text Transfer Proctol）的简称，维基百科上对HTTP的解释是：超文本传输协议是一种用于分布式、协作式和超媒体信息系统的应用层协议，它是万维网数据通信的基础，设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法，通过HTTP或者HTTPS（超文本传输安全协议）请求的资源由URI（统一资源标识符）来标识。关于HTTP的更多内容，我们推荐阅读阮一峰老师的《HTTP 协议入门》，简单的说，通过HTTP我们可以获取网络上的（基于字符的）资源，开发中经常会用到的网络API（有的地方也称之为网络数据接口）就是基于HTTP来实现数据传输的。 JSON格式 JSON（JavaScript Object Notation）是一种轻量级的数据交换语言，该语言以易于让人阅读的文字（纯文本）为基础，用来传输由属性值或者序列性的值组成的数据对象。尽管JSON是最初只是Javascript中一种创建对象的字面量语法，但它在当下更是一种独立于语言的数据格式，很多编程语言都支持JSON格式数据的生成和解析，Python内置的json模块也提供了这方面的功能。由于JSON是纯文本，它和XML一样都适用于异构系统之间的数据交换，而相较于XML，JSON显得更加的轻便和优雅。下面是表达同样信息的XML和JSON，而JSON的优势是相当直观的。 XML的例子： Alice Bob Will you marry me? JSON的例子： { 'from': 'Alice', 'to': 'Bob', 'content': 'Will you marry me?' } requests库 requests是一个基于HTTP协议来使用网络的第三库，其官方网站有这样的一句介绍它的话：“Requests是唯一的一个非转基因的Python HTTP库，人类可以安全享用。”简单的说，使用requests库可以非常方便的使用HTTP，避免安全缺陷、冗余代码以及“重复发明轮子”（行业黑话，通常用在软件工程领域表示重新创造一个已有的或是早已被优化過的基本方法）。前面的文章中我们已经使用过这个库，下面我们还是通过requests来实现一个访问网络数据接口并从中获取美女图片下载链接然后下载美女图片到本地的例子程序，程序中使用了天行数据提供的网络API。 我们可以先通过pip安装requests及其依赖库。 pip install requests 如果使用PyCharm作为开发工具，可以直接在代码中书写import requests，然后通过代码修复功能来自动下载安装requests。 from time import time from threading import Thread import requests # 继承Thread类创建自定义的线程类 class DownloadHanlder(Thread): def __init__(self, url): super().__init__() self.url = url def run(self): filename = self.url[self.url.rfind('/') + 1:] resp = requests.get(self.url) with open('/Users/Hao/' + filename, 'wb') as f: f.write(resp.content) def main(): # 通过requests模块的get函数获取网络资源 # 下面的代码中使用了天行数据接口提供的网络API # 要使用该数据接口需要在天行数据的网站上注册 # 然后用自己的Key替换掉下面代码的中APIKey即可 resp = requests.get( 'http://api.tianapi.com/meinv/?key=APIKey&num=10') # 将服务器返回的JSON格式的数据解析为字典 data_model = resp.json() for mm_dict in data_model['newslist']: url = mm_dict['picUrl'] # 通过多线程的方式实现图片下载 DownloadHanlder(url).start() if __name__ == '__main__': main() 基于传输层协议的套接字编程 套接字这个词对很多不了解网络编程的人来说显得非常晦涩和陌生，其实说得通俗点，套接字就是一套用C语言写成的应用程序开发库，主要用于实现进程间通信和网络编程，在网络应用开发中被广泛使用。在Python中也可以基于套接字来使用传输层提供的传输服务，并基于此开发自己的网络应用。实际开发中使用的套接字可以分为三类：流套接字（TCP套接字）、数据报套接字和原始套接字。 TCP套接字 所谓TCP套接字就是使用TCP协议提供的传输服务来实现网络通信的编程接口。在Python中可以通过创建socket对象并指定type属性为SOCK_STREAM来使用TCP套接字。由于一台主机可能拥有多个IP地址，而且很有可能会配置多个不同的服务，所以作为服务器端的程序，需要在创建套接字对象后将其绑定到指定的IP地址和端口上。这里的端口并不是物理设备而是对IP地址的扩展，用于区分不同的服务，例如我们通常将HTTP服务跟80端口绑定，而MySQL数据库服务默认绑定在3306端口，这样当服务器收到用户请求时就可以根据端口号来确定到底用户请求的是HTTP服务器还是数据库服务器提供的服务。端口的取值范围是0~65535，而1024以下的端口我们通常称之为“著名端口”（留给像FTP、HTTP、SMTP等“著名服务”使用的端口，有的地方也称之为“周知端口”），自定义的服务通常不使用这些端口，除非自定义的是HTTP或FTP这样的著名服务。 下面的代码实现了一个提供时间日期的服务器。 from socket import socket, SOCK_STREAM, AF_INET from datetime import datetime def main(): # 1.创建套接字对象并指定使用哪种传输服务 # family=AF_INET - IPv4地址 # family=AF_INET6 - IPv6地址 # type=SOCK_STREAM - TCP套接字 # type=SOCK_DGRAM - UDP套接字 # type=SOCK_RAW - 原始套接字 server = socket(family=AF_INET, type=SOCK_STREAM) # 2.绑定IP地址和端口(端口用于区分不同的服务) # 同一时间在同一个端口上只能绑定一个服务否则报错 server.bind(('192.168.1.2', 6789)) # 3.开启监听 - 监听客户端连接到服务器 # 参数512可以理解为连接队列的大小 server.listen(512) print('服务器启动开始监听...') while True: # 4.通过循环接收客户端的连接并作出相应的处理(提供服务) # accept方法是一个阻塞方法如果没有客户端连接到服务器代码不会向下执行 # accept方法返回一个元组其中的第一个元素是客户端对象 # 第二个元素是连接到服务器的客户端的地址(由IP和端口两部分构成) client, addr = server.accept() print(str(addr) + '连接到了服务器.') # 5.发送数据 client.send(str(datetime.now()).encode('utf-8')) # 6.断开连接 client.close() if __name__ == '__main__': main() 运行服务器程序后我们可以通过Windows系统的telnet来访问该服务器，结果如下图所示。 telnet 192.168.1.2 6789 当然我们也可以通过Python的程序来实现TCP客户端的功能，相较于实现服务器程序，实现客户端程序就简单多了，代码如下所示。 from socket import socket def main(): # 1.创建套接字对象默认使用IPv4和TCP协议 client = socket() # 2.连接到服务器(需要指定IP地址和端口) client.connect(('192.168.1.2', 6789)) # 3.从服务器接收数据 print(client.recv(1024).decode('utf-8')) client.close() if __name__ == '__main__': main() 需要注意的是，上面的服务器并没有使用多线程或者异步I/O的处理方式，这也就意味着当服务器与一个客户端处于通信状态时，其他的客户端只能排队等待。很显然，这样的服务器并不能满足我们的需求，我们需要的服务器是能够同时接纳和处理多个用户请求的。下面我们来设计一个使用多线程技术处理多个用户请求的服务器，该服务器会向连接到服务器的客户端发送一张图片。 服务器端代码： from socket import socket, SOCK_STREAM, AF_INET from base64 import b64encode from json import dumps from threading import Thread def main(): # 自定义线程类 class FileTransferHandler(Thread): def __init__(self, cclient): super().__init__() self.cclient = cclient def run(self): my_dict = {} my_dict['filename'] = 'guido.jpg' # JSON是纯文本不能携带二进制数据 # 所以图片的二进制数据要处理成base64编码 my_dict['filedata'] = data # 通过dumps函数将字典处理成JSON字符串 json_str = dumps(my_dict) # 发送JSON字符串 self.cclient.send(json_str.encode('utf-8')) self.cclient.close() # 1.创建套接字对象并指定使用哪种传输服务 server = socket() # 2.绑定IP地址和端口(区分不同的服务) server.bind(('192.168.1.2', 5566)) # 3.开启监听 - 监听客户端连接到服务器 server.listen(512) print('服务器启动开始监听...') with open('guido.jpg', 'rb') as f: # 将二进制数据处理成base64再解码成字符串 data = b64encode(f.read()).decode('utf-8') while True: client, addr = server.accept() # 启动一个线程来处理客户端的请求 FileTransferHandler(client).start() if __name__ == '__main__': main() 客户端代码： from socket import socket from json import loads from base64 import b64decode def main(): client = socket() client.connect(('192.168.1.2', 5566)) # 定义一个保存二进制数据的对象 in_data = bytes() # 由于不知道服务器发送的数据有多大每次接收1024字节 data = client.recv(1024) while data: # 将收到的数据拼接起来 in_data += data data = client.recv(1024) # 将收到的二进制数据解码成JSON字符串并转换成字典 # loads函数的作用就是将JSON字符串转成字典对象 my_dict = loads(in_data.decode('utf-8')) filename = my_dict['filename'] filedata = my_dict['filedata'].encode('utf-8') with open('/Users/Hao/' + filename, 'wb') as f: # 将base64格式的数据解码成二进制数据并写入文件 f.write(b64decode(filedata)) print('图片已保存.') if __name__ == '__main__': main() 在这个案例中，我们使用了JSON作为数据传输的格式（通过JSON格式对传输的数据进行了序列化和反序列化的操作），但是JSON并不能携带二进制数据，因此对图片的二进制数据进行了Base64编码的处理。Base64是一种用64个字符表示所有二进制数据的编码方式，通过将二进制数据每6位一组的方式重新组织，刚好可以使用0~9的数字、大小写字母以及“+”和“/”总共64个字符表示从000000到111111的64种状态。维基百科上有关于Base64编码的详细讲解，不熟悉Base64的读者可以自行阅读。 说明：上面的代码主要为了讲解网络编程的相关内容因此并没有对异常状况进行处理，请读者自行添加异常处理代码来增强程序的健壮性。 UDP套接字 传输层除了有可靠的传输协议TCP之外，还有一种非常轻便的传输协议叫做用户数据报协议，简称UDP。TCP和UDP都是提供端到端传输服务的协议，二者的差别就如同打电话和发短信的区别，后者不对传输的可靠性和可达性做出任何承诺从而避免了TCP中握手和重传的开销，所以在强调性能和而不是数据完整性的场景中（例如传输网络音视频数据），UDP可能是更好的选择。可能大家会注意到一个现象，就是在观看网络视频时，有时会出现卡顿，有时会出现花屏，这无非就是部分数据传丢或传错造成的。在Python中也可以使用UDP套接字来创建网络应用，对此我们不进行赘述，有兴趣的读者可以自行研究。 "},"Python/Python语言基础/14-网络应用开发.html":{"url":"Python/Python语言基础/14-网络应用开发.html","title":"网络应用开发","keywords":"","body":"datetime:2019/5/14 17:51 author:nzb 网络应用开发 发送电子邮件 在即时通信软件如此发达的今天，电子邮件仍然是互联网上使用最为广泛的应用之一，公司向应聘者发出录用通知、网站向用户发送一个激活账号的链接、银行向客户推广它们的理财产品等几乎都是通过电子邮件来完成的，而这些任务应该都是由程序自动完成的。 就像我们可以用HTTP（超文本传输协议）来访问一个网站一样，发送邮件要使用SMTP（简单邮件传输协议），SMTP也是一个建立在TCP（传输控制协议）提供的可靠数据传输服务的基础上的应用级协议，它规定了邮件的发送者如何跟发送邮件的服务器进行通信的细节，而Python中的smtplib模块将这些操作简化成了几个简单的函数。 下面的代码演示了如何在Python发送邮件。 from smtplib import SMTP from email.header import Header from email.mime.text import MIMEText def main(): # 请自行修改下面的邮件发送者和接收者 sender = 'abcdefg@126.com' receivers = ['uvwxyz@qq.com', 'uvwxyz@126.com'] message = MIMEText('用Python发送邮件的示例代码.', 'plain', 'utf-8') message['From'] = Header('王大锤', 'utf-8') message['To'] = Header('骆昊', 'utf-8') message['Subject'] = Header('示例代码实验邮件', 'utf-8') smtper = SMTP('smtp.126.com') # 请自行修改下面的登录口令 smtper.login(sender, 'secretpass') smtper.sendmail(sender, receivers, message.as_string()) print('邮件发送完成!') if __name__ == '__main__': main() 如果要发送带有附件的邮件，那么可以按照下面的方式进行操作。 from smtplib import SMTP from email.header import Header from email.mime.text import MIMEText from email.mime.image import MIMEImage from email.mime.multipart import MIMEMultipart import urllib def main(): # 创建一个带附件的邮件消息对象 message = MIMEMultipart() # 创建文本内容 text_content = MIMEText('附件中有本月数据请查收', 'plain', 'utf-8') message['Subject'] = Header('本月数据', 'utf-8') # 将文本内容添加到邮件消息对象中 message.attach(text_content) # 读取文件并将文件作为附件添加到邮件消息对象中 with open('/Users/Hao/Desktop/hello.txt', 'rb') as f: txt = MIMEText(f.read(), 'base64', 'utf-8') txt['Content-Type'] = 'text/plain' txt['Content-Disposition'] = 'attachment; filename=hello.txt' message.attach(txt) # 读取文件并将文件作为附件添加到邮件消息对象中 with open('/Users/Hao/Desktop/汇总数据.xlsx', 'rb') as f: xls = MIMEText(f.read(), 'base64', 'utf-8') xls['Content-Type'] = 'application/vnd.ms-excel' xls['Content-Disposition'] = 'attachment; filename=month-data.xlsx' message.attach(xls) # 创建SMTP对象 smtper = SMTP('smtp.126.com') # 开启安全连接 # smtper.starttls() sender = 'abcdefg@126.com' receivers = ['uvwxyz@qq.com'] # 登录到SMTP服务器 # 请注意此处不是使用密码而是邮件客户端授权码进行登录 # 对此有疑问的读者可以联系自己使用的邮件服务器客服 smtper.login(sender, 'secretpass') # 发送邮件 smtper.sendmail(sender, receivers, message.as_string()) # 与邮件服务器断开连接 smtper.quit() print('发送完成!') if __name__ == '__main__': main() 发送短信 发送短信也是项目中常见的功能，网站的注册码、验证码、营销信息基本上都是通过短信来发送给用户的。在下面的代码中我们使用了互亿无线短信平台（该平台为注册用户提供了50条免费短信以及常用开发语言发送短信的demo，可以登录该网站并在用户自服务页面中对短信进行配置）提供的API接口实现了发送短信的服务，当然国内的短信平台很多，读者可以根据自己的需要进行选择（通常会考虑费用预算、短信达到率、使用的难易程度等指标），如果需要在商业项目中使用短信服务建议购买短信平台提供的套餐服务。 import urllib.parse import http.client import json def main(): host = \"106.ihuyi.com\" sms_send_uri = \"/webservice/sms.php?method=Submit\" # 下面的参数需要填入自己注册的账号和对应的密码 params = urllib.parse.urlencode({'account': '你自己的账号', 'password' : '你自己的密码', 'content': '您的验证码是：147258。请不要把验证码泄露给其他人。', 'mobile': '接收者的手机号', 'format':'json' }) print(params) headers = {'Content-type': 'application/x-www-form-urlencoded', 'Accept': 'text/plain'} conn = http.client.HTTPConnection(host, port=80, timeout=30) conn.request('POST', sms_send_uri, params, headers) response = conn.getresponse() response_str = response.read() jsonstr = response_str.decode('utf-8') print(json.loads(jsonstr)) conn.close() if __name__ == '__main__': main() "},"Python/Python语言基础/15-图像和办公文档处理.html":{"url":"Python/Python语言基础/15-图像和办公文档处理.html","title":"图像和文档处理","keywords":"","body":"datetime:2019/5/14 17:55 author:nzb 图像和办公文档处理 用程序来处理图像和办公文档经常出现在实际开发中，Python的标准库中虽然没有直接支持这些操作的模块，但我们可以通过Python生态圈中的第三方模块来完成这些操作。 操作图像 计算机图像相关知识 颜色。如果你有使用颜料画画的经历，那么一定知道混合红、黄、蓝三种颜料可以得到其他的颜色，事实上这三种颜色就是被我们称为美术三原色的东西，它们是不能再分解的基本颜色。在计算机中，我们可以将红、绿、蓝三种色光以不同的比例叠加来组合成其他的颜色，因此这三种颜色就是色光三原色，所以我们通常会将一个颜色表示为一个RGB值或RGBA值（其中的A表示Alpha通道，它决定了透过这个图像的像素，也就是透明度）。 | 名称 | RGBA值 | 名称 | RGBA值 | | :---: | :------------------: | :----: | :----------------: | | White | (255, 255, 255, 255) | Red | (255, 0, 0, 255) | | Green | (0, 255, 0, 255) | Blue | (0, 0, 255, 255) | | Gray | (128, 128, 128, 255) | Yellow | (255, 255, 0, 255) | | Black | (0, 0, 0, 255) | Purple | (128, 0, 128, 255) | 像素。对于一个由数字序列表示的图像来说，最小的单位就是图像上单一颜色的小方格，这些小方块都有一个明确的位置和被分配的色彩数值，而这些一小方格的颜色和位置决定了该图像最终呈现出来的样子，它们是不可分割的单位，我们通常称之为像素（pixel）。每一个图像都包含了一定量的像素，这些像素决定图像在屏幕上所呈现的大小。 用Pillow操作图像 Pillow是由从著名的Python图像处理库PIL发展出来的一个分支，通过Pillow可以实现图像压缩和图像处理等各种操作。可以使用下面的命令来安装Pillow。 pip install pillow Pillow中最为重要的是Image类，读取和处理图像都要通过这个类来完成。 >>> from PIL import Image >>> >>> image = Image.open('./res/guido.jpg') >>> image.format, image.size, image.mode ('JPEG', (500, 750), 'RGB') >>> image.show() 剪裁图像 >>> image = Image.open('./res/guido.jpg') >>> rect = 80, 20, 310, 360 >>> image.crop(rect).show() 生成缩略图 >>> image = Image.open('./res/guido.jpg') >>> size = 128, 128 >>> image.thumbnail(size) >>> image.show() 缩放和黏贴图像 >>> image1 = Image.open('./res/luohao.png') >>> image2 = Image.open('./res/guido.jpg') >>> rect = 80, 20, 310, 360 >>> guido_head = image2.crop(rect) >>> width, height = guido_head.size >>> image1.paste(guido_head.resize((int(width / 1.5), int(height / 1.5))), (172, 40)) 旋转和翻转 >>> image = Image.open('./res/guido.png') >>> image.rotata(180).show() >>> image.transpose(Image.FLIP_LEFT_RIGHT).show() 操作像素 >>> image = Image.open('./res/guido.jpg') >>> for x in range(80, 310): ... for y in range(20, 360): ... image.putpixel((x, y), (128, 128, 128)) ... >>> image.show() 滤镜效果 >>> from PIL import Image, ImageFilter >>> >>> image = Image.open('./res/guido.jpg') >>> image.filter(ImageFilter.CONTOUR).show() 处理Excel电子表格 Python的openpyxl模块让我们可以在Python程序中读取和修改Excel电子表格，当然实际工作中，我们可能会用LibreOffice Calc和OpenOffice Calc来处理Excel的电子表格文件，这就意味着openpyxl模块也能处理来自这些软件生成的电子表格。关于openpyxl的使用手册和使用文档可以查看它的官方文档。 处理Word文档 利用python-docx模块，Pytho 可以创建和修改Word文档，当然这里的Word文档不仅仅是指通过微软的Office软件创建的扩展名为docx的文档，LibreOffice Writer和OpenOffice Writer都是免费的字处理软件。 处理PDF文档 PDF是Portable Document Format的缩写，使用.pdf作为文件扩展名。接下来我们就研究一下如何通过Python实现从PDF读取文本内容和从已有的文档生成新的PDF文件。 "},"Python/Python语言基础/16-logging日志模块.html":{"url":"Python/Python语言基础/16-logging日志模块.html","title":"logging日志模块","keywords":"","body":"datetime:2021/11/14 17:55 author:nzb logging 模块 基于 logging 实现日志，每天的日志记录到一个文件中。 例如：开发一个网站，4CPU 开 4个 进程(或 8个) 假设： 启动网站，创建 4个 进程，每个进程中都打开文件 a1.log， 每个进程中都有 # 每个进程都有各自文件对象 file_object = open(\"a1.log\", 'a', encoding='utf-8') 用户访问 # 其中 1个 进程接收并加以处理，执行自己的 write file_object.write('日志...') 同时来 4个 # 其中 4个 进程接收并处理，执行自己的 write file_object.write('日志...') logging 模块实现机制(自动切割日志的功能) 启动网站，创建 4个 进程，每个进程中都打开文件 a1.log， 每个进程中都有 # 每个进程都有各自文件对象 file_object = open(\"a1.log\", 'a', encoding='utf-8') 用户访问 # 其中 1个 进程接收并加以处理，执行自己的 write file_object.write('日志...') 同时来 4个 # 其中 4个 进程接收并处理，执行自己的 write file_object.write('日志...') 问题1：多进程写日志会导致删除 例如 11-18日 默认都会记录到 a1.log 文件中 到了 11-19日 判断 a1-11-19.log 文件是否存在，如果存在，就删除(导致多进程会一直删除文件)(优化，文件不存在，可以重命名；文件存在，继续在 a1.log 中写入日志) a1.log -> a1-11-19.log # 到 11.19 后 a1.log 重命名为 a1-11-19.log 然后再写入 a1.log 源码找原因 import time import os from logging.handlers import BaseRotatingHandler class TimedRotatingFileHandler(BaseRotatingHandler): \"\"\" Handler for logging to a file, rotating the log file at certain timed intervals. If backupCount is > 0, when rollover is done, no more than backupCount files are kept - the oldest ones are deleted. \"\"\" def doRollover(self): \"\"\" do a rollover; in this case, a date/time stamp is appended to the filename when the rollover happens. However, you want the file to be named for the start of the interval, not the current time. If there is a backup count, then we have to get a list of matching filenames, sort them and remove the one with the oldest suffix. \"\"\" if self.stream: self.stream.close() self.stream = None # get the time that this sequence started at and make it a TimeTuple currentTime = int(time.time()) dstNow = time.localtime(currentTime)[-1] t = self.rolloverAt - self.interval if self.utc: timeTuple = time.gmtime(t) else: timeTuple = time.localtime(t) dstThen = timeTuple[-1] if dstNow != dstThen: if dstNow: addend = 3600 else: addend = -3600 timeTuple = time.localtime(t + addend) # # 新文件名，a1-11-19.log # dfn = self.rotation_filename(self.baseFilename + \".\" + # time.strftime(self.suffix, timeTuple)) # # 判断是否存在，存在删除，问题就出在这，多进程时会删除其他进程创建备份的 # if os.path.exists(dfn): # os.remove(dfn) # # 重命名 # self.rotate(self.baseFilename, dfn) # 修复 dfn = self.rotation_filename(self.baseFilename + \".\" + time.strftime(self.suffix, timeTuple)) # 判断是否存在，不存在重命名 if not os.path.exists(dfn): self.rotate(self.baseFilename, dfn) if self.backupCount > 0: for s in self.getFilesToDelete(): os.remove(s) if not self.delay: self.stream = self._open() newRolloverAt = self.computeRollover(currentTime) while newRolloverAt 问题2：日志文件不能做相关操作(比如：删除或修改日志文件，日志就不创建文件继续打印了，需要重新执行该程序，才会重新创建文件写入日志) # 类比 WatchedFileHandler 提供解决思路 import os import time from stat import ST_INO, ST_DEV file_obj = open('xxx.log', 'a', encoding='utf-8') sres = os.fstat(file_obj.fileno()) dev, ino = sres[ST_DEV], sres[ST_INO] while True: # WatchedFileHandler 处理 handler 的处理机制 # 删除文件之后报错 try: # stat the file by path, checking for existence new_sres = os.stat(\"xxx.log\") except FileNotFoundError: sres = None if not new_sres or new_sres[ST_DEV] != dev or new_sres[ST_INO] != ino: print(\"文件被删除或修改了\") # 重新打开，获取标志数据 file_obj = open('xxx.log', 'a', encoding='utf-8') sres = os.fstat(file_obj.fileno()) dev, ino = sres[ST_DEV], sres[ST_INO] file_obj.write(\"111\\n\") file_obj.flush() time.sleep(1) 多进程和文件修改(删除)后 2 个结合重写 handler logging Handler 源码解析(TimedRotatingFileHandler为例) import os import time from _stat import ST_INO from logging.handlers import TimedRotatingFileHandler import logging from stat import ST_DEV LOGGING_CONFIG = { \"version\": 1, \"disable_existing_loggers\": True, \"formatters\": { \"standard\": { \"format\": '[%(levelname)s][%(asctime)s][%(filename)s:%(lineno)d]%(message)s', \"style\": \"%\" } }, \"handlers\": { \"error_file\": { \"class\": \"logging.handlers.CustomizeHandler\", # 自定义处理类 \"formatter\": \"standard\", \"filename\": \"a1.log\", \"when\": \"S\", # 根据天拆分日志, \"interval\": 10, # 1天 \"backupCount\": 2, # 备份数 \"encoding\": \"utf-8\" } }, \"loggers\": { \"\": { \"handlers\": [\"error_file\"], \"level\": \"ERROR\", \"propagate\": True }, \"error\": { \"handlers\": [\"error_file\"], \"level\": \"ERROR\", \"propagate\": True } } } \"\"\" 继承从下往上 1、实例化 CustomizeHandler 对象 logging.Filterer.__init__() logging.Handler.__init__() logging.StreamHandler.__init__() logging.FileHandler.__init__() BaseRotatingHandler.__init__() TimedRotatingFileHandler.__init__() # 接受了很多关键字参数，这些都是配置字典里面 handlers 里面的值 CustomizeHandler.__init__() # 看2、3点，发现关键点在于 self.baseFilename # 日志文件的绝对路径 self.stream = stream # 打开的文件对象 # 看第 4 点，需要写日志时 handler对象.emit(\"日志内容\") 把检测文件标识的代码移植到 emit 里面 2、FileHandler.__init__() class FileHandler(StreamHandler): def __init__(self, filename, mode='a', encoding=None, delay=False, errors=None): filename = os.fspath(filename) #keep the absolute path, otherwise derived classes which use this #may come a cropper when the current directory changes # 日志文件的绝对路径 self.baseFilename = os.path.abspath(filename) self.mode = mode self.encoding = encoding self.errors = errors self.delay = delay if delay: #We don't open the stream, but we still need to call the #Handler constructor to set level, formatter, lock etc. Handler.__init__(self) self.stream = None else: # self._open() 是打开文件对象返回的句柄 StreamHandler.__init__(self, self._open()) def _open(self): return open(self.baseFilename, self.mode, encoding=self.encoding, errors=self.errors) 3、StreamHandler.__init__() class StreamHandler(Handler): terminator = '\\n' def __init__(self, stream=None): Handler.__init__(self) if stream is None: stream = sys.stderr self.stream = stream # 关键点，这里赋值了 self.stream = 文件句柄 4、开始写日志：handler对象.emit(\"日志内容\") class BaseRotatingHandler(logging.FileHandler): def emit(self, record): try: # 判断是否已经过了设置的时间(比如第二天)，就重命名 if self.shouldRollover(record): self.doRollover() # 执行父类的写日志 logging.FileHandler.emit(self, record) except Exception: self.handleError(record) class FileHandler(StreamHandler): def emit(self, record): # 如果文件句柄为空，重新打开文件赋值 self.stream if self.stream is None: self.stream = self._open() # 执行父类的写日志 StreamHandler.emit(self, record) class StreamHandler(Handler): def emit(self, record): try: msg = self.format(record) # 按你设置的 formatter 格式化日志 stream = self.stream stream.write(msg + self.terminator) # 文件写入日志 self.flush() except RecursionError: # See issue 36272 raise except Exception: self.handleError(record) \"\"\" class CustomizeHandler(TimedRotatingFileHandler): def __init__(self, *args, **kwargs): \"\"\" 借鉴 WatchedFileHandler 的机制检测文件 :param args: :param kwargs: \"\"\" super().__init__(*args, **kwargs) self.dev, self.ino = -1, -1 self._statstream() # WatchedFileHandler 方法 def _statstream(self): if self.stream: sres = os.fstat(self.stream.fileno()) self.dev, self.ino = sres[ST_DEV], sres[ST_INO] # WatchedFileHandler 方法 def reopenIfNeeded(self): \"\"\" Reopen log file if needed. Checks if the underlying file has changed, and if it has, close the old stream and reopen the file to get the current stream. \"\"\" # Reduce the chance of race conditions by stat'ing by path only # once and then fstat'ing our new fd if we opened a new log stream. # See issue #14632: Thanks to John Mulligan for the problem report # and patch. try: # stat the file by path, checking for existence sres = os.stat(self.baseFilename) except FileNotFoundError: sres = None # compare file system stat with that of our stream file handle if not sres or sres[ST_DEV] != self.dev or sres[ST_INO] != self.ino: if self.stream is not None: # we have an open file handle, clean it up self.stream.flush() self.stream.close() self.stream = None # See Issue #21742: _open () might fail. # open a new file handle and get new stat info from that fd self.stream = self._open() self._statstream() def doRollover(self): \"\"\" do a rollover; in this case, a date/time stamp is appended to the filename when the rollover happens. However, you want the file to be named for the start of the interval, not the current time. If there is a backup count, then we have to get a list of matching filenames, sort them and remove the one with the oldest suffix. \"\"\" if self.stream: self.stream.close() self.stream = None # get the time that this sequence started at and make it a TimeTuple currentTime = int(time.time()) dstNow = time.localtime(currentTime)[-1] t = self.rolloverAt - self.interval if self.utc: timeTuple = time.gmtime(t) else: timeTuple = time.localtime(t) dstThen = timeTuple[-1] if dstNow != dstThen: if dstNow: addend = 3600 else: addend = -3600 timeTuple = time.localtime(t + addend) dfn = self.rotation_filename(self.baseFilename + \".\" + time.strftime(self.suffix, timeTuple)) if not os.path.exists(dfn): # 修复多进程删除日志文件，只有不存在再重命名 self.rotate(self.baseFilename, dfn) if self.backupCount > 0: for s in self.getFilesToDelete(): os.remove(s) if not self.delay: self.stream = self._open() newRolloverAt = self.computeRollover(currentTime) while newRolloverAt 思考：上面重写的 handler 类，会不会出现问题？ 答案：会的，比如多进程，第二天的时候所有的进程卡在时间特别短的时候，一起重命名，就会出现问题 解决：为什么不每天得日志都写入一个当天的日志，而不是重命名 每天写入当天日志 \"\"\" 继承从下往上 1、实例化 CustomizeHandler 对象 logging.Filterer.__init__() logging.Handler.__init__() logging.StreamHandler.__init__() logging.FileHandler.__init__() WatchedFileHandler.__init__() # 检测文件是否修改，删除的处理类 CustomizeOneDayOneLogHandler.__init__() \"\"\" from logging.handlers import WatchedFileHandler LOGGING_CONFIG = { \"version\": 1, \"disable_existing_loggers\": True, \"formatters\": { \"standard\": { \"format\": '[%(levelname)s][%(asctime)s][%(filename)s:%(lineno)d]%(message)s', \"style\": \"%\" } }, \"handlers\": { \"error_file\": { \"class\": \"logging.handlers.TimedRotatingFileHandler\", \"formatter\": \"standard\", \"filepath\": \"logs\", \"encoding\": \"utf-8\" } }, \"loggers\": { \"\": { \"handlers\": [\"error_file\"], \"level\": \"ERROR\", \"propagate\": True }, \"error\": { \"handlers\": [\"error_file\"], \"level\": \"ERROR\", \"propagate\": True } } } class CustomizeOneDayOneLogHandler(WatchedFileHandler): \"\"\" 每天创建一个日志，每天的日志都打入当天的日志文件 文件名：a-2021-10-20.log, 不会出现 a-2021-10-20.log.2021-10-21 这样的 \"\"\" def __init__(self, file_path, file_name_prefix, mode='a', encoding=None, delay=False, errors=None): \"\"\" :param file_path: 日志文件路径 :param file_name_prefix: 日志文件前缀，就是 logging.getLogger(__name__) 获取，只是重下了 log 类继承 Logger，详细看下面 :param mode: :param encoding: :param delay: :param errors: \"\"\" if not os.path.exists(file_path): os.makedirs(file_path) self.file_path = file_path self.file_name_prefix = file_name_prefix self.file_name = self.get_file_name() filename = os.path.join(file_path, self.file_name) # errors py3.9 有这个参数，3.8、3.7没有(更早版本也可能是) # super().__init__(filename=filename, mode=mode, encoding=encoding, delay=delay, errors=errors) super(CustomizeOneDayOneLogHandler, self).__init__(filename=filename, mode=mode, encoding=encoding, delay=delay) def get_file_name(self): \"\"\" TODO 怎么切分可以这里实现，做成那个时间切分的参数配置 :return: 日志名称 \"\"\" # 一天分一次 return \"{}-{}.log\".format(self.file_name_prefix, datetime.datetime.now().strftime(\"%Y-%m-%d\")) # 一分钟分一次 # return \"{}-{}.log\".format(self.file_name_prefix, datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')) def emit(self, record): \"\"\" Emit a record. If underlying file has changed, reopen the file before emitting the record to it. \"\"\" current_file_name = self.get_file_name() # 文件不一致，新建文件 + 重新打开 + 重新获取 os.stat if current_file_name != self.file_name: self.file_name = current_file_name # 重新赋值，当前的文件名应该是最新的日期 self.baseFilename = os.path.abspath(os.path.join(self.file_path, current_file_name)) if self.stream: self.stream.flush() self.stream.close() self.stream = self._open() self._statstream() super(CustomizeOneDayOneLogHandler, self).emit(record) 项目中使用 #!/usr/bin/env python # -*- coding:utf8 -*- __date__ = \"2021/10/20 11:20\" __doc__ = \"\"\"\"\"\" # 定义三种日志输出格式 开始 import datetime import glob import os import sys import time import traceback from logging import Logger from logging.handlers import WatchedFileHandler import logging.config standard_format = '[%(asctime)s][%(threadName)s:%(thread)d][task_id:%(name)s][%(filename)s:%(lineno)d]' '[%(levelname)s][%(message)s]' # 其中 name 为 getlogger 指定的名字 simple_format = '[%(levelname)s][%(asctime)s][%(filename)s:%(lineno)d]%(message)s' id_simple_format = '[%(levelname)s][%(asctime)s] %(message)s' # 第一种：每天一个日志文件 class CustomizeOneDayOneLogHandler(WatchedFileHandler): \"\"\" 每天创建一个日志，每天的日志都打入当天的日志文件 文件名：a-2021-10-20.log, 不会出现 a-2021-10-20.log.2021-10-21 这样的 \"\"\" def __init__(self, file_path, file_name_prefix, backup_count: int = 5, mode='a', encoding=None, delay=False, errors=None): \"\"\" :param file_path: 日志文件路径 :param file_name_prefix: 日志文件前缀 :param backup_count: 日志备份数量 :param mode: :param encoding: :param delay: :param errors: \"\"\" if not os.path.exists(file_path): os.makedirs(file_path) self.file_path = file_path self.file_name_prefix = file_name_prefix self.backup_count = backup_count self.file_name = self.get_file_name() filename = os.path.join(file_path, self.file_name) # errors py3.9 有这个参数，3.8、3.7没有(更早版本也可能是) # super().__init__(filename=filename, mode=mode, encoding=encoding, delay=delay, errors=errors) super().__init__(filename=filename, mode=mode, encoding=encoding, delay=delay) # 初始化的时候清理下，防止创建了文件不写入，导致空日志文件过多 self.auto_clear() def get_file_name(self) -> str: \"\"\" TODO 怎么切分可以这里实现，做成那个时间切分的参数配置 :return: 日志名称 \"\"\" # 一天分一次 return \"{}-{}.log\".format(self.file_name_prefix, datetime.datetime.now().strftime(\"%F\")) # 一分钟分一次 # return \"{}-{}.log\".format(self.file_name_prefix, datetime.datetime.now().strftime('%F-%H-%M')) def emit(self, record): \"\"\" Emit a record. If underlying file has changed, reopen the file before emitting the record to it. \"\"\" current_file_name = self.get_file_name() if current_file_name != self.file_name: self.file_name = current_file_name self.baseFilename = os.path.abspath(os.path.join(self.file_path, current_file_name)) if self.stream: self.stream.flush() self.stream.close() self.stream = self._open() self._statstream() self.auto_clear() super().emit(record) def auto_clear(self): \"\"\" 自动清理 log 文件 :return: \"\"\" file_list = sorted(glob.glob(os.path.join(self.file_path, self.file_name_prefix + '*')), key=lambda x: time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(os.path.getctime(x))), reverse=True) for file_ in file_list[self.backup_count:]: os.remove(file_) class MyLog(Logger): def error(self, msg, exc_info=True, extra=None, *args): \"\"\" 重写父类方法,exc_info默认为True \"\"\" if self.isEnabledFor(level=40): # 父类抄来,使用默认值 self._log(40, msg, args, exc_info=True, extra=None) def info(self, msg, *args, **kwargs): \"\"\" 防止在 exception里写 log.info(error) 抓取一切报错堆栈 Log 'msg % args' with severity 'INFO'. To pass exception information, use the keyword argument exc_info with a true value, e.g. logger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1) \"\"\" error_msg = traceback.format_exc() # Windows 和 Linux 不一样？ # if not error_msg == 'None\\n': if not error_msg == 'NoneType: None\\n': error_msg = str(msg) + error_msg self._log(20, error_msg, args, **kwargs) if self.isEnabledFor(20): # 父类抄来,使用默认值 self._log(20, msg, args, **kwargs) class LogUtil(object): def __init__(self, file_name_prefix, backup_count: int = 5, console_out: bool = False): \"\"\" :param file_name_prefix: 日志名称前缀 :param backup_count: 备份数量 :param console_out: 是否在控制台输出 \"\"\" self.file_name_prefix = file_name_prefix if sys.platform.startswith(\"linux\"): self.base_dir = '/app/logs' else: self.base_dir = './logs' # 本地调试 formatter = logging.Formatter('[%(levelname)s] [%(asctime)s] [%(filename)s-line:%(lineno)d] %(message)s') # 按天存放 同类型log最多保留5个 self.log_file_handler = CustomizeOneDayOneLogHandler(self.base_dir, self.file_name_prefix, backup_count=backup_count, encoding='utf-8') self.log_file_handler.setFormatter(formatter) self.logger = MyLog(name=self.log_file_handler.file_name) self.logger.setLevel(logging.DEBUG) self.logger.addHandler(self.log_file_handler) # 输出到文件 if console_out: # 往屏幕上输出 console_handler = logging.StreamHandler() console_handler.setFormatter(formatter) # 设置屏幕上显示的格式 self.logger.addHandler(console_handler) # 输出到控制台 log_test1 = LogUtil(\"test1\", console_out=True).logger log_test2 = LogUtil(\"test2\", console_out=True).logger if __name__ == '__main__': while True: time.sleep(5) log_test1.info(\"aaaaaaaaaaa\") # time.sleep(0.1) # log_test2.info(\"bbbbbbbbbbb\") # try: # a = 1/ 0 # except Exception as e: # # log_test1.error(\"error\") # log_test1.info(\"info\") "},"Python/Python语言基础/unittest/01-单元测试unittest基础.html":{"url":"Python/Python语言基础/unittest/01-单元测试unittest基础.html","title":"单元测试unittest基础","keywords":"","body":"datetime:2022/04/12 14:47 author:nzb 单元测试：unittest 框架基础 一、框架详解 什么是框架？ 开发者封装好的一个半成品，它已经对基础的代码进行了封装并提供了相应的接口，其他的开发者只需要去调用封装之后的接口即可。 例如：Selenium 框架 unittest 单元测试框架 单元测试框架：在编程当中，针对程序的最小单元（函数、方法、类）进行正确性的测试框架。 自动化测试框架针对软件封装的系统框架，这个代码框架就是自动化测试框架 作用 提高测试效率，降低维护成本 提高测试准确性，增加代码的重用性和可靠性 单元测试框架它是自动化测试框架的其中的组成部分，主要用于管理和运行测试用例 二、单元测试框架对比 python(市场使用占比80%) unittest(市场使用占比30%) pytest java(市场使用占比20%) junit testing unittest与pytest差异 用例编写差异 unittest用例规则(耦合，一台unittest) 测试文件必须导包：import unittest 测试类必须继承 unittest.Testcase 测试方法必须以test_开头 pytest 用例规则(非耦合) 测试文件必须以 test_开头或者_test结尾 测试类名必须以Test开头 测试方法必须test_开头 测试用例的夹具(钩子函数、前后置) unittest setUp/tearDown：在测试用例之前和之后执行 setUpClass/tearDownClass：在测试用例类之前和之后执行 setUpModule/teardownModule：在测试模块之前和之后执行 pytest setup/teardown：在测试用例之前和之后执行 setup_class/teardown_class：在测试用例类之前和之后执行 setup_module/teardown_module：在测试模块之前和之后执行 其他夹具 pytest 独有：@pytest.fixtrue() 断言差异 unittest：self.assertEqual()、self.assertIn() pytest：python 自带的 assert 报告 unittest：HtmlTestrunner.py pytest：pytest-html、allure插件 失败重跑 unittest：没有 pytest：pytest-rerunfailures 参数化 unittest：ddt pytest：@pytest.mark.parametrize() 三、单元测试框架作用 发现测试用例 执行测试用例 判断测试用例 生成测试报告 四、unittest 重要组件 TestCase 测试用例：最小单元，业务逻辑 TestSuite 测试套件：一组测试用例的集合，或者测试套件的集合 TestFixtrue 测试夹具：执行测试用例之前和之后的操作 TestLoader 测试加载器：加载测试用例 TestRunner 测试运行器：运行指定的测试用例 五、unittest 实例 单元测试：测试函数 光标放置某一函数后面，右键运行，可单独运行该用例 光标放置某一测试类后面，右键运行，可单独运行该测试类的所有用例 为什么没有 main 方法也可以运行呢？ import unittest class TestUnittest(unittest.TestCase): def test_01(self): print(\"测试test_01\") def test_02(self): print(\"测试test_02\") if __name__ == '__main__': print(\"___________________________main___________________________\") # 未打印 unittest.main() 输出 C:\\Users\\lenovo\\PycharmProjects\\demo\\venv\\Scripts\\python.exe \"D:\\Program\\PyCharm 2020.3.4\\plugins\\python\\helpers\\pycharm\\_jb_unittest_runner.py\" --target test_unittest.TestUnittest Testing started at 15:49 ... Launching unittests with arguments python -m unittest test_unittest.TestUnittest in C:\\Users\\lenovo\\PycharmProjects\\demo\\study\\unittest_demo Ran 2 tests in 0.002s OK 测试test_01 测试test_02 Process finished with exit code 0 unittest 运行方式有两种 命令行的运行方式(右键运行即为默认的测试用例的运行方式，也就是为什么不写 main 也可以运行的原因) 方式1： python -m unittest 模块名.py 例：python -m unittest test_unittest.py 方式2：python -m unittest 模块名.类名.方法名 方式3：python -m unittest -v 模块名.py -v：详细(verbose), 上面简介运行后的 . 变成了 ok 方式4：python -m unittest -v 模块名.py -k *_01 -k：通过通配符匹配方法名 python -m：以脚本(命令行)的方式来运行(测试用例) 通过 main 运行 if __name__ == \"__main__\": unittest.main() 六、unittest 的测试用例运行结果 .：成功 F：失败 E：异常 s：跳过 以上不能通过 -v 的方式运行。因为这是详细的报错方式，不是简洁的报错方式 __date__ = \"2022/4/12 15:18\" import unittest class TestUnittest(unittest.TestCase): def test_01(self): print(\"测试 test_01\") def test_02(self): print(\"测试 test_02\") self.assertEqual(1, 2) def test_03(self): print(\"测试 test_03\") raise Exception(\"报错了\") @unittest.skip(\"直接跳过\") def test_04(self): print(\"测试 test_04\") if __name__ == '__main__': print(\"___________________________main___________________________\") unittest.main() C:\\Users\\lenovo\\PycharmProjects\\demo\\venv\\Scripts\\python.exe C:/Users/lenovo/PycharmProjects/demo/study/unittest_demo/test_unittest.py ___________________________main___________________________ 测试 test_01 测试 test_02 测试 test_03 .FEs ====================================================================== ERROR: test_03 (__main__.TestUnittest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"C:\\Users\\lenovo\\PycharmProjects\\demo\\study\\unittest_demo\\test_unittest.py\", line 20, in test_03 raise Exception(\"报错了\") Exception: 报错了 ====================================================================== FAIL: test_02 (__main__.TestUnittest) ---------------------------------------------------------------------- Traceback (most recent call last): File \"C:\\Users\\lenovo\\PycharmProjects\\demo\\study\\unittest_demo\\test_unittest.py\", line 16, in test_02 self.assertEqual(1, 2) AssertionError: 1 != 2 ---------------------------------------------------------------------- Ran 4 tests in 0.001s FAILED (failures=1, errors=1, skipped=1) Process finished with exit code 1 七、多种 unittest 的加载和运行测试用例的方式 main 方法 通过测试套件来加载和运行 __date__ = \"2022/4/12 16:21\" import unittest from unittest_demo.test_unittest import TestUnittest if __name__ == '__main__': # 创建一个测试套件 suite = unittest.TestSuite() # 通过测试套件加载测试用例 # suite.addTest(TestUnittest(\"test_01\")) # suite.addTest(TestUnittest(\"test_02\")) test_cases = [TestUnittest(\"test_01\"), TestUnittest(\"test_02\")] suite.addTests(test_cases) # 运行 unittest.main(defaultTest='suite') 加载一个目录下所有的用例 __date__ = \"2022/4/12 16:21\" import unittest if __name__ == '__main__': suite = unittest.defaultTestLoader.discover('.', pattern=\"*.py\") # suite = unittest.defaultTestLoader.discover('.', pattern=\"test_unittest.py\") unittest.main(defaultTest='suite') 为什么调用 unittest.main() 就可以执行测试用例？？？ class TestProgram(object): \"\"\"A command-line program that runs a set of tests; this is primarily for making test modules conveniently executable. \"\"\" # defaults for testing module=None verbosity = 1 failfast = catchbreak = buffer = progName = warnings = testNamePatterns = None _discovery_parser = None def __init__(self, module='__main__', defaultTest=None, argv=None, testRunner=None, testLoader=loader.defaultTestLoader, exit=True, verbosity=1, failfast=None, catchbreak=None, buffer=None, warnings=None, *, tb_locals=False): \"\"\" :param module: 测试用例所在的路径，__main__：默认当前 :param defaultTest: 默认的待测试的测试用例的名称，默认执行所有用例 :param argv: 接收外部传递给程序的参数 :param testRunner: 测试运行器 :param testLoader: 测试加载器 :param exit: 是否在测试完成结束之后退出程序 :param verbosity: 显示信息的详细程度，verbose -v = 2: 显示用例总数和全局结果，并输出每个用例的详解 :param failfast: 是否在测试用例失败时终止测试 :param catchbreak: :param buffer: :param warnings: :param tb_locals: \"\"\" TestCase 测试用例：最小单元，业务逻辑 TestSuite 测试套件：一组测试用例的集合，或者测试套件的集合 # 解析测试用例和测试套件 elif self.testNames is None: self.test = self.testLoader.loadTestsFromModule(self.module) else: self.test = self.testLoader.loadTestsFromNames(self.testNames, self.module) TestFixtrue 测试夹具：执行测试用例之前和之后的操作 TestLoader 测试加载器：加载测试用例： __init__时已经给了默认的加载器 TestRunner 测试运行器：运行指定的测试用例 if self.testRunner is None: self.testRunner = runner.TextTestRunner # !/usr/bin/env python # -*- coding:utf8 -*- __date__ = \"2022/4/12 16:21\" import unittest if __name__ == '__main__': suite = unittest.defaultTestLoader.discover('.', pattern=\"*.py\") unittest.main(defaultTest='suite') # 一连串的加载相关组件后运行相当于以下运行 suite = unittest.defaultTestLoader.discover('.', pattern=\"*.py\") unittest.TextTestRunner().run(suite) "},"Python/Python语言基础/unittest/02-单元测试unittest进阶.html":{"url":"Python/Python语言基础/unittest/02-单元测试unittest进阶.html","title":"单元测试unittest进阶","keywords":"","body":"datetime:2022/04/12 17:48 author:nzb 单元测试：unittest 框架进阶 一、测试夹具（固件、钩子函数、前后置）TestFixtrue详解 setUp/tearDown：在测试用例之前和之后执行 setUpClass/tearDownClass：在测试用例类之前和之后执行（必须加 @classmethod 的装饰器） setUpModule/teardownModule：在测试模块之前和之后执行 __date__ = \"2022/4/12 15:18\" import unittest class TestUnittest(unittest.TestCase): @classmethod def setUpClass(cls) -> None: print(\"测试类之前的准备工作：连接数据库，创建日志对象等\") @classmethod def tearDownClass(cls) -> None: print(\"测试类之后的扫尾工作：销毁数据库连接，销毁日志对象等\") def setUp(self) -> None: print(\"测试用例之前的准备工作：打开浏览器，加载网页\") def tearDown(self) -> None: print(\"测试用例之后的扫尾工作：关闭浏览器\") def test_01(self): print(\"测试 test_01\") def test_02(self): print(\"测试 test_02\") # self.assertEqual(1, 2) if __name__ == '__main__': print(\"___________________________main___________________________\") suite = unittest.defaultTestLoader.discover('.', pattern=\"test_unittest.py\") unittest.main(defaultTest='suite') C:\\Users\\lenovo\\PycharmProjects\\demo\\venv\\Scripts\\python.exe C:/Users/lenovo/PycharmProjects/demo/study/unittest_demo/test_unittest.py .. ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK ___________________________main___________________________ 测试类之前的准备工作：连接数据库，创建日志对象等 测试用例之前的准备工作：打开浏览器，加载网页 测试 test_01 测试用例之后的扫尾工作：关闭浏览器 测试用例之前的准备工作：打开浏览器，加载网页 测试 test_02 测试用例之后的扫尾工作：关闭浏览器 测试类之后的扫尾工作：销毁数据库连接，销毁日志对象等 Process finished with exit code 0 夹具封装 自动化测试框架必备的思想 二、忽略测试用例 import unittest class TestUnittest(unittest.TestCase): a = 18 @unittest.skip(\"无条件忽略\") def test_04(self): print(\"测试 test_04\") @unittest.skipIf(a >= 15, \"条件为 True 忽略\") def test_05(self): print(\"测试 test_05\") @unittest.skipUnless(a >= 20, \"条件为 False 忽略\") def test_06(self): print(\"测试 test_06\") 三、断言(判断我们用例是否执行成功) 方法 检查对象 引入版本 assertEqual(a, b) a == b assertEqual(a, b) a != b assertTrue(x) bool(x) is True assertFalse(x) bool(x) is False assertIs(a, b) a is b 3.1 assertIsNot(a, b) a is not b 3.1 assertIsNone(x) x is None 3.1 assertIsNotNone(x) x is not None 3.1 assertIn(a, b) a in b 3.1 assertNotIn(a, b) a not in b 3.1 assertIsInstance(a, b) isinstance(a, b) 3.2 assertNotIsInstance(a, b) not isinstance(a, b) 3.2 常用 assertEqual(a, b) assertTrue(x) assertIn(a, b) 四、批量生产自动化的测试报告 txt 文本格式的测试报告 html格式的测试报告 第一步：下载一个 HTMLTestRunner.py (官方上的不行，仅支持py2.7) __doc__ =\"\"\" A TestRunner for use with the Python unit testing framework. It generates a HTML report to show the result at a glance. The simplest way to use this is to invoke its main method. E.g. import unittest import HTMLTestRunner ... define your tests ... if __name__ == '__main__': HTMLTestRunner.main() For more customization options, instantiates a HTMLTestRunner object. HTMLTestRunner is a counterpart to unittest's TextTestRunner. E.g. # output to a file fp = file('my_report.html', 'wb') runner = HTMLTestRunner.HTMLTestRunner( stream=fp, title='My unit test', description='This demonstrates the report output by HTMLTestRunner.' ) # Use an external stylesheet. # See the Template_mixin class for more customizable options runner.STYLESHEET_TMPL = '' # run the test runner.run(my_test_suite) ------------------------------------------------------------------------ Copyright (c) 2004-2007, Wai Yip Tung All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name Wai Yip Tung nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. \"\"\" # URL: http://tungwaiyip.info/software/HTMLTestRunner.html __author__ = \"Wai Yip Tung\" __version__ = \"0.8.2\" \"\"\" Change History Version 0.8.2 * Show output inline instead of popup window (Viorel Lupu). Version in 0.8.1 * Validated XHTML (Wolfgang Borgert). * Added description of test classes and test cases. Version in 0.8.0 * Define Template_mixin class for customization. * Workaround a IE 6 bug that it does not treat block as CDATA. Version in 0.7.1 * Back port to Python 2.3 (Frank Horowitz). * Fix missing scroll bars in detail log (Podi). \"\"\" # TODO: color stderr # TODO: simplify javascript using ,ore than 1 class in the class attribute? import datetime import io import sys import time import unittest from xml.sax import saxutils # ------------------------------------------------------------------------ # The redirectors below are used to capture output during testing. Output # sent to sys.stdout and sys.stderr are automatically captured. However # in some cases sys.stdout is already cached before HTMLTestRunner is # invoked (e.g. calling logging.basicConfig). In order to capture those # output, use the redirectors for the cached stream. # # e.g. # >>> logging.basicConfig(stream=HTMLTestRunner.stdout_redirector) # >>> class OutputRedirector(object): \"\"\" Wrapper to redirect stdout or stderr \"\"\" def __init__(self, fp): self.fp = fp def write(self, s): self.fp.write(bytes(s, 'UTF-8')) def writelines(self, lines): self.fp.writelines(lines) def flush(self): self.fp.flush() stdout_redirector = OutputRedirector(sys.stdout) stderr_redirector = OutputRedirector(sys.stderr) # ---------------------------------------------------------------------- # Template class Template_mixin(object): \"\"\" Define a HTML template for report customerization and generation. Overall structure of an HTML report HTML +------------------------+ | | | | | | | STYLESHEET | | +----------------+ | | | | | | +----------------+ | | | | | | | | | | | | HEADING | | +----------------+ | | | | | | +----------------+ | | | | REPORT | | +----------------+ | | | | | | +----------------+ | | | | ENDING | | +----------------+ | | | | | | +----------------+ | | | | | | | +------------------------+ \"\"\" STATUS = { 0: 'pass', 1: 'fail', 2: 'error', } DEFAULT_TITLE = 'Unit Test Report' DEFAULT_DESCRIPTION = '' # ------------------------------------------------------------------------ # HTML Template HTML_TMPL = r\"\"\" %(title)s %(stylesheet)s 1) { tr.className = ''; } else { tr.className = 'hiddenRow'; } } } } function showClassDetail(cid, count) { var id_list = Array(count); var toHide = 1; for (var i = 0; i /g,'&gt;'); return s; } /* obsoleted by detail in function showOutput(id, name) { var w = window.open(\"\", //url name, \"resizable,scrollbars,status,width=800,height=450\"); d = w.document; d.write(\"\"); d.write(html_escape(output_list[id])); d.write(\"\\n\"); d.write(\"close\\n\"); d.write(\"\\n\"); d.close(); } */ --> %(heading)s %(report)s %(ending)s \"\"\" # variables: (title, generator, stylesheet, heading, report, ending) # ------------------------------------------------------------------------ # Stylesheet # # alternatively use a for external style sheet, e.g. # STYLESHEET_TMPL = \"\"\" body { font-family: verdana, arial, helvetica, sans-serif; font-size: 80%; } table { font-size: 100%; } pre { } /* -- heading ---------------------------------------------------------------------- */ h1 { font-size: 16pt; color: gray; } .heading { margin-top: 0ex; margin-bottom: 1ex; } .heading .attribute { margin-top: 1ex; margin-bottom: 0; } .heading .description { margin-top: 4ex; margin-bottom: 6ex; } /* -- css div popup ------------------------------------------------------------------------ */ a.popup_link { } a.popup_link:hover { color: red; } .popup_window { display: none; position: relative; left: 0px; top: 0px; /*border: solid #627173 1px; */ padding: 10px; background-color: #E6E6D6; font-family: \"Lucida Console\", \"Courier New\", Courier, monospace; text-align: left; font-size: 8pt; width: 500px; } } /* -- report ------------------------------------------------------------------------ */ #show_detail_line { margin-top: 3ex; margin-bottom: 1ex; } #result_table { width: 80%; border-collapse: collapse; border: 1px solid #777; } #header_row { font-weight: bold; color: white; background-color: #777; } #result_table td { border: 1px solid #777; padding: 2px; } #total_row { font-weight: bold; } .passClass { background-color: #6c6; } .failClass { background-color: #c60; } .errorClass { background-color: #c00; } .passCase { color: #6c6; } .failCase { color: #c60; font-weight: bold; } .errorCase { color: #c00; font-weight: bold; } .hiddenRow { display: none; } .testcase { margin-left: 2em; } /* -- ending ---------------------------------------------------------------------- */ #ending { } \"\"\" # ------------------------------------------------------------------------ # Heading # HEADING_TMPL = \"\"\" %(title)s %(parameters)s %(description)s \"\"\" # variables: (title, parameters, description) HEADING_ATTRIBUTE_TMPL = \"\"\"%(name)s: %(value)s \"\"\" # variables: (name, value) # ------------------------------------------------------------------------ # Report # REPORT_TMPL = \"\"\" Show Summary Failed All Test Group/Test case Count Pass Fail Error View %(test_list)s Total %(count)s %(Pass)s %(fail)s %(error)s &nbsp; \"\"\" # variables: (test_list, count, Pass, fail, error) REPORT_CLASS_TMPL = r\"\"\" %(desc)s %(count)s %(Pass)s %(fail)s %(error)s Detail \"\"\" # variables: (style, desc, count, Pass, fail, error, cid) REPORT_TEST_WITH_OUTPUT_TMPL = r\"\"\" %(desc)s %(status)s [x] %(script)s \"\"\" # variables: (tid, Class, style, desc, status) REPORT_TEST_NO_OUTPUT_TMPL = r\"\"\" %(desc)s %(status)s \"\"\" # variables: (tid, Class, style, desc, status) REPORT_TEST_OUTPUT_TMPL = r\"\"\" %(id)s: %(output)s \"\"\" # variables: (id, output) # ------------------------------------------------------------------------ # ENDING # ENDING_TMPL = \"\"\"&nbsp;\"\"\" # -------------------- The end of the Template class ------------------- TestResult = unittest.TestResult class _TestResult(TestResult): # note: _TestResult is a pure representation of results. # It lacks the output and reporting ability compares to unittest._TextTestResult. def __init__(self, verbosity=1): TestResult.__init__(self) self.stdout0 = None self.stderr0 = None self.success_count = 0 self.failure_count = 0 self.error_count = 0 self.verbosity = verbosity # result is a list of result in 4 tuple # ( # result code (0: success; 1: fail; 2: error), # TestCase object, # Test output (byte string), # stack trace, # ) self.result = [] def startTest(self, test): TestResult.startTest(self, test) # just one buffer for both stdout and stderr self.outputBuffer = io.BytesIO() stdout_redirector.fp = self.outputBuffer stderr_redirector.fp = self.outputBuffer self.stdout0 = sys.stdout self.stderr0 = sys.stderr sys.stdout = stdout_redirector sys.stderr = stderr_redirector def complete_output(self): \"\"\" Disconnect output redirection and return buffer. Safe to call multiple times. \"\"\" if self.stdout0: sys.stdout = self.stdout0 sys.stderr = self.stderr0 self.stdout0 = None self.stderr0 = None return self.outputBuffer.getvalue() def stopTest(self, test): # Usually one of addSuccess, addError or addFailure would have been called. # But there are some path in unittest that would bypass this. # We must disconnect stdout in stopTest(), which is guaranteed to be called. self.complete_output() def addSuccess(self, test): self.success_count += 1 TestResult.addSuccess(self, test) output = self.complete_output() self.result.append((0, test, output, '')) if self.verbosity > 1: sys.stderr.write('ok ') sys.stderr.write(str(test)) sys.stderr.write('\\n') else: sys.stderr.write('.') def addError(self, test, err): self.error_count += 1 TestResult.addError(self, test, err) _, _exc_str = self.errors[-1] output = self.complete_output() self.result.append((2, test, output, _exc_str)) if self.verbosity > 1: sys.stderr.write('E ') sys.stderr.write(str(test)) sys.stderr.write('\\n') else: sys.stderr.write('E') def addFailure(self, test, err): self.failure_count += 1 TestResult.addFailure(self, test, err) _, _exc_str = self.failures[-1] output = self.complete_output() self.result.append((1, test, output, _exc_str)) if self.verbosity > 1: sys.stderr.write('F ') sys.stderr.write(str(test)) sys.stderr.write('\\n') else: sys.stderr.write('F') class HTMLTestRunner(Template_mixin): \"\"\" \"\"\" def __init__(self, stream=sys.stdout, verbosity=1, title=None, description=None): self.stream = stream self.verbosity = verbosity if title is None: self.title = self.DEFAULT_TITLE else: self.title = title if description is None: self.description = self.DEFAULT_DESCRIPTION else: self.description = description self.startTime = datetime.datetime.now() def run(self, test): \"Run the given test case or test suite.\" result = _TestResult(self.verbosity) test(result) self.stopTime = datetime.datetime.now() self.generateReport(test, result) print('\\nTime Elapsed: %s' % (self.stopTime - self.startTime), file=sys.stderr) return result def sortResult(self, result_list): # unittest does not seems to run in any particular order. # Here at least we want to group them together by class. rmap = {} classes = [] for n, t, o, e in result_list: cls = t.__class__ if not cls in rmap: rmap[cls] = [] classes.append(cls) rmap[cls].append((n, t, o, e)) r = [(cls, rmap[cls]) for cls in classes] return r def getReportAttributes(self, result): \"\"\" Return report attributes as a list of (name, value). Override this to add custom attributes. \"\"\" startTime = str(self.startTime)[:19] duration = str(self.stopTime - self.startTime) status = [] if result.success_count: status.append('Pass %s' % result.success_count) if result.failure_count: status.append('Failure %s' % result.failure_count) if result.error_count: status.append('Error %s' % result.error_count) if status: status = ' '.join(status) else: status = 'none' return [ ('Start Time', startTime), ('Duration', duration), ('Status', status), ] def generateReport(self, test, result): report_attrs = self.getReportAttributes(result) generator = 'HTMLTestRunner %s' % __version__ stylesheet = self._generate_stylesheet() heading = self._generate_heading(report_attrs) report = self._generate_report(result) ending = self._generate_ending() output = self.HTML_TMPL % dict( title=saxutils.escape(self.title), generator=generator, stylesheet=stylesheet, heading=heading, report=report, ending=ending, ) self.stream.write(output.encode('utf8')) def _generate_stylesheet(self): return self.STYLESHEET_TMPL def _generate_heading(self, report_attrs): a_lines = [] for name, value in report_attrs: line = self.HEADING_ATTRIBUTE_TMPL % dict( name=saxutils.escape(name), value=saxutils.escape(value), ) a_lines.append(line) heading = self.HEADING_TMPL % dict( title=saxutils.escape(self.title), parameters=''.join(a_lines), description=saxutils.escape(self.description), ) return heading def _generate_report(self, result): rows = [] sortedResult = self.sortResult(result.result) for cid, (cls, cls_results) in enumerate(sortedResult): # subtotal for a class np = nf = ne = 0 for n, t, o, e in cls_results: if n == 0: np += 1 elif n == 1: nf += 1 else: ne += 1 # format class description if cls.__module__ == \"__main__\": name = cls.__name__ else: name = \"%s.%s\" % (cls.__module__, cls.__name__) doc = cls.__doc__ and cls.__doc__.split(\"\\n\")[0] or \"\" desc = doc and '%s: %s' % (name, doc) or name row = self.REPORT_CLASS_TMPL % dict( style=ne > 0 and 'errorClass' or nf > 0 and 'failClass' or 'passClass', desc=desc, count=np + nf + ne, Pass=np, fail=nf, error=ne, cid='c%s' % (cid + 1), ) rows.append(row) for tid, (n, t, o, e) in enumerate(cls_results): self._generate_report_test(rows, cid, tid, n, t, o, e) report = self.REPORT_TMPL % dict( test_list=''.join(rows), count=str(result.success_count + result.failure_count + result.error_count), Pass=str(result.success_count), fail=str(result.failure_count), error=str(result.error_count), ) return report def _generate_report_test(self, rows, cid, tid, n, t, o, e): # e.g. 'pt1.1', 'ft1.1', etc has_output = bool(o or e) tid = (n == 0 and 'p' or 'f') + 't%s.%s' % (cid + 1, tid + 1) name = t.id().split('.')[-1] doc = t.shortDescription() or \"\" desc = doc and ('%s: %s' % (name, doc)) or name tmpl = has_output and self.REPORT_TEST_WITH_OUTPUT_TMPL or self.REPORT_TEST_NO_OUTPUT_TMPL # o and e should be byte string because they are collected from stdout and stderr? if isinstance(o, str): # TODO: some problem with 'string_escape': it escape \\n and mess up formating # uo = unicode(o.encode('string_escape')) uo = o else: uo = o.decode('utf-8') if isinstance(e, str): # TODO: some problem with 'string_escape': it escape \\n and mess up formating # ue = unicode(e.encode('string_escape')) ue = e else: ue = e.decode('utf-8') script = self.REPORT_TEST_OUTPUT_TMPL % dict( id=tid, output=saxutils.escape(uo + ue), ) row = tmpl % dict( tid=tid, Class=(n == 0 and 'hiddenRow' or 'none'), style=n == 2 and 'errorCase' or (n == 1 and 'failCase' or 'none'), desc=desc, script=script, status=self.STATUS[n], ) rows.append(row) if not has_output: return def _generate_ending(self): return self.ENDING_TMPL ############################################################################## # Facilities for running tests from the command line ############################################################################## # Note: Reuse unittest.TestProgram to launch test. In the future we may # build our own launcher to support more specific command line # parameters like test title, CSS, etc. class TestProgram(unittest.TestProgram): \"\"\" A variation of the unittest.TestProgram. Please refer to the base class for command line parameters. \"\"\" def runTests(self): # Pick HTMLTestRunner as the default test runner. # base class's testRunner parameter is not useful because it means # we have to instantiate HTMLTestRunner before we know self.verbosity. if self.testRunner is None: self.testRunner = HTMLTestRunner(verbosity=self.verbosity) unittest.TestProgram.runTests(self) main = TestProgram ############################################################################## # Executing this module from the command line ############################################################################## if __name__ == \"__main__\": main(module=None) import datetime import unittest from unittest_demo.HTMLTestRunner import HTMLTestRunner if __name__ == '__main__': suite = unittest.defaultTestLoader.discover('.', pattern=\"test_unittest.py\") time_str = datetime.datetime.now().strftime('%Y%m%d%H%M%S') with open(f\"./report_{time_str}.html\", 'wb') as f: runner = HTMLTestRunner(f, title=\"测试报告\", description=\"测试报告详情\") runner.run(suite) 测试报告中的测试用例的中文说明是测试用例函数的注释 "},"Python/Python语言基础/unittest/03-单元测试unittest集成篇.html":{"url":"Python/Python语言基础/unittest/03-单元测试unittest集成篇.html","title":"单元测试unittest集成篇","keywords":"","body":"datetime:2022/04/14 15:17 author:nzb 单元测试：unittest 集成篇 一、数据驱动简介 为什么需要数据驱动？正例、反例登录：同一个业务逻辑，代码逻辑是不变的，数据有很多组，业务逻辑和数据分离。 二、自动化主流的驱动模式介绍 数据驱动数据驱动把数据保存excel、csv、yaml、数据库，然后通过改变数据驱动我们的业务逻辑执行，并且得到不同的结果 关键字驱动关键字驱动其实是从面向对象的思想触发，它把一些业务逻辑代码封装成一个函数，方法作为一个关键字，然后调用不同的函数组成不同的复杂的业务逻辑 数据驱动+关键字驱动 三、unittest 的 ddt 数据驱动 什么是 ddt ？data driver test, 它可以完美的应用于 unittest 框架实现数据驱动 ddt 详解它是通过装饰器的方式来调用的 分为类装饰器和函数装饰器 @ddt：类装饰器，申明当前类使用 DDT 框架 @data：函数装饰器，用不给测试用例传递数据 @unpack：函数装饰器，降数据解包，一般用于元组和列表 @file_data：函数装饰器，用于读取json或yaml文件 用法 __date__ = \"2022/4/14 15:30\" import unittest from ddt import ddt, data, unpack @ddt class TestDdt(unittest.TestCase): \"\"\" @data(\"data1\") . ---------------------------------------------------------------------- Ran 1 test in 0.000s OK ('data1',) {} @data(\"data1\", \"data2\") ('data1',) {} ('data2',) {} .. ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK @data((\"data1\", \"data3\"), (\"data2\", \"data4\")) .. ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK (('data1', 'data3'),) {} (('data2', 'data4'),) {} @data((\"data1\", \"data3\"), (\"data2\", \"data4\")) @unpack ('data1', 'data3') {} ('data2', 'data4') {} .. ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK @data({\"a\": \"data1\", \"b\": \"data3\"}, {\"a\": \"data2\", \"b\": \"data4\"}) @unpack () {'a': 'data1', 'b': 'data3'} () {'a': 'data2', 'b': 'data4'} .. ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK @data({\"a\": \"data1\", \"b\": \"data3\"}, (\"data2\", \"data4\")) @unpack () {'a': 'data1', 'b': 'data3'} ('data2', 'data4') {} .. ---------------------------------------------------------------------- Ran 2 tests in 0.000s OK \"\"\" # @data(\"data1\") # @data(\"data1\", \"data2\") # @data((\"data1\", \"data3\"), (\"data2\", \"data4\")) # @data({\"a\": \"data1\", \"b\": \"data3\"}, {\"a\": \"data2\", \"b\": \"data4\"}) @data({\"a\": \"data1\", \"b\": \"data3\"}, (\"data2\", \"data4\")) @unpack def test_01(self, *args, **kwargs): \"\"\" 测试 test_01 :return: \"\"\" print(args) print(kwargs) if __name__ == '__main__': unittest.main() 总结 ddt 数据驱动中，测试用例的执行次数是有 @data() 传参的个数决定。传一个值用例执行一次，传多个值，用例执行多次 如果传的是元组(或列表)，那么可以使用 @unpack 解包元组和列表，但是需要注意的是，元组和列表中有多少个值，那么就必须用多少个变量来接收值，或者使用可变长度关键字和关键字参数接收 如果传的是多个字典，那么可以使用 @unpack 解包，但是需要注意的是：用例中的参数的名称和个数必须和字典的 key 保持一致，或者使用可变长度关键字和关键字参数接收 "},"Python/Python语言进阶/01-常用数据结构和算法.html":{"url":"Python/Python语言进阶/01-常用数据结构和算法.html","title":"常用数据结构","keywords":"","body":"datetime:2019/5/15 17:46 author:nzb 数据结构和算法 数据结构运行流程利器pythontutor 十大经典算法 算法：解决问题的方法和步骤 评价算法的好坏：渐近时间复杂度和渐近空间复杂度。 渐近时间复杂度的大O标记： - 常量时间复杂度 - 布隆过滤器 / 哈希存储 - 对数时间复杂度 - 折半查找（二分查找） - 线性时间复杂度 - 顺序查找 / 桶排序 - 对数线性时间复杂度 - 高级排序算法（归并排序、快速排序） - 平方时间复杂度 - 简单排序算法（选择排序、插入排序、冒泡排序） - 立方时间复杂度 - Floyd算法 / 矩阵乘法运算 - 几何级数时间复杂度 - 汉诺塔 - 阶乘时间复杂度 - 旅行经销商问题 - NP 排序算法（选择、冒泡和归并）和查找算法（顺序和折半） def select_sort(origin_items, comp=lambda x, y: x # 第一种 def bubble_sort(origin_items, comp=lambda x, y: x > y): \"\"\"高质量冒泡排序(搅拌排序)\"\"\" items = origin_items[:] for i in range(len(items) - 1): swapped = False for j in range(i, len(items) - 1 - i): if comp(items[j], items[j + 1]): items[j], items[j + 1] = items[j + 1], items[j] swapped = True if swapped: swapped = False for j in range(len(items) - 2 - i, i, -1): if comp(items[j - 1], items[j]): items[j], items[j - 1] = items[j - 1], items[j] swapped = True if not swapped: break return items # 第二种 def bubble_sort(origin_items, comp=lambda x, y: x > y): \"\"\"高质量冒泡排序(搅拌排序)\"\"\" items = origin_items[:] for i in range(1, len(items)): # 循环次数 for j in range(0, len(items) - i): # 循环索引 if comp(items[j], items[j + 1]): items[j], items[j + 1] = items[j + 1], items[j] return items # 第一种 def merge_sort(items, comp=lambda x, y: x def quick_sort(self, li): # 快速排序 通过 if len(li) tmp] return self.quick_sort(less) + [tmp] + self.quick_sort(more) def seq_search(items, key): \"\"\"顺序查找\"\"\" for index, item in enumerate(items): if item == key: return index return -1 def bin_search(items, key): \"\"\"折半查找\"\"\" start, end = 0, len(items) - 1 while start items[mid]: start = mid + 1 elif key 使用生成式（推导式）语法 prices = { 'AAPL': 191.88, 'GOOG': 1186.96, 'IBM': 149.24, 'ORCL': 48.44, 'ACN': 166.89, 'FB': 208.09, 'SYMC': 21.29 } # 用股票价格大于100元的股票构造一个新的字典 prices2 = {key: value for key, value in prices.items() if value > 100} print(prices2) 说明：生成式（推导式）可以用来生成列表、集合和字典。 嵌套的列表 names = ['关羽', '张飞', '赵云', '马超', '黄忠'] courses = ['语文', '数学', '英语'] # 录入五个学生三门课程的成绩 # 错误 - 参考http://pythontutor.com/visualize.html#mode=edit # scores = [[None] * len(courses)] * len(names) scores = [[None] * len(courses) for _ in range(len(names))] for row, name in enumerate(names): for col, course in enumerate(courses): scores[row][col] = float(input(f'请输入{name}的{course}成绩: ')) print(scores) Python Tutor - VISUALIZE CODE AND GET LIVE HELP heapq、itertools等的用法 \"\"\" 从列表中找出最大的或最小的N个元素 堆结构(大根堆/小根堆) \"\"\" import heapq list1 = [34, 25, 12, 99, 87, 63, 58, 78, 88, 92] list2 = [ {'name': 'IBM', 'shares': 100, 'price': 91.1}, {'name': 'AAPL', 'shares': 50, 'price': 543.22}, {'name': 'FB', 'shares': 200, 'price': 21.09}, {'name': 'HPQ', 'shares': 35, 'price': 31.75}, {'name': 'YHOO', 'shares': 45, 'price': 16.35}, {'name': 'ACME', 'shares': 75, 'price': 115.65} ] print(heapq.nlargest(3, list1)) print(heapq.nsmallest(3, list1)) print(heapq.nlargest(2, list2, key=lambda x: x['price'])) print(heapq.nlargest(2, list2, key=lambda x: x['shares'])) \"\"\" 迭代工具 - 排列 / 组合 / 笛卡尔积 \"\"\" import itertools itertools.permutations('ABCD') itertools.combinations('ABCDE', 3) itertools.product('ABCD', '123') collections模块下的工具类 \"\"\" 找出序列中出现次数最多的元素 \"\"\" from collections import Counter words = [ 'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes', 'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the', 'eyes', \"don't\", 'look', 'around', 'the', 'eyes', 'look', 'into', 'my', 'eyes', \"you're\", 'under' ] counter = Counter(words) print(counter.most_common(3)) 常用算法： 穷举法 - 又称为暴力破解法，对所有的可能性进行验证，直到找到正确答案。 贪婪法 - 在对问题求解时，总是做出在当前看来是最好的选择，不追求最优解，快速找到满意解。 分治法 - 把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题，直到可以直接求解的程度，最后将子问题的解进行合并得到原问题的解。 回溯法 - 回溯法又称为试探法，按选优条件向前搜索，当搜索到某一步发现原先选择并不优或达不到目标时，就退回一步重新选择。 动态规划 - 基本思想也是将待求解问题分解成若干个子问题，先求解并保存这些子问题的解，避免产生大量的重复运算。 穷举法例子：百钱百鸡和五人分鱼。 # 公鸡5元一只 母鸡3元一只 小鸡1元三只 # 用100元买100只鸡 问公鸡/母鸡/小鸡各多少只 for x in range(20): for y in range(33): z = 100 - x - y if 5 * x + 3 * y + z // 3 == 100 and z % 3 == 0: print(x, y, z) # A、B、C、D、E五人在某天夜里合伙捕鱼 最后疲惫不堪各自睡觉 # 第二天A第一个醒来 他将鱼分为5份 扔掉多余的1条 拿走自己的一份 # B第二个醒来 也将鱼分为5份 扔掉多余的1条 拿走自己的一份 # 然后C、D、E依次醒来也按同样的方式分鱼 问他们至少捕了多少条鱼 fish = 1 while True: total = fish enough = True for _ in range(5): if (total - 1) % 5 == 0: total = (total - 1) // 5 * 4 else: enough = False break if enough: print(fish) break fish += 1 贪婪法例子：假设小偷有一个背包，最多能装20公斤赃物，他闯入一户人家，发现如下表所示的物品。很显然，他不能把所有物品都装进背包，所以必须确定拿走哪些物品，留下哪些物品。 名称 价格（美元） 重量（kg） 电脑 200 20 收音机 20 4 钟 175 10 花瓶 50 2 书 10 1 油画 90 9 \"\"\" 贪婪法：在对问题求解时，总是做出在当前看来是最好的选择，不追求最优解，快速找到满意解。 输入： 20 6 电脑 200 20 收音机 20 4 钟 175 10 花瓶 50 2 书 10 1 油画 90 9 \"\"\" class Thing(object): \"\"\"物品\"\"\" def __init__(self, name, price, weight): self.name = name self.price = price self.weight = weight @property def value(self): \"\"\"价格重量比\"\"\" return self.price / self.weight def input_thing(): \"\"\"输入物品信息\"\"\" name_str, price_str, weight_str = input().split() return name_str, int(price_str), int(weight_str) def main(): \"\"\"主函数\"\"\" max_weight, num_of_things = map(int, input().split()) all_things = [] for _ in range(num_of_things): all_things.append(Thing(*input_thing())) all_things.sort(key=lambda x: x.value, reverse=True) total_weight = 0 total_price = 0 for thing in all_things: if total_weight + thing.weight 分治法例子：快速排序。 \"\"\" 快速排序 - 选择枢轴对元素进行划分，左边都比枢轴小右边都比枢轴大 \"\"\" def quick_sort(origin_items, comp=lambda x, y: x 回溯法例子：骑士巡逻。 \"\"\" 递归回溯法：叫称为试探法，按选优条件向前搜索，当搜索到某一步，发现原先选择并不优或达不到目标时，就退回一步重新选择，比较经典的问题包括骑士巡逻、八皇后和迷宫寻路等。 \"\"\" import sys import time SIZE = 5 total = 0 def print_board(board): for row in board: for col in row: print(str(col).center(4), end='') print() def patrol(board, row, col, step=1): if row >= 0 and row = 0 and col 动态规划例子1：斐波拉切数列。（不使用动态规划将会是几何级数复杂度） \"\"\" 动态规划 - 适用于有重叠子问题和最优子结构性质的问题 使用动态规划方法所耗时间往往远少于朴素解法(用空间换取时间) \"\"\" def fib(num, temp={}): \"\"\"用递归计算Fibonacci数\"\"\" if num in (1, 2): return 1 try: return temp[num] except KeyError: temp[num] = fib(num - 1) + fib(num - 2) return temp[num] 动态规划例子2：子列表元素之和的最大值。（使用动态规划可以避免二重循环） 说明：子列表指的是列表中索引（下标）连续的元素构成的列表；列表中的元素是int类型，可能包含正整数、0、负整数；程序输入列表中的元素，输出子列表元素求和的最大值，例如： 输入：1 -2 3 5 -3 2 输出：8 输入：0 -2 3 5 -1 2 输出：9 输入：-9 -2 -3 -5 -3 输出：-2 def main(): items = list(map(int, input().split())) size = len(items) overall, partial = {}, {} overall[size - 1] = partial[size - 1] = items[size - 1] for i in range(size - 2, -1, -1): partial[i] = max(items[i], partial[i + 1] + items[i]) overall[i] = max(partial[i], overall[i + 1]) print(overall[0]) if __name__ == '__main__': main() "},"Python/Python语言进阶/02-函数的高级用法.html":{"url":"Python/Python语言进阶/02-函数的高级用法.html","title":"函数的高级用法","keywords":"","body":"datetime:2019/5/16 13:23 author:nzb 函数的使用方式 将函数视为“一等公民” 函数可以赋值给变量 函数可以作为函数的参数 函数可以作为函数的返回值 高阶函数的用法（filter、map以及它们的替代品） items1 = list(map(lambda x: x ** 2, filter(lambda x: x % 2, range(1, 10)))) items2 = [x ** 2 for x in range(1, 10) if x % 2] 位置参数、可变参数、关键字参数、命名关键字参数 参数的元信息（代码可读性问题） 匿名函数和内联函数的用法（lambda函数） 闭包和作用域问题 闭包 函数内的属性，都是有生命周期，都是在函数执行期间 内部函数对外部函数作用域里变量的引用 闭包内的闭包函数私有化了变量，完成了数据的封装，类似面向对象 作用域 Python搜索变量的LEGB顺序（Local --> Embedded --> Global --> Built-in） global和nonlocal关键字的作用 global：声明或定义全局变量（要么直接使用现有的全局作用域的变量，要么定义一个变量放到全局作用域）。 nonlocal：声明使用嵌套作用域的变量（嵌套作用域必须存在该变量，否则报错）。 装饰器函数（使用装饰器和取消装饰器）语法糖 @ 最简单的例子： def func1(func): # 外部闭包函数的参数是被装饰的函数对象 def func2(): print('aaabbb') return func() # 返回了外部函数接收的被装饰函数的调用 return func2 # return func # 返回了函数对象 # return func() # 返回的是一个函数调用 # func1(myfunc)() # 接收别装饰的函数作为参数，而且还要继续调用一次 # func2() -> print('aaabbb') -> return myfunc() @func1 def myfunc(): print('你好') # 不影响原有函数的功能，还能添加新的功能 myfunc() # func1(myfunc)() 装饰器函数带参数（与下面一样）多一层包装来接收装饰器的参数 def arg_func(sex): def func1(b_func): def func2(): if sex == 'man': print('你是男士') if sex == 'woman': print('你是女士') return b_func() return func2 return func1 @arg_func(sex='man') def man(): print('好好上班') @arg_func(sex='woman') def woman(): print('好好上班') man() woman() 例子：输出函数执行时间的装饰器。 def record_time(func): \"\"\"自定义装饰函数的装饰器\"\"\" @wraps(func) def wrapper(*args, **kwargs): # 被装饰的函数带参数（最常见） start = time() result = func(*args, **kwargs) # 被装饰的函数带参数（最常见） print(f'{func.__name__}: {time() - start}秒') return result return wrapper 如果装饰器不希望跟print函数耦合，可以编写带参数的装饰器。 from functools import wraps from time import time def record(output): \"\"\"自定义带参数的装饰器\"\"\" def decorate(func): @wraps(func) def wrapper(*args, **kwargs): start = time() result = func(*args, **kwargs) output(func.__name__, time() - start) return result return wrapper return decorate from functools import wraps from time import time class Record(): \"\"\"自定义装饰器类(通过__call__魔术方法使得对象可以当成函数调用)\"\"\" def __init__(self, output): self.output = output def __call__(self, func): @wraps(func) def wrapper(*args, **kwargs): start = time() result = func(*args, **kwargs) self.output(func.__name__, time() - start) return result return wrapper 说明：由于对带装饰功能的函数添加了@wraps装饰器，可以通过func.__wrapped__方式获得被装饰之前的函数或类来取消装饰器的作用。 例子：用装饰器来实现单例模式。 from functools import wraps def singleton(cls): \"\"\"装饰类的装饰器\"\"\" instances = {} @wraps(cls) def wrapper(*args, **kwargs): if cls not in instances: instances[cls] = cls(*args, **kwargs) return instances[cls] return wrapper @singleton class President(): \"\"\"总统(单例类)\"\"\" pass 说明：上面的代码中用到了闭包（closure），不知道你是否已经意识到了。还有一个小问题就是，上面的代码并没有实现线程安全的单例，如果要实现线程安全的单例应该怎么做呢？ from functools import wraps def singleton(cls): \"\"\"线程安全的单例装饰器\"\"\" instances = {} locker = Lock() @wraps(cls) def wrapper(*args, **kwargs): if cls not in instances: with locker: if cls not in instances: instances[cls] = cls(*args, **kwargs) return instances[cls] return wrapper 装饰器模板 装饰器的作用：装饰器即可以装饰函数也可以装饰类。装饰器的原理：函数也是对象 使用装饰器：假设decorator是定义好的装饰器。 方法一：不用@符号 # 装饰器不传入参数时 f = decorator(函数名) # 装饰器传入参数时 f = (decorator(参数))(函数名) 或 decorator(参数)(函数名) 方法二：使用@符号 # 已定义的装饰器 @decorator def f(): pass # 执行被装饰过的函数 f() "},"Python/Python语言进阶/03-面向对象高级知识.html":{"url":"Python/Python语言进阶/03-面向对象高级知识.html","title":"面向对象高级知识","keywords":"","body":"datetime:2019/5/16 15:26 author:nzb 面向对象相关知识 三大支柱：封装、继承、多态 例子：工资结算系统。 \"\"\" 月薪结算系统 - 部门经理每月15000 程序员每小时200 销售员1800底薪加销售额5%提成 \"\"\" from abc import ABCMeta, abstractmethod class Employee(metaclass=ABCMeta): \"\"\"员工(抽象类)\"\"\" def __init__(self, name): self.name = name @abstractmethod def get_salary(self): \"\"\"结算月薪(抽象方法)\"\"\" pass class Manager(Employee): \"\"\"部门经理\"\"\" def get_salary(self): return 15000.0 class Programmer(Employee): \"\"\"程序员\"\"\" def __init__(self, name, working_hour=0): self.working_hour = working_hour super().__init__(name) def get_salary(self): return 200.0 * self.working_hour class Salesman(Employee): \"\"\"销售员\"\"\" def __init__(self, name, sales=0.0): self.sales = sales super().__init__(name) def get_salary(self): return 1800.0 + self.sales * 0.05 class EmployeeFactory(): \"\"\"创建员工的工厂（工厂模式 - 通过工厂实现对象使用者和对象之间的解耦合）\"\"\" @staticmethod def create(emp_type, *args, **kwargs): \"\"\"创建员工\"\"\" emp_type = emp_type.upper() emp = None if emp_type == 'M': emp = Manager(*args, **kwargs) elif emp_type == 'P': emp = Programmer(*args, **kwargs) elif emp_type == 'S': emp = Salesman(*args, **kwargs) return emp def main(): \"\"\"主函数\"\"\" emps = [ EmployeeFactory.create('M', '曹操'), EmployeeFactory.create('P', '荀彧', 120), EmployeeFactory.create('P', '郭嘉', 85), EmployeeFactory.create('S', '典韦', 123000), ] for emp in emps: print('%s: %.2f元' % (emp.name, emp.get_salary())) if __name__ == '__main__': main() 类与类之间的关系 is-a关系：继承 has-a关系：关联 / 聚合 / 合成 use-a关系：依赖 例子：扑克游戏。 \"\"\" 经验：符号常量总是优于字面常量，枚举类型是定义符号常量的最佳选择 \"\"\" from enum import Enum, unique import random @unique class Suite(Enum): \"\"\"花色\"\"\" SPADE, HEART, CLUB, DIAMOND = range(4) def __lt__(self, other): return self.value 对象的复制（深复制/深拷贝/深度克隆和浅复制/浅拷贝/影子克隆） 垃圾回收和循环引用以及弱引用 Python使用了自动化内存管理，这种管理机制以引用计数为基础，同时也引入了标记-清除和分代收集两种机制为辅的策略。 typedef struct_object { /* 引用计数 */ int ob_refcnt; /* 对象指针 */ struct_typeobject *ob_type; } PyObject; /* 增加引用计数的宏定义 */ #define Py_INCREF(op) ((op)->ob_refcnt++) /* 减少引用计数的宏定义 */ #define Py_DECREF(op) \\ //减少计数 if (--(op)->ob_refcnt != 0) \\ ; \\ else \\ __Py_Dealloc((PyObject *)(op)) 导致引用计数+1的情况： 对象被创建，例如a = 23 对象被引用，例如b = a 对象被作为参数，传入到一个函数中，例如f(a) 对象作为一个元素，存储在容器中，例如list1 = [a, a] 导致引用计数-1的情况： 对象的别名被显式销毁，例如del a 对象的别名被赋予新的对象，例如a = 24 一个对象离开它的作用域，例如f函数执行完毕时，f函数中的局部变量（全局变量不会） 对象所在的容器被销毁，或从容器中删除对象 引用计数可能会导致循环引用问题，而循环引用会导致内存泄露，如下面的代码所示。为了解决这个问题，Python中引入了“标记-清除”和“分代收集”。在创建一个对象的时候，对象被放在第一代中，如果在第一代的垃圾检查中对象存活了下来，该对象就会被放到第二代中，同理在第二代的垃圾检查中对象存活下来，该对象就会被放到第三代中。 # 循环引用会导致内存泄露 - Python除了引用技术还引入了标记清理和分代回收 # 在Python 3.6以前如果重写__del__魔术方法会导致循环引用处理失效 # 如果不想造成循环引用可以使用弱引用 list1 = [] list2 = [] list1.append(list2) list2.append(list1) 以下情况会导致垃圾回收： 调用gc.collect() gc模块的计数器达到阀值 程序退出 如果循环引用中两个对象都定义了__del__方法，gc模块不会销毁这些不可达对象，因为gc模块不知道应该先调用哪个对象的__del__方法，这个问题在Python 3.6中得到了解决。 也可以通过weakref模块构造弱引用的方式来解决循环引用的问题。 Python的内存管理机制及调优手段？ 内存管理机制: 引用计数、垃圾回收、内存池 引用计数：引用计数是一种非常高效的内存管理手段，当一个Python对象被引用时其引用计数增加1, def DisplayItems(self): print \"show all items---\" for item in self.__list: print item if hasattr(Parent, 'x'): print(getattr(Parent, 'x')) setattr(Parent, 'x',3) print(getattr(Parent,'x')) 当其不再被一个变量引用时则计数减1,当引用计数等于0时对象被删除。弱引用不会增加引用计数 垃圾回收：Python的垃圾回收机制采用引用计数机制为主，标记-清除和分代回收机制为辅的策略。 1.引用计数 引用计数也是一种垃圾收集机制，而且也是一种最直观、最简单的垃圾收集技术。当Python的某个对象 的引用计数降为0时，说明没有任何引用指向该对象，该对象就成为要被回收的垃圾了。比如某个新建 对象，它被分配给某个引用，对象的引用计数变为1，如果引用被删除，对象的引用计数为0,那么该对 象就可以被垃圾回收。不过如果出现循环引用的话，引用计数机制就不再起有效的作用了。 2.标记清除 3.分代回收 内存池 当创建大量消耗小内存的对象时，频繁调用 new/malloc 会导致大量的内存碎片，致使效率降低。内存池的作用就是预先在内存中申请一定数量的，大小相等的内存块留作备用，当有新的内存需求时，就先从内存池中分配内存给这个需求，不够之后再申请新的内存。这样做最显著的优势就是能够减少内存碎片，提升效率。 调优手段 1.手动垃圾回收 2.调高垃圾回收阈值 3.避免循环引用 内存泄露是什么？如何避免？ 内存泄漏指由于疏忽或错误造成程序未能释放已经不再使用的内存。内存泄漏并非指内存在物理上的消 失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控 制，从而造成了内存的浪费。 有 del() 函数的对象间的循环引用是导致内存泄露的主凶。不使用一个对象时使用: del object 来 删除一个对象的引用计数就可以有效防止内存泄露问题。 通过Python扩展模块gc 来查看不能回收的对象的详细信息。 可以通过 sys.getrefcount(obj) 来获取对象的引用计数，并根据返回值是否为0来判断是否内存泄露 魔法属性和方法（请参考《Python魔法方法指南》） 有几个小问题请大家思考： 自定义的对象能不能使用运算符做运算？ 自定义的对象能不能放到set中？能去重吗？ 自定义的对象能不能作为dict的键？ 自定义的对象能不能使用上下文语法？ 混入（Mixin） 例子：自定义字典限制只有在指定的key不存在时才能在字典中设置键值对。 class SetOnceMappingMixin(): \"\"\"自定义混入类\"\"\" __slots__ = () def __setitem__(self, key, value): if key in self: raise KeyError(str(key) + ' already set') return super().__setitem__(key, value) class SetOnceDict(SetOnceMappingMixin, dict): \"\"\"自定义字典\"\"\" pass my_dict= SetOnceDict() try: my_dict['username'] = 'jackfrued' my_dict['username'] = 'hellokitty' except KeyError: pass print(my_dict) 元编程和元类 Python2和Python3实现元类 # py2 class Foo(object): __metaclass__ = ABCMeta [...] # py3 class Simple1(object, metaclass=ABCMeta): [...] 用元类实现单例模式。 import threading class SingletonMeta(type): \"\"\"自定义元类\"\"\" def __init__(cls, *args, **kwargs): cls.__instance = None cls.__lock = threading.Lock() super().__init__(*args, **kwargs) def __call__(cls, *args, **kwargs): if cls.__instance is None: with cls.__lock: if cls.__instance is None: cls.__instance = super().__call__(*args, **kwargs) return cls.__instance class President(metaclass=SingletonMeta): \"\"\"总统(单例类)\"\"\" pass 面向对象设计原则 单一职责原则 （SRP）- 一个类只做该做的事情（类的设计要高内聚） 开闭原则 （OCP）- 软件实体应该对扩展开发对修改关闭 依赖倒转原则（DIP）- 面向抽象编程（在弱类型语言中已经被弱化） 里氏替换原则（LSP） - 任何时候可以用子类对象替换掉父类对象 接口隔离原则（ISP）- 接口要小而专不要大而全（Python中没有接口的概念） 合成聚合复用原则（CARP） - 优先使用强关联关系而不是继承关系复用代码 最少知识原则（迪米特法则，LoD）- 不要给没有必然联系的对象发消息 说明：上面加粗的字母放在一起称为面向对象的SOLID原则。 GoF设计模式 创建型模式：单例、工厂、建造者、原型 结构型模式：适配器、门面（外观）、代理 行为型模式：迭代器、观察者、状态、策略 例子：可插拔的哈希算法。 class StreamHasher(): \"\"\"哈希摘要生成器(策略模式)\"\"\" def __init__(self, alg='md5', size=4096): self.size = size alg = alg.lower() self.hasher = getattr(__import__('hashlib'), alg.lower())() def __call__(self, stream): return self.to_digest(stream) def to_digest(self, stream): \"\"\"生成十六进制形式的摘要\"\"\" for buf in iter(lambda: stream.read(self.size), b''): self.hasher.update(buf) return self.hasher.hexdigest() def main(): \"\"\"主函数\"\"\" hasher1 = StreamHasher() with open('Python-3.7.1.tgz', 'rb') as stream: print(hasher1.to_digest(stream)) hasher2 = StreamHasher('sha1') with open('Python-3.7.1.tgz', 'rb') as stream: print(hasher2(stream)) if __name__ == '__main__': main() "},"Python/Python语言进阶/04-迭代器和生成器.html":{"url":"Python/Python语言进阶/04-迭代器和生成器.html","title":"迭代器和生成器","keywords":"","body":"datetime:2019/5/16 15:32 author:nzb 迭代器和生成器 和迭代器相关的魔术方法（__iter__和__next__） 两种创建生成器的方式（生成器表达式和yield关键字） def fib(num): \"\"\"生成器\"\"\" a, b = 0, 1 for _ in range(num): a, b = b, a + b yield a class Fib(object): \"\"\"迭代器\"\"\" def __init__(self, num): self.num = num self.a, self.b = 0, 1 self.idx = 0 def __iter__(self): return self def __next__(self): if self.idx 生成器，迭代器的区别？ 迭代器：遵循迭代协议的对象。用户可以使用 iter() 以从任何序列得到迭代器（如 list, tuple,dictionary, set 等）。 另一个方法则是创建一个另一种形式的迭代器 —— generator 。要获取下一个元素，则使用成员函数 next()（Python 2） 或函数 next() function （Python 3） 。当没有元素时，则引发 StopIteration 此例外。若要实现自己的迭代器， 则只要实现 next() （Python 2）或 next ()（Python 3） 生成器（Generator）：只是在需要返回数据的时候使用yield语句。每次 next() 被调用时，生成器会返回它脱离的位置（它记忆语句最后一次执行的位置和所有的数据值） 区别： 生成器能做到迭代器能做的所有事，而且因为自动创建 iter() 和 next() 方法，生成器显得特别简洁，而且生成器也是高效的， 使用生成器表达式取代列表解析可以同时节省内存。除了创建和保存程序状态的自动方法，当发生器终结时，还会自动抛出StopIteration异常。 列表推导式、字典推导式以及生成器 import random l = [i for i in range(10)] d = {k: random.randint(4, 9) for k in ['a', 'c', 'd']} g = (i for i in range(10)) print(\"列表推导式：{}，类型：{}\".format(l, type(l))) print(\"字典推导式：{}，类型：{}\".format(d, type(d))) print(\"生成器：{}，类型：{}\".format(g, type(g))) # 结果 # 列表推导式：[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]，类型： # 字典推导式：{'a': 5, 'c': 6, 'd': 9}，类型： # 生成器： at 0x0000023498EF9390>，类型： "},"Python/Python语言进阶/05-并发和异步编程.html":{"url":"Python/Python语言进阶/05-并发和异步编程.html","title":"并发和异步编程","keywords":"","body":"datetime:2019/5/16 16:13 author:nzb 并发编程 Python中实现并发编程的三种方案：多线程、多进程和异步I/O。并发编程的好处在于可以提升程序的执行效率以及改善用户体验；坏处在于并发的程序不容易开发和调试，同时对其他程序来说它并不友好。 多线程 Python中提供了Thread类并辅以Lock、Condition、Event、Semaphore和Barrier。Python中有GIL来防止多个线程同时执行本地字节码，这个锁对于CPython是必须的，因为CPython的内存管理并不是线程安全的，因为GIL的存在多线程并不能发挥CPU的多核特性。 # 面试题：进程和线程的区别和联系？ # 进程 - 操作系统分配内存的基本单位 - 一个进程可以包含一个或多个线程 # 线程 - 操作系统分配CPU的基本单位 # 并发编程（concurrent programming） # 1. 提升执行性能 - 让程序中没有因果关系的部分可以并发的执行 # 2. 改善用户体验 - 让耗时间的操作不会造成程序的假死 import glob import os import threading from PIL import Image PREFIX = 'thumbnails' def generate_thumbnail(infile, size, format='PNG'): \"\"\"生成指定图片文件的缩略图\"\"\" file, ext = os.path.splitext(infile) file = file[file.rfind('/') + 1:] outfile = f'{PREFIX}/{file}_{size[0]}_{size[1]}.{ext}' img = Image.open(infile) img.thumbnail(size, Image.ANTIALIAS) img.save(outfile, format) def main(): \"\"\"主函数\"\"\" if not os.path.exists(PREFIX): os.mkdir(PREFIX) for infile in glob.glob('images/*.png'): for size in (32, 64, 128): # 创建并启动线程 threading.Thread( target=generate_thumbnail, args=(infile, (size, size)) ).start() if __name__ == '__main__': main() 多个线程竞争资源的情况 # 多线程程序如果没有竞争资源处理起来通常也比较简单 # 当多个线程竞争临界资源的时候如果缺乏必要的保护措施就会导致数据错乱 # 说明：临界资源就是被多个线程竞争的资源 import time import threading from concurrent.futures import ThreadPoolExecutor class Account(object): \"\"\"银行账户\"\"\" def __init__(self): self.balance = 0.0 self.lock = threading.Lock() def deposit(self, money): # 通过锁保护临界资源 with self.lock: new_balance = self.balance + money time.sleep(0.001) self.balance = new_balance class AddMoneyThread(threading.Thread): \"\"\"自定义线程类\"\"\" def __init__(self, account, money): self.account = account self.money = money # 自定义线程的初始化方法中必须调用父类的初始化方法 super().__init__() def run(self): # 线程启动之后要执行的操作 self.account.deposit(self.money) def main(): \"\"\"主函数\"\"\" account = Account() # 创建线程池 pool = ThreadPoolExecutor(max_workers=10) futures = [] for _ in range(100): # 创建线程的第1种方式 # threading.Thread( # target=account.deposit, args=(1, ) # ).start() # 创建线程的第2种方式 # AddMoneyThread(account, 1).start() # 创建线程的第3种方式 # 调用线程池中的线程来执行特定的任务 future = pool.submit(account.deposit, 1) futures.append(future) # 关闭线程池 pool.shutdown() for future in futures: future.result() print(account.balance) if __name__ == '__main__': main() 修改上面的程序，启动5个线程向账户中存钱，5个线程从账户中取钱，取钱时如果余额不足就暂停线程进行等待。为了达到上述目标，需要对存钱和取钱的线程进行调度，在余额不足时取钱的线程暂停并释放锁，而存钱的线程将钱存入后要通知取钱的线程，使其从暂停状态被唤醒。可以使用threading 模块的Condition来实现线程调度，该对象也是基于锁来创建的，代码如下所示： # 多个线程竞争一个资源 - 保护临界资源 - 锁（Lock/RLock） # 多个线程竞争多个资源（线程数>资源数） - 信号量（Semaphore） # 多个线程的调度 - 暂停线程执行/唤醒等待中的线程 - Condition from concurrent.futures import ThreadPoolExecutor from random import randint from time import sleep import threading class Account(): \"\"\"银行账户\"\"\" def __init__(self, balance=0): self.balance = balance lock = threading.Lock() self.condition = threading.Condition(lock) def withdraw(self, money): \"\"\"取钱\"\"\" with self.condition: while money > self.balance: self.condition.wait() new_balance = self.balance - money sleep(0.001) self.balance = new_balance def deposit(self, money): \"\"\"存钱\"\"\" with self.condition: new_balance = self.balance + money sleep(0.001) self.balance = new_balance self.condition.notify_all() def add_money(account): while True: money = randint(5, 10) account.deposit(money) print(threading.current_thread().name, ':', money, '====>', account.balance) sleep(0.5) def sub_money(account): while True: money = randint(10, 30) account.withdraw(money) print(threading.current_thread().name, ':', money, ' 多进程 多进程可以有效的解决GIL的问题，实现多进程主要的类是Process，其他辅助的类跟threading模块中的类似，进程间共享数据可以使用管道、套接字等，在multiprocessing模块中有一个Queue类，它基于管道和锁机制提供了多个进程共享的队列。下面是官方文档上关于多进程和进程池的一个示例。 # 多进程和进程池的使用 # 多线程因为GIL的存在不能够发挥CPU的多核特性 # 对于计算密集型任务应该考虑使用多进程 # time python3 example22.py # real 0m11.512s # user 0m39.319s # sys 0m0.169s # 使用多进程后实际执行时间为11.512秒，而用户时间39.319秒约为实际执行时间的4倍 # 这就证明我们的程序通过多进程使用了CPU的多核特性，而且这台计算机配置了4核的CPU import concurrent.futures import math PRIMES = [ 1116281, 1297337, 104395303, 472882027, 533000389, 817504243, 982451653, 112272535095293, 112582705942171, 112272535095293, 115280095190773, 115797848077099, 1099726899285419 ] * 5 def is_prime(n): \"\"\"判断素数\"\"\" if n % 2 == 0: return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n + 1, 2): if n % i == 0: return False return True def main(): \"\"\"主函数\"\"\" with concurrent.futures.ProcessPoolExecutor() as executor: for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)): print('%d is prime: %s' % (number, prime)) if __name__ == '__main__': main() 说明：多线程和多进程的比较。 以下情况需要使用多线程： 程序需要维护许多共享的状态（尤其是可变状态），Python中的列表、字典、集合都是线程安全的，所以使用线程而不是进程维护共享状态的代价相对较小。 程序会花费大量时间在I/O操作上，没有太多并行计算的需求且不需占用太多的内存。 以下情况需要使用多进程： 程序执行计算密集型任务（如：字节码操作、数据处理、科学计算）。 程序的输入可以并行的分成块，并且可以将运算结果合并。 程序在内存使用方面没有任何限制且不强依赖于I/O操作（如：读写文件、套接字等）。 协程 异步处理：从调度程序的任务队列中挑选任务，该调度程序以交叉的形式执行这些任务，我们并不能保证任务将以某种顺序去执行，因为执行顺序取决于队列中的一项任务是否愿意将CPU处理时间让位给另一项任务。异步任务通常通过多任务协作处理的方式来实现，由于执行时间和顺序的不确定，因此需要通过回调式编程或者future 对象来获取任务执行的结果。Python 3通过asyncio模块和await和async关键字（在Python 3.7中正式被列为关键字）来支持异步处理。 # 异步I/O - async / await import asyncio def num_generator(m, n): \"\"\"指定范围的数字生成器\"\"\" yield from range(m, n + 1) async def prime_filter(m, n): \"\"\"素数过滤器\"\"\" primes = [] for i in num_generator(m, n): flag = True for j in range(2, int(i ** 0.5 + 1)): if i % j == 0: flag = False break if flag: print('Prime =>', i) primes.append(i) await asyncio.sleep(0.001) return tuple(primes) async def square_mapper(m, n): \"\"\"平方映射器\"\"\" squares = [] for i in num_generator(m, n): print('Square =>', i * i) squares.append(i * i) await asyncio.sleep(0.001) return squares def main(): \"\"\"主函数\"\"\" loop = asyncio.get_event_loop() future = asyncio.gather(prime_filter(2, 100), square_mapper(1, 100)) future.add_done_callback(lambda x: print(x.result())) loop.run_until_complete(future) loop.close() if __name__ == '__main__': main() 说明：上面的代码使用get_event_loop函数获得系统默认的事件循环，通过gather函数可以获得一个future对象，future对象的add_done_callback可以添加执行完成时的回调函数，loop对象的run_until_complete方法可以等待通过future对象获得协程执行结果。 Python中有一个名为aiohttp的三方库，它提供了异步的HTTP客户端和服务器，这个三方库可以跟asyncio模块一起工作，并提供了对Future对象的支持。Python 3.6中引入了async和await来定义异步执行的函数以及创建异步上下文，在Python 3.7中它们正式成为了关键字。下面的代码异步的从5个URL中获取页面并通过正则表达式的命名捕获组提取了网站的标题。 import asyncio import re import aiohttp PATTERN = re.compile(r'\\(?P.*)\\') async def fetch_page(session, url): async with session.get(url, ssl=False) as resp: return await resp.text() async def show_title(url): async with aiohttp.ClientSession() as session: html = await fetch_page(session, url) print(PATTERN.search(html).group('title')) def main(): urls = ('https://www.python.org/', 'https://git-scm.com/', 'https://www.jd.com/', 'https://www.taobao.com/', 'https://www.douban.com/') loop = asyncio.get_event_loop() tasks = [show_title(url) for url in urls] loop.run_until_complete(asyncio.wait(tasks)) loop.close() if __name__ == '__main__': main() 说明：异步I/O与多进程的比较。 当程序不需要真正的并发性或并行性，而是更多的依赖于异步处理和回调时，asyncio就是一种很好的选择。如果程序中有大量的等待与休眠时，也应该考虑asyncio，它很适合编写没有实时数据处理需求的Web应用服务器。 Python还有很多用于处理并行任务的三方库，例如：joblib、PyMP等。实际开发中，要提升系统的可扩展性和并发性通常有垂直扩展（增加单个节点的处理能力）和水平扩展（将单个节点变成多个节点）两种做法。可以通过消息队列来实现应用程序的解耦合，消息队列相当于是多线程同步队列的扩展版本，不同机器上的应用程序相当于就是线程，而共享的分布式消息队列就是原来程序中的Queue。消息队列（面向消息的中间件）的最流行和最标准化的实现是AMQP（高级消息队列协议），AMQP源于金融行业，提供了排队、路由、可靠传输、安全等功能，最著名的实现包括：Apache的ActiveMQ、RabbitMQ等。 要实现任务的异步化，可以使用名为Celery的三方库。Celery是Python编写的分布式任务队列，它使用分布式消息进行工作，可以基于RabbitMQ或Redis来作为后端的消息代理。 "},"Python/Python语言进阶/06-asyncio异步编程.html":{"url":"Python/Python语言进阶/06-asyncio异步编程.html","title":"asynico异步编程","keywords":"","body":"datetime:2021/11/12 11:00 author:nzb asyncio 异步编程 如今编程都往异步发展，尽可能高效利用系统资源，比如：FastAPI、Tornado、Sanic、Django 3、aiohttp 等。所以，咱怎么能落后呢！！！ 1 协程 想学 asyncio，得先了解协程，协程是根本呀！ 协程（Coroutine），也可以被称为微线程，是一种用户态内的上下文切换技术。简而言之，其实就是通过一个线程实现代码块相互切换执行。例如： def func1(): print(1) ... print(2) def func2(): print(3) ... print(4) func1() func2() 上述代码是普通的函数定义和执行，按流程分别执行两个函数中的代码，并先后会输出：1、2、3、4。但如果介入协程技术那么就可以实现函数见代码切换执行，最终输入：1、3、2、4。 在Python中有多种方式可以实现协程，例如： greenlet：是一个第三方模块，用于实现协程代码（Gevent协程就是基于 greenlet 实现） yield：生成器，借助生成器的特点也可以实现协程代码。 asyncio：在 Python3.4 中引入的模块用于编写协程代码。 async & awiat：在 Python3.5 中引入的两个关键字，结合 asyncio 模块可以更方便的编写协程代码。 1.1 greenlet greentlet 是一个第三方模块，需要提前安装 pip3 install greenlet 才能使用。 from greenlet import greenlet def func1(): print(1) # 第1步：输出 1 gr2.switch() # 第3步：切换到 func2 函数 print(2) # 第6步：输出 2 gr2.switch() # 第7步：切换到 func2 函数，从上一次执行的位置继续向后执行 def func2(): print(3) # 第4步：输出 3 gr1.switch() # 第5步：切换到 func1 函数，从上一次执行的位置继续向后执行 print(4) # 第8步：输出 4 gr1 = greenlet(func1) gr2 = greenlet(func2) gr1.switch() # 第1步：去执行 func1 函数 注意：switch 中也可以传递参数用于在切换执行时相互传递值。 1.2 yield 基于 Python 的生成器的 yield 和 yield form 关键字实现协程代码。 def func1(): yield 1 yield from func2() yield 2 def func2(): yield 3 yield 4 f1 = func1() for item in f1: print(item) 注意：yield form 关键字是在 Python3.3 中引入的。 1.3 asyncio 在 Python3.4 之前官方未提供协程的类库，一般大家都是使用 greenlet 等其他来实现。在 Python3.4 发布后官方正式支持协程，即：asyncio 模块。 import asyncio @asyncio.coroutine def func1(): print(1) yield from asyncio.sleep(2) # 遇到IO耗时操作，自动化切换到tasks中的其他任务 print(2) @asyncio.coroutine def func2(): print(3) yield from asyncio.sleep(2) # 遇到IO耗时操作，自动化切换到tasks中的其他任务 print(4) tasks = [ asyncio.ensure_future(func1()), asyncio.ensure_future(func2()) ] loop = asyncio.get_event_loop() loop.run_until_complete(asyncio.wait(tasks)) 注意：基于 asyncio 模块实现的协程比之前的要更厉害，因为他的内部还集成了遇到IO耗时操作自动切花的功能。 1.4 async & awit async & awit 关键字在 Python3.5 版本中正式引入，基于他编写的协程代码其实就是上一示例的加强版，让代码可以更加简便。 Python3.8 之后 @asyncio.coroutine 装饰器就会被移除，推荐使用 async & awit关键字实现协程代码。 import asyncio async def func1(): print(1) await asyncio.sleep(2) print(2) async def func2(): print(3) await asyncio.sleep(2) print(4) tasks = [ asyncio.ensure_future(func1()), asyncio.ensure_future(func2()) ] loop = asyncio.get_event_loop() loop.run_until_complete(asyncio.wait(tasks)) 1.5 小结 关于协程有多种实现方式，目前主流使用是 Python 官方推荐的 asyncio 模块和 async & await 关键字的方式，例如：在 tonado、sanic、fastapi、django3 中均已支持。 接下来，也会针对 asyncio模块 + async & await 关键字进行更加详细的讲解。 2 协程的意义 通过上面，已经了解到协程可以通过一个线程在多个上下文中进行来回切换执行。 但是，协程来回切换执行的意义何在呢？（网上看到很多文章舔协程，协程牛逼之处是哪里呢？） 计算型的操作，利用协程来回切换执行，没有任何意义，来回切换并保存状态 反倒会降低性能。 IO型的操作，利用协程在IO等待时间就去切换执行其他任务，当IO操作结束后再自动回调，那么就会大大节省资源并提供性能，从而实现异步编程（不等待任务结束就可以去执行其他代码）。 2.1 爬虫案例 例如：用代码实现下载 url_list 中的图片。 方式一：同步编程实现 # 下载图片使用第三方模块requests，请提前安装：pip3 install requests import requests def download_image(url): print(\"开始下载:\", url) # 发送网络请求，下载图片 response = requests.get(url) print(\"下载完成\") # 图片保存到本地文件 file_name = url.rsplit('_')[-1] with open(file_name, mode='wb') as file_object: file_object.write(response.content) if __name__ == '__main__': url_list = [ 'https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg', 'https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg', 'https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg' ] for item in url_list: download_image(item) 方式二：基于协程的异步编程实现 # 下载图片使用第三方模块aiohttp，请提前安装：pip3 install aiohttp # !/usr/bin/env python # -*- coding:utf-8 -*- import aiohttp import asyncio async def fetch(session, url): print(\"发送请求：\", url) async with session.get(url, verify_ssl=False) as response: content = await response.content.read() file_name = url.rsplit('_')[-1] with open(file_name, mode='wb') as file_object: file_object.write(content) async def main(): async with aiohttp.ClientSession() as session: url_list = [ 'https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg', 'https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg', 'https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg' ] tasks = [asyncio.create_task(fetch(session, url)) for url in url_list] await asyncio.wait(tasks) if __name__ == '__main__': asyncio.run(main()) 上述两种的执行对比之后会发现，基于协程的异步编程要比同步编程的效率高了很多。因为： 同步编程，按照顺序逐一排队执行，如果图片下载时间为 2分钟，那么全部执行完则需要 6分钟。 异步编程，几乎同时发出了 3个下载任务的请求（遇到 IO 请求自动切换去发送其他任务请求），如果图片下载时间为 2分钟，那么全部执行完毕也大概需要 2分钟左右就可以了。 2.2 小结 协程一般应用在有 IO操作的程序中，因为协程可以利用 IO等待的时间去执行一些其他的代码，从而提升代码执行效率。 生活中不也是这样的么，假设 你是一家制造汽车的老板，员工点击设备的【开始】按钮之后，在设备前需等待 30分钟，然后点击【结束】按钮，此时作为老板的你一定希望这个员工在等待的那 30分钟的时间去做点其他的工作。 3 异步编程 基于 async & await 关键字的协程可以实现异步编程，这也是目前 python 异步相关的主流技术。想要真正的了解 Python 中内置的异步编程，根据下文的顺序一点点来看。 3.1 事件循环 事件循环，可以把他当做是一个 while 循环，这个 while 循环在周期性的运行并执行一些任务，在特定条件下终止循环。 # 伪代码 任务列表 = [ 任务1, 任务2, 任务3,... ] while True: 可执行的任务列表，已完成的任务列表 = 去任务列表中检查所有的任务，将'可执行'和'已完成'的任务返回 for 就绪任务 in 已准备就绪的任务列表: 执行已就绪的任务 for 已完成的任务 in 已完成的任务列表: 在任务列表中移除 已完成的任务 如果 任务列表 中的任务都已完成，则终止循环 在编写程序时候可以通过如下代码来获取和创建事件循环。 import asyncio loop = asyncio.get_event_loop() 3.2 协程和异步编程 协程函数，定义形式为 async def 的函数。 协程对象，调用 协程函数 所返回的对象。 # 定义一个协程函数 async def func(): pass # 调用协程函数，返回一个协程对象 result = func() 注意：调用协程函数时，函数内部代码不会执行，只是会返回一个协程对象。 3.2.1 基本应用 程序中，如果想要执行协程函数的内部代码，需要 事件循环 和 协程对象 配合才能实现，如： import asyncio async def func(): print(\"协程内部代码\") # 调用协程函数，返回一个协程对象。 result = func() # 方式一 # loop = asyncio.get_event_loop() # 创建一个事件循环 # loop.run_until_complete(result) # 将协程当做任务提交到事件循环的任务列表中，协程执行完成之后终止。 # 方式二 # 本质上方式一是一样的，内部先 创建事件循环 然后执行 run_until_complete，一个简便的写法。 # asyncio.run 函数在 Python 3.7 中加入 asyncio 模块， asyncio.run(result) 这个过程可以简单理解为：将协程当做任务添加到 事件循环 的任务列表，然后事件循环检测列表中的协程是否 已准备就绪（默认可理解为就绪状态），如果准备就绪则执行其内部代码。 3.2.2 await await 是一个只能在协程函数中使用的关键字，用于遇到 IO 操作时挂起 当前协程（任务），当前协程（任务）挂起过程中 事件循环可以去执行其他的协程（任务），当前协程IO处理完成时，可以再次切换回来执行 await 之后的代码。代码如下： 示例1： import asyncio async def func(): print(\"执行协程函数内部代码\") # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。 # 当前协程挂起时，事件循环可以去执行其他协程（任务）。 response = await asyncio.sleep(2) print(\"IO请求结束，结果为：\", response) result = func() asyncio.run(result) 示例2： import asyncio async def others(): print(\"start\") await asyncio.sleep(2) print('end') return '返回值' async def func(): print(\"执行协程函数内部代码\") # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。 response = await others() print(\"IO请求结束，结果为：\", response) asyncio.run(func()) 示例3： import asyncio async def others(): print(\"start\") await asyncio.sleep(2) print('end') return '返回值' async def func(): print(\"执行协程函数内部代码\") # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。 response1 = await others() print(\"IO请求结束，结果为：\", response1) response2 = await others() print(\"IO请求结束，结果为：\", response2) asyncio.run(func()) 上述的所有示例都只是创建了一个任务，即：事件循环的任务列表中只有一个任务，所以在 IO 等待时无法演示切换到其他任务效果。 在程序想要创建多个任务对象，需要使用 Task 对象来实现。 3.2.3 Task对象 Tasks are used to schedule coroutines concurrently. When a coroutine is wrapped into a Task with functions like asyncio.create_task() the coroutine is automatically scheduled to run soon。 Tasks用于并发调度协程，通过 asyncio.create_task(协程对象) 的方式创建 Task 对象，这样可以让协程加入事件循环中等待被调度执行。除了使用 asyncio.create_task() 函数以外，还可以用低层级的 loop.create_task() 或 ensure_future() 函数。不建议手动实例化 Task 对象。 本质上是将协程对象封装成task对象，并将协程立即加入事件循环，同时追踪协程的状态。 注意：asyncio.create_task() 函数在 Python 3.7 中被加入。在 Python 3.7 之前，可以改用低层级的 asyncio.ensure_future() 函数。 示例1： import asyncio async def func(): print(1) await asyncio.sleep(2) print(2) return \"返回值\" async def main(): print(\"main开始\") # 创建协程，将协程封装到一个Task对象中并立即添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。 task1 = asyncio.create_task(func()) # 创建协程，将协程封装到一个Task对象中并立即添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。 task2 = asyncio.create_task(func()) print(\"main结束\") # 当执行某协程遇到IO操作时，会自动化切换执行其他任务。 # 此处的await是等待相对应的协程全都执行完毕并获取结果 ret1 = await task1 ret2 = await task2 print(ret1, ret2) asyncio.run(main()) 示例2： import asyncio async def func(): print(1) await asyncio.sleep(2) print(2) return \"返回值\" async def main(): print(\"main开始\") # 创建协程，将协程封装到Task对象中并添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。 # 在调用 task_list = [ asyncio.create_task(func(), name=\"n1\"), asyncio.create_task(func(), name=\"n2\") ] print(\"main结束\") # 当执行某协程遇到IO操作时，会自动化切换执行其他任务。 # 此处的await是等待所有协程执行完毕，并将所有协程的返回值保存到done # 如果设置了timeout值，则意味着此处最多等待的秒，完成的协程返回值写入到done中，未完成则写到pending中。 done, pending = await asyncio.wait(task_list, timeout=None) print(done, pending) asyncio.run(main()) 注意：asyncio.wait 源码内部会对列表中的每个协程执行 ensure_future 从而封装为Task对象，所以在和wait配合使用时task_list的值为[func(),func()] 也是可以的。 示例3： import asyncio async def func(): print(\"执行协程函数内部代码\") # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。 response = await asyncio.sleep(2) print(\"IO请求结束，结果为：\", response) coroutine_list = [func(), func()] # 错误：coroutine_list = [ asyncio.create_task(func()), asyncio.create_task(func()) ] # 此处不能直接 asyncio.create_task，因为将 Task 立即加入到事件循环的任务列表。 # 但此时事件循环还未创建，所以会报错。事件循环创建在 asyncio.run 里面才创建。 # 使用 asyncio.wait 将列表封装为一个协程，并调用 asyncio.run 实现执行两个协程 # asyncio.wait 内部会对列表中的每个协程执行 ensure_future，封装为 Task 对象。 done, pending = asyncio.run(asyncio.wait(coroutine_list)) 3.2.4 asyncio.Future 对象 A Futureis a special low-level awaitable object that represents an eventual result of an asynchronous operation. asyncio中的Future对象是一个相对更偏向底层的可等待对象，通常我们不会直接用到这个对象，而是直接使用Task对象来完成任务的并和状态的追踪。（ Task 是 Futrue的子类 ） Future为我们提供了异步编程中的 最终结果 的处理（Task类也具备状态处理的功能）。 示例1： async def main(): # 获取当前事件循环 loop = asyncio.get_running_loop() # # 创建一个任务（Future对象），这个任务什么都不干。 fut = loop.create_future() # 等待任务最终结果（Future对象），没有结果则会一直等下去。 await fut asyncio.run(main()) 示例2： import asyncio async def set_after(fut): await asyncio.sleep(2) fut.set_result(\"666\") async def main(): # 获取当前事件循环 loop = asyncio.get_running_loop() # 创建一个任务（Future对象），没绑定任何行为，则这个任务永远不知道什么时候结束。 fut = loop.create_future() # 创建一个任务（Task对象），绑定了set_after函数，函数内部在2s之后，会给fut赋值。 # 即手动设置future任务的最终结果，那么fut就可以结束了。 await loop.create_task(set_after(fut)) # 等待 Future对象获取 最终结果，否则一直等下去 data = await fut print(data) asyncio.run(main()) Future 对象本身函数进行绑定，所以想要让事件循环获取 Future 的结果，则需要手动设置。而 Task 对象继承了 Future 对象，其实就对 Future 进行扩展，他可以实现在对应绑定的函数执行完成之后，自动执行 set_result，从而实现自动结束。 虽然，平时使用的是 Task 对象，但对于结果的处理本质是基于 Future 对象来实现的。 扩展：支持 await 对象语法的对象可成为可等待对象，所以 协程对象、Task 对象、Future 对象 都可以被成为可等待对象。 3.2.5 futures.Future对象 在Python的concurrent.futures模块中也有一个Future对象，这个对象是基于线程池和进程池实现异步操作时使用的对象。 import time from concurrent.futures import Future from concurrent.futures.thread import ThreadPoolExecutor from concurrent.futures.process import ProcessPoolExecutor def func(value): time.sleep(1) print(value) pool = ThreadPoolExecutor(max_workers=5) # 或 pool = ProcessPoolExecutor(max_workers=5) for i in range(10): fut = pool.submit(func, i) print(fut) 两个Future对象是不同的，他们是为不同的应用场景而设计，例如：concurrent.futures.Future 不支持await语法 等。 官方提示两对象之间不同： unlike asyncio Futures, concurrent.futures.Future instances cannot be awaited. asyncio.Future.result() and asyncio.Future.exception() do not accept the timeout argument. asyncio.Future.result() and asyncio.Future.exception() raise an InvalidStateError exception when the Future is not done. Callbacks registered with asyncio.Future.add_done_callback() are not called immediately. They are scheduled with loop.call_soon() instead. asyncio Future is not compatible with the concurrent.futures.wait() and concurrent.futures.as_completed() functions. 在 Python 提供了一个将futures.Future 对象包装成asyncio.Future对象的函数 asynic.wrap_future。 为什么python会提供这种功能？ 其实，一般在程序开发中我们要么统一使用 asycio 的协程实现异步操作、要么都使用进程池和线程池实现异步操作。但如果协程的异步和进程池/线程池的异步混搭时，那么就会用到此功能了。 import time import asyncio import concurrent.futures def func1(): # 某个耗时操作 time.sleep(2) return \"SB\" async def main(): loop = asyncio.get_running_loop() # 1. Run in the default loop's executor ( 默认ThreadPoolExecutor ) # 第一步：内部会先调用 ThreadPoolExecutor 的 submit 方法去线程池中申请一个线程去执行func1函数，并返回一个concurrent.futures.Future对象 # 第二步：调用asyncio.wrap_future将concurrent.futures.Future对象包装为asycio.Future对象。 # 因为concurrent.futures.Future对象不支持await语法，所以需要包装为 asycio.Future对象 才能使用。 fut = loop.run_in_executor(None, func1) result = await fut print('default thread pool', result) # 2. Run in a custom thread pool: # with concurrent.futures.ThreadPoolExecutor() as pool: # result = await loop.run_in_executor( # pool, func1) # print('custom thread pool', result) # 3. Run in a custom process pool: # with concurrent.futures.ProcessPoolExecutor() as pool: # result = await loop.run_in_executor( # pool, func1) # print('custom process pool', result) asyncio.run(main()) 应用场景：当项目以协程式的异步编程开发时，如果要使用一个第三方模块，而第三方模块不支持协程方式异步编程时，就需要用到这个功能，例如： import asyncio import requests async def download_image(url): # 发送网络请求，下载图片（遇到网络下载图片的IO请求，自动化切换到其他任务） print(\"开始下载:\", url) loop = asyncio.get_event_loop() # requests模块默认不支持异步操作，所以就使用线程池来配合实现了。 future = loop.run_in_executor(None, requests.get, url) response = await future print('下载完成') # 图片保存到本地文件 file_name = url.rsplit('_')[-1] with open(file_name, mode='wb') as file_object: file_object.write(response.content) if __name__ == '__main__': url_list = [ 'https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg', 'https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg', 'https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg' ] tasks = [download_image(url) for url in url_list] loop = asyncio.get_event_loop() loop.run_until_complete(asyncio.wait(tasks)) 3.2.6 异步迭代器 什么是异步迭代器 实现了 __aiter__() 和 __anext__() 方法的对象。__anext__ 必须返回一个 awaitable 对象。async for 会处理异步迭代器的__anext__() 方法所返回的可等待对象，直到其引发一个 StopAsyncIteration 异常。由 PEP 492 引入。 什么是异步可迭代对象？ 可在 async for 语句中被使用的对象。必须通过它的 __aiter__() 方法返回一个 asynchronous iterator。由 PEP 492 引入。 import asyncio class Reader(object): \"\"\" 自定义异步迭代器（同时也是异步可迭代对象） \"\"\" def __init__(self): self.count = 0 async def readline(self): # await asyncio.sleep(1) self.count += 1 if self.count == 100: return None return self.count def __aiter__(self): return self async def __anext__(self): val = await self.readline() if val == None: raise StopAsyncIteration return val async def func(): # 创建异步可迭代对象 async_iter = Reader() # async for 必须要放在async def函数内，否则语法错误。 async for item in async_iter: print(item) asyncio.run(func()) 异步迭代器其实没什么太大的作用，只是支持了async for语法而已。 3.2.6 异步上下文管理器 此种对象通过定义 __aenter__() 和 __aexit__() 方法来对 async with 语句中的环境进行控制。由 PEP 492 引入。 import asyncio class AsyncContextManager: def __init__(self): self.conn = None async def do_something(self): # 异步操作数据库 return 666 async def __aenter__(self): # 异步链接数据库 self.conn = await asyncio.sleep(1) return self async def __aexit__(self, exc_type, exc, tb): # 异步关闭数据库链接 await asyncio.sleep(1) async def func(): async with AsyncContextManager() as f: result = await f.do_something() print(result) asyncio.run(func()) 这个异步的上下文管理器还是比较有用的，平时在开发过程中 打开、处理、关闭 操作时，就可以用这种方式来处理。 3.3 小结 在程序中只要看到async和await关键字，其内部就是基于协程实现的异步编程，这种异步编程是通过一个线程在IO等待时间去执行其他任务，从而实现并发。 以上就是异步编程的常见操作，内容参考官方文档。 中文版 英文版 4 uvloop Python标准库中提供了asyncio模块，用于支持基于协程的异步编程。 uvloop 是 asyncio 中的事件循环的替代方案，替换后可以使得asyncio性能提高。事实上，uvloop要比nodejs、gevent等其他python异步框架至少要快2倍，性能可以比肩Go语言。 安装uvloop pip3 install uvloop 在项目中想要使用uvloop替换asyncio的事件循环也非常简单，只要在代码中这么做就行。 import asyncio import uvloop asyncio.set_event_loop_policy(uvloop.EventLoopPolicy()) # 编写asyncio的代码，与之前写的代码一致。 # 内部的事件循环自动化会变为uvloop asyncio.run(...) 注意：知名的 asgi uvicorn 内部就是使用的 uvloop 的事件循环。 5 实战案例 5.1 异步Redis 当通过python去操作redis时，链接、设置值、获取值 这些都涉及网络IO请求，使用asycio异步的方式可以在IO等待时去做一些其他任务，从而提升性能。 安装Python异步操作redis模块 pip3 install aioredis 示例1：异步操作 Redis #!/usr/bin/env python # -*- coding:utf-8 -*- import asyncio import aioredis async def execute(address, password): print(\"开始执行\", address) # 网络IO操作：创建redis连接 redis = await aioredis.create_redis(address, password=password) # 网络IO操作：在redis中设置哈希值car，内部在设三个键值对，即： redis = { car:{key1:1,key2:2,key3:3}} await redis.hmset_dict('car', key1=1, key2=2, key3=3) # 网络IO操作：去redis中获取值 result = await redis.hgetall('car', encoding='utf-8') print(result) redis.close() # 网络IO操作：关闭redis连接 await redis.wait_closed() print(\"结束\", address) asyncio.run(execute('redis://47.93.4.198:6379', \"root!2345\")) 示例2：连接多个redis做操作（遇到IO会切换其他任务，提供了性能）。 import asyncio import aioredis async def execute(address, password): print(\"开始执行\", address) # 网络IO操作：先去连接 47.93.4.197:6379，遇到IO则自动切换任务，去连接47.93.4.198:6379 redis = await aioredis.create_redis_pool(address, password=password) # 网络IO操作：遇到IO会自动切换任务 await redis.hmset_dict('car', key1=1, key2=2, key3=3) # 网络IO操作：遇到IO会自动切换任务 result = await redis.hgetall('car', encoding='utf-8') print(result) redis.close() # 网络IO操作：遇到IO会自动切换任务 await redis.wait_closed() print(\"结束\", address) task_list = [ execute('redis://47.93.4.197:6379', \"root!2345\"), execute('redis://47.93.4.198:6379', \"root!2345\") ] asyncio.run(asyncio.wait(task_list)) 更多redis操作参考aioredis官网 5.2 异步 MySQL 当通过python去操作MySQL时，连接、执行SQL、关闭都涉及网络IO请求，使用asycio异步的方式可以在IO等待时去做一些其他任务，从而提升性能。 安装Python异步操作redis模块 pip3 install aiomysql 示例1： import asyncio import aiomysql async def execute(): # 网络IO操作：连接MySQL conn = await aiomysql.connect(host='127.0.0.1', port=3306, user='root', password='123', db='mysql', ) # 网络IO操作：创建CURSOR cur = await conn.cursor() # 网络IO操作：执行SQL await cur.execute(\"SELECT Host,User FROM user\") # 网络IO操作：获取SQL结果 result = await cur.fetchall() print(result) # 网络IO操作：关闭链接 await cur.close() conn.close() asyncio.run(execute()) 示例2： #!/usr/bin/env python # -*- coding:utf-8 -*- import asyncio import aiomysql async def execute(host, password): print(\"开始\", host) # 网络IO操作：先去连接 47.93.40.197，遇到IO则自动切换任务，去连接47.93.40.198:6379 conn = await aiomysql.connect(host=host, port=3306, user='root', password=password, db='mysql') # 网络IO操作：遇到IO会自动切换任务 cur = await conn.cursor() # 网络IO操作：遇到IO会自动切换任务 await cur.execute(\"SELECT Host,User FROM user\") # 网络IO操作：遇到IO会自动切换任务 result = await cur.fetchall() print(result) # 网络IO操作：遇到IO会自动切换任务 await cur.close() conn.close() print(\"结束\", host) task_list = [ execute('47.93.40.197', \"root!2345\"), execute('47.93.40.197', \"root!2345\") ] asyncio.run(asyncio.wait(task_list)) 5.3 FastAPI 框架 FastAPI 是一款用于构建API的高性能web框架，框架基于Python3.6+的 type hints搭建。 接下里的异步示例以FastAPI和uvicorn来讲解（uvicorn是一个支持异步的asgi）。 安装FastAPI web 框架 pip3 install fastapi 安装uvicorn，本质上为web提供socket server的支持的asgi（一般支持异步称asgi、不支持异步称wsgi） pip3 install uvicorn 示例： # !/usr/bin/env python # -*- coding:utf-8 -*- import asyncio import uvicorn import aioredis from aioredis import Redis from fastapi import FastAPI app = FastAPI() REDIS_POOL = aioredis.ConnectionsPool('redis://47.193.14.198:6379', password=\"root123\", minsize=1, maxsize=10) @app.get(\"/\") def index(): \"\"\" 普通操作接口 \"\"\" return {\"message\": \"Hello World\"} @app.get(\"/red\") async def red(): \"\"\" 异步操作接口 \"\"\" print(\"请求来了\") await asyncio.sleep(3) # 连接池获取一个连接 conn = await REDIS_POOL.acquire() redis = Redis(conn) # 设置值 await redis.hmset_dict('car', key1=1, key2=2, key3=3) # 读取值 result = await redis.hgetall('car', encoding='utf-8') print(result) # 连接归还连接池 REDIS_POOL.release(conn) return result if __name__ == '__main__': uvicorn.run(\"demo:app\", host=\"127.0.0.1\", port=5000, log_level=\"info\") 在有多个用户并发请求的情况下，异步方式来编写的接口可以在IO等待过程中去处理其他的请求，提供性能。 例如：同时有两个用户并发来向接口 http://127.0.0.1:5000/red 发送请求，服务端只有一个线程，同一时刻只有一个请求被处理。 异步处理可以提供并发是因为：当视图函数在处理第一个请求时，第二个请求此时是等待被处理的状态，当第一个请求遇到IO等待时，会自动切换去接收并处理第二个请求，当遇到IO时自动化切换至其他请求，一旦有请求IO执行完毕，则会再次回到指定请求向下继续执行其功能代码。 基于上下文管理，来实现自动化管理的案例： 示例1：redis #!/usr/bin/env python # -*- coding:utf-8 -*- import asyncio import uvicorn import aioredis from aioredis import Redis from fastapi import FastAPI app = FastAPI() REDIS_POOL = aioredis.ConnectionsPool('redis://47.193.14.198:6379', password=\"root123\", minsize=1, maxsize=10) @app.get(\"/\") def index(): \"\"\" 普通操作接口 \"\"\" return {\"message\": \"Hello World\"} @app.get(\"/red\") async def red(): \"\"\" 异步操作接口 \"\"\" print(\"请求来了\") async with REDIS_POOL.get() as conn: redis = Redis(conn) # 设置值 await redis.hmset_dict('car', key1=1, key2=2, key3=3) # 读取值 result = await redis.hgetall('car', encoding='utf-8') print(result) return result if __name__ == '__main__': uvicorn.run(\"fast3:app\", host=\"127.0.0.1\", port=5000, log_level=\"info\") 示例2：mysql #!/usr/bin/env python # -*- coding:utf-8 -*- import asyncio import uvicorn from fastapi import FastAPI import aiomysql app = FastAPI() # 创建数据库连接池 pool = aiomysql.Pool(host='127.0.0.1', port=3306, user='root', password='123', db='mysql', minsize=1, maxsize=10, echo=False, pool_recycle=-1, loop=asyncio.get_event_loop()) @app.get(\"/red\") async def red(): \"\"\" 异步操作接口 \"\"\" # 去数据库连接池申请链接 async with pool.acquire() as conn: async with conn.cursor() as cur: # 网络IO操作：执行SQL await cur.execute(\"SELECT Host,User FROM user\") # 网络IO操作：获取SQL结果 result = await cur.fetchall() print(result) # 网络IO操作：关闭链接 return {\"result\": \"ok\"} if __name__ == '__main__': uvicorn.run(\"fast2:app\", host=\"127.0.0.1\", port=5000, log_level=\"info\") 5.4 爬虫 在编写爬虫应用时，需要通过网络IO去请求目标数据，这种情况适合使用异步编程来提升性能，接下来我们使用支持异步编程的aiohttp模块来实现。 安装aiohttp模块 pip3 install aiohttp 示例： import aiohttp import asyncio async def fetch(session, url): print(\"发送请求：\", url) async with session.get(url, verify_ssl=False) as response: text = await response.text() print(\"得到结果：\", url, len(text)) async def main(): async with aiohttp.ClientSession() as session: url_list = [ 'https://python.org', 'https://www.baidu.com', 'https://www.pythonav.com' ] tasks = [asyncio.create_task(fetch(session, url)) for url in url_list] await asyncio.wait(tasks) if __name__ == '__main__': asyncio.run(main()) 总结 为了提升性能越来越多的框架都在向异步编程靠拢，例如：sanic、tornado、django3.0、django channels组件 等，用更少资源可以做处理更多的事，何乐而不为呢。 "},"Python/Python语言进阶/07-GIL全局解释器锁.html":{"url":"Python/Python语言进阶/07-GIL全局解释器锁.html","title":"GIL全局解释器锁","keywords":"","body":"datetime:2022/09/29 10:14 author:nzb GIL全局解释器锁 GIL的定义 CPython（标准python实现，C语言实现的Python解释器）有一种称为GIL（全局解释器锁）的东西；GIL仅允许一个线程在同一时刻在一个CPU上执行，因为多个线程之间竞争GIL的控制权， 只有取得GIL的线程才能获得CPU运行的时间。因此即使在具有多个CPU内核的多线程体系结构中，GIL也因Python的“臭名昭著\"。 当遇到I/O等待或者已到CPU轮询时，系统内核会强制CPU切换，将CPU时间分配到其他任意一个线程，当然获得CPU运行时间的线程也竞逐得到GIL， 并且CPU切换同样存在时间开销。对于CPU密集型的程序来说，线程在执行计算时不存在I/O等待，但CPU只要到达轮询时，OS内核仍然会强制CPU执行切换到另外一个线程， 原先执行计算的线程只能等待下一次CPU调度才能继续执行，这种CPU切换操作无时无刻伴随着线程之间的GIL占用与释放，意味着每次CPU切换操作， 其他没有得到GIL的线程都会被强制等待(或阻塞)。这是同样的CPU密集型算法在CPython中使用多线程执行，比使用单线程还要慢的原因所在。 因为Python线程使用了操作系统的原生线程，这导致了多个线程同时执行容易出现竞争状态等问题，为了方便Python语言层面开发者的开发，就使用了GIL(Global Interpreter Lock)这个大锁，一口气锁住，这样开发起来就方便了，但也造成了当下Python运行速度慢的问题。 有人感觉GIL锁其实就是一个互斥锁(Mutex lock)，其实不然，GIL的目的是让多个线程按照一定的顺序并发执行，而不是简单的保证当下时刻只有一个线程运行，这点CPython中也有相应的注释，而且就是在GIL定义之上，具体如下： 源码路径：Python/thread_pthread.h /* A pthread mutex isn't sufficient to model the Python lock type * because, according to Draft 5 of the docs (P1003.4a/D5), both of the * following are undefined: * -> a thread tries to lock a mutex it already has locked * -> a thread tries to unlock a mutex locked by a different thread * pthread mutexes are designed for serializing threads over short pieces * of code anyway, so wouldn't be an appropriate implementation of * Python's locks regardless. * * The pthread_lock struct implements a Python lock as a \"locked?\" bit * and a pair. In general, if the bit can be acquired * instantly, it is, else the pair is used to block the thread until the * bit is cleared. 9 May 1994 tim@ksr.com */ # GIL的定义 typedef struct { char locked; /* 0=unlocked, 1=locked */ /* a pair to handle an acquire of a locked lock */ pthread_cond_t lock_released; pthread_mutex_t mut; } pthread_lock; 从GIL的定义中可知，GIL本质是一个条件互斥组，其使用条件变量lock_released与互斥锁mut来保护locked的状态，locked为0时表示未上锁，为1时表示线程上锁，而条件变量的引用让GIL可以实现多个线程按一定条件并发执行的目的。 条件变量(condition variable)是利用线程间共享的全局变量来控制多个线程同步的一种机制，其主要包含两个动作： 1.一个线程等待「条件变量的条件成立」而挂起 2.另一个线程则是「条件成功」(即发出条件成立的信号) 在很多系统中，条件变量通常与互斥锁一同使用，目的是确保多个操作的原子性从而避免死锁的发生。 GIL的获取与释放 从GIL的定义结构可以看出，线程对 GIL 的操作其实就是修过GIL结构中的 locked 变量的状态来达到获取或释放GIL的目的， 在Python/threadpthread.h中以及提供了PyThreadacquirelock()与PyThreadrelease_lock()方法来实现线程对锁的获取与释放，先来看一下获取，代码如下： PyLockStatus PyThread_acquire_lock_timed( PyThread_type_lock lock, PY_TIMEOUT_T microseconds, int intr_flag ){ PyLockStatus success = PY_LOCK_FAILURE; /* GIL */ pthread_lock *thelock = (pthread_lock *) lock; int status, error = 0; dprintf( (\"PyThread_acquire_lock_timed(%p, %lld, %d) called\\n\", lock, microseconds, intr_flag) ); if ( microseconds == 0 ){ /* 非阻塞式获取互斥锁，从而让当前线程获得操作locked变量的权限 */ status = pthread_mutex_trylock( &thelock->mut ); if ( status != EBUSY ) CHECK_STATUS_PTHREAD( \"pthread_mutex_trylock[1]\" ); }else { /* 阻塞式获取互斥锁，从而让当前线程获得操作locked变量的权限 */ status = pthread_mutex_lock( &thelock->mut ); CHECK_STATUS_PTHREAD( \"pthread_mutex_lock[1]\" ); } if ( status == 0 ){ if ( thelock->locked == 0 ){ /* 获得锁 */ success = PY_LOCK_ACQUIRED; } else if( microseconds != 0 ){ struct timespec ts; /* 时间 */ if ( microseconds > 0 ) /* 等待事件 */ MICROSECONDS_TO_TIMESPEC( microseconds, ts ); /* 继续尝试，直到我们获得锁定 * mut(互斥锁) 必须被当前线程锁定 * 获得互斥锁失败，则一直尝试 */ while ( success == PY_LOCK_FAILURE ){ if ( microseconds > 0 ){ /* 计时等待持有锁的线程释放锁 */ status = pthread_cond_timedwait(&thelock->lock_released, &thelock->mut, &ts ); if ( status == ETIMEDOUT ) break; CHECK_STATUS_PTHREAD( \"pthread_cond_timed_wait\" ); }else { /* 无条件等待持有锁的线程释放锁 */ status = pthread_cond_wait(&thelock->lock_released, &thelock->mut ); CHECK_STATUS_PTHREAD( \"pthread_cond_wait\" ); } if ( intr_flag && status == 0 && thelock->locked ){ /* 被唤醒了，但没有锁，则设置状态为PY_LOCK_INTR 当做异常状态来处理 */ success = PY_LOCK_INTR; break; } else if( status == 0 && !thelock->locked ){ success = PY_LOCK_ACQUIRED; } } } /* 获得锁，则当前线程上锁 */ if ( success == PY_LOCK_ACQUIRED ) thelock->locked = 1; /* 释放互斥锁，让其他线上有机会竞争获得锁 */ status = pthread_mutex_unlock( &thelock->mut ); CHECK_STATUS_PTHREAD( \"pthread_mutex_unlock[1]\" ); } if ( error ) success = PY_LOCK_FAILURE; dprintf( (\"PyThread_acquire_lock_timed(%p, %lld, %d) -> %d\\n\", lock, microseconds, intr_flag, success) ); return(success); } int PyThread_acquire_lock( PyThread_type_lock lock, int waitflag ) { return PyThread_acquire_lock_timed( lock, waitflag ? -1 : 0, /*intr_flag=*/ 0 ); } 上述代码中使用了下面3个方法来操作互斥锁 // 获得互斥锁(阻塞) pthread_mutex_lock(pthread_mutex_t*mutex); // 获得互斥锁(非阻塞) pthread_mutex_trylock(pthread_mutex_t*mutex); // 释放互斥锁 pthread_mutex_unlock(pthread_mutex_t*mutex); 这些方法会操作POSIX线程(POSIX thread，简称Pthread)去操作锁，在Linux、MacOS等类Unix操作系统中都会使用Pthread作为操作系统的线程。区别见文章末尾。 从上诉代码中可以看出，获取GIL锁的逻辑主要在PyThread_acquire_lock_timed()方法中，其主要的逻辑为，如果没有获得锁，就等待，具体分为计算等待与无条件等待，与Python2不同，Python3通过计时的方式来触发「检查间隔」(check interval)机制，直到成功获取GIL，具体逻辑可以看代码中注释。 接着来看是否GIL锁的逻辑，即PyThread_release_lock()方法，代码如下： void PyThread_release_lock( PyThread_type_lock lock ){ pthread_lock *thelock = (pthread_lock *) lock; int status, error = 0; (void) error; /* silence unused-but-set-variable warning */ dprintf( (\"PyThread_release_lock(%p) called\\n\", lock) ); /* 获取互斥锁，从而让当前线程操作locked变量的权限 */ status = pthread_mutex_lock( &thelock->mut ); CHECK_STATUS_PTHREAD( \"pthread_mutex_lock[3]\" ); /* 释放GIL，将locked置为0 */ thelock->locked = 0; /* wake up someone (anyone, if any) waiting on the lock */ /* 通知其他线程当前线程已经释放GIL */ status = pthread_cond_signal( &thelock->lock_released ); CHECK_STATUS_PTHREAD( \"pthread_cond_signal\" ); /* 释放互斥锁 */ status = pthread_mutex_unlock( &thelock->mut ); CHECK_STATUS_PTHREAD( \"pthread_mutex_unlock[3]\" ); } PyThread_release_lock()方法的逻辑相对简洁，首先获取互斥锁，从而拥有操作locked的权限，然后就将locked置为0，表示释放GIL， 接着通过pthread_cond_signal()方法通知其他线程「当前线程已经释放GIL」，让其他线程去获取GIL， 其他线程其实就是在调用pthread_cond_timedwait()方法或pthread_cond_wait()方法等待的线程。 GIL的改进 python3.2 之前-基于opcode数量的调度方式 在python3.2版本之前，定义了一个tick计数器，表示当前线程在释放gil之前连续执行的多少个字节码(实际上有部分执行较快的字节码并不会被计入计数器)。 如果当前的线程正在执行一个 CPU 密集型的任务, 它会在 tick 计数器到达 100 之后就释放 gil, 给其他线程一个获得 gil 的机会。 图片来自 Understanding the Python GIL(youtube) 以opcode个数为基准来计数，如果有些opcode代码复杂耗时较长，一些耗时较短，会导致同样的100个tick，一些线程的执行时间总是执行的比另一些长。是不公平的调度策略。 图片来自 Understanding-the-python-gil 如果当前的线程正在执行一个 IO密集型的 的任务, 你执行sleep/recv/send(...etc) 这些会阻塞的系统调用时, 即使 tick 计数器的值还没到 100, gil 也会被主动地释放。至于下次该执行哪一个线程这个是操作系统层面的，线程调度算法优先级调度，开发者没办法控制。 在多核机器上, 如果两个线程都在执行 CPU 密集型的任务, 操作系统有可能让这两个线程在不同的核心上运行, 也许会出现以下的情况, 当一个拥有了 gil 的线程在一个核心上执行 100 次 tick 的过程中, 在另一个核心上运行的线程频繁的进行抢占 gil, 抢占失败的循环, 导致 CPU 瞎忙影响性能。 如下图：绿色部分表示该线程在运行，且在执行有用的计算，红色部分为线程被调度唤醒， 但是无法获取GIL导致无法进行有效运算等待的时间。 由图可见，GIL的存在导致多线程无法很好的利用多核CPU的并发处理能力。 究其原因，是因为旧GIL基于ticker来决定是否释放GIL(ticker默认为100)，并且释放完后，释放的线程依旧会参与GIL争夺，这就使得某线程一释放GIL就立刻去获得它，而其他CPU核下的线程相当于白白被唤醒，没有抢到GIL后，继续挂起等待，这就造成了资源的浪费，形象如下图： python3.2 之后-基于时间片的切换 由于在多核机器下可能导致性能下降， gil的实现在python3.2之后做了一些优化 。python在初始化解释器的时候就会初始化一个gil，并设置一个DEFAULT_INTERVAL=5000, 单位是微妙，即0.005秒(在 C 里面是用 微秒 为单位存储, 在 python 解释器中以秒来表示)这个间隔就是GIL切换的标志。 // Pythonceval_gil.h #define DEFAULT_INTERVAL 5000 static void _gil_initialize(struct _gil_runtime_state *gil) { _Py_atomic_int uninitialized = {-1}; gil->locked = uninitialized; gil->interval = DEFAULT_INTERVAL; } python中查看gil切换的时间 In [7]: import sys In [8]: sys.getswitchinterval() Out[8]: 0.005 改进后的GIL不再使用ticker，而改为使用时间，可以通过 sys.getswitchinterval()来查看GIL释放的时间，默认为5毫秒，此外虽然说新GIL使用了时间， 但决定线程是否释放GIL并不取决于时间，而是取决于gil_drop_request这一全局变量，如果gil_drop_request=0，则线程会在解释器中一直运行， 直到gil_drop_request=1，此时线程才会释放GIL，下面同样以两个线程来解释新GIL在其中发挥的具体作用。 首先存在两个线程，Thread 1是正在运行的状态，Thread 2是挂起状态。 Thread 2之所以挂起，是因为Thread 2没有获得GIL，它会执行cv_wait(gil,TIMEOUT)定时等待方法，等待一段时间(默认5毫秒)， 直到Thread 1主动释放GIL(比如Thread 1 执行I/O操作时会进入休眠状态，此时它会主动释放GIL)。 当Thread 2收到signal信号后，就知道Thread 1要休眠了，此时它就可以去获取GIL从而执行自身的逻辑。 另外一种情况就是，Thread 1一直在执行，执行的时间超过了Thread 2 cvwait(gil,TIMEOUT)方法等待的时间， 此时Thread 2就会去修改全局变量gil_drop_request，将其设置为1，然后自己再次调用cvwait(gil,TIMEOUT)挂起等待。 Thread 1 发现 gil_drop_request=1 会主动释放GIL，并通过signal通知Thread 2，让其获取GIL去运行。 其中需要注意的细节如下图。当Thread 1因为gil_drop_request=1要主动释放GIL后，会调用cv_wait(gotgil)方法进入等待状态， 该状态下的Thread 1会等待Thread 2返回的signal信号，从而得知另一个线程Thread 2成功获得了GIL并在执行状态，这就避免了多个线程争夺GIL的情况，从而避免了额外资源的消耗。 如果当前有不止一个线程, 当前等待 gil 的线程在超过一定时间的等待后, 会把全局变量 gil_drop_request 的值设置为 1, 之后继续等待相同的时间, 这时拥有 gil 的线程看到了 gil_drop_request 变为 1, 就会主动释放 gil 并通过 condition variable 通知到在等待中的线程, 第一个被唤醒的等待中的线程会抢到 gil 并执行相应的任务, 将gil_drop_request设置为1的线程不一定能抢到gil, 相同的过程会重复的发生，直到线程执行结束 如果存在多个线程(大于2个线程)，此时多个线程出现等待时间超时，此时会不会发生多个线程争夺GIL的情况呢？答案是不会，如下图： 当Thread 1执行时，Thread 2等待超时了，会设置gil_drop_request = 1，从而让Thread 2获得运行权限，如果此时Thread 3或Thread 4一会后也超时了，此时是不会让Thread 2将获得的GIL立即释放的，Thread 3/4 会继续在挂起状态等待一段时间。 还需要注意的一点是，设置gil_drop_request = 1的线程并不一定会是下一个要执行的线程，下一个要执行那个线程，这取决于操作系统，直观理解如下图： 图中，Thread 2到了超时时间，将gil_drop_request设置为了1，但Thread 1发送signal信号的线程是Thread 3，这造成Thread 2继续挂起等待，而Thread 3获得GIL执行自身逻辑。 condition variable相关字段 locked ： locked 的类型是_Py_atomic_int， 值-1表示还未初始化，0表示当前的gil处于释放状态，1表示某个线程已经占用了gil，这个值的类型设置为原子类型之后在 ceval.c 就可以不加锁的对这个值进行读取。 interval：是线程在设置gil_drop_request这个变量之前需要等待的时长，默认是5000毫秒 last_holder：存放了最后一个持有 gil 的线程的 C 中对应的 PyThreadState 结构的指针地址, 通过这个值我们可以知道当前线程释放了 gil 后, 是否有其他线程获得了 gil(可以采取措施避免被自己重新获得) switch_number： 是一个计数器, 表示从解释器运行到现在, gil 总共被释放获得多少次 mutex：是一把互斥锁, 用来保护 locked, last_holder, switch_number 还有 _gil_runtime_state 中的其他变量 cond：是一个 condition variable 和 mutex 结合起来一起使用, 当前线程释放 gil 时用来给其他等待中的线程发送信号 switch_cond and switch_mutex switch_cond 是另一个 condition variable 和 switch_mutex 结合起来可以用来保证释放后重新获得 gil 的线程不是同一个前面释放 gil 的线程, 避免 gil 切换时线程未切换浪费 cpu 时间 这个功能如果编译时未定义 FORCE_SWITCHING 则不开启 static void drop_gil(struct _ceval_runtime_state *ceval, PyThreadState *tstate){ ... #ifdef FORCE_SWITCHING if (_Py_atomic_load_relaxed(&ceval->gil_drop_request) && tstate != NULL) { MUTEX_LOCK(gil->switch_mutex); /* Not switched yet => wait */ if (((PyThreadState*)_Py_atomic_load_relaxed(&gil->last_holder)) == tstate){ /* 如果 last_holder 是当前线程, 释放 switch_mutex 这把互斥锁, 等待 switch_cond 这个条件变量的信号 */ RESET_GIL_DROP_REQUEST(ceval); /* NOTE: if COND_WAIT does not atomically start waiting when releasing the mutex, another thread can run through, take the GIL and drop it again, and reset the condition before we even had a chance to wait for it. */ /* 注意, 如果 COND_WAIT 不在互斥锁释放后原子的启动, 另一个线程有可能会在这中间拿到 gil 并释放, ‘并且重置这个条件变量, 这个过程发生在了 COND_WAIT 之前 */ COND_WAIT(gil->switch_cond, gil->switch_mutex); } MUTEX_UNLOCK(gil->switch_mutex); } #endif } gil在main_loop中的体现 /* */ main_loop: for (;; ){ /* 如果 gil_drop_request 被其他线程设置为 1 */ /* 给其他线程一个获得 gil 的机会 */ if ( _Py_atomic_load_relaxed( &ceval->gil_drop_request ) ){ /* Give another thread a chance */ if ( _PyThreadState_Swap( &runtime->gilstate, NULL ) != tstate ){ Py_FatalError( \"ceval: tstate mix-up\" ); } drop_gil( ceval, tstate ); /* Other threads may run now */ take_gil( ceval, tstate ); /* Check if we should make a quick exit. */ exit_thread_if_finalizing( runtime, tstate ); if ( _PyThreadState_Swap( &runtime->gilstate, tstate ) != NULL ){ Py_FatalError( \"ceval: orphan tstate\" ); } } /* Check for asynchronous exceptions. */ /* 忽略 */ fast_next_opcode: switch ( opcode ){ case TARGET( NOP ): { FAST_DISPATCH(); } /* 忽略 */ case TARGET( UNARY_POSITIVE ): { PyObject *value = TOP(); PyObject *res = PyNumber_Positive( value ); Py_DECREF( value ); SET_TOP( res ); if ( res == NULL ) goto error; DISPATCH(); } /* 忽略 */ } /* 忽略 */ } 这个很大的 for loop 会按顺序逐个的加载 opcode, 并委派给中间很大的 switch statement 去进行执行, switch statement 会根据不同的 opcode 跳转到不同的位置执行 for loop在开始位置会检查 gil_drop_request 变量, 必要的时候会释放 gil 不是所有的 opcode 执行之前都会检查 gil_drop_request 的, 有一些 opcode 结束时的代码为 FAST_DISPATCH(), 这部分 opcode 会直接跳转到下一个 opcode 对应的代码的部分进行执行 而另一些 DISPATCH() 结尾的作用和 continue 类似, 会跳转到 for loop 顶端, 重新检测 gil_drop_request, 必要时释放 gil 。 如何解决GIL GIL只会对CPU密集型的程序产生影响，规避GIL限制主要有两种常用策略：一是使用多进程，二是使用C语言扩展，把计算密集型的任务转移到C语言中， 使其独立于Python，在C代码中释放GIL。当然也可以使用其他语言编译的解释器如 Jpython、PyPy。 总结 Python语言和GIL没有半毛钱关系，仅仅是由于历史原因在CPython解释器中难以移除GIL GIL：全局解释器锁，每个线程在执行的过程都需要先获取GIL，确保同一时刻仅有一个线程执行代码，所以python的线程无法利用多核。 线程在I/O操作等可能引起阻塞的system call之前，可以暂时释放GIL，执行完毕后重新获取GIL，python3.2以后使用时间片来切换线程，时间阈值是0.005秒，而python3.2之前是使用opcode执行的数量(tick=100)来切换的。 Python的多线程在多核CPU上，只对于IO密集型计算产生正面效果；而当有至少有一个CPU密集型线程存在，那么多线程效率会由于GIL而大幅下降 参考 Cpython-gil讲解-zpoint Python的GIL是什么鬼-卢钧轶(cenalulu) Youtube-Understanding the Python GIL 关于pthread_mutex_lock和trylock的区别 pthread_mutex_lock会阻塞，pthread_mutex_trylock是非阻塞的。 举例：lock 当A线程去lock一个锁时，如果该锁已被其他线程锁住，则A线程会被挂起，等待该锁被释放后，再进行lock。 图中如果线程1在获取lock1时，发现该锁已被占用，则线程1会被挂起，不再执行后面的程序直到抢占到lock1。 举例：trylock 当线程A去trylock一个锁时，如果该锁被占用，则线程A继续执行下面的程序，不会被挂起。 图中线程1去trylock一下lock1时，如果锁被占用，则继续执行下面的程序 总结：人如其名，trylock就是尝试锁一下，锁不到就拉倒，不会影响自己进行下一步操作。lock就比较犟，锁不到的话，我就等着，等到我能锁了，再进行一下步操作。 "},"Python/Python语言进阶/08-线程池_ThreadPoolExecutor.html":{"url":"Python/Python语言进阶/08-线程池_ThreadPoolExecutor.html","title":"线程池ThreadPoolExecutor","keywords":"","body":"datetime:2023/03/23 10:10 author:nzb 线程池 ThreadPoolExecutor 从Python3.2开始，标准库为我们提供了 concurrent.futures 模块，它提供了 ThreadPoolExecutor (线程池)和 ProcessPoolExecutor (进程池)两个类。 相比 threading 等模块，该模块通过 submit 返回的是一个 future 对象，它是一个未来可期的对象，通过它可以获取某一个线程执行的状态或者某一个任务执行的状态及返回值： 主线程可以获取某一个线程（或者任务的）的状态，以及返回值。 当一个线程完成的时候，主线程能够立即知道。 基础语法 import time from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED, as_completed def action(second): print(second) time.sleep(second) return second lists = [4, 5, 2, 3] # 创建一个最大容纳数量为2的线程池 pool = ThreadPoolExecutor(max_workers=2) # 通过submit提交执行的函数到线程池中 all_task = [pool.submit(action, i) for i in lists] # 通过result来获取返回值 result = [i.result() for i in all_task] print(f\"result:{result}\") print(\"----complete-----\") # 线程池关闭 pool.shutdown() 4 5 2 3 result:[4, 5, 2, 3] ----complete----- 使用上下文管理器 可以通过 with 关键字来管理线程池，当线程池任务完成之后自动关闭线程池。 import time from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED, as_completed def action(second): print(second) time.sleep(second) return second lists = [4, 5, 2, 3] all_task = [] with ThreadPoolExecutor(max_workers=2) as pool: for second in lists: all_task.append(pool.submit(action, second)) result = [i.result() for i in all_task] print(f\"result:{result}\") 4 5 2 3 result:[4, 5, 2, 3] 等待所有主线程完成 在需要返回值的场景下，主线程需要等到所有子线程返回再进行下一步，阻塞在当前。比如下载图片统一保存，这时就需要在主线程中一直等待，使用wait方法完成。 wait(fs, timeout=None, return_when=ALL_COMPLETED) wait 接受三个参数： fs: 表示需要执行的序列 timeout: 等待的最大时间，如果超过这个时间即使线程未执行完成也将返回 return_when：表示wait返回结果的条件，默认为 ALL_COMPLETED 全部执行完成再返回，可选 FIRST_COMPLETED import time from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED, as_completed lists = [4, 5, 2, 3] all_task = [] with ThreadPoolExecutor(max_workers=2) as pool: for second in lists: all_task.append(pool.submit(action, second)) # 主线程等待所有子线程完成 wait(all_task, return_when=ALL_COMPLETED) print(\"----complete-----\") 4 5 2 3 ----complete----- 等待第一个主线程完成 wait 方法可以设置等待第一个子线程返回就继续执行，表现为主线程在第一个线程返回后便不会阻塞，继续执行下面的操作。 import time from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED, as_completed def action(second): print(second) time.sleep(second) return second lists = [4, 5, 2, 3] all_task = [] with ThreadPoolExecutor(max_workers=2) as pool: for second in lists: all_task.append(pool.submit(action, second)) # 主线程等待第一个子线程完成 wait(all_task, return_when=FIRST_COMPLETED) print(\"----complete-----\") 4 5 2 ----complete----- 3 因为result方法是阻塞的，所以流程会在result这里阻塞直到所有子线程返回，相当于 ALL_COMPLETED 方法。 import time from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED, as_completed def action(second): print(second) time.sleep(second) return second lists = [4, 5, 2, 3] all_task = [] with ThreadPoolExecutor(max_workers=2) as pool: for second in lists: all_task.append(pool.submit(action, second)) # 主线程等待第一个子线程完成 wait(all_task, return_when=FIRST_COMPLETED) print(\"----first complete-----\") result = [i.result() for i in all_task] print(f\"result:{result}\") print(\"----complete-----\") 4 5 2 ----first complete----- 3 result:[4, 5, 2, 3] ----complete----- 返回及时处理 如果不需要等待所有线程全部返回，而是每返回一个子线程就能够处理，那么就可以使用as_completed获取每一个线程的返回结果。 as_completed() 方法是一个生成器，在没有任务完成的时候，会一直阻塞，除非设置了 timeout。当有某个任务完成的时候，会 yield 这个任务， 就能执行 for 循环下面的语句，然后继续阻塞住，循环到所有的任务结束。同时，先完成的任务会先返回给主线程。 import time from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED, as_completed def action(second): print(second) time.sleep(second) return second lists = [4, 5, 2, 3] all_task = [] with ThreadPoolExecutor(max_workers=2) as pool: for second in lists: all_task.append(pool.submit(action, second)) for future in as_completed(all_task): print(f\"{future.result()} 返回\") print(\"----complete-----\") 4 5 2 4 返回 3 5 返回 2 返回 3 返回 ----complete----- map map 方法是对序列中每一个元素都执行 action 方法，主要有两个特点： 不需要将任务submit到线程池 返回结果的顺序和元素的顺序相同，即使子线程先返回也不会获取结果 map(fn, *iterables, timeout=None) fn： 第一个参数 fn 是需要线程执行的函数； iterables：第二个参数接受一个可迭代对象； timeout： 第三个参数 timeout 跟 wait() 的 timeout 一样，但由于 map 是返回线程执行的结果，如果 timeout小于线程执行时间会抛异常 TimeoutError。 import time from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED, as_completed def action(second): print(second) time.sleep(second) return second lists = [5, 1, 2, 3] with ThreadPoolExecutor(max_workers=2) as pool: for result in pool.map(action, lists): print(f\"{result} 返回\") 5 1 2 3 5 返回 1 返回 2 返回 3 返回 可以看出返回结果和列表的结果一致，即使第2个元素只需要1s就能返回，也还是等待第一个5s线程返回只有才有结果。 自定义打印PID的线程池 import os import threading import time import sys import ctypes from concurrent.futures import ThreadPoolExecutor SYS_get_tid = 178 # 获取线程PID libc = ctypes.cdll.LoadLibrary(\"libc.so.6\") class CustomThreadPoolExecutor(ThreadPoolExecutor): \"\"\" 在 3.7 版更改: 加入 initializer 和*initargs* 参数。 \"\"\" def __init__(self, max_workers=None, thread_name_prefix='', initializer=None, initargs=()): if initializer is None: initializer = self._record_threading_info if sys.version_info >= (3, 7): super(CustomThreadPoolExecutor, self).__init__(max_workers=max_workers, thread_name_prefix=thread_name_prefix, initializer=initializer, initargs=initargs) else: super(CustomThreadPoolExecutor, self).__init__(max_workers=max_workers, thread_name_prefix=thread_name_prefix) def submit(self, fn, *args, **kwargs): self._thread_name_prefix = fn.__name__ super(CustomThreadPoolExecutor, self).submit(fn, *args, **kwargs) @staticmethod def _record_threading_info(): \"\"\"记录线程信息\"\"\" pid = os.getpid() ppid = libc.syscall(SYS_get_tid) name = threading.current_thread().name info = f\"func name: {name}, pid: {pid}, ppid: {ppid}\" print(info) pools = CustomThreadPoolExecutor(max_workers=10) def test1(): while True: time.sleep(0.1) # print(\"I'm test1!!!\") def test2(): while True: time.sleep(1) # print(\"I'm test2!!!\") if __name__ == '__main__': pools.submit(test1) pools.submit(test2) "},"Python/第三方库/Django/01-快速上手.html":{"url":"Python/第三方库/Django/01-快速上手.html","title":"快速上手","keywords":"","body":"datetime:2019/6/10 9:55 author:nzb 快速上手 Web开发的早期阶段，开发者需要手动编写每个页面，例如一个新闻门户网站，每天都要修改它的HTML页面，随着网站规模和体量的增大，这种方式就变得极度糟糕。为了解决这个问题，开发人员想到了用外部程序来为Web服务器生成动态内容，也就是说HTML页面以及页面中的动态内容不再通过手动编写而是通过程序自动生成。最早的时候，这项技术被称为CGI（公共网关接口），当然随着时间的推移，CGI暴露出的问题也越来越多，例如大量重复的样板代码，总体性能较为低下等，因此在时代呼唤新英雄的背景下，PHP、ASP、JSP这类Web应用开发技术在上世纪90年代中后期如雨后春笋般涌现。通常我们说的Web应用是指通过浏览器来访问网络资源的应用程序，因为浏览器的普及性以及易用性，Web应用使用起来方便简单，免除了安装和更新应用程序带来的麻烦，而且也不用关心用户到底用的是什么操作系统，甚至不用区分是PC端还是移动端。 Web应用机制和术语 下图向我们展示了Web应用的工作流程，其中涉及到的术语如下表所示。 说明：相信有经验的读者会发现，这张图中其实还少了很多东西，例如反向代理服务器、数据库服务器、防火墙等，而且图中的每个节点在实际项目部署时可能是一组节点组成的集群。当然，如果你对这些没有什么概念也不要紧，继续下去就行了，后面会给大家一一讲解的。 术语 解释 URL/URI 统一资源定位符/统一资源标识符，网络资源的唯一标识 域名 与Web服务器地址对应的一个易于记忆的字符串名字 DNS 域名解析服务，可以将域名转换成对应的IP地址 IP地址 网络上的主机的身份标识，通过IP地址可以区分不同的主机 HTTP 超文本传输协议，构建在TCP之上的应用级协议，万维网数据通信的基础 反向代理 代理客户端向服务器发出请求，然后将服务器返回的资源返回给客户端 Web服务器 接受HTTP请求，然后返回HTML文件、纯文本文件、图像等资源给请求者 ** Nginx** | 高性能的Web服务器，也可以用作反向代理，负载均衡 和 HTTP缓存 | HTTP协议 这里我们稍微费一些笔墨来谈谈上面提到的HTTP。HTTP（超文本传输协议）是构建于TCP（传输控制协议）之上应用级协议，它利用了TCP提供的可靠的传输服务实现了Web应用中的数据交换。按照维基百科上的介绍，设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法，也就是说这个协议是浏览器和Web服务器之间传输的数据的载体。关于这个协议的详细信息以及目前的发展状况，大家可以阅读阮一峰老师的《HTTP 协议入门》、《互联网协议入门》系列以及《图解HTTPS协议》进行了解。下图是我于2009年9月10日凌晨4点在四川省网络通信技术重点实验室用开源协议分析工具Ethereal（抓包工具WireShark的前身）截取的访问百度首页时的HTTP请求和响应的报文（协议数据），由于Ethereal截取的是经过网络适配器的数据，因此可以清晰的看到从物理链路层到应用层的协议数据。 HTTP请求（请求行+请求头+空行+[消息体]）： HTTP响应（响应行+响应头+空行+消息体）： 说明：但愿这两张如同泛黄的照片般的截图能帮助你了解HTTP到底是什么样子的。 Django概述 Python的Web框架有上百个，比它的关键字还要多。所谓Web框架，就是用于开发Web服务器端应用的基础设施（通常指封装好的模块和一系列的工具）。事实上，即便没有Web框架，我们仍然可以通过socket或CGI来开发Web服务器端应用，但是这样做的成本和代价在实际开发中通常是不能接受的。通过Web框架，我们可以化繁为简，同时降低创建、更新、扩展应用程序的工作量。Python的Web框架中比较有名的有：Flask、Django、Tornado、Sanic、Pyramid、Bottle、Web2py、web.py等。 在基于Python的Web框架中，Django是所有重量级选手中最有代表性的一位，开发者可以基于Django快速的开发可靠的Web应用程序，因为它减少了Web开发中不必要的开销，对常用的设计和开发模式进行了封装，并对MVC架构提供了支持（MTV）。许多成功的网站和App都是基于Django框架构建的，国内比较有代表性的网站包括：知乎、豆瓣网、果壳网、搜狐闪电邮箱、101围棋网、海报时尚网、背书吧、堆糖、手机搜狐网、咕咚、爱福窝、果库等。 Django诞生于2003年，它是一个在真正的应用中成长起来的项目，由劳伦斯出版集团旗下在线新闻网站的内容管理系统（CMS）研发团队编写（主要是Adrian Holovaty和Simon Willison），以比利时的吉普赛爵士吉他手Django Reinhardt来命名，在2005年夏天作为开源框架发布。使用Django能用很短的时间构建出功能完备的网站，因为它代替程序员完成了所有乏味和重复的劳动，剩下真正有意义的核心业务给程序员，这一点就是对DRY（Don't Repeat Yourself）理念的最好践行。 5分钟快速上手 准备工作 检查Python环境：Django 1.11需要Python 2.7或Python 3.4以上的版本；Django 2.0需要Python 3.4以上的版本；Django 2.1需要Python 3.5以上的版本。 $ python3 --version $ python3 >>> import sys >>> sys.version >>> sys.version_info 创建项目文件夹并切换到该目录，例如我们要实例一个OA（办公自动化）项目。 $ mkdir oa $ cd oa 创建并激活虚拟环境。 $ python3 -m venv venv $ source venv/bin/activate 说明：上面使用了Python自带的venv模块完成了虚拟环境的创建，当然也可以使用其他的工具，例如：virtualenv或pipenv等。要激活虚拟环境，在Windows系统下是通过\"venv/Scripts/activate\"`执行批处理文件来实现。 更新包管理工具pip。 (venv)$ pip install -U pip 或 (venv)$ python -m pip install -U pip 注意：请注意终端提示符发生的变化，前面的(venv)说明我们已经进入虚拟环境，而虚拟环境下的python和pip已经是Python 3的解释器和包管理工具了。 安装Django。 (venv)$ pip install django 或指定版本号来安装对应的Django的版本。 (venv)$ pip install django==1.11 检查Django的版本。 (venv)$ python -m django --version (venv)$ django-admin --version 或 (venv)$ python >>> import django >>> django.get_version() 当然，也可以通过pip来查看安装的依赖库及其版本，如： (venv)$ pip freeze (venv)$ pip list 下图展示了Django版本和Python版本的对应关系，如果在安装时没有指定版本号，将自动选择最新的版本（在写作这段内容时，最新的版本是2.0；目前最新的版本已经更新到2.2）。 Django版本 Python版本 1.8 2.7、3.2、3.3、3.4、3.5 1.9、1.10 2.7、3.4、3.5 1.11 2.7、3.4、3.5、3.6、3.7 2.0 3.4、3.5、3.6、3.7 2.1、2.2 3.5、3.6、3.7 使用django-admin创建项目，项目命名为oa。 (venv)$ django-admin startproject oa . 注意：上面的命令最后的那个点，它表示在当前路径下创建项目。 执行上面的命令后看看生成的文件和文件夹，它们的作用如下所示： manage.py： 一个让你用各种方式管理 Django 项目的命令行工具。 oa/__init__.py：一个空文件，告诉 Python 这个目录应该被认为是一个 Python 包。 oa/settings.py：Django 项目的配置文件。 oa/urls.py：Django 项目的 URL 声明，就像你网站的“目录”。 oa/wsgi.py：作为你的项目的运行在 WSGI 兼容的Web服务器上的入口。 启动服务器运行项目。 (venv)$ python manage.py runserver 在浏览器中输入http://127.0.0.1:8000访问我们的服务器，效果如下图所示。 说明1：刚刚启动的是Django自带的用于开发和测试的服务器，它是一个用纯Python编写的轻量级Web服务器，但它并不是真正意义上的生产级别的服务器，千万不要将这个服务器用于和生产环境相关的任何地方。 说明2：用于开发的服务器在需要的情况下会对每一次的访问请求重新载入一遍Python代码。所以你不需要为了让修改的代码生效而频繁的重新启动服务器。然而，一些动作，比如添加新文件，将不会触发自动重新加载，这时你得自己手动重启服务器。 说明3：可以通过python manage.py help命令查看可用命令列表；在启动服务器时，也可以通过python manage.py runserver 1.2.3.4:5678来指定绑定的IP地址和端口。 说明4：可以通过Ctrl+C来终止服务器的运行。 接下来我们修改项目的配置文件settings.py，Django是一个支持国际化和本地化的框架，因此刚才我们看到的默认首页也是支持国际化的，我们将默认语言修改为中文，时区设置为东八区。 (venv)$ vim oa/settings.py # 此处省略上面的内容 # 设置语言代码 LANGUAGE_CODE = 'zh-hans' # 设置时区 TIME_ZONE = 'Asia/Chongqing' # 此处省略下面的内容 刷新刚才的页面。 动态页面 创建名为hrs（人力资源系统）的应用，一个Django项目可以包含一个或多个应用。 (venv)$ python manage.py startapp hrs 执行上面的命令会在当前路径下创建hrs目录，其目录结构如下所示： __init__.py：一个空文件，告诉 Python 这个目录应该被认为是一个 Python 包。 admin.py：可以用来注册模型，用于在Django的管理界面管理模型。 apps.py：当前应用的配置。 migrations：存放与模型有关的数据库迁移信息。 __init__.py：一个空文件，告诉 Python 这个目录应该被认为是一个 Python 包。 models.py：存放应用的数据模型，即实体类及其之间的关系（MVC/MVT中的M）。 tests.py：包含测试应用各项功能的测试类和测试函数。 views.py：处理请求并返回响应的函数（MVC中的C，MVT中的V）。 修改应用目录下的视图文件views.py。 (venv)$ vim hrs/views.py from django.http import HttpResponse def index(request): return HttpResponse('Hello, Django!') 在应用目录创建一个urls.py文件并映射URL。 (venv)$ touch hrs/urls.py (venv)$ vim hrs/urls.py from django.urls import path from hrs import views urlpatterns = [ path('', views.index, name='index'), ] 说明：上面使用的path函数是Django 2.x中新添加的函数，除此之外还可以使用支持正则表达式的URL映射函数re_path函数；Django 1.x中是用名为url函数来设定URL映射。 切换到项目目录，修改该目录下的urls.py文件，对应用中设定的URL进行合并。 (venv) $ vim oa/urls.py from django.contrib import admin from django.urls import path, include urlpatterns = [ path('admin/', admin.site.urls), path('hrs/', include('hrs.urls')), ] 重新运行项目，并打开浏览器中访问http://localhost:8000/hrs。 (venv)$ python manage.py runserver 修改views.py生成动态内容。 (venv)$ vim hrs/views.py from io import StringIO from django.http import HttpResponse depts_list = [ {'no': 10, 'name': '财务部', 'location': '北京'}, {'no': 20, 'name': '研发部', 'location': '成都'}, {'no': 30, 'name': '销售部', 'location': '上海'}, ] def index(request): output = StringIO() output.write('\\n') output.write('\\n') output.write('\\t\\n') output.write('\\t首页') output.write('\\n') output.write('\\n') output.write('\\t部门信息\\n') output.write('\\t\\n') output.write('\\t\\n') output.write('\\t\\t\\n') output.write('\\t\\t\\t部门编号\\n') output.write('\\t\\t\\t部门名称\\n') output.write('\\t\\t\\t所在地\\n') output.write('\\t\\t\\n') for dept in depts_list: output.write('\\t\\t\\n') output.write(f'\\t\\t\\t{dept[\"no\"]}\\n') output.write(f'\\t\\t\\t{dept[\"name\"]}\\n') output.write(f'\\t\\t\\t{dept[\"location\"]}\\n') output.write('\\t\\t\\n') output.write('\\t\\n') output.write('\\n') output.write('\\n') return HttpResponse(output.getvalue()) 刷新页面查看程序的运行结果。 使用视图模板 上面通过拼接HTML代码的方式生成动态视图的做法在实际开发中是无能接受的，这一点大家一定能够想到。为了解决这个问题，我们可以提前准备一个模板页，所谓模板页就是一个带占位符的HTML页面，当我们将程序中获得的数据替换掉页面中的占位符时，一个动态页面就产生了。 我们可以用Django框架中template模块的Template类创建模板对象，通过模板对象的render方法实现对模板的渲染。所谓的渲染就是用数据替换掉模板页中的占位符，当然这里的渲染称为后端渲染，即在服务器端完成页面的渲染再输出到浏览器中，这种做法的主要坏处是当并发访问量较大时，服务器会承受较大的负担，所以今天有很多的Web应用都使用了前端渲染，即服务器只为浏览器提供所需的数据（通常是JSON格式），在浏览器中通过JavaScript获取这些数据并渲染到页面上，这些内容在后面为大家呈现。 Django框架通过shortcuts模块的快捷函数render简化了渲染模板的操作，具体的用法如下所示。 先回到manage.py文件所在的目录创建名为templates文件夹。 (venv)$ mkdir templates 创建模板页index.html。 (venv)$ touch templates/index.html (venv)$ vim templates/index.html 首页 部门信息 部门编号 部门名称 所在地 { % for dept in depts_list % } { { dept.no } } { { dept.name } } { { dept.location } } { % endfor % } 在上面的模板页中我们使用了{ { greeting } }这样的模板占位符语法，也使用了{ % for % } 这样的模板指令，这些都是Django模板语言（DTL）的一部分。如果对此不熟悉并不要紧，我们会在后续的内容中进一步的讲解，而且我们刚才也说到了，还有更好的选择就是使用前端渲染，当然这是后话。 回到应用目录，修改views.py文件。 (venv)$ vim hrs/views.py from django.shortcuts import render depts_list = [ {'no': 10, 'name': '财务部', 'location': '北京'}, {'no': 20, 'name': '研发部', 'location': '成都'}, {'no': 30, 'name': '销售部', 'location': '上海'}, ] def index(request): return render(request, 'index.html', {'depts_list': depts_list}) 到此为止，我们还没有办法让views.py中的render函数找到模板文件index.html，为此我们需要修改settings.py文件，配置模板文件所在的路径。 切换到项目目录修改settings.py文件。 (venv)$ vim oa/settings.py # 此处省略上面的内容 TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR, 'templates')], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] # 此处省略下面的内容 重新运行项目或直接刷新页面查看结果。 (venv)$ python manage.py runserver 总结 至此，我们已经利用Django框架完成了一个非常小的Web应用，虽然它并没有任何的实际价值，但是可以通过这个项目对Django框架有一个感性的认识。当然，实际开发中我们可以用PyCharm来创建项目，如果使用专业版的PyCharm，可以直接创建Django项目。使用PyCharm的好处在于编写代码时可以获得代码提示、错误修复、自动导入等功能，从而提升开发效率，但是专业版的PyCharm需要按年支付相应的费用，社区版的PyCharm中并未包含对Django框架直接的支持，但是我们仍然可以使用它来创建Django项目，只是在使用上没有专业版的方便。关于PyCharm的使用，可以参考《玩转PyCharm》 一文。 此外，学习Django最好的资料肯定是它的官方文档，除此之外图灵社区出版的《Django基础教程》也是非常适合初学者的读物。 "},"Python/第三方库/Django/02-深入模型.html":{"url":"Python/第三方库/Django/02-深入模型.html","title":"深入模型","keywords":"","body":"datetime:2019/6/10 10:01 author:nzb 深入模型 在上一个章节中，我们提到了Django是基于MVC架构的Web框架，MVC架构追求的是“模型”和“视图”的解耦合。所谓“模型”说得更直白一些就是数据，所以通常也被称作“数据模型”。在实际的项目中，数据模型通常通过数据库实现持久化操作，而关系型数据库在很长一段时间都是持久化的首选方案，下面我们以MySQL为例来说明如何使用关系型数据库来实现持久化操作。 配置关系型数据库MySQL 我们继续来完善上一个章节中的OA项目，首先从配置项目使用的数据库开始。 修改项目的settings.py文件，首先将我们之前创建的应用hrs添加已安装的项目中，然后配置MySQL作为持久化方案。 (venv)$ cd oa/settings.py # 此处省略上面的代码 INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'hrs', ] DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'oa', 'HOST': 'localhost', 'PORT': 3306, 'USER': 'root', 'PASSWORD': '123456', } } # 此处省略下面的代码 在配置ENGINE属性时，常用的可选值包括： - `'django.db.backends.sqlite3'`：SQLite嵌入式数据库。 - `'django.db.backends.postgresql'`：BSD许可证下发行的开源关系型数据库产品。 - `'django.db.backends.mysql'`：转手多次目前属于甲骨文公司的经济高效的数据库产品。 - `'django.db.backends.oracle'`：甲骨文公司的关系型数据库旗舰产品。 其他的配置可以参考官方文档中数据库配置的部分。 NAME属性代表数据库的名称，如果使用SQLite它对应着一个文件，在这种情况下NAME的属性值应该是一个绝对路径；使用其他关系型数据库，则要配置对应的HOST（主机）、PORT（端口）、USER（用户名）、PASSWORD（口令）等属性。 安装MySQL客户端工具，Python 3中使用PyMySQL，Python 2中用MySQLdb。 (venv)$ pip install pymysql 如果使用Python 3需要修改项目的__init__.py文件并加入如下所示的代码，这段代码的作用是将PyMySQL视为MySQLdb来使用，从而避免Django找不到连接MySQL的客户端工具而询问你：“Did you install mysqlclient? ”（你安装了mysqlclient吗？）。 import pymysql pymysql.install_as_MySQLdb() 运行manage.py并指定migrate参数实现数据库迁移，为应用程序创建对应的数据表，当然在此之前需要先启动MySQL数据库服务器并创建名为oa的数据库，在MySQL中创建数据库的语句如下所示。 drop database if exists oa; create database oa default charset utf8; (venv)$ cd .. (venv)$ python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying sessions.0001_initial... OK 4. 可以看到，Django帮助我们创建了10张表，这些都是使用Django框架需要的东西，稍后我们就会用到这些表。除此之外，我们还应该为我们自己的应用创建数据模型。如果要在hrs应用中实现对部门和员工的管理，我们可以创建如下所示的数据模型。 (venv)$ vim hrs/models.py from django.db import models class Dept(models.Model): \"\"\"部门类\"\"\" no = models.IntegerField(primary_key=True, db_column='dno', verbose_name='部门编号') name = models.CharField(max_length=20, db_column='dname', verbose_name='部门名称') location = models.CharField(max_length=10, db_column='dloc', verbose_name='部门所在地') class Meta: db_table = 'tb_dept' class Emp(models.Model): \"\"\"员工类\"\"\" no = models.IntegerField(primary_key=True, db_column='eno', verbose_name='员工编号') name = models.CharField(max_length=20, db_column='ename', verbose_name='员工姓名') job = models.CharField(max_length=10, verbose_name='职位') # 自参照完整性多对一外键关联 mgr = models.ForeignKey('self', on_delete=models.SET_NULL, null=True, blank=True, verbose_name='主管编号') sal = models.DecimalField(max_digits=7, decimal_places=2, verbose_name='月薪') comm = models.DecimalField(max_digits=7, decimal_places=2, null=True, blank=True, verbose_name='补贴') # 多对一外键关联 dept = models.ForeignKey(Dept, db_column='dno', on_delete=models.PROTECT, verbose_name='所在部门') class Meta: db_table = 'tb_emp' 说明：上面定义模型时使用了字段类及其属性，其中IntegerField对应数据库中的integer类型，CharField对应数据库的varchar类型，DecimalField对应数据库的decimal类型，ForeignKey用来建立多对一外键关联。字段属性primary_key用于设置主键，max_length用来设置字段的最大长度，db_column用来设置数据库中与字段对应的列，verbose_name则设置了Django后台管理系统中该字段显示的名称。如果对这些东西感到很困惑也不要紧，文末提供了字段类、字段属性、元数据选项等设置的相关说明，不清楚的读者可以稍后查看对应的参考指南。 通过模型创建数据表。 (venv)$ python manage.py makemigrations hrs Migrations for 'hrs': hrs/migrations/0001_initial.py - Create model Dept - Create model Emp (venv)$ python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, hrs, sessions Running migrations: Applying hrs.0001_initial... OK 执行完数据模型迁移操作之后，可以在通过图形化的MySQL客户端工具查看到E-R图（实体关系图）。 在后台管理模型 创建超级管理员账号。 (venv)$ python manage.py createsuperuser Username (leave blank to use 'hao'): jackfrued Email address: jackfrued@126.com Password: Password (again): Superuser created successfully. 启动Web服务器，登录后台管理系统。 (venv)$ python manage.py runserver 访问http://127.0.0.1:8000/admin，会来到如下图所示的登录界面。 登录后进入管理员操作平台。 至此我们还没有看到之前创建的模型类，需要在应用的admin.py文件中模型进行注册。 注册模型类。 (venv)$ vim hrs/admin.py from django.contrib import admin from hrs.models import Emp, Dept admin.site.register(Dept) admin.site.register(Emp) 注册模型类后，就可以在后台管理系统中看到它们。 对模型进行CRUD操作。 可以在管理员平台对模型进行C（新增）R（查看）U（更新）D（删除）操作，如下图所示。 添加新的部门。 查看所有部门。 更新和删除部门。 注册模型管理类。 再次修改admin.py文件，通过注册模型管理类，可以在后台管理系统中更好的管理模型。 from django.contrib import admin from hrs.models import Emp, Dept class DeptAdmin(admin.ModelAdmin): list_display = ('no', 'name', 'location') ordering = ('no',) class EmpAdmin(admin.ModelAdmin): list_display = ('no', 'name', 'job', 'mgr', 'sal', 'comm', 'dept') search_fields = ('name', 'job') admin.site.register(Dept, DeptAdmin) admin.site.register(Emp, EmpAdmin) 为了更好的查看模型数据，可以为Dept和Emp两个模型类添加__str__魔法方法。 from django.db import models class Dept(models.Model): \"\"\"部门类\"\"\" # 此处省略上面的代码 def __str__(self): return self.name # 此处省略下面的代码 class Emp(models.Model): \"\"\"员工类\"\"\" # 此处省略上面的代码 mgr = models.ForeignKey('self', on_delete=models.SET_NULL, null=True, blank=True, verbose_name='直接主管') # 此处省略下面的代码 # 此处省略上面的代码 def __str__(self): return self.name # 此处省略下面的代码 修改代码后刷新查看Emp模型的页面，效果如下图所示。 模型管理类详细配置 models.py from datetime import datetime from DjangoUeditor.models import UEditorField from django.db import models from organization.models import CourseOrg, Teacher # Create your models here. class Course(models.Model): course_org = models.ForeignKey(CourseOrg, verbose_name=u'课程机构', null=True, blank=True, on_delete=models.CASCADE) name = models.CharField(max_length=50, verbose_name=u'课程名称') desc = models.CharField(max_length=300, verbose_name=u'课程描述') # 使用富文本编辑器插件, ueditor的上传路径固定在ueditor目录下。文件名查看官方文档的变量设置 detail = UEditorField(verbose_name=u'课程详情', width=600, height=300, imagePath=\"courses/ueditor/\", filePath=\"courses/ueditor/\", default=u'') is_banner = models.BooleanField(default=False, verbose_name=u'是否轮播') teacher = models.ForeignKey(Teacher, verbose_name=u'讲师', null=True, blank=True, on_delete=models.CASCADE) degree = models.CharField(verbose_name=u'难度', choices=(('cj', u'初级'), ('zj', u'中级'), ('gj', u'高级')), max_length=2) learn_times = models.IntegerField(default=0, verbose_name=u'学习时长') students = models.IntegerField(default=0, verbose_name=u'学习人数') fav_nums = models.IntegerField(default=0, verbose_name=u'收藏人数') image = models.ImageField(upload_to='courses/%Y/%m', verbose_name=u'封面图', max_length=100, null=True, blank=True) click_nums = models.IntegerField(default=0, verbose_name=u'点击数') category = models.CharField(default=u'后端开发', max_length=20, verbose_name=u'课程类别') tag = models.CharField(default='', verbose_name=u'课程标签', max_length=10, ) youneed_know = models.CharField(max_length=300, verbose_name=u'课程须知', default='') what_you_learn = models.CharField(default='', max_length=300, verbose_name=u'老师告诉你能学到什么') add_time = models.DateTimeField(default=datetime.now, verbose_name=u'添加时间') class Meta: verbose_name = u'课程' verbose_name_plural = verbose_name # # def __unicode__(self): # return self.name def get_lesson_nums(self): \"\"\" 获取章节数 :return: 章节数 \"\"\" return self.lesson_set.all().count() # 给个显示名字 get_lesson_nums.short_description = u'章节数' # 跳转函数 def go_to(self): from django.utils.safestring import mark_safe return mark_safe(\"跳转\") go_to.short_description = u'跳转' def get_learn_users(self): \"\"\" 获取学习用户 :return: 学习用户 \"\"\" return self.usercourse_set.all()[:5] def get_lesson(self): \"\"\" 获取课程所有章节 :return: \"\"\" return self.lesson_set.all() # def get_user(self): # \"\"\" # 获取课程所有章节 # :return: # \"\"\" # return self.lesson_set.all() def __str__(self): return self.name class BannerCourse(Course): \"\"\"轮播课程model继承于Course,拥有Course所有方法和属性\"\"\" class Meta: verbose_name = u'轮播课程' verbose_name_plural = verbose_name # proxy必须设置为True,就不会另外生产一张表而是和Course同一张表 proxy = True class Lesson(models.Model): course = models.ForeignKey(Course, verbose_name=u'课程', on_delete=models.CASCADE) name = models.CharField(max_length=100, verbose_name=u'章节名') add_time = models.DateTimeField(default=datetime.now, verbose_name=u'添加时间') class Meta: verbose_name = u'章节' verbose_name_plural = verbose_name def get_lesson_video(self): \"\"\" 获取章节视频信息 \"\"\" return self.video_set.all() def __str__(self): return self.name class Video(models.Model): lesson = models.ForeignKey(Lesson, verbose_name=u'章节', on_delete=models.CASCADE) name = models.CharField(max_length=100, verbose_name=u'视频名') url = models.CharField(default='', max_length=200, verbose_name=u'访问地址') learn_times = models.IntegerField(default=0, verbose_name=u'学习时长') add_time = models.DateTimeField(default=datetime.now, verbose_name=u'添加时间') class Meta: verbose_name = u'视频' verbose_name_plural = verbose_name def __str__(self): return self.name class CourseResource(models.Model): course = models.ForeignKey(Course, verbose_name=u'课程', on_delete=models.CASCADE) name = models.CharField(max_length=100, verbose_name=u'名称') download = models.FileField(upload_to='course/%Y/%m', verbose_name=u'资源文件', max_length=100) add_time = models.DateTimeField(default=datetime.now, verbose_name=u'添加时间') class Meta: verbose_name = u'课程资源' verbose_name_plural = verbose_name def __str__(self): return self.name adminx.py import xadmin from .models import Course, Lesson, Video, CourseResource, BannerCourse # 配置主题功能 class BaseSetting(object): enable_themes = True use_bootswatch = True # 全局头部脚步配置 class GlobalSettings(object): site_title = '慕课网' site_footer = '慕课在线网' menu_style = 'accordion' # inline模式，只能一层嵌套，不能多层嵌套，但可以多个 class LessonInline(object): model = Lesson extra = 0 class CourseResourceInline(object): model = CourseResource extra = 0 class CourseAdmin(object): \"\"\" 课程管理器 \"\"\" # 显示的字段，还可以显示函数，可以加入model中定义的函数如获取章节数：get_lesson_nums,go_to list_display = ['name', 'course_org', 'desc', 'detail', 'degree', 'learn_times', 'students', 'fav_nums', 'image', 'click_nums', 'add_time', 'get_lesson_nums', 'go_to'] # 搜索功能 search_fields = ['name', 'desc', 'detail', 'degree', 'learn_times', 'students', 'fav_nums', 'image', 'click_nums'] # 过滤器 list_filter = ['name', 'desc', 'detail', 'degree', 'learn_times', 'students', 'fav_nums', 'image', 'click_nums', 'add_time'] # ico图标 model_icon = 'fa fa-file' # 当有一个model有一个外键指向它时，它是ajax加载方式完成，数据量过大时很有用，可进行搜索而不是下拉式 relfield_style = 'fk-ajax' # 排序规则 ordering = ['-click_nums'] # 设置某些字段为只读 readonly_fields = ['click_nums'] # 设置某些字段不显示,和上面的设置会冲突，所以某个字段只能设置其中一个 exclude = ['fav_nums'] # 展示页面中直接修改功能 list_editable = ['degree', 'desc'] # inlines 设置 inlines = [LessonInline, CourseResourceInline] # 自定义刷新时间,配置多个页面中可选 refresh_times = [3, 5] # 插件配置 # 1、指明某个字段用的是什么样式，下面就是指明detail是ueditor样式 style_fields = {\"detail\": \"ueditor\"} # 2、Excel导入导出功能,True为开启 list_export = ['xls', 'xml', 'json'] import_excel = True # 重载方法过滤课程 def queryset(self): qs = super(CourseAdmin, self).queryset() qs = qs.filter(is_banner=False) return qs def save_models(self): # 在保存课程的时候统计机构的课程数 obj = self.new_obj # 查询前先保存才能增加新增的数量 obj.save() if obj.course_org is not None: course_org = obj.course_org course_org.course_nums = Course.objects.filter(course_org=course_org).count() course_org.save() def post(self, request, *args, **kwargs): # 导入逻辑 if 'excel' in request.FILES: pass return super(CourseAdmin, self).post(request, args, kwargs) class BannerCourseAdmin(object): \"\"\" 轮播课程管理器，和上面的课程管理器管理的是同一张表 \"\"\" list_display = ['name', 'course_org', 'desc', 'detail', 'degree', 'learn_times', 'students', 'fav_nums', 'image', 'click_nums', 'add_time'] search_fields = ['name', 'desc', 'detail', 'degree', 'learn_times', 'students', 'fav_nums', 'image', 'click_nums'] list_filter = ['name', 'desc', 'detail', 'degree', 'learn_times', 'students', 'fav_nums', 'image', 'click_nums', 'add_time'] model_icon = 'fa fa-file' # 排序规则 ordering = ['-click_nums'] # 设置某些字段为只读 readonly_fields = ['click_nums'] # 设置某些字段不显示,和上面的设置会冲突，所以某个字段只能设置其中一个 exclude = ['fav_nums'] # inlines 设置 inlines = [LessonInline, CourseResourceInline] # 重载方法过滤课程 def queryset(self): qs = super(BannerCourseAdmin, self).queryset() qs = qs.filter(is_banner=True) return qs class LessonAdmin(object): list_display = ['course', 'name', 'add_time'] search_fields = ['course', 'name'] list_filter = ['course__name', 'name', 'add_time'] # course__name外键设置 model_icon = 'fa fa-file-o' class VideoAdmin(object): list_display = ['lesson', 'name', 'add_time'] search_fields = ['lesson', 'name'] list_filter = ['lesson__name', 'name', 'add_time'] # course__name外键设置 model_icon = 'fa fa-file-video-o' class CourseResourceAdmin(object): list_display = ['course', 'name', 'download', 'add_time'] search_fields = ['course', 'name', 'download'] list_filter = ['course__name', 'name', 'download', 'add_time'] model_icon = 'fa fa-file-archive-o' xadmin.site.register(Course, CourseAdmin) xadmin.site.register(BannerCourse, BannerCourseAdmin) xadmin.site.register(Lesson, LessonAdmin) xadmin.site.register(Video, VideoAdmin) xadmin.site.register(CourseResource, CourseResourceAdmin) xadmin.site.register(views.BaseAdminView, BaseSetting) xadmin.site.register(views.CommAdminView, GlobalSettings) Django_xadmin开启excel导入功能 # 文件路径：xadmin/plugins/execl.py from xadmin.sites import site from xadmin.views import BaseAdminPlugin, ListAdminView from django.template import loader from xadmin.plugins.utils import get_context_dict # excel 导入 class ListImportExcelPlugin(BaseAdminPlugin): import_excel = False def init_request(self, *args, **kwargs): return bool(self.import_excel) def block_top_toolbar(self, context, nodes): nodes.append(loader.render_to_string('xadmin/excel/model_list.top_toolbar.import.html', context=get_context_dict(context))) xadmin.site.register_plugin(ListImportExcelPlugin, ListAdminView) # 模板文件：xadmin/templates/xadmin/excel/model_list.top_toolbar.import.html { % load i18n %} 导入1 导入 Excel function fileChange(target) { // 检测上传文件的类型 var imgName = document.all.submit_upload.value; var ext, idx; if (imgName == '') { document.all.submit_upload_b.disabled = true; alert(\"请选择需要上传的 xls 文件!\"); return; } else { idx = imgName.lastIndexOf(\".\"); if (idx != -1){ ext = imgName.substr(idx+1).toUpperCase(); ext = ext.toLowerCase( ); { # alert(\"ext=\"+ext);#} if (ext != 'xls' & & ext != 'xlsx'){ document.all.submit_upload_b.disabled=true; alert(\"只能上传 .xls 类型的文件!\"); return; } } else { document.all.submit_upload_b.disabled = true; alert(\"只能上传 .xls 类型的文件!\"); return; } } } { % csrf_token %} & times; 导入 Excel { % trans \"Close\" % } 导入 # adminx.py文件 class maintenanceRecordListAdmin(object): list_display = [...] search_fields = [...] list_filter = [...] list_editable = [...] readonly_fields = [...] # excel导入导出功能 list_export = ['xls', 'xml', 'json'] import_excel = True def post(self, request, *args, **kwargs): # 导入逻辑 if 'excel' in request.FILES: pass return super(maintenanceRecordListAdmin, self).post(request, args, kwargs) 使用ORM完成模型的CRUD操作 在了解了Django提供的模型管理平台之后，我们来看看如何从代码层面完成对模型的CRUD（Create / Read / Update / Delete）操作。我们可以通过manage.py开启Shell交互式环境，然后使用Django内置的ORM框架对模型进行CRUD操作。 (venv)$ python manage.py shell Python 3.6.4 (v3.6.4:d48ecebad5, Dec 18 2017, 21:07:28) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. (InteractiveConsole) >>> 新增 >>> from hrs.models import Dept, Emp >>> dept = Dept(40, '研发2部', '深圳') >>> dept.save() 更新 >>> dept.name = '研发3部' >>> dept.save() 查询 查询所有对象。 >>> Dept.objects.all() , , , ]> 过滤数据。 >>> Dept.objects.filter(name='研发3部') # 查询部门名称为“研发3部”的部门 ]> >>> >>> Dept.objects.filter(name__contains='研发') # 查询部门名称包含“研发”的部门(模糊查询) , ]> >>> >>> Dept.objects.filter(no__gt=10).filter(no__lt=40) # 查询部门编号大于10小于40的部门 , ]> >>> >>> Dept.objects.filter(no__range=(10, 30)) # 查询部门编号在10到30之间的部门 , , ]> 查询单个对象。 >>> Dept.objects.get(pk=10) >>> >>> Dept.objects.get(no=20) >>> >>> Dept.objects.get(no__exact=30) >>> >>> Dept.objects.filter(no=10).first() 排序数据。 >>> Dept.objects.order_by('no') # 查询所有部门按部门编号升序排列 , , , ]> >>> >>> Dept.objects.order_by('-no') # 查询所有部门按部门编号降序排列 , , , ]> 切片数据。 >>> Dept.objects.order_by('no')[0:2] # 按部门编号排序查询1~2部门 , ]> >>> >>> Dept.objects.order_by('no')[2:4] # 按部门编号排序查询3~4部门 , ]> 高级查询。 >>> Emp.objects.filter(dept__no=10) # 根据部门编号查询该部门的员工 , , ]> >>> >>> Emp.objects.filter(dept__name__contains='销售') # 查询名字包含“销售”的部门的员工 ]> >>> >>> Dept.objects.get(pk=10).emp_set.all() # 通过部门反查部门所有的员工 , , ]> 说明1：由于员工与部门之间存在多对一外键关联，所以也能通过部门反向查询该部门的员工（从一对多关系中“一”的一方查询“多”的一方），反向查询属性默认的名字是类名小写_set（如上面例子中的emp_set），当然也可以在创建模型时通过ForeingKey的related_name属性指定反向查询属性的名字。如果不希望执行反向查询可以将related_name属性设置为'+'或以'+'开头的字符串。 说明2：查询多个对象的时候返回的是QuerySet对象，QuerySet使用了惰性查询，即在创建QuerySet对象的过程中不涉及任何数据库活动，等真正用到对象时（求值QuerySet）才向数据库发送SQL语句并获取对应的结果，这一点在实际开发中需要引起注意！ 说明3：可以在QuerySet上使用update()方法一次更新多个对象。 删除 >>> Dept.objects.get(pk=40).delete() (1, {'hrs.Dept': 1}) Django模型最佳实践 正确的为模型和关系字段命名。 设置适当的related_name属性。 用OneToOneField代替ForeignKeyField(unique=True)。 通过“迁移操作”（migrate）来添加模型。 用NoSQL来应对需要降低范式级别的场景。 如果布尔类型可以为空要使用NullBooleanField。 在模型中放置业务逻辑。 用.DoesNotExists取代ObjectDoesNotExists。 在数据库中不要出现无效数据。 不要对QuerySet调用len()函数。 将QuerySet的exists()方法的返回值用于if条件。 用DecimalField来存储货币相关数据而不是FloatField。 定义__str__方法。 不要将数据文件放在同一个目录中。 说明：以上内容来自于STEELKIWI网站的Best Practice working with Django models in Python，有兴趣的小伙伴可以阅读原文。 模型定义参考 字段 对字段名称的限制 字段名不能是Python的保留字，否则会导致语法错误 字段名不能有多个连续下划线，否则影响ORM查询操作 Django模型字段类 字段类 说明 AutoField 自增ID字段 BigIntegerField 64位有符号整数 BinaryField 存储二进制数据的字段，对应Python的bytes类型 BooleanField 存储True或False CharField 长度较小的字符串 DateField 存储日期，有auto_now和auto_now_add属性 DateTimeField 存储日期和日期，两个附加属性同上 DecimalField 存储固定精度小数，有max_digits（有效位数）和decimal_places（小数点后面）两个必要的参数 DurationField 存储时间跨度 EmailField 与CharField相同，可以用EmailValidator验证 FileField 文件上传字段 FloatField 存储浮点数 ImageField 其他同FileFiled，要验证上传的是不是有效图像 IntegerField 存储32位有符号整数。 GenericIPAddressField 存储IPv4或IPv6地址 NullBooleanField 存储True、False或null值 PositiveIntegerField 存储无符号整数（只能存储正数） SlugField 存储slug（简短标注） SmallIntegerField 存储16位有符号整数 TextField 存储数据量较大的文本 TimeField 存储时间 URLField 存储URL的CharField UUIDField 存储全局唯一标识符 自定义字段（了解为主） class UnsignedIntegerField(models.IntegerField): def db_type(self, connection): return 'integer UNSIGNED' 自定义char类型字段： class FixedCharField(models.Field): \"\"\" 自定义的char类型的字段类 \"\"\" def __init__(self, max_length, *args, **kwargs): super().__init__(max_length=max_length, *args, **kwargs) self.length = max_length def db_type(self, connection): \"\"\" 限定生成数据库表的字段类型为char，长度为length指定的值 \"\"\" return 'char(%s)' % self.length class Class(models.Model): id = models.AutoField(primary_key=True) title = models.CharField(max_length=25) # 使用上面自定义的char类型的字段 cname = FixedCharField(max_length=25) 字段属性 通用字段属性 选项 说明 null 数据库中对应的字段是否允许为NULL，默认为False blank 后台模型管理验证数据时，是否允许为NULL，默认为False choices 设定字段的选项，各元组中的第一个值是设置在模型上的值，第二值是人类可读的值 db_column 字段对应到数据库表中的列名，未指定时直接使用字段的名称 db_index 设置为True时将在该字段创建索引 db_tablespace 为有索引的字段设置使用的表空间，默认为DEFAULT_INDEX_TABLESPACE default 字段的默认值 editable 字段在后台模型管理或ModelForm中是否显示，默认为True error_messages 设定字段抛出异常时的默认消息的字典，其中的键包括null、blank、invalid、invalid_choice、unique和unique_for_date help_text 表单小组件旁边显示的额外的帮助文本。 primary_key 将字段指定为模型的主键，未指定时会自动添加AutoField用于主键，只读。 unique 设置为True时，表中字段的值必须是唯一的 verbose_name 字段在后台模型管理显示的名称，未指定时使用字段的名称 ForeignKey属性 1. limit_choices_to：值是一个Q对象或返回一个Q对象，用于限制后台显示哪些对象。 2. related_name：用于获取关联对象的关联管理器对象（反向查询），如果不允许反向，该属性应该被设置为`'+'`，或者以`'+'`结尾。 3. to_field：指定关联的字段，默认关联对象的主键字段。 4. db_constraint：是否为外键创建约束，默认值为True。 5. on_delete：外键关联的对象被删除时对应的动作，可取的值包括django.db.models中定义的： - CASCADE：级联删除。 - PROTECT：抛出ProtectedError异常，阻止删除引用的对象。 - SET_NULL：把外键设置为null，当null属性被设置为True时才能这么做。 - SET_DEFAULT：把外键设置为默认值，提供了默认值才能这么做。 ManyToManyField属性 1. symmetrical：是否建立对称的多对多关系。 2. through：指定维持多对多关系的中间表的Django模型。 3. throughfields：定义了中间模型时可以指定建立多对多关系的字段。 4. db_table：指定维持多对多关系的中间表的表名。 模型元数据选项 选项 说明 abstract 设置为True时模型是抽象父类 app_label 如果定义模型的应用不在INSTALLED_APPS中可以用该属性指定 db_table 模型使用的数据表名称 db_tablespace 模型使用的数据表空间 default_related_name 关联对象回指这个模型时默认使用的名称，默认为_set get_latest_by 模型中可排序字段的名称。 managed 设置为True时，Django在迁移中创建数据表并在执行flush管理命令时把表移除 order_with_respect_to 标记对象为可排序的 ordering 对象的默认排序 permissions 创建对象时写入权限表的额外权限 default_permissions 默认为('add', 'change', 'delete') unique_together 设定组合在一起时必须独一无二的字段名(联合唯一索引) index_together 设定一起建立索引的多个字段名(联合索引) verbose_name 为对象设定人类可读的名称 verbose_name_plural 设定对象的复数名称 查询参考 按字段查找可以用的条件： 1. exact / iexact：精确匹配/忽略大小写的精确匹配查询 2. contains / icontains / startswith / istartswith / endswith / iendswith：基于`like`的模糊查询 3. in：集合运算 4. gt / gte / lt / lte：大于/大于等于/小于/小于等于关系运算 5. range：指定范围查询（SQL中的`between…and…`） 6. year / month / day / week_day / hour / minute / second：查询时间日期 7. isnull：查询空值（True）或非空值（False） 8. search：基于全文索引的全文检索 9. regex / iregex：基于正则表达式的模糊匹配查询 Q对象（用于执行复杂查询）的使用： >>> from django.db.models import Q >>> Emp.objects.filter( ... Q(name__startswith='张'), ... Q(sal__gte=5000) | Q(comm__gte=1000) ... ) # 查询名字以“张”开头且工资大于等于5000或补贴大于等于1000的员工 ]> 模型定义例子 from datetime import datetime from DjangoUeditor.models import UEditorField from django.db import models from organization.models import CourseOrg, Teacher # Create your models here. class Course(models.Model): course_org = models.ForeignKey(CourseOrg, verbose_name=u'课程机构', null=True, blank=True, on_delete=models.CASCADE) name = models.CharField(max_length=50, verbose_name=u'课程名称') desc = models.CharField(max_length=300, verbose_name=u'课程描述') # 使用富文本编辑器插件, ueditor的上传路径固定在ueditor目录下。文件名查看官方文档的变量设置 detail = UEditorField(verbose_name=u'课程详情', width=600, height=300, imagePath=\"courses/ueditor/\", filePath=\"courses/ueditor/\", default=u'') is_banner = models.BooleanField(default=False, verbose_name=u'是否轮播') teacher = models.ForeignKey(Teacher, verbose_name=u'讲师', null=True, blank=True, on_delete=models.CASCADE) degree = models.CharField(verbose_name=u'难度', choices=(('cj', u'初级'), ('zj', u'中级'), ('gj', u'高级')), max_length=2) learn_times = models.IntegerField(default=0, verbose_name=u'学习时长') students = models.IntegerField(default=0, verbose_name=u'学习人数') fav_nums = models.IntegerField(default=0, verbose_name=u'收藏人数') image = models.ImageField(upload_to='courses/%Y/%m', verbose_name=u'封面图', max_length=100, null=True, blank=True) click_nums = models.IntegerField(default=0, verbose_name=u'点击数') category = models.CharField(default=u'后端开发', max_length=20, verbose_name=u'课程类别') tag = models.CharField(default='', verbose_name=u'课程标签', max_length=10, ) youneed_know = models.CharField(max_length=300, verbose_name=u'课程须知', default='') what_you_learn = models.CharField(default='', max_length=300, verbose_name=u'老师告诉你能学到什么') add_time = models.DateTimeField(default=datetime.now, verbose_name=u'添加时间') class Meta: verbose_name = u'课程' verbose_name_plural = verbose_name def get_lesson_nums(self): \"\"\" 获取章节数 :return: 章节数 \"\"\" return self.lesson_set.all().count() # 给个显示名字 get_lesson_nums.short_description = u'章节数' # 跳转函数 def go_to(self): from django.utils.safestring import mark_safe return mark_safe(\"跳转\") go_to.short_description = u'跳转' def get_learn_users(self): \"\"\" 获取学习用户 :return: 学习用户 \"\"\" return self.usercourse_set.all()[:5] def get_lesson(self): \"\"\" 获取课程所有章节 :return: \"\"\" return self.lesson_set.all() def __str__(self): return self.name class BannerCourse(Course): \"\"\"轮播课程model继承于Course,拥有Course所有方法和属性\"\"\" class Meta: verbose_name = u'轮播课程' verbose_name_plural = verbose_name # proxy必须设置为True,就不会另外生产一张表而是和Course同一张表 proxy = True class Lesson(models.Model): course = models.ForeignKey(Course, verbose_name=u'课程', on_delete=models.CASCADE) name = models.CharField(max_length=100, verbose_name=u'章节名') add_time = models.DateTimeField(default=datetime.now, verbose_name=u'添加时间') class Meta: verbose_name = u'章节' verbose_name_plural = verbose_name def get_lesson_video(self): \"\"\" 获取章节视频信息 \"\"\" return self.video_set.all() def __str__(self): return self.name class Video(models.Model): lesson = models.ForeignKey(Lesson, verbose_name=u'章节', on_delete=models.CASCADE) name = models.CharField(max_length=100, verbose_name=u'视频名') url = models.CharField(default='', max_length=200, verbose_name=u'访问地址') learn_times = models.IntegerField(default=0, verbose_name=u'学习时长') add_time = models.DateTimeField(default=datetime.now, verbose_name=u'添加时间') class Meta: verbose_name = u'视频' verbose_name_plural = verbose_name def __str__(self): return self.name class CourseResource(models.Model): course = models.ForeignKey(Course, verbose_name=u'课程', on_delete=models.CASCADE) name = models.CharField(max_length=100, verbose_name=u'名称') download = models.FileField(upload_to='course/%Y/%m', verbose_name=u'资源文件', max_length=100) add_time = models.DateTimeField(default=datetime.now, verbose_name=u'添加时间') class Meta: verbose_name = u'课程资源' verbose_name_plural = verbose_name def __str__(self): return self.name "},"Python/第三方库/Django/03-静态资源和Ajax请求.html":{"url":"Python/第三方库/Django/03-静态资源和Ajax请求.html","title":"静态资源和Ajax请求","keywords":"","body":"datetime:2019/6/10 11:32 author:nzb AJAX AJAX准备知识：JSON 什么是JSON? JSON 指的是 JavaScript 对象表示法（JavaScript Object Notation） JSON 是轻量级的文本数据交换格式 JSON 独立于语言 * JSON 具有自我描述性，更易理解 *JSON 使用 JavaScript 语法来描述数据对象，但是 JSON 仍然独立于语言和平台。JSON 解析器和 JSON 库支持许多不同的编程语言。 啥都别多说了，上图吧！ 合格的json对象： [\"one\", \"two\", \"three\"] { \"one\": 1, \"two\": 2, \"three\": 3 } {\"names\": [\"张三\", \"李四\"] } [ { \"name\": \"张三\"}, {\"name\": \"李四\"} ]　 不合格的json对象： { name: \"张三\", 'age': 32 } // 属性名必须使用双引号 [32, 64, 128, 0xFFF] // 不能使用十六进制值 { \"name\": \"张三\", \"age\": undefined } // 不能使用undefined { \"name\": \"张三\", \"birthday\": new Date('Fri, 26 Aug 2011 07:13:10 GMT'), \"getName\": function() {return this.name;} // 不能使用函数和日期对象 } stringify与parse方法 JavaScript中关于JSON对象和字符串转换的两个方法： JSON.parse(): 用于将一个 JSON 字符串转换为 JavaScript 对象　 JSON.parse('{\"name\":\"Q1mi\"}'); JSON.parse('{name:\"Q1mi\"}') ; // 错误 JSON.parse('[18,undefined]') ; // 错误 JSON.stringify(): 用于将 JavaScript 值转换为 JSON 字符串。　 JSON.stringify({\"name\":\"Q1mi\"}) 和XML的比较 JSON 格式于2001年由 Douglas Crockford 提出，目的就是取代繁琐笨重的 XML 格式。 JSON 格式有两个显著的优点：书写简单，一目了然；符合 JavaScript 原生语法，可以由解释引擎直接处理，不用另外添加解析代码。所以，JSON迅速被接受，已经成为各大网站交换数据的标准格式，并被写入ECMAScript 5，成为标准的一部分。 XML和JSON都使用结构化方法来标记数据，下面来做一个简单的比较。 用XML表示中国部分省市数据如下： 中国 黑龙江 哈尔滨 大庆 广东 广州 深圳 珠海 台湾 台北 高雄 新疆 乌鲁木齐 用JSON表示如下： { \"name\": \"中国\", \"province\": [{ \"name\": \"黑龙江\", \"cities\": { \"city\": [\"哈尔滨\", \"大庆\"] } }, { \"name\": \"广东\", \"cities\": { \"city\": [\"广州\", \"深圳\", \"珠海\"] } }, { \"name\": \"台湾\", \"cities\": { \"city\": [\"台北\", \"高雄\"] } }, { \"name\": \"新疆\", \"cities\": { \"city\": [\"乌鲁木齐\"] } }] } 由上面的两端代码可以看出，JSON 简单的语法格式和清晰的层次结构明显要比 XML 容易阅读，并且在数据交换方面，由于 JSON 所使用的字符要比 XML 少得多，可以大大得节约传输数据所占用得带宽。 AJAX简介 发送请求的方式： 直接在地址栏输入URL回车 GET请求 a标签 GET请求 form表单 GET/POST请求 AJAX GET/POST请求 AJAX（Asynchronous Javascript And XML）翻译成中文就是“异步的Javascript和XML”。即使用Javascript语言与服务器进行异步交互，传输的数据为XML（当然，传输的数据不只是XML）。 AJAX 不是新的编程语言，而是一种使用现有标准的新方法。 AJAX 最大的优点是在不重新加载整个页面的情况下，可以与服务器交换数据并更新部分网页内容。（这一特点给用户的感受是在不知不觉中完成请求和响应过程） AJAX 不需要任何浏览器插件，但需要用户允许JavaScript在浏览器上执行。 同步交互：客户端发出一个请求后，需要等待服务器响应结束后，才能发出第二个请求； 异步交互：客户端发出一个请求后，无需等待服务器响应结束，就可以发出第二个请求。 示例 页面输入两个整数，通过AJAX传输到后端计算出结果并返回。 AJAX局部刷新实例 + = $(\"#b1\").on(\"click\", function () { $.ajax({ url:\"/ajax_add/\", type:\"GET\", data:{\"i1\":$(\"#i1\").val(),\"i2\":$(\"#i2\").val()}, success:function (data) { $(\"#i3\").val(data); } }) }) def ajax_demo1(request): return render(request, \"ajax_demo1.html\") def ajax_add(request): i1 = int(request.GET.get(\"i1\")) i2 = int(request.GET.get(\"i2\")) ret = i1 + i2 return JsonResponse(ret, safe=False) urlpatterns = [ ... url(r'^ajax_add/', views.ajax_add), url(r'^ajax_demo1/', views.ajax_demo1), ... ] AJAX常见应用场景 搜索引擎根据用户输入的关键字，自动提示检索关键字。 还有一个很重要的应用场景就是注册时候的用户名的查重。 其实这里就使用了AJAX技术！当文件框发生了输入变化时，使用AJAX技术向服务器发送一个请求，然后服务器会把查询到的结果响应给浏览器，最后再把后端返回的结果展示出来。 整个过程中页面没有刷新，只是刷新页面中的局部位置而已！ 当请求发出后，浏览器还可以进行其他操作，无需等待服务器的响应！ 当输入用户名后，把光标移动到其他表单项上时，浏览器会使用AJAX技术向服务器发出请求，服务器会查询名为lemontree7777777的用户是否存在，最终服务器返回true表示名为lemontree7777777的用户已经存在了，浏览器在得到结果后显示“用户名已被注册！”。 整个过程中页面没有刷新，只是局部刷新了； 在请求发出后，浏览器不用等待服务器响应结果就可以进行其他操作； AJAX的优缺点 优点： AJAX使用JavaScript技术向服务器发送异步请求； AJAX请求无须刷新整个页面； 因为服务器响应内容不再是整个页面，而是页面中的部分内容，所以AJAX性能高； jQuery实现的AJAX 最基本的jQuery发送AJAX请求示例： ajax test AJAX 测试 $(\"#ajaxTest\").click(function () { $.ajax({ url: \"/ajax_test/\", type: \"POST\", data: {username: \"Q1mi\", password: 123456}, success: function (data) { alert(data) } }) }) views.py def ajax_test(request): user_name = request.POST.get(\"username\") password = request.POST.get(\"password\") print(user_name, password) return HttpResponse(\"OK\") $.ajax参数 data参数中的键值对，如果值值不为字符串，需要将其转换成字符串类型。 $(\"#b1\").on(\"click\", function () { $.ajax({ url:\"/ajax_add/\", type:\"GET\", data:{\"i1\":$(\"#i1\").val(),\"i2\":$(\"#i2\").val(),\"hehe\": JSON.stringify([1, 2, 3])}, success:function (data) { $(\"#i3\").val(data); } }) }) $.ajax参数data ajax有三种传递传递data的方式： 1、json格式 2、标准参数模式 3、json字符串格式 1.json对象格式： {“username”:”chen”,”nickname”:”alien”} $.ajax({ type:\"post\", url:\"/test/saveUser\", data:{\"username\":\"chen\",\"nickname\":\"alien\"}, dataType:\"json\", //指定响应的data数据类型为JSON对象。 success: function(data){ console.log(data); } }); - 如：当前的Ajax请求是一个POST请求，对请求体中的数据 使用默认的数据编码，格式如：key1 = value2&key2 = value2 a中的数据变成这样的格式：key1 = value2&key2 = value2 ，包装在Http请求体中传送给后台。 - dataType:\"json\" - dataType:“json” ：用来指定服务器返回的data数据类型必须是JSON类型。然后jQuery就会把后端返回的json字符串尝试通过JSON.parse()解析为js对象。 - 如果不指定dataType，jQuery 将自动根据 HTTP 包的 MIME 信息来智能判断，若MIME信息的值为JSON，则jQuery会自动的把data数据转换成JS对象的json，接着Script把data传递给回调函数进行JS的脚本操作。 2、标准参数模式 “username=Liudehua & age=50” $.ajax({ type:\"post\", url:\"/test/saveUser\", data:\"username=chen&nickname=alien\", dataType:\"json\", success: function(data){ console.log(data); } }); - $(“#form1”).serialize() 就是把表单的数据拼成这个格式（key1 = value2&key2 = value2）的字符串，然后放在Http请求体中传给后台！ 3.json字符串 ————>只用于post请求 “{“username”:”chen”,”nickname”:”alien”}”————>JSON对象格式的字符串 JSON.stringify({“username”:”chen”,”nickname”:”alien”})————>把JSON对象转成JSON格式的字符串。 $.ajax({ type:\"post\", url:\"/test/saveUser\", data:JSON.stringify({\"username\":\"chen\",\"nickname\":\"alien\"}), contentType:\"json/application\" dataType:\"json\", success: function(data){ console.log(data); } }); ** 第三种这种方式不能用于 Get请求。 原因： 1、因为此种方式发送的请求，后端必须得用@RequestBody进行接收，且接收的是Http请求体中的数据，Get请求没有请求体。 2、而且此方式的Ajax 必须要添加 contentType:”json/application”这个字段信息。 ** 注意： 1、若为GET请求，则会把data的数据 附加在 URL 后， 格式如：localhost://findAll ? key1=value1&key2=value2 若为POST请求，则就会把data的数据 放在请求体中。 格式如：key1 = value2&key2 = value2 2、dataType：指定服务器端返回的数据类型。 若不指定，且后端返回的是Json，前端就会自动识别返回的数据是JSON。 JS实现AJAX var b2 = document.getElementById(\"b2\"); b2.onclick = function () { // 原生JS var xmlHttp = new XMLHttpRequest(); xmlHttp.open(\"POST\", \"/ajax_test/\", true); xmlHttp.setRequestHeader(\"Content-type\", \"application/x-www-form-urlencoded\"); xmlHttp.send(\"username=q1mi&password=123456\"); xmlHttp.onreadystatechange = function () { if (xmlHttp.readyState === 4 && xmlHttp.status === 200) { alert(xmlHttp.responseText); } }; }; AJAX请求如何设置csrf_token 方式1 通过获取隐藏的input标签中的csrfmiddlewaretoken值，放置在data中发送。 $.ajax({ url: \"/cookie_ajax/\", type: \"POST\", data: { \"username\": \"Q1mi\", \"password\": 123456, \"csrfmiddlewaretoken\": $(\"[name = 'csrfmiddlewaretoken']\").val() // 使用jQuery取出csrfmiddlewaretoken的值，拼接到data中 }, success: function (data) { console.log(data); } }) 方式2 通过获取返回的cookie中的字符串 放置在请求头中发送。 注意：需要引入一个jquery.cookie.js插件。 $.ajax({ url: \"/cookie_ajax/\", type: \"POST\", headers: {\"X-CSRFToken\": $.cookie('csrftoken')}, // 从Cookie取csrftoken，并设置到请求头中 data: {\"username\": \"Q1mi\", \"password\": 123456}, success: function (data) { console.log(data); } }) 或者用自己写一个getCookie方法： function getCookie(name) { var cookieValue = null; if (document.cookie && document.cookie !== '') { var cookies = document.cookie.split(';'); for (var i = 0; i 每一次都这么写太麻烦了，可以使用$.ajaxSetup()方法为ajax请求统一设置。 function csrfSafeMethod(method) { // these HTTP methods do not require CSRF protection return (/^(GET|HEAD|OPTIONS|TRACE)$/.test(method)); } $.ajaxSetup({ beforeSend: function (xhr, settings) { if (!csrfSafeMethod(settings.type) && !this.crossDomain) { xhr.setRequestHeader(\"X-CSRFToken\", csrftoken); } } }); 注意： 如果使用从cookie中取csrftoken的方式，需要确保cookie存在csrftoken值。 如果你的视图渲染的HTML文件中没有包含 { % csrf_token % }，Django可能不会设置CSRFtoken的cookie。 这个时候需要使用ensure_csrf_cookie()装饰器强制设置Cookie。 django.views.decorators.csrf import ensure_csrf_cookie @ensure_csrf_cookie def login(request): pass 更多细节详见：Djagno官方文档中关于CSRF的内容 AJAX上传文件 XMLHttpRequest 是一个浏览器接口，通过它，我们可以使得 Javascript 进行 HTTP (S) 通信。XMLHttpRequest 在现在浏览器中是一种常用的前后台交互数据的方式。2008年 2 月，XMLHttpRequest Level 2 草案提出来了，相对于上一代，它有一些新的特性，其中 FormData 就是 XMLHttpRequest Level 2 新增的一个对象，利用它来提交表单、模拟表单提交，当然最大的优势就是可以上传二进制文件。下面就具体 首先看一下formData的基本用法：FormData对象，可以把所有表单元素的name与value组成一个queryString，提交到后台。只需要把 form 表单作为参数传入 FormData 构造函数即可： 介绍一下如何利用 FormData 来上传文件。 // 上传文件示例 $(\"#b3\").click(function () { var formData = new FormData(); formData.append(\"csrfmiddlewaretoken\", $(\"[name='csrfmiddlewaretoken']\").val()); formData.append(\"f1\", $(\"#f1\")[0].files[0]); $.ajax({ url: \"/upload/\", type: \"POST\", processData: false, // 告诉jQuery不要去处理发送的数据 contentType: false, // 告诉jQuery不要去设置Content-Type请求头 data: formData, success:function (data) { console.log(data) } }) }) 或者使用 var form = document.getElementById(\"form1\"); var fd = new FormData(form); 这样也可以直接通过ajax 的 send() 方法将 fd 发送到后台。 注意：由于 FormData 是 XMLHttpRequest Level 2 新增的接口，现在 低于IE10 的IE浏览器不支持 FormData。 练习（用户名是否已被注册） 功能介绍 在注册表单中，当用户填写了用户名后，把光标移开后，会自动向服务器发送异步请求。服务器返回这个用户名是否已经被注册过。 案例分析 页面中给出注册表单； 在username input标签中绑定onblur事件处理函数。 当input标签失去焦点后获取 username表单字段的值，向服务端发送AJAX请求； django的视图函数中处理该请求，获取username值，判断该用户在数据库中是否被注册，如果被注册了就返回“该用户已被注册”，否则响应“该用户名可以注册”。 ajax中参数traditional的作用 　　 在使用ajax向后台传值的时候，有的时候一个字段需要传多个值，这种情况下会想到用数组形式来传，比如： $.ajax({ type: \"post\", async: true, data: { \"records\": [\"123\",\"456\",\"789\"] }, url: \"xxxxx\", error: function(request) {}, success: function(data) {} }); 但是通过测试很快就会发现java后台无法取到参数，因为jQuery需要调用jQuery.param序列化参数，jQuery.param(obj, traditional )默认情况下traditional为false， 即jquery会深度序列化参数对象，以适应如PHP和Ruby on Rails框架，但servelt api无法处理，我们可以通过设置traditional 为true阻止深度序列化，然后序列化结果如下： records: [\"123\", \"456\", \"789\"] => records=123&p=456&p=789 随即，我们就可以在后台通过request.getParameterValues()来获取参数的值数组了，如下： $.ajax({ type: \"post\", async: true, traditional: true, data: { \"records\": [\"123\",\"456\",\"789\"] }, url: \"xxxxx\", error: function(request) {}, success: function(data) {} }); 序列化 Django内置的serializers def books_json(request): book_list = models.Book.objects.all()[0:10] from django.core import serializers ret = serializers.serialize(\"json\", book_list) return HttpResponse(ret) 补充一个SweetAlert插件示例 点击下载Bootstrap-sweetalert项目。 $(\".btn-danger\").on(\"click\", function () { swal({ title: \"你确定要删除吗？\", text: \"删除可就找不回来了哦！\", type: \"warning\", showCancelButton: true, confirmButtonClass: \"btn-danger\", confirmButtonText: \"删除\", cancelButtonText: \"取消\", closeOnConfirm: false }, function () { var deleteId = $(this).parent().parent().attr(\"data_id\"); $.ajax({ url: \"/delete_book/\", type: \"post\", data: {\"id\": deleteId}, success: function (data) { if (data.status === 1) { swal(\"删除成功!\", \"你可以准备跑路了！\", \"success\"); } else { swal(\"删除失败\", \"你可以再尝试一下！\", \"error\") } } }) }); }) 静态资源和Ajax请求(100天) 基于前面两个章节讲解的知识，我们已经可以使用Django框架来实现Web应用的开发了。接下来我们就尝试实现一个投票应用，具体的需求是用户进入应用首先查看到“学科介绍”页面，该页面显示了一个学校所开设的所有学科；通过点击某个学科，可以进入“老师介绍”页面，该页面展示了该学科所有老师的详细情况，可以在该页面上给老师点击“好评”或“差评”，但是会先跳转到“登录页”要求用户登录，登录成功才能投票；对于未注册的用户，可以在“登录页”点击“新用户注册”进入“注册页”完成用户注册，注册成功后会跳转到“登录页”，注册失败会获得相应的提示信息。 准备工作 由于之前已经详细的讲解了如何创建Django项目以及项目的相关配置，因此我们略过这部分内容，唯一需要说明的是，从上面对投票应用需求的描述中我们可以分析出三个业务实体：学科、老师和用户。学科和老师之间通常是一对多关联关系（一个学科有多个老师，一个老师通常只属于一个学科），用户因为要给老师投票，所以跟老师之间是多对多关联关系（一个用户可以给多个老师投票，一个老师也可以收到多个用户的投票）。首先修改应用下的models.py文件来定义数据模型，先给出学科和老师的模型。 from django.db import models class Subject(models.Model): \"\"\"学科\"\"\" no = models.AutoField(primary_key=True, verbose_name='编号') name = models.CharField(max_length=31, verbose_name='名称') intro = models.CharField(max_length=511, verbose_name='介绍') def __str__(self): return self.name class Meta: db_table = 'tb_subject' verbose_name_plural = '学科' class Teacher(models.Model): \"\"\"老师\"\"\" no = models.AutoField(primary_key=True, verbose_name='编号') name = models.CharField(max_length=15, verbose_name='姓名') gender = models.BooleanField(default=True, choices=((True, '男'), (False, '女')), verbose_name='性别') birth = models.DateField(null=True, verbose_name='出生日期') intro = models.CharField(max_length=511, default='', verbose_name='') good_count = models.IntegerField(default=0, verbose_name='好评数') bad_count = models.IntegerField(default=0, verbose_name='差评数') photo = models.CharField(max_length=255, verbose_name='照片') subject = models.ForeignKey(to=Subject, on_delete=models.PROTECT, db_column='sno', verbose_name='所属学科') def __str__(self): return self.name class Meta: db_table = 'tb_teacher' verbose_name_plural = '老师' 模型定义完成后，可以通过“生成迁移”和“执行迁移”来完成关系型数据库中二维表的创建，当然这需要提前启动数据库服务器并创建好对应的数据库，同时我们在项目中已经安装了PyMySQL而且完成了相应的配置，这些内容此处不再赘述。 (venv)$ python manage.py makemigrations vote ... (venv)$ python manage.py migrate ... 注意：为了给vote应用生成迁移，需要先修改Django项目的配置文件settings.py，在INSTALLED_APPS中添加vote应用。 完成模型迁移之后，我们可以通过下面的SQL语句来添加学科和老师测试的数据。 INSERT INTO `tb_subject` (`no`,`name`,`intro`) VALUES (1, 'Python全栈+人工智能', 'Python是一种面向对象的解释型计算机程序设计语言，由荷兰人Guido van Rossum于1989年发明，第一个公开发行版发行于1991年。'), (2, 'JavaEE+分布式服务', 'Java是一门面向对象编程语言，不仅吸收了C++语言的各种优点，还摒弃了C++里难以理解的多继承、指针等概念，因此Java语言具有功能强大和简单易用两个特征。'), (3, 'HTML5大前端', 'HTML5 将成为 HTML、XHTML 以及 HTML DOM 的新标准。'), (4, '全栈软件测试', '在规定的条件下对程序进行操作，以发现程序错误，衡量软件质量，并对其是否能满足设计要求进行评估的过程'), (5, '全链路UI/UE', '全链路要求设计师关注整个业务链中的每一个环节，将设计的价值融入每一个和用户的接触点中，让整个业务的用户体验质量得到几何级数的增长。'); INSERT INTO `tb_teacher` (`no`,`name`,`gender`,`birth`,`intro`,`good_count`,`bad_count`,`photo`,`sno`) VALUES (1, '骆昊', 1, '1980-11-28', '10年以上软硬件产品设计、研发、架构和管理经验，2003年毕业于四川大学，四川大学Java技术俱乐部创始人，四川省优秀大学毕业生，在四川省网络通信技术重点实验室工作期间，参与了2项国家自然科学基金项目、1项中国科学院中长期研究项目和多项四川省科技攻关项目，在国际会议和国内顶级期刊上发表多篇论文（1篇被SCI收录，3篇被EI收录），大规模网络性能测量系统DMC-TS的设计者和开发者，perf-TTCN语言的发明者。国内最大程序员社区CSDN的博客专家，在Github上参与和维护了多个高质量开源项目，精通C/C++、Java、Python、R、Swift、JavaScript等编程语言，擅长OOAD、系统架构、算法设计、协议分析和网络测量，主持和参与过电子政务系统、KPI考核系统、P2P借贷平台等产品的研发，一直践行“用知识创造快乐”的教学理念，善于总结，乐于分享。', 0, 0, 'images/luohao.png', 1), (2, '王海飞', 1, '1993-05-24', '5年以上Python开发经验，先后参与了O2O商城、CRM系统、CMS平台、ERP系统等项目的设计与研发，曾在全国最大最专业的汽车领域相关服务网站担任Python高级研发工程师、项目经理等职务，擅长基于Python、Java、PHP等开发语言的企业级应用开发，全程参与了多个企业级应用从需求到上线所涉及的各种工作，精通Django、Flask等框架，熟悉基于微服务的企业级项目开发，拥有丰富的项目实战经验。善于用浅显易懂的方式在课堂上传授知识点，在授课过程中经常穿插企业开发的实际案例并分析其中的重点和难点，通过这种互动性极强的教学模式帮助学员找到解决问题的办法并提升学员的综合素质。', 0, 0, 'images/wangdachui.png', 1), (3, '余婷', 0, '1992-03-12', '5年以上移动互联网项目开发经验和教学经验，曾担任上市游戏公司高级软件研发工程师和移动端（iOS）技术负责人，参了多个企业级应用和游戏类应用的移动端开发和后台服务器开发，拥有丰富的开发经验和项目管理经验，以个人开发者和协作开发者的身份在苹果的AppStore上发布过多款App。精通Python、C、Objective-C、Swift等开发语言，熟悉iOS原生App开发、RESTful接口设计以及基于Cocos2d-x的游戏开发。授课条理清晰、细致入微，性格活泼开朗、有较强的亲和力，教学过程注重理论和实践的结合，在学员中有良好的口碑。', 0, 0, 'images/yuting.png', 1), (4, '肖世荣', 1, '1977-07-02', '10年以上互联网和移动互联网产品设计、研发、技术架构和项目管理经验，曾在中国移动、symbio、ajinga.com、万达信息等公司担任架构师、项目经理、技术总监等职务，长期为苹果、保时捷、耐克、沃尔玛等国际客户以及国内的政府机构提供信息化服务，主导的项目曾获得“世界科技先锋”称号，个人作品“许愿吧”曾在腾讯应用市场生活类App排名前3，拥有百万级用户群体，运营的公众号“卵石坊”是国内知名的智能穿戴设备平台。精通Python、C++、Java、Ruby、JavaScript等开发语言，主导和参与了20多个企业级项目（含国家级重大项目和互联网创新项目），涉及的领域包括政务、社交、电信、卫生和金融，有极为丰富的项目实战经验。授课深入浅出、条理清晰，善于调动学员的学习热情并帮助学员理清思路和方法。', 0, 0, 'images/xiaoshirong.png', 1), (5, '张无忌', 1, '1987-07-07', '出生起便在冰火岛过着原始生活，踏入中土后因中玄冥神掌命危而带病习医，忍受寒毒煎熬七年最后因福缘际会练成“九阳神功”更在之后又练成了“乾坤大挪移”等盖世武功，几乎无敌于天下。 生性随和，宅心仁厚，精通医术和药理。20岁时便凭着盖世神功当上明教教主，率领百万教众及武林群雄反抗蒙古政权元朝的高压统治，最后推翻了元朝。由于擅长乾坤大挪移神功，上课遇到问题就转移话题，属于拉不出屎怪地球没有引力的类型。', 0, 0, 'images/zhangwuji.png', 5), (6, '韦一笑', 1, '1975-12-15', '外号“青翼蝠王”，为明教四大护教法王之一。 身披青条子白色长袍，轻功十分了得。由于在修炼至阴至寒的“寒冰绵掌”时出了差错，经脉中郁积了至寒阴毒，只要运上内力，寒毒就会发作，如果不吸人血解毒，全身血脉就会凝结成冰，后得张无忌相助，以其高明医术配以“九阳神功”，终将寒毒驱去，摆脱了吸吮人血这一命运。由于轻功绝顶，学生一问问题就跑了。', 0, 0, 'images/weiyixiao.png', 3); 当然也可以直接使用Django提供的后台管理应用来添加学科和老师信息，这需要先注册模型类和模型管理类。 from django.contrib import admin from django.contrib.admin import ModelAdmin from vote.models import Teacher, Subject class SubjectModelAdmin(ModelAdmin): \"\"\"学科模型管理\"\"\" list_display = ('no', 'name') ordering = ('no', ) class TeacherModelAdmin(ModelAdmin): \"\"\"老师模型管理\"\"\" list_display = ('no', 'name', 'gender', 'birth', 'good_count', 'bad_count', 'subject') ordering = ('no', ) search_fields = ('name', ) admin.site.register(Subject, SubjectModelAdmin) admin.site.register(Teacher, TeacherModelAdmin) 接下来，我们就可以修改views.py文件，通过编写视图函数先实现“学科介绍”页面。 def show_subjects(request): \"\"\"查看所有学科\"\"\" subjects = Subject.objects.all() return render(request, 'subject.html', {'subjects': subjects}) 至此，我们还需要一个模板页，模板的配置以及模板页中模板语言的用法在之前已经进行过简要的介绍，如果不熟悉可以看看下面的代码，相信这并不是一件困难的事情。 学科信息 /* 此处略去了层叠样式表的选择器 */ 千锋互联所有学科信息 { % for subject in subjects % } { { subject.name } } { { subject.intro } } { % endfor % } 在上面的模板中，我们为每个学科添加了一个超链接，点击超链接可以查看该学科的讲师信息，为此需要再编写一个视图函数来处理查看指定学科老师信息。 def show_teachers(request): \"\"\"查看指定学科的老师\"\"\" try: sno = int(request.GET['sno']) subject = Subject.objects.get(no=sno) teachers = Teacher.objects.filter(subject__no=sno) context = {'subject': subject, 'teachers': teachers} return render(request, 'teacher.html', context) except (KeyError, ValueError, Subject.DoesNotExist): return redirect('/') 显示老师信息的模板页。 { % load static % } 老师信息 /* 此处略去了层叠样式表的选择器 */ { { subject.name } }学科老师信息 { % if teachers % } { % for teacher in teachers % } 姓名：{ { teacher.name } } 性别：{ { teacher.gender | yesno:'男,女' } } 出生日期：{ { teacher.birth } } { { teacher.intro } } 好评（{ { teacher.good_count } }） 差评（{ { teacher.bad_count } }） { % endfor % } { % else % } 暂时没有该学科的老师信息 { % endif % } &lt;&lt;&nbsp;返回学科 加载静态资源 在上面的模板页面中，我们使用了标签来加载老师的照片，其中使用了引用静态资源的模板指令{ % static % }，要使用该指令，首先要使用{ % load static % }指令来加载静态资源，我们将这段代码放在了页码开始的位置。在上面的项目中，我们将静态资源置于名为static的文件夹中，在该文件夹下又创建了三个文件夹：css、js和images，分别用来保存外部层叠样式表、外部JavaScript文件和图片资源。为了能够找到保存静态资源的文件夹，我们还需要修改Django项目的配置文件settings.py，如下所示： # 此处省略上面的代码 STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static'), ] STATIC_URL = '/static/' # 此处省略下面的代码 接下来修改urls.py文件，配置用户请求的URL和视图函数的对应关系。 from django.contrib import admin from django.urls import path from vote import views urlpatterns = [ path('', views.show_subjects), path('teachers/', views.show_teachers), path('admin/', admin.site.urls), ] 启动服务器运行项目，进入首页查看学科信息。 点击学科查看老师信息。 Ajax请求 接下来就可以实现“好评”和“差评”的功能了，很明显如果能够在不刷新页面的情况下实现这两个功能会带来更好的用户体验，因此我们考虑使用Ajax技术来实现“好评”和“差评”，Ajax技术我们在之前的章节中已经介绍过了，此处不再赘述。 首先修改项目的urls.py文件，为“好评”和“差评”功能映射对应的URL。 from django.contrib import admin from django.urls import path from vote import views urlpatterns = [ path('', views.show_subjects), path('teachers/', views.show_teachers), path('praise/', views.prise_or_criticize), path('criticize/', views.prise_or_criticize), path('admin/', admin.site.urls), ] 设计视图函数praise_or_criticize来支持“好评”和“差评”功能，该视图函数通过Django封装的JsonResponse类将字典序列化成JSON字符串作为返回给浏览器的响应内容。 def praise_or_criticize(request): \"\"\"好评\"\"\" try: tno = int(request.GET['tno']) teacher = Teacher.objects.get(no=tno) if request.path.startswith('/prise'): teacher.good_count += 1 else: teacher.bad_count += 1 teacher.save() data = {'code': 200, 'hint': '操作成功'} except (KeyError, ValueError, Teacher.DoseNotExist): data = {'code': 404, 'hint': '操作失败'} return JsonResponse(data) 修改显示老师信息的模板页，引入jQuery库来实现事件处理、Ajax请求和DOM操作。 $(() => { $('.comment>a').on('click', (evt) => { evt.preventDefault(); let a = $(evt.target) let span = a.next() $.getJSON(a.attr('href'), (json) => { if (json.code == 200) { span.text(parseInt(span.text()) + 1) } else { alert(json.hint) } }) }) }) 小结 到此为止，这个投票项目的核心功能已然完成，在下面的章节中我们会要求用户必须登录才能投票，没有账号的用户可以通过注册功能注册一个账号。 "},"Python/第三方库/Django/04-Django模板系统.html":{"url":"Python/第三方库/Django/04-Django模板系统.html","title":"Django模板系统","keywords":"","body":"datetime:2019/6/10 15:35 author:nzb Django模板系统 官方文档 常见语法 只需要记两种特殊符号： { { } }和 { % % } 变量相关的用{ {} }，逻辑相关的用{ %% }。 变量 在Django的模板语言中按此语法使用：{ { 变量名 } }。 当模版引擎遇到一个变量，它将计算这个变量，然后用结果替换掉它本身。 变量的命名包括任何字母数字以及下划线 (\"_\")的组合。 变量名称中不能有空格或标点符号。 点（.）在模板语言中有特殊的含义。当模版系统遇到点(\".\")，它将以这样的顺序查询： 字典查询（Dictionary lookup） 属性或方法查询（Attribute or method lookup） 数字索引查询（Numeric index lookup） 注意事项： 如果计算结果的值是可调用的，它将被无参数的调用。 调用的结果将成为模版的值。 如果使用的变量不存在， 模版系统将插入 string_if_invalid 选项的值， 它被默认设置为'' (空字符串) 。 # 几个例子： # view中代码： def template_test(request): l = [11, 22, 33] d = {\"name\": \"alex\"} class Person(object): def __init__(self, name, age): self.name = name self.age = age def dream(self): return \"{} is dream...\".format(self.name) Alex = Person(name=\"Alex\", age=34) Egon = Person(name=\"Egon\", age=9000) Eva_J = Person(name=\"Eva_J\", age=18) person_list = [Alex, Egon, Eva_J] return render(request, \"template_test.html\", {\"l\": l, \"d\": d, \"person_list\": person_list}) # 模板中支持的写法： {# 取l中的第一个参数 #} { { l.0 } } {# 取字典中key的值 #} { { d.name } } {# 取对象的name属性 #} { { person_list.0.name } } {# .操作只能调用不带参数的方法 #} { { person_list.0.dream } } Filters(过滤器) 在Django的模板语言中，通过使用 过滤器 来改变变量的显示。 过滤器的语法： { { value|filter_name:参数 } } 使用管道符\"|\"来应用过滤器。 例如：{ { name|lower } }会将name变量应用lower过滤器之后再显示它的值。lower在这里的作用是将文本全都变成小写。 注意事项： 过滤器支持“链式”操作。即一个过滤器的输出作为另一个过滤器的输入。 过滤器可以接受参数，例如：{ { sss|truncatewords:30 } }，这将显示sss的前30个词。 过滤器参数包含空格的话，必须用引号包裹起来。比如使用逗号和空格去连接一个列表中的元素，如：{ { list|join:', ' } } '|'左右没有空格没有空格没有空格 Django的模板语言中提供了大约六十个内置过滤器。 default 如果一个变量是false或者为空，使用给定的默认值。 否则，使用变量的值。 { { value|default:\"nothing\"} } length 返回值的长度，作用于字符串和列表。 { { value|length } } 返回value的长度，如 value=['a', 'b', 'c', 'd']的话，就显示4. filesizeformat 将值格式化为一个 “人类可读的” 文件尺寸 （例如 '13 KB', '4.1 MB', '102 bytes', 等等）。例如： { { value|filesizeformat } } 如果 value 是 123456789，输出将会是 117.7 MB。 slice 切片 { {value|slice:\"2:-1\"} } date 格式化 { { value|date:\"Y-m-d H:i:s\"} } 可用的参数： 格式化字符 描述 示例输出 a 'a.m.'或'p.m.'（请注意，这与PHP的输出略有不同，因为这包括符合Associated Press风格的期间） 'a.m.' A 'AM'或'PM'。 'AM' b 月，文字，3个字母，小写。 'jan' B 未实现。 c ISO 8601格式。 （注意：与其他格式化程序不同，例如“Z”，“O”或“r”，如果值为naive datetime，则“c”格式化程序不会添加时区偏移量（请参阅datetime.tzinfo） 。 2008-01-02T10:30:00.000123+02:00或2008-01-02T10:30:00.000123如果datetime是天真的 d 月的日子，带前导零的2位数字。 '01'到'31' D 一周中的文字，3个字母。 “星期五” e 时区名称 可能是任何格式，或者可能返回一个空字符串，具体取决于datetime。 ''、'GMT'、'-500'、'US/Eastern'等 E 月份，特定地区的替代表示通常用于长日期表示。 'listopada'（对于波兰语区域，而不是'Listopad'） f 时间，在12小时的小时和分钟内，如果它们为零，则分钟停留。 专有扩展。 '1'，'1:30' F 月，文，长。 '一月' g 小时，12小时格式，无前导零。 '1'到'12' G 小时，24小时格式，无前导零。 '0'到'23' h 小时，12小时格式。 '01'到'12' H 小时，24小时格式。 '00'到'23' i 分钟。 '00'到'59' I 夏令时间，无论是否生效。 '1'或'0' j 没有前导零的月份的日子。 '1'到'31' l 星期几，文字长。 '星期五' L 布尔值是否是一个闰年。 True或False m 月，2位数字带前导零。 '01'到'12' M 月，文字，3个字母。 “扬” n 月无前导零。 '1'到'12' N 美联社风格的月份缩写。 专有扩展。 'Jan.'，'Feb.'，'March'，'May' o ISO-8601周编号，对应于使用闰年的ISO-8601周数（W）。 对于更常见的年份格式，请参见Y。 '1999年' O 与格林威治时间的差异在几小时内。 '+0200' P 时间为12小时，分钟和'a.m。'/'p.m。'，如果为零，分钟停留，特殊情况下的字符串“午夜”和“中午”。 专有扩展。 '1 am'，'1:30 pm' / t3>，'midnight'，'noon'，'12：30 pm' / T10> r RFC 5322格式化日期。 'Thu, 21 Dec 2000 16:01:07 +0200' s 秒，带前导零的2位数字。 '00'到'59' S 一个月的英文序数后缀，2个字符。 'st'，'nd'，'rd'或'th' t 给定月份的天数。 28 to 31 T 本机的时区。 'EST'，'MDT' u 微秒。 000000 to 999999 U 自Unix Epoch以来的二分之一（1970年1月1日00:00:00 UTC）。 w 星期几，数字无前导零。 '0'（星期日）至'6'（星期六） W ISO-8601周数，周数从星期一开始。 1，53 y 年份，2位数字。 '99' Y 年，4位数。 '1999年' z 一年中的日子 0到365 Z 时区偏移量，单位为秒。 UTC以西时区的偏移量总是为负数，对于UTC以东时，它们总是为正。 -43200到43200 safe Django的模板中会对HTML标签和JS等语法标签进行自动转义，原因显而易见，这样是为了安全。但是有的时候我们可能不希望这些HTML元素被转义，比如我们做一个内容管理系统，后台添加的文章中是经过修饰的，这些修饰可能是通过一个类似于FCKeditor编辑加注了HTML修饰符的文本，如果自动转义的话显示的就是保护HTML标签的源文件。为了在Django中关闭HTML的自动转义有两种方式，如果是一个单独的变量我们可以通过过滤器“|safe”的方式告诉Django这段代码是安全的不必转义。 比如： value = \"点我\" { { value|safe} } truncatechars 如果字符串字符多于指定的字符数量，那么会被截断。截断的字符串将以可翻译的省略号序列（“...”）结尾。 参数：截断的字符数 { { value|truncatechars:9} } truncatewords 在一定数量的字后截断字符串。 { { value|truncatewords:9} } cut 移除value中所有的与给出的变量相同的字符串 { { value|cut:' ' } } 如果value为'i love you'，那么将输出'iloveyou'. join 使用字符串连接列表，例如Python的str.join(list) timesince 将日期格式设为自该日期起的时间（例如，“4天，6小时”）。 采用一个可选参数，它是一个包含用作比较点的日期的变量（不带参数，比较点为现在）。 例如，如果blog_date是表示2006年6月1日午夜的日期实例，并且comment_date是2006年6月1日08:00的日期实例，则以下将返回“8小时”： { { blog_date|timesince:comment_date } } 分钟是所使用的最小单位，对于相对于比较点的未来的任何日期，将返回“0分钟”。 timeuntil 似于timesince，除了它测量从现在开始直到给定日期或日期时间的时间。 例如，如果今天是2006年6月1日，而conference_date是保留2006年6月29日的日期实例，则{ { conference_date | timeuntil } }将返回“4周”。 使用可选参数，它是一个包含用作比较点的日期（而不是现在）的变量。 如果from_date包含2006年6月22日，则以下内容将返回“1周”： { { conference_date|timeuntil:from_date } } 自定义filter 自定义过滤器只是带有一个或两个参数的Python函数: 变量（输入）的值 - -不一定是一个字符串 参数的值 - 这可以有一个默认值，或完全省略 例如，在过滤器{ {var | foo:'bar'} }中，过滤器foo将传递变量var和参数“bar”。 自定义filter代码文件摆放位置： app01/ __init__.py models.py templatetags/ # 在app01下面新建一个package package __init__.py app01_filters.py # 建一个存放自定义filter的文件 views.py 编写自定义filter: from django import template register = template.Library() @register.filter(name=\"cut\") def cut(value, arg): return value.replace(arg, \"\") @register.filter(name=\"addSB\") def add_sb(value): return \"{} SB\".format(value) 使用自定义filter: {# 先导入我们自定义filter那个文件 #} { % load app01_filters % } {# 使用我们自定义的filter #} { { somevariable|cut:\"0\" } } { { d.name|addSB } } Tags for循环 普通for循环 { % for user in user_list % } { { user.name } } { % endfor % } for循环可用的一些参数： Variable Description forloop.counter 当前循环的索引值（从1开始） forloop.counter0 当前循环的索引值（从0开始） forloop.revcounter 当前循环的倒序索引值（从1开始） forloop.revcounter0 当前循环的倒序索引值（从0开始） forloop.first 当前循环是不是第一次循环（布尔值） forloop.last 当前循环是不是最后一次循环（布尔值） forloop.parentloop 本层循环的外层循环 for ... empty { % for user in user_list % } { { user.name } } { % empty % } 空空如也 { % endfor % } if判断 if,elif和else { % if user_list % } 用户人数：{ { user_list|length } } { % elif black_list % } 黑名单数：{ { black_list|length } } { % else % } 没有用户 { % endif % } 当然也可以只有if和else { % if user_list|length > 5 % } 七座豪华SUV { % else % } 黄包车 { % endif % } if语句支持 and 、or、==、>、=、in、not in、is、is not判断。 with 定义一个中间变量，多用于给一个复杂的变量起别名。 注意等号左右不要加空格。 { % with total=business.employees.count % } { { total } } employee{ { total|pluralize } } { % endwith % } 或 { % with business.employees.count as total % } { { total } } employee{ { total|pluralize } } { % endwith % } csrf_token 这个标签用于跨站请求伪造保护。 在页面的form表单里面写上{ % csrf_token % } 注释 {# ... #} 注意事项 Django的模板语言不支持连续判断，即不支持以下写法： { % if a > b > c % } ... { % endif % } Django的模板语言中属性的优先级大于方法 def xx(request): d = {\"a\": 1, \"b\": 2, \"c\": 3, \"items\": \"100\"} return render(request, \"xx.html\", {\"data\": d}) 如上，我们在使用render方法渲染一个页面的时候，传的字典d有一个key是items并且还有默认的 d.items() 方法，此时在模板语言中: { { data.items } } 默认会取d的items key的值。 母版 Title { % block page-css % } { % endblock % } 这是母板的标题 { % block page-main % } { % endblock % } 母板底部内容 { % block page-js % } { % endblock % } 继承母版 在子页面中在页面最上方使用下面的语法来继承母板。 { % extends 'layouts.html' % } 块(block) 通过在母板中使用{ % block xxx % }来定义\"块\"。 在子页面中通过定义母板中的block名来对应替换母板中相应的内容。 { % block page-main % } 世情薄 人情恶 雨送黄昏花易落 { % endblock % } 组件 可以将常用的页面内容如导航条，页尾信息等组件保存在单独的文件中，然后在需要使用的地方按如下语法导入即可。 { % include 'navbar.html' % } 静态文件相关 { % static % } { % load static % } 引用JS文件时使用： { % load static % } 某个文件多处被用到可以存为一个变量 { % load static % } { % static \"images/hi.jpg\" as myphoto % } { % get_static_prefix % } { % load static % } 或者 { % load static % } { % get_static_prefix as STATIC_PREFIX % } simple_tag 和自定义filter类似，只不过接收更灵活的参数。 定义注册simple tag @register.simple_tag(name=\"plus\") def plus(a, b, c): return \"{} + {} + {}\".format(a, b, c) 使用自定义simple tag { % load app01_demo % } {# simple tag #} { % plus \"1\" \"2\" \"abc\" % } inclusion_tag 多用于返回html代码片段 示例： templatetags/my_inclusion.py from django import template register = template.Library() @register.inclusion_tag('result.html') def show_results(n): n = 1 if n templates/snippets/result.html { % for choice in data % } { { choice } } { % endfor % } templates/index.html inclusion_tag test { % load inclusion_tag_test % } { % show_results 10 % } 模板中或序列化中choice类型字段的值 模板中 { { obj.get_column_display } } 序列化中 column = serializers.CharField(source='get_column_display') "},"Python/第三方库/Django/05-Django的View.html":{"url":"Python/第三方库/Django/05-Django的View.html","title":"Django的View(视图)","keywords":"","body":"datetime:2019/6/11 11:10 author:nzb Django的View(视图) 一个视图函数（类），简称视图，是一个简单的Python 函数（类），它接受Web请求并且返回Web响应。 响应可以是一张网页的HTML内容，一个重定向，一个404错误，一个XML文档，或者一张图片。 无论视图本身包含什么逻辑，都要返回响应。代码写在哪里也无所谓，只要它在你当前项目目录下面。 除此之外没有更多的要求了——可以说“没有什么神奇的地方”。为了将代码放在某处，大家约定成俗将视图放置在项目（project）或应用程序（app）目录中的名为views.py的文件中。 一个简单的视图 # 下面是一个以HTML文档的形式返回当前日期和时间的视图： from django.http import HttpResponse import datetime def current_datetime(request): now = datetime.datetime.now() html = \"It is now %s.\" % now return HttpResponse(html) 让我们来逐行解释下上面的代码： 首先，我们从 django.http模块导入了HttpResponse类，以及Python的datetime库。 接着，我们定义了current_datetime函数。它就是视图函数。每个视图函数都使用HttpRequest对象作为第一个参数，并且通常称之为request。 注意，视图函数的名称并不重要；不需要用一个统一的命名方式来命名，以便让Django识别它。我们将其命名为current_datetime，是因为这个名称能够比较准确地反映出它实现的功能。 这个视图会返回一个HttpResponse对象，其中包含生成的响应。每个视图函数都负责返回一个HttpResponse对象。 Django使用请求和响应对象来通过系统传递状态。 当浏览器向服务端请求一个页面时，Django创建一个HttpRequest对象，该对象包含关于请求的元数据。然后，Django加载相应的视图，将这个HttpRequest对象作为第一个参数传递给视图函数。 每个视图负责返回一个HttpResponse对象。 CBV和FBV 我们之前写过的都是基于函数的view，就叫FBV。还可以把view写成基于类的。 就拿我们之前写过的添加班级为例： FBV版 # FBV版添加班级 def add_class(request): if request.method == \"POST\": class_name = request.POST.get(\"class_name\") models.Classes.objects.create(name=class_name) return redirect(\"/class_list/\") return render(request, \"add_class.html\") CBV版 # CBV版添加班级 from django.views import View class AddClass(View): def get(self, request): return render(request, \"add_class.html\") def post(self, request): class_name = request.POST.get(\"class_name\") models.Classes.objects.create(name=class_name) return redirect(\"/class_list/\") # 注意： # 使用CBV时，urls.py中也做对应的修改： # urls.py中 url(r'^add_class/$', views.AddClass.as_view()), 给视图加装饰器 使用装饰器装饰FBV # FBV本身就是一个函数，所以和给普通的函数加装饰器无差： def wrapper(func): def inner(*args, **kwargs): start_time = time.time() ret = func(*args, **kwargs) end_time = time.time() print(\"used:\", end_time-start_time) return ret return inner # FBV版添加班级 @wrapper def add_class(request): if request.method == \"POST\": class_name = request.POST.get(\"class_name\") models.Classes.objects.create(name=class_name) return redirect(\"/class_list/\") return render(request, \"add_class.html\") 使用装饰器装饰CBV # 类中的方法与独立函数不完全相同，因此不能直接将函数装饰器应用于类中的方法 ，我们需要先将其转换为方法装饰器。 # Django中提供了method_decorator装饰器用于将函数装饰器转换为方法装饰器。 # CBV版添加班级 from django.views import View from django.utils.decorators import method_decorator class AddClass(View): @method_decorator(wrapper) def get(self, request): return render(request, \"add_class.html\") def post(self, request): class_name = request.POST.get(\"class_name\") models.Classes.objects.create(name=class_name) return redirect(\"/class_list/\") # 使用CBV时要注意，请求过来后会先执行dispatch()这个方法，如果需要批量对具体的请求处理方法，如get，post等做一些操作的时候，这里我们可以手动改写dispatch方法，这个dispatch方法就和在FBV上加装饰器的效果一样。 class Login(View): def dispatch(self, request, *args, **kwargs): print('before') obj = super(Login,self).dispatch(request, *args, **kwargs) print('after') return obj def get(self,request): return render(request,'login.html') def post(self,request): print(request.POST.get('user')) return HttpResponse('Login.post') Request对象和Response对象 request对象 当一个页面被请求时，Django就会创建一个包含本次请求原信息的HttpRequest对象。 Django会将这个对象自动传递给响应的视图函数，一般视图函数约定俗成地使用 request 参数承接这个对象。 官方文档 请求相关的常用值 path_info 返回用户访问url，不包括域名 method 请求中使用的HTTP方法的字符串表示，全大写表示。 GET 包含所有HTTP GET参数的类字典对象 POST 包含所有HTTP POST参数的类字典对象 body 请求体，byte类型 request.POST的数据就是从body里面提取到的 属性 所有的属性应该被认为是只读的，除非另有说明。 属性： 　　django将请求报文中的请求行、头部信息、内容主体封装成 HttpRequest 类中的属性。 除了特殊说明的之外，其他均为只读的。 0. HttpRequest.scheme 表示请求方案的字符串（通常为http或https） 1. HttpRequest.body 　　一个字符串，代表请求报文的主体。在处理非 HTTP 形式的报文时非常有用，例如：二进制图片、XML,Json等。 　　但是，如果要处理表单数据的时候，推荐还是使用 HttpRequest.POST 。 　　另外，我们还可以用 python 的类文件方法去操作它，详情参考 HttpRequest.read() 。 2. HttpRequest.path 　　一个字符串，表示请求的路径组件（不含域名）。 　　例如：\"/music/bands/the_beatles/\" 3. HttpRequest.method 　　一个字符串，表示请求使用的HTTP 方法。必须使用大写。 　　例如：\"GET\"、\"POST\" 4. HttpRequest.encoding 　　一个字符串，表示提交的数据的编码方式（如果为 None 则表示使用 DEFAULT_CHARSET 的设置，默认为 'utf-8'）。 这个属性是可写的，你可以修改它来修改访问表单数据使用的编码。 接下来对属性的任何访问（例如从 GET 或 POST 中读取数据）将使用新的 encoding 值。 如果你知道表单数据的编码不是 DEFAULT_CHARSET ，则使用它。 5. HttpRequest.GET 　　一个类似于字典的对象，包含 HTTP GET 的所有参数。详情请参考 QueryDict 对象。 6. HttpRequest.POST 　　一个类似于字典的对象，如果请求中包含表单数据，则将这些数据封装成 QueryDict 对象。 　　POST 请求可以带有空的 POST 字典 —— 如果通过 HTTP POST 方法发送一个表单，但是表单中没有任何的数据，QueryDict 对象依然会被创建。 因此，不应该使用 if request.POST 来检查使用的是否是POST 方法；应该使用 if request.method == \"POST\" 　　另外：如果使用 POST 上传文件的话，文件信息将包含在 FILES 属性中。 7. HttpRequest.COOKIES 　　一个标准的Python 字典，包含所有的cookie。键和值都为字符串。 8. HttpRequest.FILES 　　一个类似于字典的对象，包含所有的上传文件信息。 FILES 中的每个键为 中的name，值则为对应的数据。 　　注意，FILES 只有在请求的方法为POST 且提交的 带有enctype=\"multipart/form-data\" 的情况下才会 包含数据。否则，FILES 将为一个空的类似于字典的对象。 9. HttpRequest.META 　　一个标准的Python 字典，包含所有的HTTP 首部。具体的头部信息取决于客户端和服务器，下面是一些示例： CONTENT_LENGTH —— 请求的正文的长度（是一个字符串）。 CONTENT_TYPE —— 请求的正文的MIME 类型。 HTTP_ACCEPT —— 响应可接收的Content-Type。 HTTP_ACCEPT_ENCODING —— 响应可接收的编码。 HTTP_ACCEPT_LANGUAGE —— 响应可接收的语言。 HTTP_HOST —— 客服端发送的HTTP Host 头部。 HTTP_REFERER —— Referring 页面。 HTTP_USER_AGENT —— 客户端的user-agent 字符串。 QUERY_STRING —— 单个字符串形式的查询字符串（未解析过的形式）。 REMOTE_ADDR —— 客户端的IP 地址。 REMOTE_HOST —— 客户端的主机名。 REMOTE_USER —— 服务器认证后的用户。 REQUEST_METHOD —— 一个字符串，例如\"GET\" 或\"POST\"。 SERVER_NAME —— 服务器的主机名。 SERVER_PORT —— 服务器的端口（是一个字符串）。 　　从上面可以看到，除 CONTENT_LENGTH 和 CONTENT_TYPE 之外，请求中的任何 HTTP 首部转换为 META 的键时， 都会将所有字母大写并将连接符替换为下划线最后加上 HTTP_ 前缀。 所以，一个叫做 X-Bender 的头部将转换成 META 中的 HTTP_X_BENDER 键。 10. HttpRequest.user 　　一个 AUTH_USER_MODEL 类型的对象，表示当前登录的用户。 　　如果用户当前没有登录，user 将设置为 django.contrib.auth.models.AnonymousUser 的一个实例。你可以通过 is_authenticated() 区分它们。 例如： if request.user.is_authenticated(): # Do something for logged-in users. else: # Do something for anonymous users. 　　user 只有当Django 启用 AuthenticationMiddleware 中间件时才可用。 ------------------------------------------------------------------------------------- 匿名用户 class models.AnonymousUser django.contrib.auth.models.AnonymousUser 类实现了django.contrib.auth.models.User 接口，但具有下面几个不同点： id 永远为None。 username 永远为空字符串。 get_username() 永远返回空字符串。 is_staff 和 is_superuser 永远为False。 is_active 永远为 False。 groups 和 user_permissions 永远为空。 is_anonymous() 返回True 而不是False。 is_authenticated() 返回False 而不是True。 set_password()、check_password()、save() 和delete() 引发 NotImplementedError。 New in Django 1.8: 新增 AnonymousUser.get_username() 以更好地模拟 django.contrib.auth.models.User。 11. HttpRequest.session 　　一个既可读又可写的类似于字典的对象，表示当前的会话。只有当Django 启用会话的支持时才可用。 完整的细节参见会话的文档。 request属性相关 上传文件示例 def upload(request): \"\"\" 保存上传文件前，数据需要存放在某个位置。默认当上传文件小于2.5M时，django会将上传文件的全部内容读进内存。从内存读取一次，写磁盘一次。 但当上传文件很大时，django会把上传文件写到临时文件中，然后存放到系统临时文件夹中。 :param request: :return: \"\"\" if request.method == \"POST\": # 从请求的FILES中获取上传文件的文件名，file为页面上type=files类型input的name属性值 filename = request.FILES[\"file\"].name # 在项目目录下新建一个文件 with open(filename, \"wb\") as f: # 从上传的文件对象中一点一点读 for chunk in request.FILES[\"file\"].chunks(): # 写入本地文件 f.write(chunk) return HttpResponse(\"上传OK\") 方法 1.HttpRequest.get_host() 　　根据从HTTP_X_FORWARDED_HOST（如果打开 USE_X_FORWARDED_HOST，默认为False）和 HTTP_HOST 头部信息返回请求的原始主机。 如果这两个头部没有提供相应的值，则使用SERVER_NAME 和SERVER_PORT，在PEP 3333 中有详细描述。 　　USE_X_FORWARDED_HOST：一个布尔值，用于指定是否优先使用 X-Forwarded-Host 首部，仅在代理设置了该首部的情况下，才可以被使用。 　　例如：\"127.0.0.1:8000\" 　　注意：当主机位于多个代理后面时，get_host() 方法将会失败。除非使用中间件重写代理的首部。 2.HttpRequest.get_full_path() 　　返回 path，如果可以将加上查询字符串。 　　例如：\"/music/bands/the_beatles/?print=true\" 3.HttpRequest.get_signed_cookie(key, default=RAISE_ERROR, salt='', max_age=None) 　　返回签名过的Cookie 对应的值，如果签名不再合法则返回django.core.signing.BadSignature。 　　如果提供 default 参数，将不会引发异常并返回 default 的值。 　　可选参数salt 可以用来对安全密钥强力攻击提供额外的保护。max_age 参数用于检查Cookie 对应的时间戳以确保Cookie 的时间不会超过max_age 秒。 复制代码 >>> request.get_signed_cookie('name') 'Tony' >>> request.get_signed_cookie('name', salt='name-salt') 'Tony' # 假设在设置cookie的时候使用的是相同的salt >>> request.get_signed_cookie('non-existing-cookie') ... KeyError: 'non-existing-cookie' # 没有相应的键时触发异常 >>> request.get_signed_cookie('non-existing-cookie', False) False >>> request.get_signed_cookie('cookie-that-was-tampered-with') ... BadSignature: ... >>> request.get_signed_cookie('name', max_age=60) ... SignatureExpired: Signature age 1677.3839159 > 60 seconds >>> request.get_signed_cookie('name', False, max_age=60) False 复制代码 4.HttpRequest.is_secure() 　　如果请求时是安全的，则返回True；即请求通是过 HTTPS 发起的。 5.HttpRequest.is_ajax() 　　如果请求是通过XMLHttpRequest 发起的，则返回True，方法是检查 HTTP_X_REQUESTED_WITH 相应的首部是否是字符串'XMLHttpRequest'。 　　大部分现代的 JavaScript 库都会发送这个头部。如果你编写自己的 XMLHttpRequest 调用（在浏览器端），你必须手工设置这个值来让 is_ajax() 可以工作。 　　如果一个响应需要根据请求是否是通过AJAX 发起的，并且你正在使用某种形式的缓存例如Django 的 cache middleware， 你应该使用 vary_on_headers('HTTP_X_REQUESTED_WITH') 装饰你的视图以让响应能够正确地缓存。 注意：键值对的值是多个的时候,比如checkbox类型的input标签，select标签，需要用： request.POST.getlist(\"hobby\") Response对象 与由Django自动创建的HttpRequest对象相比，HttpResponse对象是我们的职责范围了。我们写的每个视图都需要实例化，填充和返回一个HttpResponse。 HttpResponse类位于django.http模块中。 使用 传递字符串 from django.http import HttpResponse response = HttpResponse(\"Here's the text of the Web page.\") response = HttpResponse(\"Text only, please.\", content_type=\"text/plain\") 设置或删除响应头信息 response = HttpResponse() response['Content-Type'] = 'text/html; charset=UTF-8' del response['Content-Type'] 属性 HttpResponse.content：响应内容 HttpResponse.charset：响应内容的编码 HttpResponse.status_code：响应的状态码 JsonResponse对象 JsonResponse是HttpResponse的子类，专门用来生成JSON编码的响应。 from django.http import JsonResponse response = JsonResponse({'foo': 'bar'}) print(response.content) b'{\"foo\": \"bar\"}' 默认只能传递字典类型，如果要传递非字典类型需要设置一下safe关键字参数。 response = JsonResponse([1, 2, 3], safe=False) Django shortcut functions 官方文档 render() 结合一个给定的模板和一个给定的上下文字典，并返回一个渲染后的 HttpResponse 对象。 参数： request： 用于生成响应的请求对象。 template_name：要使用的模板的完整名称，可选的参数 context：添加到模板上下文的一个字典。默认是一个空字典。如果字典中的某个值是可调用的，视图将在渲染模板之前调用它。 content_type：生成的文档要使用的MIME类型。默认为 DEFAULT_CONTENT_TYPE 设置的值。默认为'text/html' status：响应的状态码。默认为200。 　　　useing: 用于加载模板的模板引擎的名称。 一个简单的例子： from django.shortcuts import render def my_view(request): # 视图的代码写在这里 return render(request, 'myapp/index.html', {'foo': 'bar'}) 上面的代码等于： from django.http import HttpResponse from django.template import loader def my_view(request): # 视图代码写在这里 t = loader.get_template('myapp/index.html') c = {'foo': 'bar'} return HttpResponse(t.render(c, request)) redirect() 参数可以是： 一个模型：将调用模型的get_absolute_url() 函数 一个视图，可以带有参数：将使用urlresolvers.reverse 来反向解析名称 一个绝对的或相对的URL，将原封不动的作为重定向的位置。 默认返回一个临时的重定向；传递permanent=True 可以返回一个永久的重定向。 示例: 你可以用多种方式使用redirect() 函数。 传递一个具体的ORM对象（了解即可） 将调用具体ORM对象的get_absolute_url() 方法来获取重定向的URL： from django.shortcuts import redirect def my_view(request): ... object = MyModel.objects.get(...) return redirect(object) 传递一个视图的名称 def my_view(request): ... return redirect('some-view-name', foo='bar') 传递要重定向到的一个具体的网址 def my_view(request): ... return redirect('/some/url/') 当然也可以是一个完整的网址 def my_view(request): ... return redirect('http://example.com/') 默认情况下，redirect() 返回一个临时重定向。以上所有的形式都接收一个permanent 参数；如果设置为True，将返回一个永久的重定向： def my_view(request): ... object = MyModel.objects.get(...) return redirect(object, permanent=True) 扩展阅读： 临时重定向（响应状态码：302）和永久重定向（响应状态码：301）对普通用户来说是没什么区别的，它主要面向的是搜索引擎的机器人。 A页面临时重定向到B页面，那搜索引擎收录的就是A页面。 A页面永久重定向到B页面，那搜索引擎收录的就是B页面。 "},"Python/第三方库/Django/06-Django的路由系统.html":{"url":"Python/第三方库/Django/06-Django的路由系统.html","title":"Django的路由系统","keywords":"","body":"datetime:2019/6/11 16:27 author:nzb Django的路由系统 Django 1.11版本 URLConf官方文档 URL配置(URLconf)就像Django 所支撑网站的目录。它的本质是URL与要为该URL调用的视图函数之间的映射表。 你就是以这种方式告诉Django，对于这个URL调用这段代码，对于那个URL调用那段代码。 URLconfs配置 基本格式 from django.conf.urls import url urlpatterns = [ url(正则表达式, views视图函数，参数，别名), ] 注意： Django 2.0版本中的路由系统已经替换成下面的写法(官方文档)： from django.urls import path urlpatterns = [ path('articles/2003/', views.special_case_2003), path('articles//', views.year_archive), path('articles///', views.month_archive), path('articles////', views.article_detail), ] 参数说明 正则表达式：一个正则表达式字符串 views视图函数：一个可调用对象，通常为一个视图函数或一个指定视图函数路径的字符串 参数：可选的要传递给视图函数的默认参数（字典形式） 别名：一个可选的name参数 正则表达式详解 基本配置 from django.conf.urls import url from . import views urlpatterns = [ url(r'^articles/2003/$', views.special_case_2003), url(r'^articles/([0-9]{4})/$', views.year_archive), url(r'^articles/([0-9]{4})/([0-9]{2})/$', views.month_archive), url(r'^articles/([0-9]{4})/([0-9]{2})/([0-9]+)/$', views.article_detail), ] 注意事项 urlpatterns中的元素按照书写顺序从上往下逐一匹配正则表达式，一旦匹配成功则不再继续。 若要从URL中捕获一个值，只需要在它周围放置一对圆括号（分组匹配）。 不需要添加一个前导的反斜杠，因为每个URL 都有。例如，应该是^articles 而不是 ^/articles。 每个正则表达式前面的'r' 是可选的但是建议加上。 补充说明 是否开启URL访问地址后面不为/跳转至带有/的路径的配置项 APPEND_SLASH=True Django settings.py配置文件中默认没有 APPEND_SLASH 这个参数，但 Django 默认这个参数为 APPEND_SLASH = True。 其作用就是自动在网址结尾加'/'。 其效果就是： 我们定义了urls.py： from django.conf.urls import url from app01 import views urlpatterns = [ url(r'^blog/$', views.blog), ] 访问 http://www.example.com/blog 时，默认将网址自动转换为 http://www.example/com/blog/ 。 如果在settings.py中设置了 APPEND_SLASH=False，此时我们再请求 http://www.example.com/blog 时就会提示找不到页面。 分组命名匹配 上面的示例使用简单的正则表达式分组匹配（通过圆括号）来捕获URL中的值并以位置参数形式传递给视图。 在更高级的用法中，可以使用分组命名匹配的正则表达式组来捕获URL中的值并以关键字参数形式传递给视图。 在Python的正则表达式中，分组命名正则表达式组的语法是(?Ppattern)，其中name是组的名称，pattern是要匹配的模式。 下面是以上URLconf 使用命名组的重写： from django.conf.urls import url from . import views urlpatterns = [ url(r'^articles/2003/$', views.special_case_2003), url(r'^articles/(?P[0-9]{4})/$', views.year_archive), url(r'^articles/(?P[0-9]{4})/(?P[0-9]{2})/$', views.month_archive), url(r'^articles/(?P[0-9]{4})/(?P[0-9]{2})/(?P[0-9]{2})/$', views.article_detail), ] 这个实现与前面的示例完全相同，只有一个细微的差别：捕获的值作为关键字参数而不是位置参数传递给视图函数。 例如，针对url /articles/2017/12/相当于按以下方式调用视图函数： views.month_archive(request, year=\"2017\", month=\"12\") 区别 分组匹配 --> 相当于给视图函数传递位置参数(*args) 分组命名匹配 --> 相当于给视图函数传递关键字参数(**kwargs) 例子： url(r'^articles/2003/$', views.special_case_2003), 分组匹配 url(r'^articles/(?P[0-9]{4})/$', views.year_archive), 分组命名匹配 在实际应用中，使用分组命名匹配的方式可以让你的URLconf 更加明晰且不容易产生参数顺序问题的错误，但是有些开发人员则认为分组命名组语法太丑陋、繁琐。 至于究竟应该使用哪一种，你可以根据自己的喜好来决定。 URLconf匹配的位置 URLconf 在请求的URL 上查找，将它当做一个普通的Python 字符串。不包括GET和POST参数以及域名。 例如，http://www.example.com/myapp/ 请求中，URLconf 将查找myapp/。 在http://www.example.com/myapp/?page=3 请求中，URLconf 仍将查找myapp/。 URLconf 不检查请求的方法。换句话讲，所有的请求方法 —— 同一个URL的POST、GET、HEAD等等 —— 都将路由到相同的函数。 捕获的参数永远都是字符串 每个在URLconf中捕获的参数都作为一个普通的Python字符串传递给视图，无论正则表达式使用的是什么匹配方式。例如，下面这行URLconf 中： url(r'^articles/(?P[0-9]{4})/$', views.year_archive), 传递到视图函数views.year_archive() 中的year 参数永远是一个字符串类型。 视图函数中指定默认值 urls.py中: from django.conf.urls import url from . import views urlpatterns = [ url(r'^blog/$', views.page), url(r'^blog/page(?P[0-9]+)/$', views.page), ] # views.py中，可以为num指定默认值 def page(request, num=\"1\"): pass 在上面的例子中，两个URL模式指向相同的view - views.page - 但是第一个模式并没有从URL中捕获任何东西。 如果第一个模式匹配上了，page()函数将使用其默认参数num=“1”,如果第二个模式匹配，page()将使用正则表达式捕获到的num值。 include其他的URLconfs #At any point, your urlpatterns can “include” other URLconf modules. This #essentially “roots” a set of URLs below other ones. #For example, here’s an excerpt of the URLconf for the Django website itself. #It includes a number of other URLconfs: from django.conf.urls import include, url urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^blog/', include('blog.urls')), # 可以包含其他的URLconfs文件 ] 传递额外的参数给视图函数（了解） URLconfs 具有一个钩子，让你传递一个Python 字典作为额外的参数传递给视图函数。 django.conf.urls.url() 函数可以接收一个可选的第三个参数，它是一个字典，表示想要传递给视图函数的额外关键字参数。 例如： from django.conf.urls import url from . import views urlpatterns = [ url(r'^blog/(?P[0-9]{4})/$', views.year_archive, {'foo': 'bar'}), ] 在这个例子中，对于/blog/2005/请求，Django 将调用views.year_archive(request, year='2005', foo='bar')。 这个技术在Syndication 框架中使用，来传递元数据和选项给视图。 命名URL和URL反向解析 本质就是给url匹配模式起别名，然后用别名通过reverse函数反向生成url，在HTML和视图函数中使用，就不会因为后期url的改变而出现404。 在使用Django 项目时，一个常见的需求是获得URL的最终形式，以用于嵌入到生成的内容中（视图中和显示给用户的URL等）或者用于处理服务器端的导航（重定向等）。 人们强烈希望不要硬编码这些URL（费力、不可扩展且容易产生错误）或者设计一种与URLconf 毫不相关的专门的URL 生成机制，因为这样容易导致一定程度上产生过期的URL。 换句话讲，需要的是一个DRY 机制。除了其它有点，它还允许设计的URL 可以自动更新而不用遍历项目的源代码来搜索并替换过期的URL。 获取一个URL 最开始想到的信息是处理它视图的标识（例如名字），查找正确的URL 的其它必要的信息有视图参数的类型（位置参数、关键字参数）和值。 Django 提供一个办法是让URL 映射是URL 设计唯一的地方。你填充你的URLconf，然后可以双向使用它： 根据用户/浏览器发起的URL 请求，它调用正确的Django 视图，并从URL 中提取它的参数需要的值。 根据Django 视图的标识和将要传递给它的参数的值，获取与之关联的URL。 第一种方式是我们在前面的章节中一直讨论的用法。第二种方式叫做反向解析URL、反向URL 匹配、反向URL 查询或者简单的URL 反查。 在需要URL 的地方，对于不同层级，Django 提供不同的工具用于URL 反查： 在模板中：使用url模板标签。 在Python 代码中：使用django.core.urlresolvers.reverse() 函数。 在更高层的与处理Django 模型实例相关的代码中：使用get_absolute_url() 方法。 上面说了一大堆，你可能并没有看懂。（那是官方文档的生硬翻译）。 咱们简单来说就是可以给我们的URL匹配规则起个名字，一个URL匹配模式起一个名字。 这样我们以后就不需要写死URL代码了，只需要通过名字来调用当前的URL。 举个简单的例子： url(r'^home', views.home, name='home'), # 给我的url匹配模式起名为 home url(r'^index/(\\d*)', views.index, name='index'), # 给我的url匹配模式起名为index 这样： 在模板里面可以这样引用： { % url 'home' % } 在views函数中可以这样引用： from django.urls import reverse reverse(\"index\", args=(\"2018\", )) 例子： 考虑下面的URLconf： from django.conf.urls import url from . import views urlpatterns = [ # ... url(r'^articles/([0-9]{4})/$', views.year_archive, name='news-year-archive'), # ... ] 根据这里的设计，某一年nnnn对应的归档的URL是/articles/nnnn/。 你可以在模板的代码中使用下面的方法获得它们： 2012 Archive { % for yearvar in year_list % } { { yearvar } } Archive { % endfor % } 在Python 代码中，这样使用： from django.urls import reverse from django.shortcuts import redirect def redirect_to_year(request): # ... year = 2006 # ... return redirect(reverse('news-year-archive', args=(year,))) 如果出于某种原因决定按年归档文章发布的URL应该调整一下，那么你将只需要修改URLconf 中的内容。 在某些场景中，一个视图是通用的，所以在URL 和视图之间存在多对一的关系。对于这些情况，当反查URL 时，只有视图的名字还不够。 注意： 为了完成上面例子中的URL 反查，你将需要使用命名的URL 模式。URL 的名称使用的字符串可以包含任何你喜欢的字符。不只限制在合法的Python 名称。 当命名你的URL 模式时，请确保使用的名称不会与其它应用中名称冲突。如果你的URL 模式叫做comment，而另外一个应用中也有一个同样的名称，当你在模板中使用这个名称的时候不能保证将插入哪个URL。 在URL 名称中加上一个前缀，比如应用的名称，将减少冲突的可能。我们建议使用myapp-comment 而不是comment。 命名空间模式 即使不同的APP使用相同的URL名称，URL的命名空间模式也可以让你唯一反转命名的URL。 举个例子： project中的urls.py from django.conf.urls import url, include urlpatterns = [ url(r'^app01/', include('app01.urls', namespace='app01')), url(r'^app02/', include('app02.urls', namespace='app02')), ] app01中的urls.py from django.conf.urls import url from app01 import views app_name = 'app01' urlpatterns = [ url(r'^(?P\\d+)/$', views.detail, name='detail') ] app02中的urls.py from django.conf.urls import url from app02 import views app_name = 'app02' urlpatterns = [ url(r'^(?P\\d+)/$', views.detail, name='detail') ] 现在，我的两个app中 url名称重复了，我反转URL的时候就可以通过命名空间的名称得到我当前的URL。 语法： '命名空间名称:URL名称' 模板中使用： { % url 'app01:detail' pk=12 pp=99 % } views中的函数中使用 v = reverse('app01:detail', kwargs={'pk':11}) 这样即使app中URL的命名相同，我也可以反转得到正确的URL了。 "},"Python/第三方库/Django/07-Django-ORM相关操作.html":{"url":"Python/第三方库/Django/07-Django-ORM相关操作.html","title":"Django ORM相关操作","keywords":"","body":"datetime:2019/6/12 16:47 author:nzb Django ORM相关操作 一般操作 官方文档 必知必会13条 all(): 查询所有结果 filter(**kwargs): 它包含了与所给筛选条件相匹配的对象 get(**kwargs): 返回与所给筛选条件相匹配的对象，返回结果有且只有一个，如果符合筛选条件的对象超过一个或者没有都会抛出错误。 exclude(**kwargs): 它包含了与所给筛选条件不匹配的对象 values(*field): 返回一个ValueQuerySet——一个特殊的QuerySet，运行后得到的并不是一系列model的实例化对象，而是一个可迭代的字典序列，需要哪些字段就写进去。 values_list(*field): 它与values()非常相似，它返回的是一个元组序列，values返回的是一个字典序列 order_by(*field): 对查询结果排序 reverse(): 对查询结果反向排序，请注意reverse()通常只能在具有已定义顺序的QuerySet上调用(在model类的Meta中指定ordering或调用order_by()方法)。 distinct(): 从返回结果中剔除重复纪录(如果你查询跨越多个表，可能在计算QuerySet时得到重复的结果。此时可以使用distinct()，注意只有在PostgreSQL中支持按字段去重。) count(): 返回数据库中匹配查询(QuerySet)的对象数量。 first(): 返回第一条记录 last(): 返回最后一条记录 exists(): 如果QuerySet包含数据，就返回True，否则返回False values()方法例子： 返回QuerySet对象的方法有 all() filter() exclude() order_by() reverse() distinct() 特殊QuerySet values() 返回一个可迭代的字典序列 values_list() 返回一个可迭代的元祖序列 返回具体对象的 get() first() last() 返回布尔值的方法有 exists() 返回数字的方法有 count() 单表查询之神奇的双下划线 models.Tb1.objects.filter(id__lt=10, id__gt=1) # 获取id大于1 且 小于10的值 models.Tb1.objects.filter(id__in=[11, 22, 33]) # 获取id等于11、22、33的数据 models.Tb1.objects.exclude(id__in=[11, 22, 33]) # not in models.Tb1.objects.filter(name__contains=\"ven\") # 获取name字段包含\"ven\"的 models.Tb1.objects.filter(name__icontains=\"ven\") # icontains大小写不敏感 models.Tb1.objects.filter(id__range=[1, 3]) # id范围是1到3的，等价于SQL的bettwen and 类似的还有：startswith，istartswith, endswith, iendswith　 date字段还可以： models.Class.objects.filter(first_day__year=2017) ForeignKey操作 正向查找 对象查找(跨表) 这是对对象进行操作，不能values()和values_list() 语法： 对象.关联字段.字段 示例： book_obj = models.Book.objects.first() # 第一本书对象 print(book_obj.publisher) # 得到这本书关联的出版社对象 print(book_obj.publisher.name) # 得到出版社对象的名称 字段查找(跨表) 这是对QuerySet进行操作，可以 values()和values_list() 语法： 关联字段__字段 示例： print(models.Book.objects.values_list(\"publisher__name\")) # 双下划线表示跨表 反向操作 对象查找 语法： obj.表名_set 示例： publisher_obj = models.Publisher.objects.first() # 找到第一个出版社对象 books = publisher_obj.book_set.all() # 找到第一个出版社出版的所有书 titles = books.values_list(\"title\") # 找到第一个出版社出版的所有书的书名 如果外键字段设置了：related_name：用于获取关联对象的关联管理器对象（反向查询），如果不允许反向，该属性应该被设置为'+'，或者以'+'结尾。 例子： course = models.ForeignKey(Course, verbose_name=u'课程', on_delete=models.CASCADE, related_name='course') 语法： 未设置： **obj.表名_set** 设置： **obj.course** 字段查找 语法： 表名__字段 示例： titles = models.Publisher.objects.values_list(\"book__title\") OneToOneField 当一张表的某些字段查询的比较繁琐，另外一些字段查询的不是特别繁琐，把不怎么常用的字段单独拿出来做成一张表，然后用一对一关联起来。 优势： 既保证数据能完整的保存下来，有能保证大部分的检索更快。 用法： OneToOneField(to=\"\") 例子： 作者 class Author(models.Model): name = models.CharField(max_length=12) age = models.IntegerField() phone = models.IntegerField() detail = models.OneToOneField(to=\"AuthorDetail\") def __str__(self): return self.name 作者详情 class AuthorDetail(models.Model): 爱好 hobby = models.CharField(max_length=32) 地址 addr = models.CharField(max_length=128) ManyToManyField class RelatedManager \"关联管理器\"是在一对多或者多对多的关联上下文中使用的管理器。 它存在于下面两种情况： 外键关系的反向查询 多对多关联关系 简单来说就是当 点后面的对象 可能存在多个的时候就可以使用以下的方法。 方法 create() 创建一个新的对象，保存对象，并将它添加到关联对象集之中，返回新创建的对象。 >>> import datetime >>> models.Author.objects.first().book_set.create(title=\"番茄物语\", publish_date=datetime.date.today()) add() 把指定的model对象添加到关联对象集中。 添加对象 >>> author_objs = models.Author.objects.filter(id__lt=3) >>> models.Book.objects.first().authors.add(*author_objs) 添加id >>> models.Book.objects.first().authors.add(*[1, 2]) set() 更新model对象的关联对象。 >>> book_obj = models.Book.objects.first() >>> book_obj.authors.set([2, 3]) remove() 从关联对象集中移除执行的model对象 >>> book_obj = models.Book.objects.first() >>> book_obj.authors.remove(3) clear() 从关联对象集中移除一切对象。 >>> book_obj = models.Book.objects.first() >>> book_obj.authors.clear() 注意： 对于ForeignKey对象，clear()和remove()方法仅在null=True时存在。 举个例子： ForeignKey字段没设置null=True时， class Book(models.Model): title = models.CharField(max_length=32) publisher = models.ForeignKey(to=Publisher) 没有clear()和remove()方法： >>> models.Publisher.objects.first().book_set.clear() Traceback (most recent call last): File \"\", line 1, in AttributeError: 'RelatedManager' object has no attribute 'clear' 当ForeignKey字段设置null=True时， class Book(models.Model): name = models.CharField(max_length=32) publisher = models.ForeignKey(to=Class, null=True) 此时就有clear()和remove()方法： >>> models.Publisher.objects.first().book_set.clear() 注意： 对于所有类型的关联字段，add()、create()、remove()和clear(),set()都会马上更新数据库。换句话说，在关联的任何一端，都不需要再调用save()方法。 自己创建第三张表 多对多的方式 ORM自动创建第三种表 自己创建第三张表，利用外键分别关联作者和书 关联查询比较麻烦，因为没办法使用ORM提供的便利方法 自己创建第三张表，使用ORM 的ManyToManyField() 使用此种方式创建多对多表的时候，没有add()、remove()等方法 而是直接操作第三张表 使用方法(依情况而定)： 如果你第三张表没有额外的字段，就用第一种 如果你第三张表有额外的字段，就用第三种或第一种 # 作者 class Author(models.Model): name = models.CharField(max_length=12) age = models.IntegerField() phone = models.IntegerField() # 通过through=\"AuthorBook\",through_fields=(\"author\", \"book\") 来指定使用我创建的第三张表来构建多对多的关系，而不是django自动创建的 book = models.ManyToManyField(to=\"Book\", through=\"AuthorBook\", through_fields=(\"author\", \"book\")) # through_field中，第一个字段，多对多设置在哪一张表里，第三张表通过什么字段找到这张表，就把这个字段写在前面，有关联关系的才要写进去 detail = models.OneToOneField(to=\"AuthorDetail\") def __str__(self): return self.name # 书 class Book(models.Model): name = models.CharField(max_length=50) # 自己创建作者和书关联的第三张表 # 此时，在ORM层面 作者和书就没有多对多的关系了 class AuthorBook(models.Model): # 作者id author = models.ForeignKey(to=\"Author\") # 书id book = models.ForeignKey(to=\"Book\") # 其他字段 info = models.CharField(max_length=12) class Meta: # 作者id和书id联合唯一 unique_together = ('author', 'book') 聚合查询和分组查询 聚合 aggregate()是QuerySet 的一个终止子句，意思是说，它返回一个包含一些键值对的字典。 键的名称是聚合值的标识符，值是计算出来的聚合值。键的名称是按照字段和聚合函数的名称自动生成出来的。 用到的内置函数： from django.db.models import Avg, Sum, Max, Min, Count 示例： >>> from django.db.models import Avg, Sum, Max, Min, Count >>> models.Book.objects.all().aggregate(Avg(\"price\")) {'price__avg': 13.233333} 如果你想要为聚合值指定一个名称，可以向聚合子句提供它。 >>> models.Book.objects.aggregate(average_price=Avg('price')) {'average_price': 13.233333} 如果你希望生成不止一个聚合，你可以向aggregate()子句中添加另一个参数。所以，如果你也想知道所有图书价格的最大值和最小值，可以这样查询： >>> models.Book.objects.all().aggregate(Avg(\"price\"), Max(\"price\"), Min(\"price\")) {'price__avg': 13.233333, 'price__max': Decimal('19.90'), 'price__min': Decimal('9.90')} 分组 我们在这里先复习一下SQL语句的分组。 假设现在有一张公司职员表： 我们使用原生SQL语句，按照部分分组求平均工资： select dept,AVG(salary) from employee group by dept; ORM查询: from django.db.models import Avg Employee.objects.values(\"dept\").annotate(avg=Avg(\"salary\").values(\"dept\", \"avg\") # values()就是取哪些字段，同时具有分组的作用。 连表查询的分组： SQL查询： select dept.name,AVG(salary) from employee inner join dept on (employee.dept_id=dept.id) group by dept_id; ORM查询： from django.db.models import Avg models.Employee.objects.values('dept_id').annotate(avg=Avg('salary')).values('dept__name', 'avg') # 或 models.Dept.objects.annotate(avg=Avg(\"employee__salary\")).values(\"name\", \"avg\") extra()方法分组 extra(select=None, where=None, params=None, tables=None, order_by=None, select_params=None) 有些情况下，Django的查询语法难以简单的表达复杂的 WHERE 子句，对于这种情况, Django 提供了 extra() QuerySet修改机制 — 它能在 QuerySet生成的SQL从句中注入新子句 extra可以指定一个或多个 参数,例如 select, where or tables. 这些参数都不是必须的，但是你至少要使用一个!要注意这些额外的方式对不同的数据库引擎可能存在移植性问题.(因为你在显式的书写SQL语句),除非万不得已,尽量避免这样做 参数之select The select 参数可以让你在 SELECT 从句中添加其他字段信息，它应该是一个字典，存放着属性名到 SQL 从句的映射。 queryResult=models.Article 　　　　　　　　　　　.objects.extra(select={'is_recent': \"create_time > '2017-09-05'\"}) 结果集中每个 Entry 对象都有一个额外的属性is_recent, 它是一个布尔值，表示 Article对象的create_time 是否晚于2017-09-05. article_obj=models.Article.objects.filter(nid=1).extra(select={\"standard_time\":\"strftime('%%Y-%%m-%%d',create_time)\"}).values(\"standard_time\",\"nid\",\"title\") print(article_obj) # 参数之where / tables 您可以使用where定义显式SQL WHERE子句 - 也许执行非显式连接。您可以使用tables手动将表添加到SQL FROM子句。 where和tables都接受字符串列表。所有where参数均为“与”任何其他搜索条件。 queryResult=models.Article.objects.extra(where=['nid in (1,3) OR title like \"py%\" ','nid>2']) 运用 按日查询ret = Spenging.objects.extra(select={'date':\"DATE_FORMAT(date,'%%Y-%%m-%%d')\"}).values(\"date\").annotate(total=Sum(\"money\")).values(\"date\", \"total\") 按月查询ret = Spenging.objects.extra(select={'date':\"DATE_FORMAT(date,'%%Y-%%m')\"}).values(\"date\").annotate(total=Sum(\"money\")).values(\"date\", \"total\") 按年查询ret = Spenging.objects.extra(select={'date':\"DATE_FORMAT(date,'%%Y')\"}).values(\"date\").annotate(total=Sum(\"money\")).values(\"date\", \"total\") 更多示例 示例1：统计每一本书的作者个数 >>> book_list = models.Book.objects.all().annotate(author_num=Count(\"author\")) >>> for obj in book_list: ... print(obj.author_num) ... 2 1 1 示例2：统计出每个出版社买的最便宜的书的价格 >>> publisher_list = models.Publisher.objects.annotate(min_price=Min(\"book__price\")) >>> for obj in publisher_list: ... print(obj.min_price) ... 9.90 19.90 方法二： >>> models.Book.objects.values(\"publisher__name\").annotate(min_price=Min(\"price\")) 示例3：统计不止一个作者的图书 >>> models.Book.objects.annotate(author_num=Count(\"author\")).filter(author_num__gt=1) ]> 示例4：根据一本图书作者数量的多少对查询集 QuerySet进行排序 >>> models.Book.objects.annotate(author_num=Count(\"author\")).order_by(\"author_num\") , , ]> 示例5：查询各个作者出的书的总价格 >>> models.Author.objects.annotate(sum_price=Sum(\"book__price\")).values(\"name\", \"sum_price\") 示例6：查询动态最多的组织并排序 >>> model.Organization.objects.filter(is_del=False, userdynamic__is_pass=2).annotate(dynamic_nums=Count('userdynamic__org')).order_by('-dynamic_nums').all() F查询和Q查询 F查询 在上面所有的例子中，我们构造的过滤器都只是将字段值与某个常量做比较。如果我们要对两个字段的值做比较，那该怎么做呢？ Django 提供 F() 来做这样的比较。F() 的实例可以在查询中引用字段，来比较同一个 model 实例中两个不同字段的值。 示例1： 查询评论数大于收藏数的书籍 from django.db.models import F models.Book.objects.filter(commnet_num__gt=F('keep_num')) Django 支持 F() 对象之间以及 F() 对象和常数之间的加减乘除和取模的操作。 models.Book.objects.filter(commnet_num__lt=F('keep_num')*2) 修改操作也可以使用F函数,比如将每一本书的价格提高30元 models.Book.objects.all().update(price=F(\"price\")+30) 引申： 如果要修改char字段咋办？ 如：把所有书名后面加上：(第一版) >>> from django.db.models.functions import Concat >>> from django.db.models import Value >>> models.Book.objects.all().update(title=Concat(F(\"title\"), Value(\"(\"), Value(\"第一版\"), Value(\")\"))) Q查询 filter() 等方法中的关键字参数查询都是一起进行“AND” 的。 如果你需要执行更复杂的查询（例如OR语句），你可以使用Q对象。 示例1： 查询作者名是小仙女或小魔女的 models.Book.objects.filter(Q(authors__name=\"小仙女\")|Q(authors__name=\"小魔女\")) 你可以组合& 和| 操作符以及使用括号进行分组来编写任意复杂的Q 对象。同时，Q 对象可以使用~ 操作符取反，这允许组合正常的查询和取反(NOT) 查询。 示例：查询作者名字是小仙女并且不是2018年出版的书的书名。 >>> models.Book.objects.filter(Q(author__name=\"小仙女\") & ~Q(publish_date__year=2018)).values_list(\"title\") 查询函数可以混合使用Q 对象和关键字参数。所有提供给查询函数的参数（关键字参数或Q 对象）都将\"AND”在一起。但是，如果出现Q 对象，它必须位于所有关键字参数的前面。 例如：查询出版年份是2017或2018，书名中带物语的所有书。 >>> models.Book.objects.filter(Q(publish_date__year=2018) | Q(publish_date__year=2017), title__icontains=\"物语\") , , ]> 锁和事务 锁 select_for_update(nowait=False, skip_locked=False) 返回一个锁住行直到事务结束的查询集，如果数据库支持，它将生成一个 SELECT ... FOR UPDATE 语句。 举个例子： entries = Entry.objects.select_for_update().filter(author=request.user) 所有匹配的行将被锁定，直到事务结束。这意味着可以通过锁防止数据被其它事务修改。 一般情况下如果其他事务锁定了相关行，那么本查询将被阻塞，直到锁被释放。 如果这不想要使查询阻塞的话，使用select_for_update(nowait=True)。 如果其它事务持有冲突的锁, 那么查询将引发 DatabaseError 异常。你也可以使用select_for_update(skip_locked=True)忽略锁定的行。 nowait和skip_locked是互斥的，同时设置会导致ValueError。 目前，postgresql，oracle和mysql数据库后端支持select_for_update()。 但是，MySQL不支持nowait和skip_locked参数。 使用不支持这些选项的数据库后端（如MySQL）将nowait=True或skip_locked=True转换为select_for_update()将导致抛出DatabaseError异常，这可以防止代码意外终止。 事务 import os if __name__ == '__main__': os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BMS.settings\") import django django.setup() import datetime from app01 import models try: from django.db import transaction with transaction.atomic(): new_publisher = models.Publisher.objects.create(name=\"火星出版社\") models.Book.objects.create(title=\"橘子物语\", publish_date=datetime.date.today(), publisher_id=10) # 指定一个不存在的出版社id except Exception as e: print(str(e)) 其他鲜为人知的操作(了解为主) Django_ORM执行原生SQL 在模型查询API不够用的情况下，我们还可以使用原始的SQL语句进行查询。 Django 提供两种方法使用原始SQL进行查询：一种是使用raw()方法，进行原始SQL查询并返回模型实例；另一种是完全避开模型层，直接执行自定义的SQL语句。 执行原生查询 raw()管理器方法用于原始的SQL查询，并返回模型的实例： 注意：raw()语法查询必须包含主键。 这个方法执行原始的SQL查询，并返回一个django.db.models.query.RawQuerySet 实例。 这个RawQuerySet 实例可以像一般的QuerySet那样，通过迭代来提供对象实例。 举个例子： class Person(models.Model): first_name = models.CharField(...) last_name = models.CharField(...) birth_date = models.DateField(...) 可以像下面这样执行原生SQL语句 >>> for p in Person.objects.raw('SELECT * FROM myapp_person'): ... print(p) raw()查询可以查询其他表的数据。 举个例子： ret = models.Student.objects.raw('select id, tname as hehe from app02_teacher') for i in ret: print(i.id, i.hehe) raw()方法自动将查询字段映射到模型字段。还可以通过translations参数指定一个把查询的字段名和ORM对象实例的字段名互相对应的字典 d = {'tname': 'haha'} ret = models.Student.objects.raw('select * from app02_teacher', translations=d) for i in ret: print(i.id, i.sname, i.haha) 原生SQL还可以使用参数，注意不要自己使用字符串格式化拼接SQL语句，防止SQL注入！ d = {'tname': 'haha'} ret = models.Student.objects.raw('select * from app02_teacher where id > %s', translations=d, params=[1,]) for i in ret: print(i.id, i.sname, i.haha) 直接执行自定义SQL 有时候raw()方法并不十分好用，很多情况下我们不需要将查询结果映射成模型，或者我们需要执行DELETE、 INSERT以及UPDATE操作。在这些情况下，我们可以直接访问数据库，完全避开模型层。 我们可以直接从django提供的接口中获取数据库连接，然后像使用pymysql模块一样操作数据库。 from django.db import connection, connections cursor = connection.cursor() # cursor = connections['default'].cursor() cursor.execute(\"\"\"SELECT * from auth_user where id = %s\"\"\", [1]) ret = cursor.fetchone() QuerySet方法大全 ################################################################## # PUBLIC METHODS THAT ALTER ATTRIBUTES AND RETURN A NEW QUERYSET # ################################################################## def all(self) # 获取所有的数据对象 def filter(self, *args, **kwargs) # 条件查询 # 条件可以是：参数，字典，Q def exclude(self, *args, **kwargs) # 条件查询 # 条件可以是：参数，字典，Q def select_related(self, *fields) 性能相关：表之间进行join连表操作，一次性获取关联的数据。 总结： 1. select_related主要针一对一和多对一关系进行优化。 2. select_related使用SQL的JOIN语句进行优化，通过减少SQL查询的次数来进行优化、提高性能。 def prefetch_related(self, *lookups) 性能相关：多表连表操作时速度会慢，使用其执行多次SQL查询在Python代码中实现连表操作。 总结： 1. 对于多对多字段（ManyToManyField）和一对多字段，可以使用prefetch_related()来进行优化。 2. prefetch_related()的优化方式是分别查询每个表，然后用Python处理他们之间的关系。 def annotate(self, *args, **kwargs) # 用于实现聚合group by查询 from django.db.models import Count, Avg, Max, Min, Sum v = models.UserInfo.objects.values('u_id').annotate(uid=Count('u_id')) # SELECT u_id, COUNT(ui) AS `uid` FROM UserInfo GROUP BY u_id v = models.UserInfo.objects.values('u_id').annotate(uid=Count('u_id')).filter(uid__gt=1) # SELECT u_id, COUNT(ui_id) AS `uid` FROM UserInfo GROUP BY u_id having count(u_id) > 1 v = models.UserInfo.objects.values('u_id').annotate(uid=Count('u_id',distinct=True)).filter(uid__gt=1) # SELECT u_id, COUNT( DISTINCT ui_id) AS `uid` FROM UserInfo GROUP BY u_id having count(u_id) > 1 def distinct(self, *field_names) # 用于distinct去重 models.UserInfo.objects.values('nid').distinct() # select distinct nid from userinfo 注：只有在PostgreSQL中才能使用distinct进行去重 def order_by(self, *field_names) # 用于排序 models.UserInfo.objects.all().order_by('-id','age') def extra(self, select=None, where=None, params=None, tables=None, order_by=None, select_params=None) # 构造额外的查询条件或者映射，如：子查询 Entry.objects.extra(select={'new_id': \"select col from sometable where othercol > %s\"}, select_params=(1,)) Entry.objects.extra(where=['headline=%s'], params=['Lennon']) Entry.objects.extra(where=[\"foo='a' OR bar = 'a'\", \"baz = 'a'\"]) Entry.objects.extra(select={'new_id': \"select id from tb where id > %s\"}, select_params=(1,), order_by=['-nid']) def reverse(self): # 倒序 models.UserInfo.objects.all().order_by('-nid').reverse() # 注：如果存在order_by，reverse则是倒序，如果多个排序则一一倒序 def defer(self, *fields): models.UserInfo.objects.defer('username','id') 或 models.UserInfo.objects.filter(...).defer('username','id') #映射中排除某列数据 def only(self, *fields): #仅取某个表中的数据 models.UserInfo.objects.only('username','id') 或 models.UserInfo.objects.filter(...).only('username','id') def using(self, alias): 指定使用的数据库，参数为别名（setting中的设置） ################################################## # PUBLIC METHODS THAT RETURN A QUERYSET SUBCLASS # ################################################## def raw(self, raw_query, params=None, translations=None, using=None): # 执行原生SQL models.UserInfo.objects.raw('select * from userinfo') # 如果SQL是其他表时，必须将名字设置为当前UserInfo对象的主键列名 models.UserInfo.objects.raw('select id as nid from 其他表') # 为原生SQL设置参数 models.UserInfo.objects.raw('select id as nid from userinfo where nid>%s', params=[12,]) # 将获取的到列名转换为指定列名 name_map = {'first': 'first_name', 'last': 'last_name', 'bd': 'birth_date', 'pk': 'id'} Person.objects.raw('SELECT * FROM some_other_table', translations=name_map) # 指定数据库 models.UserInfo.objects.raw('select * from userinfo', using=\"default\") ################### 原生SQL ################### from django.db import connection, connections cursor = connection.cursor() # cursor = connections['default'].cursor() cursor.execute(\"\"\"SELECT * from auth_user where id = %s\"\"\", [1]) row = cursor.fetchone() # fetchall()/fetchmany(..) def values(self, *fields): # 获取每行数据为字典格式 def values_list(self, *fields, **kwargs): # 获取每行数据为元祖 def dates(self, field_name, kind, order='ASC'): # 根据时间进行某一部分进行去重查找并截取指定内容 # kind只能是：\"year\"（年）, \"month\"（年-月）, \"day\"（年-月-日） # order只能是：\"ASC\" \"DESC\" # 并获取转换后的时间 - year : 年-01-01 - month: 年-月-01 - day : 年-月-日 models.DatePlus.objects.dates('ctime','day','DESC') def datetimes(self, field_name, kind, order='ASC', tzinfo=None): # 根据时间进行某一部分进行去重查找并截取指定内容，将时间转换为指定时区时间 # kind只能是 \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\" # order只能是：\"ASC\" \"DESC\" # tzinfo时区对象 models.DDD.objects.datetimes('ctime','hour',tzinfo=pytz.UTC) models.DDD.objects.datetimes('ctime','hour',tzinfo=pytz.timezone('Asia/Shanghai')) \"\"\" pip3 install pytz import pytz pytz.all_timezones pytz.timezone(‘Asia/Shanghai’) \"\"\" def none(self): # 空QuerySet对象 #################################### # METHODS THAT DO DATABASE QUERIES # #################################### def aggregate(self, *args, **kwargs): # 聚合函数，获取字典类型聚合结果 from django.db.models import Count, Avg, Max, Min, Sum result = models.UserInfo.objects.aggregate(k=Count('u_id', distinct=True), n=Count('nid')) ===> {'k': 3, 'n': 4} def count(self): # 获取个数 def get(self, *args, **kwargs): # 获取单个对象 def create(self, **kwargs): # 创建对象 def bulk_create(self, objs, batch_size=None): # 批量插入 # batch_size表示一次插入的个数 objs = [ models.DDD(name='r11'), models.DDD(name='r22') ] models.DDD.objects.bulk_create(objs, 10) def get_or_create(self, defaults=None, **kwargs): # 如果存在，则获取，否则，创建 # defaults 指定创建时，其他字段的值 obj, created = models.UserInfo.objects.get_or_create(username='root1', defaults={'email': '1111111','u_id': 2, 't_id': 2}) def update_or_create(self, defaults=None, **kwargs): # 如果存在，则更新，否则，创建 # defaults 指定创建时或更新时的其他字段 obj, created = models.UserInfo.objects.update_or_create(username='root1', defaults={'email': '1111111','u_id': 2, 't_id': 1}) def first(self): # 获取第一个 def last(self): # 获取最后一个 def in_bulk(self, id_list=None): # 根据主键ID进行查找 id_list = [11,21,31] models.DDD.objects.in_bulk(id_list) def delete(self): # 删除 def update(self, **kwargs): # 更新 def exists(self): # 是否有结果 Django终端打印SQL语句 在Django项目的settings.py文件中，在最后复制粘贴如下代码： LOGGING = { 'version': 1, 'disable_existing_loggers': False, 'handlers': { 'console':{ 'level':'DEBUG', 'class':'logging.StreamHandler', }, }, 'loggers': { 'django.db.backends': { 'handlers': ['console'], 'propagate': True, 'level':'DEBUG', }, } } 即为你的Django项目配置上一个名为django.db.backends的logger实例即可查看翻译后的SQL语句。 在Python脚本中调用Django环境 import os if __name__ == '__main__': os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BMS.settings\") import django django.setup() from app01 import models books = models.Book.objects.all() print(books) PS: BMS为项目名 "},"Python/第三方库/Django/08-Cookie、Session和分页.html":{"url":"Python/第三方库/Django/08-Cookie、Session和分页.html","title":"Cookie、Session和分页","keywords":"","body":"datetime:2019/6/24 9:46 author:nzb Cookie、Session和分页 Cookie Cookie的由来 大家都知道HTTP协议是无状态的。 无状态的意思是每次请求都是独立的，它的执行情况和结果与前面的请求和之后的请求都无直接关系，它不会受前面的请求响应情况直接影响， 也不会直接影响后面的请求响应情况。 一句有意思的话来描述就是人生只如初见，对服务器来说，每次的请求都是全新的。 状态可以理解为客户端和服务器在某次会话中产生的数据，那无状态的就以为这些数据不会被保留。会话中产生的数据又是我们需要保存的， 也就是说要“保持状态”。因此Cookie就是在这样一个场景下诞生。 什么是Cookie Cookie具体指的是一段小信息，它是服务器发送出来存储在浏览器上的一组组键值对，下次访问服务器时浏览器会自动携带这些键值对，以便服务器提取有用信息。 Cookie的原理 cookie的工作原理是：由服务器产生内容，浏览器收到请求后保存在本地；当浏览器再次访问时，浏览器会自动带上Cookie，这样服务器就能通过Cookie的内容来判断这个是“谁”了。 查看Cookie 我们使用Chrome浏览器，打开开发者工具。 Django中操作Cookie 获取Cookie request.COOKIES['key'] request.get_signed_cookie(key, default=RAISE_ERROR, salt='', max_age=None) 参数： default: 默认值 salt: 加密盐 max_age: 后台控制过期时间 设置Cookie rep = HttpResponse(...) rep ＝ render(request, ...) rep.set_cookie(key,value,...) rep.set_signed_cookie(key,value,salt='加密盐', max_age=None, ...) 参数： key, 键 value='', 值 max_age=None, 超时时间 expires=None, 超时时间(IE requires expires, so set it if hasn't been already.) path='/', Cookie生效的路径，/ 表示根路径，特殊的：根路径的cookie可以被任何url的页面访问 domain=None, Cookie生效的域名 secure=False, https传输 httponly=False 只能http协议传输，无法被JavaScript获取（不是绝对，底层抓包可以获取到也可以被覆盖） 删除Cookie def logout(request): rep = redirect(\"/login/\") rep.delete_cookie(\"user\") # 删除用户浏览器上之前设置的usercookie值 return rep Cookie版登陆校验 def check_login(func): @wraps(func) def inner(request, *args, **kwargs): next_url = request.get_full_path() if request.get_signed_cookie(\"login\", salt=\"SSS\", default=None) == \"yes\": # 已经登录的用户... return func(request, *args, **kwargs) else: # 没有登录的用户，跳转刚到登录页面 return redirect(\"/login/?next={}\".format(next_url)) return inner @check_login def login(request): if request.method == \"POST\": username = request.POST.get(\"username\") passwd = request.POST.get(\"password\") if username == \"xxx\" and passwd == \"dashabi\": next_url = request.GET.get(\"next\") if next_url and next_url != \"/logout/\": response = redirect(next_url) else: response = redirect(\"/class_list/\") response.set_signed_cookie(\"login\", \"yes\", salt=\"SSS\") return response return render(request, \"login.html\") Session Session的由来 Cookie虽然在一定程度上解决了“保持状态”的需求，但是由于Cookie本身最大支持4096字节，以及Cookie本身保存在客户端，可能被拦截或窃取，因此就需要有一种新的东西，它能支持更多的字节，并且他保存在服务器，有较高的安全性。这就是Session。 问题来了，基于HTTP协议的无状态特征，服务器根本就不知道访问者是“谁”。那么上述的Cookie就起到桥接的作用。 我们可以给每个客户端的Cookie分配一个唯一的id，这样用户在访问时，通过Cookie，服务器就知道来的人是“谁”。然后我们再根据不同的Cookie的id，在服务器上保存一段时间的私密资料，如“账号密码”等等。 总结而言：Cookie弥补了HTTP无状态的不足，让服务器知道来的人是“谁”；但是Cookie以文本的形式保存在本地，自身安全性较差；所以我们就通过Cookie识别不同的用户，对应的在Session里保存私密的信息以及超过4096字节的文本。 另外，上述所说的Cookie和Session其实是共通性的东西，不限于语言和框架。 Django中Session相关方法 # 获取、设置、删除Session中数据 request.session['k1'] request.session.get('k1',None) request.session['k1'] = 123 request.session.setdefault('k1',123) # 存在则不设置 del request.session['k1'] # 所有 键、值、键值对 request.session.keys() request.session.values() request.session.items() request.session.iterkeys() request.session.itervalues() request.session.iteritems() # 会话session的key request.session.session_key # 将所有Session失效日期小于当前日期的数据删除 request.session.clear_expired() # 检查会话session的key在数据库中是否存在 request.session.exists(\"session_key\") # 删除当前会话的所有Session数据 request.session.delete() 　　 # 删除当前的会话数据并删除会话的Cookie。 request.session.flush() 这用于确保前面的会话数据不可以再次被用户的浏览器访问 例如，django.contrib.auth.logout() 函数中就会调用它。 # 设置会话Session和Cookie的超时时间 request.session.set_expiry(value) * 如果value是个整数，session会在些秒数后失效。 * 如果value是个datatime或timedelta，session就会在这个时间后失效。 * 如果value是0,用户关闭浏览器session就会失效。 * 如果value是None,session会依赖全局session失效策略。 Session流程解析 Session版登陆验证 from functools import wraps def check_login(func): @wraps(func) def inner(request, *args, **kwargs): next_url = request.get_full_path() if request.session.get(\"user\"): return func(request, *args, **kwargs) else: return redirect(\"/login/?next={}\".format(next_url)) return inner def login(request): if request.method == \"POST\": user = request.POST.get(\"user\") pwd = request.POST.get(\"pwd\") if user == \"alex\" and pwd == \"alex1234\": # 设置session request.session[\"user\"] = user # 获取跳到登陆页面之前的URL next_url = request.GET.get(\"next\") # 如果有，就跳转回登陆之前的URL if next_url: return redirect(next_url) # 否则默认跳转到index页面 else: return redirect(\"/index/\") return render(request, \"login.html\") @check_login def logout(request): # 删除所有当前请求相关的session request.session.delete() return redirect(\"/login/\") @check_login def index(request): current_user = request.session.get(\"user\", None) return render(request, \"index.html\", {\"user\": current_user}) Django中的Session配置 Django中默认支持Session，其内部提供了5种类型的Session供开发者使用。 1. 数据库Session SESSION_ENGINE = 'django.contrib.sessions.backends.db' # 引擎（默认） 2. 缓存Session SESSION_ENGINE = 'django.contrib.sessions.backends.cache' # 引擎 SESSION_CACHE_ALIAS = 'default' # 使用的缓存别名（默认内存缓存，也可以是memcache），此处别名依赖缓存的设置 3. 文件Session SESSION_ENGINE = 'django.contrib.sessions.backends.file' # 引擎 SESSION_FILE_PATH = None # 缓存文件路径，如果为None，则使用tempfile模块获取一个临时地址tempfile.gettempdir() 4. 缓存+数据库 SESSION_ENGINE = 'django.contrib.sessions.backends.cached_db' # 引擎 5. 加密Cookie Session SESSION_ENGINE = 'django.contrib.sessions.backends.signed_cookies' # 引擎 其他公用设置项： SESSION_COOKIE_NAME ＝ \"sessionid\" # Session的cookie保存在浏览器上时的key，即：sessionid＝随机字符串（默认） SESSION_COOKIE_PATH ＝ \"/\" # Session的cookie保存的路径（默认） SESSION_COOKIE_DOMAIN = None # Session的cookie保存的域名（默认） SESSION_COOKIE_SECURE = False # 是否Https传输cookie（默认） SESSION_COOKIE_HTTPONLY = True # 是否Session的cookie只支持http传输（默认） SESSION_COOKIE_AGE = 1209600 # Session的cookie失效日期（2周）（默认） SESSION_EXPIRE_AT_BROWSER_CLOSE = False # 是否关闭浏览器使得Session过期（默认） SESSION_SAVE_EVERY_REQUEST = False # 是否每次请求都保存Session，默认修改之后才保存（默认） CBV中加装饰器相关 CBV实现的登录视图 class LoginView(View): def get(self, request): \"\"\" 处理GET请求 \"\"\" return render(request, 'login.html') def post(self, request): \"\"\" 处理POST请求 \"\"\" user = request.POST.get('user') pwd = request.POST.get('pwd') if user == 'alex' and pwd == \"alex1234\": next_url = request.GET.get(\"next\") # 生成随机字符串 # 写浏览器cookie -> session_id: 随机字符串 # 写到服务端session： # { # \"随机字符串\": {'user':'alex'} # } request.session['user'] = user if next_url: return redirect(next_url) else: return redirect('/index/') return render(request, 'login.html') 要在CBV视图中使用我们上面的check_login装饰器，有以下三种方式： from django.utils.decorators import method_decorator 1. 加在CBV视图的get或post方法上 from django.utils.decorators import method_decorator class HomeView(View): def dispatch(self, request, *args, **kwargs): return super(HomeView, self).dispatch(request, *args, **kwargs) def get(self, request): return render(request, \"home.html\") @method_decorator(check_login) def post(self, request): print(\"Home View POST method...\") return redirect(\"/index/\") 2. 加在dispatch方法上 from django.utils.decorators import method_decorator class HomeView(View): @method_decorator(check_login) def dispatch(self, request, *args, **kwargs): return super(HomeView, self).dispatch(request, *args, **kwargs) def get(self, request): return render(request, \"home.html\") def post(self, request): print(\"Home View POST method...\") return redirect(\"/index/\") 因为CBV中首先执行的就是dispatch方法，所以这么写相当于给get和post方法都加上了登录校验。 3. 直接加在视图类上，但method_decorator必须传 name 关键字参数 如果get方法和post方法都需要登录校验的话就写两个装饰器。 from django.utils.decorators import method_decorator @method_decorator(check_login, name=\"get\") @method_decorator(check_login, name=\"post\") class HomeView(View): def dispatch(self, request, *args, **kwargs): return super(HomeView, self).dispatch(request, *args, **kwargs) def get(self, request): return render(request, \"home.html\") def post(self, request): print(\"Home View POST method...\") return redirect(\"/index/\") 补充 CSRF Token相关装饰器在CBV只能加到dispatch方法上，或者加在视图类上然后name参数指定为dispatch方法。 备注： csrf_protect，为当前函数强制设置防跨站请求伪造功能，即便settings中没有设置全局中间件。 csrf_exempt，取消当前函数防跨站请求伪造功能，即便settings中设置了全局中间件。 from django.views.decorators.csrf import csrf_exempt, csrf_protect from django.utils.decorators import method_decorator class HomeView(View): @method_decorator(csrf_exempt) def dispatch(self, request, *args, **kwargs): return super(HomeView, self).dispatch(request, *args, **kwargs) def get(self, request): return render(request, \"home.html\") def post(self, request): print(\"Home View POST method...\") return redirect(\"/index/\") 或者 from django.views.decorators.csrf import csrf_exempt, csrf_protect from django.utils.decorators import method_decorator @method_decorator(csrf_exempt, name='dispatch') class HomeView(View): def dispatch(self, request, *args, **kwargs): return super(HomeView, self).dispatch(request, *args, **kwargs) def get(self, request): return render(request, \"home.html\") def post(self, request): print(\"Home View POST method...\") return redirect(\"/index/\") 分页 当数据库中数据有很多，我们通常会在前端页面做分页展示。 分页的数据可以在前端页面实现，也可以在后端实现分页。 后端实现分页的原理就是每次只请求一页数据。 准备工作 我们使用脚本批量创建一些测试数据（将下面的代码保存到bulk_create.py文件中放到Django项目的根目录，直接执行即可。）： import os if __name__ == \"__main__\": os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"about_orm.settings\") import django django.setup() from app01 import models bulk_obj = (models.Publisher(name='沙河第{}出版社'.format(i)) for i in range(300)) models.Publisher.objects.bulk_create(bulk_obj) 自定义分页 稳扎稳打版 def publisher_list(request): # 从URL中取当前访问的页码数 try: current_page = int(request.GET.get('page')) except Exception as e: # 取不到或者页码数不是数字都默认展示第1页 current_page = 1 # 总数据量 total_count = models.Publisher.objects.count() # 定义每页显示多少条数据 per_page = 10 # 计算出总页码数 total_page, more = divmod(total_count, per_page) if more: total_page += 1 # 定义页面上最多显示多少页码(为了左右对称，一般设为奇数) max_show = 11 half_show = max_show // 2 # 计算一下页面显示的页码范围 if total_page = total_page: # 右边越界 page_end = total_page page_start = total_page - max_show elif current_page - half_show ') # 加首页 first_li = '首页' page_html_list.append(first_li) # 加上一页 if current_page == 1: prev_li = '&laquo;' else: prev_li = '&laquo;'.format(current_page - 1) page_html_list.append(prev_li) for i in range(page_start, page_end + 1): if i == current_page: li_tag = '{0}'.format(i) else: li_tag = '{0}'.format(i) page_html_list.append(li_tag) # 加下一页 if current_page == total_page: next_li = '&raquo;' else: next_li = '&raquo;'.format(current_page + 1) page_html_list.append(next_li) # 加尾页 page_end_li = '尾页'.format(total_page) page_html_list.append(page_end_li) page_html_list.append('') page_html = \"\".join(page_html_list) return render(request, \"publisher_list.html\", {\"publisher_list\": publisher_list, \"page_html\": page_html}) 封装保存版 class Pagination(object): \"\"\"自定义分页（Bootstrap版）\"\"\" def __init__(self, current_page, total_count, base_url, per_page=10, max_show=11): \"\"\" :param current_page: 当前请求的页码 :param total_count: 总数据量 :param base_url: 请求的URL :param per_page: 每页显示的数据量，默认值为10 :param max_show: 页面上最多显示多少个页码，默认值为11 \"\"\" try: self.current_page = int(current_page) except Exception as e: # 取不到或者页码数不是数字都默认展示第1页 self.current_page = 1 # 定义每页显示多少条数据 self.per_page = per_page # 计算出总页码数 total_page, more = divmod(total_count, per_page) if more: total_page += 1 self.total_page = total_page # 定义页面上最多显示多少页码(为了左右对称，一般设为奇数) self.max_show = max_show self.half_show = max_show // 2 self.base_url = base_url @property def start(self): return (self.current_page-1) * self.per_page @property def end(self): return self.current_page * self.per_page def page_html(self): # 计算一下页面显示的页码范围 if self.total_page = self.total_page: # 右边越界 page_end = self.total_page page_start = self.total_page - self.max_show elif self.current_page - self.half_show ') # 加首页 first_li = '首页'.format(self.base_url) page_html_list.append(first_li) # 加上一页 if self.current_page == 1: prev_li = '&laquo;' else: prev_li = '&laquo;'.format( self.base_url, self.current_page - 1) page_html_list.append(prev_li) for i in range(page_start, page_end + 1): if i == self.current_page: li_tag = '{1}'.format(self.base_url, i) else: li_tag = '{1}'.format(self.base_url, i) page_html_list.append(li_tag) # 加下一页 if self.current_page == self.total_page: next_li = '&raquo;' else: next_li = '&raquo;'.format( self.base_url, self.current_page + 1) page_html_list.append(next_li) # 加尾页 page_end_li = '尾页'.format(self.base_url, self.total_page) page_html_list.append(page_end_li) page_html_list.append('') return \"\".join(page_html_list) 封装保存版使用示例 def publisher_list(request): # 从URL中取当前访问的页码数 current_page = int(request.GET.get('page')) # 比len(models.Publisher.objects.all())更高效 total_count = models.Publisher.objects.count() page_obj = Pagination(current_page, total_count, request.path_info) data = models.Publisher.objects.all()[page_obj.start:page_obj.end] page_html = page_obj.page_html() return render(request, \"publisher_list.html\", {\"publisher_list\": data, \"page_html\": page_html}) Django内置分页 内置分页view部分 from django.shortcuts import render from django.core.paginator import Paginator, EmptyPage, PageNotAnInteger L = [] for i in range(999): L.append(i) def index(request): current_page = request.GET.get('p') paginator = Paginator(L, 10) # per_page: 每页显示条目数量 # count: 数据总个数 # num_pages:总页数 # page_range:总页数的索引范围，如: (1,10),(1,200) # page: page对象 try: posts = paginator.page(current_page) # has_next 是否有下一页 # next_page_number 下一页页码 # has_previous 是否有上一页 # previous_page_number 上一页页码 # object_list 分页之后的数据列表 # number 当前页 # paginator paginator对象 except PageNotAnInteger: posts = paginator.page(1) except EmptyPage: posts = paginator.page(paginator.num_pages) return render(request, 'index.html', {'posts': posts}) 内置分页HTML部分 { % for item in posts % } { { item } } { % endfor % } { % if posts.has_previous % } Previous { % endif % } Page { { posts.number } } of { { posts.paginator.num_pages } }. { % if posts.has_next % } Next { % endif % } Cookie和Session(100天) 实现用户跟踪 如今，一个网站如果不通过某种方式记住你是谁以及你之前在网站的活动情况，失去的就是网站的可用性和便利性，继而很有可能导致网站用户的流式，所以记住一个用户（更专业的说法叫用户跟踪）对绝大多数Web应用来说都是必需的功能。 在服务器端，我们想记住一个用户最简单的办法就是创建一个对象，通过这个对象就可以把用户相关的信息都保存起来，这个对象就是我们常说的session（用户会话对象）。那么问题来了，HTTP本身是一个无连接（每次请求和响应的过程中，服务器一旦完成对客户端请求的响应之后就断开连接）、无状态（客户端再次发起对服务器的请求时，服务器无法得知这个客户端之前的任何信息）的协议，即便服务器通过session对象保留了用户数据，还得通过某种方式来确定当前的请求与之前保存过的哪一个session是有关联的。相信很多人都能想到，我们可以给每个session对象分配一个全局唯一的标识符来识别session对象，我们姑且称之为sessionid，每次客户端发起请求时，只要携带上这个sessionid，就有办法找到与之对应的session对象，从而实现在两次请求之间记住该用户的信息，也就是我们之前说的用户跟踪。 要让客户端记住并在每次请求时带上sessionid又有以下几种做法： URL重写。所谓URL重写就是在URL中携带sessionid，例如：http://www.example.com/index.html?sessionid=123456，服务器通过获取sessionid参数的值来取到与之对应的session对象。 隐藏域（隐式表单域）。在提交表单的时候，可以通过在表单中设置隐藏域向服务器发送额外的数据。例如：。 本地存储。现在的浏览器都支持多种本地存储方案，包括：cookie、localStorage、sessionStorage、IndexedDB等。在这些方案中，cookie是历史最为悠久也是被诟病得最多的一种方案，也是我们接下来首先为大家讲解的一种方案。简单的说，cookie是一种以键值对方式保存在浏览器临时文件中的数据，每次请求时，请求头中会携带本站点的cookie到服务器，那么只要将sessionid写入cookie，下次请求时服务器只要读取请求头中的cookie就能够获得这个sessionid，如下图所示。 在HTML5时代要，除了cookie，还可以使用新的本地存储API来保存数据，就是刚才提到的localStorage、sessionStorage、IndexedDB等技术，如下图所示。 Django框架对session的支持 在创建Django项目时，默认的配置文件settings.py文件中已经激活了一个名为SessionMiddleware的中间件（关于中间件的知识我们在下一个章节做详细的讲解，这里只需要知道它的存在即可），因为这个中间件的存在，我们可以直接通过请求对象的session属性来操作会话对象。session属性是一个像字典一样可以读写数据的容器对象，因此我们可以使用“键值对”的方式来保留用户数据。与此同时，SessionMiddleware中间件还封装了对cookie的操作，在cookie中保存了sessionid，就如同我们之前描述的那样。 在默认情况下，Django将session的数据序列化后保存在关系型数据库中，在Django 1.6以后的版本中，默认的序列化数据的方式是JSON序列化，而在此之前一直使用Pickle序列化。JSON序列化和Pickle序列化的差别在于前者将对象序列化为字符串（字符形式），而后者将对象序列化为字节串（二进制形式），因为安全方面的原因，JSON序列化成为了目前Django框架默认序列化数据的方式，这就要求在我们保存在session中的数据必须是能够JSON序列化的，否则就会引发异常。还有一点需要说明的是，使用关系型数据库保存session中的数据在大多数时候并不是最好的选择，因为数据库可能会承受巨大的压力而成为系统性能的瓶颈，在后面的章节中我们会告诉大家如何将session的数据保存到缓存服务中。 我们继续完善之前的投票应用，前一个章节中我们实现了用户的登录和注册，下面我们首先完善登录时对验证码的检查。 def get_captcha(request): \"\"\"验证码\"\"\" captcha_text = random_captcha_text() request.session['captcha'] = captcha_text image_data = Captcha.instance().generate(captcha_text) return HttpResponse(image_data, content_type='image/png') 注意上面代码中的第4行，我们将随机生成的验证码字符串保存到session中，稍后用户登录时，我们要将保存在session中的验证码字符串和用户输入的验证码字符串进行比对，如果用户输入了正确的验证码才能够执行后续的登录流程，代码如下所示。 def login(request: HttpRequest): \"\"\"登录\"\"\" hint = '' if request.method == 'POST': form = LoginForm(request.POST) if form.is_valid(): # 对验证码的正确性进行验证 captcha_from_user = form.cleaned_data['captcha'] captcha_from_sess = request.session.get('captcha', '') if captcha_from_sess.lower() != captcha_from_user.lower(): hint = '请输入正确的验证码' else: username = form.cleaned_data['username'] password = form.cleaned_data['password'] user = User.objects.filter(username=username, password=password).first() if user: # 登录成功后将用户编号和用户名保存在session中 request.session['userid'] = user.no request.session['username'] = user.username return redirect('/') else: hint = '用户名或密码错误' else: hint = '请输入有效的登录信息' return render(request, 'login.html', {'hint': hint}) 上面的代码中，我们设定了登录成功后会在session中保存用户的编号（userid）和用户名（username），页面会重定向到首页。接下来我们可以稍微对首页的代码进行调整，在页面的右上角显示出登录用户的用户名。我们将这段代码单独写成了一个名为header.html的HTML文件，首页中可以通过在标签中添加{ % include 'header.html' % }来包含这个页面，代码如下所示。 { % if request.session.userid % } { { request.session.username } } 注销 { % else % } 登录&nbsp;&nbsp; { % endif % } 注册 如果用户没有登录，页面会显示登录和注册的超链接；而用户登录成功后，页面上会显示用户名和注销的链接，注销链接对应的视图函数如下所示，URL的映射与之前讲过的类似，不再赘述。 def logout(request): \"\"\"注销\"\"\" request.session.flush() return redirect('/') 上面的代码通过session对象flush方法来销毁session，一方面清除了服务器上session对象保存的用户数据，一方面将保存在浏览器cookie中的sessionid删除掉，稍后我们会对如何读写cookie的操作加以说明。 我们可以通过项目使用的数据库中名为django_session 的表来找到所有的session，该表的结构如下所示： session_key session_data expire_date c9g2gt5cxo0k2evykgpejhic5ae7bfpl MmI4YzViYjJhOGMyMDJkY2M5Yzg3... 2019-05-25 23:16:13.898522 其中，第1列就是浏览器cookie中保存的sessionid；第2列是经过BASE64编码后的session中的数据，如果使用Python的base64对其进行解码，解码的过程和结果如下所示。 >>> import base64 >>> base64.b64decode('MmI4YzViYjJhOGMyMDJkY2M5Yzg3ZWIyZGViZmUzYmYxNzdlNDdmZjp7ImNhcHRjaGEiOiJzS3d0Iiwibm8iOjEsInVzZXJuYW1lIjoiamFja2ZydWVkIn0=') '2b8c5bb2a8c202dcc9c87eb2debfe3bf177e47ff:{\"captcha\":\"sKwt\",\"no\":1,\"username\":\"jackfrued\"}' 第3列是session的过期时间，session过期后浏览器保存的cookie中的sessionid就会失效，但是数据库中的这条对应的记录仍然会存在，如果想清除过期的数据，可以使用下面的命令。 python manage.py clearsessions Django框架默认的session过期时间为两周（1209600秒），如果想修改这个时间，可以在项目的配置文件中添加如下所示的代码。 # 配置会话的超时时间为1天（86400秒） SESSION_COOKIE_AGE = 86400 有很多对安全性要求较高的应用都必须在关闭浏览器窗口时让会话过期，不再保留用户的任何信息，如果希望在关闭浏览器窗口时就让会话过期（cookie中的sessionid失效），可以加入如下所示的配置。 # 设置为True在关闭浏览器窗口时session就过期 SESSION_EXPIRE_AT_BROWSER_CLOSE = True 如果不希望将session的数据保存在数据库中，可以将其放入缓存中，对应的配置如下所示，缓存的配置和使用我们在后面讲解。 # 配置将会话对象放到缓存中存储 SESSION_ENGINE = 'django.contrib.sessions.backends.cache' # 配置使用哪一组缓存来保存会话 SESSION_CACHE_ALIAS = 'default' 如果要修改session数据默认的序列化方式，可以将默认的JSONSerializer修改为PickleSerializer。 SESSION_SERIALIZER = 'django.contrib.sessions.serializers.PickleSerializer' 在视图函数中读写cookie Django封装的HttpRequest和HttpResponse对象分别提供了读写cookie的操作。 HttpRequest封装的属性和方法： COOKIES属性 - 该属性包含了HTTP请求携带的所有cookie。 get_signed_cookie方法 - 获取带签名的cookie，如果签名验证失败，会产生BadSignature异常。 HttpResponse封装的方法： set_cookie方法 - 该方法可以设置一组键值对并将其最终将写入浏览器。 set_signed_cookie方法 - 跟上面的方法作用相似，但是会对cookie进行签名来达到防篡改的作用。因为如果篡改了cookie中的数据，在不知道密钥和盐>)的情况下是无法生成有效的签名，这样服务器在读取cookie时会发现数据与签名不一致从而产生BadSignature异常。需要说明的是，这里所说的密钥就是我们在Django项目配置文件中指定的SECRET_KEY，而盐是程序中设定的一个字符串，你愿意设定为什么都可以，只要是一个有效的字符串。 上面提到的方法，如果不清楚它们的具体用法，可以自己查阅一下Django的官方文档，没有什么资料比官方文档能够更清楚的告诉你这些方法到底如何使用。 刚才我们说过了，激活SessionMiddleware之后，每个HttpRequest对象都会绑定一个session属性，它是一个类似字典的对象，除了保存用户数据之外还提供了检测浏览器是否支持cookie的方法，包括： set_test_cookie方法 - 设置用于测试的cookie。 test_cookie_worked方法 - 检测测试cookie是否工作。 delete_test_cookie方法 - 删除用于测试的cookie。 set_expiry方法 - 设置会话的过期时间。 get_expire_age/get_expire_date方法 - 获取会话的过期时间。 clear_expired方法 - 清理过期的会话。 下面是在执行登录之前检查浏览器是否支持cookie的代码。 def login(request): if request.method == 'POST': if request.session.test_cookie_worked(): request.session.delete_test_cookie() # Add your code to perform login process here else: return HttpResponse(\"Please enable cookies and try again.\") request.session.set_test_cookie() return render_to_response('login.html') Cookie的替代品 之前我们说过了，cookie的名声一直都不怎么好，当然我们在实际开发中是不会在cookie中保存用户的敏感信息（如用户的密码、信用卡的账号等）的，而且保存在cookie中的数据一般也会做好编码和签名的工作。即便如此，HTML5中还是给出了用于替代cookie的技术方案，其中使用得最为广泛的就是localStorage和sessionStorage，相信从名字上你就能听出二者的差别，存储在localStorage的数据可以长期保留；而存储在sessionStorage的数据会在浏览器关闭时会被清除 。关于这些cookie替代品的用法，建议大家查阅MDN来进行了解。 "},"Python/第三方库/Django/09-Form和ModelForm组件.html":{"url":"Python/第三方库/Django/09-Form和ModelForm组件.html","title":"Form、ModelForm组件","keywords":"","body":"datetime:2019/6/27 10:07 author:nzb Form和ModelForm组件 Form介绍 我们之前在HTML页面中利用form表单向后端提交数据时，都会写一些获取用户输入的标签并且用form标签把它们包起来。 与此同时我们在好多场景下都需要对用户的输入做校验，比如校验用户是否输入，输入的长度和格式等正不正确。如果用户输入的内容有错误就需要在页面上相应的位置显示对应的错误信息.。 Django form组件就实现了上面所述的功能。 总结一下，其实form组件的主要功能如下: 生成页面可用的HTML标签 对用户提交的数据进行校验 保留上次输入内容 普通方式手写注册功能 views.py # 注册 def register(request): error_msg = \"\" if request.method == \"POST\": username = request.POST.get(\"name\") pwd = request.POST.get(\"pwd\") # 对注册信息做校验 if len(username) login.html 注册页面 { % csrf_token % } 用户名: 密码： { { error_msg } } 使用form组件实现注册功能 views.py 先定义好一个RegForm类： from django import forms # 按照Django form组件的要求自己写一个类 class RegForm(forms.Form): name = forms.CharField(label=\"用户名\") pwd = forms.CharField(label=\"密码\") 再写一个视图函数： # 使用form组件实现注册方式 def register2(request): form_obj = RegForm() if request.method == \"POST\": # 实例化form对象的时候，把post提交过来的数据直接传进去 form_obj = RegForm(request.POST) # 调用form_obj校验数据的方法 if form_obj.is_valid(): return HttpResponse(\"注册成功\") return render(request, \"register2.html\", {\"form_obj\": form_obj}) login2.html 注册2 { % csrf_token % } { { form_obj.name.label } } { { form_obj.name } } { { form_obj.name.errors.0 } } { { form_obj.pwd.label } } { { form_obj.pwd } } { { form_obj.pwd.errors.0 } } 看网页效果发现 也验证了form的功能： 前端页面是form类的对象生成的 -->生成HTML标签功能 当用户名和密码输入为空或输错之后 页面都会提示 -->用户提交校验功能 当用户输错之后 再次输入 上次的内容还保留在input框 -->保留上次输入内容 Form那些事 常用字段与插件 创建Form类时，主要涉及到 【字段】 和 【插件】，字段用于对用户请求数据的验证，插件用于自动生成HTML; initial 初始值，input框里面的初始值。 class LoginForm(forms.Form): username = forms.CharField( min_length=8, label=\"用户名\", initial=\"张三\" **# 设置默认值** ) pwd = forms.CharField(min_length=6, label=\"密码\") error_messages 重写错误信息。 class LoginForm(forms.Form): username = forms.CharField( min_length=8, label=\"用户名\", initial=\"张三\", error_messages={ \"required\": \"不能为空\", \"invalid\": \"格式错误\", \"min_length\": \"用户名最短8位\" }, widget=forms.widgets.TextInput(attrs={'class': 'c1'}, render_value=True) ) pwd = forms.CharField(min_length=6, label=\"密码\") password class LoginForm(forms.Form): ... pwd = forms.CharField( min_length=6, label=\"密码\", widget=forms.widgets.PasswordInput( attrs={'class': 'c1'}, # **标签属性** render_value=True) # **表单值是否返回** ) radioSelect 单radio值为字符串 class LoginForm(forms.Form): username = forms.CharField( min_length=8, label=\"用户名\", initial=\"张三\", error_messages={ \"required\": \"不能为空\", \"invalid\": \"格式错误\", \"min_length\": \"用户名最短8位\" } ) pwd = forms.CharField(min_length=6, label=\"密码\") gender = forms.ChoiceField( choices=((1, \"男\"), (2, \"女\"), (3, \"保密\")), label=\"性别\", initial=3, widget=forms.widgets.RadioSelect() ) 单选Select class LoginForm(forms.Form): ... hobby = forms.ChoiceField( choices=((1, \"篮球\"), (2, \"足球\"), (3, \"双色球\"), ), label=\"爱好\", initial=3, widget=forms.widgets.Select() ) 多选Select class LoginForm(forms.Form): ... hobby = forms.MultipleChoiceField( choices=((1, \"篮球\"), (2, \"足球\"), (3, \"双色球\"), ), label=\"爱好\", initial=[1, 3], widget=forms.widgets.SelectMultiple() ) 单选checkbox class LoginForm(forms.Form): ... keep = forms.ChoiceField( label=\"是否记住密码\", initial=\"checked\", widget=forms.widgets.CheckboxInput() ) 多选checkbox class LoginForm(forms.Form): ... hobby = forms.MultipleChoiceField( choices=((1, \"篮球\"), (2, \"足球\"), (3, \"双色球\"),), label=\"爱好\", initial=[1, 3], widget=forms.widgets.CheckboxSelectMultiple() ) choice字段注意事项 在使用选择标签时，需要注意choices的选项可以配置从数据库中获取，但是由于是静态字段获取的值无法实时更新，需要重写构造方法从而实现choice实时更新。 方式一： from django.forms import Form from django.forms import widgets from django.forms import fields class MyForm(Form): user = fields.ChoiceField( # choices=((1, '上海'), (2, '北京'),), initial=2, widget=widgets.Select ) def __init__(self, *args, **kwargs): super(MyForm,self).__init__(*args, **kwargs) # self.fields['user'].choices = ((1, '上海'), (2, '北京'),) # 或 self.fields['user'].choices = models.Classes.objects.all().values_list('id','caption') 方式二： from django import forms from django.forms import fields from django.forms import models as form_model class FInfo(forms.Form): authors = form_model.ModelMultipleChoiceField(queryset=models.NNewType.objects.all()) # 多选 # authors = form_model.ModelChoiceField(queryset=models.NNewType.objects.all()) # 单选 Django Form所有内置字段 Field required=True, 是否允许为空 widget=None, HTML插件 label=None, 用于生成Label标签或显示内容 initial=None, 初始值 help_text='', 帮助信息(在标签旁边显示) error_messages=None, 错误信息 {'required': '不能为空', 'invalid': '格式错误'} validators=[], 自定义验证规则 localize=False, 是否支持本地化 disabled=False, 是否可以编辑 label_suffix=None Label内容后缀 CharField(Field) max_length=None, 最大长度 min_length=None, 最小长度 strip=True 是否移除用户输入空白 IntegerField(Field) max_value=None, 最大值 min_value=None, 最小值 FloatField(IntegerField) ... DecimalField(IntegerField) max_value=None, 最大值 min_value=None, 最小值 max_digits=None, 总长度 decimal_places=None, 小数位长度 BaseTemporalField(Field) input_formats=None 时间格式化 DateField(BaseTemporalField) 格式：2015-09-01 TimeField(BaseTemporalField) 格式：11:12 DateTimeField(BaseTemporalField)格式：2015-09-01 11:12 DurationField(Field) 时间间隔：%d %H:%M:%S.%f ... RegexField(CharField) regex, 自定制正则表达式 max_length=None, 最大长度 min_length=None, 最小长度 error_message=None, 忽略，错误信息使用 error_messages={'invalid': '...'} EmailField(CharField) ... FileField(Field) allow_empty_file=False 是否允许空文件 ImageField(FileField) ... 注：需要PIL模块，pip3 install Pillow 以上两个字典使用时，需要注意两点： - form表单中 enctype=\"multipart/form-data\" - view函数中 obj = MyForm(request.POST, request.FILES) URLField(Field) ... BooleanField(Field) ... NullBooleanField(BooleanField) ... ChoiceField(Field) ... choices=(), 选项，如：choices = ((0,'上海'),(1,'北京'),) required=True, 是否必填 widget=None, 插件，默认select插件 label=None, Label内容 initial=None, 初始值 help_text='', 帮助提示 ModelChoiceField(ChoiceField) ... django.forms.models.ModelChoiceField queryset, # 查询数据库中的数据 empty_label=\"---------\", # 默认空显示内容 to_field_name=None, # HTML中value的值对应的字段 limit_choices_to=None # ModelForm中对queryset二次筛选 ModelMultipleChoiceField(ModelChoiceField) ... django.forms.models.ModelMultipleChoiceField TypedChoiceField(ChoiceField) coerce = lambda val: val 对选中的值进行一次转换 empty_value= '' 空值的默认值 MultipleChoiceField(ChoiceField) ... TypedMultipleChoiceField(MultipleChoiceField) coerce = lambda val: val 对选中的每一个值进行一次转换 empty_value= '' 空值的默认值 ComboField(Field) fields=() 使用多个验证，如下：即验证最大长度20，又验证邮箱格式 fields.ComboField(fields=[fields.CharField(max_length=20), fields.EmailField(),]) MultiValueField(Field) PS: 抽象类，子类中可以实现聚合多个字典去匹配一个值，要配合MultiWidget使用 SplitDateTimeField(MultiValueField) input_date_formats=None, 格式列表：['%Y--%m--%d', '%m%d/%Y', '%m/%d/%y'] input_time_formats=None 格式列表：['%H:%M:%S', '%H:%M:%S.%f', '%H:%M'] FilePathField(ChoiceField) 文件选项，目录下文件显示在页面中 path, 文件夹路径 match=None, 正则匹配 recursive=False, 递归下面的文件夹 allow_files=True, 允许文件 allow_folders=False, 允许文件夹 required=True, widget=None, label=None, initial=None, help_text='' GenericIPAddressField protocol='both', both,ipv4,ipv6支持的IP格式 unpack_ipv4=False 解析ipv4地址，如果是::ffff:192.0.2.1时候，可解析为192.0.2.1， PS：protocol必须为both才能启用 SlugField(CharField) 数字，字母，下划线，减号（连字符） ... UUIDField(CharField) uuid类型 字段校验 RegexValidator验证器 from django.forms import Form from django.forms import widgets from django.forms import fields from django.core.validators import RegexValidator class MyForm(Form): user = fields.CharField( validators=[RegexValidator(r'^[0-9]+$', '请输入数字'), RegexValidator(r'^159[0-9]+$', '数字必须以159开头')], ) 自定义验证函数 import re from django.forms import Form from django.forms import widgets from django.forms import fields from django.core.exceptions import ValidationError # 自定义验证规则 def mobile_validate(value): mobile_re = re.compile(r'^(13[0-9]|15[012356789]|17[678]|18[0-9]|14[57])[0-9]{8}$') if not mobile_re.match(value): raise ValidationError('手机号码格式错误') class PublishForm(Form): title = fields.CharField(max_length=20, min_length=5, error_messages={'required': '标题不能为空', 'min_length': '标题最少为5个字符', 'max_length': '标题最多为20个字符'}, widget=widgets.TextInput(attrs={'class': \"form-control\", 'placeholder': '标题5-20个字符'})) # 使用自定义验证规则 phone = fields.CharField(validators=[mobile_validate, ], error_messages={'required': '手机不能为空'}, widget=widgets.TextInput(attrs={'class': \"form-control\", 'placeholder': u'手机号码'})) email = fields.EmailField(required=False, error_messages={'required': u'邮箱不能为空','invalid': u'邮箱格式错误'}, widget=widgets.TextInput(attrs={'class': \"form-control\", 'placeholder': u'邮箱'})) Hook方法 除了上面两种方式，我们还可以在Form类中定义钩子函数，来实现自定义的验证功能。 局部钩子 我们在Fom类中定义 clean_字段名() 方法，就能够实现对特定字段进行校验。 举个例子： class LoginForm(forms.Form): username = forms.CharField( min_length=8, label=\"用户名\", initial=\"张三\", error_messages={ \"required\": \"不能为空\", \"invalid\": \"格式错误\", \"min_length\": \"用户名最短8位\" }, widget=forms.widgets.TextInput(attrs={\"class\": \"form-control\"}) ) ... # 定义局部钩子，用来校验username字段 def clean_username(self): value = self.cleaned_data.get(\"username\") if \"666\" in value: raise ValidationError(\"光喊666是不行的\") else: return value 全局钩子 我们在Fom类中定义 clean() 方法，就能够实现对字段进行全局校验。 class LoginForm(forms.Form): ... password = forms.CharField( min_length=6, label=\"密码\", widget=forms.widgets.PasswordInput(attrs={'class': 'form-control'}, render_value=True) ) re_password = forms.CharField( min_length=6, label=\"确认密码\", widget=forms.widgets.PasswordInput(attrs={'class': 'form-control'}, render_value=True) ) ... # 定义全局的钩子，用来校验密码和确认密码字段是否相同 def clean(self): password_value = self.cleaned_data.get('password') re_password_value = self.cleaned_data.get('re_password') if password_value == re_password_value: return self.cleaned_data else: self.add_error('re_password', '两次密码不一致') raise ValidationError('两次密码不一致') 补充进阶 应用Bootstrap样式 login { % csrf_token % } { { form_obj.username.label } } { { form_obj.username } } { { form_obj.username.errors.0 } } { { form_obj.pwd.label } } { { form_obj.pwd } } { { form_obj.pwd.errors.0 } } { { form_obj.gender.label } } { % for radio in form_obj.gender % } { { radio.tag } }{ { radio.choice_label } } { % endfor % } 注册 批量添加样式 class LoginForm(forms.Form): username = forms.CharField( min_length=8, label=\"用户名\", initial=\"张三\", error_messages={ \"required\": \"不能为空\", \"invalid\": \"格式错误\", \"min_length\": \"用户名最短8位\" } ... def __init__(self, *args, **kwargs): super(LoginForm, self).__init__(*args, **kwargs) for field in iter(self.fields): self.fields[field].widget.attrs.update({ 'class': 'form-control' }) ModelForm 通常在Django项目中，我们编写的大部分都是与Django 的模型紧密映射的表单。 举个例子，你也许会有个Book 模型，并且你还想创建一个form表单用来添加和编辑书籍信息到这个模型中。 在这种情况下，在form表单中定义字段将是冗余的，因为我们已经在模型中定义了那些字段。 基于这个原因，Django 提供一个辅助类来让我们可以从Django 的模型创建Form，这就是ModelForm。 ModelForm定义 form与model的终极结合。 class BookForm(forms.ModelForm): class Meta: model = models.Book fields = \"__all__\" labels = { \"title\": \"书名\", \"price\": \"价格\" } widgets = { \"password\": forms.widgets.PasswordInput(attrs={\"class\": \"c1\"}), } class Meta下常用参数 model = models.Book # 对应的Model中的类 fields = \"__all__\" # 字段，如果是__all__,就是表示列出所有的字段 exclude = None # 排除的字段 labels = None # 提示信息 help_texts = None # 帮助提示信息 widgets = None # 自定义插件 error_messages = None # 自定义错误信息 ModelForm的验证 与普通的Form表单验证类型类似，ModelForm表单的验证在调用is_valid() 或访问errors 属性时隐式调用。 我们可以像使用Form类一样自定义局部钩子方法和全局钩子方法来实现自定义的校验规则。 如果我们不重写具体字段并设置validators属性的话，ModelForm是按照模型中字段的validators来校验的。 save()方法 每个ModelForm还具有一个save()方法。 这个方法根据表单绑定的数据创建并保存数据库对象。 ModelForm的子类可以接受现有的模型实例作为关键字参数instance；如果提供此功能，则save()将更新该实例。 如果没有提供，save() 将创建模型的一个新实例： >>> from myapp.models import Book >>> from myapp.forms import BookForm # 根据POST数据创建一个新的form对象 >>> form_obj = BookForm(request.POST) # 创建书籍对象 >>> new_ book = form_obj.save() # 基于一个书籍对象创建form对象 >>> edit_obj = Book.objects.get(id=1) # 使用POST提交的数据更新书籍对象 >>> form_obj = BookForm(request.POST, instance=edit_obj) >>> form_obj.save() 表单的应用(100天) 我们继续来完成上一章节中的项目，实现“用户注册”和“用户登录”的功能，并限制只有登录的用户才能为老师投票。Django框架中提供了对表单的封装，而且提供了多种不同的使用方式。 首先添加用户模型。 class User(models.Model): \"\"\"用户\"\"\" no = models.AutoField(primary_key=True, verbose_name='编号') username = models.CharField(max_length=20, unique=True, verbose_name='用户名') password = models.CharField(max_length=32, verbose_name='密码') regdate = models.DateTimeField(auto_now_add=True, verbose_name='注册时间') class Meta: db_table = 'tb_user' verbose_name_plural = '用户' 通过生成迁移和执行迁移操作，在数据库中创建对应的用户表。 (venv)$ python manage.py makemigrations vote ... (venv)$ python manage.py migrate ... 定制一个非常简单的注册模板页面。 用户注册 /* 此处省略层叠样式表选择器 */ 用户注册 { { hint } } { % csrf_token % } 用户名： 密码： 确认密码： 返回登录 注意，在上面的表单中，我们使用了模板指令{ % csrf_token % }为表单添加一个隐藏域（type属性值为hidden的input标签），它的作用是在表单中生成一个随机令牌（token）来防范跨站请求伪造（通常简称为CSRF），这也是Django在提交表单时的硬性要求，除非我们设置了免除CSRF令牌。下图是一个关于CSRF简单生动的例子，它来自于维基百科。 用户在提交注册表单时，我们还需要对用户的输入进行验证，例如我们的网站要求用户名必须由字母、数字、下划线构成且长度在4-20个字符之间，密码的长度为8-20个字符，确认密码必须跟密码保持一致。这些验证操作首先可以通过浏览器中的JavaScript代码来完成，但是即便如此，在服务器端仍然要对用户输入再次进行验证来避免将无效的数据库交给数据库，因为用户可能会禁用浏览器的JavaScript功能，也有可能绕过浏览器的输入检查将注册数据提交给服务器，所以服务器端的用户输入检查仍然是必要的。 我们可以利用Django框架封装的表单功能来对用户输入的有效性进行检查，虽然Django封装的表单还能帮助我们定制出页面上的表单元素，但这显然是一种灵活性很差的设计，这样的功能在实际开发中基本不考虑，所以表单主要的作用就在于数据验证，具体的做法如下所示。 USERNAME_PATTERN = re.compile(r'\\w{4,20}') class RegisterForm(forms.ModelForm): repassword = forms.CharField(min_length=8, max_length=20) def clean_username(self): username = self.cleaned_data['username'] if not USERNAME_PATTERN.fullmatch(username): raise ValidationError('用户名由字母、数字和下划线构成且长度为4-20个字符') return username def clean_password(self): password = self.cleaned_data['password'] if len(password) 20: raise ValidationError('无效的密码，密码长度为8-20个字符') return to_md5_hex(self.cleaned_data['password']) def clean_repassword(self): repassword = to_md5_hex(self.cleaned_data['repassword']) if repassword != self.cleaned_data['password']: raise ValidationError('密码和确认密码不一致') return repassword class Meta: model = User exclude = ('no', 'regdate') 上面，我们定义了一个与User模型绑定的表单（继承自ModelForm），我们排除了用户编号（no）和注册日期（regdate）这两个属性，并添加了一个repassword属性用来接收从用户表单传给服务器的确认密码。我们在定义User模型时已经对用户名的最大长度进行了限制，上面我们又对确认密码的最小和最大长度进行了限制，但是这些都不足以完成我们对用户输入的验证。上面以clean_打头的方法就是我们自定义的验证规则。很明显，clean_username是对用户名的检查，而clean_password是对密码的检查。由于数据库二维表中不应该保存密码的原文，所以对密码做了一个简单的MD5摘要处理，实际开发中如果只做出这样的处理还不太够，因为即便使用了摘要，仍然有利用彩虹表反向查询破解用户密码的风险，如何做得更好我们会在后续的内容中讲到。为字符串生成MD5摘要的代码如下所示。 def to_md5_hex(message): return hashlib.md5(message.encode()).hexdigest() 新增一个视图函数实现用户注册的功能。 def register(request): page, hint = 'register.html', '' if request.method == 'POST': form = RegisterForm(request.POST) if form.is_valid(): form.save() page = 'login.html' hint = '注册成功，请登录' else: hint = '请输入有效的注册信息' return render(request, page, {'hint': hint}) 如果用户发起GET请求，将直接跳转到注册的页面；如果用户以POST方式提交注册表单，则创建自定义的注册表单对象并获取用户输入。可以通过表单对象的is_valid方法对表单进行验证，如果用户输入没有问题，该方法返回True，否则返回False；由于我们定义的RegisterForm继承自ModelForm，因此也可以直接使用表单对象的save方法来保存模型。下面是注册请求的URL配置。 from django.contrib import admin from django.urls import path from vote import views urlpatterns = [ # 此处省略上面的代码 path('register/', views.register, name='register'), # 此处省略下面的代码 ] 说明：path函数可以通过name参数给URL绑定一个逆向解析的名字，也就是说，如果需要可以从后面给的名字逆向解析出对应的URL。 我们再来定制一个非常简单的登录页。 用户登录 /* 此处省略层叠样式表选择器 */ 用户登录 { { hint } } { % csrf_token % } 用户名： 密码： 验证码： 注册新用户 上面的登录页中，我们要求用户提供验证码，验证码全称是全自动区分计算机和人类的公开图灵测试，它是一种用来区分系统的使用者是计算机还是人类的程序。简单的说就是程序出一个只有人类能够回答的问题，由系统使用者来解答，由于计算机理论上无法解答程序提出的问题，所以回答出问题的用户就可以被认为是人类。大多数的网站都使用了不同类型的验证码技术来防范用程序自动注册用户或模拟用户登录（暴力破解用户密码），因为验证码具有一次消费性，而没有通过图灵测试的程序是不能够完成注册或登录的。 在Python程序中生成验证码并不算特别复杂，但需要三方库Pillow的支持（PIL的分支），因为要对验证码图片进行旋转、扭曲、拉伸以及加入干扰信息来防范那些用OCR（光学文字识别）破解验证码的程序。下面的代码封装了生成验证码图片的功能，大家可以直接用这些代码来生成图片验证码，不要“重复发明轮子”。 \"\"\" 图片验证码 \"\"\" import os import random from io import BytesIO from PIL import Image from PIL import ImageFilter from PIL.ImageDraw import Draw from PIL.ImageFont import truetype class Bezier(object): \"\"\"贝塞尔曲线\"\"\" def __init__(self): self.tsequence = tuple([t / 20.0 for t in range(21)]) self.beziers = {} def make_bezier(self, n): \"\"\"绘制贝塞尔曲线\"\"\" try: return self.beziers[n] except KeyError: combinations = pascal_row(n - 1) result = [] for t in self.tsequence: tpowers = (t ** i for i in range(n)) upowers = ((1 - t) ** i for i in range(n - 1, -1, -1)) coefs = [c * a * b for c, a, b in zip(combinations, tpowers, upowers)] result.append(coefs) self.beziers[n] = result return result class Captcha(object): \"\"\"验证码\"\"\" def __init__(self, width, height, fonts=None, color=None): self._image = None self._fonts = fonts if fonts else \\ [os.path.join(os.path.dirname(__file__), 'fonts', font) for font in ['ArialRB.ttf', 'ArialNI.ttf', 'Georgia.ttf', 'Kongxin.ttf']] self._color = color if color else random_color(0, 200, random.randint(220, 255)) self._width, self._height = width, height @classmethod def instance(cls, width=200, height=75): prop_name = f'_instance_{width}_{height}' if not hasattr(cls, prop_name): setattr(cls, prop_name, cls(width, height)) return getattr(cls, prop_name) def background(self): \"\"\"绘制背景\"\"\" Draw(self._image).rectangle([(0, 0), self._image.size], fill=random_color(230, 255)) def smooth(self): \"\"\"平滑图像\"\"\" return self._image.filter(ImageFilter.SMOOTH) def curve(self, width=4, number=6, color=None): \"\"\"绘制曲线\"\"\" dx, height = self._image.size dx /= number path = [(dx * i, random.randint(0, height)) for i in range(1, number)] bcoefs = Bezier().make_bezier(number - 1) points = [] for coefs in bcoefs: points.append(tuple(sum([coef * p for coef, p in zip(coefs, ps)]) for ps in zip(*path))) Draw(self._image).line(points, fill=color if color else self._color, width=width) def noise(self, number=50, level=2, color=None): \"\"\"绘制扰码\"\"\" width, height = self._image.size dx, dy = width / 10, height / 10 width, height = width - dx, height - dy draw = Draw(self._image) for i in range(number): x = int(random.uniform(dx, width)) y = int(random.uniform(dy, height)) draw.line(((x, y), (x + level, y)), fill=color if color else self._color, width=level) def text(self, captcha_text, fonts, font_sizes=None, drawings=None, squeeze_factor=0.75, color=None): \"\"\"绘制文本\"\"\" color = color if color else self._color fonts = tuple([truetype(name, size) for name in fonts for size in font_sizes or (65, 70, 75)]) draw = Draw(self._image) char_images = [] for c in captcha_text: font = random.choice(fonts) c_width, c_height = draw.textsize(c, font=font) char_image = Image.new('RGB', (c_width, c_height), (0, 0, 0)) char_draw = Draw(char_image) char_draw.text((0, 0), c, font=font, fill=color) char_image = char_image.crop(char_image.getbbox()) for drawing in drawings: d = getattr(self, drawing) char_image = d(char_image) char_images.append(char_image) width, height = self._image.size offset = int((width - sum(int(i.size[0] * squeeze_factor) for i in char_images[:-1]) - char_images[-1].size[0]) / 2) for char_image in char_images: c_width, c_height = char_image.size mask = char_image.convert('L').point(lambda i: i * 1.97) self._image.paste(char_image, (offset, int((height - c_height) / 2)), mask) offset += int(c_width * squeeze_factor) @staticmethod def warp(image, dx_factor=0.3, dy_factor=0.3): \"\"\"图像扭曲\"\"\" width, height = image.size dx = width * dx_factor dy = height * dy_factor x1 = int(random.uniform(-dx, dx)) y1 = int(random.uniform(-dy, dy)) x2 = int(random.uniform(-dx, dx)) y2 = int(random.uniform(-dy, dy)) warp_image = Image.new( 'RGB', (width + abs(x1) + abs(x2), height + abs(y1) + abs(y2))) warp_image.paste(image, (abs(x1), abs(y1))) width2, height2 = warp_image.size return warp_image.transform( (width, height), Image.QUAD, (x1, y1, -x1, height2 - y2, width2 + x2, height2 + y2, width2 - x2, -y1)) @staticmethod def offset(image, dx_factor=0.1, dy_factor=0.2): \"\"\"图像偏移\"\"\" width, height = image.size dx = int(random.random() * width * dx_factor) dy = int(random.random() * height * dy_factor) offset_image = Image.new('RGB', (width + dx, height + dy)) offset_image.paste(image, (dx, dy)) return offset_image @staticmethod def rotate(image, angle=25): \"\"\"图像旋转\"\"\" return image.rotate(random.uniform(-angle, angle), Image.BILINEAR, expand=1) def generate(self, captcha_text='', fmt='PNG'): \"\"\"生成验证码(文字和图片)\"\"\" self._image = Image.new('RGB', (self._width, self._height), (255, 255, 255)) self.background() self.text(captcha_text, self._fonts, drawings=['warp', 'rotate', 'offset']) self.curve() self.noise() self.smooth() image_bytes = BytesIO() self._image.save(image_bytes, format=fmt) return image_bytes.getvalue() def pascal_row(n=0): \"\"\"生成Pascal三角第n行\"\"\" result = [1] x, numerator = 1, n for denominator in range(1, n // 2 + 1): x *= numerator x /= denominator result.append(x) numerator -= 1 if n & 1 == 0: result.extend(reversed(result[:-1])) else: result.extend(reversed(result)) return result def random_color(start=0, end=255, opacity=255): \"\"\"获得随机颜色\"\"\" red = random.randint(start, end) green = random.randint(start, end) blue = random.randint(start, end) if opacity is None: return red, green, blue return red, green, blue, opacity 说明：上面的代码在生成验证码图片时用到了三种字体文件，使用上面的代码时需要添加字体文件到应用目录下的fonts目录中。 下面的视图函数用来生成验证码并通过HttpResponse对象输出到用户浏览器中。 ALL_CHARS = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' def get_captcha_text(length=4): selected_chars = random.choices(ALL_CHARS, k=length) return ''.join(selected_chars) def get_captcha(request): \"\"\"获得验证码\"\"\" captcha_text = get_captcha_text() image = Captcha.instance().generate(captcha_text) return HttpResponse(image, content_type='image/png') 生成的验证码如下图所示。 为了验证用户提交的登录表单，我们再定义个表单类。 class LoginForm(forms.Form): username = forms.CharField(min_length=4, max_length=20) password = forms.CharField(min_length=8, max_length=20) captcha = forms.CharField(min_length=4, max_length=4) def clean_username(self): username = self.cleaned_data['username'] if not USERNAME_PATTERN.fullmatch(username): raise ValidationError('无效的用户名') return username def clean_password(self): return to_md5_hex(self.cleaned_data['password']) 跟之前我们定义的注册表单类略有区别，登录表单类直接继承自Form没有跟模型绑定，定义了三个字段分别对应登录表单中的用户名、密码和验证码。接下来是处理用户登录的视图函数。 def login(request): hint = '' if request.method == 'POST': form = LoginForm(request.POST) if form.is_valid(): username = form.cleaned_data['username'] password = form.cleaned_data['password'] user = User.objects.filter(username=username, password=password).first() if user: return redirect('/') else: hint = '用户名或密码错误' else: hint = '请输入有效的登录信息' return render(request, 'login.html', {'hint': hint}) 映射URL。 from django.contrib import admin from django.urls import path from vote import views urlpatterns = [ # 此处省略上面的代码 path('login/', views.login, name='login'), # 此处省略下面的代码 ] 需要指出，上面我们设定用户登录成功时直接返回首页，而且在用户登录时并没有验证用户输入的验证码是否正确，这些我们留到下一个单元再为大家讲解。另外，如果要在Django自带的管理后台中进行表单验证，可以在admin.py的模型管理类中指定form属性为自定义的表单即可，例如： class UserForm(forms.ModelForm): password = forms.CharField(min_length=8, max_length=20, widget=forms.PasswordInput, label='密码') def clean_username(self): username = self.cleaned_data['username'] if not USERNAME_PATTERN.fullmatch(username): raise ValidationError('用户名由字母、数字和下划线构成且长度为4-20个字符') return username def clean_password(self): password = self.cleaned_data['password'] return to_md5_hex(self.cleaned_data['password']) class Meta: model = User exclude = ('no', ) class UserAdmin(admin.ModelAdmin): list_display = ('no', 'username', 'password', 'email', 'tel') ordering = ('no', ) form = UserForm list_per_page = 10 admin.site.register(User, UserAdmin) "},"Python/第三方库/Django/10-中间件.html":{"url":"Python/第三方库/Django/10-中间件.html","title":"中间件","keywords":"","body":"datetime:2019/6/28 14:13 author:nzb Django中间件 前戏 我们在前面的课程中已经学会了给视图函数加装饰器来判断是用户是否登录，把没有登录的用户请求跳转到登录页面。 我们通过给几个特定视图函数加装饰器实现了这个需求。但是以后添加的视图函数可能也需要加上装饰器，这样是不是稍微有点繁琐。 学完今天的内容之后呢，我们就可以用更适宜的方式来实现类似给所有请求都做相同操作的功能了 中间件 中间件介绍 什么是中间件? 官方的说法：中间件是一个用来处理Django的请求和响应的框架级别的钩子。它是一个轻量、低级别的插件系统，用于在全局范围内改变Django的输入和输出。 每个中间件组件都负责做一些特定的功能。 但是由于其影响的是全局，所以需要谨慎使用，使用不当会影响性能。 说的直白一点中间件是帮助我们在视图函数执行之前和执行之后都可以做一些额外的操作，它本质上就是一个自定义类，类中定义了几个方法， Django框架会在请求的特定的时间去执行这些方法。 我们一直都在使用中间件，只是没有注意到而已，打开Django项目的Settings.py文件，看到下图的MIDDLEWARE配置项。 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] MIDDLEWARE配置项是一个列表，列表中是一个个字符串，这些字符串其实是一个个类，也就是一个个中间件。 我们之前已经接触过一个csrf相关的中间件了？我们一开始让大家把他注释掉，再提交post请求的时候，就不会被forbidden了， 后来学会使用csrf_token之后就不再注释这个中间件了。 那接下来就学习中间件中的方法以及这些方法什么时候被执行。 自定义中间件 中间件可以定义五个方法，分别是：（主要的是process_request和process_response） process_request(self,request) process_view(self, request, view_func, view_args, view_kwargs) process_template_response(self,request,response) process_exception(self, request, exception) process_response(self, request, response) 以上方法的返回值可以是None或一个HttpResponse对象，如果是None，则继续按照django定义的规则向后继续执行，如果是HttpResponse对象， 则直接将该对象返回给用户。 自定义一个中间件 from django.utils.deprecation import MiddlewareMixin class MD1(MiddlewareMixin): def process_request(self, request): print(\"MD1里面的 process_request\") def process_response(self, request, response): print(\"MD1里面的 process_response\") return response process_request process_request有一个参数，就是request，这个request和视图函数中的request是一样的。 它的返回值可以是None也可以是HttpResponse对象。返回值是None的话，按正常流程继续走，交给下一个中间件处理，如果是HttpResponse对象， Django将不执行视图函数，而将相应对象返回给浏览器。 我们来看看多个中间件时，Django是如何执行其中的process_request方法的。 from django.utils.deprecation import MiddlewareMixin class MD1(MiddlewareMixin): def process_request(self, request): print(\"MD1里面的 process_request\") class MD2(MiddlewareMixin): def process_request(self, request): print(\"MD2里面的 process_request\") pass 在settings.py的MIDDLEWARE配置项中注册上述两个自定义中间件： MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'middlewares.MD1', # 自定义中间件MD1 'middlewares.MD2' # 自定义中间件MD2 ] 此时，我们访问一个视图，会发现终端中打印如下内容： MD1里面的 process_request MD2里面的 process_request app01 中的 index视图 把MD1和MD2的位置调换一下，再访问一个视图，会发现终端中打印的内容如下： MD2里面的 process_request MD1里面的 process_request app01 中的 index视图 看结果我们知道：视图函数还是最后执行的，MD2比MD1先执行自己的process_request方法。 在打印一下两个自定义中间件中process_request方法中的request参数，会发现它们是同一个对象。 由此总结一下： 1、中间件的process_request方法是在执行视图函数之前执行的。 2、当配置多个中间件时，会按照MIDDLEWARE中的注册顺序，也就是列表的索引值，从前到后依次执行的。 3、不同中间件之间传递的request都是同一个对象 多个中间件中的process_response方法是按照MIDDLEWARE中的注册顺序倒序执行的，也就是说第一个中间件的process_request方法首先执行， 而它的process_response方法最后执行，最后一个中间件的process_request方法最后一个执行，它的process_response方法是最先执行。 process_response 它有两个参数，一个是request，一个是response，request就是上述例子中一样的对象，response是视图函数返回的HttpResponse对象。 该方法的返回值也必须是HttpResponse对象。 给上述的M1和M2加上process_response方法： from django.utils.deprecation import MiddlewareMixin class MD1(MiddlewareMixin): def process_request(self, request): print(\"MD1里面的 process_request\") def process_response(self, request, response): print(\"MD1里面的 process_response\") return response class MD2(MiddlewareMixin): def process_request(self, request): print(\"MD2里面的 process_request\") pass def process_response(self, request, response): print(\"MD2里面的 process_response\") return response 访问一个视图，看一下终端的输出： MD2里面的 process_request MD1里面的 process_request app01 中的 index视图 MD1里面的 process_response MD2里面的 process_response 看结果可知： process_response方法是在视图函数之后执行的，并且顺序是MD1比MD2先执行。(此时settings.py中 MD2比MD1先注册) 多个中间件中的process_response方法是按照MIDDLEWARE中的注册顺序倒序执行的，也就是说第一个中间件的process_request方法首先执行， 而它的process_response方法最后执行，最后一个中间件的process_request方法最后一个执行，它的process_response方法是最先执行。 process_view process_view(self, request, view_func, view_args, view_kwargs) 该方法有四个参数 request是HttpRequest对象。 view_func是Django即将使用的视图函数。 （它是实际的函数对象，而不是函数的名称作为字符串。） view_args是将传递给视图的位置参数的列表. view_kwargs是将传递给视图的关键字参数的字典。 view_args和view_kwargs都不包含第一个视图参数（request）。 Django会在调用视图函数之前调用process_view方法。 它应该返回None或一个HttpResponse对象。 如果返回None，Django将继续处理这个请求，执行任何其他中间件的process_view方法，然后在执行相应的视图。 如果它返回一个HttpResponse对象，Django不会调用适当的视图函数。 它将执行中间件的process_response方法并将应用到该HttpResponse并返回结果。 给MD1和MD2添加process_view方法: from django.utils.deprecation import MiddlewareMixin class MD1(MiddlewareMixin): def process_request(self, request): print(\"MD1里面的 process_request\") def process_response(self, request, response): print(\"MD1里面的 process_response\") return response def process_view(self, request, view_func, view_args, view_kwargs): print(\"-\" * 80) print(\"MD1 中的process_view\") print(view_func, view_func.__name__) class MD2(MiddlewareMixin): def process_request(self, request): print(\"MD2里面的 process_request\") pass def process_response(self, request, response): print(\"MD2里面的 process_response\") return response def process_view(self, request, view_func, view_args, view_kwargs): print(\"-\" * 80) print(\"MD2 中的process_view\") print(view_func, view_func.__name__) 访问index视图函数，看一下输出结果： MD2里面的 process_request MD1里面的 process_request -------------------------------------------------------------------------------- MD2 中的process_view index -------------------------------------------------------------------------------- MD1 中的process_view index app01 中的 index视图 MD1里面的 process_response MD2里面的 process_response process_view方法是在process_request之后，视图函数之前执行的，执行顺序按照MIDDLEWARE中的注册顺序从前到后顺序执行的 process_exception process_exception(self, request, exception) 该方法两个参数: 一个HttpRequest对象 一个exception是视图函数异常产生的Exception对象。 这个方法只有在视图函数中出现异常了才执行，它返回的值可以是一个None也可以是一个HttpResponse对象。如果是HttpResponse对象，Django将调用模板和中间件中的process_response方法，并返回给浏览器，否则将默认处理异常。如果返回一个None，则交给下一个中间件的process_exception方法来处理异常。它的执行顺序也是按照中间件注册顺序的倒序执行。 给MD1和MD2添加上这个方法： from django.utils.deprecation import MiddlewareMixin class MD1(MiddlewareMixin): def process_request(self, request): print(\"MD1里面的 process_request\") def process_response(self, request, response): print(\"MD1里面的 process_response\") return response def process_view(self, request, view_func, view_args, view_kwargs): print(\"-\" * 80) print(\"MD1 中的process_view\") print(view_func, view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD1 中的process_exception\") class MD2(MiddlewareMixin): def process_request(self, request): print(\"MD2里面的 process_request\") pass def process_response(self, request, response): print(\"MD2里面的 process_response\") return response def process_view(self, request, view_func, view_args, view_kwargs): print(\"-\" * 80) print(\"MD2 中的process_view\") print(view_func, view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD2 中的process_exception\") 如果视图函数中无异常，process_exception方法不执行。 想办法，在视图函数中抛出一个异常： def index(request): print(\"app01 中的 index视图\") raise ValueError(\"呵呵\") return HttpResponse(\"O98K\") 在MD1的process_exception中返回一个响应对象： class MD1(MiddlewareMixin): def process_request(self, request): print(\"MD1里面的 process_request\") def process_response(self, request, response): print(\"MD1里面的 process_response\") return response def process_view(self, request, view_func, view_args, view_kwargs): print(\"-\" * 80) print(\"MD1 中的process_view\") print(view_func, view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD1 中的process_exception\") return HttpResponse(str(exception)) # 返回一个响应对象 看输出结果： MD2里面的 process_request MD1里面的 process_request -------------------------------------------------------------------------------- MD2 中的process_view index -------------------------------------------------------------------------------- MD1 中的process_view index app01 中的 index视图 呵呵 MD1 中的process_exception MD1里面的 process_response MD2里面的 process_response 注意，这里并没有执行MD2的process_exception方法，因为MD1中的process_exception方法直接返回了一个响应对象。 proc process_template_response(用的比较少) process_template_response(self, request, response) 它的参数，一个HttpRequest对象，response是TemplateResponse对象（由视图函数或者中间件产生）。 process_template_response是在视图函数执行完成后立即执行，但是它有一个前提条件，那就是视图函数返回的对象有一个render()方法 （或者表明该对象是一个TemplateResponse对象或等价方法）。 class MD1(MiddlewareMixin): def process_request(self, request): print(\"MD1里面的 process_request\") def process_response(self, request, response): print(\"MD1里面的 process_response\") return response def process_view(self, request, view_func, view_args, view_kwargs): print(\"-\" * 80) print(\"MD1 中的process_view\") print(view_func, view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD1 中的process_exception\") return HttpResponse(str(exception)) def process_template_response(self, request, response): print(\"MD1 中的process_template_response\") return response class MD2(MiddlewareMixin): def process_request(self, request): print(\"MD2里面的 process_request\") pass def process_response(self, request, response): print(\"MD2里面的 process_response\") return response def process_view(self, request, view_func, view_args, view_kwargs): print(\"-\" * 80) print(\"MD2 中的process_view\") print(view_func, view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD2 中的process_exception\") def process_template_response(self, request, response): print(\"MD2 中的process_template_response\") return response views.py中： def index(request): print(\"app01 中的 index视图\") def render(): print(\"in index/render\") return HttpResponse(\"O98K\") rep = HttpResponse(\"OK\") rep.render = render return rep 访问index视图，终端输出的结果： MD2里面的 process_request MD1里面的 process_request -------------------------------------------------------------------------------- MD2 中的process_view index -------------------------------------------------------------------------------- MD1 中的process_view index app01 中的 index视图 MD1 中的process_template_response MD2 中的process_template_response in index/render MD1里面的 process_response MD2里面的 process_response 从结果看出： 视图函数执行完之后，立即执行了中间件的process_template_response方法，顺序是倒序，先执行MD1的，在执行MD2的， 接着执行了视图函数返回的HttpResponse对象的render方法，返回了一个新的HttpResponse对象，接着执行中间件的process_response方法。 中间件的执行流程 上一部分，我们了解了中间件中的5个方法，它们的参数、返回值以及什么时候执行，现在总结一下中间件的执行流程。 请求到达中间件之后，先按照正序执行每个注册中间件的process_reques方法，process_request方法返回的值是None，就依次执行， 如果返回的值是HttpResponse对象，不再执行后面的process_request方法，而是执行当前对应中间件的process_response方法， 将HttpResponse对象返回给浏览器。也就是说：如果MIDDLEWARE中注册了6个中间件，执行过程中，第3个中间件返回了一个HttpResponse对象， 那么第4,5,6中间件的process_request和process_response方法都不执行，顺序执行3,2,1中间件的process_response方法。 process_request方法都执行完后，匹配路由，找到要执行的视图函数，先不执行视图函数，先执行中间件中的process_view方法， process_view方法返回None，继续按顺序执行，所有process_view方法执行完后执行视图函数。 加入中间件3 的process_view方法返回了HttpResponse对象，则4,5,6的process_view以及视图函数都不执行，直接从最后一个中间件， 也就是中间件6的process_response方法开始倒序执行。 process_template_response和process_exception两个方法的触发是有条件的，执行顺序也是倒序。总结所有的执行流程如下： 中间件版登陆验证 中间件版的登录验证需要依靠session，所以数据库中要有django_session表。 urls.py from django.conf.urls import url from app01 import views urlpatterns = [ url(r'^index/$', views.index), url(r'^login/$', views.login, name='login'), ] views.py from django.shortcuts import render, HttpResponse, redirect def index(request): return HttpResponse('this is index') def home(request): return HttpResponse('this is home') def login(request): if request.method == \"POST\": user = request.POST.get(\"user\") pwd = request.POST.get(\"pwd\") if user == \"Q1mi\" and pwd == \"123456\": # 设置session request.session[\"user\"] = user # 获取跳到登陆页面之前的URL next_url = request.GET.get(\"next\") # 如果有，就跳转回登陆之前的URL if next_url: return redirect(next_url) # 否则默认跳转到index页面 else: return redirect(\"/index/\") return render(request, \"login.html\") login.html 登录页面 用户名： 密 码： middlewares.py class AuthMD(MiddlewareMixin): white_list = ['/login/', ] # 白名单 balck_list = ['/black/', ] # 黑名单 def process_request(self, request): from django.shortcuts import redirect, HttpResponse next_url = request.path_info print(request.path_info, request.get_full_path()) if next_url in self.white_list or request.session.get(\"user\"): return elif next_url in self.balck_list: return HttpResponse('This is an illegal URL') else: return redirect(\"/login/?next={}\".format(next_url)) 在settings.py中注册 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'middlewares.AuthMD', ] AuthMD中间件注册后，所有的请求都要走AuthMD的process_request方法。 访问的URL在白名单内或者session中有user用户名，则不做阻拦走正常流程； 如果URL在黑名单中，则返回This is an illegal URL的字符串； 正常的URL但是需要登录后访问，让浏览器跳转到登录页面。 注：AuthMD中间件中需要session，所以AuthMD注册的位置要在session中间的下方。 附：Django请求流程图 中间件的应用(100天) 实现登录验证 我们继续来完善投票应用。在上一个章节中，我们在用户登录成功后通过session保留了用户信息，接下来我们可以应用做一些调整，要求在为老师投票时必须要先登录，登录过的用户可以投票，否则就将用户引导到登录页面，为此我们可以这样修改视图函数。 def praise_or_criticize(request: HttpRequest): \"\"\"投票\"\"\" if 'username' in request.session: try: tno = int(request.GET.get('tno', '0')) teacher = Teacher.objects.get(no=tno) if request.path.startswith('/praise'): teacher.good_count += 1 else: teacher.bad_count += 1 teacher.save() data = {'code': 200, 'message': '操作成功'} except (ValueError, Teacher.DoesNotExist): data = {'code': 404, 'message': '操作失败'} else: data = {'code': 401, 'message': '请先登录'} return JsonResponse(data) 前端页面在收到{'code': 401, 'message': '请先登录'}后，可以将用户引导到登录页面，修改后的teacher.html页面的JavaScript代码部门如下所示。 $(() => { $('.comment > a').on('click', (evt) => { evt.preventDefault() let a = $(evt.target) $.getJSON(a.attr('href'), (json) => { if (json.code == 200) { let span = a.next() span.text(parseInt(span.text()) + 1) } else if (json.code == 401) { location.href = '/login/?backurl=' + location.href } else { alert(json.message) } }) }) }) 注意：为了在登录成功之后能够回到刚才投票的页面，我们在跳转登录时设置了一个backurl参数，把当前浏览器中的URL作为返回的页面地址。 这样我们已经实现了用户必须登录才能投票的限制，但是一个新的问题来了。如果我们的应用中有很多功能都需要用户先登录才能执行，例如将前面导出Excel报表和查看统计图表的功能都加以登录限制，那么我们是不是需要在每个视图函数中添加代码来检查session中是否包含了登录用户的信息呢？答案是否定的，如果这样做了，我们的视图函数中必然会充斥着大量的重复代码。编程大师Martin Fowler曾经说过：代码有很多种坏味道，重复是最坏的一种。在Django项目中，我们可以把验证用户是否登录这样的重复性代码放到中间件中。 Django中间件概述 中间件是安插在Web应用请求和响应过程之间的组件，它在整个Web应用中扮演了拦截过滤器的角色，通过中间件可以拦截请求和响应，并对请求和响应进行过滤（简单的说就是执行额外的处理）。通常，一个中间件组件只专注于完成一件特定的事，例如：Django框架通过SessionMiddleware中间件实现了对session的支持，又通过AuthenticationMiddleware中间件实现了基于session的请求认证。通过把多个中间件组合在一起，我们可以完成更为复杂的任务，Django框架就是这么做的。 Django项目的配置文件中就包含了对中间件的配置，代码如下所示。 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] 我们稍微为大家解释一下这些中间件的作用： CommonMiddleware - 基础设置中间件，可以处理以下一些配置参数。 DISALLOWED_USER_AGENTS - 不被允许的用户代理（浏览器） APPEND_SLASH - 是否追加/ USE_ETAG - 浏览器缓存相关 SecurityMiddleware - 安全相关中间件，可以处理和安全相关的配置项。 SECURE_HSTS_SECONDS - 强制使用HTTPS的时间 SECURE_HSTS_INCLUDE_SUBDOMAINS - HTTPS是否覆盖子域名 SECURE_CONTENT_TYPE_NOSNIFF - 是否允许浏览器推断内容类型 SECURE_BROWSER_XSS_FILTER - 是否启用跨站脚本攻击过滤器 SECURE_SSL_REDIRECT - 是否重定向到HTTPS连接 SECURE_REDIRECT_EXEMPT - 免除重定向到HTTPS SessionMiddleware - 会话中间件。 CsrfViewMiddleware - 通过生成令牌，防范跨请求份伪的造中间件。 XFrameOptionsMiddleware - 通过设置请求头参数，防范点击劫持攻击的中间件。 在请求的过程中，上面的中间件会按照书写的顺序从上到下执行，然后是URL解析，最后请求才会来到视图函数；在响应的过程中，上面的中间件会按照书写的顺序从下到上执行，与请求时中间件执行的顺序正好相反。 自定义中间件 Django中的中间件有两种实现方式：基于类的实现方式和基于函数的实现方式，后者更接近于装饰器的写法。装饰器实际上是代理模式的应用，将横切关注功能（与正常业务逻辑没有必然联系的功能，例如：身份认证、日志记录、编码转换之类的功能）置于代理中，由代理对象来完成被代理对象的行为并添加额外的功能。中间件对用户请求和响应进行拦截过滤并增加额外的处理，在这一点上它跟装饰器是完全一致的，所以基于函数的写法来实现中间件就跟装饰器的写法几乎一模一样。下面我们用自定义的中间件来实现用户登录验证的功能。 \"\"\" middlewares.py \"\"\" from django.http import JsonResponse from django.shortcuts import redirect # 需要登录才能访问的资源路径 LOGIN_REQUIRED_URLS = { '/praise/', '/criticize/', '/excel/', '/teachers_data/', } def check_login_middleware(get_resp): def wrapper(request, *args, **kwargs): # 请求的资源路径在上面的集合中 if request.path in LOGIN_REQUIRED_URLS: # 会话中包含userid则视为已经登录 if 'userid' not in request.session: # 判断是不是Ajax请求 if request.is_ajax(): # Ajax请求返回JSON数据提示用户登录 return JsonResponse({'code': 10003, 'hint': '请先登录'}) else: backurl = request.get_full_path() # 非Ajax请求直接重定向到登录页 return redirect(f'/login/?backurl={backurl}') return get_resp(request, *args, **kwargs) return wrapper 修改配置文件，激活中间件使其生效。 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'debug_toolbar.middleware.DebugToolbarMiddleware', 'vote.middlewares.check_login_middleware', ] 注意上面这个中间件列表中元素的顺序，当收到来自用户的请求时，中间件按照从上到下的顺序依次执行，这行完这些中间件以后，请求才会最终到达视图函数。当然，在这个过程中，用户的请求可以被拦截，就像上面我们自定义的中间件那样，如果用户在没有登录的情况下访问了受保护的资源，中间件会将请求直接重定向到登录页，后面的中间件和视图函数将不再执行。在响应用户请求的过程中，上面的中间件会按照从下到上的顺序依次执行，这样的话我们还可以对响应做进一步的处理。 中间件执行的顺序是非常重要的，对于有依赖关系的中间件必须保证被依赖的中间件要置于依赖它的中间件的前面，就好比我们刚才自定义的中间件要放到SessionMiddleware的后面，因为我们要依赖这个中间件为请求绑定的session对象才能判定用户是否登录。 小结 至此，除了对用户投票数量加以限制的功能外，这个投票应用就算基本完成了，整个项目的完整代码请参考https://github.com/jackfrued/django1902，其中用户注册时使用的手机验证码功能请大家使用自己注册的短信平台替代它。如果需要投票应用完整的视频讲解，可以在首页扫码打赏后留言联系作者获取视频下载地址，谢谢大家的理解和支持。 "},"Python/第三方库/Django/Django-REST-framework.html":{"url":"Python/第三方库/Django/Django-REST-framework.html","title":"Django-REST-framework","keywords":"","body":"Django生命周期 a、wsgi wsgi：协议：web server getway interface web服务网关接口 wsgiref:是python实现wsgi协议的一个模块，模块的本质：一个socket服务端(django) werkzeug:是python实现wsgi协议的一个模块，模块的本质：一个socket服务端(Flask框架) tornado:是python实现wsgi协议的一个模块，模块的本质：一个socket服务端(Flask框架) uwsgi:是实现了wsgi协议的一个模块，模块本质：一个socket服务器 Django生命周期:(rest_framework) CBV,基于反射实现根据请求方式不同，执行不同的方法。 原理： 1、路由 url -> as_view()里的view方法 -> dispath方法（反射执行其他：GET/POST/DELETE/PUT） 2、流程 class StudentView(View): def dispath(self, request, *args, **kwargs): print('before') # 自己添加需求 ret = super(Student, self).dispath(request, *args, **kwargs) print('after') def get(self, request, *args, **kwargs): return HttpResponse('GET') def post(self, request, *args, **kwargs): return HttpResponse('POST') def put(self, request, *args, **kwargs): return HttpResponse('PUT') def delete(self, request, *args, **kwargs): return HttpResponse('DELETE') Django的rest_framework： 中间件 1、最多几个方法： process_request； process_view； process_response； process_exception； process_render_template； 执行流程： 首先进来执行所有的process_request然后路由匹配（找到函数不执行跳回去），然后再执行所有的process_view，然后再执行 视图函数，然后再执行process_response，如果报错执行process_exception，如果返回render则执行process_render_template。 2、用中间件做过什么： --利用它实现csrf_token，利用process_view中处理或装饰器 2.1、为什么用process_view而不用process_request? 因为用process_request的话如果用的是装饰器这需要到达路由匹配到函数才能知道是否加了装饰器， 而process_view已经路由匹配到函数，知道函数是否加了装饰器 --基于角色的权限控制 --用户认证 --csrf(说原理） --session(说原理） --黑名单 --日志记录 3、csrf --检查视图函数是否被 @csrf_exempt(免除csrf认证) --去请求体或cookie中获取token FBV: 情况一：FBV中，全局配置 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] from django.views.decorators.csrf import csrf_exempt @csrf_exempt # 该函数无需认证 def users(request): return HttpResponse('...') 情况二：全局注释，FBV中某些函数需要 from django.views.decorators.csrf import csrf_protect @csrf_protect # 该函数需认证 def users(request): return HttpResponse('...') CBV: # 单独在get，post。。。等中无效 方式一： from django.views.decorators.csrf import csrf_exempt,csrf_protect from django.utils.decorates import method_decorator class StudentView(View): @method_decorator(csrf_exempt) def dispath(self, request, *args, **kwargs): ret = super(Student, self).dispath(request, *args, **kwargs) def get(self, request, *args, **kwargs): return HttpResponse('GET') def post(self, request, *args, **kwargs): return HttpResponse('POST') def put(self, request, *args, **kwargs): return HttpResponse('PUT') def delete(self, request, *args, **kwargs): return HttpResponse('DELETE') 方式二： from django.views.decorators.csrf import csrf_exempt,csrf_protect from django.utils.decorates import method_decorator @method_decorator(csrf_exempt, name='dispath') class StudentView(View): def get(self, request, *args, **kwargs): return HttpResponse('GET') def post(self, request, *args, **kwargs): return HttpResponse('POST') def put(self, request, *args, **kwargs): return HttpResponse('PUT') def delete(self, request, *args, **kwargs): return HttpResponse('DELETE') 4、CBV 5、restful 3.1、10条规范 3.2、自己的认识 6、djangorestframework 5.1、如何验证（基于数据库实现用户认证） 5.2、源码流程（面向对象回顾流程） Django-Rest-framework组件 一、认证 1、使用 1.1、创建类：继承BaseAuthentication：实现：authenticate这个方法 1.2、返回值： 1.2.1、None，下一个认证类执行，全部都返回None，则返回匿名用户。 1.2.3、抛出异常，raise exceptions.AuthenticationFailed('用户认证失败') 1.2.3、返回元组，（元素1，元素2） 分别赋值给request.user，request.auth 1.3、局部使用： 需要认证的View:加上authentication_classes = [Authentication,] 1.4、全局使用：（使用路径） REST_FRAMEWORK = { # 全局使用的认证类 \"authentication_classes\": ['app01.utils.auth.Authentication',], # 匿名用户设置 # \"UNAUTHENTICATED_USER\": lambda :\"匿名用户\" \"UNAUTHENTICATED_USER\": None, # 推荐使用，匿名，因为request.user = None \"UNAUTHENTICATED_TOKEN\": None, # 匿名，因为request.auth = None } 2、源码流程 dispath -> 封装request -> 获取定义的认证类（全局/局部）,通过列表生成器创建对象 -> initial -> perform_authentication -> request.user -> Request里的user方法 -> _authenticate -> 最后执行自定义的认证类里的authenticate方法 3、示例 # 认证 # 访问进来第一步执行as_view()里面的view()里面的dispath,当前类没有找父类 class MyAuthentication(object): \"\"\" 认证源码流程 1.访问进来第一步执行dispath,当前类没有找父类 2.封装Request： initialize_request(request, *args, **kwargs) 3. initial(request, *args, **kwargs) # 这当中我们设置的raise异常都会在当前函数的下面捕获 4. perform_authentication(request) 5. request.user ————>去封装request的类里面找user()方法 6.user方法里面: _authenticate() 7._authenticate()里面循环认证类的所有对象 调用每个对象的authenticate()方法就是我们自己定义的 MyAuthentication里面的 authenticate() 8.最后反射到我们定义的View的get,post等等方法执行里面逻辑。 \"\"\" def authenticate(self, request): token = request._request.GET.get('token') # 获取用户名和密码，去数据库校验 if not token: raise exceptions.AuthenticationFailed('用户认证失败') # 返回元组（校验后的数据） return (\"nzb\", None) def authenticate_header(self, val): \"\"\" 认证失败给浏览器返回的响应头 :param val: :return: \"\"\" pass 二、权限 问题：不同的视图不同的权限 1、使用 class MyPermission(object): def has_permission(self, request, view): print(request.user) if request.user.user_type != 1: return False return True class OrderView(APIView): permission_classes = [MyPermission,] def get(self, request, *args, **kwargs): ret = {'code': 10000,'msg': None, 'data':None} try: ret['data'] = {'msg':'test'} except Exception as e: pass return JsonResponse(ret) 2、权限梳理 3.1、基本使用 3.1.1、类，必须继承rest-framework提供的类：BasePermission，必须实现：has_permission方法 from rest_framework.permissions import BasePermission class SvipPermission(BasePermission): # 定义错误信息 message = \"必须是SVIP才能访问\" def has_permission(self, request, view): # print(request.user) if request.user.user_type != 3: return False return True 3.1.2、返回值，True,有权访问，False,无权访问 3.1.3、局部使用： 需要认证的View:加上permission_classes = [SvipPermission,] 3.1.4、全局使用：（使用路径） REST_FRAMEWORK = { \"DEFAULT_PERMISSION_CLASSES\":['app01.utils.permission.SvipPermission',], } 3、源码流程 跟认证相似，执行完认证执行权限，类里面的has_permission方法。 三、频率控制(节流) 1、使用 -类，继承：BaseThrottle，实现：allow_request、wait方法 -类，继承：SimpleRateThrottle，实现：get_cache_key、scope = \"Lufei\" (配置文件中的key) 1.1、局部使用 class AuthView(APIView): \"\"\"用户认证\"\"\" # 因为全局配置了，但当前View认证，所以设置为空 authentication_classes = [] permission_classes = [] throttle_classes = [VisitThorttle, ] def post(self, request, *args, **kwargs): 1.2、全局使用 REST_FRAMEWORK = { # 访问频率控制 'DEFAULT_THROTTLE_CLASSES': ['app01.utils.throttle.UserThorttle', ], 'DEFAULT_THROTTLE_RATES': { 'Lufei': '3/m', # 匿名用户配置 一分钟三次 'LufeiUser': '3/m', # 用户配置 一分钟三次 } } import time VISIT_RECORD = {} # 放入缓存里 class VisitThorttle(object): def __init__(self): self.history = None def allow_request(self, request, view): \"\"\"60s内只能访问3次\"\"\" # 1、获取用户ip remote_addr = request._request.META.get('REMOTE_ADDR') ctime = time.time() if remote_addr not in VISIT_RECORD: VISIT_RECORD[remote_addr] = [ctime, ] return True self.history = VISIT_RECORD.get(remote_addr) # 把超出时间外的时间数据pop掉 while self.history and self.history[-1] 四、版本(全局配置就行) 1、URL中通过GET传参数 class ParamVersion(object): def determine_version(self, request, *args, **kwargs): version = request.query_params.get('version') return version class OrderView(APIView): versioning_class = ParamVersion ... 2、在URL中传参（推荐使用,正则表达式） # 版本配置类 \"DEFAULT_VERSIONING_CLASS\": 'rest_framework.versioning.URLPathVersioning', \"DEFAULT_VERSION\": 'v1', # 默认版本 \"ALLOWED_VERSIONS\": ['v1', 'v2'], # 允许版本 \"VERSION_PARAM\": 'version', # 版本参数 例：re_path('(?P[v1|v2]+)/', include(router.urls)) # 获取版本 # print(request.version) # 获取处理版本的对象 # print(request.versioning_scheme) # request.versioning_scheme # 反向生成url # print(request.versioning_scheme.reverse(viewname='order', request=request)) 五、解析器(全局配置就行) 1、前戏：django:request.POST/ request.body request.POST要有值需要满足以下2个要求： 1.1、请求头要求： Content-Type:application/x-www-form-urlencoded PS：如果请求头中的Content-Type:application/x-www-form-urlencoded，request.POST中才有值（去request.body中解析数据） 1.2、数据格式要求： name=alex&age=18&gender=男 如： a.form表单提交：默认带的是Content-Type:application/x-www-form-urlencoded b.ajax提交： $.ajax({ url:... type:POST data:{'name':'alex','age':18} # 内部转化成name=alex&age=18&gender=男，携带Content-Type:application/x-www-form-urlencoded提交 ... }) 情况一： $.ajax({ url:... type:POST headres:{'Content-Type':'application/json'} data:{'name':'alex','age':18} # 内部转化成name=alex&age=18&gender=男 ... # body有值，POST没有 }) 情况二： $.ajax({ url:... type:POST headres:{'Content-Type':'application/json'} data:JSON.stringfy({'name':'alex','age':18}) # {'name':'alex','age':18} ... # body有值，POST没有，但是可以用json.loads(request.body)得到 }) 2、rest-framework解析器，对请求体进行解析 2.1、全局配置 2.2、使用 class ParserView(APIView): \"\"\" JSONParser:表示只能解析content-type:application/json头,(最常用) FormParser:表示只能解析content-type:application/x-www-form-urlencoded头 \"\"\" def post(self, request, *args, **kwargs): \"\"\" 允许用户发送JSON格式数据 a.content-type:application/json b.{'name':'alex','age':18} :param request: :param args: :param kwargs: :return: \"\"\" # 获取解析后的结果，用了request.data才去解析 \"\"\" 1.获取用户请求 2.获取用户请求体 3.根据用户请求体和parser_classes = [JSONParser,]中支持的请求头进行比较 4.JSONParser对象处理请求体 5.request.data来触发的 \"\"\" print(request.data) return HttpResponse('ParserView') 2.3、想实现上传功能的话，局部视图配置 parser_classes = [FileUploadParser] 然后取文件： request.FILES 3、源码流程&本质： 3.1、本质 请求体 状态码 请求方法 3.2、源码流程 --dispath:request封装 --request.data 六、序列化 1、序列化： 1.1、写类，继承于Serializer(自定义生成字段)、ModelSerializer(自动生成字段，也是继承于Serializer) 1.2、字段： 1.2.1、name=serializers.CharField(source=\"xxx.xx.xx\") 1.2.2、roles = serializers.SerializerMethodField() # 自定义显示 class UserInfoSerializer(serializers.ModelSerializer): roles = serializers.SerializerMethodField() # 字段自定义显示 class Meta: model = UserInfo # fields = \"__all__\" fields = ['id', 'username', 'password', 'xxx', 'roles', 'group'] def get_roles(self, row): role_obj_list = row.roles.all() ret = [] for item in role_obj_list: ret.append({'id':item.id, 'name':item.name}) return ret 1.2.3、自定义字段类不常用 1.3、自动化序列化连表 class UserInfoSerializer(serializers.ModelSerializer): class Meta: model = UserInfo fields = \"__all__\" # fields = ['id', 'username', 'password', 'xxx', 'roles', 'group'] depth = 1 # 官方建议0~10，尽量不要超过3层 1.4、生成链接 class UserInfoSerializer(serializers.ModelSerializer): group = serializers.HyperlinkedIdentityField(view_name='group', lookup_field='group_id', lookup_url_kwarg='pk') class Meta: model = UserInfo fields = \"__all__\" fields = ['id', 'username', 'password', 'roles', 'group'] depth = 0 # 官方建议0~10，尽量不要超过3层 class UserInfoView(APIView): \"\"\"用户中心（普通用户，vip）\"\"\" # authentication_classes = [Authentication, ] # 当前permission_classes存在就不会去取配置文件里的设置 permission_classes = [VipPermission, ] def get(self, request, *args, **kwargs): users = UserInfo.objects.all() ser = UserInfoSerializer(instance=users, many=True, context={'request': request}) # print(ser.data) ret = json.dumps(ser.data, ensure_ascii=False) return HttpResponse(ret) 1.5、源码流程 单个结果，对象使用Serializer类处理 多个结果，QuerySet，ListSerializer类处理 # ser.data是入口 2、请求数据校验 class XXXValidator(object): def __init__(self, base): self.base = base def __call__(self, value): if not value.startswith(self.base): message = '名称必须以 %s 开头' % self.base raise serializers.ValidationError(message) class UserGroupSerializer(serializers.Serializer): name = serializers.CharField(error_messages={'required': '姓名不能为空'}, validators=[XXXValidator('nzb'),]) class UserGroupView(APIView): authentication_classes = [] permission_classes = [] def post(self, request, *args, **kwargs): # print(request.data) ser = UserGroupSerializer(data=request.data) if ser.is_valid(): # 取数据 print(ser.validated_data) # 单独取某些 print(ser.validated_data['name']) else: print(ser.errors) return HttpResponse('提交数据') 七、分页 数据量大时，怎么规避，1、只显示200页，2、只有上一页和下一页 1、分页，看第几页，每页显示n条数据； 2、分页，在n个位置，向后查看n条数据； 3、加密分页，只能看上一页和下一页。(记住id的最大值和最小值) 第一种分页 class MyPagination(PageNumberPagination): # 自定义分页类 page_size = 2 page_query_param = 'page' page_size_query_param = 'size' max_page_size = 5 第二种分页 class MyPagination(LimitOffsetPagination): # 自定义分页类 page_size = 2 limit_query_param = 'limit' offset_query_param = 'offset' max_limit = 5 第三种分页 class MyPagination(CursorPagination): # 自定义分页类 page_size = 2 cursor_query_param = 'cursor' max_limit = 5 ordering = 'id' page_size_query_param = None max_page_size = None class Pager1View(APIView): authentication_classes = [] permission_classes = [] def get(self, request, *args, **kwargs): # 获取所以数据 roles = Role.objects.all() # ret = json.dumps(ser.data, ensure_ascii=False) # return HttpResponse(ret) # rest_framework 渲染 # 创建分页对象 pg = MyPagination() # 在数据中获取分页的数据 pager_roles = pg.paginate_queryset(queryset=roles, request=request, view=self) # 对数据进行序列化 ser = PagerSerializer(instance=pager_roles, many=True) # return Response(ser.data) # 生成上一页下一页链接(加密分页很有用) return pg.get_paginated_response(ser.data) 总结： 1、数据量大，如何做分页？ 1.1、数据库性能相关转到rest_framework是怎么处理 1.2、 八、视图 1、过去 class XxxView(View)： pass 2、现在 class XxxView(APIView): APIView继承于VIew pass 3、没什么用的类：GenericAPIView（不使用） from app01.utils.serializers.pager import PagerSerializer from rest_framework.generics import GenericAPIView class View1View(GenericAPIView): # 继承GenericAPIView需要queryset相当于上面的roles queryset = Role.objects.all() serializer_class = PagerSerializer pagination_class = PageNumberPagination authentication_classes = [] permission_classes = [] def get(self, request, *args, **kwargs): # 获取数据 roles = self.get_queryset() # Role.objects.all() # 分页 [1,100] pager_roles = self.paginate_queryset(roles) # 序列化 ser = self.get_serializer(instance=pager_roles, many=True) return Response(ser.data) 4、GenericViewSet(ViewSetMixin, generics.GenericAPIView): 路由： re_path('(?P[v1|v2]+)/v1/', views.View1View.as_view({'get': 'list'}), name='view1'), 视图： from app01.utils.serializers.pager import PagerSerializer from rest_framework.viewsets import GenericViewSet class View1View(GenericViewSet): queryset = Role.objects.all() serializer_class = PagerSerializer pagination_class = PageNumberPagination authentication_classes = [] permission_classes = [] def list(self, request, *args, **kwargs): # 获取数据 roles = self.get_queryset() # Role.objects.all() # 分页 [1,100] pager_roles = self.paginate_queryset(roles) # 序列化 ser = self.get_serializer(instance=pager_roles, many=True) return Response(ser.data) 5、ModelViewSet(最强大) 路由： re_path('(?P[v1|v2]+)/v1/$', views.View1View.as_view({'get': 'list', 'post':'create'}), name='view1'), re_path('(?P[v1|v2]+)/v1/(?P\\d+)', views.View1View.as_view({'get': 'retrieve','delete':'destroy','put': 'update','patch': 'partial_update'}), name='view1'), 视图： from app01.utils.serializers.pager import PagerSerializer from rest_framework.viewsets import GenericViewSet, ModelViewSet from rest_framework.mixins import ListModelMixin, CreateModelMixin # class View1View(ListModelMixin,GenericViewSet,CreateModelMixin): class View1View(ModelViewSet): queryset = Role.objects.all() serializer_class = PagerSerializer pagination_class = PageNumberPagination authentication_classes = [] permission_classes = [] PS:class View1View(CreateModelMixin): 6、总结： 6.1、增删改查：ModelViewSet 6.2、增删：CreateModelMixin，DestroyModelMixin，GenericViewSet 6.4、复杂逻辑：GenericViewSet 或 APIView PS：权限： GenericAPIView.get_object check_object_permissions has_object_permission 九、路由 1、 re_path('(?P[v1|v2]+)/auth/', views.AuthView.as_view(), name='auth'), 2、 re_path('(?P[v1|v2]+)/v1/$', views.View1View.as_view({'get': 'list', 'post':'create'}), name='view1'), 3、 # http://127.0.0.1:8000/api01/v1/v1/ re_path('(?P[v1|v2]+)/v1/$', views.View1View.as_view({'get': 'list', 'post':'create'}), name='view1'), # http://127.0.0.1:8000/api01/v1/v1.json re_path('(?P[v1|v2]+)/v1\\.(?P\\w+)$', views.View1View.as_view({'get': 'list', 'post':'create'}), name='view1'), re_path('(?P[v1|v2]+)/v1/(?P\\d+)$', views.View1View.as_view({'get': 'retrieve', 'delete':'destroy', 'put': 'update', 'patch': 'partial_update'}), name='view1'), re_path('(?P[v1|v2]+)/v1/(?P\\d+)\\.(?P\\w+)', views.View1View.as_view({'get': 'retrieve','delete':'destroy','put': 'update','patch': 'partial_update'}), name='view1'), 4、自动生成路由 from app01 import views from rest_framework import routers # rest_framework路由 router = routers.DefaultRouter() router.register(r'xxx', views.View1View) router.register(r'rt', views.View1View) urlpatterns = [ # rest_framework路由 re_path('(?P[v1|v2]+)/', include(router.urls)) ] 十、渲染器 from rest_framework.renderers import JSONRenderer, BrowsableAPIRenderer, AdminRenderer, HTMLFormRenderer # class View1View(ListModelMixin,GenericViewSet,CreateModelMixin): class View1View(ModelViewSet): # 渲染器,使用JSONRenderer就行，BrowsableAPIRenderer只是界面好看 # renderer_classes = [JSONRenderer, BrowsableAPIRenderer] authentication_classes = [] permission_classes = [] queryset = Role.objects.all() serializer_class = PagerSerializer pagination_class = PageNumberPagination 全局配置： 'DEFAULT_RENDERER_CLASSES':['rest_framework.renderers.JSONRenderer','rest_framework.renderers.BrowsableAPIRenderer'] 十一、django组件content_type Django内置的一个组件，帮助开发者做连表操作。【混搭】 models里定义的时候，实现一表对多表操作 例： # 利用content-type实现一表对应多表 # models.py from django.contrib.contenttypes.fields import GenericForeignKey, GenericRelation from django.db import models from django.contrib.contenttypes.models import ContentType class Course(models.Model): \"\"\" 普通课程 \"\"\" name = models.CharField(max_length=32) # 仅用于反向查找 price_policy_list = GenericRelation('PricePolicy') class DegreeCourse(models.Model): \"\"\" 学位课程 \"\"\" name = models.CharField(max_length=32) # 仅用于反向查找 price_policy_list = GenericRelation('PricePolicy') class PricePolicy(models.Model): \"\"\"价格策略\"\"\" price = models.IntegerField() period = models.IntegerField() # 自定义 # table_name = models.CharField(verbose_name=u'关联的表名称') # object_id = models.CharField(verbose_name=u'关联表中的数据id') # 使用Django的组件content-type content_type = models.ForeignKey(ContentType, verbose_name=u'关联普通课或学位课表', on_delete=models.CASCADE) # 11、12就是上面两个表 object_id = models.IntegerField(verbose_name=u'关联表中的数据id') # 帮助你快速实现content-type操作 content_object = GenericForeignKey('content_type', 'object_id') # 视图view里面的逻辑, views.py: # 插入一条价格策略,为学位课“Python”添加一个价格策略：一个月9.9 # 1、加一个字段后，使用content-type # obj = DegreeCourse.objects.filter(name='Python').first() # PricePolicy.objects.create(price=9.9, period=30, content_object=obj) # 2、根据课程ID找到课程，并获取所有的价格策略 # course = DegreeCourse.objects.filter(id=1).first() # price_policy = course.price_policy_list.all() 十二、小知识点 1、前后端分离如何解决跨域 --jsonp --cors -响应头放在中间件 2、__init__和__new__的区别： __new__：是返回对象 __init__：是__new__返回的对象的构造方法 例： class Foo(object): def __init__(self, a1): print(a1) self.a = a1 def __new__(cls, *args, **kwargs): \"\"\" 1.根据类创建对象，并返回 2.执行返回值的__init__ \"\"\" # 如果返回的是nzb字符串，则执行字符串的构造方法__init__,上面__init__里面的输出a1为nzb(因为字符串没有构造方法) return 'nzb' # 默认,实例化当前类的对象返回, 然后去执行构造方法 return object.__new__(cls) obj = Foo(123) print(obj) "},"Python/第三方库/Django/Django开发经验/02-Django-restframework登录相关.html":{"url":"Python/第三方库/Django/Django开发经验/02-Django-restframework登录相关.html","title":"登录相关","keywords":"","body":"datetime:2020/5/13 10:33 author:nzb 登录相关（基于jwt token登录；单个用户表或多个用户表） urls.py path(\"login/\", CustomLoginJSONWebToken.as_view()), settings.py # 验证中间件 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'corsheaders.middleware.CorsMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', # 'corsheaders.middleware.CorsPostCsrfMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'middlewares.ValidTokenMiddleware', # 换台设备需重新登录 ] # drf框架的配置信息 REST_FRAMEWORK = { # 默认分页 'DEFAULT_PAGINATION_CLASS': 'utils.PagePagination', 'DATETIME_FORMAT': '%Y-%m-%d %H:%M:%S', # 自定义token内含值 'JWT_PAYLOAD_HANDLER': 'utils.custom_payload_handler', # 异常处理 'EXCEPTION_HANDLER': 'utils.exception_handler.exception_handler', # 见01-重写异常处理手柄 # 用户登陆认证方式 'DEFAULT_AUTHENTICATION_CLASSES': ( #单个用户表配置 # 'rest_framework_jwt.authentication.JSONWebTokenAuthentication', # 'rest_framework.authentication.SessionAuthentication', # 'rest_framework.authentication.BasicAuthentication', # 多个用户表配置 'authentication.CustomAuthenticate', # 自定义 JSON Token Authentication ), # 获取用户的secret_key # 没用，需要也是放到下面的 JWT_AUTH 中，不设置是获取上面的 SECRET_KEY 用于签名加密（不能泄露） # 'JWT_GET_USER_SECRET_KEY': 'utils.jwt_get_user_secret', } # jwt载荷中的有效期设置(from rest_framework_jwt) token_time = datetime.timedelta(days=365) JWT_AUTH = { 'JWT_EXPIRATION_DELTA': token_time, # 有效期设置 'JWT_REFRESH_EXPIRATION_DELTA': token_time, # 刷新有效期 'JWT_RESPONSE_PAYLOAD_HANDLER': '.utils.custom_jwt_response_payload_handler', # 自定义返回认证通过后的数据 } utils.py from django.contrib.auth import authenticate, get_user_model from rest_framework_jwt.utils import jwt_encode_handler from rest_framework_jwt.settings import api_settings def custom_payload_handler(user): '''自定义token内含值 :param user: user auth model :return: 计算token的基本信息 ''' # jwt token payload的基本信息： user_id 用户主键id, 用户first_name, 用户电话号码 phone payload = { 'user_id': user.pk, 'username': user.username, 'exp': datetime.datetime.utcnow() + api_settings.JWT_EXPIRATION_DELTA, # 'phone': user.phone 'user_secret': str(uuid.uuid4()) #　uuid } if api_settings.JWT_ALLOW_REFRESH: payload['orig_iat'] = timegm( datetime.datetime.utcnow().utctimetuple() ) if api_settings.JWT_AUDIENCE is not None: payload['aud'] = api_settings.JWT_AUDIENCE if api_settings.JWT_ISSUER is not None: payload['iss'] = api_settings.JWT_ISSUER return payload def generate_user_token(user): \"\"\"生成用户token\"\"\" user_model = get_user_model() payload = custom_payload_handler(user) token = jwt_encode_handler(payload) return token def custom_jwt_response_payload_handler(token, user=None): \"\"\" 自定义jwt认证成功返回的数据 :token 返回的jwt :user 当前登录的用户信息[对象] :request 当前本次客户端提交过来的数据 Example: return { 'token': token, 'user': UserSerializer(user, context={'request': request}).data } \"\"\" data = { 'code': 10000, 'results': { 'token': token, 'id': user.id, 'username': user.username, ．．．． } } return data def jwt_get_secret_key(payload=None): \"\"\"获取用户的secret_key（例如uuid） For enhanced security you may want to use a secret key based on user. This way you have an option to logout only this user if: - token is compromised - password is changed - etc. \"\"\" return user.user_secret # 分页 class PagePagination(LimitOffsetPagination): \"\"\"分页\"\"\" # page_size = 1 limit_query_param = 'limit' offset_query_param = 'offset' max_limit = 20 def get_paginated_response(self, data): ret = dict([ ('code', 10000, ('errMsg', ''), ('count', self.count), ('previous', self.get_previous_link()), ('next', self.get_next_link()), ]) if isinstance(data, dict): ret.update(**data) else: ret.update({ 'results': data }) return Response(OrderedDict(ret)) views.py from rest_framework_jwt.views import JSONWebTokenAPIView from rest_framework_jwt.settings import api_settings from utils import custom_jwt_response_payload_handler class CustomLoginJSONWebToken(JSONWebTokenAPIView): \"\"\" 自定义登录 \"\"\" serializer_class = CustomJSONWebTokenSerializer def post(self, request, *args, **kwargs): serializer = self.get_serializer(data=request.data) if serializer.is_valid(): user = serializer.object.get('user') or request.user token = serializer.object.get('token') #　可自定义返回认证成功后的数据,settings中的JWT_AUTH中的JWT_RESPONSE_PAYLOAD_HANDLER设置 # 这里还可以写需要的相应逻辑 response_data = custom_jwt_response_payload_handler(token, user, request) response = Response(response_data) if api_settings.JWT_AUTH_COOKIE: expiration = (datetime.utcnow() + api_settings.JWT_EXPIRATION_DELTA) response.set_cookie(api_settings.JWT_AUTH_COOKIE, token, expires=expiration, httponly=True) return response return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) serializers.py from rest_framework_jwt.serializers import JSONWebTokenSerializer from django.contrib.auth import authenticate, get_user_model from utils import generate_user_token class CustomJSONWebTokenSerializer(JSONWebTokenSerializer): \"\"\"自定义账号密码登录序列号\"\"\" def validate(self, attrs): # 密码账户验证 username = attrs.get(self.username_field) password = attrs.get('password', None) credentials = { self.username_field: username, 'password': password } if all(credentials.values()): user = authenticate(**credentials) if user: if not user.is_active: msg = {'code': 10996, 'errMsg': '用户被冻结'} raise serializers.ValidationError(msg) # payload = jwt_payload_handler(user) return { # 'token': jwt_encode_handler(payload), 'token': generate_user_token(user), 'user': user } else: # 若认证失败 msg = {'code': 10991, 'errMsg': '用户名和密码错误'} raise serializers.ValidationError(msg) else: msg = {'code': 10997, 'errMsg': 'username和password为必填字段'} raise serializers.ValidationError(msg) from rest_framework_jwt.serializers import VerifyJSONWebTokenSerializer class CustomVerifyJSONWebTokenSerializer(VerifyJSONWebTokenSerializer): \"\"\" 多个用户表时自定义验证 中间件中使用 \"\"\" def _check_user(self, payload): # print(\"-------自定义验证的payload：\", payload) username = jwt_get_username_from_payload(payload) if not username: msg = _('Invalid payload.') raise serializers.ValidationError(msg) # Make sure user exists token_type = payload.get(\"type\", None) if token_type == \"manager\": try: # 表1 user = UserManager.objects.get_by_natural_key(username) except UserManager.DoesNotExist: msg = _(\"User doesn't exist.\") raise serializers.ValidationError(msg) if not user.is_active: msg = _('User account is disabled.') raise serializers.ValidationError(msg) else: try: # 表2 user = UserStuInfo.objects.filter(id=payload.get(\"user_id\", None), sno=payload.get(\"sno\", None), is_del=False).first() except UserStuInfo.DoesNotExist: msg = _(\"User doesn't exist.\") raise serializers.ValidationError(msg) return user authentication.py（多个用户表时的登录验证） from rest_framework_jwt.authentication import JSONWebTokenAuthentication, jwt_get_username_from_payload class CustomAuthenticate(JSONWebTokenAuthentication): \"\"\"多个用户表自定义设置登录选项\"\"\" def authenticate_credentials(self, payload): \"\"\" Returns an active user that matches the payload's user id and email. \"\"\" # User = get_user_model() username = jwt_get_username_from_payload(payload) # if if not username: msg = _('Invalid payload.') raise exceptions.AuthenticationFailed(msg) token_type = payload.get(\"type\", None) if token_type == \"manager\": try: # 举例用户表1 user = UserManager.objects.get_by_natural_key(username) except user.DoesNotExist: msg = _('Invalid signature.') raise exceptions.AuthenticationFailed(msg) if not user.is_active: msg = _('User account is disabled.') raise exceptions.AuthenticationFailed(msg) else: try: # 举例用户表2 user = UserStuInfo.objects.filter(id=payload.get(\"user_id\", None), sno=payload.get(\"sno\", None), is_del=False).first() except user.DoesNotExist: msg = _('Invalid signature.') raise exceptions.AuthenticationFailed(msg) return user middleware.py from uuid import uuid4 import json from django.http import HttpResponse from jwt import InvalidSignatureError from rest_framework.exceptions import ValidationError from django.utils.deprecation import MiddlewareMixin from rest_framework_jwt.utils import jwt_decode_handler from authentication import CustomVerifyJSONWebTokenSerializer # 1.每次登录 response 处理 记录 jwt # 2.每次请求判断 jwt是否与表中相等(相当于用户异设备登录获取了新的jwt) 不等 就修改uuid class ValidTokenMiddleware(MiddlewareMixin): def process_request(self, request): # 用于处理 所有带 jwt 的请求 jwt_token = request.META.get('HTTP_AUTHORIZATION', None) if jwt_token is not None and jwt_token != '': data = { 'token': request.META['HTTP_AUTHORIZATION'].split(' ')[1], } try: # valid_data = VerifyJSONWebTokenSerializer().validate(data) # 原来的 valid_data = CustomVerifyJSONWebTokenSerializer().validate(data) # 多用户自定义后的 user = valid_data['user'] # if user: # print(\"------------请求时用户的uuid:{0}\".format(user.user_secret)) except (InvalidSignatureError, ValidationError): # 找不到用户 data = json.dumps({\"code\": 10000, \"errMsg\": \"用户未登录\"}) return HttpResponse(data, content_type='application/json', status=400) # if user.user_jwt != data['token']: # 解析token，这里面就有获取用户的user_secret，~~所以需要重写jwt_get_secret_key（不需要）~~ decode_token = jwt_decode_handler(data['token']) # print(\"------------请求时带的token：{0}\".format(decode_token)) if not user: data = json.dumps({\"code\": 10000, \"errMsg\": \"用户未登录\"}) return HttpResponse(data, content_type='application/json', status=400) elif str(user.user_secret) != decode_token.get(\"user_secret\"): user.user_secret = uuid4() user.save() data = json.dumps({\"code\": 10000, \"errMsg\": \"用户未登录\"}) return HttpResponse(data, content_type='application/json', status=400) def process_response(self, request, response): # 仅用于处理 login请求 # print(\"----------\", request.META['PATH_INFO']) MANAGER_LOGIN_PATH = \"/api/teacher/login/\" STUDENT_LOGIN_PATH = \"/api/student/login/\" if request.META['PATH_INFO'] in (MANAGER_LOGIN_PATH, STUDENT_LOGIN_PATH): try: rep_data = response.data except AttributeError as e: print(\"报错信息：\", e.args) results = rep_data.get('results', None) if results: # valid_data = VerifyJSONWebTokenSerializer().validate(results) # 原来的 valid_data = CustomVerifyJSONWebTokenSerializer().validate(results) # 多用户自定义后的 user = valid_data['user'] # user.user_jwt = rep_data['results']['token'] decode_token = jwt_decode_handler(rep_data['results']['token']) # print(\"--------登录后的token:\", decode_token) user.user_secret = decode_token.get(\"user_secret\") user.save() return response else: return response else: return response "},"Python/第三方库/Django/Django开发经验/01-Django-restframework重写异常处理手柄.html":{"url":"Python/第三方库/Django/Django开发经验/01-Django-restframework重写异常处理手柄.html","title":"异常处理手柄","keywords":"","body":"datetime:2020/1/8 16:02 author:nzb 重写异常处理返回 例如： 正常返回 { \"detail\": \"方法 “GET” 不被允许。\" } 重写返回 { \"code\": 10001, \"errMsg\": \"方法 “GET” 不被允许。\" } 源码流程 dispath() 分发 def dispatch(self, request, *args, **kwargs): \"\"\" `.dispatch()` is pretty much the same as Django's regular dispatch, but with extra hooks for startup, finalize, and exception handling. \"\"\" self.args = args self.kwargs = kwargs request = self.initialize_request(request, *args, **kwargs) self.request = request self.headers = self.default_response_headers # deprecate? try: self.initial(request, *args, **kwargs) # Get the appropriate handler method if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed # 活动到某个视图的某个方法，例如create() # 视图函数里的serializer.is_valid(raise_exception=True), # 会去验证序列化里面自带的验证规则和自定义的验证规则（并抛出异常） response = handler(request, *args, **kwargs) except Exception as exc: # 捕获异常 response = self.handle_exception(exc) self.response = self.finalize_response(request, response, *args, **kwargs) return self.response handle_exception() # 捕获异常后执行 def handle_exception(self, exc): \"\"\" Handle any exception that occurs, by returning an appropriate response, or re-raising the error. \"\"\" if isinstance(exc, (exceptions.NotAuthenticated, exceptions.AuthenticationFailed)): # WWW-Authenticate header for 401 responses, else coerce to 403 auth_header = self.get_authenticate_header(self.request) if auth_header: exc.auth_header = auth_header else: exc.status_code = status.HTTP_403_FORBIDDEN # 获取重写的异常返回函数 exception_handler = self.get_exception_handler() context = self.get_exception_handler_context() response = exception_handler(exc, context) if response is None: self.raise_uncaught_exception(exc) response.exception = True return response # 获取配置文件 def get_exception_handler(self): \"\"\" Returns the exception handler that this view uses. \"\"\" return self.settings.EXCEPTION_HANDLER 重写函数custom_exception_handler() from rest_framework.views import exception_handler def custom_exception_handler(exc,context): \"\"\" 框架自带错误码(常见已知的) ( (400, \"invalid\"), (401, \"authentication_failed\"), (401, \"not_authenticated\"), (403, \"permission_denied\"), (404, \"not_found\"), (405, \"method_not_allowed\"), ) 不常见的 ( (400, \"parse_error\"), (406, \"not_acceptable\"), (415, \"unsupported_media_type\"), (429, \"throttled\") ) \"\"\" response = exception_handler(exc, context) # 获取本来应该返回的exception的response request = context.get(\"request\", None) ... if response is not None: if response.status_code == 403: # 权限 pass elif response.status_code == 401: # 是否登录 pass elif response.status_code == 404: # 资源未找到 response.data['code'] = org_status_code.NOTFOUNDERROR_CODE.get(\"code\", None) response.data['errMsg'] = org_status_code.NOTFOUNDERROR_CODE.get(\"detail\", None) del response.data['detail'] elif response.status_code == 405: # 方法不允许 pass elif response.status_code == 400: # 重写django自带的序列化错误以及自定义的序列化错误 response = process_400_BAD_REQUEST(response) else: pass return response def process_400_BAD_REQUEST(response): \"\"\"映射自带错误和返回自定义错误\"\"\" old_data = response.data for k, v in old_data.items(): new_data = {} # 框架自带错误码(常见已知的) if v[0].code == \"required\": new_data['code'] = org_status_code.NOTNULL_CODE.get(\"code\", None) new_data['errMsg'] = org_status_code.NOTNULL_CODE.get(\"detail\", None).format(k) elif v[0].code == \"invalid\": new_data['code'] = org_status_code.TYPEERROR_CODE.get(\"code\", None) new_data['errMsg'] = org_status_code.TYPEERROR_CODE.get(\"detail\", None).format(k, v[0]) elif v[0].code == \"incorrect_type\": # 类型错误 new_data['code'] = org_status_code.TYPEERROR_CODE.get(\"code\", None) new_data['errMsg'] = org_status_code.TYPEERROR_CODE.get(\"detail\", None).format(k, v[ 0]) # \"{0}字段{1}\".format(k, v[0]) elif v[0].code == \"does_not_exist\": # 外键对象不存在 new_data['code'] = org_status_code.FOREIGNKEYNOEXISTED_CODE.get(\"code\", None) new_data['errMsg'] = org_status_code.FOREIGNKEYNOEXISTED_CODE.get(\"detail\", None).format(k, v[ 0]) # \"{0}字段{1}\".format(k, v[0]) elif v[0].code == \"unique\": # 已存在 new_data['code'] = org_status_code.EXISTED_CODE.get(\"code\", None) new_data['errMsg'] = org_status_code.EXISTED_CODE.get(\"detail\", None) elif v[0].code == \"max_length\": # 最大长度 new_data['code'] = org_status_code.MAXLENGTHERROR_CODE.get(\"code\", None) new_data['errMsg'] = v[0].replace(\"这个\", k) elif v[0].code == \"min_length\": # 最小长度 new_data['code'] = org_status_code.MINLENGTHERROR_CODE.get(\"code\", None) new_data['errMsg'] = v[0].replace(\"这个\", k) # 自定义错误码以及未知的错误码 else: if isinstance(v[0].code, int): # 自定义的错误 new_data['code'] = v[0].code new_data['errMsg'] = v[0] else: response.data = old_data return response response.data = new_data return response settings.py配置 REST_FRAMEWORK = { 'DATETIME_FORMAT': '%Y/%m/%d %H:%M:%S', 'JWT_ALLOW_REFRESH': True, 'DEFAULT_AUTHENTICATION_CLASSES': ( \"rest_framework_jwt.authentication.JSONWebTokenAuthentication\", # 'utils.authentication.CustomAuthenticate', # 自定义 JSON Token Authentication # 'rest_framework.authentication.BasicAuthentication', # 'rest_framework.authentication.SessionAuthentication', ), 'EXCEPTION_HANDLER': 'utils.exceptions.custom_exception_handler', # 自定义重写的异常处理返回 'SEARCH_PARAM': 'kw', } "},"Python/第三方库/Django/Django开发经验/03-Django-restframework过滤类相关.html":{"url":"Python/第三方库/Django/Django开发经验/03-Django-restframework过滤类相关.html","title":"过滤相关","keywords":"","body":"datetime:2020/5/13 13:45 author:nzb 过滤类相关 class NumberInFilter(django_filters.BaseInFilter, django_filters.NumberFilter): pass class MyFilter(django_filters.rest_framework.FilterSet): id_list = NumberInFilter(field_name=\"id\", label=\"xxx\", lookup_expr=\"in\") class Meta: model = TestModel fields = ['id_list'] "},"Python/第三方库/Django/Django开发经验/04-Django-Fastdfs重写存储类.html":{"url":"Python/第三方库/Django/Django开发经验/04-Django-Fastdfs重写存储类.html","title":"存储类重写","keywords":"","body":"datetime:2020/5/14 16:17 author:nzb Django-Fastdfs重写存储类 csnd文章 源码解析 本地存储类 重写存储类 client.conf # connect timeout in seconds # default value is 30s connect_timeout=30 # network timeout in seconds # default value is 30s network_timeout=60 # the base path to store log files # base_path=C:\\Users\\Admin\\PycharmProjects\\alumnus_circle\\venv # FastDFS客户端存放日志文件的目录 base_path = /data/log/fastdfs/fastdfs.log # tracker_server can ocur more than once, and tracker_server format is # \"host:port\", host can be hostname or ip address # 运行tracker服务的机器ip tracker_server = 172.26.6.129:22122 #standard log level as syslog, case insensitive, value list: ### emerg for emergency ### alert ### crit for critical ### error ### warn for warning ### notice ### info ### debug log_level=info # if use connection pool # default value is false # since V4.05 use_connection_pool = false # connections whose the idle time exceeds this time will be closed # unit: second # default value is 3600 # since V4.05 connection_pool_max_idle_time = 3600 # if load FastDFS parameters from tracker server # since V4.05 # default value is false load_fdfs_parameters_from_tracker=false # if use storage ID instead of IP address # same as tracker.conf # valid only when load_fdfs_parameters_from_tracker is false # default value is false # since V4.05 use_storage_id = false # specify storage ids filename, can use relative or absolute path # same as tracker.conf # valid only when load_fdfs_parameters_from_tracker is false # since V4.05 storage_ids_filename = storage_ids.conf #HTTP settings http.tracker_server_port=80 #use \"#include\" directive to include HTTP other settiongs ##include http.conf fdfs-storage.py # _*_ encoding:utf-8 _*_ __author__ = 'nzb' __datetime__ = '2020/1/3 15:18' from django.conf import settings from django.core.files.storage import Storage from django.utils.deconstruct import deconstructible from fdfs_client.client import Fdfs_client @deconstructible class FastDFSStorage(Storage): def __init__(self, base_url=None, client_conf=None): \"\"\" 初始化 :param base_url: 用于构造图片完整路径使用，图片服务器的域名 :param client_conf: FastDFS客户端配置文件的路径 \"\"\" if base_url is None: base_url = settings.FDFS_URL self.base_url = base_url if client_conf is None: client_conf = settings.FDFS_CLIENT_CONF self.client_conf = client_conf def _open(self, name, mode='rb'): \"\"\" 用不到打开文件，所以省略 \"\"\" pass def _save(self, name, content): \"\"\" 在FastDFS中保存文件 :param name: 传入的文件名 :param content: 文件内容 :return: 保存到数据库中的FastDFS的文件名 \"\"\" client = Fdfs_client(self.client_conf) filename = content.name filename_ext = filename.split('.') if len(filename_ext) settings.py # FastDFS # django文件存储 DEFAULT_FILE_STORAGE = 'utils.fastdfs.fdfs_storage.FastDFSStorage' FDFS_URL = 'http://img.example.com/' FDFS_CLIENT_CONF = os.path.join(BASE_DIR, 'utils/fastdfs/client.conf') 本地存储重命名 helper.py # 文件重命名 @deconstructible class RenameFile(object): def __init__(self, upload_to): self.upload_to = upload_to def __call__(self, instance, filename: str, *args, **kwargs) -> str: filename_ext = filename.split('.') if len(filename_ext) models.py class FeedBackFile(models.Model): file = models.FileField(verbose_name=\"意见反馈举报附件\", upload_to=RenameFile(\"upload/feedback/\")) create_time = models.DateTimeField(auto_now_add=True, verbose_name=\"创建时间\") class Meta: verbose_name = \"意见反馈附件\" verbose_name_plural = verbose_name 头部判断 import struct # 常见文件格式的文件头 ALLOW_FILETYPE = { \"FFD8FF\": \"JPEG (jpg)\", \"89504E47\": \"PNG (png)\", \"47494638\": \"GIF (gif)\", \"49492A00\": \"TIFF (tif)\", \"41433130\": \"CAD (dwg)\", \"D0CF11E0\": \"MS Word/Excel (xls.or.doc)\", \"255044462D312E\": \"Adobe Acrobat (pdf)\", \"504B0304\": \"ZIP Archive (zip)\", \"52617221\": \"RAR Archive (rar)\", \"41564920\": \"AVI (avi)\" } # 字节码转16进制字符串 def bytes2hex(bytes): num = len(bytes) hexstr = u\"\" for i in range(num): t = u\"%x\" % bytes[i] if len(t) % 2: hexstr += u\"0\" hexstr += t return hexstr.upper() def validate_file(file): \"\"\" 根据文件头判断文件类型 文件后缀不可信，并且后缀在linux系统下是没有这个概念的，所以通过文件中的头部标识来判断 :param file:IO文件 :return: xxx：文件类型，unknown：未知文件（不支持） \"\"\" # binfile = open(file, 'rb') # 必需二制字读取 tl = ALLOW_FILETYPE ftype = 'unknown' for hcode in tl.keys(): numOfBytes = len(hcode) / 2 # 需要读多少字节 file.seek(0) # 每次读取都要回到文件头，不然会一直往后读取 # hbytes = struct.unpack_from(\"B\" * numOfBytes, binfile.read(numOfBytes)) # 一个 \"B\"表示一个字节 hbytes = struct.unpack_from(\"B\" * int(numOfBytes), file.read(int(numOfBytes))) # 一个 \"B\"表示一个字节 f_hcode = bytes2hex(hbytes) if f_hcode == hcode: ftype = tl[hcode] break file.seek(0) # 回到文件头 return ftype if __name__ == '__main__': pass ret = validate_file('./test.jpg') print(ret) "},"Python/第三方库/Django/Django开发经验/05-Django-restframework序列化相关.html":{"url":"Python/第三方库/Django/Django开发经验/05-Django-restframework序列化相关.html","title":"序列化相关","keywords":"","body":"datetime:2020/6/28 14:34 author:nzb 唯一验证 # serialiezers.py from rest_framework import serializers from rest_framework.validators import UniqueTogetherValidator class ExampleSerializer(serializers.ModelSerializer): args1 = serializers.CharField(label=\"参数1\", required=False) class Meta: model = Example exclude = ['create_time'] validators = [UniqueTogetherValidator(queryset=Example.objects.filter(), fields=('project_id', 'project_type', 'user_id'), message='已存在')] def validate(self, attrs): file = attrs.get(\"file\", None) # 文件类型验证 if validate_file(file) == \"unknown\": raise serializers.ValidationError(code=40000, detail=\"不支持的文件类型\") return attrs 文件类型验证 # helper.py import struct # 常见文件格式的文件头 ALLOW_FILETYPE = { \"FFD8FF\": \"JPEG (jpg)\", \"89504E47\": \"PNG (png)\", \"47494638\": \"GIF (gif)\", \"49492A00\": \"TIFF (tif)\", \"41433130\": \"CAD (dwg)\", \"D0CF11E0\": \"MS Word/Excel (xls.or.doc)\", \"255044462D312E\": \"Adobe Acrobat (pdf)\", \"504B0304\": \"ZIP Archive (zip)\", \"52617221\": \"RAR Archive (rar)\", \"41564920\": \"AVI (avi)\" } # 字节码转16进制字符串 def bytes2hex(bytes): num = len(bytes) hexstr = u\"\" for i in range(num): t = u\"%x\" % bytes[i] if len(t) % 2: hexstr += u\"0\" hexstr += t return hexstr.upper() def validate_file(file): \"\"\" 根据文件头判断文件类型 文件后缀不可信，并且后缀在linux系统下是没有这个概念的，所以通过文件中的头部标识来判断 :param file:IO文件 :return: xxx：文件类型，unknown：未知文件（不支持） \"\"\" # binfile = open(file, 'rb') # 必需二制字读取 tl = ALLOW_FILETYPE ftype = 'unknown' for hcode in tl.keys(): numOfBytes = len(hcode) / 2 # 需要读多少字节 file.seek(0) # 每次读取都要回到文件头，不然会一直往后读取 # hbytes = struct.unpack_from(\"B\" * numOfBytes, binfile.read(numOfBytes)) # 一个 \"B\"表示一个字节 hbytes = struct.unpack_from(\"B\" * int(numOfBytes), file.read(int(numOfBytes))) # 一个 \"B\"表示一个字节 f_hcode = bytes2hex(hbytes) if f_hcode == hcode: ftype = tl[hcode] break file.seek(0) # 回到文件头 return ftype "},"Python/第三方库/Django/Django开发经验/06-api接口自动化测试.html":{"url":"Python/第三方库/Django/Django开发经验/06-api接口自动化测试.html","title":"自动化测试","keywords":"","body":"datetime:2020/9/17 14:35 author:nzb api接口自动化测试 配置文件数据库配置 DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'sign_server', 'USER': 'root', 'PASSWORD':'123456', 'PORT': 3306, 'HOST': '127.0.0.1', 'TEST':{ # 测试数据库，每次测试都会自动创建，测试完后会自动删除 'NAME': 'test_sign_server', 'CHARSET': 'utf8mb4', 'COLLATION': 'utf8mb4_general_ci' }, 'OPTIONS': { 'charset': 'utf8mb4' } } } 测试示例 from django.test import TestCase import json from pprint import pprint from django.urls import reverse from rest_framework import status from rest_framework.test import APITestCase from sign.models import SignInfo class SignTests(APITestCase): def test_sign(self): \"\"\"签到\"\"\" print(\"开始测试\") url = reverse('sign-list') # url：/api/sign/ for user_id in range(1, 21): data = {'pro_id': 1, \"obj_id\": 1, \"obj_type\": 0, \"user_id\": user_id, \"sign_type\": 0} response = self.client.post(url, data, format='json') self.assertEqual(response.status_code, status.HTTP_200_OK, response.data) self.assertEqual(response.data.get(\"code\"), 10000, response.data) # 用户1第二条记录 data = {'pro_id': 1, \"obj_id\": 2, \"obj_type\": 0, \"user_id\": 1, \"sign_type\": 0} response = self.client.post(url, data, format='json') self.assertEqual(response.status_code, status.HTTP_200_OK, response.data) self.assertEqual(response.data.get(\"code\"), 10000, response.data) ins_id = response.data.get(\"results\", {}).get(\"id\") # 详情 url = reverse('sign-detail', args=[ins_id]) # url：/api/sign/21/ response = self.client.get(url) self.assertEqual(response.status_code, status.HTTP_200_OK, response.data) self.assertEqual(response.data.get(\"code\"), 10000, response.data) self.assertEqual(response.data.get(\"results\", {}).get(\"status\", None), 0, \"用户签到状态错误\") # 修改处理状态 url = reverse('sign-detail', args=[ins_id]) # url：/api/sign/21/ data = {\"status\": 2} response = self.client.put(url, data, format='json') self.assertEqual(response.status_code, status.HTTP_200_OK, response.data) self.assertEqual(response.data.get(\"code\"), 10000, response.data) self.assertEqual(SignInfo.objects.get(id=ins_id).status, 2, \"修改处理状态出错\") # 补签(用户2在补签一个， obj_id=2) url = reverse('sign-list') # url：/api/sign/ data = {'pro_id': 1, \"obj_id\": 2, \"obj_type\": 0, \"user_id\": 2, \"sign_type\": 1, \"extra4\": \"我要补签\", \"extra_explain\": json.dumps({\"extra1\": \"扩展1说明\", \"extra2\": None, \"extra3\": None, \"extra4\": \"补签说明\", \"extra5\": None, \"extra6\": None})} response = self.client.post(url, data, format='json') self.assertEqual(response.status_code, status.HTTP_200_OK, response.data) self.assertEqual(response.data.get(\"code\"), 10000, response.data) self.assertEqual(response.data.get(\"results\", {}).get(\"sign_type\", None), 1, \"补签失败\") self.assertEqual(response.data.get(\"results\", {}).get(\"extra4\", None), \"我要补签\", \"补签的额外字段错误\") self.assertEqual(SignInfo.objects.filter().count(), 22, \"总数量不对\") # 用户1的签到历史 url = reverse('sign-list') + \"?offset=0&limit=1&user_id=1\" # url：/api/sign/?offset=0&limit=1&user_id=1 response = self.client.get(url) self.assertEqual(response.status_code, status.HTTP_200_OK, response.data) self.assertEqual(response.data.get(\"code\"), 10000, response.data) self.assertEqual(response.data.get(\"count\"), 2, \"用户1的数量不对\") # 签到扩展字段说明 url = reverse('sign-detail', args=['extra_explain']) + \"?pro_id=1&obj_id=2&obj_type=0\" # url：/api/sign/extra_explain/?pro_id=1&obj_id=2&obj_type=0 response = self.client.get(url) self.assertEqual(response.status_code, status.HTTP_200_OK, response.data) self.assertEqual(response.data.get(\"code\"), 10000, response.data) self.assertEqual(len(response.data.get(\"results\", [])), 1, \"额外参数说明错误\") 路由的反向解析 其中用drf注册的路由系统，反向解析如下 源码 routes = [ # List route. Route( url=r'^{prefix}{trailing_slash}$', mapping={ 'get': 'list', # 列表 'post': 'create' # 创建 }, name='{basename}-list', # 本例中：sign-list， basename：url中的别名 detail=False, initkwargs={'suffix': 'List'} ), # Dynamically generated list routes. Generated using # @action(detail=False) decorator on methods of the viewset. DynamicRoute( url=r'^{prefix}/{url_path}{trailing_slash}$', name='{basename}-{url_name}', # 装饰器的接口：detail=False detail=False, initkwargs={} ), # Detail route. Route( url=r'^{prefix}/{lookup}{trailing_slash}$', mapping={ 'get': 'retrieve', # 详情 'put': 'update', # 更新 'patch': 'partial_update', # 更新 'delete': 'destroy' # 删除 }, name='{basename}-detail', # 本例中：sign-detail， basename：url中的别名 detail=True, initkwargs={'suffix': 'Instance'} ), # Dynamically generated detail routes. Generated using # @action(detail=True) decorator on methods of the viewset. DynamicRoute( url=r'^{prefix}/{lookup}/{url_path}{trailing_slash}$', name='{basename}-{url_name}', # 装饰器的接口：detail=False detail=True, initkwargs={} ), ] 注意 被action修饰的接口尽量不用下划线连接，否则reverse不能反向解析，如果使用了下划线，只能这样url = reverse('sign-detail', args=['extra_explain']) + \"?pro_id=1&obj_id=2&obj_type=0\" detail=True：reverse(\"sign-extra\", args=[1]) 结果：/api/sign/extra/ detail=False：reverse(\"sign-extra\") 结果：/api/sign/1/extra/ 如果测试的接口有用到其他表信息：比如用户表可以直接用表创建用户 "},"Python/第三方库/Django/Django开发经验/07-为接口加速加缓存.html":{"url":"Python/第三方库/Django/Django开发经验/07-为接口加速加缓存.html","title":"接口加速缓存","keywords":"","body":"datetime:2020/9/17 15:22 author:nzb 为接口提速，加缓存 1、为什么要使用缓存 目前，用户对于接口的操作基本都需要查询数据库。获取文章列表需要从数据库查询，获取单篇文章需要从数据库查询，获取评论列表也需要查询数据。但是，对于博客中的很多资源来说，在某个时间段内，他们的内容几乎都不会发生更新。例如文章详情，文章发表后，除非对其内容做了修改，否则内容就不会变化。还有评论列表，如果没人发布新评论，评论列表也不会变化。 要知道查询数据库的操作相对而言是比较缓慢的，而直接从内存中直接读取数据就会快很多，因此缓存系统应运而生。将那些变化不那么频繁的数据缓存到内存中，内存中的数据相当于数据库中的一个副本，用户查询数据时，不从数据库查询而是直接从缓存中读取，数据库的数据发生了变化时再更新缓存，这样，数据查询的性能就大大提升了。 当然数据库性能也没有说的那么不堪，对于大部分访问量不大的个人博客而言，任何关系型数据库都足以应付。但是我们学习 django-rest-framework 不仅仅是为了写博客，也许你在工作中，面对的是流量非常大的系统，这时候缓存就不可或缺。 2、确定需缓存的接口 先来整理一下我们已有的接口，看看哪些接口是需要缓存的： 接口名 URL 需缓存 文章列表 /api/posts/ 是 文章详情 /api/posts/:id/ 是 分类列表 /categories/ 是 标签列表 /tags/ 是 归档日期列表 /posts/archive/dates/ 是 评论列表 /api/posts/:id/comments/ 是 文章搜索结果 /api/search/ 否 补充说明 文章列表：需要缓存，但如果有文章修改、新增或者删除时应使缓存失效。 文章详情：需要缓存，但如果文章内容修改或者删除了应使缓存失效。 分类、标签、归档日期：可以缓存，但同样要注意在相应的数据变化时使缓存失效。 评论列表：可以缓存，新增或者删除评论时应使缓存失效。 搜索接口：因为搜索的关键词是多种多样的，可以缓存常见搜索关键词的搜索结果，但如何确定常见搜索关键词是一个复杂的优化问题，这里我们不做任何缓存处理。 3、配置缓存 django 为我们提供了一套开箱即用的缓存框架，缓存框架对缓存的操作做了抽象，提供了统一的读写缓存的接口。无论底层使用什么样的缓存服务（例如常用的 Redis、Memcached、文件系统等），对上层应用来说，操作逻辑和调用的接口都是一样的。 配置 django 缓存，最重要的就是选择一个缓存服务，即缓存结果存储和读取的地方。本项目中我们决定开发环境使用本地内存（Local Memory）缓存服务，线上环境使用 Redis 缓存。 3.1、开发环境配置 在开发环境的配置文件 settings/local.py 中加入以下的配置项即开启本地内存缓存服务。 CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.locmem.LocMemCache', } } 3.2、线上环境配置 线上环境使用到 Redis 缓存服务，django 并未内置 Redis 缓存服务的支持，不过对于 Redis 来说当然不缺乏第三方库的支持，我们选择 django-redis-cache，先来安装它： pipenv install django-redis-cache 然后在项目的线上环境配置文件 settings/production.py 中加入以下配置： CACHES = { \"default\": { \"BACKEND\": \"redis_cache.RedisCache\", \"LOCATION\": \"redis://:UJaoRZlNrH40BDaWU6fi@redis:6379/0\", \"OPTIONS\": { \"CONNECTION_POOL_CLASS\": \"redis.BlockingConnectionPool\", \"CONNECTION_POOL_CLASS_KWARGS\": {\"max_connections\": 50, \"timeout\": 20}, \"MAX_CONNECTIONS\": 1000, \"PICKLE_VERSION\": -1, }, }, } 这样，django 的缓存功能就启用了。至于如何启动 Redis 服务，请参考教程最后的 Redis 服务部分。 3.3、drf-extensions Cache django 的缓存框架比较底层，drf-extensions 在 django 缓存框架的基础上，针对 django-rest-framework 封装了更多缓存相关的辅助函数和类，我们将借助这个第三方库来大大简化缓存逻辑的实现。 首先安装它： pipenv install drf-extensions 那么 drf-extensions 对缓存提供了哪些辅助函数和类呢？我们需要用到的主要有这些： KeyConstructor 可以理解为缓存键生成类。我们先来看看 API 接口缓存的逻辑，伪代码是这样的： 给定一个 URL, 尝试从缓存中查找这个 URL 接口的响应结果 if 结果在缓存中: return 缓存中的结果 else: 生成响应结果 将响应结果存入缓存 (以便下一次查询) return 生成的响应结果 缓存结果是以 key-value 的键值对形式存储的，这里关键的地方在于存储或者查询缓存结果时，需要生成相应的 key。例如我们可以把 API 请求的 URL 作为缓存的 key，这样同一个接口请求将返回相同的缓存内容。但是在更为复杂的场景下，不能简单使用 URL 作为 key，比如即使是同一个 API 请求，已认证和未认证的用户调用接口得到的结果是不一样的，所以 drf-extensions 使用 KeyConstructor 辅助基类来提供灵活的 key 生成方式。 KeyBit 可以理解为 KeyConstructor 定义的 key 生成规则中的某一项规则定义。例如，同一个 API 请求，已认证和未认证的用户将得到不同的响应结果，我们可以定义 key 的生成规则为请求的 URL + 用户的认证 id。那么 URL 可以看成一个 KeyBit，用户 id 是另一个 KeyBit。 cache_response 装饰器 这个装饰器用来装饰 django-rest-framework 的视图（单个视图函数、视图集中的 action 等），被装饰的视图将具备缓存功能。 4、缓存博客文章 我们首先来使用 cache_response 装饰器缓存文章列表接口，代码如下： blog/views.py from rest_framework_extensions.cache.decorators import cache_response class PostViewSet( mixins.ListModelMixin, mixins.RetrieveModelMixin, viewsets.GenericViewSet ): # ... @cache_response(timeout=5 * 60, key_func=PostListKeyConstructor()) def list(self, request, *args, **kwargs): return super().list(request, *args, **kwargs) @cache_response(timeout=5 * 60, key_func=PostObjectKeyConstructor()) def retrieve(self, request, *args, **kwargs): return super().retrieve(request, *args, **kwargs) 这里我们分别装饰了 list（获取文章列表的 action）和 retrieve（获取单篇文章），timeout 参数用于指定缓存失效时间， key_func 指定缓存 key 的生成类（即 KeyConstructor），当然 PostListKeyConstructor、和 PostObjectKeyConstructor 还未定义，接下来我们就来定义这两个缓存 key 生成类： from rest_framework_extensions.key_constructor.bits import ( ListSqlQueryKeyBit, PaginationKeyBit, RetrieveSqlQueryKeyBit, ) from rest_framework_extensions.key_constructor.constructors import DefaultKeyConstructor class PostListKeyConstructor(DefaultKeyConstructor): list_sql = ListSqlQueryKeyBit() pagination = PaginationKeyBit() updated_at = PostUpdatedAtKeyBit() class PostObjectKeyConstructor(DefaultKeyConstructor): retrieve_sql = RetrieveSqlQueryKeyBit() updated_at = PostUpdatedAtKeyBit() PostListKeyConstructor 用于文章列表接口缓存 key 的生成，它继承自 DefaultKeyConstructor，这个基类中定义了 3 条缓存 key 的 KeyBit： 接口调用的视图方法的 id，例如 blog.views. PostViewSet.list。 客户端请求的接口返回的数据格式，例如 json、xml。 客户端请求的语言类型。 另外我们还添加了 3 条自定义的缓存 key 的 KeyBit： 执行数据库查询的 sql 查询语句 分页请求的查询参数 Post 资源的最新更新时间 以上 6 条分别对应一个 KeyBit，KeyBit 将提供生成缓存键所需要的值，如果任何一个 KeyBit 提供的值发生了变化，生成的缓存 key 就会不同，查询到的缓存结果也就不一样，这个方式为我们提供了一种有效的缓存失效机制。例如 PostUpdatedAtKeyBit 是我们自定义的一个 KeyBit，它提供 Post 资源最近一次的更新时间，如果资源发生了更新，返回的值就会发生变化，生成的缓存 key 就会不同，从而不会让接口读到旧的缓存值。PostUpdatedAtKeyBit的代码如下： blog/views.py from .utils import UpdatedAtKeyBit class PostUpdatedAtKeyBit(UpdatedAtKeyBit): key = \"post_updated_at\" 因为资源更新时间的 KeyBit 是比较通用的（后面我们还会用于评论资源），所以我们定义了一个基类 UpdatedAtKeyBit，代码如下： from datetime import datetime from django.core.cache import cache from rest_framework_extensions.key_constructor.bits import KeyBitBase class UpdatedAtKeyBit(KeyBitBase): key = \"updated_at\" def get_data(self, **kwargs): value = cache.get(self.key, None) if not value: value = datetime.now() # 这边的缓存时间可以和数据的缓存时间一样（或比数据缓存的时间长） # 短了的话（取不到值），获取后生成的数据缓存key跟缓存的key不一样，会重新查询数据库 cache.set(self.key, value=value, timeout=5 * 60) return str(value) get_data 方法返回这个 KeyBit 对应的值，UpdatedAtKeyBit 首先根据设置的 key 从缓存中读取资源最近更新的时间，如果读不到就将资源最近更新的时间设为当前时间，然后返回这个时间。 当然，我们需要自动维护缓存中记录的资源更新时间，这可以通过 django 的 signal 来完成： # 也可以写在blog/signals.py blog/models.py from django.db.models.signals import post_delete, post_save def change_post_updated_at(sender=None, instance=None, *args, **kwargs): cache.set(\"post_updated_at\", datetime.utcnow()) post_save.connect(receiver=change_post_updated_at, sender=Post) post_delete.connect(receiver=change_post_updated_at, sender=Post) 每当有文章（Post）被新增、修改或者删除时，django 会发出 post_save 或者 post_delete 信号，post_save.connect 和 post_delete.connect 设置了这两个信号的接收器为 change_post_updated_at，信号发出后该方法将被调用，往缓存中写入文章资源的更新时间。 整理一下请求被缓存的逻辑： 请求文章列表接口 根据 PostListKeyConstructor 生成缓存 key，如果使用这个 key 读取到了缓存结果，就直接返回读取到的结果，否则从数据库查询结果，并把查询的结果写入缓存。 再次请求文章列表接口，PostListKeyConstructor 将生成同样的缓存 key，这时就可以直接从缓存中读到结果并返回了。 缓存更新的逻辑： 新增、修改或者删除文章，触发 post_delete, post_save 信号，文章资源的更新时间将被修改。 再次请求文章列表接口，PostListKeyConstructor 将生成不同的缓存 key，这个新的 key 不在缓存中，因此将从数据库查询最新结果，并把查询的结果写入缓存。 再次请求文章列表接口，PostListKeyConstructor 将生成同样的缓存 key，这时就可以直接从缓存中读到结果并返回了。 PostObjectKeyConstructor 用于文章详情接口缓存 key 的生成，逻辑和 PostListKeyConstructor 是完全一样。 5、缓存评论列表 有了文章列表的缓存，评论列表的缓存只需要依葫芦画瓢。 KeyBit 定义： blog/views.py class CommentUpdatedAtKeyBit(UpdatedAtKeyBit): key = \"comment_updated_at\" KeyConstructor 定义： blog/views.py class CommentListKeyConstructor(DefaultKeyConstructor): list_sql = ListSqlQueryKeyBit() pagination = PaginationKeyBit() updated_at = CommentUpdatedAtKeyBit() 视图集： @cache_response(timeout=5 * 60, key_func=CommentListKeyConstructor()) @action( methods=[\"GET\"], detail=True, url_path=\"comments\", url_name=\"comment\", pagination_class=LimitOffsetPagination, serializer_class=CommentSerializer, ) def list_comments(self, request, *args, **kwargs): # ... 6、Redis 服务 本地内存缓存服务配置简单，适合在开发环境使用，但无法适应多线程和多进程适的环境，线上环境我们使用 Redis 做缓存。有了 Docker，启动一个 Redis 服务就是一件非常简单的事。 在线上环境的容器编排文件 production.yml 中加入一个 Redis 服务： version: '3' volumes: static: database: esdata: redis_data: services: hellodjango.rest.framework.tutorial: ... depends_on: - elasticsearch - redis redis: image: 'bitnami/redis:5.0' container_name: hellodjango_rest_framework_tutorial_redis ports: - '6379:6379' volumes: - 'redis_data:/bitnami/redis/data' env_file: - .envs/.production 然后在 .envs/.production 文件中添加如下的环境变量，这个值将作为 redis 连接的密码： REDIS_PASSWORD=055EDy65AAhLgBxMp1u1 然后就可以将服务发布上线了。 "},"Python/第三方库/FastAPI/基础/01-pydantic.html":{"url":"Python/第三方库/FastAPI/基础/01-pydantic.html","title":"pydantic","keywords":"","body":"datetime:2022/09/24 15:44 author:nzb pydantic 基础使用 from datetime import datetime, date from pathlib import Path from typing import Optional, List from pydantic import BaseModel, ValidationError, constr from sqlalchemy import Column, Integer, String from sqlalchemy.dialects.postgresql import ARRAY from sqlalchemy.ext.declarative import declarative_base \"\"\" Data validation and settings management using python type annotations. 使用Python的类型注解来进行数据校验和settings管理 pydantic enforces type hints at runtime, and provides user friendly errors when data is invalid. Pydantic可以在代码运行时提供类型提示，数据校验失败时提供友好的错误提示 Define how data should be in pure, canonical python; validate it with pydantic. 定义数据应该如何在纯规范的Python代码中保存，并用Pydantic验证它 \"\"\" class User(BaseModel): id: int # 必填类型 name: str = \"Jack\" # 有默认值，选填字段 signup_ts: Optional[datetime] = None # 选填字段 friends: List[int] = [] # 列表中元素是 int 类型或者可以直接转换成 int 类型 external_data = { \"id\": \"123\", \"signup_ts\": \"2022-07-06 10:45\", \"friends\": [1, 2, \"3\"] # \"3\" 是可以 int(\"3\")的 } print(\"\\033[31m1. --- Pydantic的基本用法。Pycharm可以安装Pydantic插件 ---\\033[0m\") user = User(**external_data) print(user.id, user.friends) print(user.signup_ts) print(user.dict()) print(\"\\033[31m2. --- 校验失败处理 ---\\033[0m\") try: User(id=1, signup_ts=datetime.today(), friends=[1, 2, 'not number']) except ValidationError as e: print(e.json()) print(\"\\033[31m3. --- 模型类的的属性和方法 ---\\033[0m\") print(user.dict()) print(user.json()) print(user.copy()) # 浅拷贝 print(User.parse_obj(external_data)) print(User.parse_raw('{\"id\": \"123\", \"signup_ts\": \"2020-12-22 12:22\", \"friends\": [1, 2, \"3\"]}')) path = Path(\"pydantic_tutorial.json\") path.write_text('{\"id\": \"123\", \"signup_ts\": \"2020-12-22 12:22\", \"friends\": [1, 2, \"3\"]}') print(User.parse_file(path)) print(user.schema()) print(user.schema_json()) user_data = {\"id\": \"error\", \"signup_ts\": \"2020-12-22 12:22\", \"friends\": [1, 2, 3]} # id是字符串 是错误的 print(User.construct(**user_data)) # 不检验数据直接创建模型类，不建议在construct方法中传入未经验证的数据 # name='Jack' signup_ts='2020-12-22 12:22' friends=[1, 2, 3] id='error' print(User.__fields__.keys()) # 定义模型类的时候，所有字段都注明类型，字段顺序就不会乱 print(\"\\033[31m4. --- 递归模型 ---\\033[0m\") class Sound(BaseModel): sound: str class Dog(BaseModel): birthday: date weight: float = Optional[None] sound: List[Sound] # 不同的狗有不同的叫声。递归模型（Recursive Models）就是指一个嵌套一个 dogs = Dog(birthday=date.today(), weight=6.66, sound=[{\"sound\": \"wang wang ~\"}, {\"sound\": \"ying ying ~\"}]) print(dogs.dict()) print(\"\\033[31m5. --- ORM模型：从类实例创建符合ORM对象的模型 ---\\033[0m\") Base = declarative_base() class ComanyOrm(Base): __tablename__ = \"companies\" id = Column(Integer, primary_key=True, nullable=True) public_key = Column(String(20), index=True, nullable=True, unique=True) name = Column(String(64), unique=True) domains = Column(ARRAY(String(255))) class ComanyModel(BaseModel): id: int public_key: constr(max_length=20) name: constr(max_length=64) domains: List[constr(max_length=255)] class Config: orm_mode = True company_orm = ComanyOrm( id=123, public_key=\"foobar\", name=\"Testing\", domains=[\"demo.com\", \"example.com\"] ) print(ComanyModel.from_orm(company_orm)) print(\"\\033[31m6. --- Pydantic支撑的字段类型,官方文档：https://pydantic-docs.helpmanual.io/usage/types/ ---\\033[0m\") 1. --- Pydantic的基本用法。Pycharm可以安装Pydantic插件 --- 123 [1, 2, 3] 2022-07-06 10:45:00 {'id': 123, 'name': 'Jack', 'signup_ts': datetime.datetime(2022, 7, 6, 10, 45), 'friends': [1, 2, 3]} 2. --- 校验失败处理 --- [ { \"loc\": [ \"friends\", 2 ], \"msg\": \"value is not a valid integer\", \"type\": \"type_error.integer\" } ] 3. --- 模型类的的属性和方法 --- {'id': 123, 'name': 'Jack', 'signup_ts': datetime.datetime(2022, 7, 6, 10, 45), 'friends': [1, 2, 3]} {\"id\": 123, \"name\": \"Jack\", \"signup_ts\": \"2022-07-06T10:45:00\", \"friends\": [1, 2, 3]} id=123 name='Jack' signup_ts=datetime.datetime(2022, 7, 6, 10, 45) friends=[1, 2, 3] id=123 name='Jack' signup_ts=datetime.datetime(2022, 7, 6, 10, 45) friends=[1, 2, 3] id=123 name='Jack' signup_ts=datetime.datetime(2020, 12, 22, 12, 22) friends=[1, 2, 3] id=123 name='Jack' signup_ts=datetime.datetime(2020, 12, 22, 12, 22) friends=[1, 2, 3] {'title': 'User', 'type': 'object', 'properties': {'id': {'title': 'Id', 'type': 'integer'}, 'name': {'title': 'Name', 'default': 'Jack', 'type': 'string'}, 'signup_ts': {'title': 'Signup Ts', 'type': 'string', 'format': 'date-time'}, 'friends': {'title': 'Friends', 'default': [], 'type': 'array', 'items': {'type': 'integer'}}}, 'required': ['id']} {\"title\": \"User\", \"type\": \"object\", \"properties\": {\"id\": {\"title\": \"Id\", \"type\": \"integer\"}, \"name\": {\"title\": \"Name\", \"default\": \"Jack\", \"type\": \"string\"}, \"signup_ts\": {\"title\": \"Signup Ts\", \"type\": \"string\", \"format\": \"date-time\"}, \"friends\": {\"title\": \"Friends\", \"default\": [], \"type\": \"array\", \"items\": {\"type\": \"integer\"}}}, \"required\": [\"id\"]} name='Jack' signup_ts='2020-12-22 12:22' friends=[1, 2, 3] id='error' dict_keys(['id', 'name', 'signup_ts', 'friends']) 4. --- 递归模型 --- {'birthday': datetime.date(2022, 9, 24), 'sound': [{'sound': 'wang wang ~'}, {'sound': 'ying ying ~'}]} 5. --- ORM模型：从类实例创建符合ORM对象的模型 --- id=123 public_key='foobar' name='Testing' domains=['demo.com', 'example.com'] 6. --- Pydantic支撑的字段类型,官方文档：https://pydantic-docs.helpmanual.io/usage/types/ --- "},"Python/第三方库/FastAPI/基础/02-hello_world.html":{"url":"Python/第三方库/FastAPI/基础/02-hello_world.html","title":"hello_world","keywords":"","body":"datetime:2022/09/24 15:44 author:nzb FastAPI hello world __date__ = \"2022/7/6 14:58\" __doc__ = \"\"\"第二章文件\"\"\" from typing import Optional from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class CityInfo(BaseModel): province: str country: str is_affected: Optional[bool] = None # 与 bool 的区别是可以不传，默认是 null @app.get(\"/\") def hello_world(): return {\"hello\": \"world\"} @app.get(\"/city/{city}\") def result(city: str, query_string: Optional[str] = None): return {\"city\": city, \"query_string\": query_string} @app.put(\"/city/{city}\") def result(city: str, city_info: CityInfo): return {\"city\": city, \"countyr\": city_info.country, \"is_affected\": city_info.is_affected} # 启动命令：uvicorn hello_world:app --reload "},"Python/第三方库/FastAPI/基础/03-请求参数和验证.html":{"url":"Python/第三方库/FastAPI/基础/03-请求参数和验证.html","title":"请求参数和验证","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb 请求参数和验证 from enum import Enum from typing import Optional, List from datetime import date from fastapi import APIRouter, Path, Query, Body, Cookie, Header from pydantic import Field from pydantic.main import BaseModel app3 = APIRouter() \"\"\"Path Parameters and Number Validations 路径参数和数字验证\"\"\" @app3.get(\"/path/parameters\") async def path_params01(): return {\"message\": \"This is message\"} @app3.get(\"/path/{parameters}\") # 函数的顺序就是路由的顺序 async def path_params02(parameters: str): return {\"message\": parameters} class CityName(str, Enum): BeiJing = \"BeiJing China\" Shanghai = \"Shanghai China\" @app3.get(\"/enum/{city}\") # 枚举类型的参数 async def latest(city: CityName): if city == CityName.BeiJing: return {\"city_name\": city, \"confirmed\": 1492, \"death\": 7} elif city == CityName.Shanghai: return {\"city_name\": city, \"confirmed\": 971, \"death\": 9} return {\"city_name\": city, \"latest\": \"unknown\"} @app3.get(\"/files/{file_path:path}\") # 通过path parameters传递文件路径 async def filepath(file_path: str): return f\"The file path is {file_path}\" @app3.get(\"/validate_path/{num}\") async def path_params_validate( num: int = Path(..., title=\"Your Number\", description=\"不可描述\", ge=1, le=10) ): return num \"\"\"Query Parameters and String Validations 查询参数和字符串验证\"\"\" @app3.get(\"/query\") async def page_limit(page: int = 1, limit: Optional[int] = None): # 给了默认值就是选填的参数，没给默认值就是必填参数 if limit: return {\"page\": page, \"limit\": limit} return {\"page\": page} @app3.get(\"/query/bool/conversion\") async def type_conversion(param: bool = True): # bool类型转换：yes on 1 True true会转换成true, 其它为false return param @app3.get(\"/query/validations\") # 长度+正则表达式验证，比如长度8-16位，以a开头。其它校验方法看Query类的源码 async def query_params_validate( value: str = Query(..., min_length=5, max_length=10, regex=\"^a\"), # ...换成None就变成选填的参数 values: List[str] = Query([\"v1\", \"v2\"], alias=\"alias_name\") # 多个查询参数的列表。参数别名 ): return value, values \"\"\"Request Body and Fields 请求体和字段\"\"\" class CityInfo(BaseModel): name: str = Field(..., example=\"Beijing\") # example是注解的作用，值不会被验证 country: str country_code: str = None # 给一个默认值 country_population: int = Field(default=800, title=\"人口数量\", description=\"国家人口数量\", ge=800) class Config: schema_extra = { \"example\": { \"name\": \"Shanghai\", \"country\": \"China\", \"country_code\": \"CN\", \"country_population\": 1400000000 } } @app3.post(\"/request_body/city\") async def city_info(city: CityInfo): print(city.name, city.country) # 当在IDE中输入city.的时候，属性会自动弹出 return city.dict() \"\"\"Request Body + Path parameters + Query parameters 多参数混合\"\"\" @app3.put(\"/request_body/city/{name}\") async def mix_city_info( name: str, city01: CityInfo, city02: CityInfo, # Body可以是多个的 confirmed: int = Query(ge=0, description=\"确诊数\", default=0), death: int = Query(ge=0, description=\"死亡数\", default=0) ): if name == \"Shanghai\": return {\"Shanghai\": {\"confirmed\": confirmed, \"death\": death}} return city01.dict(), city02.dict() @app3.put(\"/request_body/multiple/parameters\") async def body_multiple_parameters( city: CityInfo = Body(..., embed=True), # 当只有一个Body参数的时候，embed=True表示请求体参数嵌套。多个Body参数默认就是嵌套的 confirmed: int = Query(ge=0, description=\"确诊数\", default=0), death: int = Query(ge=0, description=\"死亡数\", default=0) ): print(f\"{city.name} 确诊数：{confirmed} 死亡数：{death}\") return city.dict() \"\"\"Request Body - Nested Models 数据格式嵌套的请求体\"\"\" class Data(BaseModel): city: List[CityInfo] = None # 这里就是定义数据格式嵌套的请求体 date: date # 额外的数据类型，还有uuid datetime bytes frozenset等，参考：https://fastapi.tiangolo.com/tutorial/extra-data-types/ confirmed: int = Field(ge=0, description=\"确诊数\", default=0) deaths: int = Field(ge=0, description=\"死亡数\", default=0) recovered: int = Field(ge=0, description=\"痊愈数\", default=0) @app3.put(\"/request_body/nested\") async def nested_models(data: Data): return data \"\"\"Cookie 和 Header 参数\"\"\" @app3.get(\"/cookie\") # 效果只能用Postman测试 async def cookie(cookie_id: Optional[str] = Cookie(None)): # 定义Cookie参数需要使用Cookie类，否则就是查询参数 return {\"cookie_id\": cookie_id} @app3.get(\"/header\") async def header(user_agent: Optional[str] = Header(None, convert_underscores=True), x_token: List[str] = Header(None)): \"\"\" 有些HTTP代理和服务器是不允许在请求头中带有下划线的，所以Header提供convert_underscores属性让设置 :param user_agent: convert_underscores=True 会把 user_agent 变成 user-agent :param x_token: x_token是包含多个值的列表 :return: \"\"\" return {\"User-Agent\": user_agent, \"x_token\": x_token} "},"Python/第三方库/FastAPI/基础/04-响应处理和FastAPI配置.html":{"url":"Python/第三方库/FastAPI/基础/04-响应处理和FastAPI配置.html","title":"响应处理和FastAPI配置","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb 响应处理和FastAPI配置 from typing import Optional, List from fastapi import APIRouter, status, Form, File, UploadFile, HTTPException from pydantic import EmailStr from pydantic.main import BaseModel app4 = APIRouter() \"\"\"Response Model 响应模型\"\"\" class UserIn(BaseModel): username: str password: str email: EmailStr mobile: str = \"10086\" address: str = None full_name: Optional[str] = None class UserOut(BaseModel): username: str email: EmailStr # 用 EmailStr 需要 pip install pydantic[email] mobile: str = \"10086\" address: str = None full_name: Optional[str] = None users = { \"user01\": {\"username\": \"user01\", \"password\": \"123123\", \"email\": \"user01@example.com\"}, \"user02\": {\"username\": \"user02\", \"password\": \"123456\", \"email\": \"user02@example.com\", \"mobile\": \"110\"} } @app4.post(\"/response_model\", response_model=UserOut, response_model_exclude_unset=True) async def response_model(user: UserIn): \"\"\"response_model_exclude_unset=True表示默认值不包含在响应中，仅包含实际给的值，如果实际给的值与默认值相同也会包含在响应中\"\"\" print(user.password) # password不会被返回 # return user return users[\"user02\"] @app4.post( \"/response_model/attributes\", response_model=UserOut, # response_model_include=['username', 'email', 'mobile'], response_model_exclude=['mobile'], # response_model=Union[UserIn, UserOut], # response_model=List[UserOut], ) async def response_model_attributes(user: UserIn): \"\"\"response_model_include列出需要在返回结果中包含的字段；response_model_exclude列出需要在返回结果中排除的字段\"\"\" # del user.password # Union[UserIn, UserOut]后，删除password属性也能返回成功 return user # return [user, user] # List[UserOut], \"\"\"Response Status Code 响应状态码\"\"\" @app4.post(\"/status_code\", status_code=200) async def status_code(): return {\"status_code\": 200} @app4.post(\"/status_attribute\", status_code=status.HTTP_200_OK) async def status_code(): print(type(status.HTTP_200_OK)) return {\"status_code\": status.HTTP_200_OK} \"\"\"Form Data 表单数据处理\"\"\" @app4.post(\"/login\") async def login(username: str = Form(...), password: str = Form(...)): # 定义表单参数 \"\"\"用Form类需要pip install python-multipart; Form类的元数据和校验方法类似Body/Query/Path/Cookie\"\"\" return {\"username\": username} \"\"\"Request Files 单文件、多文件上传及参数详解\"\"\" @app4.post(\"/file\") async def file_(file: bytes = File(...)): # 如果要上传多个文件 files: List[bytes] = File(...) \"\"\"使用File类 文件内容会以bytes的形式读入内存 适合于上传小文件\"\"\" return {\"file_size\": len(file)} @app4.post(\"/upload_files\") async def upload_files(files: List[UploadFile] = File(...)): # 如果要上传单个文件 file: UploadFile = File(...) \"\"\" 使用UploadFile类的优势: 1.文件存储在内存中，使用的内存达到阈值后，将被保存在磁盘中 2.适合于图片、视频大文件 3.可以获取上传的文件的元数据，如文件名，创建时间等 4.有文件对象的异步接口 5.上传的文件是Python文件对象，可以使用write(), read(), seek(), close()操作 \"\"\" for file in files: contents = await file.read() print(contents) return {\"filename\": files[0].filename, \"content_type\": files[0].content_type} \"\"\"【见main.py】FastAPI项目的静态文件配置\"\"\" \"\"\"Path Operation Configuration 路径操作配置\"\"\" @app4.post( \"/path_operation_configuration\", response_model=UserOut, # tags=['Path', 'Operation', 'Configuration'], summary=\"This is summary\", description=\"This is description\", response_description=\"This is response description\", # deprecated=True, status_code=status.HTTP_200_OK ) async def path_operation_configuration(user: UserIn): \"\"\" Path Operation Configuration 路径操作配置 :param user: 用户信息 :return: 返回结果 \"\"\" return user.dict() \"\"\"【见main.py】FastAPI 应用的常见配置项\"\"\" \"\"\"Handling Errors 错误处理\"\"\" @app4.get(\"/http_exception\") async def http_exception(city: str): if city != \"Beijing\": raise HTTPException(status_code=404, detail=\"City not found!\", headers={\"X-Error\": \"Error\"}) return {\"city\": city} @app4.get(\"/http_exception/{city_id}\") async def override_http_exception(city_id: int): if city_id == 1: raise HTTPException(status_code=418, detail=\"Nope! I don't like 1.\") return {\"city_id\": city_id} "},"Python/第三方库/FastAPI/基础/05-FastAPI的依赖注入系统.html":{"url":"Python/第三方库/FastAPI/基础/05-FastAPI的依赖注入系统.html","title":"FastAPI的依赖注入系统","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb FastAPI的依赖注入系统 from typing import Optional from fastapi import APIRouter, Depends, Header, HTTPException app5 = APIRouter() \"\"\"Dependencies 创建、导入和声明依赖\"\"\" async def common_parameters(q: Optional[str] = None, page: int = 1, limit: int = 100): return {\"q\": q, \"page\": page, \"limit\": limit} @app5.get(\"/dependency01\") async def dependency01(commons: dict = Depends(common_parameters)): return commons @app5.get(\"/dependency02\") def dependency02(commons: dict = Depends(common_parameters)): # 可以在async def中调用def依赖，也可以在def中导入async def依赖 return commons \"\"\"Classes as Dependencies 类作为依赖项\"\"\" fake_items_db = [{\"item_name\": \"Foo\"}, {\"item_name\": \"Bar\"}, {\"item_name\": \"Baz\"}] class CommonQueryParams: def __init__(self, q: Optional[str] = None, page: int = 1, limit: int = 100): self.q = q self.page = page self.limit = limit @app5.get(\"/classes_as_dependencies\") # async def classses_as_dependencies(commons: CommonQueryParams = Depends(CommonQueryParams)): # async def classses_as_dependencies(commons: CommonQueryParams = Depends()): async def classses_as_dependencies(commons=Depends(CommonQueryParams)): resp = {} if commons.q: resp.update({\"q\": commons.q}) items = fake_items_db[commons.page: commons.page + commons.limit] resp.update({\"items\": items}) return resp \"\"\"Sub-dependencies 子依赖\"\"\" def query(q: Optional[str] = None): # pass 根据参数需要的公共业务逻辑 return q def sub_query(q: str = Depends(query), last_query: Optional[str] = None): if not q: return last_query return q @app5.get(\"/sub_dependency\") async def sub_dependency(final_query: str = Depends(sub_query, use_cache=True)): \"\"\"use_cache默认是True, 表示当多个依赖有一个共同的子依赖时，每次request请求只会调用子依赖一次，多次调用将从缓存中获取\"\"\" return {\"sub_dependency\": final_query} \"\"\"Dependencies in path operation decorators 路径操作装饰器中的多依赖\"\"\" async def verify_token(x_token: str = Header(...)): \"\"\"没有返回值的子依赖\"\"\" if x_token != \"fake-user-token\": return HTTPException(status_code=400, detail=\"X-Token header invalid\") async def verify_key(x_key: str = Header(...)): \"\"\"有返回值的子依赖，但是返回值不会被调用\"\"\" if x_key != \"fake-user-key\": raise HTTPException(status_code=400, detail=\"X-Key header invalid\") return x_key @app5.get(\"/dependency_in_path_operation\", dependencies=[Depends(verify_token), Depends(verify_key)]) async def dependency_in_path_operation(): return [{\"user\": \"user01\"}, {\"user\": \"user02\"}] \"\"\"Global Dependencies 全局依赖\"\"\" # app5 = APIRouter(dependencies=[Depends(verify_token), Depends(verify_key)]) \"\"\"Dependencies with yield 带yield的依赖\"\"\" # 这个需要Python3.7才支持，Python3.6需要pip install async-exit-stack async-generator # 以下都是伪代码 async def get_db(): db = \"db_connection\" try: yield db finally: db.endswith(\"db_close\") async def dependency_a(): dep_a = \"generate_dep_a()\" try: yield dep_a finally: dep_a.endswith(\"db_close\") async def dependency_b(dep_a=Depends(dependency_a)): dep_b = \"generate_dep_b()\" try: yield dep_b finally: dep_b.endswith(dep_a) # 关闭子依赖 a async def dependency_c(dep_b=Depends(dependency_b)): dep_c = \"generate_dep_c()\" try: yield dep_c finally: dep_c.endswith(dep_b) # 关闭子依赖 b "},"Python/第三方库/FastAPI/基础/06-安全、认证和授权.html":{"url":"Python/第三方库/FastAPI/基础/06-安全、认证和授权.html","title":"安全、认证和授权","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb 安全、认证和授权 import datetime from datetime import timedelta from typing import Optional from fastapi import APIRouter, Depends, HTTPException, status from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm from jose import jwt, JWTError from passlib.context import CryptContext from pydantic.main import BaseModel app6 = APIRouter() \"\"\"OAuth2 密码模式和 FastAPI 的 OAuth2PasswordBearer\"\"\" \"\"\" OAuth2PasswordBearer是接收URL作为参数的一个类：客户端会向该URL发送username和password参数，然后得到一个Token值 OAuth2PasswordBearer并不会创建相应的URL路径操作，只是指明客户端用来请求Token的URL地址 当请求到来的时候，FastAPI会检查请求的Authorization头信息，如果没有找到Authorization头信息，或者头信息的内容不是Bearer token，它会返回401状态码(UNAUTHORIZED) \"\"\" # 请求Token的URL地址 http://127.0.0.1:8000/chapter06/token # 下面有接口 oauth2_schema = OAuth2PasswordBearer(tokenUrl=\"/chapter06/token\") @app6.get(\"/oauth2_password_bearer\") async def oauth2_password_bearer(token: str = Depends(oauth2_schema)): return {\"token\": token} \"\"\"基于 Password 和 Bearer token 的 OAuth2 认证\"\"\" fake_users_db = { \"john snow\": { \"username\": \"john snow\", \"full_name\": \"John Snow\", \"email\": \"johnsnow@example.com\", \"hashed_password\": \"fakehashedsecret\", \"disabled\": False, }, \"alice\": { \"username\": \"alice\", \"full_name\": \"Alice Wonderson\", \"email\": \"alice@example.com\", \"hashed_password\": \"fakehashedsecret2\", \"disabled\": True, }, } def fake_hash_password(password: str): return \"fakehashed\" + password class User(BaseModel): username: str email: Optional[str] = None full_name: Optional[str] = None disabled: Optional[bool] = None class UserInDB(User): hashed_password: str @app6.post(\"/token\") async def login(form_data: OAuth2PasswordRequestForm = Depends()): user_dict = fake_users_db.get(form_data.username) if not user_dict: raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Incorrect username or password\") user = UserInDB(**user_dict) hashed_pwd = fake_hash_password(form_data.password) if hashed_pwd != user.hashed_password: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Incorrect username or password\") return {\"access_token\": user.username, \"token_type\": \"bearer\"} def get_user(db, username: str): if username in db: user_dict = db.get(username) return UserInDB(**user_dict) async def get_current_user(token: str = Depends(oauth2_schema)): user = get_user(fake_users_db, token) if not user: raise HTTPException( status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid authentication credentials\", headers={\"WWW-Authenticate\": \"Bearer\"}, # OAuth2的规范，如果认证失败，请求头中返回“WWW-Authenticate” ) return user async def get_current_active_user(current_user: User = Depends(get_current_user)): if current_user.disabled: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Inactive user\") return current_user @app6.get(\"/user/me\") async def read_users_me(current_user: User = Depends(get_current_active_user)): return current_user \"\"\"OAuth2 with Password (and hashing), Bearer with JWT tokens 开发基于JSON Web Tokens的认证\"\"\" fake_users_db.update({ \"john snow\": { \"username\": \"john snow\", \"full_name\": \"John Snow\", \"email\": \"johnsnow@example.com\", \"hashed_password\": \"$2b$12$EixZaYVK1fsbw1ZfbX30XePaWxn96p36WQoeG6Lruj3vjPGga31lW\", \"disabled\": False, } }) SECRET_KEY = \"09d25e094faa6ca2556c818166b7a9563b93f7099f6f0f4caa6cf63b88e8d3e7\" # 生成密钥 openssl rand -hex 32 ALGORITHM = \"HS256\" # 算法 ACCESS_TOKEN_EXPIRE_MINUTES = 30 # 访问令牌过期分钟 class Token(BaseModel): \"\"\"返回给用户的Token\"\"\" access_token: str token_type: str pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\") oauth2_schema = OAuth2PasswordBearer(tokenUrl=\"/chapter06/jwt/token\") def jwt_get_user(db, username: str): if username in db: user = db.get(username) return UserInDB(**user) def jwt_authenticate_user(db, username: str, password: str): user = jwt_get_user(db=db, username=username) if not user: return False if not pwd_context.verify(password, user.hashed_password): return False return user def create_access_token(data: dict, expires_detlta: Optional[timedelta] = None): to_encode = data.copy() if expires_detlta: expire = datetime.datetime.utcnow() + expires_detlta else: expire = datetime.datetime.utcnow() + timedelta(minutes=15) to_encode.update({\"exp\": expire}) encode_jwt = jwt.encode(to_encode, key=SECRET_KEY, algorithm=ALGORITHM) return encode_jwt @app6.post(\"/jwt/token\", response_model=Token) async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends()): user = jwt_authenticate_user(fake_users_db, username=form_data.username, password=form_data.password) if not user: raise HTTPException( status.HTTP_401_UNAUTHORIZED, detail=\"Incorrect username or password\", headers={\"WWW-Authenticate\": \"Bearer\"}, ) access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES) access_token = create_access_token(data={\"sub\": user.username}, expires_detlta=access_token_expires) return {\"access_token\": access_token, \"token_type\": \"bearer\"} async def jwt_get_current_user(token: str = Depends(oauth2_schema)): credentials_exception = HTTPException( status.HTTP_401_UNAUTHORIZED, detail=\"Could not validate credentials\", headers={\"WWW-Authenticate\": \"Bearer\"}, ) try: payload = jwt.decode(token, key=SECRET_KEY, algorithms=[ALGORITHM]) username = payload.get(\"sub\") if not username: raise credentials_exception except JWTError: raise credentials_exception user = jwt_get_user(db=fake_users_db, username=username) if not user: raise credentials_exception return user async def jwt_get_current_active_user(current_user: User = Depends(jwt_get_current_user)): if current_user.disabled: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Inactive user\") return current_user @app6.get(\"/jwt/users/me\") async def jwt_read_users_me(current_user: User = Depends(jwt_get_current_active_user)): return current_user "},"Python/第三方库/FastAPI/基础/07-FastAPI的数据库操作和多应用的目录结构设计.html":{"url":"Python/第三方库/FastAPI/基础/07-FastAPI的数据库操作和多应用的目录结构设计.html","title":"FastAPI的数据库操作和多应用的目录结构设计","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb FastAPI的数据库操作和多应用的目录结构设计 from fastapi import APIRouter, Depends, Request \"\"\"【见coronavirus应用】SQL (Relational) Databases FastAPI的数据库操作\"\"\" \"\"\"Bigger Applications - Multiple Files 多应用的目录结构设计\"\"\" async def get_user_agent(request: Request): print(request.headers[\"User-Agent\"]) app7 = APIRouter( prefix=\"/bigger_applications\", tags=[\"第七章 FastAPI的数据库操作和多应用的目录结构设计\"], # 与run.py中的tags名称相同 dependencies=[Depends(get_user_agent)], responses={200: {\"description\": \"Good job!\"}} ) @app7.get(\"/bigger_applications\") async def bigger_applications(): return {\"message\": \"Bigger Applicatins - Multiple Files\"} "},"Python/第三方库/FastAPI/基础/08-中间件、CORS、后台任务、测试用例.html":{"url":"Python/第三方库/FastAPI/基础/08-中间件、CORS、后台任务、测试用例.html","title":"中间件、CORS、后台任务、测试用例","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb 中间件、CORS、后台任务、测试用例 from typing import Optional from fastapi import APIRouter, BackgroundTasks, Depends app8 = APIRouter() \"\"\"【见main.py】Middleware 中间件\"\"\" # 注：带yield的依赖的退出部分的代码 和 后台任务 会在中间件之后运行 \"\"\"【见main.py】CORS (Cross-Origin Resource Sharing) 跨源资源共享\"\"\" # 域的概念：协议+域名+端口 \"\"\"Background Tasks 后台任务\"\"\" def bg_task(framework: str): with open(\"README.md\", mode='a') as f: f.write(f\"## {framework}框架精讲\") @app8.post(\"/background_tasks\") async def run_bg_task(framework: str, background_tasks: BackgroundTasks): \"\"\" :param framework: 被调用的后台任务函数的参数 :param background_tasks: FastAPI.BackgroundTasks :return: \"\"\" background_tasks.add_task(bg_task, framework) return {\"message\": \"任务已在后台运行\"} def continue_write_readme(background_tasks: BackgroundTasks, q: Optional[str] = None): if q: background_tasks.add_task(bg_task, \"\\n> 整体的介绍 FastAPI，快速上手开发，结合 API 交互文档逐个讲解核心模块的使用\\n\") return q @app8.post(\"/dependency/background_tasks\") async def dependency_run_bg_task(q: str = Depends(continue_write_readme)): if q: return {\"message\": \"README.md更新成功\"} "},"Python/第三方库/FastAPI/基础/09-示例新冠病毒疫情跟踪器API.html":{"url":"Python/第三方库/FastAPI/基础/09-示例新冠病毒疫情跟踪器API.html","title":"示例新冠病毒疫情跟踪器API","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb 新冠病毒疫情跟踪器API router.py from typing import List import requests from fastapi import APIRouter, Depends, HTTPException, status, Request, BackgroundTasks from fastapi.templating import Jinja2Templates from pydantic import HttpUrl from sqlalchemy.orm import Session from .database import Base, engine, SessionLocal from . import curd, schemas, models application = APIRouter() templates = Jinja2Templates(directory=\"./coronavirus/templates\") Base.metadata.create_all(bind=engine) def get_db(): db = SessionLocal() try: yield db finally: db.close() @application.post(\"/create_city\", response_model=schemas.ReadCity) async def create_city(city: schemas.CreateCity, db: Session = Depends(get_db)): db_city = curd.get_city_by_name(db, name=city.province) if db_city: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"City already registered\") return curd.create_city(db, city) @application.get(\"/get_city/{city}\", response_model=schemas.ReadCity) async def get_city(city: str, db: Session = Depends(get_db)): db_city = curd.get_city_by_name(db, name=city) if db_city is None: raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"City not found\") return db_city @application.get(\"/get_cities\", response_model=List[schemas.ReadCity]) async def get_cities(offset: int = 0, limit: int = 100, db: Session = Depends(get_db)): cities = curd.get_cities(db, offset=offset, limit=limit) return cities @application.post(\"/create_data\", response_model=schemas.ReadData) async def ceate_data_for_city(city: str, data: schemas.CreateData, db: Session = Depends(get_db)): db_city = curd.get_city_by_name(db, name=city) if db_city is None: raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"City not found\") data = curd.create_city_data(db=db, data=data, city_id=db_city.id) return data @application.get(\"/get_data\") def get_data(city: str = None, offset: int = 0, limit: int = 100, db: Session = Depends(get_db)): data = curd.get_data(db, city=city, offset=offset, limit=limit) return data def bg_task(url: HttpUrl, db: Session): \"\"\"这里注意一个坑，不要在后台任务的参数中db: Session = Depends(get_db)这样导入依赖\"\"\" city_data = requests.get(url=f\"{url}?source=jhu&country_code=CN&timelines=false\") if city_data.status_code == 200: db.query(models.City).delete() # 同步数据前先清空原有的数据 for loc in city_data.json().get(\"locations\", []): city = { \"province\": loc[\"province\"], \"country\": loc[\"country\"], \"country_code\": \"CN\", \"country_population\": loc[\"country_population\"] } curd.create_city(db, schemas.CreateCity(**city)) coronavirus_data = requests.get(url=f\"{url}?source=jhu&country_code=CN&timelines=true\") if coronavirus_data.status_code == 200: db.query(models.Data).delete() for city in coronavirus_data.json().get(\"locations\", []): db_city = curd.get_city_by_name(db, name=city.get(\"province\", \"\")) for date, confirmed in city[\"timelines\"]['confirmed']['timeline'].items(): data = { \"date\": date.split(\"T\")[0], # 把'2020-12-31T00:00:00Z' 变成 ‘2020-12-31’ \"confirmed\": confirmed, \"deaths\": city[\"timelines\"][\"deaths\"][\"timeline\"][date], \"recovered\": 0 # 每个城市每天有多少人痊愈，这种数据没有 } # 这个city_id是city表中的主键ID，不是coronavirus_data数据里的ID curd.create_city_data(db, schemas.CreateData(**data), city_id=db_city.id) @application.get(\"/sync_coronavirus_data/jhu\") async def sync_coronavirus_data(background_tasks: BackgroundTasks, db: Session = Depends(get_db)): \"\"\"从Johns Hopkins University同步COVID-19数据\"\"\" background_tasks.add_task(bg_task, \"https://coronavirus-tracker-api.herokuapp.com/v2/locations\", db) return {\"message\": \"正在后台同步数据...\"} @application.get(\"/\") async def coronavirus(request: Request, city: str = None, offset: int = 0, limit: int = 100, db: Session = Depends(get_db)): data = curd.get_data(db, city=city, offset=offset, limit=limit) return templates.TemplateResponse(\"home.html\", { \"request\": request, \"data\": data, \"sync_data_url\": \"/coronavirus/sync_coronavirus_data/jhu\" }) database.py from sqlalchemy import create_engine from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker SQLALCHEMY_DATABASE_URL = \"sqlite:///./coronavirus.sqlite3\" # SQLALCHEMY_DATABASE_URL = \"postgresql://username:password@host:port/database_name\" # MySQL或PostgreSQL的连接方法 engine = create_engine( # echo=True表示引擎将用repr()函数记录所有语句及其参数列表到日志 # 由于SQLAlchemy是多线程，指定check_same_thread=False来让建立的对象任意线程都可使用。这个参数只在用SQLite数据库时设置 SQLALCHEMY_DATABASE_URL, encoding='utf-8', echo=True, connect_args={\"check_same_thread\": False} ) # 在SQLAlchemy中，CRUD都是通过会话(session)进行的，所以我们必须要先创建会话，每一个SessionLocal实例就是一个数据库session # flush()是指发送数据库语句到数据库，但数据库不一定执行写入磁盘；commit()是指提交事务，将变更保存到数据库文件 SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False, expire_on_commit=True) # 创建基本映射类 Base = declarative_base(bind=engine, name=\"Base\") curd.py from sqlalchemy.orm import Session from . import models, schemas def get_city(db: Session, city_id: int): return db.query(models.City).filter(models.City.id == city_id).first() def get_city_by_name(db: Session, name: str): return db.query(models.City).filter(models.City.province == name).first() def get_cities(db: Session, offset: int = 0, limit: int = 100): return db.query(models.City).offset(offset).limit(limit).all() def create_city(db: Session, city: schemas.CreateCity): db_city = models.City(**city.dict()) db.add(db_city) db.commit() db.refresh(db_city) return db_city def get_data(db: Session, city: str = None, offset: int = 0, limit: int = 100): if city: return db.query(models.Data).filter( models.Data.city.has(province=city)).all() # 外键关联查询，这里不是像Django ORM那样Data.city.province return db.query(models.Data).offset(offset).limit(limit).all() def create_city_data(db: Session, data: schemas.CreateData, city_id: int): db_data = models.Data(**data.dict(), city_id=city_id) db.add(db_data) db.commit() db.refresh(db_data) return db_data models.py from sqlalchemy import Column, String, Integer, BigInteger, Date, DateTime, ForeignKey, func from sqlalchemy.orm import relationship from .database import Base class City(Base): __tablename__ = \"city\" # 数据库的表名 id = Column(Integer, autoincrement=True, primary_key=True, index=True) province = Column(String(100), unique=True, nullable=False, comment=\"省/直辖市\") country = Column(String(100), nullable=False, comment=\"国家\") country_code = Column(String(100), nullable=True, comment=\"国家代码\") country_population = Column(BigInteger, nullable=False, comment=\"国家人口\") data = relationship('Data', back_populates=\"city\") # 'Data'是关联的类名；back_populates来指定反向访问的属性名称 created_at = Column(DateTime, server_default=func.now(), comment=\"创建时间\") updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now(), comment=\"更新时间\") __mapper_args__ = {\"order_by\": country_code} # 默认是正序，倒序加上.desc()方法 def __repr__(self): return f\"{self.country}_{self.province}\" class Data(Base): __tablename__ = \"data\" id = Column(Integer, primary_key=True, autoincrement=True, index=True) city_id = Column(Integer, ForeignKey('city.id'), comment=\"所属省/直辖市\") # ForeignKey里的字符串格式不是类名.属性名，而是表名.字段名 date = Column(Date, nullable=False, comment=\"数据时间\") confirmed = Column(BigInteger, default=0, nullable=False, comment=\"确诊数量\") deaths = Column(BigInteger, default=0, nullable=False, comment=\"死亡数量\") recovered = Column(BigInteger, default=0, nullable=False, comment=\"痊愈数量\") city = relationship(\"City\", back_populates='data') # 'City'是关联的类名；back_populates来指定反向访问的属性名称 created_at = Column(DateTime, server_default=func.now(), comment=\"创建时间\") updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now(), comment=\"更新时间\") __mapper_args__ = {\"order_by\": date.desc()} # 按日期降序排列 def __repr__(self): return f\"{repr(self.date)}：确诊{self.confirmed}例\" \"\"\" 附上三个SQLAlchemy教程 SQLAlchemy的基本操作大全 http://www.taodudu.cc/news/show-175725.html Python3+SQLAlchemy+Sqlite3实现ORM教程 https://www.cnblogs.com/jiangxiaobo/p/12350561.html SQLAlchemy基础知识 Autoflush和Autocommit https://zhuanlan.zhihu.com/p/48994990 \"\"\" schemas.py from datetime import date as date_ from datetime import datetime from pydantic import BaseModel class CreateData(BaseModel): date: date_ confirmed: int = 0 deaths: int = 0 recovered: int = 0 class CreateCity(BaseModel): province: str country: str country_code: str country_population: int class ReadData(CreateData): id: int city_id: int updated_at: datetime created_at: datetime class Config: orm_mode = True class ReadCity(CreateCity): id: int updated_at: datetime created_at: datetime class Config: orm_mode = True home.html 新冠病毒疫情跟踪器 $(document).ready(function () { $(\"#filter\").click(function () { const city = $(\"#city\").val(); window.location.href = \"http://\" + window.location.host + \"/coronavirus?city=\" + city; }); $(\"#sync\").click(function () { $.get(\"{ { sync_data_url } }\", function (result) { alert(\"Message: \" + result.message); }); }); }); 新冠病毒疫情跟踪器 过滤 同步数据 城市 日期 累计确诊数 累计死亡数 累计痊愈数 更新时间 "},"Python/第三方库/FastAPI/基础/10-apSheduler动态定时任务.html":{"url":"Python/第三方库/FastAPI/基础/10-apSheduler动态定时任务.html","title":"apSheduler动态定时任务","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb apSheduler动态定时任务 __doc__ = \"\"\" http://t.zoukankan.com/CharmCode-p-14191009.html http://t.zoukankan.com/zhangliang91-p-12468871.html \"\"\" import asyncio import datetime from enum import Enum from apscheduler.executors.asyncio import AsyncIOExecutor from apscheduler.jobstores.memory import MemoryJobStore from apscheduler.schedulers.asyncio import AsyncIOScheduler from apscheduler.triggers.cron import CronTrigger from apscheduler.triggers.interval import IntervalTrigger from fastapi import APIRouter, Body, Query tasks_router = APIRouter() scheduler = AsyncIOScheduler(timezone='Asia/Shanghai') def print_time(name): print(f'{name} - {datetime.datetime.now()}') async def tick(num): await asyncio.sleep(1) print(f'Tick{num}! The time is: %s' % datetime.datetime.now()) @tasks_router.on_event(\"startup\") def init_scheduler(): \"\"\"初始化定时任务调度器\"\"\" jobstores = { # 'default': SQLAlchemyJobStore(url='sqlite:///jobs.sqlite') # SQLAlchemyJobStore指定存储链接 'default': MemoryJobStore() # SQLAlchemyJobStore指定存储链接 } executors = { # 'default': {'type': 'threadpool', 'max_workers': 20}, # 最大工作线程数20 # 'default': ThreadPoolExecutor(max_workers=20) # 最大工作进程数为5 # 'processpool': ProcessPoolExecutor(max_workers=5) # 最大工作进程数为5 'default': AsyncIOExecutor() } scheduler.configure(jobstores=jobstores, executors=executors) # # 添加一个coroutine执行，结果很不理想... scheduler.add_job(func=tick, args=(1,), trigger=CronTrigger.from_crontab(\"* * * * *\"), timezone='Asia/Shanghai', next_run_time=datetime.datetime.now().astimezone()) print(\"启动调度器...\") scheduler.start() @tasks_router.post('/get_jobs', summary=\"获取所有jobs\") async def get_jobs(): \"\"\"获取所有jobs\"\"\" res = [] data = scheduler.get_jobs() for i in data: tmp = dict() tmp['id'] = i.id tmp['name'] = i.name tmp['next_run_time'] = i.next_run_time.strftime(\"%F %X\") tmp['timezone'] = str(i.next_run_time.tzinfo) res.append(tmp) return {\"msg\": \"success!\", \"data\": res} @tasks_router.post('/print_jobs', summary=\"打印jobs\") async def print_jobs(): \"\"\"打印jobs\"\"\" scheduler.print_jobs() return {\"msg\": \"success!\"} @tasks_router.post('/add_job', summary=\"添加job\") async def add_job(job_id: str = Body(...), cron: str = Body(...)): \"\"\"添加job\"\"\" # scheduler.add_job(id=job_id, func=print_time, args=(job_id,), trigger=CronTrigger.from_crontab(cron)) # scheduler.add_job(id=job_id, func=print_time, args=(job_id,), trigger=IntervalTrigger(seconds=3)) scheduler.add_job(id=job_id, func=tick, args=(job_id,), trigger=IntervalTrigger(seconds=3)) return {\"msg\": \"success!\"} class TriggerTypeEnum(str, Enum): \"\"\"触发类型枚举\"\"\" CRON = \"cron\" INTERVAL = \"interval\" @tasks_router.post('/modify_job', summary=\"修改job\") async def modify_job( job_id: str = Query(..., description=\"job id\"), trigger_type: TriggerTypeEnum = Query(default=TriggerTypeEnum.INTERVAL, description=\"interval: 固定时间间隔运行job \" \" cron: 类似linux-crontab，某个时间点定期运行job,\" \"帮助网站：https://crontab.guru\"), interval_seconds: int = Query(None, description=\"IntervalTrigger 的秒数\"), cron_exp: str = Query(None, description=\"CronTrigger 表达式\"), ): \"\"\"修改job\"\"\" if trigger_type == TriggerTypeEnum.INTERVAL: trigger = IntervalTrigger(seconds=interval_seconds) else: trigger = CronTrigger.from_crontab(cron_exp) ntime = datetime.datetime.now() next_time = trigger.get_next_fire_time(ntime, ntime) scheduler.modify_job(job_id=job_id, trigger=trigger, next_run_time=next_time) return {\"msg\": \"success!\"} @tasks_router.post('/pause_job', summary=\"停止job\") async def pause_job(job_id): \"\"\"停止job\"\"\" scheduler.pause_job(job_id) print(f\"停止job - {job_id}\") @tasks_router.post('/resume_job', summary=\"恢复job\") async def resume_job(job_id): \"\"\"恢复job\"\"\" scheduler.resume_job(job_id) print(f\"恢复job - {job_id}\") @tasks_router.post('/remove_job', summary=\"移除job\") async def remove_job(job_id: str = Body(..., embed=True)): \"\"\"移除job\"\"\" scheduler.remove_job(job_id) return {\"msg\": \"success!\"} "},"Python/第三方库/FastAPI/基础/11-main.html":{"url":"Python/第三方库/FastAPI/基础/11-main.html","title":"入口文件、全局配置","keywords":"","body":"datetime:2022/09/24 15:52 author:nzb 入口文件 import asyncio import threading import time import uvicorn from fastapi.openapi.docs import ( get_redoc_html, get_swagger_ui_html, get_swagger_ui_oauth2_redirect_html, ) from fastapi import FastAPI, Request from fastapi.staticfiles import StaticFiles from fastapi.middleware.cors import CORSMiddleware # from fastapi.exceptions import RequestValidationError # from fastapi.responses import PlainTextResponse # from starlette.exceptions import HTTPException as StarletteHTTPException from tutorial import app3, app4, app5, app6, app7, app8 from coronavirus import application from timed_task import tasks_router app = FastAPI( title=\"FastAPI tutorial and Coronavirus Tracker API Docs\", description='FastAPI教程 新冠病毒疫情跟踪器API接口文档', version=\"1.0.0\", docs_url=None, redoc_url=None # 自定义本地js，css # dependencies=[], # 全局依赖 ) # mount表示将某个目录下一个完全独立的应用挂载过来，这个不会在API交互文档中显示 app.mount(path=\"/static\", app=StaticFiles(directory=\"./coronavirus/static\"), name='static') # .mount()不要在分路由APIRouter().mount()调用，模板会报错 # app.debug = True # @app.exception_handler(StarletteHTTPException) # 重写HTTPException异常处理器 # async def http_exception_handler(request, exc): # \"\"\" # :param request: 这个参数不能省 # :param exc: # :return: # \"\"\" # return PlainTextResponse(str(exc.detail), status_code=exc.status_code) # # # @app.exception_handler(RequestValidationError) # 重写请求验证异常处理器 # async def validation_exception_handler(request, exc): # \"\"\" # :param request: 这个参数不能省 # :param exc: # :return: # \"\"\" # return PlainTextResponse(str(exc), status_code=400) @app.middleware(\"http\") async def add_process_time_header(request: Request, call_next): start_time = time.time() resp = await call_next(request) process_time = time.time() - start_time resp.headers['X-Process-Time'] = str(process_time) return resp app.add_middleware( CORSMiddleware, allow_origins=[ \"http://127.0.0.1\", \"http://127.0.0.1:8080\", ], allow_credentials=True, allow_methods=['*'], allow_headers=['*'], ) # 自定义 swagger 相关，加速静态文件的加载 @app.get(\"/docs\", include_in_schema=False) async def custom_swagger_ui_html(): \"\"\"自定义 swagger，静态文件本地化\"\"\" return get_swagger_ui_html( openapi_url=app.openapi_url, title=app.title + \" - Swagger UI\", oauth2_redirect_url=app.swagger_ui_oauth2_redirect_url, swagger_js_url=\"/static/swagger-ui/swagger-ui-bundle.js\", swagger_css_url=\"/static/swagger-ui/swagger-ui.css\", ) @app.get(app.swagger_ui_oauth2_redirect_url, include_in_schema=False) async def swagger_ui_redirect(): \"\"\"自定义 swagger，oauth相关\"\"\" return get_swagger_ui_oauth2_redirect_html() @app.get(\"/redoc\", include_in_schema=False) async def redoc_html(): return get_redoc_html( openapi_url=app.openapi_url, title=app.title + \" - ReDoc\", redoc_js_url=\"/static/redoc.standalone.js\", # 网上找不到相关js, 该页面一般没人用 ) app.include_router(app3, prefix=\"/chapter03\", tags=[\"第三章 请求参数和验证\"]) app.include_router(app4, prefix=\"/chapter04\", tags=[\"第四章 响应处理和FastAPI配置\"]) app.include_router(app5, prefix=\"/chapter05\", tags=[\"第五章 FastAPI的依赖注入系统\"]) app.include_router(app6, prefix=\"/chapter06\", tags=[\"第六章 安全、认证和授权\"]) app.include_router(app7, prefix=\"/chapter07\", tags=['第七章 FastAPI的数据库操作和多应用的目录结构设计']) app.include_router(app8, prefix='/chapter08', tags=['第八章 中间件、CORS、后台任务、测试用例']) app.include_router(application, prefix=\"/coronavirus\", tags=[\"新冠病毒疫情跟踪器API\"]) app.include_router(tasks_router, prefix=\"/timed_tasks\", tags=[\"apSheduler动态定时任务\"]) if __name__ == '__main__': uvicorn.run('main:app', host='127.0.0.1', port=8001, reload=True, debug=True, workers=5) "},"Python/第三方库/PyQt5/":{"url":"Python/第三方库/PyQt5/","title":"导航","keywords":"","body":"datetime:2019/5/23 15:28 author:nzb PyQt5关系图 创建窗口 创建按钮 垂直布局和水平布局 栅格布局 布局添加标签 布局添加背景图 单选按钮 复选框 创建提示 行编辑 按钮组 布局组 无边框窗口 创建框架qframe 创建分离器 创建滑动条 创建滚动条 创建刻度盘 spinbox 生成随机数 进度条 工具框 菜单栏和工具栏 文档编辑框 文本框字体的选择 字体颜色 打印 打印预览 打印PDF （带选择的）消息框提示框 右键菜单 选项卡（单选下拉框和多选） stack(堆叠小部件)小部件.md) 可停靠的窗口小部件 日历 单选下拉框 首字符模糊填充（查询） 打开更多的窗口 时间编辑 列表部件 列表部件小示例 "},"Python/第三方库/PyQt5/01-窗口.html":{"url":"Python/第三方库/PyQt5/01-窗口.html","title":"窗口","keywords":"","body":"datetime:2019/5/16 16:13 author:nzb 创建窗口 import sys from PyQt5.QtWidgets import QMainWindow, QApplication, QDesktopWidget from PyQt5 import QtGui class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 demo' self.left = 600 self.top = 200 self.width = 800 self.height = 600 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 # self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 self.resize(800, 600) # 窗口大小 self.center() # 窗口居中 # 展示窗口 self.show() def center(self): \"\"\"窗口居中\"\"\" qr = self.frameGeometry() cp = QDesktopWidget().availableGeometry().center() qr.moveCenter(cp) self.move(qr.topLeft()) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/02-按钮.html":{"url":"Python/第三方库/PyQt5/02-按钮.html","title":"按钮","keywords":"","body":"datetime:2019/5/20 14:04 author:nzb 创建按钮 import sys from PyQt5.QtWidgets import QMainWindow, QApplication, QDesktopWidget, QPushButton from PyQt5 import QtGui from PyQt5 import QtCore class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 demo' self.left = 600 self.top = 200 self.width = 800 self.height = 600 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 按钮 self.button() # 展示窗口 self.show() def button(self): \"\"\"按钮\"\"\" btn = QPushButton('click me', self) # btn.resize(100, 34) # 按钮大小 # btn.move(290, 550) # 移动按钮 # 合并 btn.setGeometry(QtCore.QRect(300, 250, 150, 34)) # 按钮图标 btn.setIcon(QtGui.QIcon('../img/Agt Stop.ico')) btn.setIconSize(QtCore.QSize(40, 40)) # 设置图标大小 # 设置按钮提示 btn.setToolTip('按钮提示') # 触发事件 btn.clicked.connect(self.ClickMe) def ClickMe(self): print('Hello World') # 退出 sys.exit() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/03-垂直布局和水平布局.html":{"url":"Python/第三方库/PyQt5/03-垂直布局和水平布局.html","title":"垂直布局和水平布局","keywords":"","body":"datetime:2019/5/20 14:21 author:nzb 垂直布局和水平布局 import sys from PyQt5.QtWidgets import QApplication, QDesktopWidget, QDialog, QPushButton, QVBoxLayout, QGroupBox, QHBoxLayout from PyQt5 import QtGui from PyQt5 import QtCore class UI_demo(QDialog): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Layout Managment' self.left = 600 self.top = 200 self.width = 300 self.height = 100 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 布局 self.createLayout() vbox = QVBoxLayout() vbox.addWidget(self.groupBox) self.setLayout(vbox) # 展示窗口 self.show() def createLayout(self): \"\"\"垂直布局和水平布局\"\"\" self.groupBox = QGroupBox('What is your favorite sport?') hboxlayout = QHBoxLayout() btn = QPushButton('Soccer', self) btn.setIcon(QtGui.QIcon('../img/Soccer.ico')) btn.setIconSize(QtCore.QSize(40, 40)) btn.setMinimumHeight((40)) hboxlayout.addWidget(btn) btn1 = QPushButton('Tennis', self) btn1.setIcon(QtGui.QIcon('../img/Tennis.ico')) btn1.setIconSize(QtCore.QSize(40, 40)) btn1.setMinimumHeight((40)) hboxlayout.addWidget(btn1) btn2 = QPushButton('Basketball', self) btn2.setIcon(QtGui.QIcon('../img/Basketball.ico')) btn2.setIconSize(QtCore.QSize(40, 40)) btn2.setMinimumHeight((40)) hboxlayout.addWidget(btn2) self.groupBox.setLayout(hboxlayout) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/04-栅格布局.html":{"url":"Python/第三方库/PyQt5/04-栅格布局.html","title":"栅格布局","keywords":"","body":"datetime:2019/5/20 14:27 author:nzb 栅格布局 import sys from PyQt5.QtWidgets import QApplication, QDialog, QPushButton, QVBoxLayout, QGroupBox, QGridLayout from PyQt5 import QtGui from PyQt5 import QtCore class UI_demo(QDialog): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Grid Layout ' self.left = 600 self.top = 200 self.width = 300 self.height = 100 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 栅格布局 self.createLayout() vbox = QVBoxLayout() vbox.addWidget(self.groupBox) self.setLayout(vbox) # 展示窗口 self.show() def createLayout(self): \"\"\"栅格布局\"\"\" self.groupBox = QGroupBox('What is your favorite programming language?') gridLayout = QGridLayout() btn = QPushButton('Python', self) btn.setIcon(QtGui.QIcon('../img/python.ico')) btn.setIconSize(QtCore.QSize(40, 40)) btn.setMinimumHeight((40)) gridLayout.addWidget(btn, 0, 0) btn1 = QPushButton('java', self) btn1.setIcon(QtGui.QIcon('../img/java.ico')) btn1.setIconSize(QtCore.QSize(40, 40)) btn1.setMinimumHeight((40)) gridLayout.addWidget(btn1, 0, 1) btn2 = QPushButton('php', self) btn2.setIcon(QtGui.QIcon('../img/php.ico')) btn2.setIconSize(QtCore.QSize(40, 40)) btn2.setMinimumHeight((40)) gridLayout.addWidget(btn2, 1, 0) btn3 = QPushButton('c++', self) btn3.setIcon(QtGui.QIcon('./img/C++.ico')) btn3.setIconSize(QtCore.QSize(40, 40)) btn3.setMinimumHeight((40)) gridLayout.addWidget(btn3, 1, 1) self.groupBox.setLayout(gridLayout) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/05-布局添加标签Label.html":{"url":"Python/第三方库/PyQt5/05-布局添加标签Label.html","title":"布局添加标签Label","keywords":"","body":"datetime:2019/5/20 14:34 author:nzb 布局添加标签 import sys from PyQt5.QtWidgets import QApplication, QDialog, QVBoxLayout, QLabel from PyQt5 import QtGui class UI_demo(QDialog): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Layout Managment' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 vbox = QVBoxLayout() # 标签 label = QLabel('This is PyQt5 Label.') vbox.addWidget(label) label2 = QLabel('This is big Label.') label2.setFont(QtGui.QFont(\"Sanserif\", 20)) # 设置字体和大小 label2.setStyleSheet(\"color:red\") # 设置颜色 vbox.addWidget(label2) self.setLayout(vbox) # 展示窗口 self.show() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/06-布局添加背景图.html":{"url":"Python/第三方库/PyQt5/06-布局添加背景图.html","title":"布局添加背景图","keywords":"","body":"datetime:2019/5/20 14:41 author:nzb 布局添加背景图 import sys from PyQt5.QtWidgets import QApplication, QDialog, QVBoxLayout, QLabel from PyQt5 import QtGui class UI_demo(QDialog): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Layout Managment' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 vbox = QVBoxLayout() # 背景图 labelImage = QLabel(self) pixmap = QtGui.QPixmap('../img/default.jpg') labelImage.setPixmap(pixmap) vbox.addWidget(labelImage) self.setLayout(vbox) # 展示窗口 self.show() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/07-单选框.html":{"url":"Python/第三方库/PyQt5/07-单选框.html","title":"单选框","keywords":"","body":"datetime:2019/5/20 15:02 author:nzb 单选按钮 import sys from PyQt5.QtWidgets import QApplication, QDialog, QVBoxLayout, QLabel, QGroupBox, QRadioButton, QHBoxLayout from PyQt5 import QtGui, QtCore class UI_demo(QDialog): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Layout Managment' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 vbox = QVBoxLayout() # 单选框 self.radioButton() vbox.addWidget(self.groupBox) self.label = QLabel(self) self.label.setFont(QtGui.QFont(\"Sanserif\", 20)) vbox.addWidget(self.label) self.setLayout(vbox) # 展示窗口 self.show() def radioButton(self): \"\"\"单选框\"\"\" self.groupBox = QGroupBox(\"What is your favorite sport?\") self.groupBox.setFont(QtGui.QFont(\"Sanserif\", 12)) hboxlayout = QHBoxLayout() self.radiobtn1 = QRadioButton('Soccer') self.radiobtn1.setChecked(True) # 选中状态 self.radiobtn1.setIcon(QtGui.QIcon('../img/Soccer.ico')) self.radiobtn1.setIconSize(QtCore.QSize(40, 40)) self.radiobtn1.setFont(QtGui.QFont('Sanserif', 13)) self.radiobtn1.toggled.connect(self.OnRadioBtn) # 选中事件 hboxlayout.addWidget(self.radiobtn1) self.radiobtn2 = QRadioButton('Tennis') self.radiobtn2.setIcon(QtGui.QIcon('../img/Tennis.ico')) self.radiobtn2.setIconSize(QtCore.QSize(40, 40)) self.radiobtn2.setFont(QtGui.QFont('Sanserif', 13)) self.radiobtn2.toggled.connect(self.OnRadioBtn) hboxlayout.addWidget(self.radiobtn2) self.radiobtn3 = QRadioButton('Basketball') self.radiobtn3.setIcon(QtGui.QIcon('../img/Basketball.ico')) self.radiobtn3.setIconSize(QtCore.QSize(40, 40)) self.radiobtn3.setFont(QtGui.QFont('Sanserif', 13)) self.radiobtn3.toggled.connect(self.OnRadioBtn) hboxlayout.addWidget(self.radiobtn3) self.groupBox.setLayout(hboxlayout) def OnRadioBtn(self): \"\"\"单选框选中事件\"\"\" radioBtn = self.sender() if radioBtn.isChecked(): self.label.setText(\"You have selected \" + radioBtn.text()) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/08-复选框.html":{"url":"Python/第三方库/PyQt5/08-复选框.html","title":"复选框","keywords":"","body":"datetime:2019/5/20 15:45 author:nzb 复选框 import sys from PyQt5.QtWidgets import QApplication, QDialog, QVBoxLayout, QLabel, QGroupBox, QCheckBox, QHBoxLayout from PyQt5 import QtGui, QtCore class UI_demo(QDialog): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Check Box' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 self.CreateCheckBox() # 复选按钮 vbox = QVBoxLayout() vbox.addWidget(self.groupBox) self.label = QLabel(self) self.label.setFont(QtGui.QFont('Sanserif', 15)) #设置标签字体字号 vbox.addWidget(self.label) self.setLayout(vbox) # 展示窗口 self.show() def CreateCheckBox(self): \"\"\"复选框\"\"\" self.groupBox = QGroupBox(\"What is you favorite programming language?\") self.groupBox.setFont(QtGui.QFont(\"Sanserif\", 13)) # 设置字体字号 hboxLayout = QHBoxLayout() self.check1 = QCheckBox(\"python\") self.check1.setIcon(QtGui.QIcon('../img/python.ico')) self.check1.setIconSize(QtCore.QSize(40, 40)) self.check1.setFont(QtGui.QFont('Sanserif', 13)) # 设置字体字号 self.check1.toggled.connect(self.onCheckBox_Toggled) # 绑定事件 hboxLayout.addWidget(self.check1) self.check2 = QCheckBox(\"java\") self.check2.setIcon(QtGui.QIcon('../img/java.ico')) self.check2.setIconSize(QtCore.QSize(40, 40)) self.check2.setFont(QtGui.QFont('Sanserif', 13)) # 设置字体字号 self.check2.toggled.connect(self.onCheckBox_Toggled) # 绑定事件 hboxLayout.addWidget(self.check2) self.check3 = QCheckBox(\"php\") self.check3.setIcon(QtGui.QIcon('../img/php.ico')) self.check3.setIconSize(QtCore.QSize(40, 40)) self.check3.setFont(QtGui.QFont('Sanserif', 13)) # 设置字体字号 self.check3.toggled.connect(self.onCheckBox_Toggled) # 绑定事件 hboxLayout.addWidget(self.check3) self.groupBox.setLayout(hboxLayout) def onCheckBox_Toggled(self): \"\"\"复选框触发事件\"\"\" if self.check1.isChecked(): self.label.setText('you have select:' + self.check1.text()) if self.check2.isChecked(): self.label.setText('you have select:' + self.check2.text()) if self.check3.isChecked(): self.label.setText('you have select:' + self.check3.text()) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/09-键盘提示.html":{"url":"Python/第三方库/PyQt5/09-键盘提示.html","title":"键盘提示","keywords":"","body":"datetime:2019/5/20 15:58 author:nzb 创建提示 import sys from PyQt5.QtWidgets import QApplication, QDialog, QLabel, QHBoxLayout, QPushButton from PyQt5 import QtGui class UI_demo(QDialog): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 WhaiIsThis Class' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 hbox = QHBoxLayout() label = QLabel(\"Focus and press Shift + F1\") hbox.addWidget(label) button = QPushButton('click me', self) button.setWhatsThis(\"This is a button that you can click on this\") hbox.addWidget(button) self.setLayout(hbox) # 展示窗口 self.show() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/10-行编辑lineedit.html":{"url":"Python/第三方库/PyQt5/10-行编辑lineedit.html","title":"行编辑Lineedit","keywords":"","body":"datetime:2019/5/20 16:12 author:nzb 行编辑 import sys from PyQt5.QtWidgets import QWidget, QApplication, QDialog, QVBoxLayout, QLabel, QGroupBox, QCheckBox, QHBoxLayout, QPushButton, QLineEdit from PyQt5 import QtGui, QtCore class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Lineedit' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon('../img/home.ico')) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 行编辑 hbox = QHBoxLayout() self.lineedit = QLineEdit(self) self.lineedit.setFont(QtGui.QFont('Sanserif', 15)) self.lineedit.returnPressed.connect(self.onPressed) hbox.addWidget(self.lineedit) self.lable = QLabel(self) self.lable.setFont(QtGui.QFont('Sanserif', 15)) hbox.addWidget(self.lable) self.setLayout(hbox) # 展示窗口 self.show() def onPressed(self): \"\"\"输入绑定事件\"\"\" self.lable.setText(self.lineedit.text()) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/11-按钮组.html":{"url":"Python/第三方库/PyQt5/11-按钮组.html","title":"按钮组","keywords":"","body":"datetime:2019/5/20 16:28 author:nzb 按钮组 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, QCheckBox, QHBoxLayout, QPushButton, QButtonGroup from PyQt5 import QtGui, QtCore class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 ButtonGroup' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 按钮组 hbox = QHBoxLayout() self.label = QLabel(self) self.label.setFont(QtGui.QFont('Sanserif', 15)) hbox.addWidget(self.label) self.buttongroup = QButtonGroup() # 创建按钮组 self.buttongroup.buttonClicked[int].connect(self.on_button_clicked) # 绑定事件 button = QPushButton('python') button.setFont(QtGui.QFont('Sanserif', 15)) button.setIcon(QtGui.QIcon('../img/python.ico')) button.setIconSize(QtCore.QSize(40, 40)) self.buttongroup.addButton(button, 1) # 添加按钮 hbox.addWidget(button) button = QPushButton('java') button.setFont(QtGui.QFont('Sanserif', 15)) button.setIcon(QtGui.QIcon('../img/java.ico')) button.setIconSize(QtCore.QSize(40, 40)) self.buttongroup.addButton(button, 2) hbox.addWidget(button) button = QPushButton('php') button.setFont(QtGui.QFont('Sanserif', 15)) button.setIcon(QtGui.QIcon('../img/php.ico')) button.setIconSize(QtCore.QSize(40, 40)) self.buttongroup.addButton(button, 3) hbox.addWidget(button) self.setLayout(hbox) # 展示窗口 self.show() def on_button_clicked(self, id): \"\"\"按钮事件\"\"\" for button in self.buttongroup.buttons(): if button is self.buttongroup.button(id): self.label.setText(button.text() + \" was clicked\") if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/12-布局组.html":{"url":"Python/第三方库/PyQt5/12-布局组.html","title":"布局组","keywords":"","body":"datetime:2019/5/20 17:03 author:nzb 布局组 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, QCheckBox, QHBoxLayout, QPushButton, QButtonGroup from PyQt5.QtWidgets import QVBoxLayout, QRadioButton from PyQt5 import QtGui, QtCore class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Groupbox' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 布局组 # 水平布局 hbox = QHBoxLayout() groupbox = QGroupBox('select you favorite sport') groupbox.setFont(QtGui.QFont('Sanserif', 15)) hbox.addWidget(groupbox) # 垂直布局 vbox = QVBoxLayout() rad1 = QRadioButton('soccer') vbox.addWidget(rad1) rad2 = QRadioButton('tennis') vbox.addWidget(rad2) groupbox.setLayout(vbox) self.setLayout(hbox) # 展示窗口 self.show() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/13-无边框窗口.html":{"url":"Python/第三方库/PyQt5/13-无边框窗口.html","title":"无边框窗口","keywords":"","body":"datetime:2019/5/20 17:13 author:nzb 无边框窗口 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, QCheckBox, QHBoxLayout, QPushButton, QButtonGroup, \\ QSizeGrip from PyQt5.QtWidgets import QVBoxLayout, QRadioButton from PyQt5 import QtGui, QtCore class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Frameless Window' self.left = 600 self.top = 200 self.width = 500 self.height = 200 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 无边框窗口 flags = QtCore.Qt.WindowFlags(QtCore.Qt.FramelessWindowHint | QtCore.Qt.WindowStaysOnTopHint) self.setWindowFlags(flags) vbox = QVBoxLayout() sizegrip = QSizeGrip(self) vbox.addWidget(sizegrip) self.setLayout(vbox) # 展示窗口 self.show() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/14-框架qframe.html":{"url":"Python/第三方库/PyQt5/14-框架qframe.html","title":"框架Qframe","keywords":"","body":"datetime:2019/5/21 15:13 author:nzb 创建框架qframe import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, QCheckBox, QHBoxLayout, QPushButton, QButtonGroup, \\ QSizeGrip, QFrame from PyQt5.QtWidgets import QVBoxLayout, QRadioButton from PyQt5 import QtGui, QtCore class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Qframe' self.left = 600 self.top = 200 self.width = 500 self.height = 500 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 self.setStyleSheet('background-color:yellow') # 设置背景颜色 # 框架qframe hbox = QHBoxLayout() btn = QPushButton('click me') btn.setStyleSheet('color:white') btn.setStyleSheet('background-color:green') frame = QFrame() frame.setFrameShape(QFrame.StyledPanel) frame.setStyleSheet('background-color:red') hbox.addWidget(frame) hbox.addWidget(btn) self.setLayout(hbox) # 展示窗口 self.show() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/15-分离器.html":{"url":"Python/第三方库/PyQt5/15-分离器.html","title":"分离器","keywords":"","body":"datetime:2019/5/21 15:16 author:nzb 创建分离器 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, QCheckBox, \\ QHBoxLayout, QPushButton, QButtonGroup, QSizeGrip, QFrame from PyQt5.QtWidgets import QVBoxLayout, QRadioButton, QSplitter, QLineEdit from PyQt5 import QtGui, QtCore from PyQt5.QtCore import Qt class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Splitters' self.left = 600 self.top = 200 self.width = 500 self.height = 500 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 分离器 hbox = QHBoxLayout() left = QFrame() left.setFrameShape(QFrame.StyledPanel) bottom = QFrame() bottom.setFrameShape(QFrame.StyledPanel) splitter1 = QSplitter(Qt.Horizontal) # 水平分离（默认） splitter1.setStyleSheet('background-color:red') lineedit = QLineEdit() lineedit.setStyleSheet('background-color:green') splitter1.addWidget(left) splitter1.addWidget(lineedit) splitter1.setSizes([200, 200]) splitter2 = QSplitter(Qt.Vertical) # 垂直分离 splitter2.addWidget(splitter1) splitter2.addWidget(bottom) splitter2.setStyleSheet('background-color:blue') hbox.addWidget(splitter2) self.setLayout(hbox) # 展示窗口 self.show() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/16-滑动条.html":{"url":"Python/第三方库/PyQt5/16-滑动条.html","title":"滑动条","keywords":"","body":"datetime:2019/5/21 15:44 author:nzb 创建滑动条 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, QCheckBox, \\ QHBoxLayout, QPushButton, QButtonGroup, QFrame, QSlider from PyQt5.QtWidgets import QSplitter, QLineEdit from PyQt5 import QtGui, QtCore from PyQt5.QtCore import Qt class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Slider' self.left = 600 self.top = 200 self.width = 500 self.height = 500 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 self.setStyleSheet('background-color:yellow') # 滑动条 hbox = QHBoxLayout() # 水平布局 self.slider = QSlider() self.slider.setOrientation(Qt.Horizontal) # 水平滑动（默认垂直） self.slider.setTickPosition(QSlider.TicksBelow) # 刻度 self.slider.setTickInterval(10) # 设置刻度数量 self.slider.setMinimum(0) # 滑动条最小值 self.slider.setMaximum(100) # 滑动条最大值 self.slider.valueChanged.connect(self.changedValue) # 绑定事件 self.label = QLabel('0') self.label.setFont(QtGui.QFont('Sanserif', 15)) hbox.addWidget(self.slider) hbox.addWidget(self.label) self.setLayout(hbox) # 展示窗口 self.show() def changedValue(self): size = self.slider.value() self.label.setText(str(size)) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/17-滚动条.html":{"url":"Python/第三方库/PyQt5/17-滚动条.html","title":"滚动条","keywords":"","body":"datetime:2019/5/21 16:00 author:nzb 创建滚动条 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, QCheckBox, \\ QHBoxLayout, QFrame, QScrollArea, QFormLayout, QPushButton, QVBoxLayout from PyQt5.QtWidgets import QSplitter, QLineEdit from PyQt5 import QtGui, QtCore from PyQt5.QtCore import Qt class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self, val): super().__init__() # 窗口信息 self.title = 'PyQt5 QScroll Area' self.left = 600 self.top = 200 self.width = 500 self.height = 500 self.iconName = '../img/home.ico' self.val = val self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 滚动区域 formLayout = QFormLayout() # 表单布局 groupBox = QGroupBox(\"This is group box\") labelList = [] buttonList = [] for i in range(self.val): labelList.append(QLabel(\"Label\")) buttonList.append(QPushButton('click me')) formLayout.addRow(labelList[i], buttonList[i]) groupBox.setLayout(formLayout) scroll = QScrollArea() scroll.setWidget(groupBox) scroll.setWidgetResizable(True) scroll.setFixedHeight(400) layout = QVBoxLayout() layout.addWidget(scroll) self.setLayout(layout) # 展示窗口 self.show() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo(20) sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/18-刻度盘.html":{"url":"Python/第三方库/PyQt5/18-刻度盘.html","title":"刻度盘","keywords":"","body":"datetime:2019/5/21 16:23 author:nzb 创建刻度盘 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, QCheckBox, \\ QHBoxLayout, QFrame, QScrollArea, QFormLayout, QPushButton, QVBoxLayout from PyQt5.QtWidgets import QDial from PyQt5 import QtGui, QtCore from PyQt5.QtCore import Qt class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 QDial' self.left = 600 self.top = 200 self.width = 500 self.height = 500 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 刻度盘 vbox = QVBoxLayout() self.label = QLabel(self) self.label.setFont(QtGui.QFont('Sanserif', 15)) self.dial = QDial() self.dial.setMinimum(0) self.dial.setMaximum(100) self.dial.setValue(30) self.dial.valueChanged.connect(self.dial_changed) vbox.addWidget(self.dial) vbox.addWidget(self.label) self.setLayout(vbox) # 展示窗口 self.show() def dial_changed(self): getValue = self.dial.value() self.label.setText(\"Dial is changing：\" + str(getValue)) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/19-spinbox.html":{"url":"Python/第三方库/PyQt5/19-spinbox.html","title":"Spinbox","keywords":"","body":"datetime:2019/5/21 16:45 author:nzb spinbox import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, \\ QHBoxLayout, QPushButton, QVBoxLayout, QSpinBox from PyQt5.QtWidgets import QDial from PyQt5 import QtGui, QtCore from PyQt5.QtCore import Qt class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self, val): super().__init__() # 窗口信息 self.title = 'PyQt5 QSpinbox' self.left = 600 self.top = 200 self.width = 500 self.height = 500 self.iconName = '../img/home.ico' self.val = val self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 转动盒子 vbox = QVBoxLayout() self.spinbox = QSpinBox() self.spinbox.valueChanged.connect(self.spin_changed) vbox.addWidget(self.spinbox) self.label = QLabel() self.label.setFont(QtGui.QFont('Sanserif', 15)) self.label.setAlignment(Qt.AlignCenter) vbox.addWidget(self.label) self.setLayout(vbox) # 展示窗口 self.show() def spin_changed(self): spinValue = self.spinbox.value() self.label.setText(\"current value is :\" + str(spinValue)) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo(20) sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/20-生成随机数.html":{"url":"Python/第三方库/PyQt5/20-生成随机数.html","title":"生成随机数","keywords":"","body":"datetime:2019/5/21 16:59 author:nzb 生成随机数 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, \\ QHBoxLayout, QPushButton, QVBoxLayout, QSpinBox, QLCDNumber from PyQt5.QtWidgets import QDial from PyQt5 import QtGui, QtCore from PyQt5.QtCore import Qt from random import randint class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 QLCDNumber' self.left = 600 self.top = 200 self.width = 500 self.height = 500 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 随机生成数字 self.initUI() # 展示窗口 self.show() def initUI(self): \"\"\"随机生成数字\"\"\" vbox = QVBoxLayout() self.lcd = QLCDNumber() # self.lcd.display(60) # 显示数字 self.lcd.setStyleSheet('background-color:green') vbox.addWidget(self.lcd) self.button = QPushButton('random number generator') self.button.setStyleSheet('background-color:yellow') self.button.clicked.connect(self.LCDHandler) vbox.addWidget(self.button) self.setLayout(vbox) def LCDHandler(self): \"\"\"随机数字\"\"\" random = randint(1, 200) self.lcd.display(random) # 显示数字 if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/21-进度条.html":{"url":"Python/第三方库/PyQt5/21-进度条.html","title":"进度条","keywords":"","body":"datetime:2019/5/21 17:38 author:nzb 进度条 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, \\ QHBoxLayout, QPushButton, QVBoxLayout, QSpinBox, QLCDNumber from PyQt5.QtWidgets import QDial, QProgressBar from PyQt5 import QtGui, QtCore from PyQt5.QtCore import Qt, QThread, pyqtSignal import time class MyThead(QThread): change_value = pyqtSignal(int) def run(self): cnt = 0 while cnt "},"Python/第三方库/PyQt5/22-工具框.html":{"url":"Python/第三方库/PyQt5/22-工具框.html","title":"工具框","keywords":"","body":"datetime:2019/5/21 17:51 author:nzb 工具框 import sys from PyQt5.QtWidgets import QWidget, QApplication, QLabel, QGroupBox, \\ QHBoxLayout, QPushButton, QVBoxLayout, QSpinBox, QLCDNumber from PyQt5.QtWidgets import QDial, QToolBox from PyQt5 import QtGui, QtCore from PyQt5.QtCore import Qt, QThread, pyqtSignal class UI_demo(QWidget): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Toolbox' self.left = 600 self.top = 200 self.width = 440 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 self.setStyleSheet('background-color:yellow') # 生成工具盒子 self.initUI() # 展示窗口 self.show() def initUI(self): \"\"\"工具盒子\"\"\" vbox = QVBoxLayout() toolbox = QToolBox() toolbox.setStyleSheet('background-color:green') vbox.addWidget(toolbox) label = QLabel() toolbox.addItem(label, \"Python\") label = QLabel() toolbox.addItem(label, \"Java\") label = QLabel() toolbox.addItem(label, \"PHP\") self.setLayout(vbox) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/23-菜单栏工具栏.html":{"url":"Python/第三方库/PyQt5/23-菜单栏工具栏.html","title":"菜单栏工具栏","keywords":"","body":"datetime:2019/5/22 16:57 author:nzb 菜单栏和工具栏 菜单栏 工具栏 import sys from PyQt5.QtWidgets import QWidget, QApplication, QMainWindow, QAction from PyQt5 import QtGui,QtCore class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 MenuBar' self.left = 600 self.top = 200 self.width = 440 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 生成菜单栏 self.CreateMenu() # 展示窗口 self.show() def CreateMenu(self): \"\"\"菜单栏\"\"\" mainMenu = self.menuBar() fileMenu = mainMenu.addMenu('File') editMenu = mainMenu.addMenu('Edit') viewMenu = mainMenu.addMenu('View') helpMenu = mainMenu.addMenu('Help') copyAction = QAction(QtGui.QIcon(self.iconName), 'Copy', self) copyAction.setShortcut(\"Ctrl+C\") fileMenu.addAction(copyAction) cutAction = QAction(QtGui.QIcon(self.iconName), 'Cut', self) cutAction.setShortcut(\"Ctrl+X\") fileMenu.addAction(cutAction) saveAction = QAction(QtGui.QIcon(self.iconName), 'Save', self) saveAction.setShortcut(\"Ctrl+S\") fileMenu.addAction(saveAction) exitAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Exit', self) exitAction.setShortcut(\"Ctrl+E\") exitAction.triggered.connect(self.exitWindow) fileMenu.addAction(exitAction) pasteAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Paste', self) pasteAction.setShortcut(\"Ctrl+E\") editMenu.addAction(pasteAction) # 工具栏 toolbar = self.addToolBar(\"Toolbar\") toolbar.addAction(copyAction) toolbar.addAction(cutAction) toolbar.addAction(saveAction) toolbar.addAction(exitAction) toolbar.addAction(pasteAction) def exitWindow(self): \"\"\"关闭窗口\"\"\" self.close() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/24-文档编辑框.html":{"url":"Python/第三方库/PyQt5/24-文档编辑框.html","title":"文档编辑框","keywords":"","body":"datetime:2019/5/22 17:09 author:nzb 文档编辑框 import sys from PyQt5.QtWidgets import QWidget, QApplication, QMainWindow, QAction, QTextEdit from PyQt5 import QtGui,QtCore class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 TextEdit' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 生成菜单栏 self.CreateMenu() # 生成文档编辑 self.createEditor() # 展示窗口 self.show() def CreateMenu(self): \"\"\"菜单栏\"\"\" mainMenu = self.menuBar() fileMenu = mainMenu.addMenu('File') editMenu = mainMenu.addMenu('Edit') viewMenu = mainMenu.addMenu('View') helpMenu = mainMenu.addMenu('Help') copyAction = QAction(QtGui.QIcon(self.iconName), 'Copy', self) copyAction.setShortcut(\"Ctrl+C\") fileMenu.addAction(copyAction) cutAction = QAction(QtGui.QIcon(self.iconName), 'Cut', self) cutAction.setShortcut(\"Ctrl+X\") fileMenu.addAction(cutAction) saveAction = QAction(QtGui.QIcon(self.iconName), 'Save', self) saveAction.setShortcut(\"Ctrl+S\") fileMenu.addAction(saveAction) exitAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Exit', self) exitAction.setShortcut(\"Ctrl+E\") exitAction.triggered.connect(self.exitWindow) fileMenu.addAction(exitAction) pasteAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Paste', self) pasteAction.setShortcut(\"Ctrl+E\") editMenu.addAction(pasteAction) # 工具栏 toolbar = self.addToolBar(\"Toolbar\") toolbar.addAction(copyAction) toolbar.addAction(cutAction) toolbar.addAction(saveAction) toolbar.addAction(exitAction) toolbar.addAction(pasteAction) def exitWindow(self): \"\"\"关闭窗口\"\"\" self.close() def createEditor(self): \"\"\"文档编辑\"\"\" self.textEdit = QTextEdit(self) self.setCentralWidget(self.textEdit) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/25-字体文本框.html":{"url":"Python/第三方库/PyQt5/25-字体文本框.html","title":"字体文本框","keywords":"","body":"datetime:2019/5/22 17:20 author:nzb 文本框字体的选择 import sys from PyQt5.QtWidgets import QApplication, QMainWindow, QAction, QTextEdit, QFontDialog from PyQt5 import QtGui,QtCore class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Font Dialog' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 生成菜单栏 self.CreateMenu() # 生成文档编辑 self.createEditor() # 展示窗口 self.show() def CreateMenu(self): \"\"\"菜单栏\"\"\" mainMenu = self.menuBar() fileMenu = mainMenu.addMenu('File') editMenu = mainMenu.addMenu('Edit') viewMenu = mainMenu.addMenu('View') helpMenu = mainMenu.addMenu('Help') copyAction = QAction(QtGui.QIcon(self.iconName), 'Copy', self) copyAction.setShortcut(\"Ctrl+C\") editMenu.addAction(copyAction) cutAction = QAction(QtGui.QIcon(self.iconName), 'Cut', self) cutAction.setShortcut(\"Ctrl+X\") editMenu.addAction(cutAction) saveAction = QAction(QtGui.QIcon(self.iconName), 'Save', self) saveAction.setShortcut(\"Ctrl+S\") editMenu.addAction(saveAction) exitAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Exit', self) exitAction.setShortcut(\"Ctrl+E\") exitAction.triggered.connect(self.exitWindow) fileMenu.addAction(exitAction) pasteAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Paste', self) pasteAction.setShortcut(\"Ctrl+E\") editMenu.addAction(pasteAction) fontAction = QAction(QtGui.QIcon(self.iconName), \"Font\", self) fontAction.setShortcut(\"Ctrl+F\") fontAction.triggered.connect(self.fontDialog) viewMenu.addAction(fontAction) # 工具栏 toolbar = self.addToolBar(\"Toolbar\") toolbar.addAction(copyAction) toolbar.addAction(cutAction) toolbar.addAction(saveAction) toolbar.addAction(exitAction) toolbar.addAction(pasteAction) def exitWindow(self): \"\"\"关闭窗口\"\"\" self.close() def createEditor(self): \"\"\"文档编辑\"\"\" self.textEdit = QTextEdit(self) self.setCentralWidget(self.textEdit) def fontDialog(self): \"\"\"字体对话框\"\"\" font, ok = QFontDialog.getFont() if ok: self.textEdit.setFont(font) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/26-颜色文本框.html":{"url":"Python/第三方库/PyQt5/26-颜色文本框.html","title":"颜色文本框","keywords":"","body":"datetime:2019/5/22 17:27 author:nzb 字体颜色 import sys from PyQt5.QtWidgets import QApplication, QMainWindow, QAction, QTextEdit, QFontDialog, QColorDialog from PyQt5 import QtGui,QtCore class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Color Dialog' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 生成菜单栏 self.CreateMenu() # 生成文档编辑 self.createEditor() # 展示窗口 self.show() def CreateMenu(self): \"\"\"菜单栏\"\"\" mainMenu = self.menuBar() fileMenu = mainMenu.addMenu('File') editMenu = mainMenu.addMenu('Edit') viewMenu = mainMenu.addMenu('View') helpMenu = mainMenu.addMenu('Help') copyAction = QAction(QtGui.QIcon(self.iconName), 'Copy', self) copyAction.setShortcut(\"Ctrl+C\") editMenu.addAction(copyAction) cutAction = QAction(QtGui.QIcon(self.iconName), 'Cut', self) cutAction.setShortcut(\"Ctrl+X\") editMenu.addAction(cutAction) saveAction = QAction(QtGui.QIcon(self.iconName), 'Save', self) saveAction.setShortcut(\"Ctrl+S\") editMenu.addAction(saveAction) exitAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Exit', self) exitAction.setShortcut(\"Ctrl+E\") exitAction.triggered.connect(self.exitWindow) fileMenu.addAction(exitAction) pasteAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Paste', self) pasteAction.setShortcut(\"Ctrl+E\") editMenu.addAction(pasteAction) fontAction = QAction(QtGui.QIcon(self.iconName), \"Font\", self) fontAction.setShortcut(\"Ctrl+F\") fontAction.triggered.connect(self.fontDialog) viewMenu.addAction(fontAction) colorAction = QAction(QtGui.QIcon(self.iconName), \"Color\", self) colorAction.triggered.connect(self.colorDialog) viewMenu.addAction(colorAction) # 工具栏 toolbar = self.addToolBar(\"Toolbar\") toolbar.addAction(copyAction) toolbar.addAction(cutAction) toolbar.addAction(saveAction) toolbar.addAction(exitAction) toolbar.addAction(pasteAction) toolbar.addAction(fontAction) toolbar.addAction(colorAction) def exitWindow(self): \"\"\"关闭窗口\"\"\" self.close() def createEditor(self): \"\"\"文档编辑\"\"\" self.textEdit = QTextEdit(self) self.setCentralWidget(self.textEdit) def fontDialog(self): \"\"\"字体对话框\"\"\" font, ok = QFontDialog.getFont() if ok: self.textEdit.setFont(font) def colorDialog(self): \"\"\"颜色对话框\"\"\" color = QColorDialog.getColor() self.textEdit.setTextColor(color) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/27-打印（文本框）.html":{"url":"Python/第三方库/PyQt5/27-打印（文本框）.html","title":"打印（文本框）","keywords":"","body":"datetime:2019/5/22 17:35 author:nzb 打印 import sys from PyQt5.QtWidgets import QApplication, QMainWindow, QAction, QTextEdit, QFontDialog, QColorDialog from PyQt5 import QtGui,QtCore from PyQt5.QtPrintSupport import QPrintDialog, QPrinter class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Print Dialog' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 生成菜单栏 self.CreateMenu() # 生成文档编辑 self.createEditor() # 展示窗口 self.show() def CreateMenu(self): \"\"\"菜单栏\"\"\" mainMenu = self.menuBar() fileMenu = mainMenu.addMenu('File') editMenu = mainMenu.addMenu('Edit') viewMenu = mainMenu.addMenu('View') helpMenu = mainMenu.addMenu('Help') copyAction = QAction(QtGui.QIcon(self.iconName), 'Copy', self) copyAction.setShortcut(\"Ctrl+C\") editMenu.addAction(copyAction) cutAction = QAction(QtGui.QIcon(self.iconName), 'Cut', self) cutAction.setShortcut(\"Ctrl+X\") editMenu.addAction(cutAction) saveAction = QAction(QtGui.QIcon(self.iconName), 'Save', self) saveAction.setShortcut(\"Ctrl+S\") editMenu.addAction(saveAction) printAction = QAction(QtGui.QIcon(self.iconName), \"Print\", self) printAction.triggered.connect(self.printDialog) fileMenu.addAction(printAction) exitAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Exit', self) exitAction.setShortcut(\"Ctrl+E\") exitAction.triggered.connect(self.exitWindow) fileMenu.addAction(exitAction) pasteAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Paste', self) pasteAction.setShortcut(\"Ctrl+E\") editMenu.addAction(pasteAction) fontAction = QAction(QtGui.QIcon(self.iconName), \"Font\", self) fontAction.setShortcut(\"Ctrl+F\") fontAction.triggered.connect(self.fontDialog) viewMenu.addAction(fontAction) colorAction = QAction(QtGui.QIcon(self.iconName), \"Color\", self) colorAction.triggered.connect(self.colorDialog) viewMenu.addAction(colorAction) # 工具栏 toolbar = self.addToolBar(\"Toolbar\") toolbar.addAction(copyAction) toolbar.addAction(cutAction) toolbar.addAction(saveAction) toolbar.addAction(exitAction) toolbar.addAction(pasteAction) toolbar.addAction(fontAction) toolbar.addAction(colorAction) toolbar.addAction(printAction) def exitWindow(self): \"\"\"关闭窗口\"\"\" self.close() def createEditor(self): \"\"\"文档编辑\"\"\" self.textEdit = QTextEdit(self) self.setCentralWidget(self.textEdit) def fontDialog(self): \"\"\"字体对话框\"\"\" font, ok = QFontDialog.getFont() if ok: self.textEdit.setFont(font) def colorDialog(self): \"\"\"颜色对话框\"\"\" color = QColorDialog.getColor() self.textEdit.setTextColor(color) def printDialog(self): \"\"\"打印文本框\"\"\" printer = QPrinter(QPrinter.HighResolution) dialog = QPrintDialog(printer, self) if dialog.exec_() == QPrintDialog.Accepted: self.textEdit.print_(printer) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/28-打印预览.html":{"url":"Python/第三方库/PyQt5/28-打印预览.html","title":"打印预览","keywords":"","body":"datetime:2019/5/22 17:47 author:nzb 打印预览 import sys from PyQt5.QtWidgets import QApplication, QMainWindow, QAction, QTextEdit, QFontDialog, QColorDialog from PyQt5 import QtGui,QtCore from PyQt5.QtPrintSupport import QPrintDialog, QPrinter, QPrintPreviewDialog class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 PrintPreview Dialog' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 生成菜单栏 self.CreateMenu() # 生成文档编辑 self.createEditor() # 展示窗口 self.show() def CreateMenu(self): \"\"\"菜单栏\"\"\" mainMenu = self.menuBar() fileMenu = mainMenu.addMenu('File') editMenu = mainMenu.addMenu('Edit') viewMenu = mainMenu.addMenu('View') helpMenu = mainMenu.addMenu('Help') copyAction = QAction(QtGui.QIcon(self.iconName), 'Copy', self) copyAction.setShortcut(\"Ctrl+C\") editMenu.addAction(copyAction) cutAction = QAction(QtGui.QIcon(self.iconName), 'Cut', self) cutAction.setShortcut(\"Ctrl+X\") editMenu.addAction(cutAction) saveAction = QAction(QtGui.QIcon(self.iconName), 'Save', self) saveAction.setShortcut(\"Ctrl+S\") editMenu.addAction(saveAction) printAction = QAction(QtGui.QIcon(self.iconName), \"Print\", self) printAction.triggered.connect(self.printDialog) fileMenu.addAction(printAction) printpreviewAction = QAction(QtGui.QIcon(self.iconName), \"PrintPreview\", self) printpreviewAction.triggered.connect(self.printPreviewDialog) fileMenu.addAction(printpreviewAction) exitAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Exit', self) exitAction.setShortcut(\"Ctrl+E\") exitAction.triggered.connect(self.exitWindow) fileMenu.addAction(exitAction) pasteAction = QAction(QtGui.QIcon('../img/Agt Stop.ico'), 'Paste', self) pasteAction.setShortcut(\"Ctrl+E\") editMenu.addAction(pasteAction) fontAction = QAction(QtGui.QIcon(self.iconName), \"Font\", self) fontAction.setShortcut(\"Ctrl+F\") fontAction.triggered.connect(self.fontDialog) viewMenu.addAction(fontAction) colorAction = QAction(QtGui.QIcon(self.iconName), \"Color\", self) colorAction.triggered.connect(self.colorDialog) viewMenu.addAction(colorAction) # 工具栏 toolbar = self.addToolBar(\"Toolbar\") toolbar.addAction(copyAction) toolbar.addAction(cutAction) toolbar.addAction(saveAction) toolbar.addAction(exitAction) toolbar.addAction(pasteAction) toolbar.addAction(fontAction) toolbar.addAction(colorAction) toolbar.addAction(printAction) def exitWindow(self): \"\"\"关闭窗口\"\"\" self.close() def createEditor(self): \"\"\"文档编辑\"\"\" self.textEdit = QTextEdit(self) self.setCentralWidget(self.textEdit) def fontDialog(self): \"\"\"字体对话框\"\"\" font, ok = QFontDialog.getFont() if ok: self.textEdit.setFont(font) def colorDialog(self): \"\"\"颜色对话框\"\"\" color = QColorDialog.getColor() self.textEdit.setTextColor(color) def printDialog(self): \"\"\"打印文本框\"\"\" printer = QPrinter(QPrinter.HighResolution) dialog = QPrintDialog(printer, self) if dialog.exec_() == QPrintDialog.Accepted: self.textEdit.print_(printer) def printPreviewDialog(self): \"\"\"打印预览\"\"\" printer = QPrinter(QPrinter.HighResolution) previewDialog = QPrintPreviewDialog(printer, self) previewDialog.paintRequested.connect(self.printPreview) previewDialog.exec_() def printPreview(self, printer): \"\"\"打印预览\"\"\" self.textEdit.print_(printer) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/29-打印PDF.html":{"url":"Python/第三方库/PyQt5/29-打印PDF.html","title":"打印PDF","keywords":"","body":"datetime:2019/5/23 10:26 author:nzb 打印PDF import sys from PyQt5.QtWidgets import QFileDialog, QApplication, QMainWindow, QAction, QTextEdit, QFontDialog, QColorDialog from PyQt5 import QtGui,QtCore from PyQt5.QtPrintSupport import QPrintDialog, QPrinter, QPrintPreviewDialog from PyQt5.QtCore import QFileInfo class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 PDF' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 生成菜单栏 self.CreateMenu() # 生成文档编辑 self.createEditor() # 展示窗口 self.show() def CreateMenu(self): \"\"\"菜单栏\"\"\" mainMenu = self.menuBar() fileMenu = mainMenu.addMenu('File') editMenu = mainMenu.addMenu('Edit') viewMenu = mainMenu.addMenu('View') helpMenu = mainMenu.addMenu('Help') # 复制 copyAction = QAction(QtGui.QIcon('../img/copy.ico'), 'Copy', self) copyAction.setShortcut(\"Ctrl+C\") editMenu.addAction(copyAction) # 剪切 cutAction = QAction(QtGui.QIcon('../img/cut.png'), 'Cut', self) cutAction.setShortcut(\"Ctrl+X\") editMenu.addAction(cutAction) # 保存 saveAction = QAction(QtGui.QIcon('../img/save.png'), 'Save', self) saveAction.setShortcut(\"Ctrl+S\") editMenu.addAction(saveAction) # 打印 printAction = QAction(QtGui.QIcon('../img/print.png'), \"Print\", self) printAction.triggered.connect(self.printDialog) fileMenu.addAction(printAction) # 打印预览 printpreviewAction = QAction(QtGui.QIcon('../img/printpreview.png'), \"PrintPreview\", self) printpreviewAction.triggered.connect(self.printPreviewDialog) fileMenu.addAction(printpreviewAction) # pdf pdfAction = QAction(QtGui.QIcon('../img/pdf.png'), 'PDF', self) pdfAction.triggered.connect(self.pdfExport) fileMenu.addAction(pdfAction) # 退出 exitAction = QAction(QtGui.QIcon('../img/exit.png'), 'Exit', self) exitAction.setShortcut(\"Ctrl+E\") exitAction.triggered.connect(self.exitWindow) fileMenu.addAction(exitAction) # 黏贴 pasteAction = QAction(QtGui.QIcon('../img/paste.png'), 'Paste', self) pasteAction.setShortcut(\"Ctrl+E\") editMenu.addAction(pasteAction) # 字体 fontAction = QAction(QtGui.QIcon('../img/font.png'), \"Font\", self) fontAction.setShortcut(\"Ctrl+F\") fontAction.triggered.connect(self.fontDialog) viewMenu.addAction(fontAction) # 字体颜色 colorAction = QAction(QtGui.QIcon('../img/color.png'), \"Color\", self) colorAction.triggered.connect(self.colorDialog) viewMenu.addAction(colorAction) # 工具栏 toolbar = self.addToolBar(\"Toolbar\") toolbar.addAction(copyAction) toolbar.addAction(cutAction) toolbar.addAction(saveAction) toolbar.addAction(exitAction) toolbar.addAction(pasteAction) toolbar.addAction(fontAction) toolbar.addAction(colorAction) toolbar.addAction(printAction) toolbar.addAction(pdfAction) def exitWindow(self): \"\"\"关闭窗口\"\"\" self.close() def createEditor(self): \"\"\"文档编辑\"\"\" self.textEdit = QTextEdit(self) self.setCentralWidget(self.textEdit) def fontDialog(self): \"\"\"字体对话框\"\"\" font, ok = QFontDialog.getFont() if ok: self.textEdit.setFont(font) def colorDialog(self): \"\"\"颜色对话框\"\"\" color = QColorDialog.getColor() self.textEdit.setTextColor(color) def printDialog(self): \"\"\"打印文本框\"\"\" printer = QPrinter(QPrinter.HighResolution) dialog = QPrintDialog(printer, self) if dialog.exec_() == QPrintDialog.Accepted: self.textEdit.print_(printer) def printPreviewDialog(self): \"\"\"打印预览\"\"\" printer = QPrinter(QPrinter.HighResolution) previewDialog = QPrintPreviewDialog(printer, self) previewDialog.paintRequested.connect(self.printPreview) previewDialog.exec_() def printPreview(self, printer): \"\"\"打印预览\"\"\" self.textEdit.print_(printer) def pdfExport(self): \"\"\"导出PDF\"\"\" fn, _ = QFileDialog.getSaveFileName(self, \"Export PDF\", None, \"PDF files (.pdf);;All Files()\") if fn != '': if QFileInfo(fn).suffix() == \"\": fn += '.pdf' printer = QPrinter(QPrinter.HighResolution) printer.setOutputFormat(QPrinter.PdfFormat) printer.setOutputFileName(fn) self.textEdit.document().print_(printer) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/30-消息框提示框（带选择的）.html":{"url":"Python/第三方库/PyQt5/30-消息框提示框（带选择的）.html","title":"消息框提示框（带选择的）","keywords":"","body":"datetime:2019/5/23 10:44 author:nzb （带选择的）消息框提示框 import sys from PyQt5.QtWidgets import QFileDialog, QApplication, QMainWindow, QAction, QTextEdit, QFontDialog, QColorDialog, QMessageBox from PyQt5 import QtGui,QtCore from PyQt5.QtPrintSupport import QPrintDialog, QPrinter, QPrintPreviewDialog from PyQt5.QtCore import QFileInfo class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Messagebox' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 生成菜单栏 self.CreateMenu() # 生成文档编辑 self.createEditor() # 展示窗口 self.show() def CreateMenu(self): \"\"\"菜单栏\"\"\" mainMenu = self.menuBar() fileMenu = mainMenu.addMenu('File') editMenu = mainMenu.addMenu('Edit') viewMenu = mainMenu.addMenu('View') helpMenu = mainMenu.addMenu('Help') # 复制 copyAction = QAction(QtGui.QIcon('../img/copy.ico'), 'Copy', self) copyAction.setShortcut(\"Ctrl+C\") editMenu.addAction(copyAction) # 剪切 cutAction = QAction(QtGui.QIcon('../img/cut.png'), 'Cut', self) cutAction.setShortcut(\"Ctrl+X\") editMenu.addAction(cutAction) # 保存 saveAction = QAction(QtGui.QIcon('../img/save.png'), 'Save', self) saveAction.setShortcut(\"Ctrl+S\") editMenu.addAction(saveAction) # 打印 printAction = QAction(QtGui.QIcon('../img/print.png'), \"Print\", self) printAction.triggered.connect(self.printDialog) fileMenu.addAction(printAction) # 打印预览 printpreviewAction = QAction(QtGui.QIcon('../img/printpreview.png'), \"PrintPreview\", self) printpreviewAction.triggered.connect(self.printPreviewDialog) fileMenu.addAction(printpreviewAction) # pdf pdfAction = QAction(QtGui.QIcon('../img/pdf.png'), 'PDF', self) pdfAction.triggered.connect(self.pdfExport) fileMenu.addAction(pdfAction) # 退出 exitAction = QAction(QtGui.QIcon('../img/exit.png'), 'Exit', self) exitAction.setShortcut(\"Ctrl+E\") exitAction.triggered.connect(self.exitWindow) fileMenu.addAction(exitAction) # 黏贴 pasteAction = QAction(QtGui.QIcon('../img/paste.png'), 'Paste', self) pasteAction.setShortcut(\"Ctrl+E\") editMenu.addAction(pasteAction) # 字体 fontAction = QAction(QtGui.QIcon('../img/font.png'), \"Font\", self) fontAction.setShortcut(\"Ctrl+F\") fontAction.triggered.connect(self.fontDialog) viewMenu.addAction(fontAction) # 字体颜色 colorAction = QAction(QtGui.QIcon('../img/color.png'), \"Color\", self) colorAction.triggered.connect(self.colorDialog) viewMenu.addAction(colorAction) # 消息框，提示框 helpAction = QAction(QtGui.QIcon('../img/about.ico'), \"About\", self) helpAction.triggered.connect(self.AboutMessageBox) helpMenu.addAction(helpAction) # 带选择的消息框，提示框 choiceAction = QAction(QtGui.QIcon('../img/about.ico'), \"Choice Message\", self) choiceAction.triggered.connect(self.choiceMessageBox) helpMenu.addAction(choiceAction) # 工具栏 toolbar = self.addToolBar(\"Toolbar\") toolbar.addAction(copyAction) toolbar.addAction(cutAction) toolbar.addAction(saveAction) toolbar.addAction(exitAction) toolbar.addAction(pasteAction) toolbar.addAction(fontAction) toolbar.addAction(colorAction) toolbar.addAction(printAction) toolbar.addAction(pdfAction) toolbar.addAction(helpAction) def exitWindow(self): \"\"\"关闭窗口\"\"\" self.close() def createEditor(self): \"\"\"文档编辑\"\"\" self.textEdit = QTextEdit(self) self.setCentralWidget(self.textEdit) def fontDialog(self): \"\"\"字体对话框\"\"\" font, ok = QFontDialog.getFont() if ok: self.textEdit.setFont(font) def colorDialog(self): \"\"\"颜色对话框\"\"\" color = QColorDialog.getColor() self.textEdit.setTextColor(color) def printDialog(self): \"\"\"打印文本框\"\"\" printer = QPrinter(QPrinter.HighResolution) dialog = QPrintDialog(printer, self) if dialog.exec_() == QPrintDialog.Accepted: self.textEdit.print_(printer) def printPreviewDialog(self): \"\"\"打印预览\"\"\" printer = QPrinter(QPrinter.HighResolution) previewDialog = QPrintPreviewDialog(printer, self) previewDialog.paintRequested.connect(self.printPreview) previewDialog.exec_() def printPreview(self, printer): \"\"\"打印预览\"\"\" self.textEdit.print_(printer) def pdfExport(self): \"\"\"导出PDF\"\"\" fn, _ = QFileDialog.getSaveFileName(self, \"Export PDF\", None, \"PDF files (.pdf);;All Files()\") if fn != '': if QFileInfo(fn).suffix() == \"\": fn += '.pdf' printer = QPrinter(QPrinter.HighResolution) printer.setOutputFormat(QPrinter.PdfFormat) printer.setOutputFileName(fn) self.textEdit.document().print_(printer) def AboutMessageBox(self): \"\"\"消息框提示框\"\"\" message = QMessageBox.about(self, \"About application\", \"this is simple texteditor application\") def choiceMessageBox(self): \"\"\"带选择的消息框和提示框\"\"\" message = QMessageBox.question(self, \"Choice Message\", 'Do you like PyQt5?', QMessageBox.Yes | QMessageBox.No) if message == QMessageBox.Yes: self.textEdit.setText(\"Yes I like PyQt5\") else: self.textEdit.setText(\"No I don't like PyQt5\") if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/31-右键菜单.html":{"url":"Python/第三方库/PyQt5/31-右键菜单.html","title":"右键菜单","keywords":"","body":"datetime:2019/5/23 10:53 author:nzb 右键菜单 import sys from PyQt5.QtWidgets import QApplication, QMainWindow, QMenu from PyQt5 import QtGui class UI_demo(QMainWindow): \"\"\"用户界面\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 Context Menu' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # 展示窗口 self.show() def contextMenuEvent(self, event): \"\"\"右键菜单\"\"\" contextMenu = QMenu(self) newAction = contextMenu.addAction(\"New\") openAction = contextMenu.addAction(\"Open\") quitAction = contextMenu.addAction(\"Quit\") action = contextMenu.exec_(self.mapToGlobal(event.pos())) if action == quitAction: self.close() if __name__ == \"__main__\": app = QApplication(sys.argv) ex = UI_demo() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/32-选项卡（单选下拉框和多选）.html":{"url":"Python/第三方库/PyQt5/32-选项卡（单选下拉框和多选）.html","title":"选项卡（单选下拉框和多选）","keywords":"","body":"datetime:2019/5/23 11:26 author:nzb 选项卡（单选下拉框和多选） 选项卡 单选和多选 from PyQt5 import QtGui from PyQt5.QtWidgets import QApplication, QGroupBox, QComboBox, QCheckBox, QDialog, QTabWidget, QWidget, QVBoxLayout, QDialogButtonBox, QTabWidget, QLabel, QLineEdit import sys from PyQt5.QtGui import QIcon class Tab(QDialog): \"\"\"选项卡\"\"\" def __init__(self): super().__init__() self.setWindowTitle(\"PyQt5 Tab Widget\") self.setWindowIcon(QIcon('../img/home.ico')) vbox = QVBoxLayout() tabWidget = QTabWidget() # 按钮 buttonbox = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel) buttonbox.accepted.connect(self.accept) buttonbox.accepted.connect(self.reject) # 选项卡 tabWidget.addTab(TabContact(), \"Contact Details\") tabWidget.addTab(TabPersonDetails(), 'Personal Details') vbox.addWidget(tabWidget) vbox.addWidget(buttonbox) self.setLayout(vbox) class TabContact(QWidget): def __init__(self): super().__init__() nameLabel = QLabel(\"Name: \") nameEdit = QLineEdit() phoneLabel = QLabel(\"Phone: \") phoneEdit = QLineEdit() emailLabel = QLabel(\"Email: \") emailEdit = QLineEdit() vbox = QVBoxLayout() vbox.addWidget(nameLabel) vbox.addWidget(nameEdit) vbox.addWidget(phoneLabel) vbox.addWidget(phoneEdit) vbox.addWidget(emailLabel) vbox.addWidget(emailEdit) self.setLayout(vbox) class TabPersonDetails(QWidget): def __init__(self): super().__init__() # 单选下拉框 groupbox = QGroupBox(\"select your gender\") list1 = [\"male\", 'female'] combo = QComboBox() combo.addItems(list1) vbox = QVBoxLayout() vbox.addWidget(combo) groupbox.setLayout(vbox) # 多选 groupbox2 = QGroupBox(\"select your favorite programming language\") python = QCheckBox(\"Python\") cpp = QCheckBox(\"C++\") java = QCheckBox(\"Java\") vbox = QVBoxLayout() vbox.addWidget(python) vbox.addWidget(cpp) vbox.addWidget(java) groupbox2.setLayout(vbox) mainLayout = QVBoxLayout() mainLayout.addWidget(groupbox) mainLayout.addWidget(groupbox2) self.setLayout(mainLayout) if __name__ == \"__main__\": app = QApplication(sys.argv) tabDialog = Tab() tabDialog.show() app.exec_() "},"Python/第三方库/PyQt5/34-可停靠的窗口小部件.html":{"url":"Python/第三方库/PyQt5/34-可停靠的窗口小部件.html","title":"可停靠的窗口小部件","keywords":"","body":"datetime:2019/5/23 13:37 author:nzb 可停靠的窗口小部件 from PyQt5 import QtGui from PyQt5.QtWidgets import QApplication, QPushButton, QStackedWidget, QGroupBox, QComboBox, QDialog, QTabWidget, QWidget, QVBoxLayout, QLabel from PyQt5.QtWidgets import QTextEdit, QDockWidget, QMainWindow, QListWidget import sys from PyQt5.QtGui import QIcon from PyQt5.QtCore import Qt class DockDialog(QMainWindow): \"\"\"可停靠的窗口小部件\"\"\" def __init__(self): super().__init__() # 窗口信息 self.title = 'PyQt5 DockDialog' self.left = 600 self.top = 200 self.width = 500 self.height = 400 self.iconName = '../img/home.ico' self.initWindow() def initWindow(self): # 窗口信息 self.setWindowIcon(QtGui.QIcon(self.iconName)) # 图标设置 self.setGeometry(self.left, self.top, self.width, self.height) # 大小位置设置 self.setWindowTitle(self.title) # 窗口标题 # self.createDockWidget() # 展示窗口 self.show() def createDockWidget(self): menubar = self.menuBar() file = menubar.addMenu(\"File\") file.addAction(\"New\") file.addAction(\"Save\") file.addAction(\"Close\") self.dock = QDockWidget(\"Dockable\", self) self.listwidget = QListWidget() list1 = ['Python', 'C++', 'Java'] self.listwidget.addItems(list1) self.dock.setWidget(self.listwidget) self.setCentralWidget(QTextEdit()) self.addDockWidget(Qt.RightDockWidgetArea, self.dock) if __name__ == \"__main__\": app = QApplication(sys.argv) ex = DockDialog() sys.exit(app.exec_()) "},"Python/第三方库/PyQt5/35-日历.html":{"url":"Python/第三方库/PyQt5/35-日历.html","title":"日历","keywords":"","body":"datetime:2019/5/23 13:44 author:nzb 日历 from PyQt5 import QtGui from PyQt5.QtWidgets import QApplication, QDialog, QCalendarWidget, QVBoxLayout, QLabel import sys class Window(QDialog): def __init__(self): super().__init__() self.title = \"PyQt5 QCalender\" self.top = 200 self.left = 500 self.width = 400 self.height = 300 self.InitWindow() def InitWindow(self): self.setWindowIcon(QtGui.QIcon(\"icon.png\")) self.setWindowTitle(self.title) self.setGeometry(self.left, self.top, self.width, self.height) self.Calender() self.show() def Calender(self): vbox = QVBoxLayout() self.calender = QCalendarWidget() self.calender.selectionChanged.connect(self.onSelectionChanged) self.calender.setGridVisible(True) vbox.addWidget(self.calender) self.label = QLabel() self.label.setFont(QtGui.QFont(\"Sanserif\", 15)) self.label.setStyleSheet('color:green') vbox.addWidget(self.label) self.setLayout(vbox) def onSelectionChanged(self): ca = self.calender.selectedDate() self.label.setText(str(ca)) App = QApplication(sys.argv) window = Window() sys.exit(App.exec()) 日历中时间的格式化 from PyQt5.QtCore import QDateTime, QDate,QTime,Qt datetime = QDateTime.currentDateTime() print(datetime.toString()) print(datetime.toString(Qt.ISODate)) print(datetime.toString(Qt.DefaultLocaleLongDate)) # 周四 5月 23 13:46:48 2019 # 2019-05-23T13:46:48 # 2019年5月23日 13:46:48 date = QDate.currentDate() print(date.toString()) print(date.toString(Qt.ISODate)) print(date.toString(Qt.DefaultLocaleLongDate)) # 周四 5月 23 2019 # 2019-05-23 # 2019年5月23日 time = QTime.currentTime() print(time.toString()) print(time.toString(Qt.DefaultLocaleLongDate)) # 13:46:48 # 13:46:48 "},"Python/第三方库/PyQt5/36-单选下拉框.html":{"url":"Python/第三方库/PyQt5/36-单选下拉框.html","title":"单选下拉框","keywords":"","body":"datetime:2019/5/23 14:07 author:nzb 单选下拉框 from PyQt5 import QtGui from PyQt5.QtWidgets import QApplication,QLabel, QComboBox, QVBoxLayout, QDialog, QMainWindow, QCalendarWidget, QVBoxLayout, QLabel import sys class Window(QDialog): \"\"\"下拉框\"\"\" def __init__(self): super().__init__() self.title = \"PyQt5 combobox\" self.top = 200 self.left = 500 self.width = 400 self.height = 300 self.InitWindow() def InitWindow(self): self.setWindowIcon(QtGui.QIcon(\"icon.png\")) self.setWindowTitle(self.title) self.setGeometry(self.left, self.top, self.width, self.height) self.InitUI() self.show() def InitUI(self): vbox = QVBoxLayout() self.combo = QComboBox() self.combo.addItem(\"Python\") self.combo.addItem(\"Ruby\") self.combo.addItem(\"C++\") self.combo.addItem(\"PHP\") self.combo.currentTextChanged.connect(self.comboChanged) self.label = QLabel() self.label.setFont(QtGui.QFont(\"Sanserif\", 15)) self.label.setStyleSheet(\"color:red\") vbox.addWidget(self.combo) vbox.addWidget(self.label) self.setLayout(vbox) def comboChanged(self): \"\"\"选择事件\"\"\" text = self.combo.currentText() self.label.setText(\"You have selected \" + text) App = QApplication(sys.argv) window = Window() sys.exit(App.exec()) "},"Python/第三方库/PyQt5/37-首字符模糊填充（查询）.html":{"url":"Python/第三方库/PyQt5/37-首字符模糊填充（查询）.html","title":"首字符模糊填充（查询）","keywords":"","body":"datetime:2019/5/23 14:14 author:nzb 首字符模糊填充（查询） from PyQt5 import QtGui from PyQt5.QtWidgets import QApplication,QLabel, QComboBox, QVBoxLayout, QDialog, QMainWindow, QCalendarWidget, QVBoxLayout, QLabel import sys from PyQt5.QtWidgets import QCompleter, QLineEdit class Window(QDialog): \"\"\"模糊查询\"\"\" def __init__(self): super().__init__() self.title = \"PyQt5 completer\" self.top = 200 self.left = 500 self.width = 400 self.height = 300 self.InitWindow() def InitWindow(self): self.setWindowIcon(QtGui.QIcon(\"icon.png\")) self.setWindowTitle(self.title) self.setGeometry(self.left, self.top, self.width, self.height) self.InitUI() self.show() def InitUI(self): vbox = QVBoxLayout() names = ['China', 'USA', 'Pakistan', 'Japan', 'India', 'American', '测试中文'] completer = QCompleter(names) self.lineedit = QLineEdit() self.lineedit.setCompleter(completer) vbox.addWidget(self.lineedit) self.setLayout(vbox) App = QApplication(sys.argv) window = Window() sys.exit(App.exec()) "},"Python/第三方库/PyQt5/38-打开更多的窗口.html":{"url":"Python/第三方库/PyQt5/38-打开更多的窗口.html","title":"打开更多的窗口","keywords":"","body":"datetime:2019/5/23 14:28 author:nzb 打开更多的窗口 from PyQt5 import QtGui from PyQt5.QtWidgets import QApplication,QLabel, QPushButton, QComboBox, QVBoxLayout, QDialog, QMainWindow, QCalendarWidget, QVBoxLayout, QLabel import sys from PyQt5.QtWidgets import QCompleter, QLineEdit class Window(QDialog): \"\"\"模糊查询\"\"\" def __init__(self): super().__init__() self.title = \"PyQt5 QDialog\" self.top = 200 self.left = 500 self.width = 400 self.height = 300 self.InitWindow() def InitWindow(self): self.setWindowIcon(QtGui.QIcon(\"../img/home.ico\")) self.setWindowTitle(self.title) self.setGeometry(self.left, self.top, self.width, self.height) self.InitUI() self.show() def InitUI(self): vbox = QVBoxLayout() self.btn = QPushButton(\"Open second dialog\") self.btn.setFont(QtGui.QFont(\"Sanserif\", 15)) self.btn.clicked.connect(self.openSecondDialog) vbox.addWidget(self.btn) self.setLayout(vbox) def openSecondDialog(self): \"\"\"打开另一个窗口\"\"\" # 1.只能打开第二个，并且不能移动第一个 # mydialog = QDialog() # mydialog.setModal(True) # mydialog.exec() # 可以无限打开，并且可以在第一个上操作 mydialog = QDialog(self) mydialog.show() App = QApplication(sys.argv) window = Window() sys.exit(App.exec()) "},"Python/第三方库/PyQt5/39-时间编辑.html":{"url":"Python/第三方库/PyQt5/39-时间编辑.html","title":"时间编辑","keywords":"","body":"datetime:2019/5/23 14:37 author:nzb 时间编辑 from PyQt5 import QtGui from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QComboBox, QVBoxLayout, QDialog, QMainWindow, QCalendarWidget, QVBoxLayout, QLabel import sys from PyQt5.QtWidgets import QCompleter, QLineEdit, QTimeEdit from PyQt5.QtCore import QTime class Window(QWidget): \"\"\"时间编辑\"\"\" def __init__(self): super().__init__() self.title = \"PyQt5 QDialog\" self.top = 200 self.left = 500 self.width = 400 self.height = 300 self.InitWindow() def InitWindow(self): self.setWindowIcon(QtGui.QIcon(\"../img/home.ico\")) self.setWindowTitle(self.title) self.setGeometry(self.left, self.top, self.width, self.height) self.MyTime() self.show() def MyTime(self): vbox = QVBoxLayout() time = QTime() time.setHMS(13, 15, 40) timeedit = QTimeEdit() timeedit.setFont(QtGui.QFont('Sanserif', 15)) timeedit.setTime(time) vbox.addWidget(timeedit) self.setLayout(vbox) App = QApplication(sys.argv) window = Window() sys.exit(App.exec()) "},"Python/第三方库/PyQt5/40-列表部件.html":{"url":"Python/第三方库/PyQt5/40-列表部件.html","title":"列表部件","keywords":"","body":"datetime:2019/5/23 14:52 author:nzb 列表部件 from PyQt5 import QtGui from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QComboBox, QVBoxLayout, QDialog, QMainWindow, QCalendarWidget, QVBoxLayout, QLabel import sys from PyQt5.QtWidgets import QCompleter, QLineEdit, QTimeEdit, QListWidget from PyQt5.QtCore import QTime class Window(QWidget): \"\"\"列表部件\"\"\" def __init__(self): super().__init__() self.title = \"PyQt5 QListWidget\" self.top = 200 self.left = 500 self.width = 400 self.height = 300 self.InitWindow() def InitWindow(self): self.setWindowIcon(QtGui.QIcon(\"../img/home.ico\")) self.setWindowTitle(self.title) self.setGeometry(self.left, self.top, self.width, self.height) vbox = QVBoxLayout() self.list = QListWidget() self.list.insertItem(0, \"Python\") self.list.insertItem(1, \"PHP\") self.list.insertItem(2, \"Java\") self.list.insertItem(3, \"C++\") self.list.clicked.connect(self.listview_clicked) self.label = QLabel() self.setFont(QtGui.QFont(\"Sanserif\", 15)) vbox.addWidget(self.label) vbox.addWidget(self.list) self.setLayout(vbox) self.show() def listview_clicked(self): item = self.list.currentItem() self.label.setText(str(item.text())) App = QApplication(sys.argv) window = Window() sys.exit(App.exec()) "},"Python/第三方库/PyQt5/41-列表部件小示例.html":{"url":"Python/第三方库/PyQt5/41-列表部件小示例.html","title":"列表部件小示例","keywords":"","body":"datetime:2019/5/23 15:25 author:nzb 列表部件小示例 from PyQt5.QtWidgets import QApplication, QDialog, QLineEdit, QMessageBox, QInputDialog, QListWidget, QVBoxLayout, QPushButton, QHBoxLayout from PyQt5.QtGui import QIcon from PyQt5 import QtGui import sys class ProgrammingDialog(QDialog): def __init__(self, name, prolist = None): super(ProgrammingDialog, self).__init__() self.setWindowTitle(\"PyQt5 simple List project\") self.setWindowIcon(QtGui.QIcon('../img/home.ico')) self.name = name self.list = QListWidget() if prolist is not None: self.list.addItems(prolist) self.list.setCurrentRow(0) vbox = QVBoxLayout() for text, slot in ((\"Add\", self.Add), (\"Edit\", self.Edit), (\"Remove\", self.Remove), (\"Sort\", self.Sort), (\"Close\", self.Close)): button = QPushButton(text) button.clicked.connect(slot) vbox.addWidget(button) hbox = QHBoxLayout() hbox.addWidget(self.list) hbox.addLayout(vbox) self.setLayout(hbox) def Add(self): row = self.list.currentRow() title = \"Add {0}\".format(self.name) string, ok = QInputDialog.getText(self, title, title) if ok and string is not None: self.list.insertItem(row, string) def Edit(self): row = self.list.currentRow() item = self.list.item(row) if item is not None: title = \"Edit {0}\".format(self.name) string, ok = QInputDialog.getText(self, title, title, QLineEdit.Normal, item.text()) if ok and string is not None: item.setText(string) def Remove(self): row = self.list.currentRow() item = self.list.item(row) if item is None: return reply = QMessageBox.question(self, \"Remove{0}\".format( self.name), \"Remove{0} '{1}'?\".format( self.name, str(item.text())), QMessageBox.Yes | QMessageBox.No) if reply == QMessageBox.Yes: item = self.list.takeItem(row) del item def Sort(self): self.list.sortItems() def Close(self): self.close() # self.accept() if __name__ == '__main__': programming = [\"Python\", \"Java\", \"PHP\", \"C++\"] app = QApplication(sys.argv) dialog = ProgrammingDialog(\"Language\", programming) dialog.exec_() "},"Python/第三方库/PySide/01-Qt简介.html":{"url":"Python/第三方库/PySide/01-Qt简介.html","title":"Qt简介","keywords":"","body":"Python Qt 简介 Python图形界面开发的几种方案 程序的用户交互界面，英文称之为 UI (user interface) 当一个应用的 UI 比较复杂的时候，命令行方式就不便用户使用了，这时我们需要图形界面。 如果用 Python 语言开发 跨平台 的图形界面的程序，主要有3种选择： Tkinter 基于Tk的Python库，这是Python官方采用的标准库，优点是作为Python标准库、稳定、发布程序较小，缺点是控件相对较少。适合开发小工具，界面比较简单。 wxPython 基于wxWidgets的Python库，优点是控件比较丰富，缺点是稳定性相对差点、文档少、用户少。 PySide2、PyQt5 基于Qt 的Python库，优点是控件比较丰富、跨平台体验好、文档完善、用户多。 缺点是库比较大，发布出来的程序比较大。适合发布功能比较多的正式产品。 注意：现在已经到 PySide6 了 PySide2、PyQt5 简介 PySide2、PyQt5 都是基于著名的 Qt 库。 Qt库里面有非常强大的图形界面开发库，但是Qt库是C++语言开发的，PySide2、PyQt5可以让我们通过Python语言使用Qt。 但是 PySide2、PyQt5 这两者有什么区别呢？ 可以形象地这样说： PySide2 是Qt的 亲儿子 ， PyQt5 是Qt还没有亲儿子之前的收的 义子 （Riverbank Computing这个公司开发的）。 那为什么 PyQt5 这个义子 反而比 PySide2 这个亲儿子更出名呢？ 原因很简单：PySide2 这亲儿子最近（2018年7月）才出生。 但是亲儿子毕竟是亲儿子，Qt准备大力培养，PySide2 或许更有前途。 已经在使用 PyQt5 的朋友不要皱眉， 两个库的使用 对程序员来说，差别很小：它们的调用接口几乎一模一样。 如果你的程序是PyQt5开发的，通常只要略作修改，比如把导入的名字从 PyQt5 换成 PySide2 就行了。反之亦然。 安装 PySide2 很简单，直接执行 pip install pyside2 即可下载安装。 这个库比较大，大概有100M左右，大家耐心等待。 有的朋友，网络比较慢，可以指定国内的安装源，下载安装。 比如，使用豆瓣源下载安装：pip install pyside2 -i https://pypi.douban.com/simple/ 安装PyQt5 如果你选择PyQt5，直接执行 pip install pyqt5-tools 即可同时安装 PyQt5 和 一些重要的工具，比如 Qt designer。 "},"Python/第三方库/PySide/02-界面设计师QtDesigner.html":{"url":"Python/第三方库/PySide/02-界面设计师QtDesigner.html","title":"界面设计师QtDesigner","keywords":"","body":"界面设计师 Qt Designer Qt Designer 简介 QT程序界面的 一个个窗口、控件，就是像上面那样用相应的代码创建出来的。 但是，把你的脑海里的界面，用代码直接写出来，是有些困难的。 很多时候，运行时呈现的样子，不是我们要的。我们经常还要修改代码调整界面上控件的位置，再运行预览。反复多次这样操作。 可是这样，真的…太麻烦了。 其实，我们可以用QT界面生成器 Qt Designer ，拖拖拽拽就可以直观的创建出程序大体的界面。 怎么运行这个工具呢？ Windows下，运行 Python安装目录下 Scripts\\pyside2-designer.exe 这个可执行文件 如果你安装的是pyqt5， 运行 Python安装目录下 Scripts\\pyqt5designer.exe 这个可执行文件 通过 Qt Designer 设计的界面，最终是保存在一个ui文件中的。 大家可以打开这个ui文件看看，就是一个XML格式的界面定义。 动态加载UI文件 有了界面定义文件，我们的Python程序就可以从文件中加载UI定义，并且动态创建一个相应的窗口对象。 如下： from PySide2.QtWidgets import QApplication, QMessageBox from PySide2.QtUiTools import QUiLoader class Stats: def __init__(self): # 从文件中加载UI定义 # 从 UI 定义中动态 创建一个相应的窗口对象 # 注意：里面的控件对象也成为窗口对象的属性了 # 比如 self.ui.button , self.ui.textEdit self.ui = QUiLoader().load('main.ui') self.ui.button.clicked.connect(self.handleCalc) def handleCalc(self): info = self.ui.textEdit.toPlainText() salary_above_20k = '' salary_below_20k = '' for line in info.splitlines(): if not line.strip(): continue parts = line.split(' ') parts = [p for p in parts if p] name, salary, age = parts if int(salary) >= 20000: salary_above_20k += name + '\\n' else: salary_below_20k += name + '\\n' QMessageBox.about(self.ui, '统计结果', f'''薪资20000 以上的有：\\n{salary_above_20k} \\n薪资20000 以下的有：\\n{salary_below_20k}''' ) app = QApplication([]) stats = Stats() stats.ui.show() app.exec_() 如果你使用的是PyQt5 而不是 PySide2，加载UI文件的代码如下 from PyQt5 import uic class Stats: def __init__(self): # 从文件中加载UI定义 self.ui = uic.loadUi(\"main.ui\") 转化 UI文件为 Python 代码 还有一种使用 UI 文件的方式：先把UI文件直接转化为包含界面定义的 Python 代码文件，然后在你的程序中使用定义界面的类 执行如下的命令把 UI 文件直接转化为包含界面定义的 Python 代码文件 pyside2-uic main.ui > ui_main.py 如果你安装的是PyQt5，执行如下格式的命令转化 pyuic5 main.ui > ui_main.py 然后在你的代码文件中这样使用定义界面的类 from PySide2.QtWidgets import QApplication, QMainWindow from ui_main import Ui_MainWindow class MainWindow(QMainWindow): def __init__(self): super().__init__() # 使用ui文件导入定义界面类 self.ui = Ui_MainWindow() # 初始化界面 self.ui.setupUi(self) # 使用界面定义的控件，也是从ui里面访问 self.ui.webview.load('http://www.baidu.com') app = QApplication([]) mainw = MainWindow() mainw.show() app.exec_() 那么我们该使用哪种方式比较好呢？动态加载还是转化为Python代码？ 建议：通常采用动态加载比较方便，因为改动界面后，不需要转化，直接运行，特别方便。 但是，如果你的程序里面有非qt designer提供的控件， 这时候，需要在代码里面加上一些额外的声明，而且可能还会有奇怪的问题。往往就要采用转化Python代码的方法。 界面布局 Layout 我们前面写的界面程序有个问题，如果你用鼠标拖拽主窗口边框右下角，进行缩放，就会发现里面的控件一直保持原有大小不变。这样会很难看。 我们通常希望，随着主窗口的缩放， 界面里面的控件、控件之间的距离也相应的进行缩放。 Qt是通过界面布局 Layout 类来实现这种功能的。 我们最常用的 Layout布局 有4种，分别是 QHBoxLayout 水平布局：把控件从左到右 水平横着摆放，如下所示 QVBoxLayout 垂直布局：把控件从上到下竖着摆放，如下所示 QGridLayout 表格布局：把多个控件 格子状摆放，有的控件可以 占据多个格子，如下所示 QFormLayout 表单布局：表单就像一个只有两列的表格，非常适合填写注册表单这种类型的界面，如下所示 MainWindow 的 Layout 如果我们选择的主窗口是MainWindow类型，要给MainWindow整体设定Layout，必须先添加一个控件到 centralwidget 下面 ，如下 然后才能右键点击 MainWindow，选择布局，如下 调整控件位置和大小 调整 layout 中控件的大小比例可以通过设定控件的 sizePolicy 给不同的值来调整。 调整控件间距要调整控件上下间距，可以给控件添加layout，然后通过设定layout的上下的padding 和 margin 来调整间距。要调整控件的左右间距，可以通过添加 horizontal spacer （弹簧）进行控制，也可以通过layout的左右margin。 调整控件次序有的时候 我们需要调整一个layout里面，控件的上下显示次序，或者左右显示次序，该怎么做呢？如果是简单的两个控件在 layout里面，通常直接拖动就行了。 界面布局步骤建议 先不使用任何 Layout，把所有控件按位置摆放在界面上 然后先从 最内层开始 进行控件的 Layout 设定 逐步拓展到外层 进行控件的 Layout设定 最后调整 layout中控件的大小比例， 优先使用 Layout的 layoutStrentch 属性来控制 从一个窗口跳转到另外一个窗口 程序开始的时候显示一个窗口（比如登录窗口），操作后进入到另外一个窗口，怎么做。 方法很简单，主要就是 实例化另外一个窗口，显示新窗口，关闭老窗口。 如下代码所示 from PySide2 import QtWidgets import sys class Window2(QtWidgets.QMainWindow): def __init__(self): super().__init__() self.setWindowTitle('窗口2') centralWidget = QtWidgets.QWidget() self.setCentralWidget(centralWidget) button = QtWidgets.QPushButton('按钮2') grid = QtWidgets.QGridLayout(centralWidget) grid.addWidget(button) class MainWindow(QtWidgets.QMainWindow): def __init__(self): super().__init__() self.setWindowTitle('窗口1') centralWidget = QtWidgets.QWidget() self.setCentralWidget(centralWidget) button = QtWidgets.QPushButton('打开新窗口') button.clicked.connect(self.open_new_window) grid = QtWidgets.QGridLayout(centralWidget) grid.addWidget(button) def open_new_window(self): # 实例化另外一个窗口 self.window2 = Window2() # 显示新窗口 self.window2.show() # 关闭自己 self.close() if __name__ == '__main__': app = QtWidgets.QApplication(sys.argv) window = MainWindow() window.show() sys.exit(app.exec_()) 如果经常要在两个窗口来回跳转，可以使用 hide() 方法 隐藏窗口， 而不是 closes() 方法关闭窗口。 这样还有一个好处：被隐藏的窗口再次显示时，原来的操作内容还保存着，不会消失。 弹出模式对话框 有的时候，我们需要弹出一个模式对话框输入一些数据，然后回到 原窗口。 所谓模式对话框，就是弹出此对话框后， 原窗口就处于不可操作的状态，只有当模式对话框关闭才能继续。 参考如下代码 from PySide2 import QtWidgets import sys class MyDialog(QtWidgets.QDialog): def __init__(self): super().__init__() self.setWindowTitle('模式对话框') self.resize(500, 400) self.textEdit = QtWidgets.QPlainTextEdit(self) self.textEdit.setPlaceholderText(\"请输入薪资表\") self.textEdit.move(10, 25) self.textEdit.resize(300, 350) self.button = QtWidgets.QPushButton('统计', self) self.button.move(380, 80) class MainWindow(QtWidgets.QMainWindow): def __init__(self): super().__init__() self.setWindowTitle('主窗口') centralWidget = QtWidgets.QWidget() self.setCentralWidget(centralWidget) button = QtWidgets.QPushButton('打开模式对话框') button.clicked.connect(self.open_new_window) grid = QtWidgets.QGridLayout(centralWidget) grid.addWidget(button) def open_new_window(self): # 实例化一个对话框类 self.dlg = MyDialog() # 显示对话框，代码阻塞在这里， # 等待对话框关闭后，才能继续往后执行 self.dlg.exec_() if __name__ == '__main__': app = QtWidgets.QApplication(sys.argv) window = MainWindow() window.show() sys.exit(app.exec_()) "},"Python/第三方库/PySide/03-发布程序.html":{"url":"Python/第三方库/PySide/03-发布程序.html","title":"发布程序","keywords":"","body":"正式发布程序 前面，我们开发好了一个HTTP协议测试程序，但是这个程序是Python程序，运行它需要Python解释器。 如果我们要发布程序给客户使用，当然不能要求别人去安装Python解释器，并且敲命令 python httpclient.py。 我们应该做成 可执行程序 发布别人使用。详情 我们前面开发的QT界面程序，在Windows 上只需要执行下面的命令，即可制作独立exe程序 pyinstaller httpclient.py --noconsole --hidden-import PySide2.QtXml这样就会在当前目录下产生一个名为 dist 的目录。里面就有一个名为 httpclient 的目录，我们的可执行程序 httpclient.exe 就在里面。 其中 --noconsole 指定不要命令行窗口，否则我们的程序运行的时候，还会多一个黑窗口。 但是我建议大家可以先去掉这个参数，等确定运行成功后，再加上参数重新制作exe。因为这个黑窗口可以显示出程序的报错，这样我们容易找到问题的线索。 --hidden-import PySide2.QtXml 参数是因为这个 QtXml库是动态导入，PyInstaller没法分析出来，需要我们告诉它， 最后，别忘了，把程序所需要的ui文件拷贝到打包目录中。 因为PyInstaller只能分析出需要哪些代码文件。 而你的程序动态打开的资源文件，比如 图片、excel、ui这些，它是不会帮你打包的。 我们的 示例代码需要从 httpclient.ui 中加载界面，手动拷贝到 dist/httpclient 目录中。 然后，再双击运行 httpclient.exe ，完美！！ 程序图标 添加主窗口图标我们程序运行的窗口，需要显示自己的图标，这样才更像一个正式的产品。 通过如下代码，我们可以把一个png图片文件作为 程序窗口图标。 from PySide2.QtGui import QIcon app = QApplication([]) # 加载 icon app.setWindowIcon(QIcon('logo.png')) 注意：这些图标png文件，在使用PyInstaller创建可执行程序时，也要拷贝到程序所在目录。否则可执行程序运行后不会显示图标。 应用程序图标 应用程序图标是放在可执行程序里面的资源。 可以在PyInstaller创建可执行程序时，通过参数 --icon=\"logo.ico\" 指定。 比如 pyinstaller httpclient.py --noconsole --hidden-import PySide2.QtXml --icon=\"logo.ico\" 注意参数一定是存在的ico文件，不能是png等图片文件。 如果你只有png文件，可以通过在线的png转ico文件网站，生成ico，比如下面两个网站 网站1 网站2 注意：这些应用程序图标ico文件，在使用PyInstaller创建可执行程序时，不需要要拷贝到程序所在目录。因为它已经被嵌入可执行程序了。 "},"Python/第三方库/PySide/04-常用控件1.html":{"url":"Python/第三方库/PySide/04-常用控件1.html","title":"常用控件1","keywords":"","body":"常用控件 1 按钮 QPushButton 就是常见的按钮 信号：被点击 当按钮被点击就会发出 clicked 信号，可以这样指定处理该信号的函数 button.clicked.connect(handleCalc) 方法：改变文本 代码中可以使用 setText 方法来改变按钮文本，比如 button.setText(text) 方法：禁用、启用所有控件（继承自QWidget类）都支持 禁用和启用方法。 禁用后，该控件不再处理用户操作 禁用 button.setEnabled(False) 启用 button.setEnabled(True) 单行文本框 QLineEdit 是只能单行编辑的文本框。 信号：文本被修改当文本框中的内容被键盘编辑，被点击就会发出 textChanged 信号，可以这样指定处理该信号的函数edit.textChanged.connect(handleTextChange)Qt在调用这个信号处理函数时，传入的参数就是 文本框目前的内容字符串。 信号：按下回车键当用户在文本框中任何时候按下回车键，就会发出 returnPressed 信号。有时我们需要处理这种情况，比如登录界面，用户输完密码直接按回车键就进行登录处理，比再用鼠标点击登录按钮快捷的多。 可以指定处理 returnPressed 信号，如下所示passwordEdit.returnPressed.connect(onLogin) 方法：获取文本通过 text 方法获取编辑框内的文本内容，比如text = edit.text() 方法：设置提示通过 setPlaceholderText 方法可以设置提示文本内容，比如edit.setPlaceholderText('请在这里输入URL') 方法：设置文本通过 setText 方法设置编辑框内的文本内容为参数里面的文本字符串，比如edit.setText('你好，白月黑羽')原来的所有内容会被清除 方法：清除所有文本clear 方法可以清除编辑框内所有的文本内容，比如edit.clear() 方法：拷贝文本到剪贴板 copy 方法可以拷贝当前选中文本到剪贴板，比如edit.copy() 方法：粘贴剪贴板文本 paste 方法可以把剪贴板内容，拷贝到编辑框当前光标所在处，比如 edit.paste() 多行纯文本框 QPlainTextEdit 是可以多行的纯文本编辑框。 注意：在苹果MacOS上，有 更新文本框内容后，需要鼠标滑过才能更新显示的bug，参考这里 信号：文本被修改当文本框中的内容被键盘编辑，被点击就会发出 textChanged 信号，可以这样指定处理该信号的函数edit.textChanged.connect(handleTextChange) 注意： Qt在调用这个信号处理函数时，不会传入文本框目前的内容字符串，作为参数。这个行为 和 单行文本框不同。 信号：光标位置改变当文本框中的光标位置变动，就会发出 cursorPositionChanged 信号，可以这样指定处理该信号的函数 edit.cursorPositionChanged.connect(handleChanged) 方法：获取文本通过 toPlainText 方法获取编辑框内的文本内容，比如text = edit.toPlainText() 方法：获取选中文本 # 获取 QTextCursor 对象 textCursor = edit.textCursor() selection = textCursor.selectedText() 方法：设置提示通过 setPlaceholderText 方法可以设置提示文本内容，比如edit.setPlaceholderText('请在这里输入薪资表') 方法：设置文本通过 setPlainText 方法设置编辑框内的文本内容 为参数里面的文本字符串，比如edit.setPlainText('''你好，白月黑羽 hello byhy''')原来的所有内容会被清除 方法：在末尾添加文本通过 appendPlainText 方法在编辑框末尾添加文本内容，比如 edit.appendPlainText('你好，白月黑羽')注意：这种方法会在添加文本后 自动换行 方法：在光标处插入文本通过 insertPlainText 方法在编辑框末尾添加文本内容，比如edit.insertPlainText('你好，白月黑羽')注意：这种方法 不会 在添加文本后自动换行 方法：清除所有文本 clear 方法可以清除编辑框内所有的文本内容，比如edit.clear() 方法：拷贝文本到剪贴板 copy 方法可以拷贝当前选中文本到剪贴板，比如edit.copy() 方法：粘贴剪贴板文本 paste 方法可以把剪贴板内容，拷贝到编辑框当前光标所在处，比如edit.paste() 文本浏览框 QTextBrowser 是只能查看文本控件。通常用来显示一些操作日志信息、或者不需要用户编辑的大段文本内容。该控件 获取文本、设置文本、清除文本、剪贴板复制粘贴 等等， 都和上面介绍的 多行纯文本框是一样的。 方法：在末尾添加文本通过 append 方法在编辑框末尾添加文本内容，比如textBrowser.append('你好，白月黑羽')有时，浏览框里面的内容长度超出了可见范围，我们在末尾添加了内容，往往希望控件自动翻滚到当前添加的这行， 可以通过 ensureCursorVisible 方法来实现 textBrowser.append('你好，白月黑羽') textBrowser.ensureCursorVisible() 注意：这种方法会在添加文本后 自动换行 方法：在光标处插入文本通过 insertPlainText 方法在编辑框末尾添加文本内容，比如edit.insertPlainText('你好，白月黑羽') 注意：这种方法不会在添加文本后自动换行 标签 QLabel 就是常见的标签，可以用来显示文字（包括纯文本和富文本）、图片 甚至动画。 方法：改变文本代码中可以使用 setText 方法来改变标签文本内容，比如 button.setText(text) 显示图片QLabel 可以用来显示图片，有时一个图片可以让界面好看很多，如下图所示 怎么用 QLabel 显示图片呢？可以在 Qt Designer 上 属性编辑器 QLabel 栏 的 pixmap 属性设置中选择图片文件指定。 "},"Python/第三方库/PySide/05-常用控件2.html":{"url":"Python/第三方库/PySide/05-常用控件2.html","title":"常用控件2","keywords":"","body":"常用控件2 组合选择框 QComboBox 是组合选择框，如下图所示 信号：选项改变如果用户操作修改了QComboBox中的选项就会发出 currentIndexChanged 信号，可以这样指定处理该信号的函数cbox.currentIndexChanged.connect(handleSelectionChange) 方法：添加一个选项代码中可以使用 addItem 方法来添加一个选项到 末尾 ，参数就是选项文本cbox.addItem('byhy') 方法：添加多个选项代码中可以使用 addItems 方法来添加多个选项到 末尾，参数是包含了多个选项文本的列表cbox.addItems(['byhy','白月黑羽','python教程']) 方法：清空选项代码中可以使用 clear 方法来清空选项，也就是删除选择框内所有的选项cbox.clear() 方法：获取当前选项文本代码中可以使用 currentText 方法来获取当前 选中的选项 的文本，比如method = cbox.currentText() 列表 QListWidget 是列表控件，如下图所示Qt Designer如下图 选择： 方法：添加一个选项代码中可以使用 addItem 方法来添加一个选项到 末尾 ，参数就是选项文本listWidget.addItem('byhy') 方法：添加多个选项代码中可以使用 addItems 方法来添加多个选项到 末尾，参数是包含了多个选项文本的列表listWidget.addItems(['byhy','白月黑羽','python教程']) 方法：删除一个选项代码中可以使用 takeItem 方法来删除1个选项，参数是该选项所在行listWidget.takeItem(1)就会删除第二行选项 方法：清空选项代码中可以使用 clear 方法来清空选项，也就是删除选择框内所有的选项listWidget.clear() 方法：获取当前选项文本currentItem 方法可以得到列表当前选中项对象（QListWidgetItem） ，再调用这个对象的 text 方法，就可以获取文本内容，比如listWidget.currentItem().text()就获取了 第1行，第1列 的单元格里面的文本。listWidget.currentItem().text() 表格 QTableWidget 是表格控件，如下图所示Qt Designer 如下图 选择： 创建列和标题栏 我们可以通过 Qt designer 为一个表格创建列和对应的标题栏。只需要双击 Qt designer 设计的窗体中的 表格控件， 就会出现这样的对话框。 在列标签栏中，点击左下角的加号，就可以为 添加一个列，并且设置标题栏名称。 方法：插入一行、删除一行 insertRow 方法可以在指定位置插入一行，比如table.insertRow(0)就插入一行到第 1 行这个位置， 表格原来第1行（包括原来的第1行）以后的内容，全部往下移动一行。table.insertRow(2)就插入一行到第 3 行这个位置， 表格原来第3行（包括原来的第3行）以后的内容，全部往下移动一行。removeRow 方法可以删除指定位置的一行，比如table.removeRow(0) 就删除第 1 行， 表格原来第1行以后的内容，全部往上移动一行。table.removeRow(2)就删除第 3 行， 表格原来第3行以后的内容，全部往上移动一行。 方法：设置单元格文本内容qt表格的单元格内的内容对象 是一个 单元格对象 QTableWidgetItem 实例 如果单元格 没有被设置过 内容，可以这样 from PySide2.QtWidgets import QTableWidgetItem item = QTableWidgetItem() item.setText('白月黑羽') table.setItem(row, 0, item) 也可以简写为 from PySide2.QtWidgets import QTableWidgetItem table.setItem(row, 0, QTableWidgetItem('白月黑羽')) 如果单元格 已经被设置过 文本内容，item 方法可以获取指定位置的 QTableWidgetItem ，再调用这个对象的 setText 方法，就可以设置单元格文本内容，比如table.item(0,0).setText('白月黑羽-江老师')就设置了 第1行，第1列 的单元格里面的文本。table.item(2,4).setText('白月黑羽-江老师')就设置了 第3行，第5列 的单元格里面的文本。如果希望某个单元格为 只读，不允许修改，可以使用QTableWidgetItem对象的 setFlags 方法，像这样 from PySide2.QtWidgets import QTableWidgetItem from PySide2.QtCore import Qt item = QTableWidgetItem('白月黑羽') item.setFlags(Qt.ItemIsEnabled) # 参数名字段不允许修改 table.setItem(row, 0, item) 如果想文本内容 居中对齐，每个当对应的QTableWidgetItem 调用 setTextAlignment，如下 from PySide2.QtWidgets import QTableWidgetItem from PySide2.QtCore import Qt item = QTableWidgetItem() item.setText('白月黑羽') # 文本居中 item.setTextAlignment(Qt.AlignHCenter) table.setItem(row, 0, item) 方法：获取单元格文本的内容item 方法可以指定位置的单元格对象（QTableWidgetItem） ，再调用这个对象的 text 方法，就可以获取文本内容，比如table.item(0,0).text()就获取了 第1行，第1列 的单元格里面的文本。table.item(2,4).text() 就获取了 第3行，第5列 的单元格里面的文本。 方法：获取所有行数、列数代码中可以使用 rowCount 方法来获取表格所有的 行数 ，比如rowcount = table.rowCount()可以使用 columnCount 方法来获取表格所有的 列数 ，比如rowcount = table.columnCount() 方法：获取当前选中是第几行代码中可以使用 currentRow 方法来获取当前选中是第几行，比如currentrow = table.currentRow()注意：行数是从0开始的， 第一行的行数是 0 方法：设置表格行数、列数代码中可以使用 setRowCount 方法来设置表格 行数 ，比如table.setRowCount(10)代码中可以使用 setColumnCount 方法来设置表格 列数 ，比如table.setColumnCount(10) 方法：清除/删除所有内容clearContents 方法可以清除表格所有的内容，比如table.clearContents()清除后，仍然会留下表格栏如果连表格栏都要删除，可以使用 setRowCount(0)，像这样table.setRowCount(0) 方法：设定列宽、宽度自动缩放Qt Designer 上目前没法拖拽设定 每个列的宽度，只能在代码中指定。如下所示 # 设定第1列的宽度为 180像素 table.setColumnWidth(0, 180) # 设定第2列的宽度为 100像素 table.setColumnWidth(1, 100) 如想让 表格控件宽度 随着父窗口的缩放自动缩放，可以 在 属性编辑器 中 勾选 HorizontalHeaderStretchLastSection或者使用下面代码table.horizontalHeader().setStretchLastSection(True) 信号：单元格内容改动当用户修改了一个单元格的内容，会发出 cellChanged 信号，并且携带参数指明该单元格的行号和列号。 我们的代码可以对该信号进行相应的处理。示例代码如下 def __init__(self): # 指定单元格改动信号处理函数 self.ui.table.cellChanged.connect(self.cfgItemChanged) def cfgItemChanged(self, row, column): # 获取更改内容 cfgName = self.ui.table.item(row, 0).text() # 首列为配置名称 cfgValue = self.ui.table.item(row, column).text() "},"Python/第三方库/PySide/06-常用控件3.html":{"url":"Python/第三方库/PySide/06-常用控件3.html","title":"常用控件3","keywords":"","body":"常用控件3 单选按钮和按钮组 QRadioButton 是单选按钮，如下图所示 说明同一个父窗口 里面的多个单选按钮，只能选中一项。如果你有多组单选按钮， 每组都应该有不同的父控件，或者不同的Layout。通常建议：多组单选按钮，放到不同的 按钮组 QButtonGroup 中 信号：选中状态改变如果用户操作点击了按钮组 QButtonGroup 中的一个按钮， QButtonGroup 就会发出 buttonClicked 信号，可以这样指定处理该信号的函数buttongroup.buttonClicked.connect(handleButtonClicked)然后，在处理函数中调用QButtonGroup对象的 checkedButton() 函数，返回值就是被选中的按钮对象。再调用这个返回的按钮对象的 text() 方法得到界面文本，就可以知道是哪个选项被选中了。 勾选按钮和按钮组 QCheckBox 是勾选按钮，如下图所示 说明通常建议：多组勾选按钮，放到不同的 按钮组 QButtonGroup 中，按钮组就是父控件。可以在 Qt设计师中设置 QButtonGroup 的 exclusive 属性， 来控制 是否 只能单选一个选项。 信号：选中状态改变如果用户操作点击了按钮组 QButtonGroup 中的一个按钮， QButtonGroup 就会发出 buttonClicked 信号，可以这样指定处理该信号的函数buttongroup.buttonClicked.connect(handleButtonClicked)QButtonGroup 设置为 单选 情况下： 在处理函数中调用QButtonGroup对象的 checkedButton() 函数，返回值就是被选中的按钮对象。 再调用这个返回的按钮对象的 text() 方法得到界面文本，就可以知道是哪个选项被选中了。 QButtonGroup 设置为 多选 情况下：要得知哪些按钮被选中， 可以 对所有该组中的 按钮调用 isChecked 方法 ，来判断。 tab页控件 我们可以通过tab页控件把界面分为好几个页面，如下所示通过Qt designer 只需要拖拽控件到各个页面即可。要修改 tab 页的标题，可以先点击该 tab 页，然后在下图所示处修改 tab页中布局Layout 如果要在tab页上布局， 你可能会在对象查看器总直接右键点击该tab，可以你会发现 右键菜单里面没有布局项。 这是 Qt designer 非常坑爹的地方。 首先需要你在tab页上添加一个控件 然后点击 在对象查看器 右键点击上层 TabWidget ，这时，你就会发现有布局菜单了 进度条 QProgressBar 是进度条，如下图所示 说明进度条也是一个常用的控件，当程序需要做一件比较耗费时间的任务（比如统计数据，下载文件等）时，可以用来向用户指示操作的进度。而且有了进度显示，用户就知道应用程序仍在运行，并没有出问题。QProgressBar进度条把每个进度称之为一个step（步骤）。我们可以通过它的 setRange 方法设定步骤个数，比如progressBar.setRange(0,5)就设定了，进度分为5步。然后，通过 setValue 方法，指定当前完成到了哪一步，比如progressBar.setValue(3) 就表示完成了 3/5， 也就是 60%， 进度条就会显示60%的进度。可以使用reset()将进度条倒退到开头。有时候我们的任务没法知道完成了多少，比如下载一个未知大小的文件。这时，可以把 range 范围都设置为0，这样，进度条会显示忙碌指示符，而不是显示进度百分比。下面是一个进度条程序的示例代码 from PySide2.QtWidgets import QApplication, QMainWindow, QPushButton, QProgressBar, QMessageBox from time import sleep from threading import Thread class Stats(): def __init__(self): self.window = QMainWindow() self.window.resize(500, 400) self.window.move(300, 300) self.progressBar = QProgressBar(self.window) self.progressBar.resize(300, 20) self.progressBar.move(80, 30) # 进度是 0 - 5， self.progressBar.setRange(0, 5) self.button = QPushButton('统计', self.window) self.button.move(80, 80) self.button.clicked.connect(self.handleCalc) # 统计进行中标记，不能同时做两个统计 self.ongoing = False def handleCalc(self): def workerThreadFunc(): self.ongoing = True for i in range(1, 6): sleep(1) # 设置进度值 self.progressBar.setValue(i) self.ongoing = False if self.ongoing: QMessageBox.warning( self.window, '警告', '任务进行中，请等待完成') return # 通常任务执行比较耗时，应该在新的线程中进行 # 否则会阻塞主线程显示界面 worker = Thread(target=workerThreadFunc) worker.start() app = QApplication([]) stats = Stats() stats.window.show() app.exec_() 上面的代码，运行时，会有很多告警，因为我们在新线程中操作界面对象，容易出问题。更合理的方法是通过信号，在线程之间传递信息，对界面的操作都在主线程中完成。如下 from PySide2.QtWidgets import QApplication, QMainWindow, QPushButton, QProgressBar, QMessageBox from time import sleep from threading import Thread from PySide2.QtCore import Signal, QObject # 信号库 class SignalStore(QObject): # 定义一种信号 progress_update = Signal(int) # 还可以定义其他作用的信号 # 实例化 so = SignalStore() class Stats(): def __init__(self): # 连接信号到处理的slot函数 so.progress_update.connect(self.setProgress) self.window = QMainWindow() self.window.resize(500, 400) self.window.move(300, 300) self.progressBar = QProgressBar(self.window) self.progressBar.resize(300, 20) self.progressBar.move(80, 30) # 进度是 0 - 5， self.progressBar.setRange(0, 5) self.button = QPushButton('统计', self.window) self.button.move(80, 80) self.button.clicked.connect(self.handleCalc) # 统计进行中标记，不能同时做两个统计 self.ongoing = False def handleCalc(self): def workerThreadFunc(): self.ongoing = True for i in range(1, 6): sleep(1) # 发出信息，通知主线程进行进度处理 so.progress_update.emit(i) self.ongoing = False if self.ongoing: QMessageBox.warning( self.window, '警告', '任务进行中，请等待完成') return worker = Thread(target=workerThreadFunc) worker.start() # 处理进度的slot函数 def setProgress(self, value): self.progressBar.setValue(value) app = QApplication([]) stats = Stats() stats.window.show() app.exec_() 数字输入框 QSpinBox 是数字输入框，可以输入或使用上下箭头选择数字，如下图所示 获取数字通过 value 方法获取编辑框内的文本内容，比如number = box.value()注意：返回的是整数对象，不是字符串 方法：设置数字通过 setValue 方法可以设置提示文本内容，比如box.setValue(100) 日期控件 QDateEdit 类可以用来选择日期时间，如下图所示 获取日期 当用户点击日期时间控件并且选取了 日期和时间，后来程序要获取这个控件里面选定的日期时间，可以使用date方法获取日期对象。如下所示 # 返回 PySide2.QtCore.QDate 对象 qdate = dateEdit.date() # 可以转化为 指定格式的字符串 dateStr = qdate.toString('yyyy-MM-dd') # 也可以获取年月日 对应的数字 ，比如日期是2020年5月2号 year = qdate.year() # 返回 2020 month = qdate.month() # 返回 5 day = qdate.day() # 返回 2 选择文件框 QFileDialog 类可以用来选择文件或者目录，如下图所示 选择目录通过 getExistingDirectory 静态方法 选择目录。该方法，第一个参数是父窗口对象，第二个参数是选择框显示的标题。比如 from PySide2.QtWidgets import QFileDialog filePath = QFileDialog.getExistingDirectory(self.ui, \"选择存储路径\") 返回值即为选择的路径字符串。如果用户点击了 选择框的 取消选择按钮，返回 空字符串。 选择单个文件 如果你想弹出文件选择框，选择一个 已经存在 的文件，可以使用 QFileDialog 静态方法 getOpenFileName ，比如 from PySide2.QtWidgets import QFileDialog filePath, _ = QFileDialog.getOpenFileName( self.ui, # 父窗口对象 \"选择你要上传的图片\", # 标题 r\"d:\\\\data\", # 起始目录 \"图片类型 (*.png *.jpg *.bmp)\" # 选择类型过滤项，过滤内容在括号中 ) 该方法返回值 是一个元组，第一个元素是选择的文件路径，第二个元素是文件类型，如果你只想获取文件路径即可，可以采用上面的代码写法。如果用户点击了 选择框的 取消选择按钮，返回 空字符串。如果你想弹出文件选择框，选择路径和文件名，来 保存一个文件 ，可以使用 QFileDialog 静态方法 getSaveFileName ，比如 from PySide2.QtWidgets import QFileDialog filePath, _ = QFileDialog.getSaveFileName( self.ui, # 父窗口对象 \"保存文件\", # 标题 r\"d:\\\\data\", # 起始目录 \"json类型 (*.json)\" # 选择类型过滤项，过滤内容在括号中 ) 选择多个文件如果要选择多个文件，使用 getOpenFileNames 静态方法 from PySide2.QtWidgets import QFileDialog filePaths, _ = QFileDialog.getOpenFileNames( self.ui, # 父窗口对象 \"选择你要上传的图片\", # 标题 r\"d:\\\\data\", # 起始目录 \"图片类型 (*.png *.jpg *.bmp)\" # 选择类型过滤项，过滤内容在括号中 ) 上例中 filePaths 对应的返回值是一个列表，里面包含了选择的文件。如果用户点击了 选择框的 取消选择按钮，返回 空列表。 "},"Python/第三方库/PySide/07-常用控件4.html":{"url":"Python/第三方库/PySide/07-常用控件4.html","title":"常用控件4","keywords":"","body":"常用控件4 树控件 QTreeWidget 树控件树控件， 是和 QTreeWidgetItem 树节点控件 结合使用的。如下图所示 提示框 QMessageBox 类可以用来弹出各种提示框 该类可以通过一系列静态方法，显示 如下弹出框 错误报告使用 critical 方法 QMessageBox.critical( self.ui, '错误', '请选择爬取数据存储路径！') 警告使用 warning 方法 QMessageBox.warning( self.ui, '阅读太快', '阅读客户协议必须超过1分钟') 信息提示使用 information 方法 QMessageBox.information( self.ui, '操作成功', '请继续下一步操作') 也可以使用 about 方法 QMessageBox.about( self.ui, '操作成功', '请继续下一步操作') 确认继续使用 question 方法 choice = QMessageBox.question( self.ui, '确认', '确定要删除本文件吗？') if choice == QMessageBox.Yes: print('你选择了yes') if choice == QMessageBox.No: print('你选择了no') 输入对话框 QInputDialog 输入对话框 只让用户输入一行数据信息，比如 姓名、年龄等。可以方便的用来获取简单的信息。比如 from PySide2.QtWidgets import QInputDialog, QLineEdit # 返回值分别是输入数据 和 是否点击了 OK 按钮（True/False） title, okPressed = QInputDialog.getText( self, \"输入目录名称\", \"名称:\", QLineEdit.Normal, \"\") if not okPressed: print('你取消了输入') 常用的方法有： getText弹出对话框，让用户输入 单行文本 getMultiLineText弹出对话框，让用户输入 多行文本 getInt弹出对话框，让用户输入 整数 getItem弹出对话框，让用户选择 选项 items = [\"春天\", \"夏天\", \"秋天\", \"冬天\"] item, ok = QInputDialog().getItem(self, \"请选择\", \"季节:\", items, 0, False) if ok and not item.isEmpty(): itemLabel.setText(item) 菜单 可以在 Qt Designer上很方便的添加菜单，如下所示点击菜单的信号是 triggered， 处理点击菜单的的代码如下self.ui.actionOpenFile.triggered.connect(self.openPageFile)注意：如果菜单和工具栏有 相同的 action ，通常是先在 动作编辑器 创建一个action， 然后分别拖动到 菜单和工具栏 工具栏 在 Qt 设计师上添加工具栏，可以右键点击 Main Window 类型的窗体空白处，如下所示选择添加工具栏注意，只有 Main Window 类型的窗体，才能添加工具栏，如下添加工具栏后，还要在工具栏上添加图标。 方法是点击右下角 动作编辑器，新建动作，如下图所示然后如下图所示进行设置添加动作成功后，就可以直接拖到工具栏上了。然后，在代码中定义动作触发后的处理函数，如下所示 self.ui.actionAddNote.triggered.connect(self.actionAddNode) 状态栏 要在状态栏显示文本信息，只需要调用 QStatusBar 的 showMessage 方法self.ui.statusbar.showMessage(f'打开文件{filePath}') 剪贴板 Qt程序可以获取和设置剪贴板内容 from PySide2.QtGui import QGuiApplication cb = QGuiApplication.clipboard() # 获取剪贴板内容 originalText = cb.text() # 设置剪贴板内容 clipboard.setText(newText) MDI 多个子窗口 QMdiArea 提供了一个主窗口区，里面可以存放多个 QMdiSubWindow 子窗口如图： "},"Python/第三方库/OpenCV/01-图像基本操作.html":{"url":"Python/第三方库/OpenCV/01-图像基本操作.html","title":"图像基本操作","keywords":"","body":"datetime:2022/04/11 15:07 author:nzb 图像基本操作 数据读取 图像 读取图像使用imread()函数 img = cv2.imread(\"test.jpg\") opencv读取的格式是：BGR img.shape：获得图像的大小，返回的元组（tuple）中的三个数依次表示高度、宽度和通道数（蓝通道、绿通道、红通道）。 img.dtype：获得图片的类型。uint8是一个 8 位无符号整数。图像的RGB分量通常用 0 到 255 的 256 个灰度表示。例如，红色像素为 (R,G,B)=(255,0,0) ，白色是 (R,G,B)=( 255,255,255) 。如果图像不以这个类型保存的话，图像会变得很奇怪。 cv2.imshow()：来显示图像。cv2.imshow()的第一个参数是窗口的名字（不写也没有关系），第二个参数是要显示的图像的名称，一定要写。 cv2.imshow('image', img) cv2.waitKey(0) cv2.destroyAllWindows() img.astype(np.float32)：让img的类型变更为float32的话，可以使用astype()。 如果用这种类型显示图片，就会变成得很奇怪。所以当你想要操作图像时： 使用cv2.imread读取图像； 将图像的类型变为浮点型np.float32； 操作图像； 像素值不满 0 的将值设置为 0 ，像素值超过 255 的将值设置为 255 （超重要）； img = np.clip（img, 0 , 255） 或者 img.clip（0，255） 将图像类型变更为np.uint8并保存； astype(np.uint8) img2 = img.copy()：拷贝图像 cv2.imwrite()：保存图像 cv2.imwrite(\"sample.jpg\", img2)：例如之前的被保存为名称为的图像，如果返回值为的话，这就说明该图像被保存在同一个文件夹中，文件名为。 视频 cv2.VideoCapture可以捕获摄像头，用数字来控制不同的设备，例如0,1。 vc = cv2.VideoCapture(\"../img/test.mp4\") 如果是视频文件，直接指定好路径即可。 操作像素 例如，操作 x=30,y=20 的像素值时，进行以下的操作。像素值是按 BGR 的顺序排列的。array() 表示这个图像是 NumPy 格式。也就是说，OpenCV 是 NumPy 的高层封装。 img[20,30] 更进一步，要得到 x=30,y=20 处的 G 分量，可以使用以下代码 img[20,30,1] 切片 例如要查看 y=20, x=[30, 32] 这个范围之内（的像素）时，如果设置为30:33可以得到一个矩阵。如果设置a:b，可以获得在 a img[20, 30:33] 例如将图片左上角（ x=[0, 50], y = [0, 50] ）设置为黑色，是照下面这样做。copy()这个函数在后面介绍。 img2[:50, :50] = 0 获取颜色通道 b,g,r = cv2.split(img) 合并颜色通道 cv2.merge((b,g,r)) # 合并 之前有提到：像素的值小于 0 的时候设置为 0，超过 255 的时候修改为 255。 例如，图像的类型为float32，将一部分的B分量改为 260。uint8类型的整数范围只能取 [0,255] ，如果变成uint8型的话蝾螈的颜色一部分就会变成黄色的。 这是因为，如果将 260 变为uint8型的话，因为 260-256，所以会让B的值为 4。经常会由于这个原因让像素的值变得不正确。所以上面的第四步的操作（限定值的范围在[0,255]之间）是必要的。 边界填充 cv2.copyMakeBorder（） 选项 BORDER_REPLICATE：复制法，也就是复制最边缘像素。 BORDER_REFLECT：反射法，对感兴趣的图像中的像素在两边进行复制 例如：fedcba|abcdefgh|hgfedcb BORDER_REFLECT_101：反射法，也就是以最边缘像素为轴，对称 gfedcb|abcdefgh|gfedcba BORDER_WRAP：外包装法 cdefgh|abcdefgh|abcdefg BORDER_CONSTANT：常量法，常数值填充。 图像缩放 cv2.resize(src， dsize[， dst[， fx[， fy[，interpolation]]]]) 选项 src：必须，原图像 dsize：必须，输出图像所需大小 fx：可选，沿水平轴的比例因子 fy：可选，沿垂直轴的比例因子 interpolation：可选，插值方式 通常的，缩小使用cv.INTER_AREA，放缩使用cv.INTER_CUBIC(较慢)和cv.INTER_LINEAR(较快效果也不错)。默认情况下，所有的放缩都使用cv.INTER_LINEAR。 cv2.INTER_NEAREST：最近邻插值 cv2.INTER_LINEAR：双线性插值 cv2.INTER_CUBIC：双线性插值 cv2.INTER_AREA：使用像素区域关系重新采样。它可能是图像抽取的首选方法，因为它可以提供无莫尔条纹的结果。但是当图像被缩放时，它类似于INTER_NEAREST方法。 示例 cv2.resize（img，（0，0），fx=5，fy=5）：按不同比例缩放 cv2.resize（img，（400，500））：缩放成高400，宽500的大小 图像融合 两张图片维度需要一样 cv2.addWeighted() cv2.addWeighted（img_cat， 0.4，img_dog， 0.6，0） R = αx + βy + b；其中α和β是对应的权重，哪个值大就更明显，b是亮度级上提亮 图片拼接展示 需要注意的是图片维度需要一样 水平拼接 res = np.hstack((blur1,gussian,median)) # 水平拼接 cv2.imshow('median vs gussian vs median', res) cv2.waitKey(0) cv2.destroyAllWindows() 垂直拼接 res = np.vstack((blur1,gussian,median)) # 水平拼接 x, y, w, h作为参数的时候获取图像 操作像素：img [ y ：y + h， x：x + w ] 作为参数传递函数时：（x，y）或者（x + w，y + h） "},"Python/第三方库/OpenCV/02-图像处理.html":{"url":"Python/第三方库/OpenCV/02-图像处理.html","title":"图像处理","keywords":"","body":"datetime:2022/04/11 15:07 author:nzb 图像处理 灰度图 灰度是一种图像亮度的表示方法 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY ) 二值化（图像阈值） ret, dst = cv2.threshold(src, thresh, maxval, type) 简单二值化 src： 输入图，只能输入单通道图像，通常来说为灰度图 dst： 输出图 thresh（ret）： 阈值 maxval： 当像素值超过了阈值（或者小于阈值，根据type来决定），所赋予的值 最大：255 type：二值化操作的类型，包含以下5种类型 cv2.THRESH_BINARY：超过阈值部分取maxval（最大值），否则取0 cv2.THRESH_BINARY_INV：THRESH_BINARY的反转 cv2.THRESH_TRUNC：大于阈值部分设为阈值，否则不变 cv2.THRESH_TOZERO：大于阈值部分不改变，否则设为0 cv2.THRESH_TOZERO_INV：THRESH_TOZERO的反转 ret2,dst2= cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) Otsu （大津）二值化：找到最合适的阈值，其中threshold设置为0配合cv2.THRESH_OTSU，寻找最适合的阈值 示例 HSV变换 HSV即使用：色相（Hue）、饱和度（Saturation）、明度（Value）来表示色彩的一种方式。 色相：将颜色使用0∘到360∘表示，就是平常所说的颜色名称，如红色、蓝色。 饱和度：是指色彩的纯度，饱和度越低则颜色越黯淡（0≤S 明度：即颜色的明暗程度。数值越高越接近白色，数值越低越接近黑色（0≤V hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) 图像滤波 图像降噪，使图像更清晰，更平滑 均值滤波 blur1 = cv2.blur(noise_img, (3,3)) 3 * 3的卷积核 方框滤波 基本和均值一样，可以选择归一化 归一化 计算均值滤波 blur2 = cv2.boxFilter(noise_img,-1, (3,3), normalize=True) -1是固定值，一般不需要改变 未归一化 容易越界（未取均值，超过255，一旦越界就取255） blur3 = cv2.boxFilter(noise_img,-1, (3,3), normalize=False) 高斯滤波 更看重权重，离目标远的权重小，离目标近的权重大 gussian = cv2.GaussianBlur(noise_img, (5, 5), 1) 5*5的卷积核 中值滤波 median = cv2.medianBlur(noise_img, 5) 5*5的卷积核 形态学处理 处理二值化图像，获取轮廓 腐蚀=瘦身，膨胀=增 腐蚀（Erode） kernel = np.ones((3,3), dtype=np.uint8) 核 erode_img = cv2.erode(img, kernel, iterations=1) iterations：迭代（腐蚀）次数 不同腐蚀次数的变化 膨胀（Dilate） kernel = np.ones((3,3), dtype=np.uint8) 核 dilate_img = cv2.dilate(erosion, kernel, iterations=1) 不同膨胀次数的变化 开运算与闭运算 open_close_kernel = np.ones((5,5), np.uint8) 开运算：先腐蚀，后膨胀 开运算可以用来去除仅存的小块像素。 openimg = cv2.morphologyEx(img, cv2.MORPH_OPEN, open_close_kernel) 闭运算：先膨胀，后腐蚀 closeimg = cv2.morphologyEx(img, cv2.MORPH_CLOSE, open_close_kernel) 梯度运算 kernel = np.ones((7,7), np.uint8) 梯度 = 膨胀 - 腐蚀 形态学梯度为经过膨胀操作（dilate）的图像与经过腐蚀操作（erode）的图像的差，可以用于抽出物体的边缘。 gradient = cv2.morphologyEx(pie, cv2.MORPH_GRADIENT, kernel) 顶帽和黑帽 kernel = np.ones((7,7), np.uint8) 顶帽 顶帽 = 原始输入 - 开运算 tophat = cv2.morphologyEx(img1, cv2.MORPH_TOPHAT, kernel) 黑帽 黑帽 = 闭运算 - 原始输入 blackhat = cv2.morphologyEx(img1, cv2.MORPH_BLACKHAT, kernel) 角点检测（图像梯度，边缘检测步骤） Sobel算子 卷积核 dst = cv2.Sobel(src, ddepth, dx, dy, ksize) dx=0，dy=1，只计算垂直方向dx=1，dy=0，只计算水平方向dx=1，dy=1，直接计算（不建议，效果不好，建议分开计算再） ddepth：图像的深度 dx和dy：分别表示水平和竖直方向 ksize：是Sobel算子的大小（核大小） sobel = cv2.convertScaleAbs(sobel) 白到黑是正数，黑到白就是负数了，所有的负数会被截断成0，所以要取绝对值 sobelxy = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0) 分别计算x和y，再求和 0.5：为权重 示例 代码 lena = cv2.imread(\"../img/lena.jpg\", cv2.IMREAD_GRAYSCALE) # 分开计算 sobelx = cv2.Sobel(lena, cv2.CV_64F, 1, 0, ksize=3) sobelx = cv2.convertScaleAbs(sobelx) sobely = cv2.Sobel(lena, cv2.CV_64F, 0, 1, ksize=3) sobely = cv2.convertScaleAbs(sobely) sobelxy1 = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0) # 直接计算 sobelxy2 = cv2.Sobel(lena, cv2.CV_64F, 1, 1, ksize=3) sobelxy2 = cv2.convertScaleAbs(sobelxy2) show_img([lena, sobelxy1, sobelxy2], hstack=True) Scharr算子 更敏感 卷积核 dst = cv2.Scharr(src, ddepth, dx, dy) 示例 代码 scharrx = cv2.Scharr(lena, cv2.CV_64F, 1, 0) scharry = cv2.Scharr(lena, cv2.CV_64F, 0, 1) scharrx = cv2.convertScaleAbs(scharrx) scharry = cv2.convertScaleAbs(scharry) scharrxy = cv2.addWeighted(scharrx, 0.5, scharry, 0.5, 0) Laplacian算子 二阶导，反应一阶导的变化率，所以对变化更敏感（对噪音点敏感，如果有噪音点就不好检测了） 卷积核 dst = cv2.Laplacian(src, ddepth) 示例 代码 laplacian = cv2.Laplacian(lena, cv2.CV_64F) laplacian = cv2.convertScaleAbs(laplacian) 三者对比 代码 lena = cv2.imread(\"../img/lena.jpg\", cv2.IMREAD_GRAYSCALE) # 分开计算 sobelx = cv2.Sobel(lena, cv2.CV_64F, 1, 0, ksize=3) sobelx = cv2.convertScaleAbs(sobelx) sobely = cv2.Sobel(lena, cv2.CV_64F, 0, 1, ksize=3) sobely = cv2.convertScaleAbs(sobely) sobelxy1 = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0) # Scharr算子 scharrx = cv2.Scharr(lena, cv2.CV_64F, 1, 0) scharry = cv2.Scharr(lena, cv2.CV_64F, 0,1) scharrx = cv2.convertScaleAbs(scharrx) scharry = cv2.convertScaleAbs(scharry) scharrxy = cv2.addWeighted(scharrx, 0.5, scharry, 0.5, 0) # Laplacian算子 laplacian = cv2.Laplacian(lena, cv2.CV_64F) laplacian = cv2.convertScaleAbs(laplacian) show_img([lena, sobelxy1, scharrxy, laplacian], hstack=True) Canny边缘检测 1、 使用高斯滤波器，以平滑图像，滤除噪声。 高斯滤波器 2、 计算图像中每个像素点的梯度强度和方向。 在x方向和y方向上使用Sobel滤波器，在此之上求出边缘的强度和边缘的梯度 梯度和方向 3、 应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。 非极大值抑制 4、 应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。 双阈值检测 5、 通过抑制孤立的弱边缘最终完成边缘检测。 示例 代码 img=cv2.imread(\"lena.jpg\",cv2.IMREAD_GRAYSCALE) v1=cv2.Canny(img,80,150) v2=cv2.Canny(img,50,100) # 80和150：minVal和maxVal res = np.hstack((v1,v2)) cv_show(res,'res') 图像金字塔 高斯金字塔 高斯金字塔：向下采样方法（缩小） 高斯金字塔：向上采样方法（放大） 示例 代码 AM = cv2.imread(\"../img/AM.png\") up = cv2.pyrUp(AM) down = cv2.pyrDown(AM) show_img([AM,up,down]) 展示 原图 向上 向下 拉普拉斯金字塔 Gi：原图 示例 代码 down = cv2.pyrDown(AM) down_up = cv2.pyrUp(down) ret = AM - down_up show_img([AM,ret], hstack=True) 图像轮廓 contours, hierarchy = cv2.findContours(img,mode,method) 为了更高的准确率，使用二值图像。 contours：轮廓信息（用得较多的数据） hierarchy：层级 mode：轮廓检索模式 RETR_EXTERNAL ：只检索最外面的轮廓； RETR_LIST：检索所有的轮廓，并将其保存到一条链表当中； RETR_CCOMP：检索所有的轮廓，并将他们组织为两层：顶层是各部分的外部边界，第二层是空洞的边界; RETR_TREE：检索所有的轮廓，并重构嵌套轮廓的整个层次; 常用 method：轮廓逼近方法 CHAIN_APPROX_NONE：以Freeman链码的方式输出轮廓，所有其他方法输出多边形（顶点的序列）。 常用 CHAIN_APPROX_SIMPLE:压缩水平的、垂直的和斜的部分，也就是，函数只保留他们的终点部分。 示例 代码# 为了更高的准确率，使用二值图像。 img = cv2.imread(\"../img/car.png\") gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) show_img([img, thresh]) 绘制轮廓 res = cv2.drawContours(copy_img, contours, -1, (0,0,255), 2) 传入绘制图像， 轮廓， 轮廓索引， 颜色模式， 线条厚度 -1：所有的轮廓都画出来，0：对应的第0个轮廓，1：对应的第1个轮廓 （0,0,255）：对应：B,G,R，轮廓的颜色（这里是红色） 2：线条宽度 示例 代码 # 注意需要copy,要不原图会变 copy_img = img.copy() res = cv2.drawContours(copy_img, contours, -1, (0,0,255), 2) show_img([img, res]) 轮廓特征 # 第一个轮廓 cnt = contours[0] # 面积 area = cv2.contourArea(cnt) # 周长，True：表示闭合的 perimeter = cv2.arcLength(cnt, True) print(\"面积：\",area) print(\"周长：\", perimeter) 轮廓近似 示例 代码 img = cv2.imread(\"../img/contours2.png\") gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, 127,255, cv2.THRESH_BINARY) contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) cnt = contours[0] # 绘制轮廓 draw_img = img.copy() res1 = cv2.drawContours(draw_img, [cnt], -1, (0, 0, 255), 2) # 轮廓近似 epsilon = 0.1 * cv2.arcLength(cnt, True) # 按周长比例 approx = cv2.approxPolyDP(cnt, epsilon, True) # 近似 draw_img = img.copy() res2 = cv2.drawContours(draw_img, [approx], -1, (0, 0, 255), 2) show_img([img, res1,res2], hstack=True) 边界矩形 示例 代码 img = cv2.imread(\"../img/contours.png\") gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, 127,255, cv2.THRESH_BINARY) contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) cnt = contours[0] # 0：第0个轮廓也就是这里的三角形的外接矩形（外轮廓）; 1：内轮廓（内接矩形）..... x,y,w,h = cv2.boundingRect(cnt) img = cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,255), 2) show_img([img]) 应用 计算面积比 area = cv2.contourArea(cnt) x, y, w, h = cv2.boundingRect(cnt) rect_area = w * h extent = float(area) / rect_area print ('轮廓面积与边界矩形比',extent) 外接圆 示例 代码 (x,y),radius = cv2.minEnclosingCircle(cnt) center = (int(x),int(y)) radius = int(radius) img =cv2.circle(img,center,radius,(0,255,0),2) show_img([img]) 图像模板匹配 * 模板匹配和卷积原理很像，模板在原图像上从原点开始滑动，计算模板与（图像被模板覆盖的地方）的差别程度，这个差别程度的计算方法在opencv里有6种，然后将每次计算的结果放入一个矩阵里，作为结果输出。假如原图形是AxB大小，而模板是axb大小，则输出结果的矩阵是( A-a+1)x(B-b+1) res = cv2.matchTemplate(img, template, cv2.TM_SQDIFF) 推荐使用包含归一化的 TM_SQDIFF：计算平方不同，计算出来的值越小，越相关 TM_CCORR：计算相关性，计算出来的值越大，越相关 TM_CCOEFF：计算相关系数，计算出来的值越大，越相关 TM_SQDIFF_NORMED：计算归一化平方不同，计算出来的值越接近0，越相关 TM_CCORR_NORMED：计算归一化相关性，计算出来的值越接近1，越相关 TM_CCOEFF_NORMED：计算归一化相关系数，计算出来的值越接近1，越相关 公式 min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res) 最小值，最大值，最小值位置，最大值位置 示例 代码 img = cv2.imread('../img/lena.jpg', 0) template = cv2.imread('../img/face.jpg',0) h,w = template.shape[:2] methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR', 'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED'] # 模板匹配 res = cv2.matchTemplate(img, template, cv2.TM_SQDIFF) # 最小值，最大值，最小值位置，最大值位置 min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res) # 绘图比较 for meth in methods: img2 = img.copy() # 匹配方法的真值 method = eval(meth) # 不能是字符串 res = cv2.matchTemplate(img, template, method) min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res) # 如果是平方差匹配TM_SQDIFF或归一化平方差匹配TM_SQDIFF_NORMED，取最小值 if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]: top_left = min_loc else: top_left = max_loc bottom_right = (top_left[0] + w, top_left[1] + h) # 画矩形 cv2.rectangle(img2, top_left, bottom_right, 255, 2) plt.subplot(121), plt.imshow(res, cmap='gray') plt.xticks([]), plt.yticks([]) # 隐藏坐标轴 plt.subplot(122), plt.imshow(img2, cmap='gray') plt.xticks([]), plt.yticks([]) plt.suptitle(meth) plt.show() 展示 模板 匹配多个对象 代码 img_rgb = cv2.imread('../img/mario.jpg') img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY) template = cv2.imread('../img/mario_coin.jpg', 0) h, w = template.shape[:2] res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED) threshold = 0.8 # 取匹配程度大于%80的坐标 loc = np.where(res >= threshold) # *号表示可选参数 for pt in zip(*loc[::-1]): bottom_right = (pt[0] + w, pt[1] + h) cv2.rectangle(img_rgb, pt, bottom_right, (0, 0, 255), 2) show_img([template, img_rgb]) "},"Python/第三方库/PyInstaller/01-pyInstaller打包基础.html":{"url":"Python/第三方库/PyInstaller/01-pyInstaller打包基础.html","title":"pyInstaller打包基础","keywords":"","body":"datetime:2022/04/16 17:10 author:nzb pyinstaller 官方文档 常用参数 -F, –onefile：打包一个单个文件，如果你的代码都写在一个.py文件的话，可以用这个，如果是多个.py文件就别用 -D, –onedir：打包多个文件，在dist中生成很多依赖文件，适合以框架形式编写工具代码，我个人比较推荐这样，代码易于维护 -K, –tk：在部署时包含 TCL/TK -a, –ascii：不包含编码.在支持Unicode的python版本上默认包含所有的编码. -d, –debug：产生debug版本的可执行文件 -w,–windowed,–noconsole：使用Windows子系统执行.当程序启动的时候不会打开命令行(只对Windows有效) -c,–nowindowed,–console：使用控制台子系统执行(默认)(只对Windows有效) pyinstaller -c xxxx.py - pyinstaller xxxx.py --console -s,–strip： 可执行文件和共享库将run through strip.注意Cygwin的strip往往使普通的win32 Dll无法使用. -X, –upx：如果有UPX安装(执行Configure.py时检测),会压缩执行文件(Windows系统中的DLL也会)(参见note) -o DIR, –out=DIR：指定spec文件的生成目录,如果没有指定,而且当前目录是PyInstaller的根目录,会自动创建一个用于输出(spec和生成的可执行文件) 的目录.如果没有指定,而当前目录不是PyInstaller的根目录,则会输出到当前的目录下. -p DIR, –path=DIR：设置导入路径(和使用PYTHONPATH效果相似).可以用路径分割符(Windows使用分号,Linux使用冒号) 分割,指定多个目录.也可以使用多个-p参数来设置多个导入路径，让pyinstaller自己去找程序需要的资源 –icon=：将file.ico添加为可执行文件的资源(只对Windows系统有效)，改变程序的图标 pyinstaller -i ico路径 xxxxx.py –icon=：将file.exe的第n个图标添加为可执行文件的资源(只对Windows系统有效) -v FILE, –version=FILE：将verfile作为可执行文件的版本资源(只对Windows系统有效) -n NAME, –name=NAME：可选的项目(产生的spec的)名字.如果省略,第一个脚本的主文件名将作为spec的名字 通用参数 参数名 描述 说明 -h, --help 显示帮助 无 -v, --version 显示版本号 无 –-distpath DIR 生成文件放在哪里 默认：当前目录的dist文件夹内 --workpath WORKPATH 生成过程中的中间文件放在哪里 默认：当前目录的build文件夹内 -y, --noconfirm 如果dist文件夹内已经存在生成文件，则不询问用户，直接覆盖 默认：询问是否覆盖 --upx-dir UPX_DIR UPX_DIR 指定upx工具的目录 默认：execution path -a, --ascii 不包含unicode支持 默认：尽可能支持unicode –-clean 在本次编译开始时，清空上一次编译生成的各种文件 默认：不清除 --log-level LEVEL 控制编译时pyi打印的信息 一共有5个等级，由低到高分别为TRACE DEBUG INFO(默认) WARN ERROR CRITICAL。 默认INFO，不打印TRACE和DEBUG信息 与生成结果有关的参数 参数名 描述 说明 -D, --onedir 生成one-folder的程序（默认） 生成结果是一个目录，各种第三方依赖、资源和exe同时存储在该目录 -F, --onefile 生成one-file的程序 生成结果是一个exe文件，所有的第三方依赖、资源和代码均被打包进该exe内 --specpath DIR 指定.spec文件的存储路径 默认：当前目录 -n NAME, --name NAME 生成的.exe文件和.spec的文件名 默认：用户脚本的名称，即main.py和main.spec 指定打包哪些资源、代码 参数名 描述 说明 --add-data 打包额外资源 用法：pyinstaller main.py –add-data=src;dest windows以;分割，linux以:分割，可多次使用 --add-binary 打包额外的代码 用法：同–add-data。与–add-data不同的是，用binary添加的文件，pyi会分析它引用的文件并把它们一同添加进来 -p DIR, --paths DIR 指定额外的import路径，类似于使用PYTHONPATH 参见PYTHONPATH --hidden-import MODULENAME, --hiddenimport MODULENAME 打包额外py库pyi在分析过程中，有些import没有正确分析出来，运行时会报import error，这时可以使用该参数 --additional-hooks-dir HOOKSPATH 指定用户的hook目录 hook用法参见其他，系统hook在PyInstaller\\hooks目录下 --runtime-hook RUNTIME_HOOKS 指定用户runtime-hook 如果设置了此参数，则runtime-hook会在运行main.py之前被运行 --exclude-module EXCLUDES 需要排除的module pyi会分析出很多相互关联的库，但是某些库对用户来说是没用的，可以用这个参数排除这些库，有助于减少生成文件的大小 --key KEY pyi会存储字节码，指定加密字节码的key 16位的字符串 为什么要使用 --add-data？程序里文件格式有很多种： 源代码 .py 图片格式 .png .jpg .ico 等 配置文件 .ini .json .xml等 其他可执行文件 .bin .exe等 模型文件 .pth 等 说明文档 .txt .md等 注意： 除了.py之外，其他格式不会编译。 除了.py之外，其他格式若要打包进去，需要使用 --add-data 处理，或者手动拷贝(嫌麻烦，你每次都能记住？) 如何使用 --add-data? 用法：pyinstaller x.py --add-data=\"源地址;目标地址\"。 windows以;分割，linux以:分割 例如：将 config 目录的所有文件打包到目标的 config 文件夹（不存在会自动创建）下 pyinstaller x.py --add-data \".\\\\config\\\\*;.\\\\config\" 可使用多次 --add-data pyinstaller x.py -n Demo2.0.3 --key !@)v -i \"res\\logo.ico\" --add-data=\".\\*.txt;.\" --add-data=\".\\*.json;.\" --add-data=\"res\\*.*;.\\res\" --add-data=\"dist\\models\\*.*;.\\models\" 生成参数 参数名 描述 说明 -d, --debug 执行生成的main.exe时，会输出pyi的一些log，有助于查错 默认：不输出pyi的log -s, --strip 优化符号表 原文明确表示不建议在windows上使用 --noupx 强制不使用upx 默认：尽可能使用。 其他 参数名 描述 说明 --runtime-tmpdir PATH 指定运行时的临时目录 默认：使用系统临时目录 Windows和Mac特有的参数 参数名 描述 说明 -c, --console, --nowindowed 显示命令行窗口，与-w相反 默认含有此参数 -w, --windowed, --noconsole 不显示命令行窗口 编写GUI程序时使用此参数有用。 -i , --icon 为main.exe指定图标 pyinstaller -i beauty.ico main.py Windows特有的参数 参数名 描述 说明 --version-file FILE 添加版本信息文件 pyinstaller –version-file ver.txt -m , --manifest 添加manifest文件 pyinstaller -m main.manifest -r RESOURCE, --resource RESOURCE 请参考原文 --uac-admin 请参考原文 --uac-uiaccess 请参考原文 .spec文件打包 生成 .spec 文件：pyinstaller -F xxx.py 编写 .spec 内容 打包：pyinstaller xxx.py # -*- mode: python ; coding: utf-8 -*- block_cipher = None a = Analysis( ['run.py'], # 此列表存放项目设计的所有Python脚本文件 pathex=[\"/upper_computer/src/upper_computer_ui/script/qs_apis\"], # 此列表为项目的绝对路径 binaries=[], datas=[('./dist/*', './dist')], hiddenimports=['redis', 'paramiko', 'aioredis', 'gevent', 'requests', 'zmq', 'run'], # fastapi的打包示例，run 也要加进来，否则启动不了 hookspath=[], hooksconfig={}, runtime_hooks=[], excludes=[], win_no_prefer_redirects=False, win_private_assemblies=False, cipher=block_cipher, noarchive=False, ) pyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher) exe = EXE( pyz, a.scripts, a.binaries, a.zipfiles, a.datas, [], name='run', # 打包程序的名字 debug=False, bootloader_ignore_signals=False, strip=False, upx=True, upx_exclude=[], runtime_tmpdir=None, console=True, # 程序运行时是否打开控制台 disable_windowed_traceback=False, argv_emulation=False, target_arch=None, codesign_identity=None, entitlements_file=None, ) 常见打包错误及解决办法 1、在用pyinstaller打包（-F 选项），如果用到的第三方库含有data文件，而pyinstaller又没有自带该第三方库文件的hook的时候，执行打包后的exe一般会报以下错误 友情链接 FileNotFoundError: [Errno 2] No such file or directory: ‘C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\_MEI54762\\jieba\\dict.txt’ [20784] Failed to execute script bat_server 上面就是没把python库jieba的dict.txt打包进来，导致了错误。 那么，解决问题也很简单，自己写个hook，然后放进pyinstaller的hooks里面即可。 hook文件的命名规范为: hook-【库名】.py，以结巴分词为例，即为hook-jieba.py，然后简单敲入以下两行： from PyInstaller.utils.hooks import copy_metadata, collect_data_files datas = copy_metadata('jieba') # 解决 `pkg_resources` 错误 datas.extend(collect_data_files(\"jieba\")) # 解决静态文件不存在错误 接下来，找到pyinstaller的hooks文件夹，大概位于： python根目录\\Lib\\site-packages\\PyInstaller\\hooks下，然后把hook-jieba.py丢进去 注意是\\Lib\\site-packages\\PyInstaller\\hooks 不是 \\Lib\\site-packages\\PyInstaller\\utils\\hooks 或者可以使用参数 --additional-hooks-dir HOOKSPATH 指定用户自定义的 hook 文件夹目录 最后，回到项目根目录，用pyinstaller打包即可。（注意需要把build目录删了，使pyinstaller从头开始打包） 当看到pyinstaller的日志里使用了我们自定义的hook后，就万事大吉了。 ok 打包tushare 或 akshare 的时候也有类似问题，下次可以直接用此法解决。 "},"Python/第三方库/ZeroMQ/01-zmq基础.html":{"url":"Python/第三方库/ZeroMQ/01-zmq基础.html","title":"zmq基础","keywords":"","body":"ZeroMQ 1、zmq套接字 创建和销毁套接字：zmq.socket(), zmq.close() 配置和读取套接字：zmq.setsockopt(), zmq.getsockopt() 为套接字建立连接：zmq.bind(), zmq.connect() 发送和接收消息： zmq.send(), zmq.recv() 注： 使用zmq.bind()连接的节点称之为服务端，它有着一个较为固定的网络地址； 使用zmq.connect()连接的节点称为客户端，其地址不固定。 2、zmq消息模式 主要有三种常用模式 req/rep(请求答复模式)：主要用于远程调用及任务分配等。 pub/sub(订阅模式)： 主要用于数据分发。 push/pull(管道模式)： 主要用于多任务并行。 3、zmq内置的有效绑定对 PUB and SUB REQ and REP REQ and XREP XREQ and REP XREQ and XREP XREQ and XREQ XREP and XREP PUSH and PULL PAIR and PAIR 4、具体消息模式举例 (1)、req/rep(请求/答复模式) 一对一模式，一问一答 server服务端 import zmq context = zmq.Context(io_threads=5) # 5个线程 socket = context.socket(zmq.REP) # 设置socket的类型，zmq.REP答复 socket.bind(\"tcp://*:15000\") # 绑定服务端的IP和端口 while True: # 循环接收客户端发来的消息 message = socket.recv() # 接收客户端发送来的消息，注：是byte类型 print(message) socket.send_string(\"copy!\") # 再发回客户端消息 # 结果：客户单每请求一次就打印一次消息体 # b'request' # b'request' # b'request' # b'request' client客户端 import zmq, sys, threading context = zmq.Context() socket = context.socket(zmq.REQ) # 设置socket类型，请求端 socket.connect(\"tcp://localhost:15000\") #连接服务端的IP和端口 socket.connect(\"tcp://127.0.0.1:15000\") lock = threading.Lock() while True: data = input(\"input your request:\") if data == \"q\": sys.exit() # 客户端如果一个进程有多线程使用，需要使用锁，保证send和recv配对使用，否则会报错 with lock: socket.send_string(data) # 向服务端发送消息 message=socket.recv() #接收服务端返回的消息，注：是byte类型 print(message) recv_msg = socket.recv_string() print(f\"recv msg: {recv_msg}\") \"\"\" 结果：每输入请求一次，就得到服务端的一次返回 input your data:123 b'copy!' input your data:456 b'copy!' \"\"\" send()、recv()扩展 发送 接收 发送数据结构 返回数据结构 说明 send() recv() bytes, Frame, memoryview bytes, Frame, memoryview - send_string() recv_string() str str - send_pyobj() recv_pyobj() Python object Python object - send_json() recv_json() Python object List, str, int, float, Dict - send_serialized() recv_serialized() The message to be sent. Can be any object serializable by serialize. 自定义反序列化函数 自定义序列化函数 注意：zmq.error.ZMQError: Operation cannot be accomplished in current state zmq模式为zmq.REP。在这种模式下，我们的程序必须要遵守recv()和send()配对使用的编程模式。 也就是说，在服务程序中，必须要有完整的recv()和send()成对出现。同理，在客户端程序中，send()后，也要有recv()。 (2)、pub/sub(订阅模式) 一对多模式 一个发布者，多个订阅者，订阅者可以通过设置过滤器过滤数据。 Publisher发布者 import zmq context = zmq.Context() socket = context.socket(zmq.PUB) socket.bind(\"tcp://*:15000\") while True: data = input(\"input your data:\") print(data) socket.send_string(data) \"\"\" 结果：循环提示输入数据，当输入一次，就发送一次到订阅者 input your data:123 123 input your data:456 456 input your data:789 789 input your data: \"\"\" Subscriber订阅者 import sys import zmq context = zmq.Context() socket = context.socket(zmq.SUB) socket.connect(\"tcp://localhost:15000\") socket.setsockopt_string(zmq.SUBSCRIBE, '') # 或者： socket.setsockopt_string(zmq.SUBSCRIBE, '123') # 表示只过滤出收到消息为'123'的消息 # 或者： socket.subscribe('topic') # 订阅一个主题, 表示只过滤出收到消息为'topic'的消息 while True: message = socket.recv() print(message) \"\"\" 结果：发布者每发布一次，都能订阅到 b'123' b'456' b'789' \"\"\" (3)、push/pull(管道模式) 管道是单向的，从PUSH端单向的向PULL端单向的推送数据流。 由三部分组成，push进行数据推送，work进行数据缓存，pull进行数据竞争获取处理。 区别于Publish-Subscribe, 管道模式存在一个数据缓存和处理负载。 当连接被断开，数据不会丢失，重连后数据继续发送到对端。 推送端 import zmq context = zmq.Context() socket = context.socket(zmq.PUSH) # 设置socket类型PUSH推送 socket.bind(\"tcp://*:5557\") #绑定IP和端口 while True: data = input(\"input your data:\") socket.send_string(data) \"\"\" input your data:123 input your data:456 input your data:789 \"\"\" worker端 import zmq context = zmq.Context() socket_receive = context.socket(zmq.PULL) # 设置socket类型PULL拉取推送端的消息 socket_receive.connect(\"tcp://localhost:5557\") # 连接推送端IP和端口 socket_sender = context.socket(zmq.PUSH) # 再设置一个socket类型PUSH推送 socket_sender.connect(\"tcp://localhost:5558\") # 连接IP和端口向其推送消息 while True: data = socket_receive.recv_string() # 拉取接收消息 print(data) socket_sender.send_string(data) # 再将消息推送出去 \"\"\" 123 456 789 \"\"\" 拉取端 import zmq context = zmq.Context() socket = context.socket(zmq.PULL) # 设置socket类型PULL拉取消息 socket.bind(\"tcp://*:5558\") #绑定IP和端口去拉取消息 while True: message = socket.recv_string() print(message) \"\"\" 123 456 789 \"\"\" "},"GoLang/Go简明教程/01-Go语言简明教程.html":{"url":"GoLang/Go简明教程/01-Go语言简明教程.html","title":"Go语言简明教程","keywords":"","body":"datetime:2022/1/15 19:52 author:nzb Go 语言简明教程 Go（又称Golang）是Google开发的一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言。 —— Go - wikipedia.org 1 Go 安装 最新版本下载地址官方下载 golang.org，当前是 1.13.6。如无法访问，可以在 studygolang.com/dl 下载 使用 Linux，可以用如下方式快速安装。 $ wget https://studygolang.com/dl/golang/go1.13.6.linux-amd64.tar.gz $ tar -zxvf go1.13.6.linux-amd64.tar.gz $ sudo mv go /usr/local/ $ go version go version go1.13.6 linux/amd64 从 Go 1.11 版本开始，Go 提供了 Go Modules 的机制，推荐设置以下环境变量，第三方包的下载将通过国内镜像，避免出现官方网址被屏蔽的问题。 $ go env -w GOPROXY=https://goproxy.cn,direct 或在 ~/.profile 中设置环境变量 export GOPROXY=https://goproxy.cn 2 Hello World 新建一个文件 main.go，写入 package main import \"fmt\" func main() { fmt.Println(\"Hello World!\") } 执行go run main.go 或 go run .，将会输出 $ go run . Hello World! 如果强制启用了 Go Modules 机制，即环境变量中设置了 GO111MODULE=on，则需要先初始化模块 go mod init hello 否则会报错误：go: cannot find main module; see ‘go help modules’ 我们的第一个 Go 程序就完成了，接下来我们逐行来解读这个程序： package main：声明了 main.go 所在的包，Go 语言中使用包来组织代码。一般一个文件夹即一个包，包内可以暴露类型或方法供其他包使用。 import “fmt”：fmt 是 Go 语言的一个标准库/包，用来处理标准输入输出。 func main：main 函数是整个程序的入口，main 函数所在的包名也必须为 main。 fmt.Println(“Hello World!”)：调用 fmt 包的 Println 方法，打印出 “Hello World!” go run main.go，其实是 2 步： go build main.go：编译成二进制可执行程序 ./main：执行该程序 3 变量与内置数据类型 3.1 变量(Variable) Go 语言是静态类型的，变量声明时必须明确变量的类型。Go 语言与其他语言显著不同的一个地方在于，Go 语言的类型在变量后面。 比如 java 中，声明一个整体一般写成 int a = 1，在 Go 语言中，需要这么写： var a int // 如果没有赋值，默认为0 var a int = 1 // 声明时赋值 var a = 1 // 声明时赋值 var a = 1，因为 1 是 int 类型的，所以赋值时，a 自动被确定为 int 类型，所以类型名可以省略不写，这种方式还有一种更简单的表达： a := 1 msg := \"Hello World!\" 3.2 简单类型 空值：nil 整型类型： int(取决于操作系统), int8, int16, int32, int64, uint8, uint16, … 浮点数类型：float32, float64 字节类型：byte (等价于uint8) 字符串类型：string 布尔值类型：boolean，(true 或 false) var a int8 = 10 var c1 byte = 'a' var b float32 = 12.2 var msg = \"Hello World\" ok := false 3.3 字符串 在 Go 语言中，字符串使用 UTF8 编码，UTF8 的好处在于，如果基本是英文，每个字符占 1 byte，和 ASCII 编码是一样的，非常节省空间，如果是中文，一般占3字节。包含中文的字符串的处理方式与纯 ASCII 码构成的字符串有点区别。 我们看下面的例子： package main import ( \"fmt\" \"reflect\" ) func main() { str1 := \"Golang\" str2 := \"Go语言\" fmt.Println(reflect.TypeOf(str2[2]).Kind()) // uint8 fmt.Println(str1[2], string(str1[2])) // 108 l fmt.Printf(\"%d %c\\n\", str2[2], str2[2]) // 232 è fmt.Println(\"len(str2)：\", len(str2)) // len(str2)： 8 } reflect.TypeOf().Kind() 可以知道某个变量的类型，我们可以看到，字符串是以 byte 数组形式保存的，类型是 uint8，占1个 byte，打印时需要用 string 进行类型转换，否则打印的是编码值。 因为字符串是以 byte 数组的形式存储的，所以，str2[2] 的值并不等于语。str2 的长度 len(str2) 也不是 4，而是 8（ Go 占 2 byte，语言占 6 byte）。 正确的处理方式是将 string 转为 rune 数组 str2 := \"Go语言\" runeArr := []rune(str2) fmt.Println(reflect.TypeOf(runeArr[2]).Kind()) // int32 fmt.Println(runeArr[2], string(runeArr[2])) // 35821 语 fmt.Println(\"len(runeArr)：\", len(runeArr)) // len(runeArr)： 4 转换成 []rune 类型后，字符串中的每个字符，无论占多少个字节都用 int32 来表示，因而可以正确处理中文。 3.4 数组(array)与切片(slice) 声明数组 var arr [5]int // 一维 var arr2 [5][5]int // 二维 声明时初始化 var arr = [5]int{1, 2, 3, 4, 5} // 或 arr := [5]int{1, 2, 3, 4, 5} 使用 [] 索引/修改数组 arr := [5]int{1, 2, 3, 4, 5} for i := 0; i 数组的长度不能改变，如果想拼接2个数组，或是获取子数组，需要使用切片。切片是数组的抽象。 切片使用数组作为底层结构。切片包含三个组件：容量，长度和指向底层数组的指针,切片可以随时进行扩展 声明切片： slice1 := make([]float32, 0) // 长度为0的切片 slice2 := make([]float32, 3, 5) // [0 0 0] 长度为3容量为5的切片 fmt.Println(len(slice2), cap(slice2)) // 3 5 使用切片： // 添加元素，切片容量可以根据需要自动扩展 slice2 = append(slice2, 1, 2, 3, 4) // [0, 0, 0, 1, 2, 3, 4] fmt.Println(len(slice2), cap(slice2)) // 7 12 // 子切片 [start, end) sub1 := slice2[3:] // [1 2 3 4] sub2 := slice2[:3] // [0 0 0] sub3 := slice2[1:4] // [0 0 1] // 合并切片 combined := append(sub1, sub2...) // [1, 2, 3, 4, 0, 0, 0] 声明切片时可以为切片设置容量大小，为切片预分配空间。在实际使用的过程中，如果容量不够，切片容量会自动扩展。 sub2... 是切片解构的写法，将切片解构为 N 个独立的元素。 3.5 字典(键值对，map) map 类似于 java 的 HashMap，Python的字典(dict)，是一种存储键值对(Key-Value)的数据解构。使用方式和其他语言几乎没有区别。 // 仅声明 m1 := make(map[string]int) // 声明时初始化 m2 := map[string]string{ \"Sam\": \"Male\", \"Alice\": \"Female\", } // 赋值/修改 m1[\"Tom\"] = 18 3.6 指针(pointer) 指针即某个值的地址，类型定义时使用符号*，对一个已经存在的变量，使用 & 获取该变量的地址。 str := \"Golang\" var p *string = &str // p 是指向 str 的指针 *p = \"Hello\" fmt.Println(str) // Hello 修改了 p，str 的值也发生了改变 一般来说，指针通常在函数传递参数，或者给某个类型定义新的方法时使用。Go 语言中，参数是按值传递的，如果不使用指针，函数内部将会拷贝一份参数的副本，对参数的修改并不会影响到外部变量的值。如果参数使用指针，对参数的传递将会影响到外部变量。 例如： func add(num int) { num += 1 } func realAdd(num *int) { *num += 1 } func main() { num := 100 add(num) fmt.Println(num) // 100，num 没有变化 realAdd(&num) fmt.Println(num) // 101，指针传递，num 被修改 } 4 流程控制(if, for, switch) 4.1 条件语句 if else age := 18 if age 4.2 switch type Gender int8 const ( MALE Gender = 1 FEMALE Gender = 2 ) gender := MALE switch gender { case FEMALE: fmt.Println(\"female\") case MALE: fmt.Println(\"male\") default: fmt.Println(\"unknown\") } // male 在这里，使用了 type 关键字定义了一个新的类型 Gender。 使用 const 定义了 MALE 和 FEMALE 2 个常量，Go 语言中没有枚举(enum)的概念，一般可以用常量的方式来模拟枚举。 和其他语言不同的地方在于，Go 语言的 switch 不需要 break，匹配到某个 case，执行完该 case 定义的行为后，默认不会继续往下执行。如果需要继续往下执行，需要使用 fallthrough，例如：switch gender { case FEMALE: fmt.Println(\"female\") fallthrough case MALE: fmt.Println(\"male\") fallthrough default: fmt.Println(\"unknown\") } // 输出结果 // male // unknown 4.3 for 循环 一个简单的累加的例子，break 和 continue 的用法与其他语言没有区别。sum := 0 for i := 0; i 50 { break } sum += i } 对数组(arr)、切片(slice)、字典(map) 使用 for range 遍历： nums := []int{10, 20, 30, 40} for i, num := range nums { fmt.Println(i, num) } // 0 10 // 1 20 // 2 30 // 3 40 m2 := map[string]string{ \"Sam\": \"Male\", \"Alice\": \"Female\", } for key, value := range m2 { fmt.Println(key, value) } // Sam Male // Alice Female 5 函数(functions) 5.1 参数与返回值 一个典型的函数定义如下，使用关键字 func，参数可以有多个，返回值也支持有多个。特别地，package main 中的 func main() 约定为可执行程序的入口。 func funcName(param1 Type1, param2 Type2, ...) (return1 Type3, ...) { // body } 例如，实现2个数的加法（一个返回值）和除法（多个返回值）： func add(num1 int, num2 int) int { return num1 + num2 } func div(num1 int, num2 int) (int, int) { return num1 / num2, num1 % num2 } func main() { quo, rem := div(100, 17) fmt.Println(quo, rem) // 5 15 fmt.Println(add(100, 17)) // 117 } 也可以给返回值命名，简化 return，例如 add 函数可以改写为 func add(num1 int, num2 int) (ans int) { ans = num1 + num2 return } 5.2 错误处理(error handling) 如果函数实现过程中，如果出现不能处理的错误，可以返回给调用者处理。比如我们调用标准库函数os.Open读取文件，os.Open 有2个返回值，第一个是 *File，第二个是 error， 如果调用成功，error 的值是 nil，如果调用失败，例如文件不存在，我们可以通过 error 知道具体的错误信息。 import ( \"fmt\" \"os\" ) func main() { _, err := os.Open(\"filename.txt\") if err != nil { fmt.Println(err) } } // open filename.txt: no such file or directory 可以通过 errorw.New 返回自定义的错误 import ( \"errors\" \"fmt\" ) func hello(name string) error { if len(name) == 0 { return errors.New(\"error: name is null\") } fmt.Println(\"Hello,\", name) return nil } func main() { if err := hello(\"\"); err != nil { fmt.Println(err) } } // error: name is null error 往往是能预知的错误，但是也可能出现一些不可预知的错误，例如数组越界，这种错误可能会导致程序非正常退出，在 Go 语言中称之为 panic。 func get(index int) int { arr := [3]int{2, 3, 4} return arr[index] } func main() { fmt.Println(get(5)) fmt.Println(\"finished\") } $ go run . panic: runtime error: index out of range [5] with length 3 goroutine 1 [running]: exit status 2 在 Python、Java 等语言中有 try...catch 机制，在 try 中捕获各种类型的异常，在 catch 中定义异常处理的行为。Go 语言也提供了类似的机制 defer 和 recover。 func get(index int) (ret int) { defer func() { if r := recover(); r != nil { fmt.Println(\"Some error happened!\", r) ret = -1 } }() arr := [3]int{2, 3, 4} return arr[index] } func main() { fmt.Println(get(5)) fmt.Println(\"finished\") } $ go run . Some error happened! runtime error: index out of range [5] with length 3 -1 finished 在 get 函数中，使用 defer 定义了异常处理的函数，在协程退出前，会执行完 defer 挂载的任务。因此如果触发了 panic，控制权就交给了 defer。 在 defer 的处理逻辑中，使用 recover，使程序恢复正常，并且将返回值设置为 -1，在这里也可以不处理返回值，如果不处理返回值，返回值将被置为默认值 0。 6 结构体，方法和接口 6.1 结构体(struct) 和方法(methods) 结构体类似于其他语言中的 class，可以在结构体中定义多个字段，为结构体实现方法，实例化等。接下来我们定义一个结构体 Student，并为 Student 添加 name，age 字段，并实现 hello() 方法。 type Student struct { name string age int } func (stu *Student) hello(person string) string { return fmt.Sprintf(\"hello %s, I am %s\", person, stu.name) } func main() { stu := &Student{ name: \"Tom\", } msg := stu.hello(\"Jack\") fmt.Println(msg) // hello Jack, I am Tom } 使用 Student{field: value, ...} 的形式创建 Student 的实例，字段不需要每个都赋值，没有显性赋值的变量将被赋予默认值，例如 age 将被赋予默认值 0。 实现方法与实现函数的区别在于，func 和函数名 hello 之间，加上该方法对应的实例名 stu 及其类型 *Student，可以通过实例名访问该实例的字段name和其他方法了。 调用方法通过 实例名.方法名(参数) 的方式。 除此之外，还可以使用 new 实例化： func main() { stu2 := new(Student) fmt.Println(stu2.hello(\"Alice\")) // hello Alice, I am , name 被赋予默认值\"\" } 6.2 接口(interfaces) 一般而言，接口定义了一组方法的集合，接口不能被实例化，一个类型可以实现多个接口。 举一个简单的例子，定义一个接口 Person 和对应的方法 getName() 和 getAge()： type Person interface { getName() string } type Student struct { name string age int } func (stu *Student) getName() string { return stu.name } type Worker struct { name string gender string } func (w *Worker) getName() string { return w.name } func main() { var p Person = &Student{ name: \"Tom\", age: 18, } fmt.Println(p.getName()) // Tom } Go 语言中，并不需要显式地声明实现了哪一个接口，只需要直接实现该接口对应的方法即可。 实例化 Student 后，强制类型转换为接口类型 Person。 在上面的例子中，我们在 main 函数中尝试将 Student 实例类型转换为 Person，如果 Student 没有完全实现 Person 的方法，比如我们将 (*Student).getName() 删掉，编译时会出现如下报错信息。 *Student does not implement Person (missing getName method) 但是删除 (*Worker).getName() 程序并不会报错，因为我们并没有在 main 函数中使用。这种情况下我们如何确保某个类型实现了某个接口的所有方法呢？一般可以使用下面的方法进行检测，如果实现不完整，编译期将会报错。 var _ Person = (*Student)(nil) var _ Person = (*Worker)(nil) 将空值 nil 转换为 *Student 类型，再转换为 Person 接口，如果转换失败，说明 Student 并没有实现 Person 接口的所有方法。 Worker 同上。 实例可以强制类型转换为接口，接口也可以强制类型转换为实例。 func main() { var p Person = &Student{ name: \"Tom\", age: 18, } stu := p.(*Student) // 接口转为实例 fmt.Println(stu.getAge()) } 6.3 空接口 如果定义了一个没有任何方法的空接口，那么这个接口可以表示任意类型。例如 func main() { m := make(map[string]interface{}) m[\"name\"] = \"Tom\" m[\"age\"] = 18 m[\"scores\"] = [3]int{98, 99, 85} fmt.Println(m) // map[age:18 name:Tom scores:[98 99 85]] } 7 并发编程(goroutine) 7.1 sync Go 语言提供了 sync 和 channel 两种方式支持协程(goroutine)的并发。 例如我们希望并发下载 N 个资源，多个并发协程之间不需要通信，那么就可以使用 sync.WaitGroup，等待所有并发协程执行结束。 import ( \"fmt\" \"sync\" \"time\" ) var wg sync.WaitGroup func download(url string) { fmt.Println(\"start to download\", url) time.Sleep(time.Second) // 模拟耗时操作 wg.Done() } func main() { for i := 0; i wg.Add(1)：为 wg 添加一个计数，wg.Done()，减去一个计数。 go download()：启动新的协程并发执行 download 函数。 wg.Wait()：等待所有的协程执行结束。 $ time go run . start to download a.com/2 start to download a.com/0 start to download a.com/1 Done! real 0m1.563s 可以看到串行需要 3s 的下载操作，并发后，只需要 1s。 7.2 channel var ch = make(chan string, 10) // 创建大小为 10 的缓冲信道 func download(url string) { fmt.Println(\"start to download\", url) time.Sleep(time.Second) ch 使用 channel 信道，可以在协程之间传递消息。阻塞等待并发协程返回消息。 $ time go run . start to download a.com/2 start to download a.com/0 start to download a.com/1 finish a.com/2 finish a.com/1 finish a.com/0 Done! real 0m1.528s 8 单元测试(unit test) 假设我们希望测试 package main 下 calc.go 中的函数，要只需要新建 calc_test.go 文件，在 ``calc_test.go 中新建测试用例即可。 // calc.go package main func add(num1 int, num2 int) int { return num1 + num2 } // calc_test.go package main import \"testing\" func TestAdd(t *testing.T) { if ans := add(1, 2); ans != 3 { t.Error(\"add(1, 2) should be equal to 3\") } } 运行 go test，将自动运行当前 package 下的所有测试用例，如果需要查看详细的信息，可以添加 -v 参数。 $ go test -v === RUN TestAdd --- PASS: TestAdd (0.00s) PASS ok example 0.040s 9 包(Package)和模块(Modules) 9.1 Package 一般来说，一个文件夹可以作为 package，同一个 package 内部变量、类型、方法等定义可以相互看到。 比如我们新建一个文件 calc.go，main.go 平级，分别定义 add 和 main 方法。 // calc.go package main func add(num1 int, num2 int) int { return num1 + num2 } // main.go package main import \"fmt\" func main() { fmt.Println(add(3, 5)) // 8 } 运行 go run main.go，会报错，add 未定义： ./main.go:6:14: undefined: add 因为 go run main.go 仅编译 main.go 一个文件，所以命令需要换成 $ go run main.go calc.go 8 或 $ go run . 8 Go 语言也有 Public 和 Private 的概念，粒度是包。如果类型/接口/方法/函数/字段的首字母大写，则是 Public 的，对其他 package 可见，如果首字母小写，则是 Private 的，对其他 package 不可见。 9.2 Modules Go Modules 是 Go 1.11 版本之后引入的，Go 1.11 之前使用 $GOPATH 机制。Go Modules 可以算作是较为完善的包管理工具。同时支持代理，国内也能享受高速的第三方包镜像服务。接下来简单介绍 go mod 的使用。Go Modules 在 1.13 版本仍是可选使用的，环境变量 GO111MODULE 的值默认为 AUTO，强制使用 Go Modules 进行依赖管理，可以将 GO111MODULE 设置为 ON。 在一个空文件夹下，初始化一个 Module $ go mod init example go: creating new go.mod: module example 此时，在当前文件夹下生成了go.mod，这个文件记录当前模块的模块名以及所有依赖包的版本。 接着，我们在当前目录下新建文件 main.go，添加如下代码： package main import ( \"fmt\" \"rsc.io/quote\" ) func main() { fmt.Println(quote.Hello()) // Ahoy, world! } 运行 go run .，将会自动触发第三方包 rsc.io/quote 的下载，具体的版本信息也记录在了 go.mod 中： module example go 1.13 require rsc.io/quote v3.1.0+incompatible 我们在当前目录，添加一个子 package calc，代码目录如下： demo/ |--calc/ |--calc.go |--main.go 在 calc.go 中写入 package calc func Add(num1 int, num2 int) int { return num1 + num2 } 在 package main 中如何使用 package cal 中的 Add 函数呢？import 模块名/子目录名 即可，修改后的 main 函数如下： package main import ( \"fmt\" \"example/calc\" \"rsc.io/quote\" ) func main() { fmt.Println(quote.Hello()) fmt.Println(calc.Add(10, 3)) } $ go run . Ahoy, world! 13 "},"GoLang/Go简明教程/02-Go-Gin-简明教程.html":{"url":"GoLang/Go简明教程/02-Go-Gin-简明教程.html","title":"Gin-简明教程","keywords":"","body":"datetime:2022/1/15 22:26 author:nzb Go Gin 简明教程 Gin 简介 Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance – up to 40 times faster. If you need smashing performance, get yourself some Gin. Gin 是使用 Go/golang 语言实现的 HTTP Web 框架。接口简洁，性能极高。截止 1.4.0 版本，包含测试代码，仅14K，其中测试代码 9K 左右，也就是说框架源码仅 5K 左右。 $ find . -name \"*_test.go\" | xargs cat | wc -l 8657 $ find . -name \"*.go\" | xargs cat | wc -l 14115 Gin 特性 快速：路由不使用反射，基于Radix树，内存占用少。 中间件：HTTP请求，可先经过一系列中间件处理，例如：Logger，Authorization，GZIP等。这个特性和 NodeJs 的 Koa 框架很像。中间件机制也极大地提高了框架的可扩展性。 异常处理：服务始终可用，不会宕机。Gin 可以捕获 panic，并恢复。而且有极为便利的机制处理HTTP请求过程中发生的错误。 JSON：Gin可以解析并验证请求的JSON。这个特性对Restful API的开发尤其有用。 路由分组：例如将需要授权和不需要授权的API分组，不同版本的API分组。而且分组可嵌套，且性能不受影响。 渲染内置：原生支持JSON，XML和HTML的渲染。 安装Go & Gin 安装 Go (Ubuntu)$ sudo apt-get install golang-go $ go version # go version go1.6.2 linux/amd64 Ubuntu自带版本太老了，安装新版可以使用如下命令。 $ sudo add-apt-repository ppa:gophers/archive $ sudo apt-get update $ sudo apt-get install golang-1.11-go 默认安装在/usr/lib/go-1.11，需要将/usr/lib/go-1.11/bin手动加入环境变量。在 .bashrc 中添加下面的配置，并 source ~/.bashrc export PATH=$PATH:/usr/lib/go-1.11/bin 参考：[Golang Ubuntu - Github]https://github.com/golang/go/wiki/Ubuntu) 安装 Go (Mac) $ brew install go $ go version # go version go1.12.5 darwin/amd64 设置环境变量 设置环境变量 export GOPATH=~/go export PATH=$PATH:$GOPATH/bin 添加完后，source ~/.bashrc 安装一些辅助的工具库 由于网络原因，不能够直接访问 golang.org，但相关的库已经镜像到 Golang - Github 例如，直接安装 go-outline 时会报网络错误，因为golang.org/x/tools是go-outline的依赖库。 $ go get -u -v github.com/ramya-rao-a/go-outline github.com/ramya-rao-a/go-outline (download) Fetching https://golang.org/x/tools/go/buildutil?go-get=1 https fetch failed: Get https://golang.org/x/tools/go/buildutil?go-get=1: dial tcp 216.239.37.1:443: i/o timeout 因此，可以先从 Github 手动安装好，再安装 go-outline 和 goreturns。 git clone https://github.com/golang/tools.git $GOPATH/src/golang.org/x/tools go get -v github.com/ramya-rao-a/go-outline go get -v github.com/sqs/goreturns go get -v github.com/rogpeppe/godef Go语言有大量的辅助工具，如果你使用VSCode，将会提示你将必要的工具，例如静态检查、自动补全等工具依次安装完毕。 安装 Gin go get -u -v github.com/gin-gonic/gin -v：打印出被构建的代码包的名字 -u：已存在相关的代码包，强行更新代码包及其依赖包 第一个Gin程序 在一个空文件夹里新建文件main.go。 // geektutu.com // main.go package main import \"github.com/gin-gonic/gin\" func main() { r := gin.Default() r.GET(\"/\", func(c *gin.Context) { c.String(200, \"Hello, Golang\") }) r.Run() // listen and serve on 0.0.0.0:8080 } 首先，我们使用了gin.Default()生成了一个实例，这个实例即 WSGI 应用程序。 接下来，我们使用r.Get(\"/\", ...)声明了一个路由，告诉 Gin 什么样的URL 能触发传入的函数，这个函数返回我们想要显示在用户浏览器中的信息。 最后用 r.Run()函数来让应用运行在本地服务器上，默认监听端口是 8080，可以传入参数设置端口，例如r.Run(\":9999\")即运行在 9999端口。 运行 $ go run main.go [GIN-debug] GET / --> main.main.func1 (3 handlers) [GIN-debug] Environment variable PORT is undefined. Using port :8080 by default [GIN-debug] Listening and serving HTTP on :8080 浏览器访问 http://localhost:8080 路由(Route) 路由方法有 GET, POST, PUT, PATCH, DELETE 和 OPTIONS，还有 Any，可匹配以上任意类型的请求。 无参数 // 无参数 r.GET(\"/\", func(c *gin.Context) { c.String(http.StatusOK, \"Who are you?\") }) $ curl http://localhost:9999/ Who are you? curl参数可参考https://man.linuxde.net/curl 解析路径参数 有时候我们需要动态的路由，如 /user/:name，通过调用不同的 url 来传入不同的 name。/user/:name/*role，* 代表可选。 // 匹配 /user/geektutu r.GET(\"/user/:name\", func(c *gin.Context) { name := c.Param(\"name\") c.String(http.StatusOK, \"Hello %s\", name) }) $ curl http://localhost:9999/user/golang Hello golang 获取Query参数 // 匹配users?name=xxx&role=xxx，role可选 r.GET(\"/users\", func(c *gin.Context) { name := c.Query(\"name\") role := c.DefaultQuery(\"role\", \"teacher\") c.String(http.StatusOK, \"%s is a %s\", name, role) }) $ curl \"http://localhost:9999/users?name=Tom&role=student\" Tom is a student 获取POST参数 // POST r.POST(\"/form\", func(c *gin.Context) { username := c.PostForm(\"username\") password := c.DefaultPostForm(\"password\", \"000000\") // 可设置默认值 c.JSON(http.StatusOK, gin.H{ \"username\": username, \"password\": password, }) }) $ curl http://localhost:9999/form -X POST -d 'username=golang&password=1234' {\"password\":\"1234\",\"username\":\"golang\"} Query和POST混合参数 // GET 和 POST 混合 r.POST(\"/posts\", func(c *gin.Context) { id := c.Query(\"id\") page := c.DefaultQuery(\"page\", \"0\") username := c.PostForm(\"username\") password := c.DefaultPostForm(\"username\", \"000000\") // 可设置默认值 c.JSON(http.StatusOK, gin.H{ \"id\": id, \"page\": page, \"username\": username, \"password\": password, }) }) $ curl \"http://localhost:9999/posts?id=9876&page=7\" -X POST -d 'username=golang&password=1234' {\"id\":\"9876\",\"page\":\"7\",\"password\":\"1234\",\"username\":\"golang\"} Map参数(字典参数) r.POST(\"/post\", func(c *gin.Context) { ids := c.QueryMap(\"ids\") names := c.PostFormMap(\"names\") c.JSON(http.StatusOK, gin.H{ \"ids\": ids, \"names\": names, }) }) $ curl -g \"http://localhost:9999/post?ids[Jack]=001&ids[Tom]=002\" -X POST -d 'names[a]=Sam&names[b]=David' {\"ids\":{\"Jack\":\"001\",\"Tom\":\"002\"},\"names\":{\"a\":\"Sam\",\"b\":\"David\"} } 重定向(Redirect) r.GET(\"/redirect\", func(c *gin.Context) { c.Redirect(http.StatusMovedPermanently, \"/index\") }) r.GET(\"/goindex\", func(c *gin.Context) { c.Request.URL.Path = \"/\" r.HandleContext(c) }) $ curl -i http://localhost:9999/redirect HTTP/1.1 301 Moved Permanently Content-Type: text/html; charset=utf-8 Location: / Date: Thu, 08 Aug 2019 17:22:14 GMT Content-Length: 36 Moved Permanently. $ curl \"http://localhost:9999/goindex\" Who are you? 分组路由(Grouping Routes)如果有一组路由，前缀都是/api/v1开头，是否每个路由都需要加上/api/v1这个前缀呢？答案是不需要，分组路由可以解决这个问题。利用分组路由还可以更好地实现权限控制，例如将需要登录鉴权的路由放到同一分组中去，简化权限控制。 // group routes 分组路由 defaultHandler := func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ \"path\": c.FullPath(), }) } // group: v1 v1 := r.Group(\"/v1\") { v1.GET(\"/posts\", defaultHandler) v1.GET(\"/series\", defaultHandler) } // group: v2 v2 := r.Group(\"/v2\") { v2.GET(\"/posts\", defaultHandler) v2.GET(\"/series\", defaultHandler) } $ curl http://localhost:9999/v1/posts {\"path\":\"/v1/posts\"} $ curl http://localhost:9999/v2/posts {\"path\":\"/v2/posts\"} 上传文件 单个文件 r.POST(\"/upload1\", func(c *gin.Context) { file, _ := c.FormFile(\"file\") // c.SaveUploadedFile(file, dst) c.String(http.StatusOK, \"%s uploaded!\", file.Filename) }) 多个文件 r.POST(\"/upload2\", func(c *gin.Context) { // Multipart form form, _ := c.MultipartForm() files := form.File[\"upload[]\"] for _, file := range files { log.Println(file.Filename) // c.SaveUploadedFile(file, dst) } c.String(http.StatusOK, \"%d files uploaded!\", len(files)) }) HTML模板(Template) type student struct { Name string Age int8 } r.LoadHTMLGlob(\"templates/*\") stu1 := &student{Name: \"Geektutu\", Age: 20} stu2 := &student{Name: \"Jack\", Age: 22} r.GET(\"/arr\", func(c *gin.Context) { c.HTML(http.StatusOK, \"arr.tmpl\", gin.H{ \"title\": \"Gin\", \"stuArr\": [2]*student{stu1, stu2}, }) }) hello, { {.title} } { {range $index, $ele := .stuArr } } { { $index } }: { { $ele.Name } } is { { $ele.Age } } years old { { end } } $ curl http://localhost:9999/arr hello, Gin 0: Geektutu is 20 years old 1: Jack is 22 years old Gin默认使用模板Go语言标准库的模板text/template和html/template，语法与标准库一致，支持各种复杂场景的渲染。 参考官方文档text/template，html/template 中间件(Middleware) // 作用于全局 r.Use(gin.Logger()) r.Use(gin.Recovery()) // 作用于单个路由 r.GET(\"/benchmark\", MyBenchLogger(), benchEndpoint) // 作用于某个组 authorized := r.Group(\"/\") authorized.Use(AuthRequired()) { authorized.POST(\"/login\", loginEndpoint) authorized.POST(\"/submit\", submitEndpoint) } 如何自定义中间件呢？ func Logger() gin.HandlerFunc { return func(c *gin.Context) { t := time.Now() // 给Context实例设置一个值 c.Set(\"geektutu\", \"1111\") // 请求前 c.Next() // 请求后 latency := time.Since(t) log.Print(latency) } } 热加载调试 Hot Reload Python 的 Flask 框架，有 debug 模式，启动时传入 debug=True 就可以热加载(Hot Reload, Live Reload)了。即更改源码，保存后，自动触发更新，浏览器上刷新即可。免去了杀进程、重新启动之苦。 Gin 原生不支持，但有很多额外的库可以支持。例如 github.com/codegangsta/gin github.com/pilu/fresh 这次，我们采用 github.com/pilu/fresh 。 go get -v -u github.com/pilu/fresh 安装好后，只需要将go run main.go命令换成fresh即可。每次更改源文件，代码将自动重新编译(Auto Compile)。 参考 github.com/pilu/fresh - Github 相关链接 Golang Gin - Github Gin Web Framework - 英文官方网站 "},"GoLang/Go简明教程/03-Go2新特性简明教程.html":{"url":"GoLang/Go简明教程/03-Go2新特性简明教程.html","title":"Go2新特性简明教程","keywords":"","body":"datetime:2022/1/16 11:33 author:nzb Go2 新特性简明教程 Go 的演进 Go语言/golang 诞生于2007年，经过12年的发展，Go逐渐成为了云计算领域新一代的开发语言。Go语言在牺牲很少性能的情况下，语法简洁，功能强大。我是Python的重度用户，在学习Go时，却有一种在学习Python的感觉。并非语法相似，而是Go语言作为一门编译型语言，竟然能够像Python一样，少量的代码就能够完成尽可能多的事情。Go语言仿佛是C和Python的结合体。 Go是如何火起来的呢？我觉得有几个主要的原因，除了语言本身性能好，语法简单，易上手外。Go语言原生支持 Goroutine 和 Channel ，极大地降低了并发和异步编程的复杂度。对于服务端编程，并发和异步尤其重要，相比之下，C++，Java等语言的并发和异步控制逻辑过于复杂。另外，杀手级应用Docker的出现起到了很大的推动作用。 Go语言也有很多令人诟病的地方，例如包管理机制，Go直到v1.6才默认开启了vendor机制，vendor机制非常简陋，简单说就是在项目目录下增加一个vendor文件夹，里面放第三方依赖。vendor机制是没有版本概念的，而且不能解决vendor目录嵌套的问题以及同名包函数冲突问题。后来社区涌现了大量的包管理工具，仅官方推荐的包管理工具就有15种之多，应用比较广泛的，如dep、govendor。直到v1.11，官方增加了Go modules机制，才算较为完整地解决了包管理的问题。 Go2 可以说是Go语言一个非常重要的里程碑，Go1 目前虽然已经到了1.12版本，事实上每一个版本很少涉及语法层面的变化，而且每个版本都是向前兼容的。较大的改动如下： Go1.2 切片操作 var a = make([]int, 10) var b = a[i:j:k] Go1.4 for语言加强 // Go1.9 类型别名 type T1 = T2 Go 2 设计草案 为了进一步完善Go语言，提供更好的体验。Go语言社区目前发布了三类重要的设计草案，分别是错误处理(Error handling)、错误值(Error values)、泛型(Generics) ，这几个草案代表了社区重点关注的完善方向，但并不代表最终的实现。 错误处理(Error Handling) Go1 的错误处理机制非常简单，通过返回值的方式，强迫调用者对错误进行处理，这种设计导致会在代码中写大量的 if 判断。例如： func CopyFile(src, dst string) { r := os.Open(src) defer r.Close() w := os.Create(dst) io.Copy(w, r) w.Close() } IO操作容易引发错误，文件打开失败，创建失败，拷贝失败等都会产生错误。如果要对这个函数进行完整的错误处理，代码将变成这样： func CopyFile(src, dst string) error { r, err := os.Open(src) if err != nil { return err } defer r.Close() w, err := os.Create(dst) if err != nil { return err } defer w.Close() if _, err := io.Copy(w, r); err != nil { return err } if err := w.Close(); err != nil { return err } } 看似逻辑清晰，但不够优雅，充斥了大量重复的逻辑。这是Go错误处理机制的缺陷。同时，因为错误处理机制的繁琐，很多开发者在开发应用时，很少去检查并处理错误，程序的健壮性得不到保证。 为了解决这个问题，Go2 发布了一个设计草案供社区讨论，Go2将会完善错误处理机制，错误处理的语法将会简洁很多。 这个提案引入了handle err和check关键字，上面的函数可以简化成： func CopyFile(src, dst string) error { handle err { return fmt.Errorf(\"copy %s %s: %v\", src, dst, err) } r := check os.Open(src) defer r.Close() w := check os.Create(dst) check io.Copy(w, r) check w.Close() } 为什么不使用被Java、Python等语言采用的try关键字呢？比如写成： data := try parseHexdump(string(hex)) 上面的写法看似和谐，但try关键字直接应用在 error values 时，可读性就没那么好了： data, err := parseHexdump(string(hex)) if err == ErrBadHex { ... special handling ... } try err 很明显，在这种场景下，check err显然比try err更有意义。 错误值(Error values) 同样由于错误处理机制设计得较为简陋，Go语言对Error values支持有限。任何值，只要实现了error 接口，都是错误类型。由于缺少细粒度的设计，在各种库当中，判断是否产生错误以及产生了哪类错误的方式多种多样，例如io.EOF，os.IsNotExist，err.Error() 等，。另外，Go语言目前没有机制追溯到完整的错误链条。例如， func funcB() error { if v, err := funcA(); if err != nil { return fmt.Errorf(\"connect to db: %v\", err) } } func funcC() error { v, err := funcB() if err != nil { return fmt.Errorf(\"write users database: %v\", err) } } funcC返回的错误信息是： write users database: connect to db: open /etc/xx.conf: permission denied 每一层，用额外的字符串对错误进行封装，是目前最常用的方法，除了通过字符串解析，很难还原出完整的错误链条。 为了解决Error values缺少标准的问题，有2个提案，分别针对Error inspection和Error formatting。 针对 Error inspection ，为error定义了一个可选的接口Unwrap，用来返回错误链上的下一个错误。 package errors type Wrapper interface { Unwrap() error } 例如， // WriteError 实现 Unwrap 接口 func (e *WriteError) Unwrap() error { return e.Err } 针对 Error format，定义了一个可选的接口Format，用来返回错误信息。 package errors type Formatter interface { Format(p Printer) (next error) } 例如， func (e *WriteError) Format(p errors.Printer) (next error) { p.Printf(\"write %s database\", e.Database) if p.Detail() { p.Printf(\"more detail here\") } return e.Err } 泛型(Generics) Go语言当前可使用inferface{} ，允许函数参数和返回值是任何类型的值。但这过于灵活，很多时候需要在获取参数后使用类型断言，进而决定下一步的处理。对比C++/Java的标准容器，Go语言在泛型方面有很大不足，因此针对泛型的提案即希望弥补这方面的不足。提案希望能够支持以下功能： type List(type T) []T // 返回map的键 func Keys(type K, V)(m map[K]V) []K // 去重过滤 func Uniq( 例如，我们需要返回一个map对象中所有的键，而希望这个键的类型可以是任意类型。 var ints List(int) keysA := Keys(int, string)(map[int]string{1:\"one\", 2: \"two\"}) keysB := Keys(string, string)(map[string]string{\"name\":\"geektutu\", \"age\": \"twenty\"}) // [1, 2] Go 2 新特性 Go2还未正式发布，发布后更新 参考：Go2 wiki - Github "},"GoLang/Go简明教程/04-Go-Protobuf简明教程.html":{"url":"GoLang/Go简明教程/04-Go-Protobuf简明教程.html","title":"Protobuf简明教程","keywords":"","body":"datetime:2022/1/16 12:27 author:nzb Go Protobuf 简明教程 1 Protocol Buffers 简介 protobuf 即 Protocol Buffers，是一种轻便高效的结构化数据存储格式，与语言、平台无关，可扩展可序列化。protobuf 性能和效率大幅度优于 JSON、XML 等其他的结构化数据格式。protobuf 是以二进制方式存储的，占用空间小，但也带来了可读性差的缺点。protobuf 在通信协议和数据存储等领域应用广泛。例如著名的分布式缓存工具 Memcached 的 Go 语言版本 groupcache 就使用了 protobuf 作为其 RPC 数据格式。 Protobuf 在 .proto 定义需要处理的结构化数据，可以通过 protoc 工具，将 .proto 文件转换为 C、C++、Golang、Java、Python 等多种语言的代码，兼容性好，易于使用。 2 安装 2.1 protoc 从 Protobuf Releases 下载最先版本的发布包安装。如果是 Ubuntu，可以按照如下步骤操作（以3.11.2为例）。 # 下载安装包 $ wget https://github.com/protocolbuffers/protobuf/releases/download/v3.11.2/protoc-3.11.2-linux-x86_64.zip # 解压到 /usr/local 目录下 $ sudo 7z x protoc-3.11.2-linux-x86_64.zip -o/usr/local 如果不想安装在 /usr/local 目录下，可以解压到其他的其他，并把解压路径下的 bin 目录 加入到环境变量即可。 如果能正常显示版本，则表示安装成功。 $ protoc --version libprotoc 3.11.2 2.2 protoc-gen-go 我们需要在 Golang 中使用 protobuf，还需要安装 protoc-gen-go，这个工具用来将 .proto 文件转换为 Golang 代码。 go get -u github.com/golang/protobuf/protoc-gen-go protoc-gen-go 将自动安装到 $GOPATH/bin 目录下，也需要将这个目录加入到环境变量中。 3 定义消息类型 接下来，我们创建一个非常简单的示例，student.proto syntax = \"proto3\"; package main; // this is a comment message Student { string name = 1; bool male = 2; repeated int32 scores = 3; } 在当前目录下执行： $ protoc --go_out=. *.proto $ ls student.pb.go student.proto 即是，将该目录下的所有的 .proto 文件转换为 Go 代码，我们可以看到该目录下多出了一个 Go 文件 student.pb.go。这个文件内部定义了一个结构体 Student，以及相关的方法： type Student struct { Name string `protobuf:\"bytes,1,opt,name=name,proto3\" json:\"name,omitempty\"` Male bool `protobuf:\"varint,2,opt,name=male,proto3\" json:\"male,omitempty\"` Scores []int32 `protobuf:\"varint,3,rep,packed,name=scores,proto3\" json:\"scores,omitempty\"` ... } 逐行解读student.proto protobuf 有2个版本，默认版本是 proto2，如果需要 proto3，则需要在非空非注释第一行使用 syntax = \"proto3\" 标明版本。 package，即包名声明符是可选的，用来防止不同的消息类型有命名冲突。 消息类型 使用 message 关键字定义，Student 是类型名，name, male, scores 是该类型的 3 个字段，类型分别为 string, bool 和 []int32。字段可以是标量类型，也可以是合成类型。 每个字段的修饰符默认是 singular，一般省略不写，repeated 表示字段可重复，即用来表示 Go 语言中的数组类型。 每个字符 =后面的数字称为标识符，每个字段都需要提供一个唯一的标识符。标识符用来在消息的二进制格式中识别各个字段，一旦使用就不能够再改变，标识符的取值范围为 [1, 2^29 - 1] 。 .proto 文件可以写注释，单行注释 //，多行注释 /* ... */ 一个 .proto 文件中可以写多个消息类型，即对应多个结构体(struct)。 接下来，就可以在项目代码中直接使用了，以下是一个非常简单的例子，即证明被序列化的和反序列化后的实例，包含相同的数据。 package main import ( \"log\" \"github.com/golang/protobuf/proto\" ) func main() { test := &Student{ Name: \"geektutu\", Male: true, Scores: []int32{98, 85, 88}, } data, err := proto.Marshal(test) if err != nil { log.Fatal(\"marshaling error: \", err) } newTest := &Student{} err = proto.Unmarshal(data, newTest) if err != nil { log.Fatal(\"unmarshaling error: \", err) } // Now test and newTest contain the same data. if test.GetName() != newTest.GetName() { log.Fatalf(\"data mismatch %q != %q\", test.GetName(), newTest.GetName()) } } 保留字段(Reserved Field) 更新消息类型时，可能会将某些字段/标识符删除。这些被删掉的字段/标识符可能被重新使用，如果加载老版本的数据时，可能会造成数据冲突，在升级时，可以将这些字段/标识符保留(reserved)，这样就不会被重新使用了，protoc 会检查。 message Foo { reserved 2, 15, 9 to 11; reserved \"foo\", \"bar\"; } 4 字段类型 4.1 标量类型(Scalar) proto类型 go类型 备注 double float64 float float32 int32 int32 int64 int64 uint32 uint32 uint64 uint64 sint32 int32 适合负数 sint64 int64 适合负数 fixed32 uint32 固长编码，适合大于2^28的值 fixed64 uint64 固长编码，适合大于2^56的值 sfixed32 int32 固长编码 sfixed64 int64 固长编码 bool bool string string UTF8 编码，长度不超过 2^32 bytes []byte 任意字节序列，长度不超过 2^32 标量类型如果没有被赋值，则不会被序列化，解析时，会赋予默认值。 strings：空字符串 bytes：空序列 bools：false 数值类型：0 4.2 枚举(Enumerations) 枚举类型适用于提供一组预定义的值，选择其中一个。例如我们将性别定义为枚举类型。 message Student { string name = 1; enum Gender { FEMALE = 0; MALE = 1; } Gender gender = 2; repeated int32 scores = 3; } 枚举类型的第一个选项的标识符必须是0，这也是枚举类型的默认值。 别名（Alias），允许为不同的枚举值赋予相同的标识符，称之为别名，需要打开allow_alias选项。message EnumAllowAlias { enum Status { option allow_alias = true; UNKOWN = 0; STARTED = 1; RUNNING = 1; } } 4.3 使用其他消息类型 Result 是另一个消息类型，在 SearchReponse 作为一个消息字段类型使用。 message SearchResponse { repeated Result results = 1; } message Result { string url = 1; string title = 2; repeated string snippets = 3; } 嵌套写也是支持的： message SearchResponse { message Result { string url = 1; string title = 2; repeated string snippets = 3; } repeated Result results = 1; } 如果定义在其他文件中，可以导入其他消息类型来使用： import \"myproject/other_protos.proto\"; 4.4 任意类型(Any) Any 可以表示不在 .proto 中定义任意的内置类型。 import \"google/protobuf/any.proto\"; message ErrorStatus { string message = 1; repeated google.protobuf.Any details = 2; } 4.5 oneof message SampleMessage { oneof test_oneof { string name = 4; SubMessage sub_message = 9; } } 4.6 map message MapRequest { map points = 1; } 5 定义服务(Services) 如果消息类型是用来远程通信的(Remote Procedure Call, RPC)，可以在 .proto 文件中定义 RPC 服务接口。例如我们定义了一个名为 SearchService 的 RPC 服务，提供了 Search 接口，入参是 SearchRequest 类型，返回类型是 SearchResponse service SearchService { rpc Search (SearchRequest) returns (SearchResponse); } 官方仓库也提供了一个插件列表，帮助开发基于 Protocol Buffer 的 RPC 服务。 6 protoc 其他参数 命令行使用方法 protoc --proto_path=IMPORT_PATH --_out=DST_DIR path/to/file.proto --proto_path=IMPORT_PATH：可以在 .proto 文件中 import 其他的 .proto 文件，proto_path 即用来指定其他 .proto 文件的查找目录。如果没有引入其他的 .proto 文件，该参数可以省略。 --_out=DST_DIR：指定生成代码的目标文件夹，例如 –go_out=. 即生成 GO 代码在当前文件夹，另外支持 cpp/java/python/ruby/objc/csharp/php 等语言 7 推荐风格 文件(Files) 文件名使用小写下划线的命名风格，例如 lower_snake_case.proto 每行不超过 80 字符 使用 2 个空格缩进 包(Packages) 包名应该和目录结构对应，例如文件在my/package/目录下，包名应为 my.package 消息和字段(Messages & Fields) 消息名使用首字母大写驼峰风格(CamelCase)，例如message StudentRequest { ... } 字段名使用小写下划线的风格，例如 string status_code = 1 枚举类型，枚举名使用首字母大写驼峰风格，例如 enum FooBar，枚举值使用全大写下划线隔开的风格(CAPITALS_WITH_UNDERSCORES )，例如 FOO_DEFAULT=1 服务(Services) RPC 服务名和方法名，均使用首字母大写驼峰风格，例如 service FooService{ rpc GetSomething() } 附：参考 protobuf 代码仓库 - github.com golang protobuf 代码仓库 - github.com Remote procedure call 远程过程调用 - wikipedia.org Groupcache Go语言版 memcached - github.com Language Guide (proto3) 官方指南 - google.com Proto Style Guide 代码风格指南 - google.com Protocol Buffer 插件列表 - github.com "},"GoLang/Go简明教程/05-Go-RPC&TLS鉴权简明教程.html":{"url":"GoLang/Go简明教程/05-Go-RPC&TLS鉴权简明教程.html","title":"RPC&TLS鉴权简明教程","keywords":"","body":"datetime:2022/1/16 14:32 author:nzb Go RPC & TLS 鉴权简明教程 本文介绍了 Go 语言远程过程调用(Remote Procedure Call, RPC)的使用方式，示例基于 Golang 标准库 net/rpc，同时介绍了如何基于 TLS/SSL 实现服务器端和客户端的单向鉴权、双向鉴权。 1 RPC 简介 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节）。RPC是一种服务器-客户端（Client/Server）模式，经典实现是一个通过发送请求-接受回应进行信息交互的系统。 – 远程过程调用 - Wikipedia.org 划重点：程序员就像调用本地程序一样，无需关注细节 RPC 协议假定某种传输协议(TCP, UDP)存在，为通信程序之间携带信息数据。使用 RPC 协议，无需关注底层网络技术协议，调用远程方法就像在调用本地方法一样。 RPC 流程： RPC 模型是一个典型的客户端-服务器模型(Client-Server, CS)，相比于调用本地的接口，RPC 还需要知道的是服务器端的地址信息。本地调用，好比两个人面对面说话，而 RPC 好比打电话，需要知道对方的电话号码，但是并不需要关心语音是怎么编码，如何传输，又如何解码的。 接下来我们将展示如何将一个简单的本地调用的程序一步步地改造一个 RPC 服务。 示例使用 Go 语言，RPC 使用 Golang 提供的net/rpc 标准库 2 一个简单的计算二次方的程序 不考虑 RPC 调用，仅考虑本地调用的场景，程序实现如下： // main.go package main import \"log\" type Result struct { Num, Ans int } type Cal int func (cal *Cal) Square(num int) *Result { return &Result{ Num: num, Ans: num * num, } } func main() { cal := new(Cal) result := cal.Square(12) log.Printf(\"%d^2 = %d\", result.Num, result.Ans) } 在这个20行的程序中，我们做了以下几件事： Cal 结构体，提供了 Square 方法，用于计算传入参数 num 的 二次方。 Result 结构体，包含 Num 和 Ans 两个字段，Ans 是计算后的值，Num 是待计算的值。 main 函数，测试我们实现的 Square 方法。 运行 main.go，将会输出 $ go run main.go 2020/01/13 20:27:08 12^2 = 144 3 RPC 需要满足什么条件 虽然说，远程过程调用并不需要我们关心如何编解码，如何通信，但是最基本的，如果一个方法需要支持远程过程调用，需要满足一定的约束和规范。不同 RPC 框架的约束和规范是不同的，如果使用 Golang 的标准库 net/rpc，方法需要长这个样子： func (t *T) MethodName(argType T1, replyType *T2) error 即需要满足以下 5 个条件： 方法类型（T）是导出的（首字母大写） 方法名（MethodName）是导出的 方法有2个参数(argType T1, replyType *T2)，均为导出/内置类型 方法的第2个参数一个指针(replyType *T2) 方法的返回值类型是 error net/rpc 对参数个数的限制比较严格，仅能有2个，第一个参数是调用者提供的请求参数，第二个参数是返回给调用者的响应参数，也就是说，服务端需要将计算结果写在第二个参数中。如果调用过程中发生错误，会返回 error 给调用者。 接下来，我们改造下 Square 函数，以满足上述 5 个条件。 func (cal *Cal) Square(num int, result *Result) error { result.Num = num result.Ans = num * num return nil } func main() { cal := new(Cal) var result Result cal.Square(11, &result) log.Printf(\"%d^2 = %d\", result.Num, result.Ans) } Cal 和 Square 均为导出类型，满足条件 1) 和 2) 2 个参数，num int 为内置类型，result *Result 为导出类型，满足条件 3) 第2个参数 result *Result 是一个指针，满足条件 4) 返回值类型是 error，满足条件 5) 至此，方法 Cal.Square 满足了 RPC 调用的5个条件。 4 RPC 服务与调用 4.1 基于HTTP，启动 RPC 服务 RPC 是一个典型的客户端-服务器(Client-Server, CS) 架构模型，很显然，需要将 Cal.Square 方法放在服务端。服务端需要提供一个套接字服务，处理客户端发送的请求。通常可以基于 HTTP 协议，监听一个端口，等待 HTTP 请求。 接下来我们新建一个文件夹 server，将 Cal.Square 方法移动到 server/main.go 中，并在 main 函数中启动 RPC 服务。 // server/main.go package main import ( \"log\" \"net\" \"net/http\" \"net/rpc\" ) type Result struct { Num, Ans int } type Cal int func (cal *Cal) Square(num int, result *Result) error { result.Num = num result.Ans = num * num return nil } func main() { rpc.Register(new(Cal)) rpc.HandleHTTP() log.Printf(\"Serving RPC server on port %d\", 1234) if err := http.ListenAndServe(\":1234\", nil); err != nil { log.Fatal(\"Error serving: \", err) } } 使用 rpc.Register，发布 Cal 中满足 RPC 注册条件的方法（Cal.Square） 使用 rpc.HandleHTTP 注册用于处理 RPC 消息的 HTTP Handler 使用 http.ListenAndServe 监听 1234 端口，等待 RPC 请求。 我们在 server 目录下，执行 $ go run main.go 2020/01/13 20:59:22 Serving RPC server on port 1234 此时，RPC 服务已经启动，等待客户端的调用。 4.2 实现客户端 我们在 client 目录中新建文件 client/main.go，创建 HTTP 客户端，调用 Cal.Square 方法。 // client/main.go package main import ( \"log\" \"net/rpc\" ) type Result struct { Num, Ans int } func main() { client, _ := rpc.DialHTTP(\"tcp\", \"localhost:1234\") var result Result if err := client.Call(\"Cal.Square\", 12, &result); err != nil { log.Fatal(\"Failed to call Cal.Square. \", err) } log.Printf(\"%d^2 = %d\", result.Num, result.Ans) } 在客户端的实现中，因为要用到 Result 类型，简单起见，我们拷贝了 Result 的定义。 使用 rpc.DialHTTP 创建了 HTTP 客户端 client，并且创建了与 localhost:1234 的链接，1234 恰好是 RPC 服务监听的端口。 使用 rpc.Call 调用远程方法，第1个参数是方法名 Cal.Square，后两个参数与 Cal.Square 的定义的参数相对应。 我们在 client 目录下，执行 2020/01/13 21:17:45 12^2 = 144 如果能够返回计算的结果，说明调用成功。 4.3 异步调用 client.Call 是同步调用的方式，会阻塞当前的程序，直到结果返回。如果有异步调用的需求，可以考虑使用 client.Go，如下 func main() { client, _ := rpc.DialHTTP(\"tcp\", \"localhost:1234\") var result Result asyncCall := client.Go(\"Cal.Square\", 12, &result, nil) log.Printf(\"%d^2 = %d\", result.Num, result.Ans) 执行结果如下： 2020/01/13 21:34:26 0^2 = 0 2020/01/13 21:34:26 12^2 = 144 因为 client.Go 是异步调用，因此第一次打印 result，result 没有被赋值。而通过调用 ，阻塞当前程序直到 RPC 调用结束，因此第二次打印 result 时，能够看到正确的赋值。 5 证书鉴权(TLS/SSL) 5.1 客户端对服务器端鉴权 HTTP 协议默认是不加密的，我们可以使用证书来保证通信过程的安全。 生成私钥和自签名的证书，并将 server.key 权限设置为只读，保证私钥的安全。 # 生成私钥 openssl genrsa -out server.key 2048 # 生成证书 openssl req -new -x509 -key server.key -out server.crt -days 3650 # 只读权限 chmod 400 server.key 执行完，当前文件夹下多出了 server.crt 和 server.key 2 个文件。 服务器端可以使用生成的 server.crt 和 server.key 文件启动 TLS 的端口监听。 // server/main.go import ( \"crypto/tls\" \"log\" \"net/rpc\" ) func main() { rpc.Register(new(Cal)) cert, _ := tls.LoadX509KeyPair(\"server.crt\", \"server.key\") config := &tls.Config{ Certificates: []tls.Certificate{cert}, } listener, _ := tls.Listen(\"tcp\", \":1234\", config) log.Printf(\"Serving RPC server on port %d\", 1234) for { conn, _ := listener.Accept() defer conn.Close() go rpc.ServeConn(conn) } } 客户端也需要做相应的修改，使用 tls.Dial 代替 rpc.DialHTTP 连接服务端，如果客户端不需要对服务端鉴权，那么可以设置 InsecureSkipVerify:true，即可跳过对服务端的鉴权，例如： // client/main.go import ( \"crypto/tls\" \"log\" \"net/rpc\" ) func main() { config := &tls.Config{ InsecureSkipVerify: true, } conn, _ := tls.Dial(\"tcp\", \"localhost:1234\", config) defer conn.Close() client := rpc.NewClient(conn) var result Result if err := client.Call(\"Cal.Square\", 12, &result); err != nil { log.Fatal(\"Failed to call Cal.Square. \", err) } log.Printf(\"%d^2 = %d\", result.Num, result.Ans) } 如果需要对服务器端鉴权，那么需要将服务端的证书添加到信任证书池中，如下： // client/main.go func main() { certPool := x509.NewCertPool() certBytes, err := ioutil.ReadFile(\"../server/server.crt\") if err != nil { log.Fatal(\"Failed to read server.crt\") } certPool.AppendCertsFromPEM(certBytes) config := &tls.Config{ RootCAs: certPool, } conn, _ := tls.Dial(\"tcp\", \"localhost:1234\", config) defer conn.Close() client := rpc.NewClient(conn) var result Result if err := client.Call(\"Cal.Square\", 12, &result); err != nil { log.Fatal(\"Failed to call Cal.Square. \", err) } log.Printf(\"%d^2 = %d\", result.Num, result.Ans) } 5.2 服务器端对客户端的鉴权 服务器端对客户端的鉴权是类似的，核心在于 tls.Config 的配置： 把对方的证书添加到自己的信任证书池 RootCAs(客户端配置)，ClientCAs(服务器端配置) 中。 创建链接时，配置自己的证书 Certificates。 客户端的 config 作如下修改： // client/main.go cert, _ := tls.LoadX509KeyPair(\"client.crt\", \"client.key\") certPool := x509.NewCertPool() certBytes, _ := ioutil.ReadFile(\"../server/server.crt\") certPool.AppendCertsFromPEM(certBytes) config := &tls.Config{ Certificates: []tls.Certificate{cert}, RootCAs: certPool, } 服务器端的 config 作如下修改： // server/main.go cert, _ := tls.LoadX509KeyPair(\"server.crt\", \"server.key\") certPool := x509.NewCertPool() certBytes, _ := ioutil.ReadFile(\"../client/client.crt\") certPool.AppendCertsFromPEM(certBytes) config := &tls.Config{ Certificates: []tls.Certificate{cert}, ClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: certPool, } 附：参考 Golang net/rpc 官方文档 - golang.org Golang TLS 配置 - github.com "},"GoLang/Go简明教程/06-Go-WebAssembly简明教程.html":{"url":"GoLang/Go简明教程/06-Go-WebAssembly简明教程.html","title":"WebAssembly(Wasm)简明教程","keywords":"","body":"datetime:2022/1/16 16:00 author:nzb Go WebAssembly (Wasm) 简明教程 1 WebAssembly 简介 WebAssembly是一种新的编码方式，可以在现代的网络浏览器中运行 － 它是一种低级的类汇编语言，具有紧凑的二进制格式，可以接近原生的性能运行，并为诸如C / C ++等语言提供一个编译目标，以便它们可以在Web上运行。它也被设计为可以与JavaScript共存，允许两者一起工作。 —— MDN web docs - mozilla.org 从 MDN 的介绍中，我们可以得出几个结论： WebAssembly 是一种二进制编码格式，而不是一门新的语言。 WebAssembly 不是为了取代 JavaScript，而是一种补充（至少现阶段是这样），结合 WebAssembly 的性能优势，很大可能集中在对性能要求高（例如游戏，AI），或是对交互体验要求高（例如移动端）的场景。 C/C++ 等语言可以编译 WebAssembly 的目标文件，也就是说，其他语言可以通过编译器支持，而写出能够在浏览器前端运行的代码。 Go 语言在 1.11 版本(2018年8月) 加入了对 WebAssembly (Wasm) 的原生支持，使用 Go 语言开发 WebAssembly 相关的应用变得更加地简单。Go 语言的内建支持是 Go 语言进军前端的一个重要的里程碑。在这之前，如果想使用 Go 语言开发前端，需要使用 GopherJS，GopherJS 是一个编译器，可以将 Go 语言转换成可以在浏览器中运行的 JavaScript 代码。新版本的 Go 则直接将 Go 代码编译为 wasm 二进制文件，而不再需要转为 JavaScript 代码。更巧的是，实现 GopherJS 和在 Go 语言中内建支持 WebAssembly 的是同一拨人。 Go 语言实现的函数可以直接导出供 JavaScript 代码调用，同时，Go 语言内置了 syscall/js 包，可以在 Go 语言中直接调用 JavaScript 函数，包括对 DOM 树的操作。 2 Hello World 接下来，我们使用 Go 语言实现一个最简单的程序，在网页上弹出 Hello World。 第一步，新建文件 main.go，使用 js.Global().get(‘alert’) 获取全局的 alert 对象，通过 Invoke 方法调用。等价于在 js 中调用 window.alert(\"Hello World\")。 // main.go package main import \"syscall/js\" func main() { alert := js.Global().Get(\"alert\") alert.Invoke(\"Hello World!\") } 第二步，将 main.go 编译为 static/main.wasm 如果启用了 GO MODULES，则需要使用 go mod init 初始化模块，或设置 GO111MODULE=auto。 $ GOOS=js GOARCH=wasm go build -o static/main.wasm 第三步，拷贝 wasm_exec.js (JavaScript 支持文件，加载 wasm 文件时需要) 到 static 文件夹 $ cp \"$(go env GOROOT)/misc/wasm/wasm_exec.js\" static 第四步，创建 index.html，引用 static/main.wasm 和 static/wasm_exec.js。 const go = new Go(); WebAssembly.instantiateStreaming(fetch(\"static/main.wasm\"), go.importObject) .then((result) => go.run(result.instance)); 第五步，使用 goexec 启动 Web 服务 如果没有安装 goexec，可用 go get -u github.com/shurcooL/goexec 安装，需要将 $GOBIN 或 $GOPATH/bin 加入环境变量 当前的目录结构如下： demo/ |--static/ |--wasm_exec.js |--main.wasm |--main.go |--index.html $ goexec 'http.ListenAndServe(`:9999`, http.FileServer(http.Dir(`.`)))' 浏览器访问 localhost:9999，则会有一个弹出窗口，上面写着 Hello World!。 为了避免每次编译都需要输入繁琐的命令，可将这个过程写在 Makefile 中 all: static/main.wasm static/wasm_exec.js goexec 'http.ListenAndServe(`:9999`, http.FileServer(http.Dir(`.`)))' static/wasm_exec.js: cp \"$(shell go env GOROOT)/misc/wasm/wasm_exec.js\" static static/main.wasm : main.go GO111MODULE=auto GOOS=js GOARCH=wasm go build -o static/main.wasm . 这样一个敲一下 make 就够了 3 注册函数(Register Functions) 在 Go 语言中调用 JavaScript 函数是一方面，另一方面，如果仅仅是使用 WebAssembly 替代性能要求高的模块，那么就需要注册函数，以便其他 JavaScript 代码调用。 假设我们需要注册一个计算斐波那契数列的函数，可以这么实现。 // main.go package main import \"syscall/js\" func fib(i int) int { if i == 0 || i == 1 { return 1 } return fib(i-1) + fib(i-2) } func fibFunc(this js.Value, args []js.Value) interface{} { return js.ValueOf(fib(args[0].Int())) } func main() { done := make(chan int, 0) js.Global().Set(\"fibFunc\", js.FuncOf(fibFunc)) fib 是一个普通的 Go 函数，通过递归计算第 i 个斐波那契数，接收一个 int 入参，返回值也是 int。 定义了 fibFunc 函数，为 fib 函数套了一个壳，从 args[0] 获取入参，计算结果用 js.ValueOf 包装，并返回。 使用 js.Global().Set() 方法，将注册函数 fibFunc 到全局，以便在浏览器中能够调用。 js.Value 可以将 Js 的值转换为 Go 的值，比如 args[0].Int()，则是转换为 Go 语言中的整型。js.ValueOf，则用来将 Go 的值，转换为 Js 的值。另外，注册函数的时候，使用 js.FuncOf 将函数转换为 Func 类型，只有 Func 类型的函数，才能在 JavaScript 中调用。可以认为这是 Go 与 JavaScript 之间的接口/约定。 js.Func() 接受一个函数类型作为其参数，该函数的定义必须是： func(this Value, args []Value) interface{} // this 即 JavaScript 中的 this // args 是在 JavaScript 中调用该函数的参数列表。 // 返回值需用 js.ValueOf 映射成 JavaScript 的值 在 main 函数中，创建了信道(chan) done，阻塞主协程(goroutine)。fibFunc 如果在 JavaScript 中被调用，会开启一个新的子协程执行。 A wrapped function triggered during a call from Go to JavaScript gets executed on the same goroutine. A wrapped function triggered by JavaScript’s event loop gets executed on an extra goroutine. —— FuncOf - golang.org 接下来，修改之前的 index.html，在其中添加一个输入框(num)，一个按钮(btn) 和一个文本框(ans，用来显示计算结果)，并给按钮添加了一个点击事件，调用 fibFunc，并将计算结果显示在文本框(ans)中。 ... Click 1 使用之前的命令重新编译 main.go，并在 9999 端口启动 Web 服务，如果我们已经将命令写在 Makefile 中了，只需要运行 make 即可。 接下来访问 localhost:9999，可以看到如下效果。输入一个数字，点击Click，计算结果显示在输入框下方。 4 操作 DOM 在上一个例子中，仅仅是注册了全局函数 fibFunc，事件注册，调用，对 DOM 元素的操作都是在 HTML 中通过原生的 JavaScript 函数实现的。这些事情，能不能全部在 Go 语言中完成呢？答案可以。 首先修改 index.html，删除事件注册部分和 对 DOM 元素的操作部分。 ... Click 1 修改 main.go： package main import ( \"strconv\" \"syscall/js\" ) func fib(i int) int { if i == 0 || i == 1 { return 1 } return fib(i-1) + fib(i-2) } var ( document = js.Global().Get(\"document\") numEle = document.Call(\"getElementById\", \"num\") ansEle = document.Call(\"getElementById\", \"ans\") btnEle = js.Global().Get(\"btn\") ) func fibFunc(this js.Value, args []js.Value) interface{} { v := numEle.Get(\"value\") if num, err := strconv.Atoi(v.String()); err == nil { ansEle.Set(\"innerHTML\", js.ValueOf(fib(num))) } return nil } func main() { done := make(chan int, 0) btnEle.Call(\"addEventListener\", \"click\", js.FuncOf(fibFunc)) 通过 js.Global().Get(\"btn\") 或 document.Call(\"getElementById\", \"num\") 两种方式获取到 DOM 元素。 btnEle 调用 addEventListener 为 btn 绑定点击事件 fibFunc。 在 fibFunc 中使用 numEle.Get(\"value\") 获取到 numEle 的值（字符串），转为整型并调用 fib 计算出结果。 ansEle 调用 Set(\"innerHTML\", ...) 渲染计算结果。 重新编译 main.go，访问 localhost:9999，效果与之前是一致的。 5 回调函数(Callback Functions) 在 JavaScript 中，异步+回调是非常常见的，比如请求一个 Restful API，注册一个回调函数，待数据获取到，再执行回调函数的逻辑，这个期间程序可以继续做其他的事情。Go 语言可以通过协程实现异步。 假设 fib 的计算非常耗时，那么可以启动注册一个回调函数，待 fib 计算完成后，再把计算结果显示出来。 我们先修改 main.go，使得 fibFunc 支持传入回调函数。 package main import ( \"syscall/js\" \"time\" ) func fib(i int) int { if i == 0 || i == 1 { return 1 } return fib(i-1) + fib(i-2) } func fibFunc(this js.Value, args []js.Value) interface{} { callback := args[len(args)-1] go func() { time.Sleep(3 * time.Second) v := fib(args[0].Int()) callback.Invoke(v) }() js.Global().Get(\"ans\").Set(\"innerHTML\", \"Waiting 3s...\") return nil } func main() { done := make(chan int, 0) js.Global().Set(\"fibFunc\", js.FuncOf(fibFunc)) 假设调用 fibFunc 时，回调函数作为最后一个参数，那么通过 args[len(args)-1] 便可以获取到该函数。这与其他类型参数的传递并无区别。 使用 go func() 启动子协程，调用 fib 计算结果，计算结束后，调用回调函数 callback，并将计算结果传递给回调函数，使用 time.Sleep() 模拟 3s 的耗时操作。 计算结果出来前，先在界面上显示 Waiting 3s... 接下来我们修改 index.html，为按钮添加点击事件，调用 fibFunc ... ans.innerHTML=v)\">Click 为 btn 注册了点击事件，第一个参数是待计算的数字，从 num 输入框获取。 第二个参数是一个回调函数，将参数 v 显示在 ans 文本框中。 接下来，重新编译 main.go，访问 localhost:9999，随便输入一个数字，点击 Click。页面会先显示 Waiting 3s...，3s过后显示计算结果。 6 进一步的尝试 6.1 工具框架 WebAssembly 的二进制分析工具 WebAssembly Code Explorer 使用NodeJs 或浏览器测试 Go Wasm 代码 Github Wiki 借鉴 Vue 实现的 Golang WebAssembly 前端框架 Vugu ，完全使用 Go，不用写任何的 JavaScript 代码。 6.2 Demo/项目 使用 Go Assembly 前端渲染的一些例子 jsgo 这个项目汇聚一些小而精的项目，包括 2048 ，俄罗斯方块 等游戏，还有证明Go 可以完整开发前端项目的 TodoMVC 6.3 相关文档 syscall/js 官方文档 - golang.org Go WebAssembly 官方文档 - github.com "},"GoLang/Go简明教程/07-Go-Test单元测试简明教程.html":{"url":"GoLang/Go简明教程/07-Go-Test单元测试简明教程.html","title":"Test单元测试简明教程","keywords":"","body":"datetime:2022/01/31 16:35 author:nzb Go Test 单元测试简明教程 1 如何写好单元测试 单元测试(Unit Tests, UT) 是一个优秀项目不可或缺的一部分，特别是在一些频繁变动和多人合作开发的项目中尤为重要。你或多或少都会有因为自己的提交，导致应用挂掉或服务宕机的经历。如果这个时候你的修改导致测试用例失败，你再重新审视自己的修改，发现之前的修改还有一些特殊场景没有包含，恭喜你减少了一次上库失误。也会有这样的情况，项目很大，启动环境很复杂，你优化了一个函数的性能，或是添加了某个新的特性，如果部署在正式环境上之后再进行测试，成本太高。对于这种场景，几个小小的测试用例或许就能够覆盖大部分的测试场景。而且在开发过程中，效率最高的莫过于所见即所得了，单元测试也能够帮助你做到这一点，试想一下，假如你一口气写完一千行代码，debug 的过程也不会轻松，如果在这个过程中，对于一些逻辑较为复杂的函数，同时添加一些测试用例，即时确保正确性，最后集成的时候，会是另外一番体验。 如何写好单元测试呢？ 首先，学会写测试用例。比如如何测试单个函数/方法；比如如何做基准测试；比如如何写出简洁精炼的测试代码；再比如遇到数据库访问等的方法调用时，如何 mock。 然后，写可测试的代码。高内聚，低耦合是软件工程的原则，同样，对测试而言，函数/方法写法不同，测试难度也是不一样的。职责单一，参数类型简单，与其他函数耦合度低的函数往往更容易测试。我们经常会说，“这种代码没法测试”，这种时候，就得思考函数的写法可不可以改得更好一些。为了代码可测试而重构是值得的。 接下来将介绍如何使用 Go 语言的标准库 testing 进行单元测试。 2 一个简单例子 Go 语言推荐测试文件和源代码文件放在一块，测试文件以 _test.go 结尾。比如，当前 package 有 calc.go 一个文件，我们想测试 calc.go 中的 Add 和 Mul 函数，那么应该新建 calc_test.go 作为测试文件。 example/ |--calc.go |--calc_test.go 假如 calc.go 的代码如下： package main func Add(a int, b int) int { return a + b } func Mul(a int, b int) int { return a * b } 那么 calc_test.go 中的测试用例可以这么写： package main import \"testing\" func TestAdd(t *testing.T) { if ans := Add(1, 2); ans != 3 { t.Errorf(\"1 + 2 expected be 3, but %d got\", ans) } if ans := Add(-10, -20); ans != -30 { t.Errorf(\"-10 + -20 expected be -30, but %d got\", ans) } } 测试用例名称一般命名为 Test 加上待测试的方法名。 测试用的参数有且只有一个，在这里是 t *testing.T。 基准测试(benchmark)的参数是 testing.B，TestMain 的参数是 testing.M 类型。 运行 go test，该 package 下所有的测试用例都会被执行。 $ go test ok example 0.009s 或 go test -v，-v 参数会显示每个用例的测试结果，另外 -cover 参数可以查看覆盖率。 $ go test -v === RUN TestAdd --- PASS: TestAdd (0.00s) === RUN TestMul --- PASS: TestMul (0.00s) PASS ok example 0.007s 如果只想运行其中的一个用例，例如 TestAdd，可以用 -run 参数指定，该参数支持通配符 *，和部分正则表达式，例如 ^、$。 $ go test -run TestAdd -v === RUN TestAdd --- PASS: TestAdd (0.00s) PASS ok example 0.007s 3 子测试(Subtests) 子测试是 Go 语言内置支持的，可以在某个测试用例中，根据测试场景使用 t.Run创建不同的子测试用例： // calc_test.go func TestMul(t *testing.T) { t.Run(\"pos\", func(t *testing.T) { if Mul(2, 3) != 6 { t.Fatal(\"fail\") } }) t.Run(\"neg\", func(t *testing.T) { if Mul(2, -3) != -6 { t.Fatal(\"fail\") } }) } 之前的例子测试失败时使用 t.Error/t.Errorf，这个例子中使用 t.Fatal/t.Fatalf，区别在于前者遇错不停，还会继续执行其他的测试用例，后者遇错即停。 运行某个测试用例的子测试： $ go test -run TestMul/pos -v === RUN TestMul === RUN TestMul/pos --- PASS: TestMul (0.00s) --- PASS: TestMul/pos (0.00s) PASS ok example 0.008s 对于多个子测试的场景，更推荐如下的写法(table-driven tests)： // calc_test.go func TestMul(t *testing.T) { cases := []struct { Name string A, B, Expected int }{ {\"pos\", 2, 3, 6}, {\"neg\", 2, -3, -6}, {\"zero\", 2, 0, 0}, } for _, c := range cases { t.Run(c.Name, func(t *testing.T) { if ans := Mul(c.A, c.B); ans != c.Expected { t.Fatalf(\"%d * %d expected %d, but %d got\", c.A, c.B, c.Expected, ans) } }) } } 所有用例的数据组织在切片 cases 中，看起来就像一张表，借助循环创建子测试。这样写的好处有： 新增用例非常简单，只需给 cases 新增一条测试数据即可。 测试代码可读性好，直观地能够看到每个子测试的参数和期待的返回值。 用例失败时，报错信息的格式比较统一，测试报告易于阅读。 如果数据量较大，或是一些二进制数据，推荐使用相对路径从文件中读取。 4 帮助函数(helpers) 对一些重复的逻辑，抽取出来作为公共的帮助函数(helpers)，可以增加测试代码的可读性和可维护性。 借助帮助函数，可以让测试用例的主逻辑看起来更清晰。 例如，我们可以将创建子测试的逻辑抽取出来： // calc_test.go package main import \"testing\" type calcCase struct{ A, B, Expected int } func createMulTestCase(t *testing.T, c *calcCase) { // t.Helper() if ans := Mul(c.A, c.B); ans != c.Expected { t.Fatalf(\"%d * %d expected %d, but %d got\", c.A, c.B, c.Expected, ans) } } func TestMul(t *testing.T) { createMulTestCase(t, &calcCase{2, 3, 6}) createMulTestCase(t, &calcCase{2, -3, -6}) createMulTestCase(t, &calcCase{2, 0, 1}) // wrong case } 在这里，我们故意创建了一个错误的测试用例，运行 go test，用例失败，会报告错误发生的文件和行号信息： $ go test --- FAIL: TestMul (0.00s) calc_test.go:11: 2 * 0 expected 1, but 0 got FAIL exit status 1 FAIL example 0.007s 可以看到，错误发生在第11行，也就是帮助函数 createMulTestCase 内部。18, 19, 20行都调用了该方法，我们第一时间并不能够确定是哪一行发生了错误。有些帮助函数还可能在不同的函数中被调用，报错信息都在同一处，不方便问题定位。因此，Go 语言在 1.9 版本中引入了 t.Helper()，用于标注该函数是帮助函数，报错时将输出帮助函数调用者的信息，而不是帮助函数的内部信息。 修改 createMulTestCase，调用 t.Helper() func createMulTestCase(c *calcCase, t *testing.T) { t.Helper() t.Run(c.Name, func(t *testing.T) { if ans := Mul(c.A, c.B); ans != c.Expected { t.Fatalf(\"%d * %d expected %d, but %d got\", c.A, c.B, c.Expected, ans) } }) } 运行 go test，报错信息如下，可以非常清晰地知道，错误发生在第 20 行。 $ go test --- FAIL: TestMul (0.00s) calc_test.go:20: 2 * 0 expected 1, but 0 got FAIL exit status 1 FAIL example 0.006s 关于 helper 函数的 2 个建议： 不要返回错误， 帮助函数内部直接使用 t.Error 或 t.Fatal 即可，在用例主逻辑中不会因为太多的错误处理代码，影响可读性。 调用 t.Helper() 让报错信息更准确，有助于定位。 5 setup 和 teardown 如果在同一个测试文件中，每一个测试用例运行前后的逻辑是相同的，一般会写在 setup 和 teardown 函数中。例如执行前需要实例化待测试的对象，如果这个对象比较复杂，很适合将这一部分逻辑提取出来；执行后，可能会做一些资源回收类的工作，例如关闭网络连接，释放文件等。标准库 testing 提供了这样的机制： func setup() { fmt.Println(\"Before all tests\") } func teardown() { fmt.Println(\"After all tests\") } func Test1(t *testing.T) { fmt.Println(\"I'm test1\") } func Test2(t *testing.T) { fmt.Println(\"I'm test2\") } func TestMain(m *testing.M) { setup() code := m.Run() teardown() os.Exit(code) } 在这个测试文件中，包含有2个测试用例，Test1 和 Test2。 如果测试文件中包含函数 TestMain，那么生成的测试将调用 TestMain(m)，而不是直接运行测试。 调用 m.Run() 触发所有测试用例的执行，并使用 os.Exit() 处理返回的状态码，如果不为0，说明有用例失败。 因此可以在调用 m.Run() 前后做一些额外的准备(setup)和回收(teardown)工作。 执行 go test，将会输出 $ go test Before all tests I'm test1 I'm test2 PASS After all tests ok example 0.006s 6 网络测试(Network) 6.1 TCP/HTTP 假设需要测试某个 API 接口的 handler 能够正常工作，例如 helloHandler func helloHandler(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) } 那我们可以创建真实的网络连接进行测试： // test code import ( \"io/ioutil\" \"net\" \"net/http\" \"testing\" ) func handleError(t *testing.T, err error) { t.Helper() if err != nil { t.Fatal(\"failed\", err) } } func TestConn(t *testing.T) { ln, err := net.Listen(\"tcp\", \"127.0.0.1:0\") handleError(t, err) defer ln.Close() http.HandleFunc(\"/hello\", helloHandler) go http.Serve(ln, nil) resp, err := http.Get(\"http://\" + ln.Addr().String() + \"/hello\") handleError(t, err) defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) handleError(t, err) if string(body) != \"hello world\" { t.Fatal(\"expected hello world, but got\", string(body)) } } net.Listen(\"tcp\", \"127.0.0.1:0\")：监听一个未被占用的端口，并返回 Listener。 调用 http.Serve(ln, nil) 启动 http 服务。 使用 http.Get 发起一个 Get 请求，检查返回值是否正确。 尽量不对 http 和 net 库使用 mock，这样可以覆盖较为真实的场景。 6.2 httptest 针对 http 开发的场景，使用标准库 net/http/httptest 进行测试更为高效。 上述的测试用例改写如下： // test code import ( \"io/ioutil\" \"net/http\" \"net/http/httptest\" \"testing\" ) func TestConn(t *testing.T) { req := httptest.NewRequest(\"GET\", \"http://example.com/foo\", nil) w := httptest.NewRecorder() helloHandler(w, req) bytes, _ := ioutil.ReadAll(w.Result().Body) if string(bytes) != \"hello world\" { t.Fatal(\"expected hello world, but got\", string(bytes)) } } 使用 httptest 模拟请求对象(req)和响应对象(w)，达到了相同的目的。 7 Benchmark 基准测试 基准测试用例的定义如下： func BenchmarkName(b *testing.B){ // ... } 函数名必须以 Benchmark 开头，后面一般跟待测试的函数名 参数为 b *testing.B。 执行基准测试时，需要添加 -bench 参数。 例如： func BenchmarkHello(b *testing.B) { for i := 0; i $ go test -benchmem -bench . ... BenchmarkHello-16 15991854 71.6 ns/op 5 B/op 1 allocs/op ... 基准测试报告每一列值对应的含义如下： type BenchmarkResult struct { N int // 迭代次数 T time.Duration // 基准测试花费的时间 Bytes int64 // 一次迭代处理的字节数 MemAllocs uint64 // 总的分配内存的次数 MemBytes uint64 // 总的分配内存的字节数 } 如果在运行前基准测试需要一些耗时的配置，则可以使用 b.ResetTimer() 先重置定时器，例如： func BenchmarkHello(b *testing.B) { ... // 耗时操作 b.ResetTimer() for i := 0; i 使用 RunParallel 测试并发性能 func BenchmarkParallel(b *testing.B) { templ := template.Must(template.New(\"test\").Parse(\"Hello, { {.} }!\")) b.RunParallel(func(pb *testing.PB) { var buf bytes.Buffer for pb.Next() { // 所有 goroutine 一起，循环一共执行 b.N 次 buf.Reset() templ.Execute(&buf, \"World\") } }) } $ go test -benchmem -bench . ... BenchmarkParallel-16 3325430 375 ns/op 272 B/op 8 allocs/op ... 参考链接 testing - golang.org Advanced Testing in Go - sourcegraph.com "},"GoLang/Go简明教程/08-Go-Mock简明教程.html":{"url":"GoLang/Go简明教程/08-Go-Mock简明教程.html","title":"Mock(gomock)简明教程","keywords":"","body":"datetime:2022/02/01 15::02 author:nzb Go Mock (gomock)简明教程 1 gomock 简介 上一篇文章 Go Test 单元测试简明教程 介绍了 Go 语言中单元测试的常用方法，包括子测试(subtests)、表格驱动测试(table-driven tests)、帮助函数(helpers)、网络测试和基准测试(Benchmark)等。这篇文章介绍一种新的测试方法，mock/stub 测试，当待测试的函数/对象的依赖关系很复杂，并且有些依赖不能直接创建，例如数据库连接、文件I/O等。这种场景就非常适合使用 mock/stub 测试。简单来说，就是用 mock 对象模拟依赖项的行为。 GoMock is a mocking framework for the Go programming language. It integrates well with Go’s built-in testing package, but can be used in other contexts too. gomock 是官方提供的 mock 框架，同时还提供了 mockgen 工具用来辅助生成测试代码。 使用如下命令即可安装： go get -u github.com/golang/mock/gomock go get -u github.com/golang/mock/mockgen 2 一个简单的 Demo // db.go type DB interface { Get(key string) (int, error) } func GetFromDB(db DB, key string) int { if value, err := db.Get(key); err == nil { return value } return -1 } 假设 DB 是代码中负责与数据库交互的部分(在这里用 map 模拟)，测试用例中不能创建真实的数据库连接。这个时候，如果我们需要测试 GetFromDB 这个函数内部的逻辑，就需要 mock 接口 DB。 第一步：使用 mockgen 生成 db_mock.go。一般传递三个参数。包含需要被mock的接口得到源文件source，生成的目标文件destination，包名package。 $ mockgen -source=db.go -destination=db_mock.go -package=main 第二步：新建 db_test.go，写测试用例。 func TestGetFromDB(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() // 断言 DB.Get() 方法是否被调用 m := NewMockDB(ctrl) m.EXPECT().Get(gomock.Eq(\"Tom\")).Return(100, errors.New(\"not exist\")) if v := GetFromDB(m, \"Tom\"); v != -1 { t.Fatal(\"expected -1, but got\", v) } } 这个测试用例有2个目的，一是使用 ctrl.Finish() 断言 DB.Get() 被是否被调用，如果没有被调用，后续的 mock 就失去了意义； 二是测试方法 GetFromDB() 的逻辑是否正确(如果 DB.Get() 返回 error，那么 GetFromDB() 返回 -1)。 NewMockDB() 的定义在 db_mock.go 中，由 mockgen 自动生成。 最终的代码结构如下： project/ |--db.go |--db_mock.go // generated by mockgen |--db_test.go 执行测试： $ go test . -cover -v === RUN TestGetFromDB --- PASS: TestGetFromDB (0.00s) PASS coverage: 81.2% of statements ok example 0.008s coverage: 81.2% of statements 3 打桩(stubs) 在上面的例子中，当 Get() 的参数为 Tom，则返回 error，这称之为打桩(stub)，有明确的参数和返回值是最简单打桩方式。除此之外，检测调用次数、调用顺序，动态设置返回值等方式也经常使用。 3.1 参数(Eq, Any, Not, Nil) m.EXPECT().Get(gomock.Eq(\"Tom\")).Return(0, errors.New(\"not exist\")) m.EXPECT().Get(gomock.Any()).Return(630, nil) m.EXPECT().Get(gomock.Not(\"Sam\")).Return(0, nil) m.EXPECT().Get(gomock.Nil()).Return(0, errors.New(\"nil\")) Eq(value) 表示与 value 等价的值。 Any() 可以用来表示任意的入参。 Not(value) 用来表示非 value 以外的值。 Nil() 表示 None 值 3.2 返回值(Return, DoAndReturn) m.EXPECT().Get(gomock.Not(\"Sam\")).Return(0, nil) m.EXPECT().Get(gomock.Any()).Do(func(key string) { t.Log(key) }) m.EXPECT().Get(gomock.Any()).DoAndReturn(func(key string) (int, error) { if key == \"Sam\" { return 630, nil } return 0, errors.New(\"not exist\") }) Return 返回确定的值 Do Mock 方法被调用时，要执行的操作吗，忽略返回值。 DoAndReturn 可以动态地控制返回值。 3.3 调用次数(Times) func TestGetFromDB(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() m := NewMockDB(ctrl) m.EXPECT().Get(gomock.Not(\"Sam\")).Return(0, nil).Times(2) GetFromDB(m, \"ABC\") GetFromDB(m, \"DEF\") } Times() 断言 Mock 方法被调用的次数。 MaxTimes() 最大次数。 MinTimes() 最小次数。 AnyTimes() 任意次数（包括 0 次）。 3.4 调用顺序(InOrder) func TestGetFromDB(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() // 断言 DB.Get() 方法是否被调用 m := NewMockDB(ctrl) o1 := m.EXPECT().Get(gomock.Eq(\"Tom\")).Return(0, errors.New(\"not exist\")) o2 := m.EXPECT().Get(gomock.Eq(\"Sam\")).Return(630, nil) gomock.InOrder(o1, o2) GetFromDB(m, \"Tom\") GetFromDB(m, \"Sam\") } 4 如何编写可 mock 的代码 写可测试的代码与写好测试用例是同等重要的，如何写可 mock 的代码呢？ mock 作用的是接口，因此将依赖抽象为接口，而不是直接依赖具体的类。 不直接依赖的实例，而是使用依赖注入降低耦合性。 在软件工程中，依赖注入的意思为，给予调用方它所需要的事物。 “依赖”是指可被方法调用的事物。依赖注入形式下，调用方不再直接指使用“依赖”，取而代之是“注入” 。“注入”是指将“依赖”传递给调用方的过程。在“注入”之后，调用方才会调用该“依赖”。传递依赖给调用方，而不是让让调用方直接获得依赖，这个是该设计的根本需求。 依赖注入 - Wikipedia 如果 GetFromDB() 方法长这个样子 func GetFromDB(key string) int { db := NewDB() if value, err := db.Get(key); err == nil { return value } return -1 } 对 DB 接口的 mock 并不能作用于 GetFromDB() 内部，这样写是没办法进行测试的。那如果将接口 db DB 通过参数传递到 GetFromDB()，那么就可以轻而易举地传入 Mock 对象了。 "},"GoLang/Go简明教程/09-Go-Mmap-文件内存映射简明教程.html":{"url":"GoLang/Go简明教程/09-Go-Mmap-文件内存映射简明教程.html","title":"Mmap-文件内存映射简明教程","keywords":"","body":"datetime:2022/02/01 18:53 author:nzb Go Mmap 文件内存映射简明教程 1 mmap 简介 In computing, mmap is a POSIX-compliant Unix system call that maps files or devices into memory. It is a method of memory-mapped file I/O. mmap - wikipedia.org 简单理解，mmap 是一种将文件/设备映射到内存的方法，实现文件的磁盘地址和进程虚拟地址空间中的一段虚拟地址的一一映射关系。也就是说，可以在某个进程中通过操作这一段映射的内存，实现对文件的读写等操作。修改了这一段内存的内容，文件对应位置的内容也会同步修改，而读取这一段内存的内容，相当于读取文件对应位置的内容。 mmap 另一个非常重要的特性是：减少内存的拷贝次数。在 linux 系统中，文件的读写操作通常通过 read 和 write 这两个系统调用来实现，这个过程会产生频繁的内存拷贝。比如 read 函数就涉及了 2 次内存拷贝： 操作系统读取磁盘文件到页缓存； 从页缓存将数据拷贝到 read 传递的 buf 中(例如进程中创建的byte数组)。 mmap 只需要一次拷贝。即操作系统读取磁盘文件到页缓存，进程内部直接通过指针方式修改映射的内存。因此 mmap 特别适合读写频繁的场景，既减少了内存拷贝次数，提高效率，又简化了操作。KV数据库 bbolt 就使用了这个方法持久化数据。 2 标准库 mmap Go 语言标准库 golang.org/x/exp/mmap 仅实现了 read 操作，后续能否支持 write 操作未知。使用场景非常有限。看一个简单的例子： 从第4个byte开始，读取 tmp.txt 2个byte的内容。 package main import ( \"fmt\" \"golang.org/x/exp/mmap\" ) func main() { at, _ := mmap.Open(\"./tmp.txt\") buff := make([]byte, 2) _, _ = at.ReadAt(buff, 4) _ = at.Close() fmt.Println(string(buff)) } $ echo \"abcdefg\" > tmp.txt $ go run . ef 如果使用 os.File 操作，代码几乎是一样的，os.File 还支持写操作 WriteAt： package main import ( \"fmt\" \"os\" ) func main() { f, _ := os.OpenFile(\"tmp.txt\", os.O_CREATE|os.O_RDWR, 0644) _, _ = f.WriteAt([]byte(\"abcdefg\"), 0) buff := make([]byte, 2) _, _ = f.ReadAt(buff, 4) _ = f.Close() fmt.Println(string(buff)) } 3 mmap(linux) 如果要支持 write 操作，那么就需要直接调用 mmap 的系统调用来实现了。Linux 和 Windows 都支持 mmap，但接口有所不同。对于 linux 系统，mmap 方法定义如下： func Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error) 每个参数的含义分别是： - fd：待映射的文件描述符。 - offset：映射到内存区域的起始位置，0 表示由内核指定内存地址。 - length：要映射的内存区域的大小。 - prot：内存保护标志位，可以通过或运算符`|`组合 - PROT_EXEC // 页内容可以被执行 - PROT_READ // 页内容可以被读取 - PROT_WRITE // 页可以被写入 - PROT_NONE // 页不可访问 - flags：映射对象的类型，常用的是以下两类 - MAP_SHARED // 共享映射，写入数据会复制回文件, 与映射该文件的其他进程共享。 - MAP_PRIVATE // 建立一个写入时拷贝的私有映射，写入数据不影响原文件。 首先定义2个常量和数据类型Demo： const defaultMaxFileSize = 1 内存有换页机制，映射的物理内存可以远小于文件。 Demo结构体由3个字段构成，file 即文件描述符，data 是映射内存的起始地址，dataRef 用于后续取消映射。 定义 mmap, grow, ummap 三个方法： func (demo *Demo) mmap() { b, err := syscall.Mmap(int(demo.file.Fd()), 0, defaultMemMapSize, syscall.PROT_WRITE|syscall.PROT_READ, syscall.MAP_SHARED) _assert(err == nil, \"failed to mmap\", err) demo.dataRef = b demo.data = (*[defaultMaxFileSize]byte)(unsafe.Pointer(&b[0])) } func (demo *Demo) grow(size int64) { if info, _ := demo.file.Stat(); info.Size() >= size { return } _assert(demo.file.Truncate(size) == nil, \"failed to truncate\") } func (demo *Demo) munmap() { _assert(syscall.Munmap(demo.dataRef) == nil, \"failed to munmap\") demo.data = nil demo.dataRef = nil } mmap 传入的内存保护标志位为 syscall.PROT_WRITE|syscall.PROT_READ，即可读可写，映射类型为 syscall.MAP_SHARED，即对内存的修改会同步到文件。 syscall.Mmap 返回的是一个切片对象，需要从该切片中获取到内存的起始地址，并转换为可操作的 byte 数组，byte数组的长度为 defaultMaxFileSize。 grow 用于修改文件的大小，Linux 不允许操作超过文件大小之外的内存地址。例如文件大小为 4K，可访问的地址是data[0~4095]，如果访问 data[10000] 会报错。 munmap 用于取消映射。 在文件中写入 hello, world! func main() { _ = os.Remove(\"tmp.txt\") f, _ := os.OpenFile(\"tmp.txt\", os.O_CREATE|os.O_RDWR, 0644) demo := &Demo{file: f} demo.grow(1) demo.mmap() defer demo.munmap() msg := \"hello world!\" demo.grow(int64(len(msg) * 2)) for i, v := range msg { demo.data[2*i] = byte(v) demo.data[2*i+1] = byte(' ') } } 在调用 mmap 之前，调用了 grow(1)，因为在 mmap 中使用 &b[0] 获取到映射内存的起始地址，所以文件大小至少为 1 byte。 接下来，便是通过直接操作 demo.data，修改文件内容了。 运行：$ go run . $ cat tmp.txt h e l l o w o r l d ! 4 mmap(Windows) 相对于 Linux，Windows 上 mmap 的使用要复杂一些。 func (demo *Demo) mmap() { h, err := syscall.CreateFileMapping(syscall.Handle(demo.file.Fd()), nil, syscall.PAGE_READWRITE, 0, defaultMemMapSize, nil) _assert(h != 0, \"failed to map\", err) addr, err := syscall.MapViewOfFile(h, syscall.FILE_MAP_WRITE, 0, 0, uintptr(defaultMemMapSize)) _assert(addr != 0, \"MapViewOfFile failed\", err) err = syscall.CloseHandle(syscall.Handle(h)); _assert(err == nil, \"CloseHandle failed\") // Convert to a byte array. demo.data = (*[defaultMaxFileSize]byte)(unsafe.Pointer(addr)) } func (demo *Demo) munmap() { addr := (uintptr)(unsafe.Pointer(&demo.data[0])) _assert(syscall.UnmapViewOfFile(addr) == nil, \"failed to munmap\") } 需要 CreateFileMapping 和 MapViewOfFile 两步才能完成内存映射。MapViewOfFile 返回映射成功的内存地址，因此可以直接将该地址转换成 byte 数组。 Windows 对文件的大小没有要求，直接操作内存data，文件大小会自动发生改变。 使用时无需关注文件的大小。 func main() { _ = os.Remove(\"tmp.txt\") f, _ := os.OpenFile(\"tmp.txt\", os.O_CREATE|os.O_RDWR, 0644) demo := &Demo{file: f} demo.mmap() defer demo.munmap() msg := \"hello world!\" for i, v := range msg { demo.data[2*i] = byte(v) demo.data[2*i+1] = byte(' ') } } $ go run . $ cat .\\tmp.txt h e l l o w o r l d ! 参考链接 edsrzf/mmap-go - github.com golang 官方文档 syscall - golang.org "},"GoLang/Go简明教程/10-Go-Context并发编程简明教程.html":{"url":"GoLang/Go简明教程/10-Go-Context并发编程简明教程.html","title":"Context并发编程简明教程","keywords":"","body":"datetime:2022/02/01 19:13 author:nzb Go Context 并发编程简明教程 1 为什么需要 Context WaitGroup 和信道(channel)是常见的 2 种并发控制的方式。 如果并发启动了多个子协程，需要等待所有的子协程完成任务，WaitGroup 非常适合于这类场景，例如下面的例子： var wg sync.WaitGroup func doTask(n int) { time.Sleep(time.Duration(n)) fmt.Printf(\"Task %d Done\\n\", n) wg.Done() } func main() { for i := 0; i wg.Wait() 会等待所有的子协程任务全部完成，所有子协程结束后，才会执行 wg.Wait() 后面的代码。 Task 3 Done Task 1 Done Task 2 Done All Task Done WaitGroup 只是傻傻地等待子协程结束，但是并不能主动通知子协程退出。假如开启了一个定时轮询的子协程，有没有什么办法，通知该子协程退出呢？这种场景下，可以使用 select+chan 的机制。 var stop chan bool func reqTask(name string) { for { select { case 子协程使用 for 循环定时轮询，如果 stop 信道有值，则退出，否则继续轮询。 worker1 send request worker1 send request worker1 send request stop worker1 更复杂的场景如何做并发控制呢？比如子协程中开启了新的子协程，或者需要同时控制多个子协程。这种场景下，select+chan的方式就显得力不从心了。 Go 语言提供了 Context 标准库可以解决这类场景的问题，Context 的作用和它的名字很像，上下文，即子协程的下上文。Context 有两个主要的功能： 通知子协程退出（正常退出，超时退出等）； 传递必要的参数。 2 context.WithCancel context.WithCancel() 创建可取消的 Context 对象，即可以主动通知子协程退出。 2.1 控制单个协程 使用 Context 改写上述的例子，效果与 select+chan 相同。 func reqTask(ctx context.Context, name string) { for { select { case context.Backgroud() 创建根 Context，通常在 main 函数、初始化和测试代码中创建，作为顶层 Context。 context.WithCancel(parent) 创建可取消的子 Context，同时返回函数 cancel。 在子协程中，使用 select 调用 判断是否需要退出。 主协程中，调用 cancel() 函数通知子协程退出。 2.2 控制多个协程 func main() { ctx, cancel := context.WithCancel(context.Background()) go reqTask(ctx, \"worker1\") go reqTask(ctx, \"worker2\") time.Sleep(3 * time.Second) cancel() time.Sleep(3 * time.Second) } 为每个子协程传递相同的上下文 ctx 即可，调用 cancel() 函数后该 Context 控制的所有子协程都会退出。 worker1 send request worker2 send request worker1 send request worker2 send request worker1 send request worker2 send request stop worker1 stop worker2 3 context.WithValue 如果需要往子协程中传递参数，可以使用 context.WithValue()。 type Options struct{ Interval time.Duration } func reqTask(ctx context.Context, name string) { for { select { case context.WithValue() 创建了一个基于 ctx 的子 Context，并携带了值 options。 在子协程中，使用 ctx.Value(\"options\") 获取到传递的值，读取/修改该值。 4 context.WithTimeout 如果需要控制子协程的执行时间，可以使用 context.WithTimeout 创建具有超时通知机制的 Context 对象。 func main() { ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) go reqTask(ctx, \"worker1\") go reqTask(ctx, \"worker2\") time.Sleep(3 * time.Second) fmt.Println(\"before cancel\") cancel() time.Sleep(3 * time.Second) } WithTimeout()的使用与 WithCancel() 类似，多了一个参数，用于设置超时时间。执行结果如下： worker2 send request worker1 send request worker1 send request worker2 send request stop worker2 stop worker1 before cancel 因为超时时间设置为 2s，但是 main 函数中，3s 后才会调用 cancel()，因此，在调用 cancel() 函数前，子协程因为超时已经退出了。 5 context.WithDeadline 超时退出可以控制子协程的最长执行时间，那 context.WithDeadline() 则可以控制子协程的最迟退出时间。 func reqTask(ctx context.Context, name string) { for { select { case WithDeadline 用于设置截止时间。在这个例子中，将截止时间设置为1s后，cancel() 函数在 3s 后调用，因此子协程将在调用 cancel() 函数前结束。 在子协程中，可以通过 ctx.Err() 获取到子协程退出的错误原因。 运行结果如下： worker2 send request worker1 send request stop worker2 context deadline exceeded stop worker1 context deadline exceeded before cancel 可以看到，子协程 worker1 和 worker2 均是因为截止时间到了而退出。 "},"GoLang/GoLang基础/01-GoLang发展史.html":{"url":"GoLang/GoLang基础/01-GoLang发展史.html","title":"GoLang发展史","keywords":"","body":"datetime:2020/8/18 10:53 author:nzb Go语言发展简史 开发文档 https://studygolang.com/pkgdoc Go语言核心开发团队 Ken Thompson（肯·汤普森）：1983年图灵奖（Turing Award）和1998年美国国家技术奖（National Medal of Technology）得主。他与Dennis Ritchie是Unix的原创者。Thompson也发明了后来衍生出C语言的B程序语言，同时也是C语言的主要发明人。 Rob Pike（罗布-派克）：曾是贝尔实验室（Bell Labs）的Unix团队，和Plan 9操作系统计划的成员。 他与Thompson共事多年，并共创出广泛使用的UTF-8字元编码。 Robert Griesemer：曾协助制作Java的HotSpot编译器，和Chrome浏览器的JavaScript引擎V8。 Google为什么要创建Go 计算机硬件技术更新频繁，性能提高很快。目前主流的编程语言发展明显落后于硬件，不能合理利用多核多CPU的优势提升软件系统性能。 软件系统复杂度越来越高，维护成本越来越高，目前缺乏一个足够简洁高效的编程语言。 现有编程语言存在：风格不统一、计算能力不够、处理大并发不够好 企业运行维护很多c/c++的项目，c/c++程序运行速度虽然很快，但是编译速度确很慢，同时还存在内存泄漏的一系列的困扰需要解决。 Go语言发展历史 2007年，谷歌工程师Rob Pike，Ken Thompson和Robert Griesemer开始设计一门全新的语言，这是Go语言的最初原型。 2009年11月10日，Google将Go语言以开放源代码的方式向全球发布。 2015年8月19日，Go1.5版发布，本次更新中移除了”最后残余的c代码” 2017年2月17日，Go语言Go1.8版发布。 2017年8月24日，Go语言Go1.9版发布。 2018年2月16日，Go语言Go1.10版发布。 Go语言的特点 Go语言保证了既能到达静态编译语言的安全和性能，又达到了动态语言开发维护的高效率，使用一个表达式来形容Go语言：Go=C+Python，说明Go语言既有C静态语言程序的运行速度，又能达到Python动态语言的快速开发。 从c语言中继承了很多理念，包括表达式语法，控制结构，基础数据类型，调用参数传值，指针等等，也保留了和C语言一样的编译执行方式及弱化的指针。 // go语言的指针使用特点 func testPtr(num *int) { *num = 20 } 引入包的概念，用于组织程序结构，Go语言的一个文件都要归属于一个包，而不能单独存在。 垃圾回收机制，内存自动回收，不需开发人员管理 【稍微不注意就会出现内存泄漏】 天然并发【重要特点】 从语言层面支持并发，实现简单 goroutine，轻量级线程，可实现大并发处理，高效利用多核。 基于CPS并发模型（Communicating Sequential Processes）实现 吸收了管道通信机制，形成go语言特有的管道channel，通过管道channel，可以实现不同的goroute之间的相互通信 函数返回多个值（实例代码） 新的创新：比如切片slice，延时执行defer等 Hello Go 我们写一个最简单的入门代码，在控制台输出hello go！ package main // fmt包中提供格式化，输入和输出的函数 import \"fmt\" func main() { fmt.Println(\"hello go!\") } Golang执行流程分析 我们可以通过以下命令来进行操作 go build hello.go -> hello.exe go run hello.go 两种执行流程分析 如果我们先编译生成了可执行文件，那么我们可以将该可执行文件拷贝到没有go开发环境的机器上，然可以运行 如果我们是直接go rungo源代码，那么如果要在另外一个机器上这么运行，也需要go开发环境，否则无法执行。 在编译时，编译器会将程序运行依赖的库文件包含在可执行文件中，所以，可执行文件变大了很多。 什么是编译 有了go源文件，通过编译器将其编译成机器可以识别的二进制码文件。 在该源文件目录下，通过go build 对hello.go文件进行编译。可以指定生成的可执行文件名，在windows下必须是.exe后缀。 如果程序没有错误，没有任何提示，会在当前目录下会出现一个可执行文件（windows下是.exe Linux下是一个可执行文件），该文件是二进制码文件，也是可以执行的程序。 如果程序有错误，编译时，会在错误的那行报错。 Go语言代码风格 代码每一行结束后不用写分号（：） 运算符左右建议各加一个空格 Go语言程序员推荐使用驼峰式命名 强制的代码风格 左括号必须紧接着语句不换行，这个特性刚开始会使开发者不习惯，但随着对Go语言的不断熟悉，就会发现风格统一让大家在阅读代码时把注意力集中在解决问题上，而不是代码风格上 Go语言开发注意事项 Go源文件以“go”为扩展名 Go应用程序的执行入口是main()方法 Go语言严格区分大小写。 Go方法由一条条语句构成，每个语句后不需要分号（Go语言会在每行后自动加分号），这也体现出Golang的简洁性。 Go编译器是一行行进行编译的，因此我们一行就写一条语句，不能把多条语句写在同一个，否则报错 Go语言定义的变量或者import的包如果没有使用到，代码不能编译通过 大括号都是成对出现的，缺一不可。 Go语言中的转义字符 GoLang常用的转义字符（escape char） \\t：一个制表位，实现对齐的功能 \\n：换行符 \\：一个\\ \\r：一个回车 "},"GoLang/GoLang基础/02-打印输出.html":{"url":"GoLang/GoLang基础/02-打印输出.html","title":"打印输出","keywords":"","body":"datetime:2020/8/17 15:17 author:nzb 打印输出和键盘输入 1、打印输出 1.1、fmt包 import 'fmt' 1.2、常用打印函数 打印：fmt.Print() 格式化打印：fmt.Printf 格式化打印中的常用占位符 占位符 说明 %v 原样输出 %T 打印类型 %t bool类型 %s 字符串 %f 浮点 %d 10进制的整数 %b 2进制的整数 %o 8进制 %x,%X 16进制%x：0-9，a-f%X：0-9，A-F %c 打印字符 %p 打印地址 ... ... 打印后换行：fmt.Println() 示例代码 示例 package main import \"fmt\" func main(){ a := 100 b := 3.14 c := true d := \"Hello Golang\" e := `Golang` f := 'A' fmt.Printf(\"--------------Print--------------\\n\") fmt.Print(a, b, c, d, e, f) fmt.Printf(\"\\n--------------Printf格式化输出--------------\\n\") fmt.Printf(\"%T, %b\\n\", a, a) fmt.Printf(\"%T, %f\", b, b) fmt.Printf(\"%T,%t\\n\", c, c) fmt.Printf(\"%T,%s\\n\", d, d) fmt.Printf(\"%T,%s\\n\", e, e) fmt.Printf(\"%T,%d,%c\\n\", f, f, f) fmt.Printf(\"\\n--------------Printf原样输出--------------\\n\") fmt.Printf(\"%v\\n\", a) fmt.Printf(\"%v\\n\", b) fmt.Printf(\"%v\\n\", c) fmt.Printf(\"%v\\n\", d) fmt.Printf(\"%v\\n\", e) fmt.Printf(\"%v\\n\", f) fmt.Printf(\"\\n--------------Println--------------\\n\") fmt.Println(a) fmt.Println(b) } 输出 --------------Print-------------- 100 3.14 trueHello GolangGolang65 --------------Printf格式化输出-------------- int, 1100100 float64, 3.140000bool,true string,Hello Golang string,Golang int32,65,A --------------Printf原样输出-------------- 100 3.14 true Hello Golang Golang 65 --------------Println-------------- 100 3.14 2、键盘输入 fmt.Scan() fmt.Scanf() fmt.Scanln() 示例代码 示例 package main import \"fmt\" func main(){ var x int var y float64 fmt.Println(\"请输入一个整数，一个浮点数：\") fmt.Scanln(&x, &y) //读取键盘的输入，通过操作地址，赋值给x和y 阻塞式 fmt.Printf(\"x的数值：%d, y的数值：%f\\n\", x, y) fmt.Scanf(\"%d, %f\", &x, &y) fmt.Printf(\"x:%d, y:%f\\n\", x, y) } 输出 请输入一个整数，一个浮点数： x的数值：12, y的数值：34.000000 x:21, y:34.000000 "},"GoLang/GoLang基础/03-变量和常量.html":{"url":"GoLang/GoLang基础/03-变量和常量.html","title":"变量和常量","keywords":"","body":"datetime:2020/8/18 10:57 author:nzb Go语言中的变量和常量 1、Go语言中变量的声明 Go语言变量是由字母、数字、下划线组成，其中首个字符不能为数字。Go语言中关键字和保留字都不能用作变量名 Go语言中变量需要声明后才能使用，同一作用域内不支持重复声明。并且Go语言的变量声明后必须使用。 变量声明后，没有初始化，打印出来的是空 1.1、如何定义变量 方式1 var name = \"zhangsan\" 方式2：带类型 var name string = \"zhangsan\" 方式3：类型推导方式定义变量 在函数内部，可以使用更简略的 := 方式声明并初始化变量 注意：短变量只能用于声明局部变量，不能用于全局变量声明 变量名 := 表达式 方式4：声明多个变量 类型都是一样的变量 var 变量名称， 变量名称 类型 a, b, c := 1,2,\"3\" 类型不一样的变量 var ( 变量名称 类型 变量名称 类型 ) 匿名变量 在使用多重赋值时，如果想要忽略某个值，可以使用匿名变量（anonymous variable） 匿名变量用一个下划线“_”表示 func Getuser(){ return username, age } var username, _ = Getuser() 示例代码 代码 package main import \"fmt\" func main() { var a = 10 fmt.Printf(\"%d\\n\", a) var name1 = \"zhangsan\" var name2 string = \"lishi\" name3 := \"wangwu\" fmt.Println(name1) fmt.Println(name2) fmt.Println(name3) fmt.Printf(\"name1=%v, name2=%v, name3=%v\", name1, name2, name3) var b, c string b = \"b\" c = \"c\" fmt.Printf(\"\\nb=%v, c=%v\\n\", b, c) var ( d int e string f bool ) d = 100 e = \"string\" f = true //var ( // d int = 1 // e string = 'e' // f bool = false //) fmt.Printf(\"d=%v, e=%v, f=%v\\n\", d, e, f) } 输出 10 zhangsan lishi wangwu name1=zhangsan, name2=lishi, name3=wangwu b=b, c=c d=100, e=string, f=true 2、常量 2.1、如何定义常量 相对于变量，常量是恒定不变的值，多用于定义程序运行期间不会改变的那些值。常量的声明和变量声明非常类似，只是把var换成了const，常量在定义的时候必须赋值。 // 定义了常量，可以不用立即使用 const pi = 3.14 // 定义两个常量 const( A = \"A\" B = \"B\" ) // const同时声明多个常量时，如果省略了值表示和上面一行的值相同 const( A = \"A\" B C ) 2.2、 Const常量结合iota的使用 iota是golang 语言的常量计数器，只能在常量的表达式中使用 iota在const关键字出现时将被重置为0（const内部的第一行之前），const中每新增一行常量声明将使iota计数一次（iota可理解为const语句块中的行索引）。 每次const出现，都会让iota初始化为0【自增长】 const a = iota // a = 0 const ( b = iota // b=0 c // c = 1 d // d = 2 ) const iota使用_跳过某些值 const ( b = iota // b=0 _ d // d = 2 ) 多个赋值 const ( n1, n2 = iota + 1, iota + 2 //1 2 n3, n4 // 2 3 n5, n6 //3 4 ) 3、Go语言变量、常量命名规则 变量名必须有数字、字母、下划线组成 标识符不能是数字 标识符不能是保留字和关键字 变量的名字是区分大小写的 标识符（变量名称）一定要见名思意：变量名称建议用名词，方法名称建议用动词 变量命名一般采用驼峰式。 "},"GoLang/GoLang基础/04-数据类型.html":{"url":"GoLang/GoLang基础/04-数据类型.html","title":"数据类型","keywords":"","body":"datetime:2020/8/18 15:42 author:nzb Golang的数据类型 1、概述 Go 语言中数据类型分为：基本数据类型和复合数据类型基本数据类型有： 整型、浮点型、布尔型、字符串 复合数据类型有： 数组、切片、结构体、函数、map、通道（channel）、接口等。 2、整型 整型的类型有很多中，包括 int8，int16，int32，int64。我们可以根据具体的情况来进行定义 如果我们直接写 int也是可以的，它在不同的操作系统中，int的大小是不一样的 32位操作系统：int -> int32 64位操作系统：int -> int64 默认值为：0 有符号和无符号整型 可以通过unsafe.Sizeof 查看不同长度的整型，在内存里面的存储空间 var num2 = 12 fmt.Println(unsafe.Sizeof(num2)) 2.1、类型转换 通过在变量前面添加指定类型，就可以进行强制类型转换 var a1 int16 = 10 var a2 int32 = 12 var a3 = int32(a1) + a2 fmt.Println(a3) 注意，高位转低位的时候，需要注意，会存在精度丢失，比如上述16转8位的时候，就丢失了 var n1 int16 = 130 fmt.Println(int8(n1)) // 变成 -126 2.2、数字字面量语法 Go1.13版本之后，引入了数字字面量语法，这样便于开发者以二进制、八进制或十六进制浮点数的格式定义数字，例如： v := 0b00101101 // 代表二进制的101101 v := Oo377 // 代表八进制的377 2.3、进制转换 var number = 17 // 原样输出 fmt.Printf(\"%v\\n\", number) // 十进制输出 fmt.Printf(\"%d\\n\", number) // 以八进制输出 fmt.Printf(\"%o\\n\", number) // 以二进制输出 fmt.Printf(\"%b\\n\", number) // 以十六进制输出 fmt.Printf(\"%x\\n\", number) 3、浮点型 Go语言支持两种浮点型数：float32和float64。这两种浮点型数据格式遵循IEEE754标准： float32的浮点数的最大范围约为3.4e38，可以使用常量定义：math.MaxFloat32。float64的浮点数的最大范围约为1.8e308，可以使用一个常量定义：math.MaxFloat64 默认值为：0 打印浮点数时，可以使用fmt包配合动词%f，代码如下： var pi = math.Pi // 打印浮点类型，默认小数点6位 fmt.Printf(\"%f\\n\", pi) // 打印浮点类型，打印小数点后2位 fmt.Printf(\"%.2f\\n\", pi) // 科学计数 var f2 = 3.14e2 // 3.14 * 10的2次方 fmt.Printf(\"\\n%v,%T\\n\", f2, f2) // 314,float64 3.1、Golang中精度丢失的问题 几乎所有的编程语言都有精度丢失的问题，这是典型的二进制浮点数精度损失问题，在定长条件下，二进制小数和十进制小数互转可能有精度丢失 d := 1129.6 fmt.Println(d*100) //输出112959.99999999 解决方法，使用第三方包来解决精度损失的问题 4、布尔类型 Go语言中以bool类型进行声明布尔型数据，布尔型数据只有true和false 注意 布尔类型变量的默认值为false Go语言中不允许将整型强制转换为布尔型 布尔型无法参与数值运算，也无法与其他类型进行转换 var fl = false if f1 { fmt.Println(\"true\") } else { fmt.Println(\"false\") } 5、字符串类型 Go 语言中的字符串以原生数据类型出现，使用字符串就像使用其他原生数据类型（int、bool、float32、float64等）一样。Go语言里的字符串的内部实现使用UTF-8编码。字符串的值为双引号（\" ）中的内容，可以在Go语言的源码中直接添加非ASCll码字符，例如： s1 := \"hello\" s1 := \"你好\" 默认值为：空字符串 如果想要定义多行字符串，可以使用反引号 var str = `第一行 第二行` fmt.Println(str) 转义输出 str1 := \"this is \\nstr\" str2 := \"C:\\\\go\\\\demo\" str3 := \"this is\\\" str3\" fmt.Println(str1) fmt.Println(str2) fmt.Println(str3) this is str C:\\go\\demo this is\" str3 5.1、字符串常见操作 len(str)：求长度 \"aaa\"：3（3个字节） \"你好\"：6（一个汉字3个字节） +或fmt.Sprintf：拼接字符串 str1 := \"你好\" str2 := \"golang\" str3 := fmt.Sprintf(\"%v%v, str1, str2) fmt.Println(str3) fmt.Sprintf(\"%v%v, str1, str2) // 可以任意拼接（加空格加符号） strings.Split：分割 strings.contains：判断是否包含 strings.HasPrefix，strings.HasSuffix：前缀/后缀判断 strings.Index()，strings.LastIndex()：子串出现的位置，不存在返回：-1 strings.Join()：join操作 strings.Index()：判断在字符串中的位置 6、byte 和 rune类型 组成每个字符串的元素叫做 “字符”，可以通过遍历字符串元素获得字符。字符用单引号 '' 包裹起来 Go语言中的字符有以下两种类型 uint8类型：或者叫byte型，代表了ACII码的一个字符 rune类型：代表一个UTF-8字符 当需要处理中文，日文或者其他复合字符时，则需要用到rune类型，rune类型实际上是一个int32 Go使用了特殊的rune类型来处理Unicode，让基于Unicode的文本处理更为方便，也可以使用byte型进行默认字符串处理，性能和扩展性都有照顾。 需要注意的是，在go语言中，一个汉字占用3个字节（utf-8），一个字母占用1个字节 package main import \"fmt\" func main() { var a byte = 'a' // 输出的是ASCII码值，也就是说当我们直接输出byte（字符）的时候，输出的是这个字符对应的码值 fmt.Println(a) // 输出的是字符 fmt.Printf(\"%c\", a) fmt.Printf(\"\\n--------------通过len来循环的，相当于打印的是ASCII码，汉字出现乱码--------------\\n\") // for循环打印字符串里面的字符 // 通过len来循环的，相当于打印的是ASCII码 s := \"你好 golang\" for i := 0; i 结果 97 a --------------通过len来循环的，相当于打印的是ASCII码，汉字出现乱码-------------- 228(ä) 189(½) 160( ) 229(å) 165(¥) 189(½) 32( ) 103(g) 111(o) 108(l) 97(a) 110(n) 103(g) ------通过rune打印的是 utf-8字符，汉字就不能乱码，rune类型兼容byte类型------- 0 20320 3 22909 6 32 7 103 8 111 9 108 10 97 11 110 12 103 6.1、修改字符串 要修改字符串，需要先将其转换成[]rune 或 []byte类型，完成后在转换成string，无论哪种转换都会重新分配内存，并复制字节数组 转换为 []byte 类型 // 字符串转换 s1 := \"big\" byteS1 := []byte(s1) byteS1[0] = 'p' fmt.Println(string(byteS1)) 转换为rune类型 // rune类型 s2 := \"你好golang\" byteS2 := []rune(s2) byteS2[0] = '我' fmt.Println(string(byteS2)) 7、基本数据类型转换 7.1、数值类型转换 // 整型和浮点型之间转换 var aa int8 = 20 var bb int16 = 40 fmt.Println(int16(aa) + bb) // 建议整型转换成浮点型 var cc int8 = 20 var dd float32 = 40 fmt.Println(float32(cc) + dd) 建议从低位转换成高位，这样可以避免 7.2、转换成字符串类型 第一种方式，就是通过 fmt.Sprintf()来转换 // 字符串类型转换 var i int = 20 var f float64 = 12.456 var t bool = true var b byte = 'a' str1 := fmt.Sprintf(\"%d\", i) fmt.Printf(\"类型：%v-%T \\n\", str1, str1) str2 := fmt.Sprintf(\"%f\", f) fmt.Printf(\"类型：%v-%T \\n\", str2, str2) str3 := fmt.Sprintf(\"%t\", t) fmt.Printf(\"类型：%v-%T \\n\", str3, str3) str4 := fmt.Sprintf(\"%c\", b) fmt.Printf(\"类型：%v-%T \\n\", str4, str4) 第二种方法就是通过strconv包里面的集中转换方法进行转换 package main import ( \"fmt\" \"strconv\" ) func main() { // int类型转换str类型 var num1 int64 = 20 s1 := strconv.FormatInt(num1, 10) fmt.Printf(\"转换值：%v - 类型：%T\\n\", s1, s1) // float类型转换成string类型 var num2 float64 = 3.1415926 /* 参数1：要转换的值 参数2：格式化类型 'f'表示float，'b'表示二进制，‘e’表示 十进制 参数3：表示保留的小数点，-1表示不对小数点格式化 参数4：格式化的类型，传入64位 或者 32位 */ s2 := strconv.FormatFloat(num2, 'f', -1, 64) fmt.Printf(\"转换值：%v-类型：%T\", s2, s2) } 结果 转换值：20 - 类型：string 转换值：3.1415926-类型：string 7.3、字符串转换成int 和 float类型 str := \"10\" // 第一个参数：需要转换的数，第二个参数：进制， 参数三：32位或64位 num,_ = strconv.ParseInt(str, 10, 64) // 转换成float类型 str2 := \"3.141592654\" num,_ = strconv.ParseFloat(str2, 10) 7.4 不建议string类型转换为bool类型（无意义） "},"GoLang/GoLang基础/05-运算符.html":{"url":"GoLang/GoLang基础/05-运算符.html","title":"运算符","keywords":"","body":"datetime:2020/8/31 16:26 author:nzb Go的运算符 1、算数运算符 运算符 说明 + 相加 - 相减 * 相乘 / 相除 % 求余= 被除数 - (被除数 / 除数) * 除数 fmt.Println(-10 % 3) // 结果是 -1 fmt.Println(10 % -3) // 结果是 1 1.2、注意事项 ++ 和 --在go语言中不是运算符 除法注意，如果运算的数是整数，那么除后，去掉小数部分，保留整数部分，如果是浮点数，保留小数部分 在golang中， ++ 和 -- 只能单独使用，错误的写法如下 var i int = 8 var a int a = i++ // 错误，i++只能单独使用 a = i-- // 错误，i--只能单独使用 同时在golang中，没有 ++i这样的操作 var i int = 1 ++i // 错误 正确的写法 var i int = 1 i++ //正确 2、关系运算符 运算符 说明 == 检查两个值是否相等，如果相等返回True，否则返回False != 检查两个值是否不相等，如果不相等返回True，否则返回False > 检查左边值是否大于右边值，如果是返回True，否则返回False >= 检查左边值是否大于等于右边值，如果是返回True，否则返回False 检查左边值是否小于右边值，如果是返回True，否则返回False 检查左边值是否小于等于右边值，如果是返回True，否则返回False 3、逻辑运算符 运算符 说明 && 逻辑 AND 运算符，如果两边的操作数都是True，则为True，否则为False || 逻辑 OR 运算符，如果两边的操作数有一个是True，则为True，否则为False ! 逻辑 NOT 运算符，如果条件为True，则为False，否则为True 短路用法，逻辑与前面为False后面的就不执行了，逻辑或前面的为True后面的也不执行了 4、赋值辑运算符 运算符 说明 = 简单的赋值运算符，将一个表达式的值赋给一个左值(从右往左计算赋值) += 相加后再赋值 -= 相减后再赋值 *= 相乘后再赋值 /= 相除后再赋值（跟上面算术运算符的注意事项相同） %= 求余后再赋值 5、位运算符 位运算符对整数在内存中的二进制位进行操作 运算符 说明 & 参与运算的两数各对应的二进位相与。（两位均为1才为1） | 参与运算的两数各对应的二进位相或。（两位有一个为1就为1） ^ 参与运算的两数各对应的二进位相异或，当两对应的二进位相异时，结果为1,。（两位不一样则为1） 左移n位就是乘以2的n次方。“a >> 左移n位就是除以2的n次方。“a>>b”是把a的各二进位全部右移b位。 "},"GoLang/GoLang基础/06-流程控制.html":{"url":"GoLang/GoLang基础/06-流程控制.html","title":"流程控制","keywords":"","body":"datetime:2020/9/16 11:41 author:nzb Go的流程控制 流程控制是每种编程语言控制逻辑走向和执行次序的重要部分，流程控制可以说是一门语言的“经脉\" Go 语言中最常用的流程控制有if和for，而switch和goto主要是为了简化代码、降低重复代码而生的结构，属于扩展类的流程控制。 1、条件语句 1.1、if else 推荐if后面不适用括号，当然也可以使用括号括起来 if 布尔表达式 { /* 在布尔表达式为 true 时执行 */ } else { /* 在布尔表达式为 false 时执行 */ } func main() { var num = 10 if num == 10 { fmt.Println(\"hello == 10\") } else if(num > 10) { fmt.Println(\"hello > 10\") } else { fmt.Println(\"hello if的另外一种写法，下面的方法的区别是 num2是局部变量 if num2:= 10; num2>=10 { fmt.Println(\"hello >=10\") fmt.Println(num2) // 可打印 } fmt.Println(num2) // 报错，因为 num2 是局部变量 if 语句嵌套 if 布尔表达式 1 { /* 在布尔表达式 1 为 true 时执行 */ if 布尔表达式 2 { /* 在布尔表达式 2 为 true 时执行 */ } } 你可以以同样的方式在 if 语句中嵌套 else if...else 语句 1、if 后的 大括号 {}不能省略 2、{必须紧挨着条件 1.2、switch case 使用switch语句可方便的对大量的值进行条件判断 switch 默认情况下 case 最后自带 break 语句，匹配成功后就不会执行其他 case，如果我们需要执行后面的 case，可以使用 fallthrough 。 switch var1 { case val1: ... case val2: ... default: ... } extname := \".a\" switch extname { case \".html\": { fmt.Println(\".html\") break } case \".doc\": { fmt.Println(\".doc\") break } case \".js\": { fmt.Println(\".js\") } default: { fmt.Println(\"其它后缀\") } } switch的另外一种写法 switch extname := \".a\"; extname { case \".html\": { fmt.Println(\".html\") break } case \".doc\": { fmt.Println(\".doc\") break } case \".js\": { fmt.Println(\".js\") } default: { fmt.Println(\"其它后缀\") } } 同时一个分支可以有多个值 extname := \".txt\" switch extname { case \".html\": { fmt.Println(\".html\") break } case \".txt\",\".doc\": { fmt.Println(\"传递来的是文档\") break } case \".js\": { fmt.Println(\".js\") } default: { fmt.Println(\"其它后缀\") } } tip：在golang中，break可以不写，也能够跳出case，而不会执行其它的。 如果我们需要使用switch的穿透 fallthrought，fallthrough语法可以执行满足条件的 case 的下一个case，为了兼容c语言中的case设计 extname := \".txt\" switch extname { case \".html\": { fmt.Println(\".html\") fallthrought } case \".txt\",\".doc\": { fmt.Println(\"传递来的是文档\") fallthrought } case \".js\": { fmt.Println(\".js\") fallthrought } default: { fmt.Println(\"其它后缀\") } } fallthrought 只能穿透紧挨着的一层，不会一直穿透，但是如果每一层都写的话，就会导致每一层都进行穿透 2、循环语句 2.1、for 循环结构 Go语言中的所有循环类型均可使用for关键字来完成 for循环的基本格式如下： for 初始语句; 条件表达式; 结束语句 { 循环体 } 第一种写法： for i := 1 ; i 第二种写法：和 C 的 while 一样： for condition { } 示例： i := 1 for ; i 第三种写法 i := 1 for i 第四种写法：和 C 的 for(;;) 一样： for { } 示例： i := 1 for { if i 条件表达式返回true时循环体不停地进行循环，直到条件表达式返回false时自动退出循环 实例：打印1 ~ 10 for i := 0; i 2.2、for range（键值循环） Go 语言中可以使用for range遍历数组、切片、字符串、map及通道（channel）。通过for range遍历的返回值有以下规律： for key, value := range oldMap { newMap[key] = value } 数组、切片、字符串返回索引和值。 map返回键和值。 通道（channel）只返回通道内的值。 实例：遍历字符串 var str = \"你好golang\" for key, value := range str { fmt.Printf(\"%v - %c \", key, value) } 遍历切片（数组） var array = []string{\"php\", \"java\", \"node\", \"golang\"} for index, value := range array { fmt.Printf(\"%v %s \", index, value) } for循环可以通过break、goto、return、panic语句退出循环 2.3、循环嵌套 for [condition | ( init; condition; increment ) | Range] { for [condition | ( init; condition; increment ) | Range] { statement(s); } statement(s); } 2.4、循环控制语句 2.4.1、break：跳出循环 Go语言中break 语句用于以下几个方面： 用于循环语句中跳出循环，并开始执行循环之后的语句。 break在switch（开关语句）中在执行一条case后跳出语句的作用。 在多重循环中，可以用标号label标出想break的循环。 var i = 0 for { if i == 10{ fmt.Println(\"跳出循环\") break } i++ fmt.Println(i) } 使用label package main import \"fmt\" func main() { // 不使用标记 fmt.Println(\"---- break ----\") for i := 1; i ---- break ---- i: 1 i2: 11 i: 2 i2: 11 i: 3 i2: 11 ---- break label ---- i: 1 i2: 11 2.4.2、 continue：跳过当前循环的剩余语句，然后继续进行下一轮循环 Go 语言的 continue 语句 有点像 break 语句。但是 continue 不是跳出循环，而是跳过当前循环执行下一次循环语句。 for 循环中，执行 continue 语句会触发 for 增量语句的执行。 在多重循环中，可以用标号 label 标出想 continue 的循环。 package main import \"fmt\" func main() { // 不使用标记 fmt.Println(\"---- continue ---- \") for i := 1; i ---- continue ---- i: 1 i2: 11 i2: 12 i2: 13 i: 2 i2: 11 i2: 12 i2: 13 i: 3 i2: 11 i2: 12 i2: 13 ---- continue label ---- i: 1 i2: 11 i: 2 i2: 11 i: 3 i2: 11 2.4.3、 goto：跳转到指定标签 Go 语言的 goto 语句可以无条件地转移到过程中指定的行。 goto 语句通常与条件语句配合使用。可用来实现条件转移， 构成循环，跳出循环体等功能。 但是，在结构化程序设计中一般不主张使用 goto 语句， 以免造成程序流程的混乱，使理解和调试程序都产生困难。 goto label; .. . label: statement; var n = 20 if n > 24 { fmt.Println(\"成年人\") } else { goto lable3 } fmt.Println(\"aaa\") fmt.Println(\"bbb\") lable3: fmt.Println(\"ccc\") fmt.Println(\"ddd\") "},"GoLang/GoLang基础/07-数组.html":{"url":"GoLang/GoLang基础/07-数组.html","title":"数组","keywords":"","body":"datetime:2020/9/16 14:56 author:nzb Go的数组 1、Array数组介绍 数组是指一系列同一类型数据的集合。数组中包含的每个数据被称为数组元素（element），这种类型可以是意的原始类型，比如int、string等，也可以是用户自定义的类型。一个数组包含的元素个数被称为数组的长度。在Golang中数组是一个长度固定的数据类型，数组的长度是类型的一部分，也就是说[5]int和[10]int是两个不同的类型。Golang中数组的另一个特点是占用内存的连续性，也就是说数组中的元素是被分配到连续的内存地址中的，因而索引数组元素的速度非常快。 和数组对应的类型是Slice（切片），Slice是可以增长和收缩的动态序列，功能也更灵活，但是想要理解slice工作原理的话需要先理解数组，所以本节主要为大家讲解数组的使用。 2、数组定义 var variable_name [SIZE] variable_type 示例 // 数组的长度是类型的一部分 var arr1 [3]int var arr2 [4]string fmt.Printf(\"%T, %T \\n\", arr1, arr2) 第一种方法 var arr3 [3]int arr3[0] = 1 arr3[1] = 2 arr3[2] = 3 fmt.Println(arr3) 第二种初始化数组的方法 var arr4 = [4]int {10, 20, 30, 40} fmt.Println(arr4) 第三种数组初始化方法，自动推断数组长度 var arr5 = [...]int{1, 2} fmt.Println(arr5) 第四种初始化数组的方法，指定下标 a := [...]int{1:1, 3:5} fmt.Println(a) 3、遍历数组 方法1 // 第四种初始化数组的方法，指定下标 a := [...]int{1:1, 3:5} for i := 0; i 方法2 // 第四种初始化数组的方法，指定下标 a := [...]int{1:1, 3:5} for _, value := range a { fmt.Print(value, \" \") } 4、数组的值类型 数组是值类型，赋值和传参会赋值整个数组，因此改变副本的值，不会改变本身的值 // 数组 var array1 = [...]int {1, 2, 3} array2 := array1 array2[0] = 3 fmt.Println(array1, array2) 例如上述的代码，我们将数组进行赋值后，该改变数组中的值时，发现结果如下 [1 2 3] [3 2 3] 这就说明了，golang中的数组是值类型，而不是和java一样属于引用数据类型 5、切片定义(引用类型) 在golang中，切片的定义和数组定义是相似的，但是需要注意的是，切片是引用数据类型，如下 // 切片定义 var array3 = []int{1,2,3} array4 := array3 array4[0] = 3 fmt.Println(array3, array4) 我们通过改变第一个切片元素，然后查看最后的效果 [3 2 3] [3 2 3] 6、二维数组 Go语言支持多维数组，我们这里以二维数组为例（数组中又嵌套数组）： 二维 var arrayName [ x ][ y ] variable_type 示例 // 二维数组 var array5 = [2][2]int{ {1,2},{2,3} } fmt.Println(array5) 多维 var variable_name [SIZE1][SIZE2]...[SIZEN] variable_type 7、数组遍历 二维数据组的遍历 // 二维数组 var array5 = [2][2]int{ {1,2},{2,3} } for i := 0; i 遍历方式2 for _, item := range array5 { for _, item2 := range item { fmt.Println(item2) } } 8、类型推导 另外我们在进行数组的创建的时候，还可以使用类型推导，但是只能使用一个 ... // 二维数组（正确写法） var array5 = [...][2]int{ {1,2},{2,3} } 错误写法 // 二维数组 var array5 = [2][...]int{ {1,2},{2,3} } 9、完整代码 package main import \"fmt\" func main() { // 数组的长度是类型的一部分 var arr1 [3]int var arr2 [4]string fmt.Printf(\"%T, %T \\n\", arr1, arr2) // 数组的初始化 第一种方法 var arr3 [3]int arr3[0] = 1 arr3[1] = 2 arr3[2] = 3 fmt.Println(arr3) // 第二种初始化数组的犯法 var arr4 = [4]int {10, 20, 30, 40} fmt.Println(arr4) // 第三种数组初始化方法，自动推断数组长度 var arr5 = [...]int{1, 2} fmt.Println(arr5) // 第四种初始化数组的方法，指定下标 a := [...]int{1:1, 3:5} fmt.Println(a) for i := 0; i 10、向函数传递数组 方式一：形参设定数组大小： void myFunction(param [10]int) { . . . } 方式二：形参未设定数组大小： void myFunction(param []int) { . . . } "},"GoLang/GoLang基础/08-切片.html":{"url":"GoLang/GoLang基础/08-切片.html","title":"切片","keywords":"","body":"datetime:2020/10/23 10:48 author:nzb Go的切片 1、为什么要使用切片 切片（Slice）是一个拥有相同类型元素的可变长度的序列。它是基于数组类型做的一层封装。 它非常灵活，支持自动扩容。 切片是一个引用类型，它的内部结构包含地址、长度和容量。 声明切片类型的基本语法如下： var name [] T 其中： name：表示变量名 T：表示切片中的元素类型 举例 // 声明切片，把长度去除就是切片 var slice = []int{1,2,3} fmt.Println(slice) 2、关于nil的认识 当你声明了一个变量，但却还并没有赋值时，golang中会自动给你的变量赋值一个默认的零值。这是每种类型对应的零值。 bool：false numbers：0 string：\"\" pointers：nil slices：nil maps：nil channels：nil functions：nil nil表示空，也就是数组初始化的默认值就是nil var slice2 [] int fmt.Println(slice2 == nil) 运行结果 true 3、切片的遍历 切片的遍历和数组是一样的 var slice = []int{1,2,3} for i := 0; i 4、基于数组定义切片 由于切片的底层就是一个数组，所以我们可以基于数组来定义切片 // 基于数组定义切片 a := [5]int {55,56,57,58,59} // 获取数组所有值，返回的是一个切片 b := a[:] // 从数组获取指定的切片 c := a[1:4] // 获取 下标3之前的数据（不包括3） d := a[:3] // 获取下标3以后的数据（包括3） e := a[3:] 运行结果 [55 56 57 58 59] [55 56 57 58 59] [56 57 58] [55 56 57] [58 59] 同理，我们不仅可以对数组进行切片，还可以切片在切片 5、切片的长度和容量 切片拥有自己的长度和容量，我们可以通过使用内置的len）函数求长度，使用内置的cap（） 函数求切片的容量。 切片的长度就是它所包含的元素个数。 切片的容量是从它的第一个元素开始数，到其底层数组元素末尾的个数。切片s的长度和容量可通过表达式len（s）和cap（s）来获取。 举例 // 长度和容量 s := []int {2,3,5,7,11,13} fmt.Printf(\"长度%d 容量%d\\n\", len(s), cap(s)) ss := s[2:] fmt.Printf(\"长度%d 容量%d\\n\", len(ss), cap(ss)) sss := s[2:4] fmt.Printf(\"长度%d 容量%d\\n\", len(sss), cap(sss)) 运行结果 长度6 容量6 长度4 容量4 长度2 容量4 为什么最后一个容量不一样呢，因为我们知道，经过切片后sss = [5, 7] 所以切片的长度为2，但是因为容量是从2的位置一直到末尾，所以为4 6、切片的本质 切片的本质就是对底层数组的封装，它包含了三个信息 底层数组的指针 切片的长度(len) 切片的容量(cap) 举个例子，现在有一个数组 a := [8]int {0,1,2,3,4,5,6,7}，切片 s1 := a[:5]，相应示意图如下 切片 s2 := a[3:6]，相应示意图如下： 7、使用make函数构造切片 我们上面都是基于数组来创建切片的，如果需要动态的创建一个切片，我们就需要使用内置的make函数，格式如下： make ([]T, size, cap) 其中： T：切片的元素类型 size：切片中元素的数量 cap：切片的容量 举例： // make()函数创建切片 fmt.Println() var slices = make([]int, 4, 8) //[0 0 0 0] fmt.Println(slices) // 长度：4, 容量8 fmt.Printf(\"长度：%d, 容量%d\", len(slices), cap(slices)) 需要注意的是，golang中没办法通过下标来给切片扩容，如果需要扩容，需要用到append slices2 := []int{1,2,3,4} slices2 = append(slices2, 5) fmt.Println(slices2) // 输出结果 [1 2 3 4 5] 同时切片还可以将两个切片进行合并 // 合并切片 slices3 := []int{6,7,8} slices2 = append(slices2, slices3...) fmt.Println(slices2) // 输出结果 [1 2 3 4 5 6 7 8] 需要注意的是，切片会有一个扩容操作，当元素存放不下的时候，会将原来的容量扩大两倍，详情 8、使用copy()函数复制切片 前面我们知道，切片就是引用数据类型 值类型：改变变量副本的时候，不会改变变量本身 引用类型：改变变量副本值的时候，会改变变量本身的值 如果我们需要改变切片的值，同时又不想影响到原来的切片，那么就需要用到copy函数 // 需要复制的切片 var slices4 = []int{1,2,3,4} // 使用make函数创建一个切片 var slices5 = make([]int, len(slices4), len(slices4)) // 拷贝切片的值 copy(slices5, slices4) // 修改切片 slices5[0] = 4 fmt.Println(slices4) fmt.Println(slices5) 运行结果为 [1 2 3 4] [4 2 3 4] 9、删除切片中的值 Go语言中并没有删除切片元素的专用方法，我们可以利用切片本身的特性来删除元素。代码如下 // 删除切片中的值 var slices6 = []int {0,1,2,3,4,5,6,7,8,9} // 删除下标为1的值 slices6 = append(slices6[:1], slices6[2:]...) fmt.Println(slices6) 运行结果 [0 2 3 4 5 6 7 8 9] 10、切片的排序算法以及sort包 编写一个简单的冒泡排序算法 func main() { var numSlice = []int{9,8,7,6,5,4} for i := 0; i numSlice[j+1] { var temp = numSlice[j+1] numSlice[j+1] = numSlice[j] numSlice[j] = temp flag = true } } if !flag { break } } fmt.Println(numSlice) } 在来一个选择排序 // 编写选择排序 var numSlice2 = []int{9,8,7,6,5,4} for i := 0; i numSlice2[j] { var temp = numSlice2[i] numSlice2[i] = numSlice2[j] numSlice2[j] = temp } } } fmt.Println(numSlice2) 对于int、float64 和 string数组或是切片的排序，go分别提供了sort.Ints()、sort.Float64s() 和 sort.Strings()函数，默认都是从小到大进行排序 var numSlice2 = []int{9,8,7,6,5,4} sort.Ints(numSlice2) fmt.Println(numSlice2) 降序排列 Golang的sort包可以使用 sort.Reverse(slic e) 来调换slice.Interface.Less，也就是比较函数，所以int、float64 和 string的逆序排序函数可以这样写 // 逆序排列 var numSlice4 = []int{9,8,4,5,1,7} sort.Sort(sort.Reverse(sort.IntSlice(numSlice4))) fmt.Println(numSlice4) "},"GoLang/GoLang基础/09-map.html":{"url":"GoLang/GoLang基础/09-map.html","title":"map","keywords":"","body":"datetime:2020/10/23 15:57 author:nzb Go的map 1、map的介绍 map是一种无序的基于key-value的数据结构，Go语言中的map是引用类型，必须初始化才能使用。 Go语言中map的定义语法如下： map[KeyType]ValueType 其中： KeyType：表示键的类型 ValueType：表示键对应的值的类型 map类型的变量默认初始值为nil，需要使用make()函数来分配内存。语法为： make：用于slice、map和channel的初始化 示例如下所示： // 方式1初始化 var userInfo = make(map[string]string) userInfo[\"userName\"] = \"zhangsan\" userInfo[\"age\"] = \"20\" userInfo[\"sex\"] = \"男\" fmt.Println(userInfo) fmt.Println(userInfo[\"userName\"]) // 创建方式2，map也支持声明的时候填充元素 var userInfo2 = map[string]string { \"username\":\"张三\", \"age\":\"21\", \"sex\":\"女\", } fmt.Println(userInfo2) 2、遍历map 使用for range遍历 // 遍历map for key, value := range userInfo2 { fmt.Println(\"key:\", key, \" value:\", value) } 3、判断map中某个键值是否存在 我们在获取map的时候，会返回两个值，也可以是返回的结果，一个是是否有该元素 // 判断是否存在,如果存在 ok = true，否则 ok = false value, ok := userInfo2[\"username2\"] fmt.Println(value, ok) 4、使用delete()函数删除键值对 使用delete()内建函数从map中删除一组键值对，delete函数的格式如下所示 delete(map 对象, key) 其中： map对象：表示要删除键值对的map对象 key：表示要删除的键值对的键 示例代码如下 // 删除map数据里面的key，以及对应的值 delete(userInfo2, \"sex\") fmt.Println(userInfo2) 5、元素为map类型的切片 我们想要在切片里面存放一系列用户的信息，这时候我们就可以定义一个元素为map类型的切片 // 切片中存放map var userInfoList = make([]map[string]string, 3, 3) var user = map[string]string{ \"userName\": \"张安\", \"age\": \"15\", } var user2 = map[string]string{ \"userName\": \"张2\", \"age\": \"15\", } var user3 = map[string]string{ \"userName\": \"张3\", \"age\": \"15\", } userInfoList[0] = user userInfoList[1] = user2 userInfoList[2] = user3 fmt.Println(userInfoList) for _, item := range userInfoList { fmt.Println(item) } 6、值为切片类型的map 我们可以在map中存储切片 // 将map类型的值定义为切片 var userinfo = make(map[string][]string) userinfo[\"hobby\"] = []string {\"吃饭\", \"睡觉\", \"敲代码\"} fmt.Println(userinfo) 7、示例 统计字符串中单词出现的次数 // 写一个程序，统计一个字符串中每个单词出现的次数。比如 \"how do you do\" var str = \"how do you do\" array := strings.Split(str, \" \") fmt.Println(array) countMap := make(map[string]int) for _, item := range array { countMap[item]++ } fmt.Println(countMap) 升序输出 map 的值 map1 := make(map[int]int, 10) map1[10] = 100 map1[1] = 13 map1[4] = 56 map1[8] = 90 map1[12] = 43 map1[7] = 32 // 1、把 map 的 key 升序放入切片 keySlice []int for k, _ := range map1{ keySlice = append(keySlice, k) } fmt.Println(keySlice) // 2、升序 sort.Ints(keySlice) fmt.Println(keySlice) // 3、输出 for _, v := range keySlice{ fmt.Printf(\"key=%v, value=%v\", v, map1[v]) } "},"GoLang/GoLang基础/10-函数.html":{"url":"GoLang/GoLang基础/10-函数.html","title":"函数","keywords":"","body":"datetime:2020/10/26 15:40 author:nzb Go的函数 1、函数定义 函数是组织好的、可重复使用的、用于执行指定任务的代码块 Go语言支持：函数、匿名函数和闭包 Go语言中定义函数使用func关键字，具体格式如下： func 函数名(参数)(返回值) { 函数体 } 其中： 函数名：由字母、数字、下划线组成。但函数名的第一个字母不能是数字。在同一个包内，函数名也不能重名 示例 // 求两个数的和 func sumFn(x int, y int) int{ return x + y } // 调用方式 sunFn(1, 2) // 类型可以简写（多个返回值时也是） func sumFn(x, y int) int{ return x + y } // 调用方式 sunFn(1, 2) 获取可变的参数，可变参数是指函数的参数数量不固定。Go语言中的可变参数通过在参数名后面加 ... 来标识。 注意：可变参数通常要作为函数的最后一个参数 func sunFn2(x ...int) int { sum := 0 for _, num := range x { sum = sum + num } return sum } // 调用方法 sunFn2(1, 2, 3, 4, 5, 7) 方法多返回值，Go语言中函数支持多返回值，同时还支持返回值命名，函数定义时可以给返回值命名，并在函数体中直接使用这些变量，最后通过return关键字返回 // 方法多返回值1 func sunFn4(x int, y int)(int, int) { sum = x + y sub = x -y return sum, sub } // 方法多返回值2 func sunFn4(x int, y int)(sum int, sub int) { sum = x + y sub = x -y return } 2、函数类型和变量 2.1、定义函数类型 我们可以使用type关键字来定义一个函数类型，具体格式如下 type calculation func(int, int) int 上面语句定义了一个calculation类型，它是一种函数类型，这种函数接收两个int类型的参数并且返回一个int类型的返回值。 简单来说，凡是满足这两个条件的函数都是calculation类型的函数，例如下面的add 和 sub 是calculation类型 type calc func(int, int) int // 求两个数的和 func sumFn(x int, y int) int{ return x + y } func main() { var c calc c = add // 打印：c的类型是：main.cal，事先声明了类型为 calc d := add // 打印：d的类型是：func(int, int) int，使用类型推导，没有事先声明 } 2.2、方法作为参数 类型Python的filter、sorted等方法 /** 传递两个参数和一个方法 */ func sunFn (a int, b int, sum func(int, int)int) int { return sum(a, b) } 返回值是函数：使用switch定义方法，这里用到了匿名函数 // 返回一个方法 type calcType func(int, int)int func sumFn(x int, y int) int{ return x + y } func do(o string) calcType { switch o { case \"+\": return sumFn /* return func(i int, i2 int) int { return i + i2 } */ case \"-\": // 匿名函数 return func(i int, i2 int) int { return i - i2 } case \"*\": return func(i int, i2 int) int { return i * i2 } case \"/\": return func(i int, i2 int) int { return i / i2 } default: return nil } } func main() { add := do(\"+\") fmt.Println(add(1,5)) } 3、匿名函数 函数当然还可以作为返回值，但是在Go语言中，函数内部不能再像之前那样定义函数了，只能定义匿名函数。匿名函数就是没有函数名的函数，匿名函数的定义格式如下 func (参数)(返回值) { 函数体 } 匿名函数因为没有函数名，所以没有办法像普通函数那样调用，所以匿名函数需要保存到某个变量或者作为立即执行函数： func main() { // 第一种 func () { fmt.Println(\"匿名自执行函数\") }() //第二种 a := func () { fmt.Println(\"匿名自执行函数\") } a() } 4、闭包 4.1、全局变量和局部变量 全局变量的特点： 常驻内存 污染全局 局部变量的特点（注意if语句中的局部变量） 不常驻内存 不污染全局 4.2、闭包 可以让一个变量常驻内存 可以让一个变量不污染全局 闭包可以理解成 “定义在一个函数内部的函数”。在本质上，闭包就是将函数内部 和 函数外部连接起来的桥梁。或者说是函数和其引用环境的组合体。 闭包是指有权访问另一个函数作用域中的变量的函数 创建闭包的常见的方式就是在一个函数内部创建另一个函数，通过另一个函数访问这个函数的局部变量 注意：由于闭包里作用域返回的局部变量资源不会被立刻销毁，所以可能会占用更多的内存，过度使用闭包会导致性能下降，建议在非常有必要的时候才使用闭包。 // 闭包的写法：函数里面嵌套一个函数，最后返回里面的函数就形成了闭包 // 返回值是一个匿名函数 func adder() func() int { var i = 10 return func() int { return i + 1 } } func main() { var fn = adder() fmt.Println(fn()) fmt.Println(fn()) fmt.Println(fn()) } 最后输出的结果 11 11 11 另一个闭包的写法，让一个变量常驻内存，不污染全局 func adder2() func(y int) int { var i = 10 return func(y int) int { i = i + y return i } } func main() { var fn2 = adder2() fmt.Println(fn2(10)) // 20 fmt.Println(fn2(10)) // 30 fmt.Println(fn2(10)) // 40 } 5、defer语句 Go 语言中的defer 语句会将其后面跟随的语句进行延迟处理。在defer归属的函数即将返回时，将延迟处理的语句按defer定义的逆序进行执行，也就是说，先被defer的语句最后被执行，最后被defer的语句，最先被执行。 // defer函数 fmt.Println(\"1\") defer fmt.Println(\"2\") fmt.Println(\"3\") fmt.Println(\"4\") defer将会延迟执行 1 3 4 2 如果有多个defer修饰的语句，将会逆序进行执行 // defer函数 fmt.Println(\"1\") defer fmt.Println(\"2\") defer fmt.Println(\"3\") fmt.Println(\"4\") 运行结果 1 4 3 2 如果需要用defer运行一系列的语句，那么就可以使用匿名函数 func main() { fmt.Println(\"开始\") defer func() { fmt.Println(\"1\") fmt.Println(\"2\") }() fmt.Println(\"结束\") } 运行结果 开始 结束 1 2 5.1、defer执行时机 在Go语言的函数中return语句在底层并不是原子操作，它分为返回值赋值和RET指令两步。而defer语句执行的时机就在返回值赋值操作后，RET指令执行前，具体如下图所示 示例1 package main import \"fmt\" func f1() int{ x := 5 defer func(){ x++ }() return x // 5，匿名返回值，直接返回 5 } func f2() (x int){ defer func(){ x++ }() return 5 // 6， 顺序：x=0, return 5, 赋值 x, 再执行 x++，返回 } func f3() (y int){ 变量x, y不一样 x := 5 defer func(){ x++ }() return x // 5 因为 y 不存在，先把 x 的值 5 赋给了 y, 所以 x++ 后不会改变返回值 } func f4() (x int){ defer func(x int){ // 参数可类比 ay int // x = 0 x++ // y ++ }(x) // defer 注册要延迟执行的函数时该函数所有的参数都需要确定其值，及 x = 0 return 5 // 5 } func main() { fmt.Println(f1()) fmt.Println(f2()) fmt.Println(f3()) fmt.Println(f4()) } 结果 5 6 5 5 示例2 package main import \"fmt\" // defer 注册要延迟执行的函数时该函数所有的参数都需要确定其值，及 x = 0 func calc(index string, a, b int) int { ret := a + b fmt.Println(index, a, b, ret) return ret } func main() { x := 1 y := 2 defer calc(\"AA\", x, calc(\"A\", x, y)) x = 10 defer calc(\"BB\", x, calc(\"B\", x, y)) y = 20 } /* // 注册 defer calc(\"AA\", x, calc(\"A\", x, y)) defer calc(\"BB\", x, calc(\"B\", x, y)) // 执行 defer calc(\"BB\", x, calc(\"B\", x, y)) defer calc(\"AA\", x, calc(\"A\", x, y)) 1、calc(\"A\", x, y) A 1 2 3 2、calc(\"B\", x, y) B 10 2 12 3、calc(\"BB\", x, calc(\"B\", x, y)) BB 10 12 22 4、calc(\"AA\", x, calc(\"A\", x, y)) AA 1 3 4 */ 结果 A 1 2 3 B 10 2 12 BB 10 12 22 AA 1 3 4 6、panic/revocer处理异常 Go语言中是没有异常机制，但是使用panic / recover模式来处理错误 panic：可以在任何地方引发 recover：只有在defer调用函数内有效 func fn1() { fmt.Println(\"fn1\") } func fn2() { panic(\"抛出一个异常\") } func main() { fn1() fn2() fmt.Println(\"结束\") } 上述程序会直接抛出异常，无法正常运行 fn1 panic: 抛出一个异常 解决方法就是使用 recover进行异常的监听 func fn1() { fmt.Println(\"fn1\") } func fn2() { // 使用recover监听异常 defer func() { err := recover() if err != nil { fmt.Println(err) } }() panic(\"抛出一个异常\") } func main() { fn1() fn2() fmt.Println(\"结束\") } 7、异常运用场景 模拟一个读取文件的方法，这里可以主动发送使用panic 和 recover func readFile(fileName string) error { if fileName == \"main.go\" { return nil } else { return errors.New(\"读取文件失败\") } } func myFn () { defer func() { e := recover() if e != nil { fmt.Println(\"给管理员发送邮件\") } }() err := readFile(\"XXX.go\") if err != nil { panic(err) } } func main() { myFn() } 8、内置函数 内置函数 介绍 close 主要用来关闭channel len 用来求长度，比如string、array、slice、map、channel new 用来分配内存、主要用来分配值类型，比如 int、struct ，返回的是指针 make 用来分配内存，主要用来分配引用类型，比如chan、map、slice append 用来追加元素到数组、slice中 panic\\recover 用来处理错误 "},"GoLang/GoLang基础/11-time包日期函数.html":{"url":"GoLang/GoLang基础/11-time包日期函数.html","title":"time包日期函数","keywords":"","body":"datetime:2020/10/26 16:57 author:nzb Go中的日期函数 time包 时间和日期是我们编程中经常会用到的，在golang中time包提供了时间的显示和测量用的函数。 1、time.Now获取当前时间 timeObj := time.Now() year := timeObj.Year() month := timeObj.Month() day := timeObj.Day() fmt.Printf(\"%d-%02d-%02d \\n\", year, month, day) %02d 2 表示宽度，如果整数不够 2 列就补上 0 2、格式化日期 时间类型有一个自带的方法 Format进行格式化 需要注意的是Go语言中格式化时间模板不是长久的 Y-m-d H:M:S 而是使用Go的诞生时间 2006年1月2日 15点04分 （记忆口诀：2006 1 2 3 4 5） /** 时间类型有一个自带的方法 Format进行格式化 需要注意的是Go语言中格式化时间模板不是长久的 Y-m-d H:M:S 而是使用Go的诞生时间 2006年1月2日 15点04分 （记忆口诀：2006 1 2 3 4 5） */ timeObj2 := time.Now() // 24小时值 （15表示二十四小时） fmt.Println(timeObj2.Format(\"2006-01-02 15:04:05\")) // 12小时制 fmt.Println(timeObj2.Format(\"2006-01-02 03:04:05\")) 3、获取当前时间戳 时间戳是自1070年1月1日（08:00:00GMT）至当前时间的总毫秒数。它也被称为Unix时间戳 10位数的时间戳是以 秒 为单位； 13位数的时间戳是以 毫秒 为单位； 19位数的时间戳是以 纳秒 为单位； /** 获取当前时间戳 */ timeObj3 := time.Now() // 获取秒时间戳 unixTime := timeObj3.Unix() // 获取纳秒时间戳 unixNaTime := timeObj3.UnixNano() package main import ( \"time\" \"fmt\" ) func main() { fmt.Printf(\"时间戳（秒）：%v;\\n\", time.Now().Unix()) fmt.Printf(\"时间戳（纳秒）：%v;\\n\",time.Now().UnixNano()) fmt.Printf(\"时间戳（毫秒）：%v;\\n\",time.Now().UnixNano() / 1e6) fmt.Printf(\"时间戳（纳秒转换为秒）：%v;\\n\",time.Now().UnixNano() / 1e9) } //输出 时间戳（秒）：1530027865; 时间戳（纳秒）：1530027865231834600; 时间戳（毫秒）：1530027865231; 时间戳（纳秒转换为秒）：1530027865; 4、时间戳转日期字符串 通过将时间戳我们可以转换成日期字符串 // 时间戳转换年月日时分秒（一个参数是秒，另一个参数是毫秒） var timeObj4 = time.Unix(1595289901, 0) var timeStr = timeObj4.Format(\"2006-01-02 15:04:05\") fmt.Println(timeStr) 5、日期字符串转换成时间戳 // 日期字符串转换成时间戳 var timeStr2 = \"2020-07-21 08:10:05\"; var tmp = \"2006-01-02 15:04:05\" timeObj5, _ := time.ParseInLocation(tmp, timeStr2, time.Local) fmt.Println(timeObj5.Unix()) 6、时间间隔 time.Duration是time包定义的一个类型，它代表两个时间点之间经过的时间，以纳秒为单位。time.Duration表示一段时间间隔，可表示的最大长度段大约290年。 time包中定义的时间间隔类型的常量如下： 7、时间操作函数 我们在日常的编码过程中可能会遇到要求时间+时间间隔的需求，Go语言的时间对象有提供Add方法如下 func (t Time) Add(d Duration)Time 例如 // 时间相加 now := time.Now() // 当前时间加1个小时后 later := now.Add(time.Hour) fmt.Println(later) 同理的方法还有：时间差、判断相等 8、定时器 方式1：使用time.NewTicker（时间间隔）来设置定时器 // 定时器, 定义一个1秒间隔的定时器 ticker := time.NewTicker(time.Second) n := 0 for i := range ticker.C { fmt.Println(i) n++ if n>5 { // 终止定时器 ticker.Stop() return } } 方式2：time.Sleep(time.Second)来实现定时器 for { time.Sleep(time.Second) fmt.Println(\"一秒后\") } "},"GoLang/GoLang基础/12-指针.html":{"url":"GoLang/GoLang基础/12-指针.html","title":"指针","keywords":"","body":"datetime:2020/10/26 17:42 author:nzb Go中的指针 要搞明白Go语言中的指针需要先知道三个概念 指针地址 指针类型 指针取值 Go语言中的指针操作非常简单，我们只需要记住两个符号：&：取地址，*：根据地址取值 1、关于指针 我们知道变量是用来存储数据的，变量的本质是给存储数据的内存地址起了一个好记的别名。比如我们定义了一个变量a:=10，这个时候可以直接通过a这个变量来读取内存中保存的10这个值。在计算机底层a这个变量其实对应了一个内存地址。 指针也是一个变量，但它是一种特殊的变量，它存储的数据不是一个普通的值，而是另一个变量的内存地址。 2、指针地址和指针类型 每个变量在运行时都拥有一个地址，这个地址代表变量在内存中的位置。Go 语言中使用&字符放在变量前面对变量进行取地址操作。Go语言中的值类型（int、float、bool、string、array、struct）都有对应的指针类型，如： *int、，*int64、*string等 取变量指针的语法如下： ptr := &v 其中： v：代表被取地址的变量，类型为T ptr：用于接收地址的变量，ptr的类型就为T，被称做T的指针类型。\\ 代表指针 举个例子： 3、指针取值 在对普通变量进行&操作符取地址后，会获得这个变量指针，然后可以对指针使用*操作，也就是指针取值 // 指针取值 var c = 20 // 得到c的地址，赋值给d var d = &c // 指针类型 *int // 打印d的值，也就是c的地址 fmt.Println(d) // 取出d指针所对应的值 fmt.Println(*d) // c对应地址的值，改成30 *d = 30 // c已经变成30了 fmt.Println(c) 改变内存中的值，会直接改变原来的变量值 // 这个类似于值传递 func fn4(x int) { x = 10 } // 这个类似于引用数据类型 func fn5(x *int) { *x = 20 } func main() { x := 5 fn4(x) fmt.Println(x) fn5(&x) fmt.Println(x) } 我们创建了两个方法，一个是传入局部变量，一个是传入指针类型，最后运行得到的结果 5 20 4、new和make函数 需要注意的是，指针必须在创建内存后才可以使用，这个和 slice 和 map是一样的 // 报错，map,slice等是引用数据类型需要分配空间 var userInfo = map[string]string userInfo[\"userName\"] = \"zhangsan\" fmt.Println(userInfo) // 引用数据类型map、slice等，必须使用make分配空间，才能够使用 var userInfo = make(map[string]string) userInfo[\"userName\"] = \"zhangsan\" fmt.Println(userInfo) var array = make([]int, 4, 4) array[0] = 1 fmt.Println(array) 对于指针变量来说 // 指针变量初始化 var a *int *a = 100 fmt.Println(a) 正确做法 var a *int a = new(int) *a = 100 fmt.Println(a) 执行上面的代码会引发panic，为什么呢？在Go语言中对于引用类型的变量，我们在使用的时候不仅要声明它，还要为它分配内存空间，否则我们的值就没办法存储。而对于值类型的声明不需要分配内存空间，是因为它们在声明的时候已经默认分配好了内存空间。要分配内存，就引出来今天的new和make。Go 语言中new和make是内建的两个函数，主要用来分配内存。 这个时候，我们就需要使用new关键字来分配内存，new是一个内置的函数，它的函数签名如下： func new(Type) *Type 其中 Type表示类型，new函数只接受一个参数，这个参数是一个类型 *Type表示类型指针，new函数返回一个指向该类型内存地址的指针 实际开发中new函数不太常用，使用new函数得到的是一个类型的指针，并且该指针对应的值为该类型的零值。举个例子： // 使用new关键字创建指针 aPoint := new(int) bPoint := new(bool) fmt.Printf(\"%T \\n\", aPoint) fmt.Printf(\"%T \\n\", bPoint) fmt.Println(*aPoint) fmt.Println(*bPoint) 本节开始的示例代码中 var a *int 只是声明了一个指针变量a但是没有初始化，指针作为引用类型需要初始化后才会拥有内存空间，才可以给它赋值。应该按照如下方式使用内置的 5、make和new的区别 两者都是用来做内存分配的 make只能用于slice、map以及channel的初始化，返回的还是这三个引用类型的本身 而new用于类型的内存分配，并且内存对应的值为类型的零值，返回的是指向类型的指针（不常用） "},"GoLang/GoLang基础/13-结构体.html":{"url":"GoLang/GoLang基础/13-结构体.html","title":"结构体","keywords":"","body":"datetime:2020/10/26 18:03 author:nzb Go中的结构体 1、关于结构体 Golang中没有“类”的概念，Golang中的结构体和其他语言中的类有点相似。和其他面向对象语言中的类相比，Golang中的结构体具有更高的扩展性和灵活性。 Golang中的基础数据类型可以装示一些事物的基本属性，但是当我们想表达一个事物的全部或部分属性时，这时候再用单一的基本数据类型就无法满足需求了，Golang提供了一种自定义数据类型，可以封装多个基本数据类型，这种数据类型叫结构体，英文名称struct。也就是我们可以通过struct来定义自己的类型了。 2、Type关键字 Golang中通过type关键词定义一个结构体，需要注意的是，数组和结构体都是值类型，在这个和Java是有区别的 2.1、自定义类型 在Go语言中有一些基本的数据类型，如string、整型、浮点型、布尔等数据类型，Go语言中可以使用type关键字来定义自定义类型。 type myInt int 上面代码表示：将mylnt定义为int类型，通过type关键字的定义，mylnt就是一种新的类型，它具有int的特性。 示例：如下所示，我们定义了一个myInt类型 type myInt int func main() { var a myInt = 10 fmt.Printf(\"%v %T\", a, a) } 输出查看它的值以及类型，能够发现该类型就是myInt类型 10 main.myInt 除此之外，我们还可以定义一个方法类型 func fun(x int, y int)int { return x + y } func main() { var fn myFn = fun fmt.Println(fn(1, 2)) } 然后调用并输出 3 2.2、类型别名 Golang1.9版本以后添加的新功能 类型别名规定：TypeAlias只是Type的别名，本质上TypeAlias与Type是同一个类型。就像一个孩子小时候有大名、小名、英文名，但这些名字都指的是他本人 type TypeAlias = Type 我们之前见过的rune 和 byte 就是类型别名，他们的底层代码如下 type byte = uint8 type rune = int32 示例 type myInt int // 自定义类型 type myFloat = float64 // 类型别名 func main(){ var a myInt = 10 fmt.Printf(\"%v %T\", a, a) // 10 main.myInt var b myFloat = 12.3 fmt.Printf(\"%v %T\", b, b) // 12.3 float64s } 3、结构体定义和初始化 3.1、结构体的定义 使用type 和 struct关键字来定义结构体，具体代码格式如下所示： type 类型名 struct { 字段名 字段类型 字段名 字段类型 ... } 其中 类型名：表示自定义结构体的名称，在同一个包内不能重复。 字段名：表示结构体字段名。结构体中的字段名必须唯一。 字段类型：表示结构体字段的具体类型。 /** 定义一个人结构体 */ type Person struct { name string age int sex string } func main() { // 实例化结构体 var person Person person.name = \"张三\" person.age = 20 person.sex = \"男\" fmt.Printf(\"%#v\", person) } 注意：结构体首字母可以大写也可以小写，大写表示这个结构体是公有的，在其它的包里面也可以使用，小写表示结构体属于私有的，在其它地方不能使用 例如： type Person struct { Name string Age int Sex string } 3.2、实例化结构体1 刚刚实例化结构体用到了：var person Person // 实例化结构体 var person Person person.name = \"张三\" person.age = 20 person.sex = \"男\" 3.3、实例化结构体2 我们下面使用另外一个方式来实例化结构体，通过new关键字来实例化结构体，得到的是结构体的地址，格式如下 var person2 = new(Person) person2.name = \"李四\" person2.age = 30 person2.sex = \"女\" fmt.Printf(\"%#v\", person2) 输出如下所示，从打印结果可以看出person2是一个结构体指针 &main.Person{name:\"李四\", age:30, sex:\"女\"} 需要注意：在Golang中支持对结构体指针直接使用，来访问结构体的成员 person2.name = \"李四\" // 等价于 (*person2).name = \"李四\" 3.4、实例化结构体3 使用&对结构体进行取地址操作，相当于对该结构体类型进行了一次new实例化操作 // 第三种方式实例化 var person3 = &Person{} person3.name = \"赵四\" person3.age = 28 person3.sex = \"男\" fmt.Printf(\"%#v\", person3) 3.5、实例化结构体4 使用键值对的方式来实例化结构体，实例化的时候，可以直接指定对应的值 // 第四种方式初始化 var person4 = Person{ name: \"张三\", age: 10, sex: \"女\", } fmt.Printf(\"%#v\", person4) 3.6、实例化结构体5 第五种和第四种差不多，不过是用了取地址，然后返回的也是一个地址 // 第五种方式初始化 var person5 = &Person{ name: \"孙五\", age: 10, sex: \"女\", } fmt.Printf(\"%#v\", person5) 3.7、实例化结构体6 第六种方式是可以简写结构体里面的key var person6 = Person{ \"张三\", 5, \"女\", } fmt.Println(person6) 4、结构体方法和接收者 在go语言中，没有类的概念但是可以给类型（结构体，自定义类型）定义方法。所谓方法就是定义了接收者的函数。接收者的概念就类似于其他语言中的this 或者self。 方法的定义格式如下： func (接收者变量 接收者类型) 方法名(参数列表)(返回参数) { 函数体 } 其中 接收者变量：接收者中的参数变量名在命名时，官方建议使用接收者类型名的第一个小写字母，而不是self、this之类的命名。例如，Person类型的接收者变量应该命名为p，Connector类型的接收者变量应该命名为c等。、 接收者类型：接收者类型和参数类似，可以是指针类型和非指针类型。 非指针类型：表示不修改结构体的内容 指针类型：表示修改结构体中的内容 方法名、参数列表、返回参数：具体格式与函数定义相同 如果示例所示： /** 定义一个人结构体 */ type Person struct { name string age int sex string } // 定义一个结构体方法 func (p Person) PrintInfo() { fmt.Print(\" 姓名: \", p.name) fmt.Print(\" 年龄: \", p.age) fmt.Print(\" 性别: \", p.sex) fmt.Println() } func (p *Person) SetInfo(name string, age int, sex string) { p.name = name p.age = age p.sex = sex } func main() { var person = Person{ \"张三\", 18, \"女\", } person.PrintInfo() person.SetInfo(\"李四\", 18, \"男\") person.PrintInfo() } 运行结果为： 姓名: 张三 年龄: 18 性别: 女 姓名: 李四 年龄: 18 性别: 男 注意，因为结构体是值类型，所以我们修改的时候，因为是传入的指针(修改的是实例里面的属性) func (p *Person) SetInfo(name string, age int, sex string) { p.name = name p.age = age p.sex = sex } 不传指针(修改是结构体的属性p，不是修改的结构体实例的值，所以都一样)func (p Person) SetInfo(name string, age int, sex string) { p.name = name p.age = age p.sex = sex } 姓名: 张三 年龄: 18 性别: 女 姓名: 张三 年龄: 18 性别: 女 5、给任意类型添加方法 在Go语言中，接收者的类型可以是任何类型，不仅仅是结构体，任何类型都可以拥有方法。 举个例子，我们基于内置的int类型使用type关键字可以定义新的自定义类型，然后为我们的自定义类型添加方法。 type myInt int func fun(x int, y int)int { return x + y } func (m myInt) PrintInfo() { fmt.Println(\"我是自定义类型里面的自定义方法\") } func main() { var a myInt = 10 fmt.Printf(\"%v %T \\n\", a, a) a.PrintInfo() } 注意：非本地类型不能定义方法，也就是说我们不能给别的包的类型定义方法。 6、结构体的匿名字段 结构体允许其成员字段在声明时没有字段名而只有类型，这种没有名字的字段就被称为匿名字段 匿名字段默认采用类型名作为字段名，结构体要求字段名称必须唯一，因此一个结构体中同种类型的匿名字段只能一个 /** 定义一个人结构体 */ type Person struct { string int } func main() { // 结构体的匿名字段 var person = Person{ \"张三\", 18 } } 结构体的字段类型可以是：基本数据类型，也可以是切片、Map 以及结构体 如果结构体的字段类型是：指针、slice、和 map 的零值都是nil，即还没有分配空间 如果需要使用这样的字段，需要先make，才能使用 /** 定义一个人结构体 */ type Person struct { name string age int hobby []string mapValue map[string]string } func main() { // 结构体的匿名字段 var person = Person{} person.name = \"张三\" person.age = 10 // 给切片申请内存空间 person.hobby = make([]string, 4, 4) person.hobby[0] = \"睡觉\" person.hobby[1] = \"吃饭\" person.hobby[2] = \"打豆豆\" // 给map申请存储空间 person.mapValue = make(map[string]string) person.mapValue[\"address\"] = \"北京\" person.mapValue[\"phone\"] = \"123456789\" // 加入#打印完整信息 fmt.Printf(\"%#v\", person) } 同时我们还支持结构体的嵌套，如下所示 // 用户结构体 type User struct { userName string password string sex string age int address Address // User结构体嵌套Address结构体 } // 收货地址结构体 type Address struct { name string phone string city string } func main() { var u User u.userName = \"moguBlog\" u.password = \"123456\" u.sex = \"男\" u.age = 18 var address Address address.name = \"张三\" address.phone = \"110\" address.city = \"北京\" u.address = address fmt.Printf(\"%#v\", u) } 7、嵌套结构体的字段名冲突 嵌套结构体内部可能存在相同的字段名，这个时候为了避免歧义，需要指定具体的内嵌结构体的字段。（例如，父结构体中的字段 和 子结构体中的字段相似） 默认会从父结构体中寻找，如果找不到的话，再去子结构体中在找(可获取值和设置值) 如果子类的结构体中，同时存在着两个相同的字段，那么这个时候就会报错了，因为程序不知道修改那个字段的为准。 8、结构体的继承 结构体的继承，其实就类似于结构体的嵌套，可嵌套结构体或结构体指针，如下所示，我们定义了两个结构体，分别是Animal 和 Dog，其中每个结构体都有各自的方法，然后通过Dog结构体 继承于 Animal结构体 继承-嵌套结构体 // 用户结构体 type Animal struct { name string } func (a Animal) run() { fmt.Printf(\"%v 在运动 \\n\", a.name) } // 子结构体 type Dog struct { age int // 通过结构体嵌套，完成继承 Animal } func (dog Dog) wang() { fmt.Printf(\"%v 在汪汪汪 \\n\", dog.name) } func main() { var dog = Dog{ age: 10, Animal: Animal{ name: \"阿帕奇\", }, } dog.run(); dog.wang(); } 运行后，发现Dog拥有了父类的方法 阿帕奇 在运动 阿帕奇 在汪汪汪 继承-嵌套结构体指针 // 用户结构体 type Animal struct { name string } func (a Animal) run() { fmt.Printf(\"%v 在运动 \\n\", a.name) } // 子结构体 type Dog struct { age int // 通过结构体嵌套，完成继承 *Animal // 这边继承的是指结构体指针 } func (dog Dog) wang() { fmt.Printf(\"%v 在汪汪汪 \\n\", dog.name) } func main() { var dog = Dog{ age: 10, Animal: &Animal{ // 因为什么继承的是结构体指针，所以这边需要传指针 name: \"阿帕奇\", }, } dog.run(); dog.wang(); } 9、Go中的结构体和Json相互转换 JSON（JavaScript Object Notation）是一种轻量级的数据交换格式。易于人阅读和编写。同时也易于机器解析和生成。RESTfull Api接口中返回的数据都是json数据。 { \"name\": \"张三\", \"age\": 15 } 比如我们Golang要给App或者小程序提供Api接口数据，这个时候就需要涉及到结构体和Json之间的相互转换 Golang JSON序列化是指把结构体数据转化成JSON格式的字符串，Golang JSON的反序列化是指把JSON数据转化成Golang中的结构体对象 Golang中的序列化和反序列化主要通过“encoding/json”包中的 json.Marshal() 和 son.Unmarshal() // 定义一个学生结构体，注意结构体的首字母必须大写，代表公有，否则将无法转换 type Student struct { ID string Gender string Name string Sno string } func main() { var s1 = Student{ ID: \"12\", Gender: \"男\", Name: \"李四\", Sno: \"s001\", } // 结构体转换成Json（返回的是byte类型的切片） jsonByte, _ := json.Marshal(s1) jsonStr := string(jsonByte) fmt.Printf(jsonStr) } 将字符串转换成结构体类型 // 定义一个学生结构体，注意结构体的首字母必须大写，代表公有，否则将无法转换 type Student struct { ID string Gender string Name string Sno string } func main() { // Json字符串转换成结构体 var str = `{\"ID\":\"12\",\"Gender\":\"男\",\"Name\":\"李四\",\"Sno\":\"s001\"}` var s2 = Student{} // 第一个是需要传入byte类型的数据，第二参数需要传入转换的地址，因为需要修改 s2 的属性 err := json.Unmarshal([]byte(str), &s2) if err != nil { fmt.Printf(\"转换失败 \\n\") } else { fmt.Printf(\"%#v \\n\", s2) } } 注意 我们想要实现结构体转换成字符串，必须保证结构体中的字段是公有的，也就是首字母必须是大写的，这样才能够实现结构体 到 Json字符串的转换。 10、结构体标签Tag Tag是结构体的元信息，可以在运行的时候通过反射的机制读取出来。Tag在结构体字段的后方定义，由一对反引号包裹起来，具体的格式如下： key1：\"value1\" key2：\"value2\" 结构体tag由一个或多个键值对组成。键与值使用冒号分隔，值用双引号括起来。同一个结构体字段可以设置多个键值对tag，不同的键值对之间使用空格分隔。 注意事项：为结构体编写Tag时，必须严格遵守键值对的规则。结构体标签的解析代码的容错能力很差，一旦格式写错，编译和运行时都不会提示任何错误，通过反射也无法正确取值。例如不要在key和value之间添加空格。 如下所示，我们通过tag标签，来转换字符串的key // 定义一个Student体，使用结构体标签 type Student2 struct { Id string `json:\"id\"` // 通过指定tag实现json序列化该字段的key Gender string `json:\"gender\"` Name string `json:\"name\"` Sno string `json:\"sno\"` } func main() { var s1 = Student2{ Id: \"12\", Gender: \"男\", Name: \"李四\", Sno: \"s001\", } // 结构体转换成Json jsonByte, _ := json.Marshal(s1) jsonStr := string(jsonByte) fmt.Println(jsonStr) // Json字符串转换成结构体 var str = `{\"Id\":\"12\",\"Gender\":\"男\",\"Name\":\"李四\",\"Sno\":\"s001\"}` var s2 = Student2{} // 第一个是需要传入byte类型的数据，第二参数需要传入转换的地址 err := json.Unmarshal([]byte(str), &s2) if err != nil { fmt.Printf(\"转换失败 \\n\") } else { fmt.Printf(\"%#v \\n\", s2) } } 11、嵌套结构体和Json序列化反序列化 和刚刚类似，我们同样也是使用的是 json.Marshal() // 嵌套结构体 到 Json的互相转换 // 定义一个Student结构体 type Student3 struct { Id int Gender string Name string } // 定义一个班级结构体 type Class struct { Title string Students []Student3 } func main() { var class = Class{ Title: \"1班\", Students: make([]Student3, 0), } for i := 0; i "},"GoLang/GoLang基础/14-GoMod及包.html":{"url":"GoLang/GoLang基础/14-GoMod及包.html","title":"GoMod及包","keywords":"","body":"datetime:2020/10/28 15:19 author:nzb Go中的包 1、Go中的包的介绍和定义 包（package）是多个Go源码的集合，是一种高级的代码复用方案，Go语言为我们提供了很多内置包，如fmt、strconv、strings、sort、errors、time、encoding/json、os、io等。 Golang中的包可以分为三种：1、系统内置包 2、自定义包 3、第三方包 系统内置包：Golang 语言给我们提供的内置包，引入后可以直接使用，如fmt、strconv、strings、sort、errors、time、encoding/json、os、io等。 自定义包：开发者自己写的包 第三方包：属于自定义包的一种，需要下载安装到本地后才可以使用，如前面给大家介绍的 \"github.com/shopspring/decimal\"包解决float精度丢失问题。 2、Go包管理工具 go mod 在Golang1.11版本之前如果我们要自定义包的话必须把项目放在GOPATH目录。Go1.11版本之后无需手动配置环境变量，使用go mod 管理项目，也不需要非得把项目放到GOPATH指定目录下，你可以在你磁盘的任何位置新建一个项目，Go1.13以后可以彻底不要GOPATH了。 2.1、go mod init初始化项目 实际项目开发中我们首先要在我们项目目录中用go mod命令生成一个go.mod文件管理我们项目的依赖。 比如我们的golang项目文件要放在了 goProject 这个文件夹，这个时候我们需要在 goProject 文件夹里面使用go mod命令生成一个go.mod文件 go mod init goProject 然后会生成一个 go.mod 的文件，里面的内容是go版本，以及以后添加的包 module goProject go 1.14 2.2、引入其它项目的包 首先我们创建一个 calc，然后里面有一个calc的文件 package calc // 自定义包，最好和文件夹统一起来 // 私有变量 var age = 10 // 公有变量 var Name = \"张三\" // 首字母大写，表示共有方法 func Add(x, y int)int { return x + y } func Sub(x, y int)int { return x - y } 在其它地方需要引用的话，就是这样 package main import ( \"fmt\" \"goProject/calc\" ) func main() { fmt.Printf(\"%v\", calc.Add(2, 5)) } 2.3、导入一个包 单行导入 import \"包1\" import \"包2\" 多行导入 import ( \"包1\" \"包2\" ) 自定义包名在导入包名的时候，我们还可以为导入的包设置别名。通常用于导入的包名太长或者导入的包名冲突的情况。具体格式 import 别名 \"包的路径\" // 单行引入定义别名 import c \"goProject/calc\" // 多行引入定义别名 import ( \"fmt\" T \"goProject/calc\" ) fmt.Println(T.test()) 匿名导入包如果只希望导入包，而不使用内部的数据时，可以使用匿名导入包。具体格式 import _ \"包的路径\" 3、Golang中自定义包 包（package）是多个Go源码的集合，一个包可以简单理解为一个存放多个.go文件的文件夹。该文件夹下面的所有go文件都要在代码的第一行添加如下代码，声明该文件归属的包。 package 包名 注意事项 一个文件夹下面直接包含的文件只能归属一个package，同样一个package的文件不能在多个文件夹下。 包名可以不和文件夹的名字一样，包名不能包含-符号。 包名为main的包为应用程序的入口包，这种包编译后会得到一个可执行文件，而编译不包含main包的源代码则不会得到可执行文件。 4、Go中init()初始化函数 4.1、init函数介绍 在Go 语言程序执行时导入包语句会自动触发包内部init（）函数的调用。需要注意的是：init（） 函数没有参数也没有返回值。init（）函数在程序运行时自动被调用执行，不能在代码中主动调用它。 包初始化执行的顺序如下图所示： 包初始化执行的顺序如下图所示： 4.2、init函数执行顺序 Go语言包会从main包开始检查其导入的所有包，每个包中又可能导入了其他的包。Go编译器由此构建出一个树状的包引用关系，再根据引用顺序决定编译顺序，依次编译这些包的代码。 在运行时，被最后导入的包会最先初始化并调用其init（）函数，如下图示： 也就是父类中的init先执行 5、Go中的第三方包 我们可以在 https://pkg.go.dev/ 查找看常见的golang第三方包 例如，前面找到前面我们需要下载的第三方包的地址 https://github.com/shopspring/decimal 然后安装这个包 5.1、方法1：go get 包全名 （全局） go get github.com/shopspring/decimal 5.2、方法2：go mod download （全局） go mod download 依赖包会自动下载到 $GOPATH/pkg/mod目录，并且多个项目可以共享缓存的mod，注意使用go mod download的时候，需要首先在你的项目中引入第三方包 5.3、方法3：go mod vendor 将依赖复制到当前项目的vendor（本项目） go mod vendor 将依赖复制到当前项目的vendor下 注意：使用go mod vendor的时候，首先需要在你的项目里面引入第三方包 5.4、go mod常见命令 go download：下载依赖的module到本地cache go edit：编辑go.mod文件 go graph：打印模块依赖图 go init：在当前文件夹下初始化一个新的module，创建go.mod文件 tidy：增加丢失的module，去掉未使用的module vendor：将依赖复制到vendor下 verify：校验依赖，检查下载的第三方库有没有本地修改，如果有修改，则会返回非0，否则校验成功 6、安装依赖 首先我们先去官网找到这个包，https://github.com/shopspring/decimal 然后在我们的项目中引入 import ( \"fmt\" \"github.com/shopspring/decimal\" \"goProject/calc\" ) func main() { fmt.Printf(\"%v \\n\", calc.Add(2, 5)) // 打印公有变量 fmt.Println(calc.Name) _, err := decimal.NewFromString(\"136.02\") if err != nil { panic(err) } } 引入后，我们运行项目，就会去下载了，下载完成后，我们到 go.mod文件，能够看到依赖被引入了 module goProject go 1.14 require github.com/shopspring/decimal v1.2.0 // indirect 同时还生成了一个 go.sum文件 github.com/shopspring/decimal v1.2.0 h1:abSATXmQEYyShuxI4/vyW3tV1MrKAJzCZ/0zLUXYbsQ= github.com/shopspring/decimal v1.2.0/go.mod h1:DKyhrW/HYNuLGql+MJL6WCR6knT2jwCFRcu2hWCYk4o= 这样我们就可以使用第三包开始具体的使用了~，我们实现一个Float类型的加法 package main import ( \"fmt\" \"github.com/shopspring/decimal\" ) func main() { var num1 float64 = 3.1 var num2 float64 = 4.2 d1 := decimal.NewFromFloat(num1).Add(decimal.NewFromFloat(num2)) fmt.Println(d1) } 7、完整案例 寻找依赖 首先我们需要去 依赖官网，类似于我们的 maven repository 然后我们搜索gJson的包，这个包主要是用于json相关的操作 我们进去后，找到它的https://github.com/tidwall/gjson，然后提供了完整的教程 # 下载依赖 go get -u github.com/tidwall/gjson 使用 package main import \"github.com/tidwall/gjson\" const json = `{\"name\":{\"first\":\"Janet\",\"last\":\"Prichard\"},\"age\":47}` func main() { value := gjson.Get(json, \"name.last\") println(value.String()) } "},"GoLang/GoLang基础/15-接口.html":{"url":"GoLang/GoLang基础/15-接口.html","title":"接口","keywords":"","body":"datetime:2021/12/02 14:55 author:nzb Go中的接口 接口的介绍 现实生活中手机、相机、U盘都可以和电脑的USB接口建立连接。我们不需要关注usb卡槽大小是否一样，因为所有的USB接口都是按照统一的标准来设计的。 Golang中的接口是一种抽象数据类型，Golang中接口定义了对象的行为规范，只定义规范不实现。接口中定义的规范由具体的对象来实现。 通俗的讲接口就一个标准，它是对一个对象的行为和规范进行约定，约定实现接口的对象必须得按照接口的规范。 Go接口的定义 在Golang中接口（interface）是一种类型，一种抽象的类型。接口（interface）是一组函数method的集合，Golang中的接口不能包含任何变量。 在Golang中接口中的所有方法都没有方法体，接口定义了一个对象的行为规范，只定义规范不实现。接口体现了程序设计的多态和高内聚低耦合的思想N Golang中的接口也是一种数据类型，不需要显示实现。只需要一个变量含有接口类型中的所有方法，那么这个变量就实现了这个接口。 Golang中每个接口由数个方法组成，接口的定义格式如下： type 接口名 interface { 方法名1 (参数列表1) 返回值列表1 方法名2 (参数列表2) 返回值列表2 } 接口名：使用type将接口定义为自定义的类型名。Go语言的接口在命名时，一般会在单词后面添加er，如有写操作的接口叫Writer，有字符串功能的接口叫Stringer等，接口名最好突出该接口的类型含义。 方法名：当方法名首字母是大写且这个接口类型名首字母也是大写时，这个方法可以被接口所在的包（package）之外的代码访问。 参数列表、返回值列表：参数列表和返回值列表中的参数变量名是可以省略 演示：定义一个Usber接口让Phone 和 Camera结构体实现这个接口 首先我们定义一个Usber接口，接口里面就定义了两个方法 // 定义一个Usber接口 type Usber interface { start() stop() } 注意：如果接口里面有方法的话，必须要通过结构体或自定义类型实现这个接口 然后我们创建一个Phone的结构体，来实现这个接口 // 使用结构体来实现 接口 type Phone struct { Name string } // 手机要实现Usber接口的话，必须实现usb接口的所有方法 func (p Phone) start() { fmt.Println(p.Name, \"启动\") } func (p Phone) stop() { fmt.Println(p.Name, \"关闭\") } func main() { var phone Usber = Phone{ \"三星手机\", } phone.start() phone.stop() } 我们再创建一个Camera结构体 // 使用相机结构体来实现 接口 type Camera struct { Name string } // 相机要实现Usber接口的话，必须实现usb接口的所有方法 func (p Camera) start() { fmt.Println(p.Name, \"启动\") } func (p Camera) stop() { fmt.Println(p.Name, \"关闭\") } func main() { var camera Usber = Camera{ \"佳能\", } camera.start() camera.stop() } 我们创建一个电脑的结构体，电脑的结构体就是用于接收两个实现了Usber的结构体，然后让其工作 // 电脑 type Computer struct { } // 接收一个实现了Usber接口的 结构体 func (computer Computer) Startup(usb Usber) { usb.start() } // 关闭 func (computer Computer) Shutdown (usb Usber) { usb.stop() } 最后我们在main中调用方法 func main() { var camera interfaceDemo.Camera = interfaceDemo.Camera{ \"佳能\", } var phone interfaceDemo.Phone = interfaceDemo.Phone{ \"苹果\", } var computer interfaceDemo.Computer = interfaceDemo.Computer{} computer.Startup(camera) computer.Startup(phone) computer.Shutdown(camera) computer.Shutdown(phone) 运行结果如下所示： 佳能 启动 苹果 启动 佳能 关闭 苹果 关闭 空接口（Object类型） Golang中的接口可以不定义任何方法，没有定义任何方法的接口就是空接口。空接口表示没有任何约束，因此任何类型变量都可以实现空接口。 空接口在实际项目中用的是非常多的，用空接口可以表示任意数据类型。 // 空接口表示没有任何约束，任意的类型都可以实现空接口 type EmptyA interface { } func main() { var a EmptyA var str = \"你好golang\" // 让字符串实现A接口 a = str fmt.Println(a) } 同时golang中空接口也可以直接当做类型来使用，可以表示任意类型。相当于Java中的Object类型 var a interface{} a = 20 a = \"hello\" a = true 空接口可以作为函数的参数，使用空接口可以接收任意类型的函数参数 // 空接口作为函数参数 func show(a interface{}) { fmt.println(a) } map的值实现空接口 使用空接口实现可以保存任意值的字典 // 定义一个值为空接口类型 var studentInfo = make(map[string]interface{}) studentInfo[\"userName\"] = \"张三\" studentInfo[\"age\"] = 15 studentInfo[\"isWork\"] = true slice切片实现空接口 // 定义一个空接口类型的切片 var slice = make([]interface{}, 4, 4) slice[0] = \"张三\" slice[1] = 1 slice[2] = true 类型断言 一个接口的值（简称接口值）是由一个具体类型和具体类型的值两部分组成的。这两部分分别称为接口的动态类型和动态值。 如果我们想要判断空接口中值的类型，那么这个时候就可以使用类型断言，其语法格式： x.(T) x：表示类型为interface{}的变量 T：表示断言x可能是的类型 该语法返回两个参数，第一个参数是x转化为T类型后的变量，第二个值是一个布尔值，若为true则表示断言成功，为false则表示断言失败 // 类型断言 var a interface{} a = \"132\" value, isString := a.(string) if isString { fmt.Println(\"是String类型, 值为：\", value) } else { fmt.Println(\"断言失败\") } 或者我们可以定义一个能传入任意类型的方法 // 定义一个方法，可以传入任意数据类型，然后根据不同类型实现不同的功能 func Print(x interface{}) { if _,ok := x.(string); ok { fmt.Println(\"传入参数是string类型\") } else if _, ok := x.(int); ok { fmt.Println(\"传入参数是int类型\") } else { fmt.Println(\"传入其它类型\") } } 上面的示例代码中，如果要断言多次，那么就需要写很多if，这个时候我们可以使用switch语句来实现： 注意： 类型.(type) 只能结合switch语句使用 func Print2(x interface{}) { switch x.(type) { case int: fmt.Println(\"int类型\") case string: fmt.Println(\"string类型\") case bool: fmt.Println(\"bool类型\") default: fmt.Println(\"其它类型\") } } 结构体接收者 值接收者 如果结构体中的方法是值接收者，那么实例化后的结构体值类型和结构体指针类型都可以赋值给接口变量 package main import \"fmt\" type Usber interface { start() stop() } type Phone struct { Name string } func (p Phone) start() { // 值接收者 fmt.Println(p.Name, \"启动\") } func (p Phone) stop() { fmt.Println(p.Name, \"关机\") } func main() { var p1 = Phone{ // 结构体值类型 Name: \"华为手机\", } var p2 Usber = p1 // 表示让 Phone 实现 Usb 的接口 p2.start() var p3 = &Phone{ // 结构体指针类型 Name: \"小米手机\", } var p4 Usber = p3 p4.start() } 指针接收者 如果结构体中的方法是指针接收者，那么实例化后结构体指针类型都可以赋值给接口变量，结构体指类型不能赋值给接口变量 package main import \"fmt\" type Usber interface { start() stop() } type Phone struct { Name string } func (p *Phone) start() { // 指针接收者 fmt.Println(p.Name, \"启动\") } func (p *Phone) stop() { fmt.Println(p.Name, \"关机\") } func main() { /* 错误写法 var p1 = Phone{ // 结构体值类型 Name: \"华为手机\", } var p2 Usber = p1 // Phone does not implement Usber (start method has pointer receiver) p2.start() */ var p3 = &Phone{ // 结构体指针类型 Name: \"小米手机\", } var p4 Usber = p3 p4.start() } 结构体实现多个接口 实现多个接口的话，可能就同时用两个接口进行结构体的接受 // 定义一个Animal的接口，Animal中定义了两个方法，分别是setName 和 getName，分别让DOg结构体和Cat结构体实现 type Animal interface { SetName(string) } // 接口2 type Animal2 interface { GetName()string } type Dog struct { Name string } func (d *Dog) SetName(name string) { d.Name = name } func (d Dog)GetName()string { return d.Name } func main() { var dog = &Dog{ \"小黑\", } // 同时实现两个接口 var d1 Animal = dog var d2 Animal2 = dog d1.SetName(\"小鸡\") fmt.Println(d2.GetName()) } 接口嵌套 在golang中，允许接口嵌套接口，我们首先创建一个 Animal1 和 Animal2 接口，然后使用Animal接受刚刚的两个接口，实现接口的嵌套。 // 定义一个Animal的接口，Animal中定义了两个方法，分别是setName 和 getName，分别让DOg结构体和Cat结构体实现 type Animal1 interface { SetName(string) } // 接口2 type Animal2 interface { GetName()string } type Animal interface { Animal1 Animal2 } type Dog struct { Name string } func (d *Dog) SetName(name string) { d.Name = name } func (d Dog)GetName()string { return d.Name } func main() { var dog = &Dog{ \"小黑\", } // 同时实现两个接口 var d Animal = dog d.SetName(\"小鸡\") fmt.Println(d.GetName()) } Golang中空接口和类型断言 package main import \"fmt\" type Address struct { Name string Phone int } func main() { // golang中空接口和类型断言 var userInfo = make(map[string]interface{}) userInfo[\"userName\"] = \"zhangsan\" userInfo[\"age\"] = 10 userInfo[\"hobby\"] = []string{\"吃饭\", \"睡觉\"} fmt.Println(userInfo[\"userName\"]) fmt.Println(userInfo[\"age\"]) fmt.Println(userInfo[\"hobby\"]) // 但是我们空接口如何获取数组中的值？发现 userInfo[\"hobby\"][0] 这样做不行 // fmt.Println(userInfo[\"hobby\"][0]) // invalid operation: userInfo[\"hobby\"][0] (index of type interface {}) var address = Address{ Name: \"李四\", Phone: 110, } userInfo[\"address\"] = address fmt.Println(address.Name) fmt.Println(userInfo[\"address\"]) // {李四 110} // fmt.Println(userInfo[\"address\"].Name) //userInfo[\"address\"].Name undefined (type interface {} has no field or method Name) // 可通过断言获取 hobby2, _ := userInfo[\"hobby\"].([]string) fmt.Println(hobby2[1]) address2, _ := userInfo[\"address\"].(Address) fmt.Println(address2.Name) } 也就是我们的空接口，无法直接通过索引获取数组中的内容，因此这个时候就需要使用类型断言了 // 这个时候我们就可以使用类型断言了 hobbyValue,ok := userInfo[\"hobby\"].([]string) if ok { fmt.Println(hobbyValue[0]) } 通过类型断言返回来的值，我们就能够直接通过角标获取了。 确保接口的所有方法被实现（利用强制类型转换） 一般而言，接口定义了一组方法的集合，接口不能被实例化，一个类型可以实现多个接口。 举一个简单的例子，定义一个接口 Person和对应的方法 getName()： package main import \"fmt\" type Person interface { getName() string } type Student struct { name string age int } func (stu *Student) getName() string { return stu.name } type Worker struct { name string age int } func (w *Worker) getName() string { return w.name } // 确保某个类型实现了某个接口的所有方法 var _ Person = (*Student)(nil) var _ Person = (*Worker)(nil) func main() { var p Person = &Student{ name: \"小明\", age: 18, } fmt.Println(p.getName()) // 小明 } Go 语言中，并不需要显式地声明实现了哪一个接口，只需要直接实现该接口对应的方法即可。 实例化 Student后，强制类型转换为接口类型 Person。 在上面的例子中，我们在 main 函数中尝试将 Student 实例类型转换为 Person，如果 Student 没有完全实现 Person 的方法，比如我们将 (*Student).getName() 删掉，编译时会出现如下报错信息。 *Student does not implement Person (missing getName method) 但是删除 (*Worker).getName() 程序并不会报错，因为我们并没有在 main 函数中使用。这种情况下我们如何确保某个类型实现了某个接口的所有方法呢？一般可以使用下面的方法进行检测，如果实现不完整，编译期将会报错。 var _ Person = (*Student)(nil) var _ Person = (*Worker)(nil) 将空值 nil 转换为 *Student 类型，再转换为 Person 接口，如果转换失败，说明 Student 并没有实现 Person 接口的所有方法。 Worker 同上。 实例可以强制类型转换为接口，接口也可以强制类型转换为实例。 func main() { var p Person = &Student{ name: \"Tom\", age: 18, } stu := p.(*Student) // 接口转为实例 fmt.Println(stu.getAge()) } 这是确保接口被实现常用的方式。即利用强制类型转换，确保 struct Student 实现了接口 Person。这样 IDE 和编译期间就可以检查，而不是等到使用的时候。 "},"GoLang/GoLang基础/16-goroutine实现并行和并发.html":{"url":"GoLang/GoLang基础/16-goroutine实现并行和并发.html","title":"协程","keywords":"","body":"datetime:2021/12/27 21:53 author:nzb Golang goroutine channel 实现并发和并行 为什么要使用goroutine呢 需求：要统计1-10000000的数字中那些是素数，并打印这些素数？ 素数：就是除了1和它本身不能被其他数整除的数 实现方法： 传统方法，通过一个for循环判断各个数是不是素数 使用并发或者并行的方式，将统计素数的任务分配给多个 goroutine 去完成，这个时候就用到了goroutine goroutine 结合 channel 进程、线程以及并行、并发 进程 进程（Process）就是程序在操作系统中的一次执行过程，是系统进行资源分配和调度的基本单位，进程是一个动态概念，是程序在执行过程中分配和管理资源的基本单位，每一个进程都有一个自己的地址空间。一个进程至少有5种基本状态，它们是：初始态，执行态，等待状态，就绪状态，终止状态。 通俗的讲进程就是一个正在执行的程序。 线程 线程是进程的一个执行实例，是程序执行的最小单元，它是比进程更小的能独立运行的基本单位 一个进程可以创建多个线程，同一个进程中多个线程可以并发执行 ，一个线程要运行的话，至少有一个进程 并发和并行 并发：多个线程同时竞争一个位置，竞争到的才可以执行，每一个时间段只有一个线程在执行。 并行：多个线程可以同时执行，每一个时间段，可以有多个线程同时执行。 通俗的讲多线程程序在单核CPU上面运行就是并发，多线程程序在多核CUP上运行就是并行，如果线程数大于CPU核数，则多线程程序在多个CPU上面运行既有并行又有并发 Golang中协程（goroutine）以及主线程 Golang 中的主线程：（可以理解为线程/也可以理解为进程），在一个 Golang 程序的主线程上可以起多个协程。Golang 中多协程可以实现并行或者并发。 协程 ：可以理解为用户级线程，这是对内核透明的，也就是系统并不知道有协程的存在，是完全由用户自己的程序进行调度的。Golang的一大特色就是从语言层面原生持协程，在函数或者方法前面加go关键字就可创建一个协程。可以说Golang中的协程就是 goroutine。 Golang中的多协程有点类似于Java中的多线程 多协程和多线程 多协程和多线程：Golang 中每个 goroutine（协程）默认占用内存远比 Java、C的线程少。 OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB左右），一个 goroutine（协程）占用内存非常小，只有 2KB 左右，多协程 goroutine 切换调度开销方面远比线程要少。 这也是为什么越来越多的大公司使用Golang的原因之一。 goroutine的使用以及sync.WaitGroup 并行执行需求 在主线程（可以理解成进程）中，开启一个 goroutine，该协程每隔50毫秒秒输出“你好golang\" 在主线程中也每隔50毫秒输出“你好golang\"，输出10次后，退出程序，要求主线程和 goroutine 同时执行。 这时候，我们就可以开启协程来了，通过 go 关键字开启 // 协程需要运行的方法 func test() { for i := 0; i 运行结果如下，我们能够看到他们之间不存在所谓的顺序关系了 main 你好golang test 你好golang main 你好golang test 你好golang test 你好golang main 你好golang main 你好golang test 你好golang test 你好golang main 你好golang 但是上述的代码其实还有问题的，也就是说当主进程执行完毕后，不管协程有没有执行完成，都会退出 这是使用我们就需要用到 sync.WaitGroup 等待协程 首先我们需要创建一个协程计数器 // 定义一个协程计数器 var wg sync.WaitGroup 然后当我们开启协程的时候，我们要让计数器加1 // 开启协程，协程计数器加1 wg.Add(1) go test2() 当我们协程结束前，我们需要让计数器减1 // 协程计数器减1 wg.Done() 完整代码如下 // 定义一个协程计数器 var wg sync.WaitGroup func test() { // 这是主进程执行的 for i := 0; i 设置Go并行运行的时候占用的cpu数量 Go 运行时的调度器使用 GOMAXPROCS 参数来确定需要使用多少个 OS 线程来同时执行 Go 代码。默认值是机器上的CPU核心数。例如在一个8核心的机器上，调度器会把 Go 代码同时调度到 8个 OS 线程上。 Go 语言中可以通过 runtime.GOMAXPROCS（）函数设置当前程序并发时占用的 CPU 逻辑核心数。 Go1.5 版本之前，默认使用的是单核心执行。Go1.5版本之后，默认使用全部的 CPU 逻辑核心数。 func main() { // 获取cpu个数 npmCpu := runtime.NumCPU() fmt.Println(\"cup的个数:\", npmCpu) // 设置允许使用的CPU数量 runtime.GOMAXPROCS(runtime.NumCPU() - 1) } for循环开启多个协程 类似于Java里面开启多个线程，同时执行 func test(num int) { for i := 0; i 因为我们协程会在主线程退出后就终止，所以我们还需要使用到 sync.WaitGroup 来控制主线程的终止。 Channel管道 管道是Golang在语言级别上提供的goroutine间的通讯方式，我们可以使用channel在多个goroutine之间传递消息。如果说goroutine是Go程序并发的执行体，channel就是它们之间的连接。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 Golang的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。 Go语言中的管道（channel）是一种特殊的类型。管道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个管道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。 channel类型 channel是一种类型，一种引用类型。声明管道类型的格式如下： // 声明一个传递整型的管道 var ch1 chan int // 声明一个传递布尔类型的管道 var ch2 chan bool // 声明一个传递int切片的管道 var ch3 chan []int 创建channel 声明管道后，需要使用make函数初始化之后才能使用 make(chan 元素类型, 容量) 举例如下： // 创建一个能存储10个int类型的数据管道 ch1 = make(chan int, 10) // 创建一个能存储4个bool类型的数据管道 ch2 = make(chan bool, 4) // 创建一个能存储3个[]int切片类型的管道 ch3 = make(chan []int, 3) channel操作 管道有发送，接收和关闭的三个功能 发送和接收都使用 符号 现在我们先使用以下语句定义一个管道： ch := make(chan int, 3) 发送 将数据放到管道内，将一个值发送到管道内 // 把10发送到ch中 ch 取操作 x := 关闭管道 通过调用内置的close函数来关闭管道 close(ch) 完整示例 // 创建管道 ch := make(chan int, 3) // 给管道里面存储数据 ch for range从管道循环取值 当向管道中发送完数据时，我们可以通过close函数来关闭管道，当管道被关闭时，再往该管道发送值会引发panic，从该管道取值的操作会去完管道中的值，再然后取到的值一直都是对应类型的零值。那如何判断一个管道是否被关闭的呢？ // 创建管道 ch := make(chan int, 10) // 循环写入值 for i := 0; i 注意：使用for range遍历的时候，一定在之前需要先关闭管道 思考：通过for循环来遍历管道，需要关闭么？ // 创建管道 ch := make(chan int, 10) // 循环写入值 for i := 0; i 上述代码没有报错，说明通过for i的循环方式，可以不关闭管道 Goroutine 结合 channel 管道 需求1：定义两个方法，一个方法给管道里面写数据，一个给管道里面读取数据。要求同步进行。 开启一个fn1的的协程给向管道inChan中写入00条数据 开启一个fn2的协程读取inChan中写入的数据 注意：fn1和fn2同时操作一个管道 主线程必须等待操作完成后才可以退出 func write(ch chan int) { for i := 0; i 管道是安全的，是一边写入，一边读取，当读取比较快的时候，会等待写入 goroutine 结合 channel打印素数 // 想intChan中放入 1~ 120000个数 func putNum(intChan chan int) { for i := 2; i 单向管道 有时候我们会将管道作为参数在多个任务函数间传递，很多时候我们在不同的任务函数中，使用管道都会对其进行限制，比如限制管道在函数中只能发送或者只能接受 默认的管道是 可读可写 // 定义一种可读可写的管道 var ch = make(chan int, 2) ch Select多路复用 在某些场景下我们需要同时从多个通道接收数据。这个时候就可以用到golang中给我们提供的select多路复用。 通常情况通道在接收数据时，如果没有数据可以接收将会发生阻塞。 比如说下面代码来实现从多个通道接受数据的时候就会发生阻塞 这种方式虽然可以实现从多个管道接收值的需求，但是运行性能会差很多。为了应对这种场景，Go内置了select关键字，可以同时响应多个管道的操作。 select的使用类似于switch 语句，它有一系列case分支和一个默认的分支。每个case会对应一个管道的通信（接收或发送）过程。select会一直等待，直到某个case的通信操作完成时，就会执行case分支对应的语句。具体格式如下： intChan := make(chan int, 10) intChan 使用select来获取数据的时候，不需要关闭channel，不然会出现问题 Goroutine Recover 解决协程中出现的 Panic func sayHello() { for i := 0; i 当我们出现问题的时候，我们还是按照原来的方法，通过defer func创建匿名自启动 // 捕获异常 defer func() { if err := recover(); err != nil { fmt.Println(\"errTest发生错误\") } }() Go中的并发安全和锁 如下面一段代码，我们在并发环境下进行操作，就会出现并发访问的问题 var count = 0 var wg sync.WaitGroup func test() { count++ fmt.Println(\"the count is : \", count) time.Sleep(time.Millisecond) wg.Done() } func main() { for i := 0; i 互斥锁 互斥锁是传统并发编程中对共享资源进行访问控制的主要手段，它由标准库sync中的Mutex结构体类型表示。sync.Mutex类型只有两个公开的指针方法，Lock和Unlock。Lock锁定当前的共享资源，Unlock 进行解锁 // 定义一个锁 var mutex sync.Mutex // 加锁 mutex.Lock() // 解锁 mutex.Unlock() 完整代码 var count = 0 var wg sync.WaitGroup var mutex sync.Mutex func test() { // 加锁 mutex.Lock() count++ fmt.Println(\"the count is : \", count) time.Sleep(time.Millisecond) wg.Done() // 解锁 mutex.Unlock() } func main() { for i := 0; i 通过下面命令，build的时候，可以查看是否具有竞争关系 // 通过 -race 参数进行构建 go build -race main.go // 运行插件 main.ext 读写互斥锁 互斥锁的本质是当一个goroutine访问的时候，其他goroutine都不能访问。这样在资源同步，避免竞争的同时也降低了程序的并发性能。程序由原来的并行执行变成了串行执行。 其实，当我们对一个不会变化的数据只做“读”操作的话，是不存在资源竞争的问题的。因为数据是不变的，不管怎么读取，多少goroutine同时读取，都是可以的。 所以问题不是出在“读”上，主要是修改，也就是“写”。修改的数据要同步，这样其他goroutine才可以感知到。所以真正的互斥应该是读取和修改、修改和修改之间，读和读是没有互斥操作的必要的。 因此，衍生出另外一种锁，叫做读写锁。 读写锁可以让多个读操作并发，同时读取，但是对于写操作是完全互斥的。也就是说，当一个goroutine进行写操作的时候，其他goroutine既不能进行读操作，也不能进行写操作。 GO中的读写锁由结构体类型sync.RWMutex表示。此类型的方法集合中包含两对方法： 一组是对写操作的锁定和解锁，简称“写锁定”和“写解锁” func (*RWMutex)Lock() func (*RWMutex)UnLock() 另一组是对读操作的锁定和解锁，简称“读锁定”和“读解锁”func(*RWMutex)Rlock() func(*RWMutex)RUnlock()读写锁示例 示例代码 package main import ( \"fmt\" \"sync\" \"time\" ) var wg = sync.WaitGroup //var mutex = sync.Mutex // 互斥锁 var mutex = sync.RWMutex // 读写互斥锁 fund write(){ mutex.Lock() fmt.Println(\"+++执行写操作\") time.Sleep(time.Seconde * 2) mutex.UnLock() wg.Done() } func read(){ mutex.RLock() fmt.Println(\"执行读操作\") time.Sleep(time.Seconde * 2) wg.Done() mutex.RUnLock() } func main(){ // 开启10个协程执行写操作 for i:=0; i "},"GoLang/GoLang基础/17-反射.html":{"url":"GoLang/GoLang基础/17-反射.html","title":"反射","keywords":"","body":"datetime:2022/1/1 15:10 author:nzb GoLang中的反射 反射 有时我们需要写一个函数，这个函数有能力统一处理各种值类型，而这些类型可能无法共享同一个接口，也可能布局未知，也有可能这个类型在我们设计函数时还不存在，这个时候我们就可以用到反射。 空接口可以存储任意类型的变量，那我们如何知道这个空接口保存数据的类型是什么？ 值是什么呢？ 可以使用类型断言 可以使用反射实现，也就是在程序运行时动态的获取一个变量的类型信息和值信息。 把结构体序列化成json字符串，自定义结构体Tab标签的时候就用到了反射 后面所说的ORM框架，底层就是用到了反射技术 ORM：对象关系映射（Object Relational Mapping，简称 ORM）是通过使用描述对象和数据库之间的映射的元数据，将面向对象语言程序中的对象自动持久化到关系数据库中。 反射的基本介绍 反射是指在程序运行期间对程序本身进行访问和修改的能力。正常情况程序在编译时，变量被转换为内存地址，变量名不会被编译器写入到可执行部分。在运行程序时，程序无法获取自身的信息。支持反射的语言可以在程序编译期将变量的反射信息，如字段名称、类型信息、结构体信息等整合到可执行文件中，并给程序提供接口访问反射信息，这样就可以在程序运行期获取类型的反射信息，并且有能力修改它们。 Go可以实现的功能 反射可以在程序运行期间动态的获取变量的各种信息，比如变量的类型类别 如果是结构体，通过反射还可以获取结构体本身的信息，比如结构体的字段、结构体的方法。 通过反射，可以修改变量的值，可以调用关联的方法 Go语言中的变量是分为两部分的： 类型信息：预先定义好的元信息。 值信息：程序运行过程中可动态变化的。 在Go语言的反射机制中，任何接口值都由是一个具体类型和具体类型的值两部分组成的。 在Go语言中反射的相关功能由内置的reflect包提供，任意接口值在反射中都可以理解为由 reflect.Type 和 reflect.Value两部分组成，并且reflect包提供了reflect.TypeOf和reflect.ValueOf两个重要函数来获取任意对象的 Value 和 Type reflect.TypeOf()获取任意值的类型对象 在Go 语言中，使用 reflect.TypeOf() 函数可以接受任意interface}参数，可以获得任意值的类型对象（reflect.Type），程序通过类型对象可以访问任意值的类型信息。 通过反射获取空接口的类型 func reflectFun(x interface{}) { v := reflect.TypeOf(x) fmt.Println(v) } func main() { reflectFun(10) reflectFun(10.01) reflectFun(\"abc\") reflectFun(true) } type Name 和 type Kind 在反射中关于类型还划分为两种：类型（Type）和种类（Kind）。因为在Go语言中我们可以使用type关键字构造很多自定义类型，而种类（Kind）就是指底层的类型，但在反射中，当需要区分指针、结构体等大品种的类型时，就会用到种类（Kind）。举个例子，我们定义了两个指针类型和两个结构体类型，通过反射查看它们的类型和种类。 Go 语言的反射中像数组、切片、Map、指针等类型的变量，它们的.Name()都是返回空。 v := reflect.TypeOf(x) fmt.Println(\"类型 \", v) fmt.Println(\"类型名称 \", v.Name()) fmt.Println(\"类型种类 \", v.Kind()) reflect.ValueOf reflect.ValueOf() 返回的是 reflect.Value 类型，其中包含了原始值的值信息，reflect.Value与原始值之间可以互相转换 reflect.value类型提供的获取原始值的方法如下 方法 说明 interface{} 将值以interface{}类型返回，可以通过类型断言转换为指定类型 Int() int64 将值以int类型返回，所有有符号整型均可以此方式返回 Uint() uint64 将值以uint类型返回，所有无符号整型均可以以此方式返回 Float() float64 将值以双精度(float 64)类型返回，所有浮点数(float 32、float64)均可以以此方式返回 我们之前可以通过类型断言来实现空接口类型的数相加操作 func reflectValue(x interface{}) { b,_ := x.(int) var num = 10 + b fmt.Println(num) } 到现在的话，我们就可以使用reflect.TypeOf来实现了 func reflectValue2(x interface{}) { // 通过反射来获取变量的原始值 v := reflect.ValueOf(x) fmt.Println(v) // 获取到V的int类型 var n = v.Int() + 12 fmt.Println(n) } 同时我们还可以通过switch来完成 // 通过反射来获取变量的原始值 v := reflect.ValueOf(x) // 获取种类 kind := v.Kind() switch kind { case reflect.Int: fmt.Println(\"我是int类型\") case reflect.Float64: fmt.Println(\"我是float64类型\") default: fmt.Println(\"我是其它类型\") } 通过反射设置变量的值 package main import ( \"fmt\" \"reflect\" ) func reflectSetValue(x interface{}) { // 第一种：不行 // *x = 120 //invalid indirect of x (type interface {}) // 第二种：不行 // v, _ := x.(*int) // *v = 120 // panic: runtime error: invalid memory address or nil pointer dereference // 第三种：利用反射 v := reflect.ValueOf(x) // fmt.Println(v.Kind()) // ptr // fmt.Println(v.Elem().Kind()) // int64 if v.Elem().Kind() == reflect.Int64 { v.Elem().SetInt(123) } else if v.Elem().Kind() == reflect.String { v.Elem().SetString(\"你好 Golang\") } } func main() { var a int64 = 100 reflectSetValue(&a) fmt.Println(a) var b string = \"Hello GoLang\" reflectSetValue(&b) fmt.Println(b) } 结构体反射 与结构体相关的方法 任意值通过reflect.Typeof() 获得反射对象信息后，如果它的类型是结构体，可以通过反射值对象（reflect.Type）的NumField（）和Field（）方法获得结构体成员的详细信息。 reflect.Type中与获取结构体成员相关的的方法如下表所示。 方法 说明 Field(i int)StructField 根据索引，返回索引对应的结构体字段的信息 NumField() int 返回结构体成员字段数量 FieldByName(name string)(StructField, bool) 根据给定字符串返回字符串匹配的结构体字段信息 FieldByIndex(index []int)StructField 多层成员访问时，根据[] int 提供的每个结构体的字段索引，返回字段信息 FieldByNameFunc(match func(string)bool)(StructField, bool) 根据传入的匹配函数匹配需要的字段 NumMethod() int 返回该类型的方法集中方法的数目 Method(int) Method 返回该类型的方法集中的第i个方法 MethodByName(string)(Method, bool) 根据方法名返回该类型的方法集中的方法 StructField 类型 StructField 类型用来描述结构体中的字段的信息。StructField的定义如下： type StructField struct { // Name is the field name. Name string // 字段的名字 PkgPath string // 是非导出字段的包路径，对导出字段该字段为“” Type Type // field type， 字段的类型 Tag StructTag // field tag string，字段的标签 Offset uintptr // offset within struct, in bytes，结构体中的字节偏移量 Index []int // index sequence for Type.FieldByIndex，用于 Type.FieldByIndex时的索引切片 Anonymous bool // is an embedded field } 示例代码，如下所示 我们修改结构体中的字段和类型 package main import ( \"fmt\" \"reflect\" ) // 学生结构体 type Student4 struct { Name string `json: \"name\" form:\"username\"` Age int `json: \"age\"` Score int `json: \"score\"` } func (s Student4) GetInfo() string { var str = fmt.Sprintf(\"姓名：%v 年龄：%v 成绩：%v\", s.Name, s.Age, s.Score) return str } func (s *Student4) SetInfo(name string, age int, score int) { s.Name = name s.Age = age s.Score = score } func (s Student4) PrintStudent() { fmt.Println(\"打印学生\") } // 打印结构体中的字段 func PrintStructField(s interface{}) { t := reflect.TypeOf(s) // 判断传递过来的是否是结构体, 如果传入的是指针地址则需要 .Elem().Kind 查看原始类型 if t.Kind() != reflect.Struct && t.Elem().Kind() != reflect.Struct { fmt.Println(\"请传入结构体类型!\") return } // 通过类型变量里面的Field可以获取结构体的字段 field0 := t.Field(0) // 获取第0个字段 fmt.Printf(\"%#v \\n\", field0) fmt.Println(\"字段名称:\", field0.Name) fmt.Println(\"字段类型:\", field0.Type) fmt.Println(\"字段Tag1:\", field0.Tag.Get(\"json\")) fmt.Println(\"字段Tag2:\", field0.Tag.Get(\"form\")) // 通过类型变量里面的FieldByName可以获取结构体的字段中 field1, ok := t.FieldByName(\"Age\") if ok { fmt.Println(\"字段名称:\", field1.Name) fmt.Println(\"字段类型:\", field1.Type) fmt.Println(\"字段Tag:\", field1.Tag) } // 通过类型变量里面的NumField获取该结构体有几个字段 var fieldCount = t.NumField() fmt.Println(\"结构体有：\", fieldCount, \" 个属性\") // 获取结构体属性对应的值 v := reflect.ValueOf(s) nameValue := v.FieldByName(\"Name\") fmt.Println(\"nameValue:\", nameValue) // for 循环遍历 for i := 0; i 下列代码是获取结构体中的方法，然后调用 // 打印执行方法 func PrintStructFn(s interface{}) { t := reflect.TypeOf(s) // 判断传递过来的是否是结构体 if t.Kind() != reflect.Struct && t.Elem().Kind() != reflect.Struct { fmt.Println(\"请传入结构体类型!\") return } // 通过类型变量里面的Method，可以获取结构体的方法 method0 := t.Method(0) // 获取第一个方法， 这个是和ACSII相关 fmt.Println(method0.Name) // 通过类型变量获取这个结构体有多少方法 methodCount := t.NumMethod() fmt.Println(\"拥有的方法\", methodCount) // 通过值变量 执行方法（注意需要使用值变量，并且要注意参数） v := reflect.ValueOf(s) // 通过值变量来获取参数 v.MethodByName(\"PrintStudent\").Call(nil) // 手动传参 var params []reflect.Value params = append(params, reflect.ValueOf(\"张三\")) params = append(params, reflect.ValueOf(23)) params = append(params, reflect.ValueOf(99)) // 执行setInfo方法 v.MethodByName(\"SetInfo\").Call(params) // 通过值变量来获取参数 v.MethodByName(\"PrintStudent\").Call(nil) } 不要乱用反射 反射是一个强大并附有表现力的工具，能让我们写出更灵活的代码，但是反射不应该被滥用，原因： 基于反射的代码是及其脆弱的，反射中的类型错误会在真正运行的时候才会引发 panic，那可能是在代码写完很长时间之后 大量使用反射的代码通常难以理解（对于不熟悉反射的开发者来说，代码可读性差） "},"GoLang/GoLang基础/18-文件和目录操作.html":{"url":"GoLang/GoLang基础/18-文件和目录操作.html","title":"文件和目录操作","keywords":"","body":"datetime:2022/1/2 13:35 author:nzb Go中的文件和目录操作 文件的读取 通过os.Open方法读取文件 func main() { // 读取文件 方法1 file, err := os.Open(\"./main/test.txt\") // 关闭文件流 defer file.Close(); if err != nil { fmt.Println(\"打开文件出错\") return } // 读取文件里面的内容 var tempSlice = make([]byte, 1024) var strSlice []byte for { n, err := file.Read(tempSlice) if err == io.EOF { // err==io.EOF表示读取完毕 fmt.Printf(\"读取完毕\") break } fmt.Printf(\"读取到了%v 个字节 \\n\", n) strSlice := append(strSlice, tempSlice[:n]...) // 切片，防止最后读到的数据没有 1024 长度，导致拼接乱码 fmt.Println(string(strSlice)) } } 通过bufio的方式读取 func main() { // 读取文件 方法2 file, err := os.Open(\"./main/test.txt\") // 关闭文件流 defer file.Close(); if err != nil { fmt.Println(\"打开文件出错\") } // 通过创建bufio来读取 reader := bufio.NewReader(file) var fileStr string var count int = 0 for { // 相当于读取一行 str, err := reader.ReadString('\\n') if err == io.EOF { // 读取完成的时候，也会有内容 fileStr += str fmt.Println(\"读取结束\", count) break } if err != nil { fmt.Println(err) break } count ++ fileStr += str } fmt.Println(fileStr) } 通过ioutil读取 文件大小比较小的时候，可以通过ioutil来读取文件 // 通过 ioutil 读取 byteStr, _ := ioutil.ReadFile(\"./main/test.txt\") fmt.Println(string(byteStr)) 文件的写入 文件的写入，我们首先需要通过 os.OpenFile 打开文件 // 打开文件 file, _ := os.OpenFile(\"./main/test.txt\", os.O_CREATE | os.O_RDWR, 777) 这里有三个参数 name：要打开的文件名 flag：打开文件的模式 os.O_WRONLY：只读 os.O_CREATE：创建 os.O_RDONLY：只读 os.O_RDWR：读写 os.O_TRUNC：清空 os.O_APPEND：追加 perm：文件权限，一个八进制数，r（读）04，w（写）02，x（执行）01 通过OpenFile打开文件写入 package main import ( \"fmt\" \"os\" ) func main() { // 打开文件 file, err := os.OpenFile(\"./test.txt\", os.O_CREATE|os.O_RDWR|os.O_APPEND, 0666) if err != nil { fmt.Println(err) return } defer file.Close() str := \"啦啦啦 \\r\\n\" for i := 0; i 通过bufio写入 package main import ( \"bufio\" \"os\" ) func main() { // 打开文件 file, _ := os.OpenFile(\"./test.txt\", os.O_CREATE|os.O_RDWR|os.O_APPEND, 777) defer file.Close() str := \"啦啦啦 \\r\\n\" file.WriteString(str) // 通过bufio写入 writer := bufio.NewWriter(file) // 先将数据写入缓存 writer.WriteString(\"你好，我是通过writer写入的 \\r\\n\") // 将缓存中的内容写入文件 writer.Flush() } 通过ioutil写入 package main import \"io/ioutil\" func main() { // 第三种方式，通过ioutil str2 := \"hello\" ioutil.WriteFile(\"./test.txt\", []byte(str2), 777) } 文件复制 通过ioutil读取和复制文件 // 读取文件 byteStr, err := ioutil.ReadFile(\"./main/test.txt\") if err != nil { fmt.Println(\"读取文件出错\") return } // 写入指定的文件 ioutil.WriteFile(\"./main/test2.txt\", byteStr, 777) 大文件通过文件流复制文件 package main import ( \"io\" \"os\" ) func CopyFile(srcFileName string, dstFileName string) (err error) { sFile, err1 := os.Open(srcFileName) dFile, err2 := os.OpenFile(dstFileName, os.O_CREATE|os.O_WRONLY, 0666) defer sFile.Close() defer dFile.Close() if err1 != nil { return err1 } if err2 != nil { return err2 } var tmpSlice = make([]byte, 128) for { n1, e1 := sFile.Read(tmpSlice) if err == io.EOF { break } if e1 != nil { return e1 } if _, err := dFile.Write(tmpSlice[:n1]); err != nil { return err } } return nil } func main() { // 读取文件 srcFile := \"./test.txt\" dstFile := \"C:/Users/lenovo/Desktop/test.txt\" CopyFile(srcFile, dstFile) } 创建目录 package main import ( \"fmt\" \"os\" ) func main() { err1 := os.Mkdir(\"./abc\", 777) if err1 != nil { fmt.Println(err1) } err2 := os.MkdirAll(\"./efg/abc/hij\", 777) //创建多级目录 if err2 != nil { fmt.Println(err2) } } 删除操作 package main import ( \"fmt\" \"os\" ) func main() { // 删除文件 os.Remove(\"./test.txt\") err1 := os.Remove(\"./abc\") // 删除目录 if err1 != nil { fmt.Println(err1) } err2 := os.RemoveAll(\"./efg\") //删除多个文件和目录 if err2 != nil { fmt.Println(err2) } } 重命名 package main import ( \"os\" ) func main() { os.Rename(\"./test.txt\", \"11.txt\") } "},"GoLang/7daysGoLang/":{"url":"GoLang/7daysGoLang/","title":"目录","keywords":"","body":"datetime:2022-01-02 16:40:30 author:nzb 7 days golang programs from scratch 基于该项目【7天用Go动手写/从零实现系列】所写 7天用Go从零实现系列 7天能写什么呢？类似 gin 的 web 框架？类似 groupcache 的分布式缓存？或者一个简单的 Python 解释器？希望这个仓库能给你答案。 推荐先阅读 Go 语言基础，一篇文章了解Go的基本语法、并发编程，依赖管理等内容。 推荐 Go 语言笔试面试题，加深对 Go 语言的理解。 推荐 Go 语言高性能编程(项目地址)，写出高性能的 Go 代码。 7天用Go从零实现Web框架 - Gee Gee 是一个模仿 gin 实现的 Web 框架，Go Gin简明教程可以快速入门。 第一天：前置知识(http.Handler接口) | Code - Github 第二天：上下文设计(Context) | Code - Github 第三天：Trie树路由(Router) | Code - Github 第四天：分组控制(Group) | Code - Github 第五天：中间件(Middleware) | Code - Github 第六天：HTML模板(Template) | Code - Github 第七天：错误恢复(Panic Recover) | Code - Github 7天用Go从零实现分布式缓存 GeeCache GeeCache 是一个模仿 groupcache 实现的分布式缓存系统 第一天：LRU 缓存淘汰策略 | Code 第二天：单机并发缓存 | Code 第三天：HTTP 服务端 | Code 第四天：一致性哈希(Hash) | Code 第五天：分布式节点 | Code 第六天：防止缓存击穿 | Code 第七天：使用 Protobuf 通信 | Code 7天用Go从零实现ORM框架 GeeORM GeeORM 是一个模仿 gorm 和 xorm 的 ORM 框架 gorm 准备推出完全重写的 v2 版本(目前还在开发中)，相对 gorm-v1 来说，xorm 的设计更容易理解，所以 geeorm 接口设计上主要参考了 xorm，一些细节实现上参考了 gorm。 第一天：database/sql 基础 | Code 第二天：对象表结构映射 | Code 第三天：记录新增和查询 | Code 第四天：链式操作与更新删除 | Code 第五天：实现钩子(Hooks) | Code 第六天：支持事务(Transaction) | Code 第七天：数据库迁移(Migrate) | Code 7天用Go从零实现RPC框架 GeeRPC GeeRPC 是一个基于 net/rpc 开发的 RPC 框架 GeeRPC 是基于 Go 语言标准库 net/rpc 实现的，添加了协议交换、服务注册与发现、负载均衡等功能，代码约 1k。 第一天 - 服务端与消息编码 | Code 第二天 - 支持并发与异步的客户端 | Code 第三天 - 服务注册(service register) | Code 第四天 - 超时处理(timeout) | Code 第五天 - 支持HTTP协议 | Code 第六天 - 负载均衡(load balance) | Code 第七天 - 服务发现与注册中心(registry) | Code WebAssembly 使用示例 具体的实践过程记录在 Go WebAssembly 简明教程。 示例一：Hello World | Code 示例二：注册函数 | Code 示例三：操作 DOM | Code 示例四：回调函数 | Code README 英文版本 What can be accomplished in 7 days? A gin-like web framework? A distributed cache like groupcache? Or a simple Python interpreter? Hope this repo can give you the answer. ## Web Framework - Gee [Gee](https://geektutu.com/post/gee.html) is a [gin](https://github.com/gin-gonic/gin)-like framework - Day 1 - http.Handler Interface Basic [Code](gee-web/day1-http-base) - Day 2 - Design a Flexiable Context [Code](gee-web/day2-context) - Day 3 - Router with Trie-Tree Algorithm [Code](gee-web/day3-router) - Day 4 - Group Control [Code](gee-web/day4-group) - Day 5 - Middleware Mechanism [Code](gee-web/day5-middleware) - Day 6 - Embeded Template Support [Code](gee-web/day6-template) - Day 7 - Panic Recover & Make it Robust [Code](gee-web/day7-panic-recover) ## Distributed Cache - GeeCache [GeeCache](https://geektutu.com/post/geecache.html) is a [groupcache](https://github.com/golang/groupcache)-like distributed cache - Day 1 - LRU (Least Recently Used) Caching Strategy [Code](gee-cache/day1-lru) - Day 2 - Single Machine Concurrent Cache [Code](gee-cache/day2-single-node) - Day 3 - Launch a HTTP Server [Code](gee-cache/day3-http-server) - Day 4 - Consistent Hash Algorithm [Code](gee-cache/day4-consistent-hash) - Day 5 - Communication between Distributed Nodes [Code](gee-cache/day5-multi-nodes) - Day 6 - Cache Breakdown & Single Flight | [Code](gee-cache/day6-single-flight) - Day 7 - Use Protobuf as RPC Data Exchange Type | [Code](gee-cache/day7-proto-buf) ## Object Relational Mapping - GeeORM [GeeORM](https://geektutu.com/post/geeorm.html) is a [gorm](https://github.com/jinzhu/gorm)-like and [xorm](https://github.com/go-xorm/xorm)-like object relational mapping library Xorm's desgin is easier to understand than gorm-v1, so the main designs references xorm and some detailed implementions references gorm-v1. - Day 1 - database/sql Basic | [Code](gee-orm/day1-database-sql) - Day 2 - Object Schame Mapping | [Code](gee-orm/day2-reflect-schema) - Day 3 - Insert and Query | [Code](gee-orm/day3-save-query) - Day 4 - Chain, Delete and Update | [Code](gee-orm/day4-chain-operation) - Day 5 - Support Hooks | [Code](gee-orm/day5-hooks) - Day 6 - Support Transaction | [Code](gee-orm/day6-transaction) - Day 7 - Migrate Database | [Code](gee-orm/day7-migrate) ## RPC Framework - GeeRPC [GeeRPC](https://geektutu.com/post/geerpc.html) is a [net/rpc](https://github.com/golang/go/tree/master/src/net/rpc)-like RPC framework Based on golang standard library `net/rpc`, GeeRPC implements more features. eg, protocol exchange, service registration and discovery, load balance, etc. - Day 1 - Server Message Codec | [Code](gee-rpc/day1-codec) - Day 2 - Concurrent Client | [Code](gee-rpc/day2-client) - Day 3 - Service Register | [Code](gee-rpc/day3-service ) - Day 4 - Timeout Processing | [Code](gee-rpc/day4-timeout ) - Day 5 - Support HTTP Protocol | [Code](gee-rpc/day5-http-debug) - Day 6 - Load Balance | [Code](gee-rpc/day6-load-balance) - Day 7 - Discovery and Registry | [Code](gee-rpc/day7-registry) ## Golang WebAssembly Demo - Demo 1 - Hello World [Code](demo-wasm/hello-world) - Demo 2 - Register Functions [Code](demo-wasm/register-functions) - Demo 3 - Manipulate DOM [Code](demo-wasm/manipulate-dom) - Demo 4 - Callback [Code](demo-wasm/callback) "},"GoLang/7daysGoLang/gee-web/doc/gee-day1.html":{"url":"GoLang/7daysGoLang/gee-web/doc/gee-day1.html","title":"前置知识(http.Handler接口)","keywords":"","body":"datetime:2022/02/05 16:52 author:nzb Go语言动手写Web框架 - Gee第一天 http.Handler 本文是7天用Go从零实现Web框架Gee教程系列的第一篇。 简单介绍net/http库以及http.Handler接口。 搭建Gee框架的雏形，代码约50行。 标准库启动Web服务 Go语言内置了 net/http库，封装了HTTP网络编程的基础的接口，我们实现的Gee Web 框架便是基于net/http的。我们接下来通过一个例子，简单介绍下这个库的使用。 day1-http-base/base1/main.go package main import ( \"fmt\" \"log\" \"net/http\" ) func main() { http.HandleFunc(\"/\", indexHandler) http.HandleFunc(\"/hello\", helloHandler) log.Fatal(http.ListenAndServe(\":9999\", nil)) } // handler echoes r.URL.Path func indexHandler(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \"URL.Path = %q\\n\", req.URL.Path) } // handler echoes r.URL.Header func helloHandler(w http.ResponseWriter, req *http.Request) { for k, v := range req.Header { fmt.Fprintf(w, \"Header[%q] = %q\\n\", k, v) } } 我们设置了2个路由，/和/hello，分别绑定 indexHandler 和 helloHandler ， 根据不同的HTTP请求会调用不同的处理函数。访问/，响应是URL.Path = /，而/hello的响应则是请求头(header)中的键值对信息。 用 curl 这个工具测试一下，将会得到如下的结果。 $ curl http://localhost:9999/ URL.Path = \"/\" $ curl http://localhost:9999/hello Header[\"Accept\"] = [\"*/*\"] Header[\"User-Agent\"] = [\"curl/7.54.0\"] main 函数的最后一行，是用来启动 Web 服务的，第一个参数是地址，:9999表示在 9999 端口监听。而第二个参数则代表处理所有的HTTP请求的实例，nil 代表使用标准库中的实例处理。第二个参数，则是我们基于net/http标准库实现Web框架的入口。 实现http.Handler接口 package http type Handler interface { ServeHTTP(w ResponseWriter, r *Request) } func ListenAndServe(address string, h Handler) error 第二个参数的类型是什么呢？通过查看net/http的源码可以发现，Handler是一个接口，需要实现方法 ServeHTTP ，也就是说，只要传入任何实现了 ServerHTTP 接口的实例，所有的HTTP请求，就都交给了该实例处理了。马上来试一试吧。 day1-http-base/base2/main.go package main import ( \"fmt\" \"log\" \"net/http\" ) // Engine is the uni handler for all requests type Engine struct{} func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { switch req.URL.Path { case \"/\": fmt.Fprintf(w, \"URL.Path = %q\\n\", req.URL.Path) case \"/hello\": for k, v := range req.Header { fmt.Fprintf(w, \"Header[%q] = %q\\n\", k, v) } default: fmt.Fprintf(w, \"404 NOT FOUND: %s\\n\", req.URL) } } func main() { engine := new(Engine) log.Fatal(http.ListenAndServe(\":9999\", engine)) } 我们定义了一个空的结构体Engine，实现了方法ServeHTTP。这个方法有2个参数，第二个参数是 Request ，该对象包含了该HTTP请求的所有的信息，比如请求地址、Header和Body等信息；第一个参数是 ResponseWriter ，利用 ResponseWriter 可以构造针对该请求的响应。 在 main 函数中，我们给 ListenAndServe 方法的第二个参数传入了刚才创建的engine实例。至此，我们走出了实现Web框架的第一步，即，将所有的HTTP请求转向了我们自己的处理逻辑。还记得吗，在实现Engine之前，我们调用 http.HandleFunc 实现了路由和Handler的映射，也就是只能针对具体的路由写处理逻辑。比如/hello。但是在实现Engine之后，我们拦截了所有的HTTP请求，拥有了统一的控制入口。在这里我们可以自由定义路由映射的规则，也可以统一添加一些处理逻辑，例如日志、异常处理等。 代码的运行结果与之前的是一致的。 Gee框架的雏形 我们接下来重新组织上面的代码，搭建出整个框架的雏形。 最终的代码目录结构是这样的。 gee/ |--gee.go |--go.mod main.go go.mod go.mod day1-http-base/base3/go.mod module example go 1.13 require gee v0.0.0 replace gee => ./gee 在 go.mod 中使用 replace 将 gee 指向 ./gee 从 go 1.11 版本开始，引用相对路径的 package 需要使用上述方式。 main.go day1-http-base/base3/main.go package main import ( \"fmt\" \"net/http\" \"gee\" ) func main() { r := gee.New() r.GET(\"/\", func(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \"URL.Path = %q\\n\", req.URL.Path) }) r.GET(\"/hello\", func(w http.ResponseWriter, req *http.Request) { for k, v := range req.Header { fmt.Fprintf(w, \"Header[%q] = %q\\n\", k, v) } }) r.Run(\":9999\") } 看到这里，如果你使用过gin框架的话，肯定会觉得无比的亲切。gee框架的设计以及API均参考了gin。使用New()创建 gee 的实例，使用 GET()方法添加路由，最后使用Run()启动Web服务。这里的路由，只是静态路由，不支持/hello/:name这样的动态路由，动态路由我们将在下一次实现。 gee.go day1-http-base/base3/gee/gee.go package gee import ( \"fmt\" \"net/http\" ) // HandlerFunc defines the request handler used by gee type HandlerFunc func(http.ResponseWriter, *http.Request) // Engine implement the interface of ServeHTTP type Engine struct { router map[string]HandlerFunc } // New is the constructor of gee.Engine func New() *Engine { return &Engine{router: make(map[string]HandlerFunc)} } func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) { key := method + \"-\" + pattern engine.router[key] = handler } // GET defines the method to add GET request func (engine *Engine) GET(pattern string, handler HandlerFunc) { engine.addRoute(\"GET\", pattern, handler) } // POST defines the method to add POST request func (engine *Engine) POST(pattern string, handler HandlerFunc) { engine.addRoute(\"POST\", pattern, handler) } // Run defines the method to start a http server func (engine *Engine) Run(addr string) (err error) { return http.ListenAndServe(addr, engine) } func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { key := req.Method + \"-\" + req.URL.Path if handler, ok := engine.router[key]; ok { handler(w, req) } else { fmt.Fprintf(w, \"404 NOT FOUND: %s\\n\", req.URL) } } 那么gee.go就是重头戏了。我们重点介绍一下这部分的实现。 首先定义了类型HandlerFunc，这是提供给框架用户的，用来定义路由映射的处理方法。我们在Engine中，添加了一张路由映射表router，key 由请求方法和静态路由地址构成，例如GET-/、GET-/hello、POST-/hello，这样针对相同的路由，如果请求方法不同,可以映射不同的处理方法(Handler)，value 是用户映射的处理方法。 当用户调用(*Engine).GET()方法时，会将路由和处理方法注册到映射表 router 中，(*Engine).Run()方法，是 ListenAndServe 的包装。 Engine实现的 ServeHTTP 方法的作用就是，解析请求的路径，查找路由映射表，如果查到，就执行注册的处理方法。如果查不到，就返回 404 NOT FOUND 。 执行go run main.go，再用 curl 工具访问，结果与最开始的一致。 $ curl http://localhost:9999/ URL.Path = \"/\" $ curl http://localhost:9999/hello Header[\"Accept\"] = [\"*/*\"] Header[\"User-Agent\"] = [\"curl/7.54.0\"] curl http://localhost:9999/world 404 NOT FOUND: /world 至此，整个Gee框架的原型已经出来了。实现了路由映射表，提供了用户注册静态路由的方法，包装了启动服务的函数。当然，到目前为止，我们还没有实现比net/http标准库更强大的能力，不用担心，很快就可以将动态路由、中间件等功能添加上去了。 "},"GoLang/7daysGoLang/gee-web/doc/gee-day2.html":{"url":"GoLang/7daysGoLang/gee-web/doc/gee-day2.html","title":"上下文设计(Context)","keywords":"","body":"datetime:2022/02/05 16:58 author:nzb Go语言动手写Web框架 - Gee第二天 上下文Context 本文是 7天用Go从零实现Web框架Gee教程系列的第二篇。 将路由(router)独立出来，方便之后增强。 设计上下文(Context)，封装 Request 和 Response ，提供对 JSON、HTML 等返回类型的支持。 动手写 Gee 框架的第二天，框架代码140行，新增代码约90行 使用效果 为了展示第二天的成果，我们看一看在使用时的效果。 day2-context/main.go func main() { r := gee.New() r.GET(\"/\", func(c *gee.Context) { c.HTML(http.StatusOK, \"Hello Gee\") }) r.GET(\"/hello\", func(c *gee.Context) { // expect /hello?name=geektutu c.String(http.StatusOK, \"hello %s, you're at %s\\n\", c.Query(\"name\"), c.Path) }) r.POST(\"/login\", func(c *gee.Context) { c.JSON(http.StatusOK, gee.H{ \"username\": c.PostForm(\"username\"), \"password\": c.PostForm(\"password\"), }) }) r.Run(\":9999\") } Handler的参数变成成了gee.Context，提供了查询Query/PostForm参数的功能。 gee.Context封装了HTML/String/JSON函数，能够快速构造HTTP响应。 设计Context 必要性 对Web服务来说，无非是根据请求*http.Request，构造响应http.ResponseWriter。但是这两个对象提供的接口粒度太细，比如我们要构造一个完整的响应，需要考虑消息头(Header)和消息体(Body)，而 Header 包含了状态码(StatusCode)，消息类型(ContentType)等几乎每次请求都需要设置的信息。因此，如果不进行有效的封装，那么框架的用户将需要写大量重复，繁杂的代码，而且容易出错。针对常用场景，能够高效地构造出 HTTP 响应是一个好的框架必须考虑的点。 用返回 JSON 数据作比较，感受下封装前后的差距。 封装前 obj = map[string]interface{}{ \"name\": \"geektutu\", \"password\": \"1234\", } w.Header().Set(\"Content-Type\", \"application/json\") w.WriteHeader(http.StatusOK) encoder := json.NewEncoder(w) if err := encoder.Encode(obj); err != nil { http.Error(w, err.Error(), 500) } VS 封装后： c.JSON(http.StatusOK, gee.H{ \"username\": c.PostForm(\"username\"), \"password\": c.PostForm(\"password\"), }) 针对使用场景，封装*http.Request和http.ResponseWriter的方法，简化相关接口的调用，只是设计 Context 的原因之一。对于框架来说，还需要支撑额外的功能。例如，将来解析动态路由/hello/:name，参数:name的值放在哪呢？再比如，框架需要支持中间件，那中间件产生的信息放在哪呢？Context 随着每一个请求的出现而产生，请求的结束而销毁，和当前请求强相关的信息都应由 Context 承载。因此，设计 Context 结构，扩展性和复杂性留在了内部，而对外简化了接口。路由的处理函数，以及将要实现的中间件，参数都统一使用 Context 实例， Context 就像一次会话的百宝箱，可以找到任何东西。 具体实现 day2-context/gee/context.go type H map[string]interface{} type Context struct { // origin objects Writer http.ResponseWriter Req *http.Request // request info Path string Method string // response info StatusCode int } func newContext(w http.ResponseWriter, req *http.Request) *Context { return &Context{ Writer: w, Req: req, Path: req.URL.Path, Method: req.Method, } } func (c *Context) PostForm(key string) string { return c.Req.FormValue(key) } func (c *Context) Query(key string) string { return c.Req.URL.Query().Get(key) } func (c *Context) Status(code int) { c.StatusCode = code c.Writer.WriteHeader(code) } func (c *Context) SetHeader(key string, value string) { c.Writer.Header().Set(key, value) } func (c *Context) String(code int, format string, values ...interface{}) { c.SetHeader(\"Content-Type\", \"text/plain\") c.Status(code) c.Writer.Write([]byte(fmt.Sprintf(format, values...))) } func (c *Context) JSON(code int, obj interface{}) { c.SetHeader(\"Content-Type\", \"application/json\") c.Status(code) encoder := json.NewEncoder(c.Writer) if err := encoder.Encode(obj); err != nil { http.Error(c.Writer, err.Error(), 500) } } func (c *Context) Data(code int, data []byte) { c.Status(code) c.Writer.Write(data) } func (c *Context) HTML(code int, html string) { c.SetHeader(\"Content-Type\", \"text/html\") c.Status(code) c.Writer.Write([]byte(html)) } 代码最开头，给map[string]interface{}起了一个别名gee.H，构建JSON数据时，显得更简洁。 Context目前只包含了http.ResponseWriter和*http.Request，另外提供了对 Method 和 Path 这两个常用属性的直接访问。 提供了访问Query和PostForm参数的方法。 提供了快速构造String/Data/JSON/HTML响应的方法。 路由(Router) 我们将和路由相关的方法和结构提取了出来，放到了一个新的文件中router.go，方便我们下一次对 router 的功能进行增强，例如提供动态路由的支持。 router 的 handle 方法作了一个细微的调整，即 handler 的参数，变成了 Context。 day2-context/gee/router.go type router struct { handlers map[string]HandlerFunc } func newRouter() *router { return &router{handlers: make(map[string]HandlerFunc)} } func (r *router) addRoute(method string, pattern string, handler HandlerFunc) { log.Printf(\"Route %4s - %s\", method, pattern) key := method + \"-\" + pattern r.handlers[key] = handler } func (r *router) handle(c *Context) { key := c.Method + \"-\" + c.Path if handler, ok := r.handlers[key]; ok { handler(c) } else { c.String(http.StatusNotFound, \"404 NOT FOUND: %s\\n\", c.Path) } } 框架入口 day2-context/gee/gee.go // HandlerFunc defines the request handler used by gee type HandlerFunc func(*Context) // Engine implement the interface of ServeHTTP type Engine struct { router *router } // New is the constructor of gee.Engine func New() *Engine { return &Engine{router: newRouter()} } func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) { engine.router.addRoute(method, pattern, handler) } // GET defines the method to add GET request func (engine *Engine) GET(pattern string, handler HandlerFunc) { engine.addRoute(\"GET\", pattern, handler) } // POST defines the method to add POST request func (engine *Engine) POST(pattern string, handler HandlerFunc) { engine.addRoute(\"POST\", pattern, handler) } // Run defines the method to start a http server func (engine *Engine) Run(addr string) (err error) { return http.ListenAndServe(addr, engine) } func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { c := newContext(w, req) engine.router.handle(c) } 将router相关的代码独立后，gee.go简单了不少。最重要的还是通过实现了 ServeHTTP 接口，接管了所有的 HTTP 请求。相比第一天的代码，这个方法也有细微的调整，在调用 router.handle 之前，构造了一个 Context 对象。这个对象目前还非常简单，仅仅是包装了原来的两个参数，之后我们会慢慢地给Context插上翅膀。 如何使用，main.go一开始就已经亮相了。运行go run main.go，借助 curl ，一起看一看今天的成果吧。 $ curl -i http://localhost:9999/ HTTP/1.1 200 OK Date: Mon, 12 Aug 2019 16:52:52 GMT Content-Length: 18 Content-Type: text/html; charset=utf-8 Hello Gee $ curl \"http://localhost:9999/hello?name=geektutu\" hello geektutu, you're at /hello $ curl \"http://localhost:9999/login\" -X POST -d 'username=geektutu&password=1234' {\"password\":\"1234\",\"username\":\"geektutu\"} $ curl \"http://localhost:9999/xxx\" 404 NOT FOUND: /xxx "},"GoLang/7daysGoLang/gee-web/doc/gee-day3.html":{"url":"GoLang/7daysGoLang/gee-web/doc/gee-day3.html","title":"Trie树路由(Router)","keywords":"","body":"datetime:2022/02/05 16:58 author:nzb Go语言动手写Web框架 - Gee第三天 前缀树路由Router 本文是 7天用Go从零实现Web框架Gee教程系列的第三篇。 使用 Trie 树实现动态路由(dynamic route)解析。 支持两种模式:name和*filepath，代码约150行。 Trie 树简介 之前，我们用了一个非常简单的map结构存储了路由表，使用map存储键值对，索引非常高效，但是有一个弊端，键值对的存储的方式，只能用来索引静态路由。那如果我们想支持类似于/hello/:name这样的动态路由怎么办呢？所谓动态路由，即一条路由规则可以匹配某一类型而非某一条固定的路由。例如/hello/:name，可以匹配/hello/geektutu、hello/jack等。 动态路由有很多种实现方式，支持的规则、性能等有很大的差异。例如开源的路由实现gorouter支持在路由规则中嵌入正则表达式，例如/p/[0-9A-Za-z]+，即路径中的参数仅匹配数字和字母；另一个开源实现httprouter就不支持正则表达式。著名的Web开源框架gin 在早期的版本，并没有实现自己的路由，而是直接使用了httprouter，后来不知道什么原因，放弃了httprouter，自己实现了一个版本。 实现动态路由最常用的数据结构，被称为前缀树(Trie树)。看到名字你大概也能知道前缀树长啥样了：每一个节点的所有的子节点都拥有相同的前缀。这种结构非常适用于路由匹配，比如我们定义了如下路由规则： /:lang/doc /:lang/tutorial /:lang/intro /about /p/blog /p/related 我们用前缀树来表示，是这样的。 HTTP请求的路径恰好是由/分隔的多段构成的，因此，每一段可以作为前缀树的一个节点。我们通过树结构查询，如果中间某一层的节点都不满足条件，那么就说明没有匹配到的路由，查询结束。 接下来我们实现的动态路由具备以下两个功能。 参数匹配:。例如 /p/:lang/doc，可以匹配 /p/c/doc 和 /p/go/doc。 通配*。例如 /static/*filepath，可以匹配/static/fav.ico，也可以匹配/static/js/jQuery.js，这种模式常用于静态服务器，能够递归地匹配子路径。 Trie 树实现 首先我们需要设计树节点上应该存储那些信息。 day3-router/gee/trie.go type node struct { pattern string // 待匹配路由，例如 /p/:lang part string // 路由中的一部分，例如 :lang children []*node // 子节点，例如 [doc, tutorial, intro] isWild bool // 是否精确匹配，part 含有 : 或 * 时为true } 与普通的树不同，为了实现动态路由匹配，加上了isWild这个参数。即当我们匹配 /p/go/doc/这个路由时，第一层节点，p精准匹配到了p，第二层节点，go模糊匹配到:lang，那么将会把lang这个参数赋值为go，继续下一层匹配。我们将匹配的逻辑，包装为一个辅助函数。 // 第一个匹配成功的节点，用于插入 func (n *node) matchChild(part string) *node { for _, child := range n.children { if child.part == part || child.isWild { return child } } return nil } // 所有匹配成功的节点，用于查找 func (n *node) matchChildren(part string) []*node { nodes := make([]*node, 0) for _, child := range n.children { if child.part == part || child.isWild { nodes = append(nodes, child) } } return nodes } 对于路由来说，最重要的当然是注册与匹配了。开发服务时，注册路由规则，映射handler；访问时，匹配路由规则，查找到对应的handler。因此，Trie 树需要支持节点的插入与查询。插入功能很简单，递归查找每一层的节点，如果没有匹配到当前part的节点，则新建一个，有一点需要注意，/p/:lang/doc只有在第三层节点，即doc节点，pattern才会设置为/p/:lang/doc。p和:lang节点的pattern属性皆为空。因此，当匹配结束时，我们可以使用n.pattern == \"\"来判断路由规则是否匹配成功。例如，/p/python虽能成功匹配到:lang，但:lang的pattern值为空，因此匹配失败。查询功能，同样也是递归查询每一层的节点，退出规则是，匹配到了*，匹配失败，或者匹配到了第len(parts)层节点。 func (n *node) insert(pattern string, parts []string, height int) { if len(parts) == height { n.pattern = pattern return } part := parts[height] child := n.matchChild(part) if child == nil { child = &node{part: part, isWild: part[0] == ':' || part[0] == '*'} n.children = append(n.children, child) } child.insert(pattern, parts, height+1) } func (n *node) search(parts []string, height int) *node { if len(parts) == height || strings.HasPrefix(n.part, \"*\") { if n.pattern == \"\" { return nil } return n } part := parts[height] children := n.matchChildren(part) for _, child := range children { result := child.search(parts, height+1) if result != nil { return result } } return nil } Router Trie 树的插入与查找都成功实现了，接下来我们将 Trie 树应用到路由中去吧。我们使用 roots 来存储每种请求方式的Trie 树根节点。使用 handlers 存储每种请求方式的 HandlerFunc 。getRoute 函数中，还解析了:和*两种匹配符的参数，返回一个 map 。例如/p/go/doc匹配到/p/:lang/doc，解析结果为：{lang: \"go\"}，/static/css/geektutu.css匹配到/static/*filepath，解析结果为{filepath: \"css/geektutu.css\"}。 day3-router/gee/router.go type router struct { roots map[string]*node handlers map[string]HandlerFunc } // roots key eg, roots['GET'] roots['POST'] // handlers key eg, handlers['GET-/p/:lang/doc'], handlers['POST-/p/book'] func newRouter() *router { return &router{ roots: make(map[string]*node), handlers: make(map[string]HandlerFunc), } } // Only one * is allowed func parsePattern(pattern string) []string { vs := strings.Split(pattern, \"/\") parts := make([]string, 0) for _, item := range vs { if item != \"\" { parts = append(parts, item) if item[0] == '*' { break } } } return parts } func (r *router) addRoute(method string, pattern string, handler HandlerFunc) { parts := parsePattern(pattern) key := method + \"-\" + pattern _, ok := r.roots[method] if !ok { r.roots[method] = &node{} } r.roots[method].insert(pattern, parts, 0) r.handlers[key] = handler } func (r *router) getRoute(method string, path string) (*node, map[string]string) { searchParts := parsePattern(path) params := make(map[string]string) root, ok := r.roots[method] if !ok { return nil, nil } n := root.search(searchParts, 0) if n != nil { parts := parsePattern(n.pattern) for index, part := range parts { if part[0] == ':' { params[part[1:]] = searchParts[index] } if part[0] == '*' && len(part) > 1 { params[part[1:]] = strings.Join(searchParts[index:], \"/\") break } } return n, params } return nil, nil } Context与handle的变化 在 HandlerFunc 中，希望能够访问到解析的参数，因此，需要对 Context 对象增加一个属性和方法，来提供对路由参数的访问。我们将解析后的参数存储到Params中，通过c.Param(\"lang\")的方式获取到对应的值。 day3-router/gee/context.go type Context struct { // origin objects Writer http.ResponseWriter Req *http.Request // request info Path string Method string Params map[string]string // response info StatusCode int } func (c *Context) Param(key string) string { value, _ := c.Params[key] return value } day3-router/gee/router.go func (r *router) handle(c *Context) { n, params := r.getRoute(c.Method, c.Path) if n != nil { c.Params = params key := c.Method + \"-\" + n.pattern r.handlers[key](c) } else { c.String(http.StatusNotFound, \"404 NOT FOUND: %s\\n\", c.Path) } } router.go的变化比较小，比较重要的一点是，在调用匹配到的handler前，将解析出来的路由参数赋值给了c.Params。这样就能够在handler中，通过Context对象访问到具体的值了。 单元测试 func newTestRouter() *router { r := newRouter() r.addRoute(\"GET\", \"/\", nil) r.addRoute(\"GET\", \"/hello/:name\", nil) r.addRoute(\"GET\", \"/hello/b/c\", nil) r.addRoute(\"GET\", \"/hi/:name\", nil) r.addRoute(\"GET\", \"/assets/*filepath\", nil) return r } func TestParsePattern(t *testing.T) { ok := reflect.DeepEqual(parsePattern(\"/p/:name\"), []string{\"p\", \":name\"}) ok = ok && reflect.DeepEqual(parsePattern(\"/p/*\"), []string{\"p\", \"*\"}) ok = ok && reflect.DeepEqual(parsePattern(\"/p/*name/*\"), []string{\"p\", \"*name\"}) if !ok { t.Fatal(\"test parsePattern failed\") } } func TestGetRoute(t *testing.T) { r := newTestRouter() n, ps := r.getRoute(\"GET\", \"/hello/geektutu\") if n == nil { t.Fatal(\"nil shouldn't be returned\") } if n.pattern != \"/hello/:name\" { t.Fatal(\"should match /hello/:name\") } if ps[\"name\"] != \"geektutu\" { t.Fatal(\"name should be equal to 'geektutu'\") } fmt.Printf(\"matched path: %s, params['name']: %s\\n\", n.pattern, ps[\"name\"]) } 使用Demo 看看框架使用的样例吧。 day3-router/main.go func main() { r := gee.New() r.GET(\"/\", func(c *gee.Context) { c.HTML(http.StatusOK, \"Hello Gee\") }) r.GET(\"/hello\", func(c *gee.Context) { // expect /hello?name=geektutu c.String(http.StatusOK, \"hello %s, you're at %s\\n\", c.Query(\"name\"), c.Path) }) r.GET(\"/hello/:name\", func(c *gee.Context) { // expect /hello/geektutu c.String(http.StatusOK, \"hello %s, you're at %s\\n\", c.Param(\"name\"), c.Path) }) r.GET(\"/assets/*filepath\", func(c *gee.Context) { c.JSON(http.StatusOK, gee.H{\"filepath\": c.Param(\"filepath\")}) }) r.Run(\":9999\") } 使用curl工具，测试结果。 $ curl \"http://localhost:9999/hello/geektutu\" hello geektutu, you're at /hello/geektutu $ curl \"http://localhost:9999/assets/css/geektutu.css\" {\"filepath\":\"css/geektutu.css\"} "},"GoLang/7daysGoLang/gee-web/doc/gee-day4.html":{"url":"GoLang/7daysGoLang/gee-web/doc/gee-day4.html","title":"分组控制(Group)","keywords":"","body":"datetime:2022/02/05 16:58 author:nzb Go语言动手写Web框架 - Gee第四天 分组控制Group 本文是 7天用Go从零实现Web框架Gee教程系列的第四篇。 实现路由分组控制(Route Group Control)，代码约50行 分组的意义 分组控制(Group Control)是 Web 框架应提供的基础功能之一。所谓分组，是指路由的分组。如果没有路由分组，我们需要针对每一个路由进行控制。但是真实的业务场景中，往往某一组路由需要相似的处理。例如： 以/post开头的路由匿名可访问。 以/admin开头的路由需要鉴权。 以/api开头的路由是 RESTful 接口，可以对接第三方平台，需要三方平台鉴权。 大部分情况下的路由分组，是以相同的前缀来区分的。因此，我们今天实现的分组控制也是以前缀来区分，并且支持分组的嵌套。例如/post是一个分组，/post/a和/post/b可以是该分组下的子分组。作用在/post分组上的中间件(middleware)，也都会作用在子分组，子分组还可以应用自己特有的中间件。 中间件可以给框架提供无限的扩展能力，应用在分组上，可以使得分组控制的收益更为明显，而不是共享相同的路由前缀这么简单。例如/admin的分组，可以应用鉴权中间件；/分组应用日志中间件，/是默认的最顶层的分组，也就意味着给所有的路由，即整个框架增加了记录日志的能力。 提供扩展能力支持中间件的内容，我们将在下一节当中介绍。 分组嵌套 一个 Group 对象需要具备哪些属性呢？首先是前缀(prefix)，比如/，或者/api；要支持分组嵌套，那么需要知道当前分组的父亲(parent)是谁；当然了，按照我们一开始的分析，中间件是应用在分组上的，那还需要存储应用在该分组上的中间件(middlewares)。还记得，我们之前调用函数(*Engine).addRoute()来映射所有的路由规则和 Handler 。如果Group对象需要直接映射路由规则的话，比如我们想在使用框架时，这么调用： r := gee.New() v1 := r.Group(\"/v1\") v1.GET(\"/\", func(c *gee.Context) { c.HTML(http.StatusOK, \"Hello Gee\") }) 那么Group对象，还需要有访问Router的能力，为了方便，我们可以在Group中，保存一个指针，指向Engine，整个框架的所有资源都是由Engine统一协调的，那么就可以通过Engine间接地访问各种接口了。 所以，最后的 Group 的定义是这样的： day4-group/gee/gee.go RouterGroup struct { prefix string middlewares []HandlerFunc // support middleware parent *RouterGroup // support nesting engine *Engine // all groups share a Engine instance } 我们还可以进一步地抽象，将Engine作为最顶层的分组，也就是说Engine拥有RouterGroup所有的能力。 Engine struct { *RouterGroup router *router groups []*RouterGroup // store all groups } 那我们就可以将和路由有关的函数，都交给RouterGroup实现了。 // New is the constructor of gee.Engine func New() *Engine { engine := &Engine{router: newRouter()} engine.RouterGroup = &RouterGroup{engine: engine} engine.groups = []*RouterGroup{engine.RouterGroup} return engine } // Group is defined to create a new RouterGroup // remember all groups share the same Engine instance func (group *RouterGroup) Group(prefix string) *RouterGroup { engine := group.engine newGroup := &RouterGroup{ prefix: group.prefix + prefix, parent: group, engine: engine, } engine.groups = append(engine.groups, newGroup) return newGroup } func (group *RouterGroup) addRoute(method string, comp string, handler HandlerFunc) { pattern := group.prefix + comp log.Printf(\"Route %4s - %s\", method, pattern) group.engine.router.addRoute(method, pattern, handler) } // GET defines the method to add GET request func (group *RouterGroup) GET(pattern string, handler HandlerFunc) { group.addRoute(\"GET\", pattern, handler) } // POST defines the method to add POST request func (group *RouterGroup) POST(pattern string, handler HandlerFunc) { group.addRoute(\"POST\", pattern, handler) } 可以仔细观察下addRoute函数，调用了group.engine.router.addRoute来实现了路由的映射。由于Engine从某种意义上继承了RouterGroup的所有属性和方法，因为 (*Engine).engine 是指向自己的。这样实现，我们既可以像原来一样添加路由，也可以通过分组添加路由。 使用 Demo 测试框架的Demo就可以这样写了： func main() { r := gee.New() r.GET(\"/index\", func(c *gee.Context) { c.HTML(http.StatusOK, \"Index Page\") }) v1 := r.Group(\"/v1\") { v1.GET(\"/\", func(c *gee.Context) { c.HTML(http.StatusOK, \"Hello Gee\") }) v1.GET(\"/hello\", func(c *gee.Context) { // expect /hello?name=geektutu c.String(http.StatusOK, \"hello %s, you're at %s\\n\", c.Query(\"name\"), c.Path) }) } v2 := r.Group(\"/v2\") { v2.GET(\"/hello/:name\", func(c *gee.Context) { // expect /hello/geektutu c.String(http.StatusOK, \"hello %s, you're at %s\\n\", c.Param(\"name\"), c.Path) }) v2.POST(\"/login\", func(c *gee.Context) { c.JSON(http.StatusOK, gee.H{ \"username\": c.PostForm(\"username\"), \"password\": c.PostForm(\"password\"), }) }) } r.Run(\":9999\") } 通过 curl 简单测试： $ curl \"http://localhost:9999/v1/hello?name=geektutu\" hello geektutu, you're at /v1/hello $ curl \"http://localhost:9999/v2/hello/geektutu\" hello geektutu, you're at /hello/geektutu "},"GoLang/7daysGoLang/gee-web/doc/gee-day5.html":{"url":"GoLang/7daysGoLang/gee-web/doc/gee-day5.html","title":"中间件(Middleware)","keywords":"","body":"datetime:2022/02/05 16:58 author:nzb Go语言动手写Web框架 - Gee第五天 中间件Middleware 本文是7天用Go从零实现Web框架Gee教程系列的第五篇。 设计并实现 Web 框架的中间件(Middlewares)机制。 实现通用的Logger中间件，能够记录请求到响应所花费的时间，代码约50行 中间件是什么 中间件(middlewares)，简单说，就是非业务的技术类组件。Web 框架本身不可能去理解所有的业务，因而不可能实现所有的功能。因此，框架需要有一个插口，允许用户自己定义功能，嵌入到框架中，仿佛这个功能是框架原生支持的一样。因此，对中间件而言，需要考虑2个比较关键的点： 插入点在哪？使用框架的人并不关心底层逻辑的具体实现，如果插入点太底层，中间件逻辑就会非常复杂。如果插入点离用户太近，那和用户直接定义一组函数，每次在 Handler 中手工调用没有多大的优势了。 中间件的输入是什么？中间件的输入，决定了扩展能力。暴露的参数太少，用户发挥空间有限。 那对于一个 Web 框架而言，中间件应该设计成什么样呢？接下来的实现，基本参考了 Gin 框架。 中间件设计 Gee 的中间件的定义与路由映射的 Handler 一致，处理的输入是Context对象。插入点是框架接收到请求初始化Context对象后，允许用户使用自己定义的中间件做一些额外的处理，例如记录日志等，以及对Context进行二次加工。另外通过调用(*Context).Next()函数，中间件可等待用户自己定义的 Handler处理结束后，再做一些额外的操作，例如计算本次处理所用时间等。即 Gee 的中间件支持用户在请求被处理的前后，做一些额外的操作。举个例子，我们希望最终能够支持如下定义的中间件，c.Next()表示等待执行其他的中间件或用户的Handler： day5-middleware/gee/logger.go func Logger() HandlerFunc { return func(c *Context) { // Start timer t := time.Now() // Process request c.Next() // Calculate resolution time log.Printf(\"[%d] %s in %v\", c.StatusCode, c.Req.RequestURI, time.Since(t)) } } 另外，支持设置多个中间件，依次进行调用。 我们上一篇文章分组控制 Group Control中讲到，中间件是应用在RouterGroup上的，应用在最顶层的 Group，相当于作用于全局，所有的请求都会被中间件处理。那为什么不作用在每一条路由规则上呢？作用在某条路由规则，那还不如用户直接在 Handler 中调用直观。只作用在某条路由规则的功能通用性太差，不适合定义为中间件。 我们之前的框架设计是这样的，当接收到请求后，匹配路由，该请求的所有信息都保存在Context中。中间件也不例外，接收到请求后，应查找所有应作用于该路由的中间件，保存在Context中，依次进行调用。为什么依次调用后，还需要在Context中保存呢？因为在设计中，中间件不仅作用在处理流程前，也可以作用在处理流程后，即在用户定义的 Handler 处理完毕后，还可以执行剩下的操作。 为此，我们给Context添加了2个参数，定义了Next方法： day5-middleware/gee/context.go type Context struct { // origin objects Writer http.ResponseWriter Req *http.Request // request info Path string Method string Params map[string]string // response info StatusCode int // middleware handlers []HandlerFunc index int } func newContext(w http.ResponseWriter, req *http.Request) *Context { return &Context{ Path: req.URL.Path, Method: req.Method, Req: req, Writer: w, index: -1, } } func (c *Context) Next() { c.index++ s := len(c.handlers) for ; c.index index是记录当前执行到第几个中间件，当在中间件中调用Next方法时，控制权交给了下一个中间件，直到调用到最后一个中间件，然后再从后往前，调用每个中间件在Next方法之后定义的部分。如果我们将用户在映射路由时定义的Handler添加到c.handlers列表中，结果会怎么样呢？想必你已经猜到了。 func A(c *Context) { part1 c.Next() part2 } func B(c *Context) { part3 c.Next() part4 } 假设我们应用了中间件 A 和 B，和路由映射的 Handler。c.handlers是这样的[A, B, Handler]，c.index初始化为-1。调用c.Next()，接下来的流程是这样的： c.index++，c.index 变为 0 0 执行 part1，调用 c.Next() c.index++，c.index 变为 1 1 执行 part3，调用 c.Next() c.index++，c.index 变为 2 2 Handler 调用完毕，返回到 B 中的 part4，执行 part4 part4 执行完毕，返回到 A 中的 part2，执行 part2 part2 执行完毕，结束。 一句话说清楚重点，最终的顺序是part1 -> part3 -> Handler -> part 4 -> part2。恰恰满足了我们对中间件的要求，接下来看调用部分的代码，就能全部串起来了。 代码实现 定义Use函数，将中间件应用到某个 Group 。 day5-middleware/gee/gee.go // Use is defined to add middleware to the group func (group *RouterGroup) Use(middlewares ...HandlerFunc) { group.middlewares = append(group.middlewares, middlewares...) } func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { var middlewares []HandlerFunc for _, group := range engine.groups { if strings.HasPrefix(req.URL.Path, group.prefix) { middlewares = append(middlewares, group.middlewares...) } } c := newContext(w, req) c.handlers = middlewares engine.router.handle(c) } ServeHTTP 函数也有变化，当我们接收到一个具体请求时，要判断该请求适用于哪些中间件，在这里我们简单通过 URL 的前缀来判断。得到中间件列表后，赋值给 c.handlers。 handle 函数中，将从路由匹配得到的 Handler 添加到 c.handlers列表中，执行c.Next()。 day5-middleware/gee/router.go func (r *router) handle(c *Context) { n, params := r.getRoute(c.Method, c.Path) if n != nil { key := c.Method + \"-\" + n.pattern c.Params = params c.handlers = append(c.handlers, r.handlers[key]) } else { c.handlers = append(c.handlers, func(c *Context) { c.String(http.StatusNotFound, \"404 NOT FOUND: %s\\n\", c.Path) }) } c.Next() } 使用 Demo func onlyForV2() gee.HandlerFunc { return func(c *gee.Context) { // Start timer t := time.Now() // if a server error occurred c.Fail(500, \"Internal Server Error\") // Calculate resolution time log.Printf(\"[%d] %s in %v for group v2\", c.StatusCode, c.Req.RequestURI, time.Since(t)) } } func main() { r := gee.New() r.Use(gee.Logger()) // global midlleware r.GET(\"/\", func(c *gee.Context) { c.HTML(http.StatusOK, \"Hello Gee\") }) v2 := r.Group(\"/v2\") v2.Use(onlyForV2()) // v2 group middleware { v2.GET(\"/hello/:name\", func(c *gee.Context) { // expect /hello/geektutu c.String(http.StatusOK, \"hello %s, you're at %s\\n\", c.Param(\"name\"), c.Path) }) } r.Run(\":9999\") } gee.Logger()即我们一开始就介绍的中间件，我们将这个中间件和框架代码放在了一起，作为框架默认提供的中间件。在这个例子中，我们将gee.Logger()应用在了全局，所有的路由都会应用该中间件。onlyForV2()是用来测试功能的，仅在v2对应的 Group 中应用了。 接下来使用 curl 测试，可以看到，v2 Group 2个中间件都生效了。 $ curl http://localhost:9999/ >>> log 2019/08/17 01:37:38 [200] / in 3.14µs (2) global + group middleware $ curl http://localhost:9999/v2/hello/geektutu >>> log 2019/08/17 01:38:48 [200] /v2/hello/geektutu in 61.467µs for group v2 2019/08/17 01:38:48 [200] /v2/hello/geektutu in 281µs "},"GoLang/7daysGoLang/gee-web/doc/gee-day6.html":{"url":"GoLang/7daysGoLang/gee-web/doc/gee-day6.html","title":"HTML模板(Template)","keywords":"","body":"datetime:2022/02/05 16:58 author:nzb Go语言动手写Web框架 - Gee第六天 模板(HTML Template) 本文是7天用Go从零实现Web框架Gee教程系列的第六篇。 实现静态资源服务(Static Resource)。 支持HTML模板渲染。 服务端渲染 现在越来越流行前后端分离的开发模式，即 Web 后端提供 RESTful 接口，返回结构化的数据(通常为 JSON 或者 XML)。前端使用 AJAX 技术请求到所需的数据，利用 JavaScript 进行渲染。Vue/React 等前端框架持续火热，这种开发模式前后端解耦，优势非常突出。后端童鞋专心解决资源利用，并发，数据库等问题，只需要考虑数据如何生成；前端童鞋专注于界面设计实现，只需要考虑拿到数据后如何渲染即可。使用 JSP 写过网站的童鞋，应该能感受到前后端耦合的痛苦。JSP 的表现力肯定是远不如 Vue/React 等专业做前端渲染的框架的。而且前后端分离在当前还有另外一个不可忽视的优势。因为后端只关注于数据，接口返回值是结构化的，与前端解耦。同一套后端服务能够同时支撑小程序、移动APP、PC端 Web 页面，以及对外提供的接口。随着前端工程化的不断地发展，Webpack，gulp 等工具层出不穷，前端技术越来越自成体系了。 但前后分离的一大问题在于，页面是在客户端渲染的，比如浏览器，这对于爬虫并不友好。Google 爬虫已经能够爬取渲染后的网页，但是短期内爬取服务端直接渲染的 HTML 页面仍是主流。 今天的内容便是介绍 Web 框架如何支持服务端渲染的场景。 静态文件(Serve Static Files) 网页的三剑客，JavaScript、CSS 和 HTML。要做到服务端渲染，第一步便是要支持 JS、CSS 等静态文件。还记得我们之前设计动态路由的时候，支持通配符*匹配多级子路径。比如路由规则/assets/*filepath，可以匹配/assets/开头的所有的地址。例如/assets/js/geektutu.js，匹配后，参数filepath就赋值为js/geektutu.js。 那如果我么将所有的静态文件放在/usr/web目录下，那么filepath的值即是该目录下文件的相对地址。映射到真实的文件后，将文件返回，静态服务器就实现了。 找到文件后，如何返回这一步，net/http库已经实现了。因此，gee 框架要做的，仅仅是解析请求的地址，映射到服务器上文件的真实地址，交给http.FileServer处理就好了。 day6-template/gee/gee.go // create static handler func (group *RouterGroup) createStaticHandler(relativePath string, fs http.FileSystem) HandlerFunc { absolutePath := path.Join(group.prefix, relativePath) fileServer := http.StripPrefix(absolutePath, http.FileServer(fs)) return func(c *Context) { file := c.Param(\"filepath\") // Check if file exists and/or if we have permission to access it if _, err := fs.Open(file); err != nil { c.Status(http.StatusNotFound) return } fileServer.ServeHTTP(c.Writer, c.Req) } } // serve static files func (group *RouterGroup) Static(relativePath string, root string) { handler := group.createStaticHandler(relativePath, http.Dir(root)) urlPattern := path.Join(relativePath, \"/*filepath\") // Register GET handlers group.GET(urlPattern, handler) } 我们给RouterGroup添加了2个方法，Static这个方法是暴露给用户的。用户可以将磁盘上的某个文件夹root映射到路由relativePath。例如： r := gee.New() r.Static(\"/assets\", \"/usr/geektutu/blog/static\") // 或相对路径 r.Static(\"/assets\", \"./static\") r.Run(\":9999\") 用户访问localhost:9999/assets/js/geektutu.js，最终返回/usr/geektutu/blog/static/js/geektutu.js。 HTML 模板渲染 Go语言内置了text/template和html/template2个模板标准库，其中html/template为 HTML 提供了较为完整的支持。包括普通变量渲染、列表渲染、对象渲染等。gee 框架的模板渲染直接使用了html/template提供的能力。 Engine struct { *RouterGroup router *router groups []*RouterGroup // store all groups htmlTemplates *template.Template // for html render funcMap template.FuncMap // for html render } func (engine *Engine) SetFuncMap(funcMap template.FuncMap) { engine.funcMap = funcMap } func (engine *Engine) LoadHTMLGlob(pattern string) { engine.htmlTemplates = template.Must(template.New(\"\").Funcs(engine.funcMap).ParseGlob(pattern)) } 首先为 Engine 示例添加了 *template.Template 和 template.FuncMap对象，前者将所有的模板加载进内存，后者是所有的自定义模板渲染函数。 另外，给用户分别提供了设置自定义渲染函数funcMap和加载模板的方法。 接下来，对原来的 (*Context).HTML()方法做了些小修改，使之支持根据模板文件名选择模板进行渲染。 day6-template/gee/context.go type Context struct { // ... // engine pointer engine *Engine } func (c *Context) HTML(code int, name string, data interface{}) { c.SetHeader(\"Content-Type\", \"text/html\") c.Status(code) if err := c.engine.htmlTemplates.ExecuteTemplate(c.Writer, name, data); err != nil { c.Fail(500, err.Error()) } } 我们在 Context 中添加了成员变量 engine *Engine，这样就能够通过 Context 访问 Engine 中的 HTML 模板。实例化 Context 时，还需要给 c.engine 赋值。 day6-template/gee/gee.go func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { // ... c := newContext(w, req) c.handlers = middlewares c.engine = engine engine.router.handle(c) } 使用Demo 最终的目录结构 ---gee/ ---static/ |---css/ |---geektutu.css |---file1.txt ---templates/ |---arr.tmpl |---css.tmpl |---custom_func.tmpl ---main.go geektutu.css is loaded day6-template/main.go type student struct { Name string Age int8 } func FormatAsDate(t time.Time) string { year, month, day := t.Date() return fmt.Sprintf(\"%d-%02d-%02d\", year, month, day) } func main() { r := gee.New() r.Use(gee.Logger()) r.SetFuncMap(template.FuncMap{ \"FormatAsDate\": FormatAsDate, }) r.LoadHTMLGlob(\"templates/*\") r.Static(\"/assets\", \"./static\") stu1 := &student{Name: \"Geektutu\", Age: 20} stu2 := &student{Name: \"Jack\", Age: 22} r.GET(\"/\", func(c *gee.Context) { c.HTML(http.StatusOK, \"css.tmpl\", nil) }) r.GET(\"/students\", func(c *gee.Context) { c.HTML(http.StatusOK, \"arr.tmpl\", gee.H{ \"title\": \"gee\", \"stuArr\": [2]*student{stu1, stu2}, }) }) r.GET(\"/date\", func(c *gee.Context) { c.HTML(http.StatusOK, \"custom_func.tmpl\", gee.H{ \"title\": \"gee\", \"now\": time.Date(2019, 8, 17, 0, 0, 0, 0, time.UTC), }) }) r.Run(\":9999\") } 访问下主页，模板正常渲染，CSS 静态文件加载成功。 "},"GoLang/7daysGoLang/gee-web/doc/gee-day7.html":{"url":"GoLang/7daysGoLang/gee-web/doc/gee-day7.html","title":"错误恢复(Panic Recover)","keywords":"","body":"datetime:2022/02/05 16:58 author:nzb Go语言动手写Web框架 - Gee第七天 错误恢复(Panic Recover) 本文是7天用Go从零实现Web框架Gee教程系列的第七篇。 实现错误处理机制。 panic Go 语言中，比较常见的错误处理方法是返回 error，由调用者决定后续如何处理。但是如果是无法恢复的错误，可以手动触发 panic，当然如果在程序运行过程中出现了类似于数组越界的错误，panic 也会被触发。panic 会中止当前执行的程序，退出。 下面是主动触发的例子： // hello.go func main() { fmt.Println(\"before panic\") panic(\"crash\") fmt.Println(\"after panic\") } $ go run hello.go before panic panic: crash goroutine 1 [running]: main.main() ~/go_demo/hello/hello.go:7 +0x95 exit status 2 下面是数组越界触发的 panic // hello.go func main() { arr := []int{1, 2, 3} fmt.Println(arr[4]) } $ go run hello.go panic: runtime error: index out of range [4] with length 3 defer panic 会导致程序被中止，但是在退出前，会先处理完当前协程上已经defer 的任务，执行完成后再退出。效果类似于 java 语言的 try...catch。 // hello.go func main() { defer func() { fmt.Println(\"defer func\") }() arr := []int{1, 2, 3} fmt.Println(arr[4]) } $ go run hello.go defer func panic: runtime error: index out of range [4] with length 3 可以 defer 多个任务，在同一个函数中 defer 多个任务，会逆序执行。即先执行最后 defer 的任务。 在这里，defer 的任务执行完成之后，panic 还会继续被抛出，导致程序非正常结束。 recover Go 语言还提供了 recover 函数，可以避免因为 panic 发生而导致整个程序终止，recover 函数只在 defer 中生效。 // hello.go func test_recover() { defer func() { fmt.Println(\"defer func\") if err := recover(); err != nil { fmt.Println(\"recover success\") } }() arr := []int{1, 2, 3} fmt.Println(arr[4]) fmt.Println(\"after panic\") } func main() { test_recover() fmt.Println(\"after recover\") } $ go run hello.go defer func recover success after recover 我们可以看到，recover 捕获了 panic，程序正常结束。test_recover() 中的 after panic 没有打印，这是正确的，当 panic 被触发时，控制权就被交给了 defer 。就像在 java 中，try代码块中发生了异常，控制权交给了 catch，接下来执行 catch 代码块中的代码。而在 main() 中打印了 after recover，说明程序已经恢复正常，继续往下执行直到结束。 Gee 的错误处理机制 对一个 Web 框架而言，错误处理机制是非常必要的。可能是框架本身没有完备的测试，导致在某些情况下出现空指针异常等情况。也有可能用户不正确的参数，触发了某些异常，例如数组越界，空指针等。如果因为这些原因导致系统宕机，必然是不可接受的。 我们在第六天实现的框架并没有加入异常处理机制，如果代码中存在会触发 panic 的 BUG，很容易宕掉。 例如下面的代码： func main() { r := gee.New() r.GET(\"/panic\", func(c *gee.Context) { names := []string{\"geektutu\"} c.String(http.StatusOK, names[100]) }) r.Run(\":9999\") } 在上面的代码中，我们为 gee 注册了路由 /panic，而这个路由的处理函数内部存在数组越界 names[100]，如果访问 localhost:9999/panic，Web 服务就会宕掉。 今天，我们将在 gee 中添加一个非常简单的错误处理机制，即在此类错误发生时，向用户返回 Internal Server Error，并且在日志中打印必要的错误信息，方便进行错误定位。 我们之前实现了中间件机制，错误处理也可以作为一个中间件，增强 gee 框架的能力。 新增文件 gee/recovery.go，在这个文件中实现中间件 Recovery。 func Recovery() HandlerFunc { return func(c *Context) { defer func() { if err := recover(); err != nil { message := fmt.Sprintf(\"%s\", err) log.Printf(\"%s\\n\\n\", trace(message)) c.Fail(http.StatusInternalServerError, \"Internal Server Error\") } }() c.Next() } } Recovery 的实现非常简单，使用 defer 挂载上错误恢复的函数，在这个函数中调用 recover()，捕获 panic，并且将堆栈信息打印在日志中，向用户返回 Internal Server Error。 你可能注意到，这里有一个 trace() 函数，这个函数是用来获取触发 panic 的堆栈信息，完整代码如下： day7-panic-recover/gee/recovery.go package gee import ( \"fmt\" \"log\" \"net/http\" \"runtime\" \"strings\" ) // print stack trace for debug func trace(message string) string { var pcs [32]uintptr n := runtime.Callers(3, pcs[:]) // skip first 3 caller var str strings.Builder str.WriteString(message + \"\\nTraceback:\") for _, pc := range pcs[:n] { fn := runtime.FuncForPC(pc) file, line := fn.FileLine(pc) str.WriteString(fmt.Sprintf(\"\\n\\t%s:%d\", file, line)) } return str.String() } func Recovery() HandlerFunc { return func(c *Context) { defer func() { if err := recover(); err != nil { message := fmt.Sprintf(\"%s\", err) log.Printf(\"%s\\n\\n\", trace(message)) c.Fail(http.StatusInternalServerError, \"Internal Server Error\") } }() c.Next() } } 在 trace() 中，调用了 runtime.Callers(3, pcs[:])，Callers 用来返回调用栈的程序计数器, 第 0 个 Caller 是 Callers 本身，第 1 个是上一层 trace，第 2 个是再上一层的 defer func。因此，为了日志简洁一点，我们跳过了前 3 个 Caller。 接下来，通过 runtime.FuncForPC(pc) 获取对应的函数，在通过 fn.FileLine(pc) 获取到调用该函数的文件名和行号，打印在日志中。 至此，gee 框架的错误处理机制就完成了。 使用 Demo day7-panic-recover/main.go package main import ( \"net/http\" \"gee\" ) func main() { r := gee.Default() r.GET(\"/\", func(c *gee.Context) { c.String(http.StatusOK, \"Hello Geektutu\\n\") }) // index out of range for testing Recovery() r.GET(\"/panic\", func(c *gee.Context) { names := []string{\"geektutu\"} c.String(http.StatusOK, names[100]) }) r.Run(\":9999\") } 接下来进行测试，先访问主页，访问一个有BUG的 /panic，服务正常返回。接下来我们再一次成功访问了主页，说明服务完全运转正常。 $ curl \"http://localhost:9999\" Hello Geektutu $ curl \"http://localhost:9999/panic\" {\"message\":\"Internal Server Error\"} $ curl \"http://localhost:9999\" Hello Geektutu 我们可以在后台日志中看到如下内容，引发错误的原因和堆栈信息都被打印了出来，通过日志，我们可以很容易地知道，在day7-panic-recover/main.go:47 的地方出现了 index out of range 错误。 2020/01/09 01:00:10 Route GET - / 2020/01/09 01:00:10 Route GET - /panic 2020/01/09 01:00:22 [200] / in 25.364µs 2020/01/09 01:00:32 runtime error: index out of range Traceback: /usr/local/Cellar/go/1.12.5/libexec/src/runtime/panic.go:523 /usr/local/Cellar/go/1.12.5/libexec/src/runtime/panic.go:44 /tmp/7days-golang/day7-panic-recover/main.go:47 /tmp/7days-golang/day7-panic-recover/gee/context.go:41 /tmp/7days-golang/day7-panic-recover/gee/recovery.go:37 /tmp/7days-golang/day7-panic-recover/gee/context.go:41 /tmp/7days-golang/day7-panic-recover/gee/logger.go:15 /tmp/7days-golang/day7-panic-recover/gee/context.go:41 /tmp/7days-golang/day7-panic-recover/gee/router.go:99 /tmp/7days-golang/day7-panic-recover/gee/gee.go:130 /usr/local/Cellar/go/1.12.5/libexec/src/net/http/server.go:2775 /usr/local/Cellar/go/1.12.5/libexec/src/net/http/server.go:1879 /usr/local/Cellar/go/1.12.5/libexec/src/runtime/asm_amd64.s:1338 2020/01/09 01:00:32 [500] /panic in 395.846µs 2020/01/09 01:00:38 [200] / in 6.985µs 参考 Package runtime - golang.org Is it possible get information about caller function in Golang? - StackOverflow "},"C++/基础/01-C++初识.html":{"url":"C++/基础/01-C++初识.html","title":"C++初始","keywords":"","body":"datetime:2022/08/15 14:02 author:nzb 1 C++初识 1.1 第一个C++程序 编写一个C++程序总共分为4个步骤 创建项目 创建文件 编写代码 运行程序 1.1.1 创建项目 Visual Studio是我们用来编写C++程序的主要工具，我们先将它打开 1.1.2 创建文件 右键源文件，选择添加->新建项 给C++文件起个名称，然后点击添加即可。 1.1.3 编写代码 #include using namespace std; int main() { cout 1.1.4 运行程序 1.2 注释 作用：在代码中加一些说明和解释，方便自己或其他程序员程序员阅读代码 两种格式 单行注释：// 描述信息 通常放在一行代码的上方，或者一条语句的末尾，==对该行代码说明== 多行注释： /* 描述信息 */ 通常放在一段代码的上方，==对该段代码做整体说明== 提示：编译器在编译代码时，会忽略注释的内容 1.3 变量 作用：给一段指定的内存空间起名，方便操作这段内存 语法：数据类型 变量名 = 初始值; 示例： #include using namespace std; int main() { //变量的定义 //语法：数据类型 变量名 = 初始值 int a = 10; cout 注意：C++在创建变量时，必须给变量一个初始值，否则会报错 1.4 常量 作用：用于记录程序中不可更改的数据 C++定义常量两种方式 #define 宏常量： #define 常量名 常量值 通常在文件上方定义，表示一个常量 const修饰的变量 const 数据类型 常量名 = 常量值 通常在变量定义前加关键字const，修饰该变量为常量，不可修改 示例： //1、宏常量 #define day 7 int main() { cout 1.5 关键字 作用：关键字是C++中预先保留的单词（标识符） 在定义变量或者常量时候，不要用关键字 C++关键字如下： asm do if return typedef auto double inline short typeid bool dynamic_cast int signed typename break else long sizeof union case enum mutable static unsigned catch explicit namespace static_cast using char export new struct virtual class extern operator switch void const false private template volatile const_cast float protected this wchar_t continue for public throw while default friend register true delete goto reinterpret_cast try 提示：在给变量或者常量起名称时候，不要用C++得关键字，否则会产生歧义。 1.6 标识符命名规则 作用：C++规定给标识符（变量、常量）命名时，有一套自己的规则 标识符不能是关键字 标识符只能由字母、数字、下划线组成 第一个字符必须为字母或下划线 标识符中字母区分大小写 建议：给标识符命名时，争取做到见名知意的效果，方便自己和他人的阅读 "},"C++/基础/02-数据类型.html":{"url":"C++/基础/02-数据类型.html","title":"数据类型","keywords":"","body":"datetime:2022/08/15 14:02 author:nzb 2 数据类型 C++规定在创建一个变量或者常量时，必须要指定出相应的数据类型，否则无法给变量分配内存 2.1 整型 作用：整型变量表示的是整数类型的数据 C++中能够表示整型的类型有以下几种方式，区别在于所占内存空间不同： 数据类型 占用空间 取值范围 short(短整型) 2字节 (-2^15 ~ 2^15-1) int(整型) 4字节 (-2^31 ~ 2^31-1) long(长整形) Windows为4字节，Linux为4字节(32位)，8字节(64位) (-2^31 ~ 2^31-1) long long(长长整形) 8字节 (-2^63 ~ 2^63-1) 2.2 sizeof关键字 作用：利用sizeof关键字可以统计数据类型所占内存大小 语法： sizeof( 数据类型 / 变量) 示例： int main() { cout 整型结论：short 2.3 实型（浮点型） 作用：用于表示小数 浮点型变量分为两种： 单精度float 双精度double 两者的区别在于表示的有效数字范围不同。 数据类型 占用空间 有效数字范围 float 4字节 7位有效数字 double 8字节 15～16位有效数字 示例： int main() { float f1 = 3.14f; double d1 = 3.14; cout 2.4 字符型 作用：字符型变量用于显示单个字符 语法：char ch = 'a'; 注意1：在显示字符型变量时，用单引号将字符括起来，不要用双引号 注意2：单引号内只能有一个字符，不可以是字符串 C和C++中字符型变量只占用1个字节。 字符型变量并不是把字符本身放到内存中存储，而是将对应的ASCII编码放入到存储单元 示例： int main() { char ch = 'a'; cout ASCII码表格： ASCII值 控制字符 ASCII值 字符 ASCII值 字符 ASCII值 字符 0 NUT 32 (space) 64 @ 96 、 1 SOH 33 ! 65 A 97 a 2 STX 34 \" 66 B 98 b 3 ETX 35 # 67 C 99 c 4 EOT 36 $ 68 D 100 d 5 ENQ 37 % 69 E 101 e 6 ACK 38 & 70 F 102 f 7 BEL 39 , 71 G 103 g 8 BS 40 ( 72 H 104 h 9 HT 41 ) 73 I 105 i 10 LF 42 * 74 J 106 j 11 VT 43 + 75 K 107 k 12 FF 44 , 76 L 108 l 13 CR 45 - 77 M 109 m 14 SO 46 . 78 N 110 n 15 SI 47 / 79 O 111 o 16 DLE 48 0 80 P 112 p 17 DCI 49 1 81 Q 113 q 18 DC2 50 2 82 R 114 r 19 DC3 51 3 83 S 115 s 20 DC4 52 4 84 T 116 t 21 NAK 53 5 85 U 117 u 22 SYN 54 6 86 V 118 v 23 TB 55 7 87 W 119 w 24 CAN 56 8 88 X 120 x 25 EM 57 9 89 Y 121 y 26 SUB 58 : 90 Z 122 z 27 ESC 59 ; 91 [ 123 { 28 FS 60 92 / 124 \\ 29 GS 61 = 93 ] 125 } 30 RS 62 > 94 ^ 126 ` 31 US 63 ? 95 _ 127 DEL ASCII 码大致由以下两部分组成： ASCII 非打印控制字符： ASCII 表上的数字 0-31 分配给了控制字符，用于控制像打印机等一些外围设备。 ASCII 打印字符：数字 32-126 分配给了能在键盘上找到的字符，当查看或打印文档时就会出现。 2.5 转义字符 作用：用于表示一些不能显示出来的ASCII字符 现阶段我们常用的转义字符有：\\n \\\\ \\t 转义字符 含义 ASCII码值（十进制） \\a 警报 007 \\b 退格(BS) ，将当前位置移到前一列 008 \\f 换页(FF)，将当前位置移到下页开头 012 \\n 换行(LF) ，将当前位置移到下一行开头 010 \\r 回车(CR) ，将当前位置移到本行开头 013 \\t 水平制表(HT) （跳到下一个TAB位置） 009 \\v 垂直制表(VT) 011 \\\\ 代表一个反斜线字符\"\\\" 092 \\' 代表一个单引号（撇号）字符 039 \\\" 代表一个双引号字符 034 \\? 代表一个问号 063 \\0 数字0 000 \\ddd 8进制转义字符，d范围0~7 3位8进制 \\xhh 16进制转义字符，h范围0~9，a~f，A~F 3位16进制 示例： int main() { cout 2.6 字符串型 作用：用于表示一串字符 两种风格 C风格字符串： char 变量名[] = \"字符串值\" 示例： int main() { char str1[] = \"hello world\"; cout C++风格字符串： string 变量名 = \"字符串值\" 示例： int main() { string str = \"hello world\"; cout 注意：C风格的字符串要用双引号括起来注意：C++风格字符串，需要加入头文件#include 2.7 布尔类型 bool 作用：布尔数据类型代表真或假的值 bool类型只有两个值： true：真（本质是1） false： 假（本质是0） bool类型占1个字节大小 示例： int main() { bool flag = true; cout 2.8 数据的输入 作用：用于从键盘获取数据 关键字：cin 语法： cin >> 变量 示例： int main(){ //整型输入 int a = 0; cout > a; cout > d; cout > ch; cout > str; cout > flag; cout "},"C++/基础/03-运算符.html":{"url":"C++/基础/03-运算符.html","title":"运算符","keywords":"","body":"datetime:2022/08/15 15:52 author:nzb 3 运算符 作用：用于执行代码的运算 本章我们主要讲解以下几类运算符： 运算符类型 作用 算术运算符 用于处理四则运算 赋值运算符 用于将表达式的值赋给变量 比较运算符 用于表达式的比较，并返回一个真值或假值 逻辑运算符 用于根据表达式的值返回真值或假值 3.1 算术运算符 作用：用于处理四则运算 算术运算符包括以下符号： 运算符 术语 示例 结果 + 正号 +3 3 - 负号 -3 -3 + 加 10 + 5 15 - 减 10 - 5 5 * 乘 10 * 5 50 / 除 10 / 5 2 % 取模(取余) 10 % 3 1 ++ 前置递增 a=2; b=++a; a=3; b=3; ++ 后置递增 a=2; b=a++; a=3; b=2; -- 前置递减 a=2; b=--a; a=1; b=1; -- 后置递减 a=2; b=a--; a=1; b=2; 示例1： //加减乘除 int main() { int a1 = 10; int b1 = 3; cout 总结：在除法运算中，除数不能为0 示例2： //取模 int main() { int a1 = 10; int b1 = 3; cout 总结：只有整型变量可以进行取模运算 示例3： //递增 int main() { //后置递增 int a = 10; a++; //等价于a = a + 1 cout 总结：前置递增先对变量进行++，再计算表达式，后置递增相反 3.2 赋值运算符 作用：用于将表达式的值赋给变量 赋值运算符包括以下几个符号： 运算符 术语 示例 结果 = 赋值 a=2; b=3; a=2; b=3; += 加等于 a=0; a+=2; a=2; -= 减等于 a=5; a-=3; a=2; *= 乘等于 a=2; a*=2; a=4; /= 除等于 a=4; a/=2; a=2; %= 模等于 a=3; a%2; a=1; 示例： int main() { //赋值运算符 // = int a = 10; a = 100; cout 3.3 比较运算符 作用：用于表达式的比较，并返回一个真值或假值 比较运算符有以下符号： 运算符 术语 示例 结果 == 相等于 4 == 3 0 != 不等于 4 != 3 1 小于 4 0 > 大于 4 > 3 1 小于等于 4 0 >= 大于等于 4 >= 1 1 示例： int main() { int a = 10; int b = 20; cout b) = b) 注意：C和C++ 语言的比较运算中， “真”用数字“1”来表示， “假”用数字“0”来表示。 3.4 逻辑运算符 作用：用于根据表达式的值返回真值或假值 逻辑运算符有以下符号： 运算符 术语 示例 结果 ! 非 !a 如果a为假，则!a为真； 如果a为真，则!a为假。 && 与 a && b 如果a和b都为真，则结果为真，否则为假。 ` ` 或 a ` ` b 如果a和b有一个为真，则结果为真，二者都为假时，结果为假。 示例1：逻辑非 //逻辑运算符 --- 非 int main() { int a = 10; cout 总结： 真变假，假变真 示例2：逻辑与 //逻辑运算符 --- 与 int main() { int a = 10; int b = 10; cout 总结：逻辑与运算符，同真为真，其余为假 示例3：逻辑或 //逻辑运算符 --- 或 int main() { int a = 10; int b = 10; cout 总结：逻辑或运算符，同假为假，其余为真 "},"C++/基础/04-流程控制.html":{"url":"C++/基础/04-流程控制.html","title":"流程控制","keywords":"","body":"datetime:2022/08/15 16:02 author:nzb 4 程序流程结构 C/C++支持最基本的三种程序运行结构：==顺序结构、选择结构、循环结构== 顺序结构：程序按顺序执行，不发生跳转 选择结构：依据条件是否满足，有选择的执行相应功能 循环结构：依据条件是否满足，循环多次执行某段代码 4.1 选择结构 4.1.1 if语句 作用：执行满足条件的语句 if语句的三种形式 单行格式if语句 多行格式if语句 多条件的if语句 - 1. 单行格式if语句：`if(条件){ 条件满足执行的语句 }` 示例： int main() { //选择结构-单行if语句 //输入一个分数，如果分数大于600分，视为考上一本大学，并在屏幕上打印 int score = 0; cout > score; cout 600) { cout 注意：if条件表达式后不要加分号 - 2. 多行格式if语句：`if(条件){ 条件满足执行的语句 }else{ 条件不满足执行的语句 };` 示例： int main() { int score = 0; cout > score; if (score > 600) { cout - 3. 多条件的if语句：`if(条件1){ 条件1满足执行的语句 }else if(条件2){条件2满足执行的语句}... else{ 都不满足执行的语句}` 示例： int main() { int score = 0; cout > score; if (score > 600) { cout 500) { cout 400) { cout 嵌套if语句：在if语句中，可以嵌套使用if语句，达到更精确的条件判断 案例需求： 提示用户输入一个高考考试分数，根据分数做如下判断 分数如果大于600分视为考上一本，大于500分考上二本，大于400考上三本，其余视为未考上本科； 在一本分数中，如果大于700分，考入北大，大于650分，考入清华，大于600考入人大。 示例： int main() { int score = 0; cout > score; if (score > 600) { cout 700) { cout 650) { cout 500) { cout 400) { cout 练习案例： 三只小猪称体重 有三只小猪ABC，请分别输入三只小猪的体重，并且判断哪只小猪最重？ 4.1.2 三目运算符 作用：通过三目运算符实现简单的判断 语法：表达式1 ? 表达式2 ：表达式3 解释： 如果表达式1的值为真，执行表达式2，并返回表达式2的结果； 如果表达式1的值为假，执行表达式3，并返回表达式3的结果。 示例： int main() { int a = 10; int b = 20; int c = 0; c = a > b ? a : b; cout b ? a : b) = 100; cout 总结：和if语句比较，三目运算符优点是短小整洁，缺点是如果用嵌套，结构不清晰 4.1.3 switch语句 作用：执行多条件分支语句 语法： switch(表达式) { case 结果1：执行语句;break; case 结果2：执行语句;break; ... default:执行语句;break; } 示例： int main() { //请给电影评分 //10 ~ 9 经典 // 8 ~ 7 非常好 // 6 ~ 5 一般 // 5分以下 烂片 int score = 0; cout > score; switch (score) { case 10: case 9: cout 注意1：switch语句中表达式类型只能是整型或者字符型注意2：case里如果没有break，那么程序会一直向下执行总结：与if语句比，对于多条件判断时，switch的结构清晰，执行效率高，缺点是switch不可以判断区间 4.2 循环结构 4.2.1 while循环语句 作用：满足循环条件，执行循环语句 语法：while(循环条件){ 循环语句 } 解释： 只要循环条件的结果为真，就执行循环语句 示例： int main() { int num = 0; while (num 注意：在执行循环语句时候，程序必须提供跳出循环的出口，否则出现死循环 while循环练习案例：猜数字 案例描述：系统随机生成一个1到100之间的数字，玩家进行猜测，如果猜错，提示玩家数字过大或过小，如果猜对恭喜玩家胜利，并且退出游戏。 4.2.2 do...while循环语句 作用：满足循环条件，执行循环语句 语法：do{ 循环语句 } while(循环条件); 注意：与while的区别在于do...while会先执行一次循环语句，再判断循环条件 示例： int main() { int num = 0; do { cout 总结：与while循环区别在于，do...while先执行一次循环语句，再判断循环条件 练习案例：水仙花数 案例描述：水仙花数是指一个 3 位数，它的每个位上的数字的 3次幂之和等于它本身 例如：1^3 + 5^3+ 3^3 = 153 请利用do...while语句，求出所有3位数中的水仙花数 int main() { // 1、先打印所有的三位数字 int num = 100; do { // 2、从所有三位数中找到水仙花 int a = 0; // 个位 int b = 0; // 十位 int c = 0; // 百位 a = num % 10; b = num / 10 % 10; c = num / 100 % 10; if (a * a * a + b * b * b + c * c * c == num) { cout 4.2.3 for循环语句 作用：满足循环条件，执行循环语句 语法：for(起始表达式;条件表达式;末尾循环体) { 循环语句; } 示例： int main() { for (int i = 0; i 详解： 注意：for循环中的表达式，要用分号进行分隔 总结：while , do...while, for都是开发中常用的循环语句，for循环结构比较清晰，比较常用 练习案例：敲桌子 案例描述：从1开始数到数字100， 如果数字个位含有7，或者数字十位含有7，或者该数字是7的倍数，我们打印敲桌子，其余数字直接打印输出。 int main() { // 1、先输出1~100 for (int i = 1; i 4.2.4 嵌套循环 作用： 在循环体中再嵌套一层循环，解决一些实际问题 例如我们想在屏幕中打印如下图片，就需要利用嵌套循环 示例： int main() { //外层循环执行1次，内层循环执行1轮 for (int i = 0; i 练习案例：乘法口诀表 案例描述：利用嵌套循环，实现九九乘法表 int main() { for (int i = 1; i 4.3 跳转语句 4.3.1 break语句 作用: 用于跳出选择结构或者循环结构 break使用的时机： 出现在switch条件语句中，作用是终止case并跳出switch 出现在循环语句中，作用是跳出当前的循环语句 出现在嵌套循环中，跳出最近的内层循环语句 示例1： int main() { //1、在switch 语句中使用break cout > num; switch (num) { case 1: cout 示例2： int main() { //2、在循环语句中用break for (int i = 0; i 示例3： int main() { //在嵌套循环语句中使用break，退出内层循环 for (int i = 0; i 4.3.2 continue语句 作用：在循环语句中，跳过本次循环中余下尚未执行的语句，继续执行下一次循环 示例： int main() { for (int i = 0; i 注意：continue并没有使整个循环终止，而break会跳出循环 4.3.3 goto语句 作用：可以无条件跳转语句 语法： goto 标记; 解释：如果标记的名称存在，执行到goto语句时，会跳转到标记的位置 示例： int main() { cout 注意：在程序中不建议使用goto语句，以免造成程序流程混乱 "},"C++/基础/05-数组.html":{"url":"C++/基础/05-数组.html","title":"数组","keywords":"","body":"datetime:2022/08/19 14:07 author:nzb 5 数组 5.1 概述 所谓数组，就是一个集合，里面存放了相同类型的数据元素 特点1：数组中的每个数据元素都是相同的数据类型 特点2：数组是由连续的内存位置组成的 5.2 一维数组 5.2.1 一维数组定义方式 一维数组定义的三种方式： 1、数据类型 数组名[ 数组长度 ]; 2、数据类型 数组名[ 数组长度 ] = { 值1，值2 ...}; 3、数据类型 数组名[ ] = { 值1，值2 ...}; 示例 int main() { //定义方式1 //数据类型 数组名[元素个数]; int score[10]; //利用下标赋值 score[0] = 100; score[1] = 99; score[2] = 85; //利用下标输出 cout 总结1：数组名的命名规范与变量名命名规范一致，不要和变量重名 总结2：数组中下标是从0开始索引 5.2.2 一维数组数组名 一维数组名称的用途： 1、 可以统计整个数组在内存中的长度 2、 可以获取数组在内存中的首地址 示例： int main() { //数组名用途 //1、可以获取整个数组占用内存空间大小 int arr[10] = { 1,2,3,4,5,6,7,8,9,10 }; cout 注意：数组名是常量，不可以赋值 总结1：直接打印数组名，可以查看数组所占内存的首地址 总结2：对数组名进行sizeof，可以获取整个数组占内存空间的大小 练习案例1：五只小猪称体重 案例描述：：在一个数组中记录了五只小猪的体重，如：int arr[5] = {300,350,200,400,250};找出并打印最重的小猪体重。 int main() { int arr[5] = {300,350,200,400,250}; int max = 0; for (int i = 0; i max){ max = arr[i]; } } cout 练习案例2：数组元素逆置 案例描述：请声明一个5个元素的数组，并且将元素逆置.(如原数组元素为：1,3,2,5,4;逆置后输出结果为:4,5,2,3,1); int main() { int arr[5] = {1,3,2,5,4}; cout 5.2.3 冒泡排序 作用： 最常用的排序算法，对数组内元素进行排序 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素做同样的工作，执行完毕后，找到第一个最大值。 重复以上的步骤，每次比较次数-1，直到不需要比较 示例： 将数组 { 4,2,8,0,5,7,1,3,9 } 进行升序排序 int main() { int arr[9] = { 4,2,8,0,5,7,1,3,9 }; for (int i = 0; i arr[j + 1]) { int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; } } } for (int i = 0; i 5.3 二维数组 二维数组就是在一维数组上，多加一个维度。 5.3.1 二维数组定义方式 二维数组定义的四种方式： 1、 数据类型 数组名[ 行数 ][ 列数 ]; 2、 数据类型 数组名[ 行数 ][ 列数 ] = { {数据1，数据2 } ，{数据3，数据4 } }; 3、 数据类型 数组名[ 行数 ][ 列数 ] = { 数据1，数据2，数据3，数据4}; 4、 数据类型 数组名[ ][ 列数 ] = { 数据1，数据2，数据3，数据4}; 建议：以上4种定义方式，利用第二种更加直观，提高代码的可读性 示例： int main() { //方式1 //数组类型 数组名 [行数][列数] int arr[2][3]; arr[0][0] = 1; arr[0][1] = 2; arr[0][2] = 3; arr[1][0] = 4; arr[1][1] = 5; arr[1][2] = 6; for (int i = 0; i 总结：在定义二维数组时，如果初始化了数据，可以省略行数 5.3.2 二维数组数组名 查看二维数组所占内存空间 获取二维数组首地址 示例： int main() { //二维数组数组名 int arr[2][3] = { {1,2,3}, {4,5,6} }; cout 总结1：二维数组名就是这个数组的首地址 总结2：对二维数组名进行sizeof时，可以获取整个二维数组占用的内存空间大小 5.3.3 二维数组应用案例 考试成绩统计： 案例描述：有三名同学（张三，李四，王五），在一次考试中的成绩分别如下表，请分别输出三名同学的总成绩 语文 数学 英语 张三 100 100 100 李四 90 50 100 王五 60 70 80 参考答案： int main() { int scores[3][3] = { {100,100,100}, {90,50,100}, {60,70,80}, }; string names[3] = { \"张三\",\"李四\",\"王五\" }; for (int i = 0; i "},"C++/基础/06-函数.html":{"url":"C++/基础/06-函数.html","title":"函数","keywords":"","body":"datetime:2022/10/17 10:47 author:nzb 6、函数 6.1 概述 作用：将一段经常使用的代码封装起来，减少重复代码 一个较大的程序，一般分为若干个程序块，每个模块实现特定的功能。 6.2 函数的定义 函数的定义一般主要有5个步骤： 1、返回值类型 2、函数名 3、参数表列 4、函数体语句 5、return 表达式 语法： 返回值类型 函数名 （参数列表） { 函数体语句 return 表达式 } 返回值类型 ：一个函数可以返回一个值。在函数定义中 函数名：给函数起个名称 参数列表：使用该函数时，传入的数据 函数体语句：花括号内的代码，函数内需要执行的语句 return表达式： 和返回值类型挂钩，函数执行完后，返回相应的数据 示例：定义一个加法函数，实现两个数相加 //函数定义 int add(int num1, int num2) { int sum = num1 + num2; return sum; } 6.3 函数的调用 功能：使用定义好的函数 语法：函数名（参数） 示例： //函数定义 int add(int num1, int num2) //定义中的num1,num2称为形式参数，简称形参 { int sum = num1 + num2; return sum; } int main() { int a = 10; int b = 10; //调用add函数 int sum = add(a, b);//调用时的a，b称为实际参数，简称实参 cout 总结：函数定义里小括号内称为形参，函数调用时传入的参数称为实参 6.4 值传递 所谓值传递，就是函数调用时实参将数值传入给形参 值传递时，如果形参发生，并不会影响实参 示例： void swap(int num1, int num2) { cout 总结： 值传递时，形参是修饰不了实参的 6.5 函数的常见样式 常见的函数样式有4种 无参无返 有参无返 无参有返 有参有返 示例： //函数常见样式 //1、 无参无返 void test01() { //void a = 10; //无类型不可以创建变量,原因无法分配内存 cout 6.6 函数的声明 作用： 告诉编译器函数名称及如何调用函数。函数的实际主体可以单独定义。 函数的声明可以多次，但是函数的定义只能有一次 示例： //声明可以多次，定义只能一次 //声明 int max(int a, int b); int max(int a, int b); //定义 int max(int a, int b) { return a > b ? a : b; } int main() { int a = 100; int b = 200; cout 6.7 函数的分文件编写 作用：让代码结构更加清晰，函数分文件编写一般有4个步骤 创建后缀名为.h的头文件 创建后缀名为.cpp的源文件 在头文件中写函数的声明 在源文件中写函数的定义 示例： //swap.h文件 #include using namespace std; //实现两个数字交换的函数声明 void swap(int a, int b); //swap.cpp文件 #include \"swap.h\" void swap(int a, int b) { int temp = a; a = b; b = temp; cout //main函数文件 #include \"swap.h\" int main() { int a = 100; int b = 200; swap(a, b); system(\"pause\"); return 0; } "},"C++/基础/07-指针.html":{"url":"C++/基础/07-指针.html","title":"指针","keywords":"","body":"datetime:2022/10/17 14:48 author:nzb 7 指针 7.1 指针的基本概念 指针的作用： 可以通过指针间接访问内存 内存编号是从0开始记录的，一般用十六进制数字表示 可以利用指针变量保存地址 7.2 指针变量的定义和使用 指针变量定义语法： 数据类型 * 变量名； 示例： int main() { //1、指针的定义 int a = 10; //定义整型变量a //指针定义语法： 数据类型 * 变量名 ; int * p; //指针变量赋值 p = &a; //指针指向变量a的地址 cout 指针变量和普通变量的区别 普通变量存放的是数据,指针变量存放的是地址 指针变量可以通过*操作符，操作指针变量指向的内存空间，这个过程称为解引用 总结1： 我们可以通过 & 符号 获取变量的地址 总结2：利用指针可以记录地址 总结3：对指针变量解引用，可以操作指针指向的内存 7.3 指针所占内存空间 提问：指针也是种数据类型，那么这种数据类型占用多少内存空间？ 示例： int main() { int a = 10; int * p; p = &a; //指针指向数据a的地址 cout 总结：所有指针类型在32位操作系统下是4个字节 7.4 空指针和野指针 空指针：指针变量指向内存中编号为0的空间 用途：初始化指针变量 注意：空指针指向的内存是不可以访问的 示例1：空指针 int main() { //指针变量p指向内存地址编号为0的空间 int * p = NULL; //访问空指针报错 //内存编号0 ~255为系统占用内存，不允许用户访问 cout 野指针：指针变量指向非法的内存空间 示例2：野指针 int main() { //指针变量p指向内存地址编号为0x1100的空间 int * p = (int *)0x1100; //访问野指针报错 cout 总结：空指针和野指针都不是我们申请的空间，因此不要访问。 7.5 const修饰指针 const修饰指针有三种情况 const修饰指针 -> 常量指针 const修饰常量 -> 指针常量 const即修饰指针，又修饰常量 示例： int main() { int a = 10; int b = 10; //常量指针：const修饰的是指针，指针指向可以改，指针指向的值不可以更改 const int * p1 = &a; p1 = &b; //正确 //*p1 = 100; 报错 //指针常量：const修饰的是常量，指针指向不可以改，指针指向的值可以更改 int * const p2 = &a; //p2 = &b; //错误 *p2 = 100; //正确 //const既修饰指针又修饰常量 const int * const p3 = &a; //p3 = &b; //错误 //*p3 = 100; //错误 system(\"pause\"); return 0; } 技巧1：看const右侧紧跟着的是指针还是常量, 是指针就是常量指针，是常量就是指针常量 技巧2：const int * p1 = &a; const 修饰的是*，叫常量指针，const 后面跟的是 *，则取*不能做，即解引用错误（即不能：*p1 = 1） 技巧3：int * const p2 = &a; * 修饰的是const，叫指针常量，const 后面跟的是常量，则不能操作它（赋值）了（即不能：p2 = &b） 7.6 指针和数组 作用：利用指针访问数组中元素 示例： int main() { int arr[] = { 1,2,3,4,5,6,7,8,9,10 }; int * p = arr; //指向数组的指针 cout 7.7 指针和函数 作用：利用指针作函数参数，可以修改实参的值 示例： //值传递 void swap1(int a ,int b) { int temp = a; a = b; b = temp; } //地址传递 void swap2(int * p1, int *p2) { int temp = *p1; *p1 = *p2; *p2 = temp; } int main() { int a = 10; int b = 20; swap1(a, b); // 值传递不会改变实参 swap2(&a, &b); //地址传递会改变实参 cout 总结：如果不想修改实参，就用值传递，如果想修改实参，就用地址传递 7.8 指针、数组、函数 案例描述：封装一个函数，利用冒泡排序，实现对整型数组的升序排序 例如数组：int arr[10] = { 4,3,6,9,1,2,10,8,7,5 }; 示例： //冒泡排序函数 void bubbleSort(int * arr, int len) //int * arr 也可以写为int arr[] { for (int i = 0; i arr[j + 1]) { int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; } } } } //打印数组函数 void printArray(int arr[], int len) { for (int i = 0; i 总结：当数组名传入到函数作为参数时，被退化为指向首元素的指针 "},"C++/基础/08-结构体.html":{"url":"C++/基础/08-结构体.html","title":"结构体","keywords":"","body":"datetime:2022/10/17 15:30 author:nzb 8 结构体 8.1 结构体基本概念 结构体属于用户自定义的数据类型，允许用户存储不同的数据类型 8.2 结构体定义和使用 语法：struct 结构体名 { 结构体成员列表 }； 通过结构体创建变量的方式有三种： struct 结构体名 变量名 struct 结构体名 变量名 = { 成员1值 ， 成员2值...} 定义结构体时顺便创建变量 示例 //结构体定义 struct student { //成员列表 string name; //姓名 int age; //年龄 int score; //分数 }stu3; //结构体变量创建方式3 int main() { //结构体变量创建方式1 struct student stu1; //struct 关键字可以省略 stu1.name = \"张三\"; stu1.age = 18; stu1.score = 100; cout 总结1：定义结构体时的关键字是struct，不可省略 总结2：创建结构体变量时，关键字struct可以省略 总结3：结构体变量利用操作符 ''.'' 访问成员 8.3 结构体数组 作用：将自定义的结构体放入到数组中方便维护 语法：struct 结构体名 数组名[元素个数] = { {} , {} , ... {} } 示例 //结构体定义 struct student { //成员列表 string name; //姓名 int age; //年龄 int score; //分数 } int main() { //结构体数组 struct student arr[3]= { {\"张三\",18,80 }, {\"李四\",19,60 }, {\"王五\",20,70 } }; for (int i = 0; i 8.4 结构体指针 作用：通过指针访问结构体中的成员 利用操作符 ->可以通过结构体指针访问结构体属性 示例 //结构体定义 struct student { //成员列表 string name; //姓名 int age; //年龄 int score; //分数 }; int main() { struct student stu = { \"张三\",18,100, }; struct student * p = &stu; p->score = 80; //指针通过 -> 操作符可以访问成员 cout name age score 总结：结构体指针可以通过 -> 操作符 来访问结构体中的成员 8.5 结构体嵌套结构体 作用： 结构体中的成员可以是另一个结构体 例如：每个老师辅导一个学员，一个老师的结构体中，记录一个学生的结构体 示例 //学生结构体定义 struct student { //成员列表 string name; //姓名 int age; //年龄 int score; //分数 }; //教师结构体定义 struct teacher { //成员列表 int id; //职工编号 string name; //教师姓名 int age; //教师年龄 struct student stu; //子结构体 学生 }; int main() { struct teacher t1; t1.id = 10000; t1.name = \"老王\"; t1.age = 40; t1.stu.name = \"张三\"; t1.stu.age = 18; t1.stu.score = 100; cout 总结：在结构体中可以定义另一个结构体作为成员，用来解决实际问题 8.6 结构体做函数参数 作用：将结构体作为参数向函数中传递 传递方式有两种： 值传递 地址传递 示例： //学生结构体定义 struct student { //成员列表 string name; //姓名 int age; //年龄 int score; //分数 }; //值传递 void printStudent(student stu ) { stu.age = 28; cout age = 28; cout name age score 总结：如果不想修改主函数中的数据，用值传递，反之用地址传递 8.7 结构体中 const 使用场景 作用：用const来防止误操作 示例： //学生结构体定义 struct student { //成员列表 string name; //姓名 int age; //年龄 int score; //分数 }; //const使用场景 void printStudent(const student *stu) //加const防止函数体中的误操作 { //stu->age = 100; //操作失败，因为加了const修饰 cout name age score 8.8 结构体案例 8.8.1 案例1 案例描述： 学校正在做毕设项目，每名老师带领5个学生，总共有3名老师，需求如下 设计学生和老师的结构体，其中在老师的结构体中，有老师姓名和一个存放5名学生的数组作为成员 学生的成员有姓名、考试分数，创建数组存放3名老师，通过函数给每个老师及所带的学生赋值 最终打印出老师数据以及老师所带的学生数据。 示例 struct Student { string name; int score; }; struct Teacher { string name; Student sArray[5]; }; void allocateSpace(Teacher tArray[] , int len) { string tName = \"教师\"; string sName = \"学生\"; string nameSeed = \"ABCDE\"; for (int i = 0; i Teacher tArray[3]; //老师数组 int len = sizeof(tArray) / sizeof(Teacher); allocateSpace(tArray, len); //创建数据 printTeachers(tArray, len); //打印数据 system(\"pause\"); return 0; } 8.8.2 案例2 案例描述： 设计一个英雄的结构体，包括成员姓名，年龄，性别;创建结构体数组，数组中存放5名英雄。 通过冒泡排序的算法，将数组中的英雄按照年龄进行升序排序，最终打印排序后的结果。 五名英雄信息如下： {\"刘备\",23,\"男\"}, {\"关羽\",22,\"男\"}, {\"张飞\",20,\"男\"}, {\"赵云\",21,\"男\"}, {\"貂蝉\",19,\"女\"}, 示例 //英雄结构体 struct hero { string name; int age; string sex; }; //冒泡排序 void bubbleSort(hero arr[] , int len) { for (int i = 0; i arr[j + 1].age) { hero temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; } } } } //打印数组 void printHeros(hero arr[], int len) { for (int i = 0; i "},"C++/基础/09-内存分区模型.html":{"url":"C++/基础/09-内存分区模型.html","title":"内存分区模型","keywords":"","body":"datetime:2022/10/18 10:04 author:nzb 9、内存分区模型 C++程序在执行时，将内存大方向划分为4个区域 代码区：存放函数体的二进制代码，由操作系统进行管理的 全局区：存放全局变量和静态变量以及常量 栈区：由编译器自动分配释放, 存放函数的参数值,局部变量等 堆区：由程序员分配和释放,若程序员不释放,程序结束时由操作系统回收 内存四区意义： 不同区域存放的数据，赋予不同的生命周期, 给我们更大的灵活编程 9.1 程序运行前 在程序编译后，生成了exe可执行程序，未执行该程序前分为两个区域 代码区 存放 CPU 执行的机器指令 代码区是共享的，共享的目的是对于频繁被执行的程序，只需要在内存中有一份代码即可 代码区是只读的，使其只读的原因是防止程序意外地修改了它的指令 全局区 全局变量和静态变量存放在此. 全局区还包含了常量区, 字符串常量和其他常量也存放在此. 该区域的数据在程序结束后由操作系统释放 示例 //全局变量 int g_a = 10; int g_b = 10; //全局常量 const int c_g_a = 10; const int c_g_b = 10; int main() { //局部变量 int a = 10; int b = 10; //打印地址 cout 打印结果： 总结： C++中在程序运行前分为代码区和全局区 代码区特点是共享和只读 全局区中存放全局变量、常量、静态变量 常量区中存放 const修饰的全局常量 和 字符串常量 9.2 程序运行后 栈区 由编译器自动分配释放, 存放函数的参数值（形参），局部变量等 注意事项：不要返回局部变量的地址，栈区开辟的数据由编译器自动释放 示例 int * func() { int a = 10; // 局部变量 存放在栈区，栈区的数据在函数执行完后自动释放 return &a; // 返回局部变量的地址 } int main() { int * p = func(); cout 堆区 由程序员分配释放,若程序员不释放,程序结束时由操作系统回收 在C++中主要利用new在堆区开辟内存 示例 int * func() { // 利用`new`在堆区开辟内存 // 指针 本质也是局部变量，放在栈上，指针保存的数据是放在堆区 int * a = new int(10); return a; } int main() { int *p = func(); cout 总结 堆区数据由程序员管理开辟和释放 堆区数据利用new关键字进行开辟内存 9.3 new操作符 C++中利用new操作符在堆区开辟数据 堆区开辟的数据，由程序员手动开辟，手动释放，释放利用操作符delete 语法：new 数据类型，利用new创建的数据，会返回该数据对应的类型的指针 示例1： 基本语法 int * func() { int * a = new int(10); return a; } int main() { int * p = func(); cout 示例2：开辟数组 //堆区开辟数组 int main() { int * arr = new int[10]; for (int i = 0; i "},"C++/基础/10-引用.html":{"url":"C++/基础/10-引用.html","title":"引用","keywords":"","body":"datetime:2022/10/18 10:49 author:nzb 10、引用 10.1 引用的基本使用 作用： 给变量起别名 语法： 数据类型 &别名 = 原名 示例： int main() { int a = 10; int &b = a; cout 10.2 引用注意事项 引用必须初始化 引用在初始化后，不可以改变 示例： int main() { int a = 10; int b = 20; //int &c; //错误，引用必须初始化 int &c = a; //一旦初始化后，就不可以更改 c = b; //这是赋值操作，不是更改引用 cout 10.3 引用做函数参数 作用：函数传参时，可以利用引用的技术让形参修饰实参 优点：可以简化指针修改实参 示例： //1. 值传递 void mySwap01(int a, int b) { int temp = a; a = b; b = temp; } //2. 地址传递 void mySwap02(int *a, int *b) { int temp = *a; *a = *b; *b = temp; } //3. 引用传递 void mySwap03(int &a, int &b) { int temp = a; a = b; b = temp; } int main() { int a = 10; int b = 20; mySwap01(a, b); cout 总结：通过引用参数产生的效果同按地址传递是一样的。引用的语法更清楚简单 10.4 引用做函数返回值 作用：引用是可以作为函数的返回值存在的 注意：不要返回局部变量引用 用法：函数调用作为左值，如果函数的返回值是引用，这个函数调用可以作为左值 示例： //返回局部变量引用 int& test01() { int a = 10; //局部变量 return a; } //返回静态变量引用 int& test02() { static int a = 20; return a; } int main() { //不能返回局部变量的引用 int &ref = test01(); cout 10.5 引用的本质 本质：引用的本质在c++内部实现是一个指针常量 讲解示例： //发现是引用，转换为 int* const ref = &a; void func(int& ref){ ref = 100; // ref是引用，转换为*ref = 100 } int main(){ int a = 10; //自动转换为 int* const ref = &a; 指针常量是指针指向不可改，也说明为什么引用不可更改 int& ref = a; ref = 20; //内部发现ref是引用，自动帮我们转换为: *ref = 20; cout 结论：C++推荐用引用技术，因为语法方便，引用本质是指针常量，但是所有的指针操作编译器都帮我们做了 10.6 常量引用 作用：常量引用主要用来修饰形参，防止误操作 在函数形参列表中，可以加const修饰形参，防止形参改变实参 示例： //引用使用的场景，通常用来修饰形参 void showValue(const int& v) { //v += 10; cout "},"C++/基础/11-函数进阶.html":{"url":"C++/基础/11-函数进阶.html","title":"函数进阶","keywords":"","body":"datetime:2022/10/19 10:00 author:nzb 11、函数提高 11.1 函数默认参数 在C++中，函数的形参列表中的形参是可以有默认值的。 语法：返回值类型 函数名 （参数= 默认值）{} 示例 int func(int a, int b = 10, int c = 10) { return a + b + c; } //1. 如果某个位置参数有默认值，那么从这个位置往后，从左向右，必须都要有默认值 //2. 如果函数声明有默认值，函数实现的时候就不能有默认参数 int func2(int a = 10, int b = 10); int func2(int a, int b) { return a + b; } int main() { cout 11.2 函数占位参数 C++中函数的形参列表里可以有占位参数，用来做占位，调用函数时必须填补该位置 语法：返回值类型 函数名 (数据类型){} 在现阶段函数的占位参数存在意义不大，但是后面会用到该技术 示例 //函数占位参数 ，占位参数也可以有默认参数 void func(int a, int) { cout 11.3 函数重载 11.3.1 函数重载概述 作用：函数名可以相同，提高复用性 函数重载满足条件 同一个作用域下 函数名称相同 函数参数类型不同或者个数不同或者顺序不同 注意: 函数的返回值不可以作为函数重载的条件 示例 //函数重载需要函数都在同一个作用域下 void func() { cout 11.3.2 函数重载注意事项 可以把引用作为重载条件 函数重载碰到函数默认参数（尽量避免） 示例 //函数重载注意事项 //1、引用作为重载条件 // 直接传10，形参接受实参，相当于 int &a = 10 // int &a 引用需要一个合法的内存空间，要么在栈区，要么在堆区，这个10是在常量区（全局区），所以不合法 void func(int &a) { cout "},"C++/基础/12-类和对象.html":{"url":"C++/基础/12-类和对象.html","title":"类和对象","keywords":"","body":"datetime:2022/10/19 10:26 author:nzb 12、 类和对象 C++面向对象的三大特性为：封装、继承、多态 C++认为万事万物都皆为对象，对象上有其属性和行为 例如 人可以作为对象，属性有姓名、年龄、身高、体重...，行为有走、跑、跳、吃饭、唱歌... 车也可以作为对象，属性有轮胎、方向盘、车灯...,行为有载人、放音乐、放空调... 具有相同性质的对象，我们可以抽象称为类，人属于人类，车属于车类 12.1 封装 12.1.1 封装的意义 封装是C++面向对象三大特性之一 封装的意义： 将属性和行为作为一个整体，表现生活中的事物 将属性和行为加以权限控制 语法：class 类名{ 访问权限： 属性 / 行为 }; 封装意义一：在设计类的时候，属性和行为写在一起，表现事物 示例1：设计一个圆类，求圆的周长 //圆周率 const double PI = 3.14; //1、封装的意义 //将属性和行为作为一个整体，用来表现生活中的事物 //封装一个圆类，求圆的周长 //class代表设计一个类，后面跟着的是类名 class Circle { public: //访问权限 公共的权限 //属性 int m_r;//半径 //行为 //获取到圆的周长 double calculateZC() { //2 * pi * r //获取圆的周长 return 2 * PI * m_r; } }; int main() { //通过圆类，创建圆的对象 // c1就是一个具体的圆 Circle c1; c1.m_r = 10; //给圆对象的半径 进行赋值操作 //2 * pi * 10 = = 62.8 cout 示例2：设计一个学生类，属性有姓名和学号，可以给姓名和学号赋值，可以显示学生的姓名和学号 //学生类 class Student { public: void setName(string name) { m_name = name; } void setID(int id) { m_id = id; } void showStudent() { cout 封装意义二：类在设计时，可以把属性和行为放在不同的权限下，加以控制 访问权限有三种： public 公共权限 protected 保护权限 private 私有权限 示例 //三种权限 //公共权限 public 类内可以访问 类外可以访问 //保护权限 protected 类内可以访问 类外不可以访问 //私有权限 private 类内可以访问 类外不可以访问 class Person { //姓名 公共权限 public: string m_Name; //汽车 保护权限 protected: string m_Car; //银行卡密码 私有权限 private: int m_Password; public: void func() { m_Name = \"张三\"; m_Car = \"拖拉机\"; m_Password = 123456; } }; int main() { Person p; p.m_Name = \"李四\"; //p.m_Car = \"奔驰\"; //保护权限类外访问不到 //p.m_Password = 123; //私有权限类外访问不到 system(\"pause\"); return 0; } 12.1.2 struct和class区别 在C++中 struct和class唯一的区别就在于默认的访问权限不同 区别： struct 默认权限为公共 class 默认权限为私有 class C1 { int m_A; //默认是私有权限 }; struct C2 { int m_A; //默认是公共权限 }; int main() { C1 c1; c1.m_A = 10; //错误，访问权限是私有 C2 c2; c2.m_A = 10; //正确，访问权限是公共 system(\"pause\"); return 0; } 12.1.3 成员属性设置为私有 优点1：将所有成员属性设置为私有，可以自己控制读写权限 优点2：对于写权限，我们可以检测数据的有效性 示例 class Person { public: //姓名设置可读可写 void setName(string name) { m_Name = name; } string getName() { return m_Name; } //获取年龄 int getAge() { return m_Age; } //设置年龄 void setAge(int age) { if (age 150) { cout 练习案例1：设计立方体类 设计立方体类(Cube) 求出立方体的面积和体积 分别用全局函数和成员函数判断两个立方体是否相等。 练习案例2：点和圆的关系 设计一个圆形类（Circle），和一个点类（Point），计算点和圆的关系。 12.2 对象的初始化和清理 生活中我们买的电子产品都基本会有出厂设置，在某一天我们不用时候也会删除一些自己信息数据保证安全 C++中的面向对象来源于生活，每个对象也都会有初始设置以及 对象销毁前的清理数据的设置。 12.2.1 构造函数和析构函数 对象的初始化和清理也是两个非常重要的安全问题 一个对象或者变量没有初始状态，对其使用后果是未知 同样的使用完一个对象或变量，没有及时清理，也会造成一定的安全问题 c++利用了构造函数和析构函数解决上述问题，这两个函数将会被编译器自动调用，完成对象初始化和清理工作。 对象的初始化和清理工作是编译器强制要我们做的事情，因此如果我们不提供构造和析构，编译器会提供 编译器提供的构造函数和析构函数是空实现。 构造函数：主要作用在于创建对象时为对象的成员属性赋值，构造函数由编译器自动调用，无须手动调用。 析构函数：主要作用在于对象销毁前系统自动调用，执行一些清理工作。 构造函数语法：类名(){} 构造函数，没有返回值也不写void 函数名称与类名相同 构造函数可以有参数，因此可以发生重载 程序在调用对象时候会自动调用构造，无须手动调用,而且只会调用一次 析构函数语法：~类名(){} 析构函数，没有返回值也不写void 函数名称与类名相同,在名称前加上符号 ~ 析构函数不可以有参数，因此不可以发生重载 程序在对象销毁前会自动调用析构，无须手动调用,而且只会调用一次 class Person { public: //构造函数 Person() { cout 12.2.2 构造函数的分类及调用 两种分类方式： 按参数分为： 有参构造和无参构造 按类型分为： 普通构造和拷贝构造 三种调用方式： 括号法 显示法 隐式转换法 示例 //1、构造函数分类 // 按照参数分类分为 有参和无参构造 无参又称为默认构造函数 // 按照类型分类分为 普通构造和拷贝构造 class Person { public: //无参（默认）构造函数 Person() { cout 12.2.3 拷贝构造函数调用时机 C++中拷贝构造函数调用时机通常有三种情况 使用一个已经创建完毕的对象来初始化一个新对象 值传递的方式给函数参数传值 以值方式返回局部对象 示例 class Person { public: Person() { cout 12.2.4 构造函数调用规则 默认情况下，c++编译器至少给一个类添加3个函数 1．默认构造函数(无参，函数体为空) 2．默认析构函数(无参，函数体为空) 3．默认拷贝构造函数，对属性进行值拷贝 构造函数调用规则如下： 如果用户定义有参构造函数，c++不在提供默认无参构造，但是会提供默认拷贝构造 如果用户定义拷贝构造函数，c++不会再提供其他构造函数 示例： class Person { public: //无参（默认）构造函数 Person() { cout 4.2.5 深拷贝与浅拷贝 深浅拷贝是面试经典问题，也是常见的一个坑 浅拷贝：简单的赋值拷贝操作 深拷贝：在堆区重新申请空间，进行拷贝操作 示例： class Person { public: //无参（默认）构造函数 Person() { cout 总结：如果属性有在堆区开辟的，一定要自己提供拷贝构造函数，防止浅拷贝带来的问题 12.2.6 初始化列表 作用：C++提供了初始化列表语法，用来初始化属性 语法：构造函数()：属性1(值1),属性2（值2）... {} 示例 class Person { public: ////传统方式初始化 //Person(int a, int b, int c) { // m_A = a; // m_B = b; // m_C = c; //} //初始化列表方式初始化 Person(int a, int b, int c) :m_A(a), m_B(b), m_C(c) {} void PrintPerson() { cout 12.2.7 类对象作为类成员 C++类中的成员可以是另一个类的对象，我们称该成员为对象成员 例如： class A {} class B { A a； } B类中有对象A作为成员，A为对象成员 那么当创建B对象时，A与B的构造和析构的顺序是谁先谁后？ 示例 class Phone { public: Phone(string name) { m_PhoneName = name; cout 12.2.8 静态成员 静态成员就是在成员变量和成员函数前加上关键字static，称为静态成员 静态成员分为： 静态成员变量 所有对象共享同一份数据 在编译阶段分配内存 类内声明，类外初始化 静态成员函数 所有对象共享同一个函数 静态成员函数只能访问静态成员变量 示例1 ：静态成员变量 class Person { public: static int m_A; //静态成员变量，类内声明 //静态成员变量特点： //1 在编译阶段分配内存 //2 类内声明，类外初始化 //3 所有对象共享同一份数据 private: static int m_B; //静态成员变量也是有访问权限的 }; int Person::m_A = 10; // 类外初始化 int Person::m_B = 10; // 类外初始化 void test01() { //静态成员变量两种访问方式 //1、通过对象 Person p1; p1.m_A = 100; cout 示例2：静态成员函数 class Person { public: //静态成员函数特点： //1 程序共享一个函数 //2 静态成员函数只能访问静态成员变量 static void func() { cout 12.3 C++对象模型和this指针 12.3.1 成员变量和成员函数分开存储 在C++中，类内的成员变量和成员函数分开存储 只有非静态成员变量才属于类的对象上 class Person { public: Person() { mA = 0; } //非静态成员变量占对象空间，属于类的对象上 int mA; //静态成员变量不占对象空间，不属于类的对象上 static int mB; //非静态成员函数也不占对象空间，所有函数共享一个函数实例 void func() { cout mA 12.3.2 this指针概念 通过12.3.1我们知道在C++中成员变量和成员函数是分开存储的 每一个非静态成员函数只会诞生一份函数实例，也就是说多个同类型的对象会共用一块代码 那么问题是：这一块代码是如何区分那个对象调用自己的呢？ c++通过提供特殊的对象指针，this指针，解决上述问题。this指针指向被调用的成员函数所属的对象 this指针是隐含每一个非静态成员函数内的一种指针 this指针不需要定义，直接使用即可 this指针的用途： 当形参和成员变量同名时，可用this指针来区分 在类的非静态成员函数中返回对象本身，可使用return *this class Person { public: Person(int age) { //1、当形参和成员变量同名时，可用this指针来区分 this->age = age; } // 引用返回，如果不是就会浅拷贝，导致拷贝一个对象 Person& PersonAddPerson(Person p) { this->age += p.age; //返回对象本身 // this 指向p2的指针，而*this指向就是这个对象本体 return *this; } int age; }; void test01() { Person p1(10); cout 12.3.3 空指针访问成员函数 C++中空指针也是可以调用成员函数的，但是也要注意有没有用到this指针 如果用到this指针，需要加以判断保证代码的健壮性 示例 //空指针访问成员函数 class Person { public: void ShowClassName() { cout mAge } public: int mAge; }; void test01() { Person * p = NULL; p->ShowClassName(); //空指针，可以调用成员函数 p->ShowPerson(); //但是如果成员函数中用到了this指针，就不可以了 } int main() { test01(); system(\"pause\"); return 0; } 12.3.4 const修饰成员函数 常函数： 成员函数后加const后我们称为这个函数为常函数 常函数内不可以修改成员属性 成员属性声明时加关键字mutable后，在常函数中依然可以修改 常对象： 声明对象前加const称该对象为常对象 常对象只能调用常函数 示例 class Person { public: Person() { m_A = 0; m_B = 0; } //this指针的本质是一个指针常量，指针的指向不可修改 //如果想让指针指向的值也不可以修改，需要声明常函数 void ShowPerson() const { //const Type* const pointer; //this = NULL; //不能修改指针的指向 Person * const this; //this->mA = 100; //但是this指针指向的对象的数据是可以修改的 //const修饰成员函数，表示指针指向的内存空间的数据不能修改，除了mutable修饰的变量, 即 const Person * const this; this->m_B = 100; } void MyFunc() const { //mA = 10000; } public: int m_A; mutable int m_B; //可修改 可变的 }; //const修饰对象 常对象 void test01() { const Person person; //在对象前面加const, 变成常量对象 cout 12.4 友元 生活中你的家有客厅(Public)，有你的卧室(Private) 客厅所有来的客人都可以进去，但是你的卧室是私有的，也就是说只有你能进去 但是呢，你也可以允许你的好闺蜜好基友进去。 在程序里，有些私有属性 也想让类外特殊的一些函数或者类进行访问，就需要用到友元的技术 友元的目的就是让一个函数或者类 访问另一个类中私有成员 友元的关键字为friend 友元的三种实现 全局函数做友元 类做友元 成员函数做友元 12.4.1 全局函数做友元 class Building { //告诉编译器 goodGay全局函数 是 Building类的好朋友，可以访问类中的私有内容 friend void goodGay(Building * building); public: Building() { this->m_SittingRoom = \"客厅\"; this->m_BedRoom = \"卧室\"; } public: string m_SittingRoom; //客厅 private: string m_BedRoom; //卧室 }; void goodGay(Building * building) { cout m_SittingRoom m_BedRoom 12.4.2 类做友元 class Building; // 预先声明类，告诉编译器等下不要报错 class goodGay { public: goodGay(); // 构造函数 void visit(); private: Building *building; }; class Building { //告诉编译器 goodGay类是Building类的好朋友，可以访问到Building类中私有内容 friend class goodGay; public: Building(); // 构造函数 public: string m_SittingRoom; //客厅 private: string m_BedRoom;//卧室 }; // 类外写成员函数 Building::Building() { this->m_SittingRoom = \"客厅\"; this->m_BedRoom = \"卧室\"; } // 类外写成员函数 goodGay::goodGay() { building = new Building; } void goodGay::visit() { cout m_SittingRoom m_BedRoom 12.4.3 成员函数做友元 class Building; class goodGay { public: goodGay(); void visit(); //只让visit函数作为Building的好朋友，可以发访问Building中私有内容 void visit2(); private: Building *building; }; class Building { //告诉编译器 goodGay类中的visit成员函数 是Building好朋友，可以访问私有内容 friend void goodGay::visit(); public: Building(); public: string m_SittingRoom; //客厅 private: string m_BedRoom;//卧室 }; // 类外实现成员函数 Building::Building() { this->m_SittingRoom = \"客厅\"; this->m_BedRoom = \"卧室\"; } goodGay::goodGay() { building = new Building; } void goodGay::visit() { cout m_SittingRoom m_BedRoom m_SittingRoom m_BedRoom 12.5 运算符重载 运算符重载概念：对已有的运算符重新进行定义，赋予其另一种功能，以适应不同的数据类型 12.5.1 加号运算符重载 作用：实现两个自定义数据类型相加的运算 class Person { public: Person() {}; Person(int a, int b) { this->m_A = a; this->m_B = b; } //1、成员函数实现 + 号运算符重载 Person operator+(const Person& p) { Person temp; temp.m_A = this->m_A + p.m_A; temp.m_B = this->m_B + p.m_B; return temp; } public: int m_A; int m_B; }; //2、全局函数实现 + 号运算符重载 //Person operator+(const Person &p1, const Person &p2) { // Person temp(0, 0); // temp.m_A = p1.m_A + p2.m_A; // temp.m_B = p1.m_B + p2.m_B; // return temp; //} //运算符重载 可以发生函数重载 Person operator+(const Person &p2, int val) { Person temp; temp.m_A = p2.m_A + val; temp.m_B = p2.m_B + val; return temp; } void test() { Person p1(10, 10); Person p2(20, 20); //成员函数方式 Person p3 = p2 + p1; //相当于 p2.operaor+(p1) cout 总结1：对于内置的数据类型的表达式的的运算符是不可能改变的 总结2：不要滥用运算符重载 12.5.2 左移运算符重载 作用：可以输出自定义数据类型 class Person { friend ostream & operatorm_A = a; this->m_B = b; } //成员函数 实现不了 p 总结：重载左移运算符配合友元可以实现输出自定义数据类型 12.5.3 递增运算符重载 作用： 通过重载递增运算符，实现自己的整型数据 class MyInteger { friend ostream & operator 总结： 前置递增返回引用，后置递增返回值 12.5.4 赋值运算符重载 c++编译器至少给一个类添加4个函数 默认构造函数(无参，函数体为空) 默认析构函数(无参，函数体为空) 默认拷贝构造函数，对属性进行值拷贝 赋值运算符 operator=, 对属性进行值拷贝 如果类中有属性指向堆区，做赋值操作时也会出现深浅拷贝问题 示例 class Person { public: Person(int age) { //将年龄数据开辟到堆区 m_Age = new int(age); } //重载赋值运算符 Person & operator=(Person &p) { // 先判断是否有属性在堆区，如果有先释放干净，然后再深拷贝 if (m_Age != NULL) { delete m_Age; m_Age = NULL; } //编译器提供的代码是浅拷贝 //m_Age = p.m_Age; //提供深拷贝 解决浅拷贝的问题 m_Age = new int(*p.m_Age); //返回自身 return *this; } ~Person() { if (m_Age != NULL) { delete m_Age; m_Age = NULL; } } //年龄的指针 int *m_Age; }; void test01() { Person p1(18); Person p2(20); Person p3(30); p3 = p2 = p1; //赋值操作，默认浅拷贝，链式编程 cout 12.5.5 关系运算符重载 作用：重载关系运算符，可以让两个自定义类型对象进行对比操作 示例 class Person { public: Person(string name, int age) { this->m_Name = name; this->m_Age = age; }; bool operator==(Person &p) { if (this->m_Name == p.m_Name && this->m_Age == p.m_Age) { return true; } else { return false; } } bool operator!=(Person &p) { if (this->m_Name == p.m_Name && this->m_Age == p.m_Age) { return false; } else { return true; } } string m_Name; int m_Age; }; void test01() { //int a = 0; //int b = 0; Person a(\"孙悟空\", 18); Person b(\"孙悟空\", 18); if (a == b) { cout 12.5.6 函数调用运算符重载 函数调用运算符 () 也可以重载 由于重载后使用的方式非常像函数的调用，因此称为仿函数 仿函数没有固定写法，非常灵活 示例 class MyPrint { public: void operator()(string text) { cout 12.6 继承 继承是面向对象三大特性之一 有些类与类之间存在特殊的关系，例如下图中： 我们发现，定义这些类时，下级别的成员除了拥有上一级的共性，还有自己的特性。 这个时候我们就可以考虑利用继承的技术，减少重复代码 12.6.1 继承的基本语法 例如我们看到很多网站中，都有公共的头部，公共的底部，甚至公共的左侧列表，只有中心内容不同 接下来我们分别利用普通写法和继承的写法来实现网页中的内容，看一下继承存在的意义以及好处 普通实现 //Java页面 class Java { public: void header() { cout 继承实现 //公共页面 class BasePage { public: void header() { cout 总结 继承的好处：可以减少重复的代码 class A : public B; A 类称为子类 或 派生类 B 类称为父类 或 基类 派生类中的成员，包含两大部分： 一类是从基类继承过来的，一类是自己增加的成员。 从基类继承过过来的表现其共性，而新增的成员体现了其个性。 12.6.2 继承方式 继承的语法：class 子类 : 继承方式 父类 继承方式一共有三种： 公共继承：父类公共和保护属性，子类也是一样公共和保护属性，父类私有属性，子类不可访问 保护继承：父类公共和保护属性，子类变成保护属性，父类私有属性，子类不可访问 私有继承：父类公共和保护属性，子类变成私有属性，父类私有属性，子类不可访问 示例 class Base1 { public: int m_A; protected: int m_B; private: int m_C; }; //公共继承 class Son1 :public Base1 { public: void func() { m_A; //可访问 public权限 m_B; //可访问 protected权限（保护权限类外不可访问） //m_C; //不可访问 } }; void myClass() { Son1 s1; s1.m_A; //其他类只能访问到公共权限 // s1.m_B; //保护权限类外不可访问 } //保护继承 class Base2 { public: int m_A; protected: int m_B; private: int m_C; }; class Son2:protected Base2 { public: void func() { m_A; //可访问 protected权限 m_B; //可访问 protected权限 //m_C; //不可访问 } }; void myClass2() { Son2 s; //s.m_A; //不可访问（保护权限类外不可访问） } //私有继承 class Base3 { public: int m_A; protected: int m_B; private: int m_C; }; class Son3:private Base3 { public: void func() { m_A; //可访问 private权限 m_B; //可访问 private权限 //m_C; //不可访问 } }; class GrandSon3 :public Son3 { public: void func() { //Son3是私有继承，所以继承Son3的属性在GrandSon3中都无法访问到（因为私有属性都是不可访问的） //m_A; //m_B; //m_C; } }; 12.6.3 继承中的对象模型 问题：从父类继承过来的成员，哪些属于子类对象中？ 示例 class Base { public: int m_A; protected: int m_B; private: int m_C; //私有成员只是被隐藏了，但是还是会继承下去 }; //公共继承 class Son :public Base { public: int m_D; }; void test01() { // 父类中所有非静态成员属性都会被子类继承下去 // 父类中私有成员属性是被编译器给隐藏了，因此是访问不到，但是确实被继承下去了 cout 利用工具查看： 打开工具窗口后，定位到当前CPP文件的盘符 然后输入： cl /d1 reportSingleClassLayout查看的类名 所属文件名 效果如下图： 结论： 父类中私有成员也是被子类继承下去了，只是由编译器给隐藏后访问不到 12.6.4 继承中构造和析构顺序 子类继承父类后，当创建子类对象，也会调用父类的构造函数 问题：父类和子类的构造和析构顺序是谁先谁后？ 示例： class Base { public: Base() { cout 总结：继承中 先调用父类构造函数，再调用子类构造函数，析构顺序与构造相反 12.6.5 继承同名成员处理方式 问题：当子类与父类出现同名的成员，如何通过子类对象，访问到子类或父类中同名的数据呢？ 访问子类同名成员 直接访问即可 访问父类同名成员 需要加作用域 示例 class Base { public: Base() { m_A = 100; } void func() { cout 总结： 子类对象可以直接访问到子类中同名成员 子类对象加作用域可以访问到父类同名成员 当子类与父类拥有同名的成员函数，子类会隐藏父类中同名成员函数，加作用域可以访问到父类中同名函数 12.6.6 继承同名静态成员处理方式 问题：继承中同名的静态成员在子类对象上如何进行访问？ 静态成员和非静态成员出现同名，处理方式一致 访问子类同名成员 直接访问即可 访问父类同名成员 需要加作用域 示例 class Base { public: static void func() { cout 总结：同名静态成员处理方式和非静态处理方式一样，只不过有两种访问的方式（通过对象 和 通过类名） 12.6.7 多继承语法 C++允许一个类继承多个类 语法：class 子类 ：继承方式 父类1 ， 继承方式 父类2... 多继承可能会引发父类中有同名成员出现，需要加作用域区分 C++实际开发中不建议用多继承 示例 class Base1 { public: Base1() { m_A = 100; } public: int m_A; }; class Base2 { public: Base2() { m_A = 200; //开始是m_B 不会出问题，但是改为mA就会出现不明确 } public: int m_A; }; //语法：class 子类：继承方式 父类1 ，继承方式 父类2 class Son : public Base2, public Base1 { public: Son() { m_C = 300; m_D = 400; } public: int m_C; int m_D; }; //多继承容易产生成员同名的情况 //通过使用类名作用域可以区分调用哪一个基类的成员 void test01() { Son s; cout 总结： 多继承中如果父类中出现了同名情况，子类使用时候要加作用域 12.6.8 菱形继承 菱形继承概念： 两个派生类继承同一个基类 又有某个类同时继承者两个派生类 这种继承被称为菱形继承，或者钻石继承 典型的菱形继承案例 菱形继承问题 羊继承了动物的数据，驼同样继承了动物的数据，当草泥马使用数据时，就会产生二义性。 草泥马继承自动物的数据继承了两份，其实我们应该清楚，这份数据我们只需要一份就可以。 示例 class Animal { public: int m_Age; }; //继承前加virtual关键字后，变为虚继承 //此时公共的父类Animal称为虚基类 class Sheep : virtual public Animal {}; class Tuo : virtual public Animal {}; class SheepTuo : public Sheep, public Tuo {}; void test01() { SheepTuo st; st.Sheep::m_Age = 100; st.Tuo::m_Age = 200; cout 总结： 菱形继承带来的主要问题是子类继承两份相同的数据，导致资源浪费以及毫无意义 利用虚继承可以解决菱形继承问题 12.7 多态 12.7.1 多态的基本概念 多态是C++面向对象三大特性之一 多态分为两类 静态多态: 函数重载 和 运算符重载属于静态多态，复用函数名 动态多态: 派生类和虚函数实现运行时多态 静态多态和动态多态区别： 静态多态的函数地址早绑定 - 编译阶段确定函数地址 动态多态的函数地址晚绑定 - 运行阶段确定函数地址 下面通过案例进行讲解多态 class Animal { public: //Speak函数就是虚函数 //函数前面加上virtual关键字，变成虚函数，那么编译器在编译的时候就不能确定函数调用了。 virtual void speak() { cout 总结： 多态满足条件 有继承关系 子类重写父类中的虚函数 多态使用条件 父类指针或引用指向子类对象，Animal & animal = cat; 重写：函数返回值类型 函数名 参数列表 完全一致称为重写 12.7.2 多态案例一-计算器类 案例描述： 分别利用普通写法和多态技术，设计实现两个操作数进行运算的计算器类 多态的优点： 代码组织结构清晰 可读性强 利于前期和后期的扩展以及维护 示例 //普通实现 class Calculator { public: int getResult(string oper) { if (oper == \"+\") { return m_Num1 + m_Num2; } else if (oper == \"-\") { return m_Num1 - m_Num2; } else if (oper == \"*\") { return m_Num1 * m_Num2; } //如果要提供新的运算，需要修改源码 } public: int m_Num1; int m_Num2; }; void test01() { //普通实现测试 Calculator c; c.m_Num1 = 10; c.m_Num2 = 10; cout m_Num1 = 10; abc->m_Num2 = 10; cout m_Num1 m_Num2 getResult() m_Num1 = 10; abc->m_Num2 = 10; cout m_Num1 m_Num2 getResult() m_Num1 = 10; abc->m_Num2 = 10; cout m_Num1 m_Num2 getResult() 总结：C++开发提倡利用多态设计程序架构，因为多态优点很多 12.7.3 纯虚函数和抽象类 在多态中，通常父类中虚函数的实现是毫无意义的，主要都是调用子类重写的内容 因此可以将虚函数改为纯虚函数 纯虚函数语法：virtual 返回值类型 函数名 （参数列表）= 0 ; 当类中有了纯虚函数，这个类也称为抽象类 抽象类特点： 无法实例化对象 子类必须重写抽象类中的纯虚函数，否则也属于抽象类 示例： class Base { public: //纯虚函数 //类中只要有一个纯虚函数就称为抽象类 //抽象类无法实例化对象 //子类必须重写父类中的纯虚函数，否则也属于抽象类 virtual void func() = 0; }; class Son :public Base { public: virtual void func() { cout func(); delete base;//记得销毁 } int main() { test01(); system(\"pause\"); return 0; } 12.7.4 多态案例二-制作饮品 案例描述 制作饮品的大致流程为：煮水 - 冲泡 - 倒入杯中 - 加入辅料 利用多态技术实现本案例，提供抽象制作饮品基类，提供子类制作咖啡和茶叶 示例 //抽象制作饮品 class AbstractDrinking { public: //烧水 virtual void Boil() = 0; //冲泡 virtual void Brew() = 0; //倒入杯中 virtual void PourInCup() = 0; //加入辅料 virtual void PutSomething() = 0; //规定流程 void MakeDrink() { Boil(); Brew(); PourInCup(); PutSomething(); } }; //制作咖啡 class Coffee : public AbstractDrinking { public: //烧水 virtual void Boil() { cout MakeDrink(); delete drink; } void test01() { DoWork(new Coffee); cout 12.7.5 虚析构和纯虚析构 多态使用时，如果子类中有属性开辟到堆区，那么父类指针在释放时无法调用到子类的析构代码 解决方式：将父类中的析构函数改为虚析构或者纯虚析构 虚析构和纯虚析构共性： 可以解决父类指针释放子类对象 都需要有具体的函数实现 虚析构和纯虚析构区别： 如果是纯虚析构，该类属于抽象类，无法实例化对象 虚析构语法：virtual ~类名(){} 纯虚析构语法： virtual ~类名() = 0; 类名::~类名(){} 示例 class Animal { public: Animal() { cout m_Name != NULL) { delete m_Name; m_Name = NULL; } } public: string *m_Name; }; void test01() { Animal *animal = new Cat(\"Tom\"); animal->Speak(); //通过父类指针去释放，会导致子类对象可能清理不干净，造成内存泄漏 //怎么解决？给基类增加一个虚析构函数 //虚析构函数就是用来解决通过父类指针释放子类对象 delete animal; } int main() { test01(); system(\"pause\"); return 0; } 总结： 虚析构或纯虚析构就是用来解决通过父类指针释放子类对象 如果子类中没有堆区数据，可以不写为虚析构或纯虚析构 拥有纯虚析构函数的类也属于抽象类 12.7.6 多态案例三-电脑组装 案例描述： 电脑主要组成部件为 CPU（用于计算），显卡（用于显示），内存条（用于存储） 将每个零件封装出抽象基类，并且提供不同的厂商生产不同的零件，例如Intel厂商和Lenovo厂商 创建电脑类提供让电脑工作的函数，并且调用每个零件工作的接口 测试时组装三台不同的电脑进行工作 示例 #include using namespace std; //抽象CPU类 class CPU { public: //抽象的计算函数 virtual void calculate() = 0; }; //抽象显卡类 class VideoCard { public: //抽象的显示函数 virtual void display() = 0; }; //抽象内存条类 class Memory { public: //抽象的存储函数 virtual void storage() = 0; }; //电脑类 class Computer { public: Computer(CPU * cpu, VideoCard * vc, Memory * mem) { m_cpu = cpu; m_vc = vc; m_mem = mem; } //提供工作的函数 void work() { //让零件工作起来，调用接口 m_cpu->calculate(); m_vc->display(); m_mem->storage(); } //提供析构函数 释放3个电脑零件 ~Computer() { //释放CPU零件 if (m_cpu != NULL) { delete m_cpu; m_cpu = NULL; } //释放显卡零件 if (m_vc != NULL) { delete m_vc; m_vc = NULL; } //释放内存条零件 if (m_mem != NULL) { delete m_mem; m_mem = NULL; } } private: CPU * m_cpu; //CPU的零件指针 VideoCard * m_vc; //显卡零件指针 Memory * m_mem; //内存条零件指针 }; //具体厂商 //Intel厂商 class IntelCPU :public CPU { public: virtual void calculate() { cout work(); delete computer1; cout work(); delete computer2; cout work(); delete computer3; } "},"C++/基础/13-文件操作.html":{"url":"C++/基础/13-文件操作.html","title":"文件操作","keywords":"","body":"datetime:2022/10/25 15:02 author:nzb 13、文件操作 程序运行时产生的数据都属于临时数据，程序一旦运行结束都会被释放 通过文件可以将数据持久化 C++中对文件操作需要包含头文件 文件类型分为两种： 文本文件：文件以文本的ASCII码形式存储在计算机中 二进制文件：文件以文本的二进制形式存储在计算机中，用户一般不能直接读懂它们 操作文件的三大类: ofstream：写操作 ifstream： 读操作 fstream ： 读写操作 13.1文本文件 13.1.1写文件 写文件步骤如下： 包含头文件 #include 创建流对象 ofstream ofs; 打开文件 ofs.open(\"文件路径\",打开方式); 写数据 ofs 关闭文件 ofs.close(); 文件打开方式： 打开方式 解释 ios::in 为读文件而打开文件 ios::out 为写文件而打开文件 ios::ate 初始位置：文件尾 ios::app 追加方式写文件 ios::trunc 如果文件存在先删除，再创建 ios::binary 二进制方式 注意： 文件打开方式可以配合使用，利用|操作符 例如：用二进制方式写文件 ios::binary | ios:: out 示例 #include void test01() { ofstream ofs; ofs.open(\"test.txt\", ios::out); ofs 总结： 文件操作必须包含头文件 fstream 读文件可以利用 ofstream ，或者fstream类 打开文件时候需要指定操作文件的路径，以及打开方式 利用 操作完毕，要关闭文件 13.1.2读文件 读文件与写文件步骤相似，但是读取方式相对于比较多 读文件步骤如下： 包含头文件 #include 创建流对象 ifstream ifs; 打开文件并判断文件是否打开成功 ifs.open(\"文件路径\",打开方式); 读数据 四种方式读取 关闭文件 ifs.close(); 示例： #include #include void test01() { ifstream ifs; ifs.open(\"test.txt\", ios::in); if (!ifs.is_open()) { cout > buf) //{ // cout 总结： 读文件可以利用 ifstream ，或者fstream类 利用is_open函数可以判断文件是否打开成功 close 关闭文件 13.2 二进制文件 以二进制的方式对文件进行读写操作 打开方式要指定为 ios::binary 13.2.1 写文件 二进制方式写文件主要利用流对象调用成员函数write 函数原型 ：ostream& write(const char * buffer,int len); 参数解释：字符指针buffer指向内存中一段存储空间。len是读写的字节数 示例 #include #include class Person { public: char m_Name[64]; int m_Age; }; //二进制文件 写文件 void test01() { //1、包含头文件 //2、创建输出流对象 ofstream ofs(\"person.txt\", ios::out | ios::binary); //3、打开文件 //ofs.open(\"person.txt\", ios::out | ios::binary); Person p = {\"张三\" , 18}; //4、写文件 ofs.write((const char *)&p, sizeof(p)); //5、关闭文件 ofs.close(); } int main() { test01(); system(\"pause\"); return 0; } 总结： 文件输出流对象 可以通过write函数，以二进制方式写数据 13.2.2 读文件 二进制方式读文件主要利用流对象调用成员函数read 函数原型：istream& read(char *buffer,int len); 参数解释：字符指针buffer指向内存中一段存储空间。len是读写的字节数 示例 #include #include class Person { public: char m_Name[64]; int m_Age; }; void test01() { ifstream ifs(\"person.txt\", ios::in | ios::binary); if (!ifs.is_open()) { cout 文件输入流对象 可以通过read函数，以二进制方式读数据 "},"C++/进阶/01-模板.html":{"url":"C++/进阶/01-模板.html","title":"模板","keywords":"","body":"datetime:2022/10/31 15:37 author:nzb 1 模板 1.1 模板的概念 模板就是建立通用的模具，大大提高复用性 例如生活中的模板 一寸照片模板： PPT模板： 模板的特点： 模板不可以直接使用，它只是一个框架 模板的通用并不是万能的 1.2 函数模板 C++另一种编程思想称为泛型编程 ，主要利用的技术就是模板 C++提供两种模板机制:函数模板和类模板 1.2.1 函数模板语法 函数模板作用：建立一个通用函数，其函数返回值类型和形参类型可以不具体制定，用一个虚拟的类型来代表。 语法 template 函数声明或定义 解释 template:声明创建模板 typename:表面其后面的符号是一种数据类型，可以用class代替 T:通用的数据类型，名称可以替换，通常为大写字母 示例 //交换整型函数 void swapInt(int& a, int& b) { int temp = a; a = b; b = temp; } //交换浮点型函数 void swapDouble(double& a, double& b) { double temp = a; a = b; b = temp; } //利用模板提供通用的交换函数 template void mySwap(T& a, T& b) { T temp = a; a = b; b = temp; } void test01() { int a = 10; int b = 20; //swapInt(a, b); //利用模板实现交换 //1、自动类型推导 mySwap(a, b); //2、显示指定类型 mySwap(a, b); cout 总结： 函数模板利用关键字 template 使用函数模板有两种方式：自动类型推导、显示指定类型 模板的目的是为了提高复用性，将类型参数化 1.2.2 函数模板注意事项 注意事项： 自动类型推导，必须推导出一致的数据类型T,才可以使用 模板必须要确定出T的数据类型，才可以使用 示例 //利用模板提供通用的交换函数 template void mySwap(T&a, T&b) { T temp = a; a = b; b = temp; } // 1、自动类型推导，必须推导出一致的数据类型T,才可以使用 void test01() { int a = 10; int b = 20; char c = 'c'; mySwap(a, b); // 正确，可以推导出一致的T //mySwap(a, c); // 错误，推导不出一致的T类型 } // 2、模板必须要确定出T的数据类型，才可以使用 template void func() { cout (); //利用显示指定类型的方式，给T一个类型，才可以使用该模板 } int main() { test01(); test02(); system(\"pause\"); return 0; } 总结： 使用模板时必须确定出通用数据类型T，并且能够推导出一致的类型 1.2.3 函数模板案例 案例描述： 利用函数模板封装一个排序的函数，可以对不同数据类型数组进行排序 排序规则从大到小，排序算法为选择排序 分别利用char数组和int数组进行测试 示例： //交换的函数模板 template void mySwap(T&a, T&b) { T temp = a; a = b; b = temp; } template // 也可以替换成typename //利用选择排序，进行对数组从大到小的排序 void mySort(T arr[], int len) { for (int i = 0; i void printArray(T arr[], int len) { for (int i = 0; i 总结：模板可以提高代码复用，需要熟练掌握 1.2.4 普通函数与函数模板的区别 普通函数与函数模板区别： 普通函数调用时可以发生自动类型转换（隐式类型转换） 函数模板调用时，如果利用自动类型推导，不会发生隐式类型转换 如果利用显示指定类型的方式，可以发生隐式类型转换 示例： //普通函数 int myAdd01(int a, int b) { return a + b; } //函数模板 template T myAdd02(T a, T b) { return a + b; } //使用函数模板时，如果用自动类型推导，不会发生自动类型转换,即隐式类型转换 void test01() { int a = 10; int b = 20; char c = 'c'; cout (a, c); //正确，如果用显示指定类型，可以发生隐式类型转换 } int main() { test01(); system(\"pause\"); return 0; } 总结：建议使用显示指定类型的方式，调用函数模板，因为可以自己确定通用类型T 1.2.5 普通函数与函数模板的调用规则 调用规则如下： 如果函数模板和普通函数都可以实现，优先调用普通函数 可以通过空模板参数列表来强制调用函数模板 函数模板也可以发生重载 如果函数模板可以产生更好的匹配,优先调用函数模板 示例 //普通函数与函数模板调用规则 void myPrint(int a, int b) { cout void myPrint(T a, T b) { cout void myPrint(T a, T b, T c) { cout (a, b); //调用函数模板 //3、函数模板也可以发生重载 int c = 30; myPrint(a, b, c); //调用重载的函数模板 //4、 如果函数模板可以产生更好的匹配,优先调用函数模板 char c1 = 'a'; char c2 = 'b'; myPrint(c1, c2); //调用函数模板 } int main() { test01(); system(\"pause\"); return 0; } 总结：既然提供了函数模板，最好就不要提供普通函数，否则容易出现二义性 1.2.6 模板的局限性 局限性： 模板的通用性并不是万能的 例如 template void f(T a, T b) { a = b; } 在上述代码中提供的赋值操作，如果传入的a和b是一个数组，就无法实现了 再例如： template void f(T a, T b) { if(a > b) { ... } } 在上述代码中，如果T的数据类型传入的是像Person这样的自定义数据类型，也无法正常运行 因此C++为了解决这种问题，提供模板的重载，可以为这些特定的类型提供具体化的模板 示例 #include using namespace std; #include class Person { public: Person(string name, int age) { this->m_Name = name; this->m_Age = age; } string m_Name; int m_Age; }; //普通函数模板 template bool myCompare(T &a, T &b) { if (a == b) { return true; } else { return false; } } //具体化，显示具体化的原型和定意思以template<>开头，并通过名称来指出类型 //具体化优先于常规模板 template<> bool myCompare(Person &p1, Person &p2) { if ( p1.m_Name == p2.m_Name && p1.m_Age == p2.m_Age) { return true; } else { return false; } } void test01() { int a = 10; int b = 20; //内置数据类型可以直接使用通用的函数模板 bool ret = myCompare(a, b); if (ret) { cout 总结： 利用具体化的模板，可以解决自定义类型的通用化 学习模板并不是为了写模板，而是在STL能够运用系统提供的模板 1.3 类模板 1.3.1 类模板语法 类模板作用：建立一个通用类，类中的成员 数据类型可以不具体制定，用一个虚拟的类型来代表。 语法 template 类 解释 template:声明创建模板 typename:表面其后面的符号是一种数据类型，可以用class代替 T:通用的数据类型，名称可以替换，通常为大写字母 示例 #include //类模板 template class Person { public: Person(NameType name, AgeType age) { this->mName = name; this->mAge = age; } void showPerson() { cout mName mAge P1(\"孙悟空\", 999); P1.showPerson(); } int main() { test01(); system(\"pause\"); return 0; } 总结：类模板和函数模板语法相似，在声明模板template后面加类，此类称为类模板 1.3.2 类模板与函数模板区别 类模板与函数模板区别主要有两点： 类模板没有自动类型推导的使用方式 类模板在模板参数列表中可以有默认参数 示例 #include //类模板 template class Person { public: Person(NameType name, AgeType age) { this->mName = name; this->mAge = age; } void showPerson() { cout mName mAge p(\"孙悟空\", 1000); //必须使用显示指定类型的方式，使用类模板 p.showPerson(); } //2、类模板在模板参数列表中可以有默认参数 void test02() { Person p(\"猪八戒\", 999); //类模板中的模板参数列表 可以指定默认参数 p.showPerson(); } int main() { test01(); test02(); system(\"pause\"); return 0; } 总结： 类模板使用只能用显示指定类型方式 类模板中的模板参数列表可以有默认参数 1.3.3 类模板中成员函数创建时机 类模板中成员函数和普通类中成员函数创建时机是有区别的： 普通类中的成员函数一开始就可以创建 类模板中的成员函数在调用时才创建 示例 class Person1 { public: void showPerson1() { cout class MyClass { public: T obj; //类模板中的成员函数，并不是一开始就创建的，而是在模板调用时再生成 void fun1() { obj.showPerson1(); } void fun2() { obj.showPerson2(); } }; void test01() { MyClass m; m.fun1(); // MyClass m; //m.fun2();//编译会出错，说明函数调用才会去创建成员函数 } int main() { test01(); system(\"pause\"); return 0; } 总结：类模板中的成员函数并不是一开始就创建的，在调用时才去创建 1.3.4 类模板对象做函数参数 一共有三种传入方式： 指定传入的类型：直接显示对象的数据类型 参数模板化：将对象中的参数变为模板进行传递 整个类模板化：将这个对象类型 模板化进行传递 示例 #include //类模板 template class Person { public: Person(NameType name, AgeType age) { this->mName = name; this->mAge = age; } void showPerson() { cout mName mAge &p) { p.showPerson(); } void test01() { Person p(\"孙悟空\", 100); printPerson1(p); } //2、参数模板化 template void printPerson2(Person&p) { p.showPerson(); cout p(\"猪八戒\", 90); printPerson2(p); } //3、整个类模板化 template void printPerson3(T &p) { cout p(\"唐僧\", 30); printPerson3(p); } int main() { test01(); test02(); test03(); system(\"pause\"); return 0; } 总结： 通过类模板创建的对象，可以有三种方式向函数中进行传参 使用比较广泛是第一种：指定传入的类型 1.3.5 类模板与继承 当类模板碰到继承时，需要注意一下几点： 当子类继承的父类是一个类模板时，子类在声明的时候，要指定出父类中T的类型 如果不指定，编译器无法给子类分配内存 如果想灵活指定出父类中T的类型，子类也需变为类模板 示例 template class Base { T m; }; //class Son:public Base //错误，c++编译需要给子类分配内存，必须知道父类中T的类型才可以向下继承 class Son :public Base //必须指定一个类型 { }; void test01() { Son c; } //类模板继承类模板 ,可以用T2指定父类中的T类型 template class Son2 :public Base { public: Son2() { cout child1; } int main() { test01(); test02(); system(\"pause\"); return 0; } 总结：如果父类是类模板，子类需要指定出父类中T的数据类型 1.3.6 类模板成员函数类外实现 学习目标：能够掌握类模板中的成员函数类外实现 示例 #include //类模板中成员函数类外实现 template class Person { public: //成员函数类内声明 Person(T1 name, T2 age); void showPerson(); public: T1 m_Name; T2 m_Age; }; //构造函数 类外实现 template Person::Person(T1 name, T2 age) { this->m_Name = name; this->m_Age = age; } //成员函数 类外实现 template void Person::showPerson() { cout m_Name m_Age p(\"Tom\", 20); p.showPerson(); } int main() { test01(); system(\"pause\"); return 0; } 总结：类模板中成员函数类外实现时，需要加上模板参数列表 1.3.7 类模板分文件编写 学习目标： 掌握类模板成员函数分文件编写产生的问题以及解决方式 问题： 类模板中成员函数创建时机是在调用阶段，导致分文件编写时链接不到 解决： 解决方式1：直接包含.cpp源文件 解决方式2：将声明和实现写到同一个文件中，并更改后缀名为.hpp，hpp是约定的名称，并不是强制 示例 person.hpp中代码： #pragma once #include using namespace std; #include template class Person { public: Person(T1 name, T2 age); void showPerson(); public: T1 m_Name; T2 m_Age; }; //构造函数 类外实现 template Person::Person(T1 name, T2 age) { this->m_Name = name; this->m_Age = age; } //成员函数 类外实现 template void Person::showPerson() { cout m_Name m_Age 类模板分文件编写.cpp中代码 #include using namespace std; //#include \"person.h\" #include \"person.cpp\" //解决方式1，包含cpp源文件 //解决方式2，将声明和实现写到一起，文件后缀名改为.hpp #include \"person.hpp\" void test01() { Person p(\"Tom\", 10); p.showPerson(); } int main() { test01(); system(\"pause\"); return 0; } 总结：主流的解决方式是第二种，将类模板成员函数写到一起，并将后缀名改为.hpp 1.3.8 类模板与友元 学习目标： 掌握类模板配合友元函数的类内和类外实现 全局函数类内实现 - 直接在类内声明友元即可 全局函数类外实现 - 需要提前让编译器知道全局函数的存在 全局函数类内实现示例 #include template class Person { //1、全局函数配合友元 类内实现 friend void printPerson(Person & p) { cout m_Name = name; this->m_Age = age; } private: T1 m_Name; T2 m_Age; }; //1、全局函数在类内实现 void test01() { Person p(\"Tom\", 20); printPerson(p); } int main() { test01(); system(\"pause\"); return 0; } 全局函数类外实现示例 #include //2、全局函数配合友元 类外实现 - 先做函数模板声明，下方在做函数模板定义，在做友元 template class Person; //如果声明了函数模板，可以将实现写到后面，否则需要将实现体写到类的前面让编译器提前看到 //template void printPerson2(Person & p); template void printPerson2(Person & p) { cout class Person { //全局函数配合友元 类外实现 // 加空模板参数列表 printPerson2<> friend void printPerson2<>(Person & p); public: Person(T1 name, T2 age) { this->m_Name = name; this->m_Age = age; } private: T1 m_Name; T2 m_Age; }; //2、全局函数在类外实现 void test02() { Person p(\"Jerry\", 30); printPerson2(p); } int main() { test02(); system(\"pause\"); return 0; } 总结：建议全局函数做类内实现，用法简单，而且编译器可以直接识别 1.3.9 类模板案例 案例描述: 实现一个通用的数组类，要求如下： 可以对内置数据类型以及自定义数据类型的数据进行存储 将数组中的数据存储到堆区 构造函数中可以传入数组的容量 提供对应的拷贝构造函数以及operator=防止浅拷贝问题 提供尾插法和尾删法对数组中的数据进行增加和删除 可以通过下标的方式访问数组中的元素 可以获取数组中当前元素个数和数组的容量 示例： myArray.hpp中代码 #pragma once #include using namespace std; template class MyArray { public: //构造函数 MyArray(int capacity) { this->m_Capacity = capacity; this->m_Size = 0; pAddress = new T[this->m_Capacity]; } //拷贝构造 MyArray(const MyArray& arr) { this->m_Capacity = arr.m_Capacity; this->m_Size = arr.m_Size; // this->pAddress = arr.pAddress; // 编译器默认，浅拷贝 this->pAddress = new T[this->m_Capacity]; for (int i = 0; i m_Size; i++) { //如果T为对象，而且还包含指针，必须需要重载 = 操作符，因为这个等号不是 构造 而是赋值， // 普通类型可以直接= 但是指针类型需要深拷贝 this->pAddress[i] = arr.pAddress[i]; } } //重载= 操作符 防止浅拷贝问题，类似：a = b = c, 链式编程 MyArray& operator=(const MyArray& myarray) { // 先释放 if (this->pAddress != NULL) { delete[] this->pAddress; this->m_Capacity = 0; this->m_Size = 0; } // 深拷贝 this->m_Capacity = myarray.m_Capacity; this->m_Size = myarray.m_Size; this->pAddress = new T[this->m_Capacity]; for (int i = 0; i m_Size; i++) { this->pAddress[i] = myarray[i]; } return *this; } //重载[] 操作符 arr[0] T& operator [](int index) // T& 可以返回做左值操作，例如：arr[0] = 111 { return this->pAddress[index]; //不考虑越界，用户自己去处理 } //尾插法 void Push_back(const T & val) { if (this->m_Capacity == this->m_Size) { return; } this->pAddress[this->m_Size] = val; this->m_Size++; } //尾删法 void Pop_back() { if (this->m_Size == 0) { return; } this->m_Size--; } //获取数组容量 int getCapacity() { return this->m_Capacity; } //获取数组大小 int getSize() { return this->m_Size; } //析构 ~MyArray() { if (this->pAddress != NULL) { delete[] this->pAddress; this->pAddress = NULL; this->m_Capacity = 0; this->m_Size = 0; } } private: T * pAddress; //指向一个堆空间，这个空间存储真正的数据 int m_Capacity; //容量 int m_Size; // 大小 }; 类模板案例—数组类封装.cpp中 #include \"myArray.hpp\" #include void printIntArray(MyArray& arr) { for (int i = 0; i array1(10); for (int i = 0; i array2(array1); array2.Pop_back(); cout m_Name = name; this->m_Age = age; } public: string m_Name; int m_Age; }; void printPersonArray(MyArray& personArr) { for (int i = 0; i pArray(10); Person p1(\"孙悟空\", 30); Person p2(\"韩信\", 20); Person p3(\"妲己\", 18); Person p4(\"王昭君\", 15); Person p5(\"赵云\", 24); //插入数据 pArray.Push_back(p1); pArray.Push_back(p2); pArray.Push_back(p3); pArray.Push_back(p4); pArray.Push_back(p5); printPersonArray(pArray); cout 总结：能够利用所学知识点实现通用的数组 "},"C++/进阶/02-STL初识.html":{"url":"C++/进阶/02-STL初识.html","title":"STL初识","keywords":"","body":"datetime:2022/11/02 16:17 author:nzb 2 STL初识 2.1 STL的诞生 长久以来，软件界一直希望建立一种可重复利用的东西 C++的面向对象和泛型编程思想，目的就是复用性的提升 大多情况下，数据结构和算法都未能有一套标准,导致被迫从事大量重复工作 为了建立数据结构和算法的一套标准,诞生了STL 2.2 STL基本概念 STL(Standard Template Library,标准模板库) STL 从广义上分为: 容器(container) 算法(algorithm) 迭代器(iterator) 容器和算法之间通过迭代器进行无缝连接。 STL 几乎所有的代码都采用了模板类或者模板函数 2.3 STL六大组件 STL大体分为六大组件，分别是:容器、算法、迭代器、仿函数、适配器（配接器）、空间配置器 容器：各种数据结构，如vector、list、deque、set、map等,用来存放数据。 算法：各种常用的算法，如sort、find、copy、for_each等 迭代器：扮演了容器与算法之间的胶合剂。 仿函数：行为类似函数，可作为算法的某种策略。 适配器：一种用来修饰容器或者仿函数或迭代器接口的东西。 空间配置器：负责空间的配置与管理。 2.4 STL中容器、算法、迭代器 容器：置物之所也 STL容器就是将运用最广泛的一些数据结构实现出来 常用的数据结构：数组, 链表,树, 栈, 队列, 集合, 映射表 等 这些容器分为序列式容器和关联式容器两种: 序列式容器：强调值的排序，序列式容器中的每个元素均有固定的位置。 关联式容器：二叉树结构，各元素之间没有严格的物理上的顺序关系 算法：问题之解法也 有限的步骤，解决逻辑或数学上的问题，这一门学科我们叫做算法(Algorithms) 算法分为:质变算法和非质变算法。 质变算法：是指运算过程中会更改区间内的元素的内容。例如拷贝，替换，删除等等 非质变算法：是指运算过程中不会更改区间内的元素内容，例如查找、计数、遍历、寻找极值等等 迭代器：容器和算法之间粘合剂 提供一种方法，使之能够依序寻访某个容器所含的各个元素，而又无需暴露该容器的内部表示方式。 每个容器都有自己专属的迭代器 迭代器使用非常类似于指针，初学阶段我们可以先理解迭代器为指针 迭代器种类： 种类 功能 支持运算 输入迭代器 对数据的只读访问 只读，支持++、==、！= 输出迭代器 对数据的只写访问 只写，支持++ 前向迭代器 读写操作，并能向前推进迭代器 读写，支持++、==、！= 双向迭代器 读写操作，并能向前和向后操作 读写，支持++、--， 随机访问迭代器 读写操作，可以以跳跃的方式访问任意数据，功能最强的迭代器 读写，支持++、--、[n]、-n、、>= 常用的容器中迭代器种类为双向迭代器，和随机访问迭代器 2.5 容器算法迭代器初识 了解STL中容器、算法、迭代器概念之后，我们利用代码感受STL的魅力 STL中最常用的容器为Vector，可以理解为数组，下面我们将学习如何向这个容器中插入数据、并遍历这个容器 2.5.1 vector存放内置数据类型 容器： vector 算法： for_each 迭代器： vector::iterator 示例： #include #include void MyPrint(int val) { cout v; //向容器中放数据 v.push_back(10); v.push_back(20); v.push_back(30); v.push_back(40); //每一个容器都有自己的迭代器，迭代器是用来遍历容器中的元素 //v.begin()返回迭代器，这个迭代器指向容器中第一个数据 //v.end()返回迭代器，这个迭代器指向容器元素的最后一个元素的下一个位置 //vector::iterator 拿到vector这种容器的迭代器类型 //第一种遍历方式： vector::iterator pBegin = v.begin(); vector::iterator pEnd = v.end(); while (pBegin != pEnd) { cout ::iterator it = v.begin(); it != v.end(); it++) { cout 2.5.2 Vector存放自定义数据类型 学习目标：vector中存放自定义数据类型，并打印输出 示例 #include #include //自定义数据类型 class Person { public: Person(string name, int age) { mName = name; mAge = age; } public: string mName; int mAge; }; //存放对象 void test01() { vector v; //创建数据 Person p1(\"aaa\", 10); Person p2(\"bbb\", 20); Person p3(\"ccc\", 30); Person p4(\"ddd\", 40); Person p5(\"eee\", 50); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); v.push_back(p5); for (vector::iterator it = v.begin(); it != v.end(); it++) { cout v; //创建数据 Person p1(\"aaa\", 10); Person p2(\"bbb\", 20); Person p3(\"ccc\", 30); Person p4(\"ddd\", 40); Person p5(\"eee\", 50); v.push_back(&p1); v.push_back(&p2); v.push_back(&p3); v.push_back(&p4); v.push_back(&p5); for (vector::iterator it = v.begin(); it != v.end(); it++) { Person * p = (*it); cout mName mAge 2.5.3 Vector容器嵌套容器 学习目标：容器中嵌套容器，我们将所有数据进行遍历输出 示例 #include //容器嵌套容器 void test01() { vector > v; vector v1; vector v2; vector v3; vector v4; for (int i = 0; i >::iterator it = v.begin(); it != v.end(); it++) { for (vector::iterator vit = (*it).begin(); vit != (*it).end(); vit++) { cout "},"C++/进阶/03-1-STL常用容器-string.html":{"url":"C++/进阶/03-1-STL常用容器-string.html","title":"string","keywords":"","body":"datetime:2022/11/03 10:32 author:nzb 3 STL- 常用容器 3.1 string容器 3.1.1 string基本概念 本质： string是C++风格的字符串，而string本质上是一个类 string和char * 区别： char * 是一个指针 string是一个类，类内部封装了char *，管理这个字符串，是一个char *型的容器。 特点： string 类内部封装了很多成员方法 例如：查找find，拷贝copy，删除delete 替换replace，插入insert string管理char*所分配的内存，不用担心复制越界和取值越界等，由类内部进行负责 3.1.2 string构造函数 构造函数原型： string(); //创建一个空的字符串 例如: string str; string(const char* s); //使用字符串s初始化 string(const string& str); //使用一个string对象初始化另一个string对象 string(int n, char c); //使用n个字符c初始化 示例 #include //string构造 void test01() { string s1; //创建空字符串，调用无参构造函数 cout 总结：string的多种构造方式没有可比性，灵活使用即可 3.1.3 string赋值操作 功能描述： 给string字符串进行赋值 赋值的函数原型： string& operator=(const char* s); //char*类型字符串 赋值给当前的字符串 string& operator=(const string &s); //把字符串s赋给当前的字符串 string& operator=(char c); //字符赋值给当前的字符串 string& assign(const char *s); //把字符串s赋给当前的字符串 string& assign(const char *s, int n); //把字符串s的前n个字符赋给当前的字符串 string& assign(const string &s); //把字符串s赋给当前字符串 string& assign(int n, char c); //用n个字符c赋给当前字符串 示例 //赋值 void test01() { string str1; str1 = \"hello world\"; cout 总结：string的赋值方式很多，operator= 这种方式是比较实用的 3.1.4 string字符串拼接 功能描述：实现在字符串末尾拼接字符串 函数原型 string& operator+=(const char* str); //重载+=操作符 string& operator+=(const char c); //重载+=操作符 string& operator+=(const string& str); //重载+=操作符 string& append(const char *s); //把字符串s连接到当前字符串结尾 string& append(const char *s, int n); //把字符串s的前n个字符连接到当前字符串结尾 string& append(const string &s); //同operator+=(const string& str) string& append(const string &s, int pos, int n);//字符串s中从pos开始的n个字符连接到字符串结尾 示例 //字符串拼接 void test01() { string str1 = \"我\"; str1 += \"爱玩游戏\"; cout 总结：字符串拼接的重载版本很多，初学阶段记住几种即可 3.1.5 string查找和替换 功能描述 查找：查找指定字符串是否存在 替换：在指定的位置替换字符串 函数原型 int find(const string& str, int pos = 0) const; //查找str第一次出现位置,从pos开始查找 int find(const char* s, int pos = 0) const; //查找s第一次出现位置,从pos开始查找 int find(const char* s, int pos, int n) const; //从pos位置查找s的前n个字符第一次位置 int find(const char c, int pos = 0) const; //查找字符c第一次出现位置 int rfind(const string& str, int pos = npos) const; //查找str最后一次位置,从pos开始查找 int rfind(const char* s, int pos = npos) const; //查找s最后一次出现位置,从pos开始查找 int rfind(const char* s, int pos, int n) const; //从pos查找s的前n个字符最后一次位置 int rfind(const char c, int pos = 0) const; //查找字符c最后一次出现位置 string& replace(int pos, int n, const string& str); //替换从pos开始n个字符为字符串str string& replace(int pos, int n,const char* s); //替换从pos开始的n个字符为字符串s 示例 //查找和替换 void test01() { //查找 string str1 = \"abcdefgde\"; int pos = str1.find(\"de\"); if (pos == -1) { cout 总结： find查找是从左往后，rfind从右往左 find找到字符串后返回查找的第一个字符位置，找不到返回-1 replace在替换时，要指定从哪个位置起，多少个字符，替换成什么样的字符串 3.1.6 string字符串比较 功能描述：字符串之间的比较 比较方式：字符串比较是按字符的ASCII码进行对比 = 返回 0 > 返回 1 函数原型： int compare(const string &s) const; //与字符串s比较 int compare(const char *s) const; //与字符串s比较 示例： //字符串比较 void test01() { string s1 = \"hello\"; string s2 = \"aello\"; int ret = s1.compare(s2); if (ret == 0) { cout 0) { cout 总结：字符串对比主要是用于比较两个字符串是否相等，判断谁大谁小的意义并不是很大 3.1.7 string字符存取 string中单个字符存取方式有两种 char& operator[](int n); //通过[]方式取字符 char& at(int n); //通过at方法获取字符 示例 void test01() { string str = \"hello world\"; for (int i = 0; i 总结：string字符串中单个字符存取有两种方式，利用 [ ] 或 at 3.1.8 string插入和删除 功能描述：对string字符串进行插入和删除字符操作 函数原型 string& insert(int pos, const char* s); //插入字符串 string& insert(int pos, const string& str); //插入字符串 string& insert(int pos, int n, char c); //在指定位置插入n个字符c string& erase(int pos, int n = npos); //删除从Pos开始的n个字符 示例 //字符串插入和删除 void test01() { string str = \"hello\"; str.insert(1, \"111\"); cout 总结：插入和删除的起始下标都是从0开始 3.1.9 string子串 功能描述：从字符串中获取想要的子串 函数原型 string substr(int pos = 0, int n = npos) const; //返回由pos开始的n个字符组成的字符串 示例： //子串 void test01() { string str = \"abcdefg\"; string subStr = str.substr(1, 3); cout 总结：灵活的运用求子串功能，可以在实际开发中获取有效的信息 "},"C++/进阶/03-2-STL常用容器-vector.html":{"url":"C++/进阶/03-2-STL常用容器-vector.html","title":"vector","keywords":"","body":"datetime:2022/11/03 10:32 author:nzb 3 STL- 常用容器 3.2 vector容器 3.2.1 vector基本概念 功能 vector数据结构和数组非常相似，也称为单端数组 vector与普通数组区别 不同之处在于数组是静态空间，而vector可以动态扩展 动态扩展 并不是在原空间之后续接新空间，而是找更大的内存空间，然后将原数据拷贝新空间，释放原空间 vector容器的迭代器是支持随机访问的迭代器 3.2.2 vector构造函数 功能描述：创建vector容器 函数原型 vector v; //采用模板实现类实现，默认构造函数 vector(v.begin(), v.end()); //将v[begin(), end())区间中的元素拷贝给本身。 vector(n, elem); //构造函数将n个elem拷贝给本身。 vector(const vector &vec); //拷贝构造函数。 示例 #include void printVector(vector& v) { for (vector::iterator it = v.begin(); it != v.end(); it++) { cout v1; //无参构造 for (int i = 0; i v2(v1.begin(), v1.end()); printVector(v2); vector v3(10, 100); printVector(v3); // 拷贝构造 vector v4(v3); printVector(v4); } int main() { test01(); system(\"pause\"); return 0; } 总结：vector的多种构造方式没有可比性，灵活使用即可 3.2.3 vector赋值操作 功能描述：给vector容器进行赋值 函数原型 vector& operator=(const vector &vec);//重载等号操作符 assign(beg, end); //将[beg, end)区间中的数据拷贝赋值给本身。 assign(n, elem); //将n个elem拷贝赋值给本身。 示例 #include void printVector(vector& v) { for (vector::iterator it = v.begin(); it != v.end(); it++) { cout v1; //无参构造 for (int i = 0; i v2; v2 = v1; printVector(v2); vectorv3; v3.assign(v1.begin(), v1.end()); printVector(v3); vectorv4; v4.assign(10, 100); printVector(v4); } int main() { test01(); system(\"pause\"); return 0; } 总结： vector赋值方式比较简单，使用operator=，或者assign都可以 3.2.4 vector容量和大小 功能描述：对vector容器的容量和大小操作 函数原型 empty(); //判断容器是否为空 capacity(); //容器的容量 size(); //返回容器中元素的个数 resize(int num); //重新指定容器的长度为num，若容器变长，则以默认值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除。 resize(int num, elem); //重新指定容器的长度为num，若容器变长，则以elem值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除 示例 #include void printVector(vector& v) { for (vector::iterator it = v.begin(); it != v.end(); it++) { cout v1; for (int i = 0; i 总结： 判断是否为空 --- empty 返回元素个数 --- size 返回容器容量 --- capacity 重新指定大小 --- resize 3.2.5 vector插入和删除 功能描述：对vector容器进行插入、删除操作 函数原型 push_back(ele); //尾部插入元素ele pop_back(); //删除最后一个元素 insert(const_iterator pos, ele); //迭代器指向位置pos插入元素ele insert(const_iterator pos, int count,ele);//迭代器指向位置pos插入count个元素ele erase(const_iterator pos); //删除迭代器指向的元素 erase(const_iterator start, const_iterator end);//删除迭代器从start到end之间的元素 clear(); //删除容器中所有元素 示例 #include void printVector(vector& v) { for (vector::iterator it = v.begin(); it != v.end(); it++) { cout v1; //尾插 v1.push_back(10); v1.push_back(20); v1.push_back(30); v1.push_back(40); v1.push_back(50); printVector(v1); //尾删 v1.pop_back(); printVector(v1); //插入 v1.insert(v1.begin(), 100); printVector(v1); v1.insert(v1.begin(), 2, 1000); printVector(v1); //删除 v1.erase(v1.begin()); printVector(v1); //清空 v1.erase(v1.begin(), v1.end()); v1.clear(); printVector(v1); } int main() { test01(); system(\"pause\"); return 0; } 总结： 尾插 --- push_back 尾删 --- pop_back 插入 --- insert (位置迭代器) 删除 --- erase （位置迭代器） 清空 --- clear 3.2.6 vector数据存取 功能描述：对vector中的数据的存取操作 函数原型 at(int idx); //返回索引idx所指的数据 operator[]; //返回索引idx所指的数据 front(); //返回容器中第一个数据元素 back(); //返回容器中最后一个数据元素 示例 #include void test01() { vectorv1; for (int i = 0; i 总结： 除了用迭代器获取vector容器中元素，[ ]和at也可以 front返回容器第一个元素 back返回容器最后一个元素 3.2.7 vector互换容器 功能描述：实现两个容器内元素进行互换 函数原型 swap(vec); // 将vec与本身的元素互换 示例 #include void printVector(vector& v) { for (vector::iterator it = v.begin(); it != v.end(); it++) { cout v1; for (int i = 0; i v2; for (int i = 10; i > 0; i--) { v2.push_back(i); } printVector(v2); //互换容器 cout v; for (int i = 0; i (v).swap(v); //匿名对象 cout 总结：swap可以使两个容器互换，可以达到实用的收缩内存效果 3.2.8 vector预留空间 功能描述：减少vector在动态扩展容量时的扩展次数 函数原型 reserve(int len);//容器预留len个元素长度，预留位置不初始化，元素不可访问。 示例 #include void test01() { vector v; //预留空间 v.reserve(100000); // 不写，需要开辟30次 int num = 0; int * p = NULL; for (int i = 0; i 总结：如果数据量较大，可以一开始利用reserve预留空间 "},"C++/进阶/03-3-STL常用容器-deque.html":{"url":"C++/进阶/03-3-STL常用容器-deque.html","title":"deque","keywords":"","body":"datetime:2022/11/03 10:32 author:nzb 3 STL- 常用容器 3.3 deque容器 3.3.1 deque容器基本概念 功能：双端数组，可以对头端进行插入删除操作 deque与vector区别： vector对于头部的插入删除效率低，数据量越大，效率越低 deque相对而言，对头部的插入删除速度回比vector快 vector访问元素时的速度会比deque快,这和两者内部实现有关，因为deque需要先查询中控器 deque内部工作原理: deque内部有个中控器，维护每段缓冲区中的内容，缓冲区中存放真实数据 中控器维护的是每个缓冲区的地址，使得使用deque时像一片连续的内存空间 deque容器的迭代器也是支持随机访问的 3.3.2 deque构造函数 功能描述：deque容器构造 函数原型 deque deqT; //默认构造形式 deque(beg, end); //构造函数将[beg, end)区间中的元素拷贝给本身。 deque(n, elem); //构造函数将n个elem拷贝给本身。 deque(const deque &deq); //拷贝构造函数 示例 #include void printDeque(const deque& d) { for (deque::const_iterator it = d.begin(); it != d.end(); it++) { cout d1; //无参构造函数 for (int i = 0; i d2(d1.begin(),d1.end()); printDeque(d2); dequed3(10,100); printDeque(d3); dequed4 = d3; printDeque(d4); } int main() { test01(); system(\"pause\"); return 0; } 总结：deque容器和vector容器的构造方式几乎一致，灵活使用即可 3.3.3 deque赋值操作 功能描述：给deque容器进行赋值 函数原型 deque& operator=(const deque &deq); //重载等号操作符 assign(beg, end); //将[beg, end)区间中的数据拷贝赋值给本身。 assign(n, elem); //将n个elem拷贝赋值给本身。 示例 #include void printDeque(const deque& d) { for (deque::const_iterator it = d.begin(); it != d.end(); it++) { cout d1; for (int i = 0; i d2; d2 = d1; printDeque(d2); dequed3; d3.assign(d1.begin(), d1.end()); printDeque(d3); dequed4; d4.assign(10, 100); printDeque(d4); } int main() { test01(); system(\"pause\"); return 0; } 总结：deque赋值操作也与vector相同，需熟练掌握 3.3.4 deque大小操作 功能描述：对deque容器的大小进行操作 函数原型 deque.empty(); //判断容器是否为空 deque.size(); //返回容器中元素的个数 deque.resize(num); //重新指定容器的长度为num,若容器变长，则以默认值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除。 deque.resize(num, elem); //重新指定容器的长度为num,若容器变长，则以elem值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除。 示例 #include void printDeque(const deque& d) { for (deque::const_iterator it = d.begin(); it != d.end(); it++) { cout d1; for (int i = 0; i 总结： deque没有容量的概念 判断是否为空 --- empty 返回元素个数 --- size 重新指定个数 --- resize 3.3.5 deque 插入和删除 功能描述：向deque容器中插入和删除数据 函数原型 两端插入操作 push_back(elem); //在容器尾部添加一个数据 push_front(elem); //在容器头部插入一个数据 pop_back(); //删除容器最后一个数据 pop_front(); //删除容器第一个数据 指定位置操作 insert(pos,elem); //在pos位置插入一个elem元素的拷贝，返回新数据的位置。 insert(pos,n,elem); //在pos位置插入n个elem数据，无返回值。 insert(pos,beg,end); //在pos位置插入[beg,end)区间的数据，无返回值。 clear(); //清空容器的所有数据 erase(beg,end); //删除[beg,end)区间的数据，返回下一个数据的位置。 erase(pos); //删除pos位置的数据，返回下一个数据的位置。 示例 #include void printDeque(const deque& d) { for (deque::const_iterator it = d.begin(); it != d.end(); it++) { cout d; //尾插 d.push_back(10); d.push_back(20); //头插 d.push_front(100); d.push_front(200); printDeque(d); //尾删 d.pop_back(); //头删 d.pop_front(); printDeque(d); } //插入 void test02() { deque d; d.push_back(10); d.push_back(20); d.push_front(100); d.push_front(200); printDeque(d); d.insert(d.begin(), 1000); printDeque(d); d.insert(d.begin(), 2,10000); printDeque(d); dequed2; d2.push_back(1); d2.push_back(2); d2.push_back(3); d.insert(d.begin(), d2.begin(), d2.end()); printDeque(d); } //删除 void test03() { deque d; d.push_back(10); d.push_back(20); d.push_front(100); d.push_front(200); printDeque(d); d.erase(d.begin()); printDeque(d); d.erase(d.begin(), d.end()); d.clear(); printDeque(d); } int main() { //test01(); //test02(); test03(); system(\"pause\"); return 0; } 总结： 插入和删除提供的位置是迭代器！ 尾插 --- push_back 尾删 --- pop_back 头插 --- push_front 头删 --- pop_front 3.3.6 deque 数据存取 功能描述：对deque 中的数据的存取操作 函数原型 at(int idx); //返回索引idx所指的数据 operator[]; //返回索引idx所指的数据 front(); //返回容器中第一个数据元素 back(); //返回容器中最后一个数据元素 示例 #include void printDeque(const deque& d) { for (deque::const_iterator it = d.begin(); it != d.end(); it++) { cout d; d.push_back(10); d.push_back(20); d.push_front(100); d.push_front(200); for (int i = 0; i 总结： 除了用迭代器获取deque容器中元素，[ ]和at也可以 front返回容器第一个元素 back返回容器最后一个元素 3.3.7 deque 排序 功能描述：利用算法实现对deque容器进行排序 算法 sort(iterator beg, iterator end) //对beg和end区间内元素进行排序 示例 #include #include void printDeque(const deque& d) { for (deque::const_iterator it = d.begin(); it != d.end(); it++) { cout d; d.push_back(10); d.push_back(20); d.push_front(100); d.push_front(200); printDeque(d); sort(d.begin(), d.end()); printDeque(d); } int main() { test01(); system(\"pause\"); return 0; } 总结：sort算法非常实用，使用时包含头文件 algorithm即可 3.4 案例-评委打分 3.4.1 案例描述 有5名选手：选手ABCDE，10个评委分别对每一名选手打分，去除最高分，去除评委中最低分，取平均分。 3.4.2 实现步骤 创建五名选手，放到vector中 遍历vector容器，取出来每一个选手，执行for循环，可以把10个评分打分存到deque容器中 sort算法对deque容器中分数排序，去除最高和最低分 deque容器遍历一遍，累加总分 获取平均分 示例代码 //选手类 class Person { public: Person(string name, int score) { this->m_Name = name; this->m_Score = score; } string m_Name; //姓名 int m_Score; //平均分 }; void createPerson(vector&v) { string nameSeed = \"ABCDE\"; for (int i = 0; i &v) { for (vector::iterator it = v.begin(); it != v.end(); it++) { //将评委的分数 放入到deque容器中 dequed; for (int i = 0; i m_Name ::iterator dit = d.begin(); dit != d.end(); dit++) //{ // cout ::iterator dit = d.begin(); dit != d.end(); dit++) { sum += *dit; //累加每个评委的分数 } int avg = sum / d.size(); //将平均分 赋值给选手身上 it->m_Score = avg; } } void showScore(vector&v) { for (vector::iterator it = v.begin(); it != v.end(); it++) { cout m_Name m_Score v; //存放选手容器 createPerson(v); //测试 //for (vector::iterator it = v.begin(); it != v.end(); it++) //{ // cout 总结：选取不同的容器操作数据，可以提升代码的效率 "},"C++/进阶/03-4-STL常用容器-stack.html":{"url":"C++/进阶/03-4-STL常用容器-stack.html","title":"stack","keywords":"","body":"datetime:2022/11/03 10:32 author:nzb 3 STL- 常用容器 3.5 stack容器 3.5.1 stack 基本概念 概念：stack是一种先进后出(First In Last Out,FILO)的数据结构，它只有一个出口 栈中只有顶端的元素才可以被外界使用，因此栈不允许有遍历行为 栈中进入数据称为 --- 入栈 push 栈中弹出数据称为 --- 出栈 pop 生活中的栈： 3.5.2 stack 常用接口 功能描述：栈容器常用的对外接口 构造函数 stack stk; //stack采用模板类实现， stack对象的默认构造形式 stack(const stack &stk); //拷贝构造函数 赋值操作 stack& operator=(const stack &stk); //重载等号操作符 数据存取 push(elem); //向栈顶添加元素 pop(); //从栈顶移除第一个元素 top(); //返回栈顶元素 大小操作 empty(); //判断堆栈是否为空 size(); //返回栈的大小 示例 #include //栈容器常用接口 void test01() { //创建栈容器 栈容器必须符合先进后出 stack s; //向栈中添加元素，叫做 压栈 入栈 s.push(10); s.push(20); s.push(30); while (!s.empty()) { //输出栈顶元素 cout 总结： 入栈 --- push 出栈 --- pop 返回栈顶 --- top 判断栈是否为空 --- empty 返回栈大小 --- size "},"C++/进阶/03-5-STL常用容器-queue.html":{"url":"C++/进阶/03-5-STL常用容器-queue.html","title":"queue","keywords":"","body":"datetime:2022/11/03 10:32 author:nzb 3 STL- 常用容器 3.6 queue 容器 3.6.1 queue 基本概念 概念：Queue是一种先进先出(First In First Out,FIFO)的数据结构，它有两个出口 队列容器允许从一端新增元素，从另一端移除元素 队列中只有队头和队尾才可以被外界使用，因此队列不允许有遍历行为 队列中进数据称为 --- 入队 push 队列中出数据称为 --- 出队 pop 生活中的队列： 3.6.2 queue 常用接口 功能描述：栈容器常用的对外接口 构造函数 queue que; //queue采用模板类实现，queue对象的默认构造形式 queue(const queue &que); //拷贝构造函数 赋值操作 queue& operator=(const queue &que); //重载等号操作符 数据存取 push(elem); //往队尾添加元素 pop(); //从队头移除第一个元素 back(); //返回最后一个元素 front(); //返回第一个元素 大小操作 empty(); //判断堆栈是否为空 size(); //返回栈的大小 示例 #include #include class Person { public: Person(string name, int age) { this->m_Name = name; this->m_Age = age; } string m_Name; int m_Age; }; void test01() { //创建队列 queue q; //准备数据 Person p1(\"唐僧\", 30); Person p2(\"孙悟空\", 1000); Person p3(\"猪八戒\", 900); Person p4(\"沙僧\", 800); //向队列中添加元素 入队操作 q.push(p1); q.push(p2); q.push(p3); q.push(p4); //队列不提供迭代器，更不支持随机访问 while (!q.empty()) { //输出队头元素 cout 总结： 入队 --- push 出队 --- pop 返回队头元素 --- front 返回队尾元素 --- back 判断队是否为空 --- empty 返回队列大小 --- size "},"C++/进阶/03-6-STL常用容器-list.html":{"url":"C++/进阶/03-6-STL常用容器-list.html","title":"list","keywords":"","body":"datetime:2022/11/03 10:32 author:nzb 3 STL- 常用容器 3.7 list容器 3.7.1 list基本概念 功能：将数据进行链式存储 链表（list）是一种物理存储单元上非连续的存储结构，数据元素的逻辑顺序是通过链表中的指针链接实现的 链表的组成：链表由一系列结点组成 结点的组成：一个是存储数据元素的数据域，另一个是存储下一个结点地址的指针域 STL中的链表是一个双向循环链表 由于链表的存储方式并不是连续的内存空间，因此链表list中的迭代器只支持前移和后移，属于双向迭代器 list的优点： 采用动态存储分配，不会造成内存浪费和溢出 链表执行插入和删除操作十分方便，修改指针即可，不需要移动大量元素 list的缺点： 链表灵活，但是空间(指针域) 和 时间（遍历）额外耗费较大 占用空间比数组大，因为多了个指针域 List有一个重要的性质，插入操作和删除操作都不会造成原有list迭代器的失效，这在vector是不成立的。 总结：STL中List和vector是两个最常被使用的容器，各有优缺点 3.7.2 list构造函数 功能描述：创建list容器 函数原型 list lst; //list采用采用模板类实现,对象的默认构造形式： list(beg,end); //构造函数将[beg, end)区间中的元素拷贝给本身。 list(n,elem); //构造函数将n个elem拷贝给本身。 list(const list &lst); //拷贝构造函数。 示例： #include void printList(const list& L) { for (list::const_iterator it = L.begin(); it != L.end(); it++) { cout L1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); printList(L1); listL2(L1.begin(),L1.end()); printList(L2); listL3(L2); printList(L3); listL4(10, 1000); printList(L4); } int main() { test01(); system(\"pause\"); return 0; } 总结：list构造方式同其他几个STL常用容器，熟练掌握即可 3.7.3 list 赋值和交换 功能描述：给list容器进行赋值，以及交换list容器 函数原型 assign(beg, end); //将[beg, end)区间中的数据拷贝赋值给本身。 assign(n, elem); //将n个elem拷贝赋值给本身。 list& operator=(const list &lst); //重载等号操作符 swap(lst); //将lst与本身的元素互换。 示例 #include void printList(const list& L) { for (list::const_iterator it = L.begin(); it != L.end(); it++) { cout L1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); printList(L1); //赋值 listL2; L2 = L1; printList(L2); listL3; L3.assign(L2.begin(), L2.end()); printList(L3); listL4; L4.assign(10, 100); printList(L4); } //交换 void test02() { listL1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); listL2; L2.assign(10, 100); cout 总结：list赋值和交换操作能够灵活运用即可 3.7.4 list 大小操作 功能描述：对list容器的大小进行操作 函数原型 size(); //返回容器中元素的个数 empty(); //判断容器是否为空 resize(num); //重新指定容器的长度为num，若容器变长，则以默认值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除。 resize(num, elem); //重新指定容器的长度为num，若容器变长，则以elem值填充新位置。 //如果容器变短，则末尾超出容器长度的元素被删除。 示例 #include void printList(const list& L) { for (list::const_iterator it = L.begin(); it != L.end(); it++) { cout L1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); if (L1.empty()) { cout 总结： 判断是否为空 --- empty 返回元素个数 --- size 重新指定个数 --- resize 3.7.5 list 插入和删除 功能描述：对list容器进行数据的插入和删除 函数原型 push_back(elem);//在容器尾部加入一个元素 pop_back();//删除容器中最后一个元素 push_front(elem);//在容器开头插入一个元素 pop_front();//从容器开头移除第一个元素 insert(pos,elem);//在pos位置插elem元素的拷贝，返回新数据的位置。 insert(pos,n,elem);//在pos位置插入n个elem数据，无返回值。 insert(pos,beg,end);//在pos位置插入[beg,end)区间的数据，无返回值。 clear();//移除容器的所有数据 erase(beg,end);//删除[beg,end)区间的数据，返回下一个数据的位置。 erase(pos);//删除pos位置的数据，返回下一个数据的位置。 remove(elem);//删除容器中所有与elem值匹配的元素。 示例 #include void printList(const list& L) { for (list::const_iterator it = L.begin(); it != L.end(); it++) { cout L; //尾插 L.push_back(10); L.push_back(20); L.push_back(30); //头插 L.push_front(100); L.push_front(200); L.push_front(300); printList(L); //尾删 L.pop_back(); printList(L); //头删 L.pop_front(); printList(L); //插入 list::iterator it = L.begin(); L.insert(++it, 1000); printList(L); //删除 it = L.begin(); L.erase(++it); printList(L); //移除 L.push_back(10000); L.push_back(10000); L.push_back(10000); printList(L); L.remove(10000); printList(L); //清空 L.clear(); printList(L); } int main() { test01(); system(\"pause\"); return 0; } 总结： 尾插 --- push_back 尾删 --- pop_back 头插 --- push_front 头删 --- pop_front 插入 --- insert 删除 --- erase 移除 --- remove 清空 --- clear 3.7.6 list 数据存取 功能描述：对list容器中数据进行存取 函数原型 front(); //返回第一个元素。 back(); //返回最后一个元素。 示例 #include //数据存取 void test01() { listL1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); //cout ::iterator it = L1.begin(); //it = it + 1;//错误，不可以跳跃访问，即使是+1 } int main() { test01(); system(\"pause\"); return 0; } 总结： list容器中不可以通过[]或者at方式访问数据 返回第一个元素 --- front 返回最后一个元素 --- back 3.7.7 list 反转和排序 功能描述：将容器中的元素反转，以及将容器中的数据进行排序 函数原型 reverse(); //反转链表 sort(); //链表排序 示例 void printList(const list& L) { for (list::const_iterator it = L.begin(); it != L.end(); it++) { cout val2; } //反转和排序 void test01() { list L; L.push_back(90); L.push_back(30); L.push_back(20); L.push_back(70); printList(L); //反转容器的元素 L.reverse(); printList(L); //排序 L.sort(); //默认的排序规则 从小到大 printList(L); L.sort(myCompare); //指定规则，从大到小 printList(L); } int main() { test01(); system(\"pause\"); return 0; } 总结： 反转 --- reverse（成员函数） 排序 --- sort （成员函数） 3.7.8 排序案例 案例描述：将Person自定义数据类型进行排序，Person中属性有姓名、年龄、身高 排序规则：按照年龄进行升序，如果年龄相同按照身高进行降序 示例 #include #include class Person { public: Person(string name, int age , int height) { m_Name = name; m_Age = age; m_Height = height; } public: string m_Name; //姓名 int m_Age; //年龄 int m_Height; //身高 }; bool ComparePerson(Person& p1, Person& p2) { if (p1.m_Age == p2.m_Age) { return p1.m_Height > p2.m_Height; } else { return p1.m_Age L; Person p1(\"刘备\", 35 , 175); Person p2(\"曹操\", 45 , 180); Person p3(\"孙权\", 40 , 170); Person p4(\"赵云\", 25 , 190); Person p5(\"张飞\", 35 , 160); Person p6(\"关羽\", 35 , 200); L.push_back(p1); L.push_back(p2); L.push_back(p3); L.push_back(p4); L.push_back(p5); L.push_back(p6); for (list::iterator it = L.begin(); it != L.end(); it++) { cout m_Name m_Age m_Height ::iterator it = L.begin(); it != L.end(); it++) { cout m_Name m_Age m_Height 总结： 对于自定义数据类型，必须要指定排序规则，否则编译器不知道如何进行排序 高级排序只是在排序规则上再进行一次逻辑规则制定，并不复杂 "},"C++/进阶/03-7-STL常用容器-set-multiset.html":{"url":"C++/进阶/03-7-STL常用容器-set-multiset.html","title":"set-multiset","keywords":"","body":"datetime:2022/11/03 10:32 author:nzb 3 STL- 常用容器 3.8 set/ multiset 容器 3.8.1 set基本概念 简介 所有元素都会在插入时自动被排序 本质 set/multiset属于关联式容器，底层结构是用二叉树实现。 set和multiset区别 set不允许容器中有重复的元素 multiset允许容器中有重复的元素 3.8.2 set构造和赋值 功能描述：创建set容器以及赋值 构造： set st; //默认构造函数： set(const set &st); //拷贝构造函数 赋值： set& operator=(const set &st); //重载等号操作符 示例 #include void printSet(set & s) { for (set::iterator it = s.begin(); it != s.end(); it++) { cout s1; s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); printSet(s1); //拷贝构造 sets2(s1); printSet(s2); //赋值 sets3; s3 = s2; printSet(s3); } int main() { test01(); system(\"pause\"); return 0; } 总结： set容器插入数据时用insert set容器插入数据的数据会自动排序 3.8.3 set大小和交换 功能描述：统计set容器大小以及交换set容器 函数原型 size(); //返回容器中元素的数目 empty(); //判断容器是否为空 swap(st); //交换两个集合容器 示例 #include void printSet(set & s) { for (set::iterator it = s.begin(); it != s.end(); it++) { cout s1; s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); if (s1.empty()) { cout s1; s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); set s2; s2.insert(100); s2.insert(300); s2.insert(200); s2.insert(400); cout 总结： 统计大小 --- size 判断是否为空 --- empty 交换容器 --- swap 3.8.4 set插入和删除 功能描述：set容器进行插入数据和删除数据 函数原型 insert(elem); //在容器中插入元素。 clear(); //清除所有元素 erase(pos); //删除pos迭代器所指的元素，返回下一个元素的迭代器。 erase(beg, end); //删除区间[beg,end)的所有元素 ，返回下一个元素的迭代器。 erase(elem); //删除容器中值为elem的元素。 示例 #include void printSet(set & s) { for (set::iterator it = s.begin(); it != s.end(); it++) { cout s1; //插入 s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); printSet(s1); //删除 s1.erase(s1.begin()); printSet(s1); s1.erase(30); printSet(s1); //清空 //s1.erase(s1.begin(), s1.end()); s1.clear(); printSet(s1); } int main() { test01(); system(\"pause\"); return 0; } 总结： 插入 --- insert 删除 --- erase 清空 --- clear 3.8.5 set查找和统计 功能描述：对set容器进行查找数据以及统计数据 函数原型 find(key); //查找key是否存在,若存在，返回该键的元素的迭代器；若不存在，返回set.end(); count(key); //统计key的元素个数 示例 #include //查找和统计 void test01() { set s1; //插入 s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); //查找 set::iterator pos = s1.find(30); if (pos != s1.end()) { cout 总结： 查找 --- find （返回的是迭代器） 统计 --- count （对于set，结果为0或者1，因为不存在重复值） 3.8.6 set和multiset区别 学习目标 掌握set和multiset的区别 区别 set不可以插入重复数据，而multiset可以 set插入数据的同时会返回插入结果，表示插入是否成功 multiset不会检测数据，因此可以插入重复数据 示例 #include //set和multiset区别 void test01() { set s; pair::iterator, bool> ret = s.insert(10); if (ret.second) { cout ms; ms.insert(10); ms.insert(10); for (multiset::iterator it = ms.begin(); it != ms.end(); it++) { cout 总结： 如果不允许插入重复数据可以利用set 如果需要插入重复数据利用multiset 3.8.7 pair对组创建 功能描述：成对出现的数据，利用对组可以返回两个数据 两种创建方式 pair p ( value1, value2 ); pair p = make_pair( value1, value2 ); 示例 #include //对组创建 void test01() { pair p(string(\"Tom\"), 20); cout p2 = make_pair(\"Jerry\", 10); cout 总结： 两种方式都可以创建对组，记住一种即可 3.8.8 set容器排序 学习目标： set容器默认排序规则为从小到大，掌握如何改变排序规则 主要技术点： 利用仿函数，可以改变排序规则 示例一：set存放内置数据类型 #include class MyCompare { public: bool operator()(int v1, int v2) { return v1 > v2; } }; void test01() { set s1; s1.insert(10); s1.insert(40); s1.insert(20); s1.insert(30); s1.insert(50); //默认从小到大 for (set::iterator it = s1.begin(); it != s1.end(); it++) { cout s2; s2.insert(10); s2.insert(40); s2.insert(20); s2.insert(30); s2.insert(50); for (set::iterator it = s2.begin(); it != s2.end(); it++) { cout 总结：利用仿函数可以指定set容器的排序规则 示例二：set存放自定义数据类型 #include #include class Person { public: Person(string name, int age) { this->m_Name = name; this->m_Age = age; } string m_Name; int m_Age; }; class comparePerson { public: bool operator()(const Person& p1, const Person &p2) { //按照年龄进行排序 降序 return p1.m_Age > p2.m_Age; } }; void test01() { set s; Person p1(\"刘备\", 23); Person p2(\"关羽\", 27); Person p3(\"张飞\", 25); Person p4(\"赵云\", 21); s.insert(p1); s.insert(p2); s.insert(p3); s.insert(p4); for (set::iterator it = s.begin(); it != s.end(); it++) { cout m_Name m_Age 总结： 对于自定义数据类型，set必须指定排序规则才可以插入数据 "},"C++/进阶/03-8-STL常用容器-map-multimap.html":{"url":"C++/进阶/03-8-STL常用容器-map-multimap.html","title":"map-multimap","keywords":"","body":"datetime:2022/11/03 10:32 author:nzb 3 STL- 常用容器 3.9 map/ multimap容器 3.9.1 map基本概念 简介 map中所有元素都是pair pair中第一个元素为key（键值），起到索引作用，第二个元素为value（实值） 所有元素都会根据元素的键值自动排序 本质 map/multimap属于关联式容器，底层结构是用二叉树实现。 优点 可以根据key值快速找到value值 map和multimap区别 map不允许容器中有重复key值元素 multimap允许容器中有重复key值元素 3.9.2 map构造和赋值 功能描述：对map容器进行构造和赋值操作 函数原型 构造 map mp; //map默认构造函数: map(const map &mp); //拷贝构造函数 赋值 map& operator=(const map &mp); //重载等号操作符 示例 #include void printMap(map&m) { for (map::iterator it = m.begin(); it != m.end(); it++) { cout first second m; //默认构造 m.insert(pair(1, 10)); m.insert(pair(2, 20)); m.insert(pair(3, 30)); printMap(m); mapm2(m); //拷贝构造 printMap(m2); mapm3; m3 = m2; //赋值 printMap(m3); } int main() { test01(); system(\"pause\"); return 0; } 总结：map中所有元素都是成对出现，插入数据时候要使用对组 3.9.3 map大小和交换 功能描述：统计map容器大小以及交换map容器 函数原型： size(); //返回容器中元素的数目 empty(); //判断容器是否为空 swap(st); //交换两个集合容器 示例 #include void printMap(map&m) { for (map::iterator it = m.begin(); it != m.end(); it++) { cout first second m; m.insert(pair(1, 10)); m.insert(pair(2, 20)); m.insert(pair(3, 30)); if (m.empty()) { cout m; m.insert(pair(1, 10)); m.insert(pair(2, 20)); m.insert(pair(3, 30)); mapm2; m2.insert(pair(4, 100)); m2.insert(pair(5, 200)); m2.insert(pair(6, 300)); cout 总结： 统计大小 --- size 判断是否为空 --- empty 交换容器 --- swap 3.9.4 map插入和删除 功能描述：map容器进行插入数据和删除数据 函数原型 insert(elem); //在容器中插入元素。 clear(); //清除所有元素 erase(pos); //删除pos迭代器所指的元素，返回下一个元素的迭代器。 erase(beg, end); //删除区间[beg,end)的所有元素 ，返回下一个元素的迭代器。 erase(key); //删除容器中值为key的元素。 示例 #include void printMap(map&m) { for (map::iterator it = m.begin(); it != m.end(); it++) { cout first second m; //第一种插入方式 m.insert(pair(1, 10)); //第二种插入方式 m.insert(make_pair(2, 20)); //第三种插入方式 m.insert(map::value_type(3, 30)); //第四种插入方式, 不建议使用插入，可以用来访问 m[4] = 40; printMap(m); //删除 m.erase(m.begin()); printMap(m); m.erase(3); printMap(m); //清空 m.erase(m.begin(),m.end()); m.clear(); printMap(m); } int main() { test01(); system(\"pause\"); return 0; } 总结： map插入方式很多，记住其一即可 插入 --- insert 删除 --- erase 清空 --- clear 3.9.5 map查找和统计 功能描述：对map容器进行查找数据以及统计数据 函数原型 find(key); //查找key是否存在,若存在，返回该键的元素的迭代器；若不存在，返回set.end(); count(key); //统计key的元素个数(对于map，结果为0或1) 示例 #include //查找和统计 void test01() { mapm; m.insert(pair(1, 10)); m.insert(pair(2, 20)); m.insert(pair(3, 30)); //查找 map::iterator pos = m.find(3); if (pos != m.end()) { cout 总结： 查找 --- find （返回的是迭代器） 统计 --- count （对于map，结果为0或者1） 3.9.6 map容器排序 学习目标：map容器默认排序规则为 按照key值进行 从小到大排序，掌握如何改变排序规则 主要技术点 利用仿函数，可以改变排序规则 示例 #include class MyCompare { public: bool operator()(int v1, int v2) { return v1 > v2; // 降序 } }; void test01() { //默认从小到大排序 //利用仿函数实现从大到小排序 map m; m.insert(make_pair(1, 10)); m.insert(make_pair(2, 20)); m.insert(make_pair(3, 30)); m.insert(make_pair(4, 40)); m.insert(make_pair(5, 50)); for (map::iterator it = m.begin(); it != m.end(); it++) { cout first second 总结： 利用仿函数可以指定map容器的排序规则 对于自定义数据类型，map必须要指定排序规则,同set容器 3.10 案例-员工分组 3.10.1 案例描述 公司今天招聘了10个员工（ABCDEFGHIJ），10名员工进入公司之后，需要指派员工在那个部门工作 员工信息有: 姓名 工资组成；部门分为：策划、美术、研发 随机给10名员工分配部门和工资 通过multimap进行信息的插入 key(部门编号) value(员工) 分部门显示员工信息 3.10.2 实现步骤 创建10名员工，放到vector中 遍历vector容器，取出每个员工，进行随机分组 分组后，将员工部门编号作为key，具体员工作为value，放入到multimap容器中 分部门显示员工信息 案例代码： #include using namespace std; #include #include #include #include /* - 公司今天招聘了10个员工（ABCDEFGHIJ），10名员工进入公司之后，需要指派员工在那个部门工作 - 员工信息有: 姓名 工资组成；部门分为：策划、美术、研发 - 随机给10名员工分配部门和工资 - 通过multimap进行信息的插入 key(部门编号) value(员工) - 分部门显示员工信息 */ #define CEHUA 0 #define MEISHU 1 #define YANFA 2 class Worker { public: string m_Name; int m_Salary; }; void createWorker(vector&v) { string nameSeed = \"ABCDEFGHIJ\"; for (int i = 0; i &v,multimap&m) { for (vector::iterator it = v.begin(); it != v.end(); it++) { //产生随机部门编号 int deptId = rand() % 3; // 0 1 2 //将员工插入到分组中 //key部门编号，value具体员工 m.insert(make_pair(deptId, *it)); } } void showWorkerByGourp(multimap&m) { // 0 A B C 1 D E 2 F G ... cout ::iterator pos = m.find(CEHUA); int count = m.count(CEHUA); // 统计具体人数 int index = 0; for (; pos != m.end() && index second.m_Name second.m_Salary second.m_Name second.m_Salary second.m_Name second.m_Salary vWorker; createWorker(vWorker); //2、员工分组 multimapmWorker; setGroup(vWorker, mWorker); //3、分组显示员工 showWorkerByGourp(mWorker); ////测试 //for (vector::iterator it = vWorker.begin(); it != vWorker.end(); it++) //{ // cout m_Name m_Salary 总结： 当数据以键值对形式存在，可以考虑用map 或 multimap "},"C++/进阶/04-STL函数对象.html":{"url":"C++/进阶/04-STL函数对象.html","title":"STL函数对象","keywords":"","body":"datetime:2022/11/05 15:12 author:nzb 4 STL- 函数对象 4.1 函数对象 4.1.1 函数对象概念 概念 重载函数调用操作符的类，其对象常称为函数对象 函数对象使用重载的()时，行为类似函数调用，也叫仿函数 类似 Python 的 __call__ 魔术方法，实例可调用 本质 函数对象(仿函数)是一个类，不是一个函数 4.1.2 函数对象使用 特点 函数对象在使用时，可以像普通函数那样调用, 可以有参数，可以有返回值 函数对象超出普通函数的概念，函数对象可以有自己的状态 函数对象可以作为参数传递 示例 #include //1、函数对象在使用时，可以像普通函数那样调用, 可以有参数，可以有返回值 class MyAdd { public : int operator()(int v1,int v2) { return v1 + v2; } }; void test01() { MyAdd myAdd; cout 总结： 仿函数写法非常灵活，可以作为参数进行传递。 4.2 谓词 4.2.1 谓词概念 概念 返回bool类型的仿函数称为谓词 如果operator()接受一个参数，那么叫做一元谓词 如果operator()接受两个参数，那么叫做二元谓词 4.2.2 一元谓词 示例 #include #include //1.一元谓词 struct GreaterFive{ bool operator()(int val) { return val > 5; } }; void test01() { vector v; for (int i = 0; i ::iterator it = find_if(v.begin(), v.end(), GreaterFive()); if (it == v.end()) { cout 总结：参数只有一个的谓词，称为一元谓词 4.2.3 二元谓词 示例 #include #include //二元谓词 class MyCompare { public: bool operator()(int num1, int num2) { return num1 > num2; } }; void test01() { vector v; v.push_back(10); v.push_back(40); v.push_back(20); v.push_back(30); v.push_back(50); //默认从小到大 sort(v.begin(), v.end()); for (vector::iterator it = v.begin(); it != v.end(); it++) { cout ::iterator it = v.begin(); it != v.end(); it++) { cout 总结：参数只有两个的谓词，称为二元谓词 4.3 内建函数对象 4.3.1 内建函数对象意义 概念 STL内建了一些函数对象 分类 算术仿函数 关系仿函数 逻辑仿函数 用法 这些仿函数所产生的对象，用法和一般函数完全相同 使用内建函数对象，需要引入头文件 #include 4.3.2 算术仿函数 功能描述 实现四则运算 其中negate是一元运算，其他都是二元运算 仿函数原型 template T plus //加法仿函数 template T minus //减法仿函数 template T multiplies //乘法仿函数 template T divides //除法仿函数 template T modulus //取模仿函数 template T negate //取反仿函数 示例 #include //negate void test01() { negate n; cout p; cout 总结：使用内建函数对象时，需要引入头文件 #include 4.3.3 关系仿函数 功能描述：实现关系对比 仿函数原型 template bool equal_to //等于 template bool not_equal_to //不等于 template bool greater //大于 template bool greater_equal //大于等于 template bool less //小于 template bool less_equal //小于等于 示例 #include #include #include class MyCompare { public: bool operator()(int v1,int v2) { return v1 > v2; } }; void test01() { vector v; v.push_back(10); v.push_back(30); v.push_back(50); v.push_back(40); v.push_back(20); for (vector::iterator it = v.begin(); it != v.end(); it++) { cout ()); for (vector::iterator it = v.begin(); it != v.end(); it++) { cout 总结：关系仿函数中最常用的就是greater<>大于 4.3.4 逻辑仿函数 功能描述：实现逻辑运算 函数原型 template bool logical_and //逻辑与 template bool logical_or //逻辑或 template bool logical_not //逻辑非 示例 #include #include #include void test01() { vector v; v.push_back(true); v.push_back(false); v.push_back(true); v.push_back(false); for (vector::iterator it = v.begin();it!= v.end();it++) { cout v2; v2.resize(v.size()); // 需指定大小，否则 transform 是不能操作的 transform(v.begin(), v.end(), v2.begin(), logical_not()); for (vector::iterator it = v2.begin(); it != v2.end(); it++) { cout 总结：逻辑仿函数实际应用较少，了解即可 "},"C++/进阶/05-1-STL常用算法-遍历.html":{"url":"C++/进阶/05-1-STL常用算法-遍历.html","title":"遍历","keywords":"","body":"datetime:2022/11/05 15:42 author:nzb 5 STL- 常用算法 概述 算法主要是由头文件 组成。 是所有STL头文件中最大的一个，范围涉及到比较、 交换、查找、遍历操作、复制、修改等等 体积很小，只包括几个在序列上面进行简单数学运算的模板函数 定义了一些模板类,用以声明函数对象。 5.1 常用遍历算法 学习目标：掌握常用的遍历算法 算法简介 for_each //遍历容器 transform //搬运容器到另一个容器中 5.1.1 for_each 功能描述：实现遍历容器 函数原型 for_each(iterator beg, iterator end, _func); 遍历算法 遍历容器元素 beg 开始迭代器 end 结束迭代器 _func 函数或者函数对象 示例 #include #include //普通函数 void print01(int val) { cout v; for (int i = 0; i 总结：for_each在实际开发中是最常用遍历算法，需要熟练掌握 5.1.2 transform 功能描述：搬运容器到另一个容器中 函数原型 transform(iterator beg1, iterator end1, iterator beg2, _func); beg1 源容器开始迭代器 end1 源容器结束迭代器 beg2 目标容器开始迭代器 _func 函数或者函数对象 示例 #include #include //常用遍历算法 搬运 transform class TransForm { public: int operator()(int val) { return val; } }; class MyPrint { public: void operator()(int val) { cout v; for (int i = 0; i vTarget; //目标容器 vTarget.resize(v.size()); // 目标容器需要提前开辟空间 transform(v.begin(), v.end(), vTarget.begin(), TransForm()); for_each(vTarget.begin(), vTarget.end(), MyPrint()); } int main() { test01(); system(\"pause\"); return 0; } 总结：搬运的目标容器必须要提前开辟空间，否则无法正常搬运 "},"C++/进阶/05-2-STL常用算法-查找.html":{"url":"C++/进阶/05-2-STL常用算法-查找.html","title":"查找","keywords":"","body":"datetime:2022/11/05 15:42 author:nzb 5 STL- 常用算法 概述 算法主要是由头文件 组成。 是所有STL头文件中最大的一个，范围涉及到比较、 交换、查找、遍历操作、复制、修改等等 体积很小，只包括几个在序列上面进行简单数学运算的模板函数 定义了一些模板类,用以声明函数对象。 5.2 常用查找算法 学习目标：掌握常用的查找算法 算法简介 find //查找元素 find_if //按条件查找元素 adjacent_find //查找相邻重复元素 binary_search //二分查找法 count //统计元素个数 count_if //按条件统计元素个数 5.2.1 find 功能描述：查找指定元素，找到返回指定元素的迭代器，找不到返回结束迭代器end() 函数原型 find(iterator beg, iterator end, value); 按值查找元素，找到返回指定位置迭代器，找不到返回结束迭代器位置 beg 开始迭代器 end 结束迭代器 value 查找的元素 示例 #include #include #include void test01() { vector v; for (int i = 0; i ::iterator it = find(v.begin(), v.end(), 5); if (it == v.end()) { cout m_Name = name; this->m_Age = age; } //重载== bool operator==(const Person& p) { if (this->m_Name == p.m_Name && this->m_Age == p.m_Age) { return true; } return false; } public: string m_Name; int m_Age; }; void test02() { vector v; //创建数据 Person p1(\"aaa\", 10); Person p2(\"bbb\", 20); Person p3(\"ccc\", 30); Person p4(\"ddd\", 40); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); vector::iterator it = find(v.begin(), v.end(), p2); if (it == v.end()) { cout m_Name m_Age 总结： 利用find可以在容器中找指定的元素，返回值是迭代器 5.2.2 find_if 功能描述：按条件查找元素 函数原型 find_if(iterator beg, iterator end, _Pred); 按值查找元素，找到返回指定位置迭代器，找不到返回结束迭代器位置 beg 开始迭代器 end 结束迭代器 _Pred 函数或者谓词（返回bool类型的仿函数） 示例 #include #include #include //内置数据类型 class GreaterFive { public: bool operator()(int val) { return val > 5; } }; void test01() { vector v; for (int i = 0; i ::iterator it = find_if(v.begin(), v.end(), GreaterFive()); if (it == v.end()) { cout m_Name = name; this->m_Age = age; } public: string m_Name; int m_Age; }; class Greater20 { public: bool operator()(Person &p) { return p.m_Age > 20; } }; void test02() { vector v; //创建数据 Person p1(\"aaa\", 10); Person p2(\"bbb\", 20); Person p3(\"ccc\", 30); Person p4(\"ddd\", 40); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); vector::iterator it = find_if(v.begin(), v.end(), Greater20()); if (it == v.end()) { cout m_Name m_Age 总结：find_if按条件查找使查找更加灵活，提供的仿函数可以改变不同的策略 5.2.3 adjacent_find 功能描述：查找相邻重复元素 函数原型 adjacent_find(iterator beg, iterator end); 查找相邻重复元素,返回相邻元素的第一个位置的迭代器 beg 开始迭代器 end 结束迭代器 示例 #include #include void test01() { vector v; v.push_back(1); v.push_back(2); v.push_back(5); v.push_back(2); v.push_back(4); v.push_back(4); v.push_back(3); //查找相邻重复元素 vector::iterator it = adjacent_find(v.begin(), v.end()); if (it == v.end()) { cout 总结：面试题中如果出现查找相邻重复元素，记得用STL中的adjacent_find算法 5.2.4 binary_search 功能描述：查找指定元素是否存在 函数原型 bool binary_search(iterator beg, iterator end, value); 查找指定的元素，查到 返回true 否则false beg 开始迭代器 end 结束迭代器 value 查找的元素 注意: 在无序序列中不可用 示例 #include #include void test01() { vectorv; for (int i = 0; i 总结：二分查找法查找效率很高，值得注意的是查找的容器中元素必须的有序序列 5.2.5 count 功能描述：统计元素个数 函数原型 count(iterator beg, iterator end, value); 统计元素出现次数 beg 开始迭代器 end 结束迭代器 value 统计的元素 示例 #include #include //内置数据类型 void test01() { vector v; v.push_back(1); v.push_back(2); v.push_back(4); v.push_back(5); v.push_back(3); v.push_back(4); v.push_back(4); int num = count(v.begin(), v.end(), 4); cout m_Name = name; this->m_Age = age; } bool operator==(const Person & p) { if (this->m_Age == p.m_Age) { return true; } else { return false; } } string m_Name; int m_Age; }; void test02() { vector v; Person p1(\"刘备\", 35); Person p2(\"关羽\", 35); Person p3(\"张飞\", 35); Person p4(\"赵云\", 30); Person p5(\"曹操\", 25); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); v.push_back(p5); Person p(\"诸葛亮\",35); int num = count(v.begin(), v.end(), p); cout 总结： 统计自定义数据类型时候，需要配合重载 operator== 5.2.6 count_if 功能描述：按条件统计元素个数 函数原型 count_if(iterator beg, iterator end, _Pred); 按条件统计元素出现次数 beg 开始迭代器 end 结束迭代器 _Pred 谓词 示例 #include #include class Greater4 { public: bool operator()(int val) { return val >= 4; } }; //内置数据类型 void test01() { vector v; v.push_back(1); v.push_back(2); v.push_back(4); v.push_back(5); v.push_back(3); v.push_back(4); v.push_back(4); int num = count_if(v.begin(), v.end(), Greater4()); cout m_Name = name; this->m_Age = age; } string m_Name; int m_Age; }; class AgeLess35 { public: bool operator()(const Person &p) { return p.m_Age v; Person p1(\"刘备\", 35); Person p2(\"关羽\", 35); Person p3(\"张飞\", 35); Person p4(\"赵云\", 30); Person p5(\"曹操\", 25); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); v.push_back(p5); int num = count_if(v.begin(), v.end(), AgeLess35()); cout 总结：按值统计用count，按条件统计用count_if "},"C++/进阶/05-3-STL常用算法-排序.html":{"url":"C++/进阶/05-3-STL常用算法-排序.html","title":"排序","keywords":"","body":"datetime:2022/11/05 15:42 author:nzb 5 STL- 常用算法 概述 算法主要是由头文件 组成。 是所有STL头文件中最大的一个，范围涉及到比较、 交换、查找、遍历操作、复制、修改等等 体积很小，只包括几个在序列上面进行简单数学运算的模板函数 定义了一些模板类,用以声明函数对象。 5.3 常用排序算法 学习目标：掌握常用的排序算法 算法简介 sort //对容器内元素进行排序 random_shuffle //洗牌 指定范围内的元素随机调整次序 merge // 容器元素合并，并存储到另一容器中 reverse // 反转指定范围的元素 5.3.1 sort 功能描述：对容器内元素进行排序 函数原型 sort(iterator beg, iterator end, _Pred); 按值查找元素，找到返回指定位置迭代器，找不到返回结束迭代器位置 beg 开始迭代器 end 结束迭代器 _Pred 谓词 示例 #include #include void myPrint(int val) { cout v; v.push_back(10); v.push_back(30); v.push_back(50); v.push_back(20); v.push_back(40); //sort默认从小到大排序 sort(v.begin(), v.end()); for_each(v.begin(), v.end(), myPrint); cout ()); for_each(v.begin(), v.end(), myPrint); cout 总结：sort属于开发中最常用的算法之一，需熟练掌握 5.3.2 random_shuffle 功能描述：洗牌 指定范围内的元素随机调整次序 函数原型 random_shuffle(iterator beg, iterator end); 指定范围内的元素随机调整次序 beg 开始迭代器 end 结束迭代器 示例 #include #include #include class myPrint { public: void operator()(int val) { cout v; for(int i = 0 ; i 总结：random_shuffle洗牌算法比较实用，使用时记得加随机数种子 5.3.3 merge 功能描述：两个容器元素合并，并存储到另一容器中 函数原型 merge(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest); 容器元素合并，并存储到另一容器中 beg1 容器1开始迭代器 end1 容器1结束迭代器 beg2 容器2开始迭代器 end2 容器2结束迭代器 dest 目标容器开始迭代器 注意: 两个容器必须是有序的 示例 #include #include class myPrint { public: void operator()(int val) { cout v1; vector v2; for (int i = 0; i vtarget; //目标容器需要提前开辟空间 vtarget.resize(v1.size() + v2.size()); //合并 需要两个有序序列 merge(v1.begin(), v1.end(), v2.begin(), v2.end(), vtarget.begin()); for_each(vtarget.begin(), vtarget.end(), myPrint()); cout 总结：merge合并的两个容器必须的有序序列 5.3.4 reverse 功能描述：将容器内元素进行反转 函数原型 reverse(iterator beg, iterator end); 反转指定范围的元素 beg 开始迭代器 end 结束迭代器 示例 #include #include class myPrint { public: void operator()(int val) { cout v; v.push_back(10); v.push_back(30); v.push_back(50); v.push_back(20); v.push_back(40); cout 总结：reverse反转区间内元素，面试题可能涉及到 "},"C++/进阶/05-4-STL常用算法-拷贝替换.html":{"url":"C++/进阶/05-4-STL常用算法-拷贝替换.html","title":"拷贝替换","keywords":"","body":"datetime:2022/11/05 15:42 author:nzb 5 STL- 常用算法 概述 算法主要是由头文件 组成。 是所有STL头文件中最大的一个，范围涉及到比较、 交换、查找、遍历操作、复制、修改等等 体积很小，只包括几个在序列上面进行简单数学运算的模板函数 定义了一些模板类,用以声明函数对象。 5.4 常用拷贝和替换算法 学习目标：掌握常用的拷贝和替换算法 算法简介 copy // 容器内指定范围的元素拷贝到另一容器中 replace // 将容器内指定范围的旧元素修改为新元素 replace_if // 容器内指定范围满足条件的元素替换为新元素 swap // 互换两个容器的元素 5.4.1 copy 功能描述：容器内指定范围的元素拷贝到另一容器中 函数原型 copy(iterator beg, iterator end, iterator dest); 按值查找元素，找到返回指定位置迭代器，找不到返回结束迭代器位置 beg 开始迭代器 end 结束迭代器 dest 目标起始迭代器 示例 #include #include class myPrint { public: void operator()(int val) { cout v1; for (int i = 0; i v2; v2.resize(v1.size()); copy(v1.begin(), v1.end(), v2.begin()); for_each(v2.begin(), v2.end(), myPrint()); cout 总结：利用copy算法在拷贝时，目标容器记得提前开辟空间 5.4.2 replace 功能描述：将容器内指定范围的旧元素修改为新元素 函数原型 replace(iterator beg, iterator end, oldvalue, newvalue); 将区间内旧元素 替换成 新元素 beg 开始迭代器 end 结束迭代器 oldvalue 旧元素 newvalue 新元素 示例 #include #include class myPrint { public: void operator()(int val) { cout v; v.push_back(20); v.push_back(30); v.push_back(20); v.push_back(40); v.push_back(50); v.push_back(10); v.push_back(20); cout 总结：replace会替换区间内满足条件的元素 5.4.3 replace_if 功能描述: 将区间内满足条件的元素，替换成指定元素 函数原型 replace_if(iterator beg, iterator end, _pred, newvalue); 按条件替换元素，满足条件的替换成指定元素 beg 开始迭代器 end 结束迭代器 _pred 谓词 newvalue 替换的新元素 示例 #include #include class myPrint { public: void operator()(int val) { cout = 30; } }; void test01() { vector v; v.push_back(20); v.push_back(30); v.push_back(20); v.push_back(40); v.push_back(50); v.push_back(10); v.push_back(20); cout 总结：replace_if按条件查找，可以利用仿函数灵活筛选满足的条件 5.4.4 swap 功能描述：互换两个容器的元素 函数原型 swap(container c1, container c2); 互换两个容器的元素 c1容器1 c2容器2 示例 #include #include class myPrint { public: void operator()(int val) { cout v1; vector v2; for (int i = 0; i 总结：swap交换容器时，注意交换的容器要同种类型 "},"C++/进阶/05-5-STL常用算法-算术生成.html":{"url":"C++/进阶/05-5-STL常用算法-算术生成.html","title":"算术生成","keywords":"","body":"datetime:2022/11/05 15:42 author:nzb 5 STL- 常用算法 概述 算法主要是由头文件 组成。 是所有STL头文件中最大的一个，范围涉及到比较、 交换、查找、遍历操作、复制、修改等等 体积很小，只包括几个在序列上面进行简单数学运算的模板函数 定义了一些模板类,用以声明函数对象。 5.5 常用算术生成算法 学习目标：掌握常用的算术生成算法 注意 算术生成算法属于小型算法，使用时包含的头文件为 #include 算法简介 accumulate // 计算容器元素累计总和 fill // 向容器中添加元素 5.5.1 accumulate 功能描述：计算区间内 容器元素累计总和 函数原型 accumulate(iterator beg, iterator end, value); 计算容器元素累计总和 beg 开始迭代器 end 结束迭代器 value 起始值 示例 #include #include void test01() { vector v; for (int i = 0; i 总结：accumulate使用时头文件注意是 numeric，这个算法很实用 5.5.2 fill 功能描述：向容器中填充指定的元素 函数原型 fill(iterator beg, iterator end, value); 向容器中填充元素 beg 开始迭代器 end 结束迭代器 value 填充的值 示例 #include #include #include class myPrint { public: void operator()(int val) { cout v; v.resize(10); //填充 fill(v.begin(), v.end(), 100); for_each(v.begin(), v.end(), myPrint()); cout 总结：利用fill可以将容器区间内元素填充为 指定的值 "},"C++/进阶/05-6-STL常用算法-集合算法.html":{"url":"C++/进阶/05-6-STL常用算法-集合算法.html","title":"集合算法","keywords":"","body":"datetime:2022/11/05 15:42 author:nzb 5 STL- 常用算法 概述 算法主要是由头文件 组成。 是所有STL头文件中最大的一个，范围涉及到比较、 交换、查找、遍历操作、复制、修改等等 体积很小，只包括几个在序列上面进行简单数学运算的模板函数 定义了一些模板类,用以声明函数对象。 5.6 常用集合算法 学习目标：掌握常用的集合算法 算法简介 set_intersection // 求两个容器的交集 set_union // 求两个容器的并集 set_difference // 求两个容器的差集 5.6.1 set_intersection 功能描述：求两个容器的交集 函数原型 set_intersection(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest); 求两个集合的交集 beg1 容器1开始迭代器 end1 容器1结束迭代器 beg2 容器2开始迭代器 end2 容器2结束迭代器 dest 目标容器开始迭代器 注意:两个集合必须是有序序列 示例 #include #include class myPrint { public: void operator()(int val) { cout v1; vector v2; for (int i = 0; i vTarget; //取两个里面较小的值给目标容器开辟空间 vTarget.resize(min(v1.size(), v2.size())); //返回目标容器的最后一个元素的迭代器地址 vector::iterator itEnd = set_intersection(v1.begin(), v1.end(), v2.begin(), v2.end(), vTarget.begin()); for_each(vTarget.begin(), itEnd, myPrint()); cout 总结 求交集的两个集合必须的有序序列 目标容器开辟空间需要从两个容器中取小值 set_intersection返回值既是交集中最后一个元素的位置 5.6.2 set_union 功能描述：求两个集合的并集 函数原型 set_union(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest); 求两个集合的并集 beg1 容器1开始迭代器 end1 容器1结束迭代器 beg2 容器2开始迭代器 end2 容器2结束迭代器 dest 目标容器开始迭代器 注意:两个集合必须是有序序列 示例 #include #include class myPrint { public: void operator()(int val) { cout v1; vector v2; for (int i = 0; i vTarget; //取两个容器的和给目标容器开辟空间 vTarget.resize(v1.size() + v2.size()); //返回目标容器的最后一个元素的迭代器地址 vector::iterator itEnd = set_union(v1.begin(), v1.end(), v2.begin(), v2.end(), vTarget.begin()); for_each(vTarget.begin(), itEnd, myPrint()); cout 总结 求并集的两个集合必须的有序序列 目标容器开辟空间需要两个容器相加 set_union返回值既是并集中最后一个元素的位置 5.6.3 set_difference 功能描述：求两个集合的差集 函数原型 set_difference(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest); 求两个集合的差集 beg1 容器1开始迭代器 end1 容器1结束迭代器 beg2 容器2开始迭代器 end2 容器2结束迭代器 dest 目标容器开始迭代器 注意:两个集合必须是有序序列 示例 #include #include class myPrint { public: void operator()(int val) { cout v1; vector v2; for (int i = 0; i vTarget; //取两个里面较大的值给目标容器开辟空间 vTarget.resize( max(v1.size() , v2.size())); //返回目标容器的最后一个元素的迭代器地址 cout ::iterator itEnd = set_difference(v1.begin(), v1.end(), v2.begin(), v2.end(), vTarget.begin()); for_each(vTarget.begin(), itEnd, myPrint()); cout 总结 求差集的两个集合必须的有序序列 目标容器开辟空间需要从两个容器取较大值 set_difference返回值既是差集中最后一个元素的位置 "},"C++/Linux环境编程/01-gdb调试.html":{"url":"C++/Linux环境编程/01-gdb调试.html","title":"gdb调试","keywords":"","body":"datetime:2022/12/17 16:07 author:nzb gdb调试 gdb的安装 CentOS系统中，用root用户登录服务器，执行以下命令安装或升级。 yum -y install gdb 注意，如果您的服务器没有安装gdb，以上命令就会安装最新版本的gdb，如果已经安装了gdb，就会更新到最新版本的gdb，所以，以上命令不管执行多少次都没有问题。 安装gdb，前提条件是服务器必须接入互联网。 调试前的准备 用gcc编译源程序的时候，编译后的可执行文件不会包含源程序代码，如果您打算编译后的程序可以被调试，编译的时候要加-g的参数，例如： gcc -g -o book113 book113.c 在命令提示符下输入gdb book113就可以调试book113程序了。 gdb book113 基本调试命令 命令 命令缩写 命令说明 set args 设置主程序的参数。例如：./book119 /oracle/c/book1.c /tmp/book1.c 设置参数的方法是：gdb book119(gdb) set args /oracle/c/book1.c /tmp/book1.c break b 设置断点，b 20 表示在第20行设置断点，可以设置多个断点。 run r 开始运行程序, 程序运行到断点的位置会停下来，如果没有遇到断点，程序一直运行下去。 next n 执行当前行语句，如果该语句为函数调用，不会进入函数内部执行。 step s 执行当前行语句，如果该语句为函数调用，则进入函数执行其中的第一条语句。注意了，如果函数是库函数或第三方提供的函数，用s也是进不去的，因为没有源代码，如果是您自定义的函数，只要有源码就可以进去。 print p 显示变量值，例如：p name表示显示变量name的值。 continue c 继续程序的运行，直到遇到下一个断点。 set var name=value 设置变量的值，假设程序有两个变量：int ii; char name[21];set var ii=10 把ii的值设置为10；set var name=\"西施\" 把name的值设置为\"西施\"，注意，不是strcpy。 quit q 退出gdb环境。 注意，在gdb环境中，可以用上下光标键选择执行过的gdb命令。 调试core文件 程序挂掉时，系统缺省不会生成core文件 ulimit -a: 查看系统参数 ulimit -c unlimit: 把 core 文件的大小设置为无限制 运行文件，生成core文件 gdb 程序名 core文件名 root@7bae19ca1bcd:~/c++/gdb# ./core_demo Segmentation fault (core dumped) # 报错生成 core 文件 root@7bae19ca1bcd:~/c++/gdb# ls core core_demo core_dmeo.cpp root@7bae19ca1bcd:~/c++/gdb# gdb core_demo core GNU gdb (Debian 7.7.1+dfsg-5) 7.7.1 Copyright (C) 2014 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: . Find the GDB manual and other documentation resources online at: . For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from core_demo...done. [New LWP 43] Core was generated by `./core_demo'. Program terminated with signal SIGSEGV, Segmentation fault. #0 0x00000000004005dc in bb (bbb=13) at core_dmeo.cpp:10 10 *p = bbb; // 报错行 (gdb) bt // bt，显示调用栈 #0 0x00000000004005dc in bb (bbb=13) at core_dmeo.cpp:10 #1 0x00000000004005f5 in aa (aaa=13) at core_dmeo.cpp:15 #2 0x0000000000400609 in main () at core_dmeo.cpp:20 (gdb) 调试正在运行的程序 调试多进程服务程序 调试多线程服务程序 参考链接 "},"C++/Linux环境编程/02-make和Makefile.html":{"url":"C++/Linux环境编程/02-make和Makefile.html","title":"make和Makefile","keywords":"","body":"datetime:2022/12/19 10:34 author:nzb make和Makefile 在软件的工程中的源文件是很多的，其按照类型、功能、模块分别放在若干个目录和文件中，哪些文件需要编译，那些文件需要后编译，那些文件需要重新编译，甚至进行更复杂的功能操作，这就有了我们的系统编译的工具。 在linux和unix中，有一个强大的实用程序，叫make，可以用它来管理多模块程序的编译和链接，直至生成可执行文件。 make程序需要一个编译规则说明文件，称为makefile，makefile文件中描述了整个软件工程的编译规则和各个文件之间的依赖关系。 makefile就像是一个shell脚本一样，其中可以执行操作系统的命令，它带来的好处就是我们能够实现“自动化编译”，一旦写好，只要一个make命令，整个软件功能就完全自动编译，提高了软件开发的效率。 make是一个命令工具，是一个解释makefile中指令的命令工具，一般来说大多数编译器都有这个命令，使用make可以是重新编译的次数达到最小化。 一、makefile的编写 makefile文件的规则可以非常复杂，比C程序还要复杂，我通过示例来介绍它的简单用法。 文件名：makefile，内容如下： all:book1 book46 book1:book1.c gcc -o book1 book1.c book46:book46.c _public.h _public.c gcc -o book46 book46.c _public.c clean: rm -f book1 book46 第一行: all:book book46 all: 这是固定的写法。 book1 book46表示需要编译目标程序的清单，中间用空格分隔开，如果清单很长，可以用\\换行。 第二行: makefile文件中的空行就像C程序中的空行一样，只是为了书写整洁，没有什么意义。 第三行: book1:book1.c book1: 表示需要编译的目标程序。 如果要编译目标程序book1，需要依赖源程序book1.c，当book1.c的内容发生了变化，执行make的时候就会重新编译book1。 第四行: gcc -o book1 book1.c 这是一个编译命令，和在操作系统命令行输入的命令一样，但是要注意一个问题，在gcc之前要用tab键，看上去像8个空格，实际不是，一定要用tab，空格不行。 第六行: book46:book46.c _public.h _public.c 与第三行的含义相同。 book46: 表示编译的目标程序。 如果要编译目标程序book46，需要依赖源程序book46.c、_public.h和_public.c三个文件，只要任何一个的内容发生了变化，执行make的时候就会重新编译book46。 第七行: gcc -o book46 book46.c _public.c与第四行的含义相同。 第九行: clean 清除目标文件，清除的命令由第十行之后的脚本来执行。 第十行: rm -f book1 book46清除目标文件的脚本命令，注意了，rm之前也是一个tab键，不是空格。 二、make命令 makefile准备好了，在命令提示符下执行make就可以编译makefile中all参数指定的目标文件。 执行make编译目标程序： 再执行一次make： 因为全部的目标程序都是最新的，所以提示没有目标可以编译。 执行make clean，执行清除目标文件的指令。 再执行make重新编译。 修改_public.c程序，随便改点什么，只要改了就行。 然后再执行make： 注意了，因为book46依赖的源程序之一_public.c改变了，所以book46重新编译。 book1没有重新编译，因为book1依赖的源文件并没有改变。 三、makefile文件中的变量 makefile中，变量就是一个名字，变量的值就是一个文本字符串。在makefile中的目标，依赖，命令或其他地方引用变量时，变量会被它的值替代。 我通过示例来介绍它的简单用法。 第一行: CC=gcc定义变量CC，赋值gcc。 第二行: FLAG=-g 定义变量FLAG，赋值-g。 第七行: $(CC) $(FLAG) -o book1 book1.c $(CC)和$(FLAG)就是使用变量CC和FLAG的值，类似于C语言的宏定义，替换后的结果是：gcc -g -o book1 book1.c编译效果： 在makefile文件中，使用变量的好处有两个 1）如果在很多编译指令采用了变量，只要修改变量的值，就相当于修改全部的编译指令； 2）把比较长的、公共的编译指令采用变量来表示，可以让makefile更简洁。 "},"C++/Linux环境编程/03-CMakeLists入门.html":{"url":"C++/Linux环境编程/03-CMakeLists入门.html","title":"CMakeLists入门","keywords":"","body":"datetime:2023/04/12 14:45 author:nzb CMakeLists入门 makefile文件的编写实在是个繁琐的事，于是，CMake出现了，使得这一切变得简单，CMake通过CMakeLists.txt读入所有源文件自动生成makefile，进而将源文件编译成可执行文件或库文件 一、CMake常用的命令 # 设置cmake最低版本 cmake_minimum_required(VERSION 3.2) # project命令用于指定cmake工程的名称，实际上，它还可以指定cmake工程的版本号（VERSION关键字）、简短的描述（DESCRIPTION关键字）、主页URL（HOMEPAGE_URL关键字）和编译工程使用的语言（LANGUAGES关键字） # project( [...]) # project( [VERSION [.[.[.]]]] [DESCRIPTION ][HOMEPAGE_URL ] [LANGUAGES ...]) # ${PROJECT_SOURCE_DIR} 和 _SOURCE_DIR：本CMakeLists.txt所在的文件夹路径 # ${PROJECT_NAME}：本CMakeLists.txt的project名称 project(xxx) project(mytest VERSION 1.2.3.4) project (mytest HOMEPAGE_URL “https://www.XXX(示例).com”) # 获取路径下所有的.cpp/.c/.cc文件（不包括子目录），并赋值给变量中 aux_source_directory(路径 变量) # GLOB 获取目录下的所有cpp文件（不包括子目录），并赋值给SOURCES file( GLOB SOURCES ${PROJECT_SOURCE_DIR}/*.c ) # GLOB_RECURSE 获取目录下的所有cpp文件（包括子目录），并赋值给NATIVE_SRC file( GLOB_RECURSE NATIVE_SRC ${PROJECT_SOURCE_DIR}/lib/*.cpp ) # 给文件名/路径名或其他字符串起别名，用${变量}获取变量内容 set(变量 文件名/路径/...) # 添加编译选项FOO BAR # add_definitions定义宏，但是这种定义方式无法给宏具体值 等价C语言中的#define MG_ENABLE_OPENSSL add_definitions(-DFOO -DBAR ...) # add_compile_definitions定义宏，这种方式可以给宏具体值，但是这个指令只要高版本的cmake支持 等价C语言中 #define MG_ENABLE_OPENSSL 1 add_compile_definitions(MG_ENABLE_OPENSSL=1) # 打印消息 message(消息) # 编译子文件夹的CMakeLists.txt add_subdirectory(子文件夹名称) # 将.cpp/.c/.cc文件生成.a静态库 # 注意，库文件名称通常为libxxx.so，在这里只要写xxx即可 add_library(库文件名称 STATIC 文件) # 将.cpp/.c/.cc文件生成可执行文件 add_executable(可执行文件名称 文件) # 规定.h头文件路径 include_directories(路径) # 规定.so/.a库文件路径 link_directories(路径) # 设置编译选项及默认值 option(TEST_DEBUG \"option for debug\" OFF) # 对add_library或add_executable生成的文件进行链接操作 # 注意，库文件名称通常为libxxx.so，在这里只要写xxx即可 target_link_libraries(库文件名称/可执行文件名称 链接的库文件名称) 通常一个CMakeLists.txt需按照下面的流程： project(xxx) #必须 add_subdirectory(子文件夹名称) #父目录必须，子目录不必 add_library(库文件名称 STATIC 文件) #通常子目录(二选一) add_executable(可执行文件名称 文件) #通常父目录(二选一) include_directories(路径) #必须 link_directories(路径) #必须 target_link_libraries(库文件名称/可执行文件名称 链接的库文件名称) #必须 二、CMakeLists实例 示例1：只有一个源文件main.c 目录结构如下： + | +--- main.c +--- CMakeLists.txt | 代码如下： // main.c #include int main() { printf(\"hello world\"); return 0; } # CMakeLists cmake_minimum_required(VERSION 3.0) project(HELLO VERSION 1.0 LANGUAGES C CXX) set(SOURCES main.c) add_executable(hello ${SOURCES}) ⚠️警告：project设置VERSION,要求cmake的最低版本3.0 注意： 为了简单起见，我们从一开始就采用cmake的 out-of-source 方式来构建（即生成中间产物与源代码分离），并始终坚持这种方法，这也就是此处为什么单独创建一个目录，然后在该目录下执行 cmake 的原因 在CMakeLists.txt目录下执行以下命令 mkdir build cd build cmake .. make 即可生成可执行程序 hello(.exe)目录结构如下 + | +--- main.c +--- CMakeLists.txt | /--+ build/ | +--- hello(exec) project 会引入两个变量HELLO_BINARY_DIR 和 HELLO_SOURCE_DIR，这两个变量和PROJECT_BINARY_DIR 和 PROJECT_SOURCE_DIR等价 message(${PROJECT_SOURCE_DIR})打印变量的值 set 命令用来设置变量 add_exectuable 告诉工程生成一个可执行文件。 add_library 则告诉生成一个库文件 示例2：拆成3个文件 hello.h hello.c main.c 目录结构如下： + | +--- main.c +--- hello.h +--- hello.c +--- CMakeLists.txt | 代码如下： // main.c #include \"hello.h\" int main() { hello(\"World\"); return 0; } // hello.h #ifndef DBZHANG_HELLO_ #define DBZHANG_HELLO_ void hello(const char* name); #endif //DBZHANG_HELLO_ // hello.c #include #include \"hello.h\" void hello(const char * name) { printf (\"Hello %s! \\n\", name); } # CMakeLists cmake_minimum_required(VERSION 3.0) project(HELLO VERSION 1.0 LANGUAGES C CXX) set(SOURCES hello.c main.c) add_executable(hello ${SOURCES}) 执行cmake的过程同上，目录结构 + | +--- main.c +--- hello.h +--- hello.c +--- CMakeLists.txt | /--+ build/ | +--- hello(exec) 示例3：在示例2的基础上，先将 hello.c 生成一个库hellolib，再给main.c使用 我们只需修改下CMakeLists即可 # CMakeLists cmake_minimum_required(VERSION 3.0) project(HELLO VERSION 1.0 LANGUAGES C CXX) set(LIB_SRC hello.c) add_library(libhello ${LIB_SRC}) set(APP_SRC main.c) add_executable(hello ${APP_SRC}) target_link_libraries(hello libhello) 执行cmake的过程同上，目录结构如下 + | +--- main.c +--- hello.h +--- hello.c +--- CMakeLists.txt | /--+ build/ | +--- liblibhello.a +--- hello(exec) target_link_libraries 该指令的作用为将目标文件与库文件进行链接。该指令的语法如下： target_link_libraries( [item1] [item2] [...] [[debug|optimized|general] ] ...) 上述指令中的是指通过add_executable()和add_library()指令生成已经创建的目标文件。 而[item] 表示库文件没有后缀的名字。默认情况下，库依赖项是传递的。当这个目标链接到另一个目标时，链接到这个目标的库也会出现在另一个目标的连接线上 target_link_libraries里库文件的顺序符合gcc链接顺序的规则，即被依赖的库放在依赖它的库的后面，比如 target_link_libraries(hello A B.a C.so) 在上面的命令中，libA.so可能依赖于libB.a和libC.so，如果顺序有错，链接时会报错。还有一点，B.a会告诉CMake优先使用静态链接库libB.a， C.so会告诉CMake优先使用动态链接库libC.so，也可直接使用库文件的相对路径或绝对路径。使用绝对路径的好处 于，当依赖的库被更新时，make的时候也会重新链接 set_target_properties（...）是一个便捷功能 设置多个目标的多个属性：set_target_properties(libhello PROPERTIES OUTPUT_NAME \"hello\") 重命名libhello为hello： set_target_properties(Thirdlib PROPERTIES IMPORTED_LOCATION ${CMAKE_CURRENT_SOURCE_DIR}/jniLibs/libThirdlib.so) cmakelist 添加依赖库：set_target_properties(test PROPERTIES LINKER_LANGUAGE CXX) // 指定C++ set_target_properties(test PROPERTIES LINKER_LANGUAGE C) // 指定C 该目标属性用于指定编译器的语言。即当调用可执行程序、共享库和模块时，用于指定编译器链接语言（C or CXX），若是没有设置，则默认具有最高链接器首选项值的语言 示例4：将源文件放置到不同的目录 在示例2的基础上，我们修改下目录结构 目录结构如下： + | +--- CMakeLists.txt /--+ src/ | | | +--- main.c | +--- CMakeLists.txt | /--+ libhello/ | | | +--- hello.h | +--- hello.c | +--- CMakeLists.txt 顶层的CMakeLists.txt # CMakeLists cmake_minimum_required(VERSION 3.0) project(HELLO VERSION 1.0 LANGUAGES C CXX) add_subdirectory(src) add_subdirectory(libhello) src的CMakeLists.txt # src CMakeLists include_directories(${PROJECT_SOURCE_DIR}/libhello) set(APP_SRC main.c) add_executable(hello ${APP_SRC}) target_link_libraries(hello libhello) libhello的CMakeLists.txt #libhello CMakeLists set(LIB_SRC hello.c) add_library(libhello ${LIB_SRC}) 执行cmake的过程同上，目录结构如下 + | +--- CMakeLists.txt /--+ src/ | +--- main.c +--- CMakeLists.txt /--+ libhello/ | +--- hello.h +--- hello.c +--- CMakeLists.txt /--+ build/ | / --+ src/ | +--- hello(exec) / --+ libhello/ | +--- liblibhello.a add_subdirectory (source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 添加一个子目录并构建该子目录 source_dir：必选参数。该参数指定一个子目录，子目录下应该包含CMakeLists.txt文件和代码文件。子目录可以是相对路径也可以是绝对路径，如果是相对路径，则是相对当前目录的一个相对路径。 binary_dir：可选参数。该参数指定一个目录，用于存放输出文件。可以是相对路径也可以是绝对路径，如果是相对路径，则是相对当前输出目录的一个相对路径。如果该参数没有指定，则默认的输出目录使用source_dir。 EXCLUDE_FROM_ALL：可选参数。当指定了该参数，则子目录下的目标不会被父目录下的目标文件包含进去，父目录的CMakeLists.txt不会构建子目录的目标文件，必须在子目录下显式去构建。例外情况：当父目录的目标依赖于子目录的目标，则子目录的目标仍然会被构建出来以满足依赖关系（例如使用了target_link_libraries） include_directories ([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...]) 将指定目录添加到编译器的头文件搜索路径之下，指定的目录被解释成当前源码路径的相对路径 示例5：在示例4的基础上，将可执行文件和lib都放到对应的bin目录和lib目录下 方法一：修改顶层CMakeLists.txt中的add_subdirectory方法 # 顶层CMakeLists cmake_minimum_required(VERSION 3.0) project(HELLO VERSION 1.0 LANGUAGES C CXX) add_subdirectory(src ./bin) add_subdirectory(libhello ./lib) 生成的可执行文件在build/bin中，生成的lib文件在build/lib中 方法二：修改其他两个文件CMakeLists.txt # src CMakeLists include_directories(${PROJECT_SOURCE_DIR}/libhello) set(APP_SRC main.c) set(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin) add_executable(hello ${APP_SRC}) target_link_libraries(hello libhello) # libhello CMakeLists set(LIB_SRC hello.c) set(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib) add_library(libhello ${LIB_SRC}) set(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin) 设置可执行文件输出路径 set(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib) 设置lib库输出路径 示例6：在示例4的基础上，编译动态库 add_library(libhello SHARED ${LIB_SRC}) # 顶层 CMakeLists cmake_minimum_required(VERSION 3.0) project(HELLO VERSION 1.0 LANGUAGES C CXX) option(TEST_DEBUG \"option for debug\" OFF) if (TEST_DEBUG) add_definitions(-DTEST_DEBUG) endif() add_definitions(-DBUILD_SHARED) add_subdirectory(src) add_subdirectory(libhello) # src CMakeLists include_directories(${PROJECT_SOURCE_DIR}/libhello) set(APP_SRC main.c) set(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin) add_executable(hello ${APP_SRC}) target_link_libraries(hello libhello) # libhello CMakeLists set(LIB_SRC hello.c) set(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib) if(BUILD_SHARED) add_library(libhello SHARED ${LIB_SRC}) else() add_library(libhello STATIC ${LIB_SRC}) endif() 我们在main.c中使用CMakeLists中定义的宏TEST_DEBUG // main.c #include \"hello.h\" #include int main() { hello(\"World\"); #ifdef TEST_DEBUG printf (\"DEBUG \\n\"); #endif return 0; } 执行cmake #生成动态库 cmake .. -DBUILD_SHARED=1 # main.c中的“DEBUG“会打印 cmake .. -DTEST_DEBUG=ON "},"C++/Linux环境编程/05-CMakeLists进阶find_package的用法.html":{"url":"C++/Linux环境编程/05-CMakeLists进阶find_package的用法.html","title":"CMakeLists进阶find_package的用法","keywords":"","body":"datetime:2023/04/17 11:28 author:nzb find_package的用法 CMake模块化项目管理：第三方库/依赖性配置 用 find_package 寻找系统中安装的第三方库并链接他们。 find_package 语法 常用参数列表一览： find_package( [version] [EXACT] [QUIET] [CONFIG] [MODULE] [REQUIRED] [[COMPONENTS] [components...]] [OPTIONAL_COMPONENTS components...] ) find_package 命令用法举例 find_package(OpenCV) 查找名为 OpenCV 的包，找不到不报错，事后可以通过 ${OpenCV_FOUND} 查询是否找到。 find_package(OpenCV QUIET) 查找名为 OpenCV 的包，找不到不报错，也不打印任何信息。 find_package(OpenCV REQUIRED) # 最常见用法 查找名为 OpenCV 的包，找不到就报错（并终止 cmake 进程，不再继续往下执行）。 find_package(OpenCV REQUIRED COMPONENTS core videoio) 查找名为 OpenCV 的包，找不到就报错，且必须具有 OpenCV::core 和 OpenCV::videoio 这两个组件，如果没有这两个组件也会报错。 find_package(OpenCV REQUIRED OPTIONAL_COMPONENTS core videoio) 查找名为 OpenCV 的包，找不到就报错，可具有 OpenCV::core 和 OpenCV::videoio 这两个组件，没有这两组件不会报错，通过 ${OpenCV_core_FOUND} 查询是否找到 core 组件。 find_package 说是找“包(package)”，到底是在找什么？ 寻找包配置文件 find_package(OpenCV) 实际上是在找一个名为 OpenCVConfig.cmake 的文件。 注：出于历史兼容性考虑，除了 OpenCVConfig.cmake 以外 OpenCV-config.cmake 这个文件名也会被 CMake 识别到。 同理，find_package(Qt5) 则是会去找名为 Qt5Config.cmake 的文件。 这些形如 包名 + Config.cmake 的文件，我称之为包配置文件。 Qt5Config.cmake 是在安装 Qt5 时，随 libQt5Core.so 等实际的库文件，一起装到系统中去的。 以 Arch Linux 系统为例： 包配置文件位于 /usr/lib/cmake/Qt5/Qt5Config.cmake。 实际的动态库文件位于 /usr/lib/libQt5Core.so。 以 Ubuntu 22.04 系统为例： 包配置文件位于 /usr/lib/x86_64-linux-gnu/cmake/Qt5/Qt5Config.cmake 实际的动态库文件位于 /usr/lib/x86_64-linux-gnu/libQt5Core.so 包配置文件包含什么？ 因此 find_package 并不是直接去找具体的动态库文件和头文件（例如libQt5Core.so）。而是去找包配置文件（例如Qt5Config.cmake）， 这个配置文件里包含了包的具体信息 ，包括动态库文件的位置，头文件的目录，链接时需要开启的编译选项等等。 而且某些库都具有多个子动态库，例如 Qt 就有 libQt5Core.so、libQt5Widgets.so、libQt5Network.so。 因此 CMake 要求所有第三方库作者 统一包装成一个 Qt5Config.cmake 文件包含所有相关信息（类似于 nodejs 的 package.json），比你单独的一个个去找动态库文件要灵活的多。 在XXXConfig.cmake文件中，库的路径都是相对路径，比如说../../libXXX.so，而不是绝对路径/usr/lib/libXXX.so... 这样做可以让CMake更容易找到对应的动态库，因为不一定每个人的系统库都是安装在/usr/lib/...下！比如Arch Linux和Ubuntu的库安装路径就不一样！因此相对路径会更加方便。 包配置文件怎么来的？ 包配置文件由第三方库的作者（Qt的开发团队）提供，在这个库安装时（Qt的安装程序或apt install等）会自动放到 /usr/lib/cmake/XXX/XXXConfig.cmake 这个路径（其中XXX是包名），供 CMake 用户找到并了解该包的具体信息。 /usr/lib/cmake 这个位置是 CMake 和第三方库作者约定俗成的，由第三方库的安装程序负责把包配置文件放到这里。如果第三方库的作者比较懒，没提供 CMake 支持（由安装程序提供XXXConfig.cmake ），那么得用另外的一套方法（FindXXX.cmake），稍后细谈。 Windows 系统下的搜索路径 / /cmake/ /*/ /*/cmake/ /*/(lib/|lib*|share)/cmake/*/ /*/(lib/|lib*|share)/*/ /*/(lib/|lib*|share)/*/cmake/ 其中： 是变量 ${CMAKE_PREFIX_PATH}，Windows 平台默认为 C:/Program Files。 是你在 find_package( REQUIRED) 命令中指定的包名。 是系统的架构名。 Unix 类系统下的搜索路径 /(lib/|lib*|share)/cmake/*/ /(lib/|lib*|share)/*/ /(lib/|lib*|share)/*/cmake/ /*/(lib/|lib*|share)/cmake/*/ /*/(lib/|lib*|share)/*/ /*/(lib/|lib*|share)/*/cmake/ 其中： 是变量 ${CMAKE_PREFIX_PATH}，Unix 平台默认为 /usr。 是你在 find_package( REQUIRED) 命令中指定的包名。 是系统的架构，例如 x86_64-linux-gnu 或 i386-linux-gnu。 （用于伺候 Ubuntu 喜欢把库文件套娃在 /usr/lib/x86_64-linux-gnu 目录下） 举例说明 find_package 搜索路径 例如你是 64 位的 Linux 系统，find_package(Qt5 REQUIRED) 会依次搜索： /usr/lib/cmake/Qt5/Qt5Config.cmake /usr/lib/x86_64-linux-gnu/cmake/Qt5/Qt5Config.cmake /usr/share/cmake/Qt5/Qt5Config.cmake /usr/lib/Qt5/Qt5Config.cmake /usr/lib/x86_64-linux-gnu/Qt5/Qt5Config.cmake /usr/share/Qt5/Qt5Config.cmake /usr/Qt5/lib/cmake/Qt5/Qt5Config.cmake /usr/Qt5/lib/x86_64-linux-gnu/cmake/Qt5/Qt5Config.cmake /usr/Qt5/share/cmake/Qt5/Qt5Config.cmake /usr/Qt5/lib/Qt5/Qt5Config.cmake /usr/Qt5/lib/x86_64-linux-gnu/Qt5/Qt5Config.cmake /usr/Qt5/share/Qt5/Qt5Config.cmake 例如你是 64 位的 Windows 系统，find_package(Qt5 REQUIRED) 会依次搜索： C:/Program Files/Qt5Config.cmake C:/Program Files/cmake/Qt5Config.cmake C:/Program Files/Qt5/Qt5Config.cmake C:/Program Files/Qt5/cmake/Qt5Config.cmake C:/Program Files/Qt5/lib/cmake/Qt5/Qt5Config.cmake C:/Program Files/Qt5/lib/x86_64-windows-gnu/cmake/Qt5/Qt5Config.cmake C:/Program Files/Qt5/share/cmake/Qt5/Qt5Config.cmake C:/Program Files/Qt5/lib/Qt5/Qt5Config.cmake C:/Program Files/Qt5/lib/x86_64-windows-gnu/Qt5/Qt5Config.cmake C:/Program Files/Qt5/share/Qt5/Qt5Config.cmake 还有一点， 可以有额外后缀，且不分大小写（无论 Linux 还是 Windows），例如在Windows系统中： C:/Program Files/Qt5/cmake/Qt5Config.cmake C:/Program Files/Qt5.12.1/cmake/Qt5Config.cmake C:/Program Files/qt5dnmd/cmake/Qt5Config.cmake 都是可以被 find_package(Qt5 REQUIRED) 搜索到的。 在 Linux 系统中： /usr/lib/cmake/OpenCV/OpenCVConfig.cmake /usr/lib/cmake/opencv4/OpenCVConfig.cmake 都是可以被 find_package(OpenCV REQUIRED) 搜索到的。 安装在非标准路径的库如何处理？ 以 Qt5 为例，如果你安装在下列标准路径，find_package 能够自动找到。 Windows：C:/Program Files/Qt5.12.1/lib/cmake/Qt5/Qt5Config.cmake。 Linux：/usr/lib/cmake/Qt5/Qt5Config.cmake。 但是假如我的库不是装在这些标准路径，而是我自定义的路径，怎么办？ 而且即使你不自定义安装路径，Windows 版的 Qt 默认安装就会安装到： C:/Qt5.12.1/msvc2017_64/lib/cmake/Qt5/Qt5Config.cmake。 何况我们同学有的还喜欢装到 D 盘去，Windows 是非标准路径的重灾区，他就没有一个统一的 /usr/lib 目录。然而你一旦把库安装到非标准路径，find_package 是找不到的。 这时你需要手动指定一个变量告诉他在哪儿，可以是普通变量 ${Qt5_DIR}，也可以是环境变量 $ENV{Qt5_DIR}，两个中只要设置了任何一个 find_package 都可以识别到。 变量一般通过命令行 -DQt5_DIR=”C:/Program Files/Qt5.12.1/lib/cmake/Qt5” 设置。 举例，Windows 系统，Qt5 例如我把 Qt5 安装到了 D:/Qt5.12.1。 首先找到他里面的 Qt5Config.cmake 文件所在位置（可以用文件管理器的“搜索”功能或者everything）。 假如你找到该文件的位置是 D:/Qt5.12.1/msvc2017/lib/cmake/Qt5/Qt5Config.cmake，那么请你设置变量 Qt5_DIR 为 D:/Qt5.12.1/msvc2017/lib/cmake/Qt5。有三种设置方法： 单次有效。在 configure 阶段，可以从命令行设置（注意要加引号）： cmake -B build -DQt5_DIR=”D:/Qt5.12.1/msvc2017/lib/cmake/Qt5” 全局启用。右键“我的电脑”->“管理”->“高级”添加一个环境变量 Qt5_DIR 值为 D:/Qt5.12.1/msvc2017/lib/cmake/Qt5，然后重启 Visual Studio。 这样以后你每次构建任何项目，find_package 都能自动找到这个路径的 Qt5 包了。 单项目有效。直接在你自己项目的 CMakeLists.txt 最开头写一行（注意要加引号）： set(Qt5_DIR ”D:/Qt5.12.1/msvc2017/lib/cmake/Qt5”) # 一定要加在最前面！ 举例，Linux 系统，Qt5 例如我把 Qt5 安装到了 /opt/Qt5.12.1。 首先找到他里面的 Qt5Config.cmake 文件所在位置（可以用文件管理器的“搜索”功能）。 假如你找到该文件的位置是 /opt/Qt5.12.1/lib/cmake/Qt5/Qt5Config.cmake，那么请你设置变量 Qt5_DIR 为 /opt/Qt5.12.1/lib/cmake/Qt5。有三种设置方法： 单次有效。在 configure 阶段，可以从命令行设置： cmake -B build -DQt5_DIR=”/opt/Qt5.12.1/lib/cmake/Qt5” 全局启用。修改你的 ~/.bashrc 文件添加环境变量： export Qt5_DIR=”/opt/Qt5.12.1/lib/cmake/Qt5”，然后重启终端。这样以后你每次构建任何项目，find_package 都能自动找到这个路径的 Qt5 包了。 单项目有效。直接在你自己项目的 CMakeLists.txt 最开头写一行： set(Qt5_DIR ”/opt/Qt5.12.1/lib/cmake/Qt5”) # 一定要加在最前面！ 三种方案利弊分析 单次有效（通过命令行）最安全，高度推荐。 全局有效（添加环境变量）可能影响以后其他项目。 比如你的 A 项目依赖 Qt5.12.1，你设置了环境变量 Qt5_DIR=/opt/Qt5.12.1，后来又搞了个 B 项目依赖 Qt5.10.3 ，但是你忘了你设置过全局的环境变量指向 5.12.1 了，导致版本冲突。 单项目有效（写死在 CMakeLists.txt）虽然方便了你，但是你的 CMakeLists.txt 拿到别人电脑上就冲突了 （例如你通过 GitHub 开源的），可能你 set(Qt5_DIR D:/Qt5)，而人家却需要 set(Qt5_DIR E:/Qt5) 。 所以“单次有效”虽然劳驾您的高抬贵手每次命令行打一下 -DQt5_DIR=”D:/Qt5”，但人家也打一下 -DQt5_DIR=”E:/Qt5”，就没有冲突，各美其美，美美与共，赋能多元化社会，下沉团队合作发力面。 实际上只要你不删 build，不需要每次都 -DQt5_DIR 一下，CMake 具有“记忆”功能。 cmake -B build -DQt5_DIR=D:/Qt5 # 只需要第一次指定好 cmake -B build # 以后第二次运行可以省略！ rm -rf build # 只有清理了 build 以后， cmake -B build -DQt5_DIR=D:/Qt5 # 才需要重新指定。 科普：类似 Qt 这种亲 Unix 软件，在 Windows 下的目录组织格式 例如你安装 Qt 时设置安装路径为 D:/Qt5.12.1。 则你会看到他下面有几个子目录： D:/Qt5.12.1/msvc2017_64（由VS2017编译64位版本） D:/Qt5.12.1/mingw_64（由MinGW编译64位版本） 这几个目录里又分别包含： D:/Qt5.12.1/msvc2017_64/include/qt/QtCore/qstring.h（实际的头文件，属于 Qt5::Core） D:/Qt5.12.1/msvc2017_64/bin/Qt5Core.dll（实际的动态库文件，对应 Qt5::Core） D:/Qt5.12.1/msvc2017_64/lib/Qt5Core.lib（实际的静态库文件，对应 Qt5::Core） D:/Qt5.12.1/msvc2017_64/lib/cmake/Qt5/Qt5Config.cmake（包配置文件） 可以看到尽管是 Windows 版的 Qt，他内部仍然是在模仿 Linux 下 /usr 的目录组织格式。 注意这里的 Qt5Core.dll位于 bin 目录，而不是 lib 目录，这是为什么呢？ 因为 Windows 要求 exe 和 dll 位于同一目录，否则 exe 在运行时就会找不到 dll。 为了符合 Linux 分离 bin 和 lib 的组织格式，又要伺候 Windows 的沙雕同目录规则， 我们通常把 dll动态库文件视为“可执行文件”和 exe 一起放到 bin 目录， 而静态库则没有运行时必须同目录的限制，所以可以照常放到 lib 目录。 科普：类似 Qt 这种亲 Unix 软件，在 Linux 下的目录组织格式 Linux 用户从源码安装 Qt 这种库时，会有一个 --prefix 选项，指定安装的根路径。 默认的 --prefix 是 /usr，这个路径由全部软件共享，Qt 会把他的文件安装到以下目录： /usr/include/qt/QtCore/qstring.h（实际的头文件，对应 Qt5::Core） /usr/lib/libQt5Core.so（实际的动态库文件，对应 Qt5::Core） /usr/lib/libQt5Core.a（实际的静态库文件，对应 Qt5::Core） /usr/lib/cmake/Qt5/Qt5Config.cmake（包配置文件，用于 find_package） 假如你指定 --prefix=/usr/local，这个路径通常是用户自己手动装的软件，那么就会变成： /usr/local/lib/cmake/Qt5/Qt5Config.cmake 假如你指定 --prefix=/opt/myqtroot，那么就会变成：/opt/myqtroot/lib/cmake/Qt5/Qt5Config.cmake 伺候这种非常规安装，就需要设置变量 -DQt5_DIR=/opt/myqtroot/lib/cmake/Qt5 了。 科普：亲 Unix 软件从源码安装的通用套路 通过Makefile 构建系统： ./configure --prefix=/usr --with-some-options # 生成 Makefile（这个 configure 脚本由 Autoconf 生成） make -j 8 # 8 核心编译，生成 libtest.so sudo make install # 安装，拷贝到 /usr/lib/libtest.so 通过CMake 构建系统： cmake -B build -DCMAKE_INSTALL_PREFIX=/usr -DWITH_SOME_OPTIONS=ON # 生成 Makefile cmake --build build --parallel 8 # 8 核心编译，生成 libtest.so sudo cmake --build build --target install # 安装，拷贝到 /usr/lib/libtest.so 注：如果 -DCMAKE_INSTALL_PREFIX=/usr/local 则会拷贝到 /usr/local/lib/libtest.so 如果第三方库发懒，没有提供 Config 文件怎么办？ 绝大多数常用 C++ 库都提供了 CMake 支持（即使他们本身不一定是用 CMake 构建的）： /usr/lib/cmake/Boost-1.80.0/BoostConfig.cmake /usr/lib/cmake/opencv4/OpenCVConfig.cmake /usr/lib/cmake/Qt5/Qt5Config.cmake 这些 Config 文件都是由第三方库负责安装到 /usr/lib/cmake。 通过CMake官方提供的 FindXXX.cmake 但是，也有少数不听话的库，官方不提供 CMake 支持，即安装时不自带 Config 文件。恼人的是，这些不听话的库有些竟然是非常热门的库！例如 Python，CUDA，Jemalloc。 为了不影响 CMake 用户体验，CMake 发明了 Find 文件（FindXXX.cmake），你不支持我是吧？我支持你！Find 文件会在 CMake 安装时自动安装到/usr/share/cmake/Modules 。 包搜索文件（FindXXX.cmake）可以在不知道包具体位置信息的情况下搜索他们（在 /usr/lib 等默认路径搜索）。 这些都是 CMake 自带的包搜索文件： /usr/share/cmake/Modules/FindCUDAToolkit.cmake /usr/share/cmake/Modules/FindPython.cmake 通过热心网友提供的 FindXXX.cmake 那么如果有个不太热门的第三方库没提供包配置文件，CMake 也没提供包搜索文件，我们该如何找到他？这就需要自己提供包搜索文件了！别担心，你不用自己写， GitHub 上有很多志士仁人已经写过了对应的包搜索文件，你搜一下 FindXXX.cmake 就能找到了。 举例：FindJemalloc.cmake ConfigXXX.cmake 文件通常风格比较统一，都是 XXX::xxx 这种格式。 但是不同的 Find 文件，特别是这种网上志士仁人自己编写的文件，风格可能千差万别（没办法，毕竟不是官方的支持嘛），很多都还是古代 CMake 的用法，例如 ${XXX_LIBRARIES}。 关于具体使用的细节可以打开 FindXXX.cmake 文件查看， 文件的前半部分一般是注释，会讲解如何使用。 现在我们就知道该如何解决这个问题了： 下载这个文件，放到 cmake/FindXXX.cmake。 然后在 CMakeLists.txt 文件的最前方写一行： set(CMAKE_MODULE_PATH “${CMAKE_CURRENT_LIST_DIR}/cmake;${CMAKE_MODULE_PATH}”) 这样做之后， find_package(XXX) 就会用你下载的这个 FindXXX.cmake 去找包了。 现代 vs 古代：用法上完全不同！ OpenCVConfig.cmake（现代） FindCURL.cmake（古代） 可以看得到古代CMake不如现代CMake的用法来得统一 比如说target_link_libraries(curltest ${CURL_LIBRARY})和target_include_directories(clib PRIVATE ${CURL_INCLUDE_DIR}) 就需要自己去看官方文档， 然后才知道里面到底返回了什么变量，CURL在这里返回的变量中就有CURL_LIBRARY和CURL_INCLUDE_DIR 远远不如现代CMake的target_link_libraries(main PUBLIC OpenCV::core)来得统一。 现代和古代的区别 不管是 Find 类还是 Config 类，一定要打开相应的 cmake 文件看看注释，才能确定他是古代风格还是现代风格。 古代 CMake 的命名规范高度不统一，有的是 ${XXX_LIBRARIES}，有的又是 ${XXX_LIBRARY} ，非常沙雕，需要看相应 cmake 文件的注释，才能确定具体是怎么命名的。 现代 CMake 就好多了，统一用 包名::组件名 的格式。但是具体的组件名，还是要查看 cmake 文件中的注释才能确定。例如 CURL::libcurl OpenCV::core Qt5::core TBB::tbb 等。 古代（仅用于伺候很老的库）： find_package(XXX) if (NOT XXX_FOUND) message(FATAL_ERROR “XXX not found”) endif() target_include_directories(yourapp ${XXX_INCLUDE_DIRS}) target_link_libraries(yourapp ${XXX_LIBRARIES}) 现代（推荐）： find_package(XXX REQUIRED COMPONENTS xxx) target_link_libraries(yourapp XXX::xxx) 大多都的库能同时兼容现代和古代 大多现代的 Find/Config 文件，都同时兼容现代和古代的用法。 特别古老的 Find 文件，则只能用古代的用法。 例如下图是 FindCURL.cmake 的注释，可以看到 IMPORTED Targets 章节是在介绍现代的用法，而 Result Variables 章节是在介绍古代的用法，我们尽量用现代的那种就行。 官方文档：find_package 的两种模式 其实上面我们已经讲过了，就是Module模式和Config模式两种。 指定使用哪种模式 只使用Module模式： find_package(TBB MODULE REQUIRED) 只会寻找 FindTBB.cmake，搜索路径： ${CMAKE_MODULE_PATH}（默认为 /usr/share/cmake/Modules） 只使用Config模式： find_package(TBB CONFIG REQUIRED) 只会寻找 TBBConfig.cmake，搜索路径： ${CMAKE_PREFIX_PATH}/lib/cmake/TBB（默认为 /usr/lib/cmake/TBB） ${TBB_DIR} 或 $ENV{TBB_DIR} 不指定使用模式： find_package(TBB REQUIRED) 不指定则两者都会尝试，先尝试FindTBB.cmake，再尝试TBBConfig.cmake。 关于 vcpkg 的坑 刚刚说了有些懒惰第三方库，比如 Jemalloc，他不提供 Config 文件，需要我们自己手写个（或抄别人开源项目里的） Find 文件，用起来很不方便。 但是 vcpkg 会为所有第三方库，即使是懒惰的 Jemalloc，都配备一个 Config 文件方便你使用 find_package 导入。所以用 vcpkg 时，尽量用 find_package(XXX CONFIG REQUIRED) 避免被 CMake 自带的 Find 文件误导找到别的地方的库（并非 vcpkg 安装的那个）。 另外注意 vcpkg 需要的 CMAKE_TOOLCHAIN_FILE 如果你用 set 设置，必须在 project 命令前面，并且修改这个变量后要删除 build 目录重新 cmake -B build 一遍才能生效（否则会在旧的环境里找，找不到 vcpkg 装的库）。 科普：语义版本号（semantic versioning）系统 软件行业记录版本迭代普遍采用的是一套所谓的语义版本号系统，英文简称 semver。 通常他的格式是三个用点分隔开来的十进制数字：..，例如：1.2.0，0.6.8，18.11.0 major 称为主版本号，出现功能重大变更，以至于和旧 API 不兼容的时候会增加该号。 minor 称为次版本号，功能有所变更或增加，但依然和旧的 API 兼容时会增加该号。 patch 称为补丁版号，功能没有改变，只是修复了一些 bug 就重新发布时会增加该号。 也有的软件不拘一格（例如 zeno），索性用发布的日期作为版本号的三个数字，例如 2022.11.2。不论采用哪种编号方案，都是几个用点分开的数字，并且数字越大越新，且优先比较靠前面的数字。 因此为了通用，CMake 支持最多四个点分开的版本号：...。并且如果你写 0.6.8 他会自动帮你把多余的 tweak 等于 0 ，也就是说 0.6.8 == 0.6.8.0，1.2 == 1.2.0 == 1.2.0.0。 比较版本号时，可以用 if (${XXX_VERSION} VERSION_LESS 3.1.0) 判断大小。 find_package 命令指定版本 find_package(OpenCV REQUIRED) 查找名为 OpenCV 的包，不限版本，事后可以通过 ${OpenCV_VERSION} 查询找到的版本。 find_package(OpenCV 2.0.1 REQUIRED) 查找版本在 2.0.1 以上的 OpenCV 包（version >= 2.0.1）。 find_package(OpenCV 2.0.1 EXACT REQUIRED) 查找版本刚好为 2.0.1 的 OpenCV 包（version == 2.0.1）。 如果没写全，则没写的部分默认为 0。例如下列三者等价： find_package(OpenCV 2 REQUIRED) find_package(OpenCV 2.0 REQUIRED) find_package(OpenCV 2.0.0 REQUIRED) 总结 安装 TBB： cd tbb ./configure --prefix=/opt/tbbinstalldir make -j 8 sudo make install 在你的项目里使用 TBB： cd yourapp cmake -B build -DTBB_DIR=/opt/tbbinstalldir/lib/cmake/TBB cmake --build build --parallel 8 CMakeLists.txt 这样写： project(yourapp) add_executable(yourapp yourmain.cpp) find_package(TBB CONFIG REQUIRED COMPONENTS tbb) target_link_libraries(yourapp PUBLIC TBB::tbb) 古代 CMake 常见问题 1、target_link_libraries(yourapp ${XXX_LIBRARIES}) 2、 target_include_directories(yourapp ${XXX_INCLUDE_DIRS}) Q: 我明明链接了 XXX 库，编译时却报错“找不到头文件 XXX.h”怎么办？ A: 你漏了上面的 2。 Q: 我明明编译都通过了，链接却报错“undefined symbol：XXXfunc”怎么办？ A: 你漏了上面的 1。 打印检查一下这两个变量是不是空的：message(“!!!!!!” ${XXX_INCLUDE_DIRS}) 如果为空说明你变量名打错了，CMake 特色就是找不到变量不报错，而是视为空字符串。 去看一下 FindXXX.cmake 里的注释（那就是文档），确定一下到底是什么名字。 少见的 add_subdirectory 邪教 大部分第三方库都需要提前安装好，然后再 find_package 找到他，然后才能链接。 也有少数第三方库为了方便，还支持作为子项目加到你的项目中来，这种就不需要 :: 语法。 标准方法： find_package(spdlog REQUIRED) target_link_libraries(yourapp PUBLIC spdlog::spdlog) 邪教方法： add_subdirectory(spdlog) # 需要下载好他们的源码放到你的根目录下 target_link_libraries(yourapp PUBLIC spdlog) "},"C++/Linux环境编程/04-静态库和动态库的制作和使用.html":{"url":"C++/Linux环境编程/04-静态库和动态库的制作和使用.html","title":"静态库和动态库的制作和使用","keywords":"","body":"datetime:2023/04/17 11:28 author:nzb 静态库，动态库的制作和使用 静态库动态库概念 静态库动态库概念 静态库：链接时，静态库代码被打包到可执行程序里 动态库：链接时，动态库代码不会被打包到可执行程序里，只会打包名字等库信息。启动时，动态库会被动态加载到内存中， 通过ldd(list dynamic dependencied) 命令可以检查动态库依赖关系。 优缺点对比 静态库 动态库 制作静态库及使用 制作静态库 gcc -c test.cpp 生成.o目标文件 ar rcs libxxx.a xxx.o xxx.o 打包文件制作静态库 libxxx.a （windows libxxx.lib) 使用静态库 g++ main.cpp -o app -ltest -L ./ -I ./ 注意 制作的静态库目录在哪里 -L 后便要指定静态库目录，否则系统会去默认路径查找 -I ./ 指明.h文件目录 制作动态库（共享库）及使用 制作动态库 gcc -c -fpic/-fPIC test.cpp 生成 .o 目标文件 （是一个和位置无关的代码） -fpic （ pic:position independent code位置无关码）用于编译阶段，产生的代码没有绝对地址，全部用相对地址，满足了共享库的要求，共享库被加载时地址不是固定的。 如果不加-fpic ，那么生成的代码就会与位置有关，当进程使用该.so文件时都需要重定位，且会产生成该文件的副本，每个副本都不同，不同点取决于该文件代码段与数据段所映射内存的位置。 gcc -shared -o xxx.o xxx.o libxxx.so 打包文件制作动态库 libxxx.so （windows libxxx.dll) 使用动态库 g++ main.cpp -o app -lcalc -L ./ 编译可执行文件名为 app 此时./app运行出错 加载失败 ldd app 列出app依赖动态库 ，发现 libcalc.so not found 如何定位动态库文件：用系统动态载入器（ld-linux.so，专门用来负责定位、加载程序所需要的所有动态库文件)获取绝对路径。 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/nowcoder/projects/linuxtest 将当前目录加进ld_library_path。此时ldd app 可以找到该动态库。 但是临时有效。 永久有效(用户级) cd /home vim ~/.bashrc // 进入.bashrc 隐藏文件，底端输入 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/nowcoder/projects/linuxtest source ~/.bashrc 使生效 或 echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/nowcoder/projects/linuxtest' >> ~/.bashrc source ~/.bashrc "},"C++/网络通信socket/01-socket概述.html":{"url":"C++/网络通信socket/01-socket概述.html","title":"socket概述","keywords":"","body":"datetime:2022/12/19 16:45 author:nzb socket 网络通信socket socket就是插座（中文翻译成套接字有点莫名其妙），运行在计算机中的两个程序通过socket建立起一个通道，数据在通道中传输。 socket把复杂的TCP/IP协议族隐藏了起来，对程序员来说，只要用好socket相关的函数，就可以完成网络通信。 二、socket的分类 socket提供了流（stream）和数据报（datagram）两种通信机制，即流socket和数据报socket。 流socket基于TCP协议，是一个有序、可靠、双向字节流的通道，传输数据不会丢失、不会重复、顺序也不会错乱。就像两个人在打电话，接通后就在线了，您一句我一句的聊天。 数据报socket基于UDP协议，不需要建立和维持连接，可能会丢失或错乱。UDP不是一个可靠的协议，对数据的长度有限制，但是它的速度比较高。就像短信功能，一个人向另一个人发短信，对方不一定能收到。 在实际开发中，数据报socket的应用场景极少，本教程只介绍流socket。 三、客户/服务端模式 在TCP/IP网络应用中，两个程序之间通信模式是客户/服务端模式（client/server），客户/服务端也叫作客户/服务器，各人习惯。 1、服务端的工作流程 1）创建服务端的socket。 2）把服务端用于通信的地址和端口绑定到socket上。 3）把socket设置为监听模式。 4）接受客户端的连接。 5）与客户端通信，接收客户端发过来的报文后，回复处理结果。 6）不断的重复第5）步，直到客户端断开连接。 7）关闭socket，释放资源。 服务端示例（server.cpp） #include #include #include #include #include #include #include #include int main(int argc, char *argv[]) { if (argc != 2) { printf(\"Using:./server port\\nExample:./server 5005\\n\\n\"); return -1; } int listenfd; // 第1步：创建服务端的socket。 if ((listenfd = socket(AF_INET, SOCK_STREAM, 0)) == -1) { perror(\"socket\"); return -1; } printf(\"fd=%d\\n\", listenfd); // 第2步：把服务端用于通信的地址和端口绑定到socket上。 struct sockaddr_in servaddr; // 服务端地址信息的数据结构。 memset(&servaddr, 0, sizeof(servaddr)); servaddr.sin_family = AF_INET; // 协议族，在socket编程中只能是AF_INET。 servaddr.sin_addr.s_addr = htonl(INADDR_ANY); // 任意ip地址。 //servaddr.sin_addr.s_addr = inet_addr(\"172.17.0.2\"); // 指定ip地址。 servaddr.sin_port = htons(atoi(argv[1])); // 指定通信端口。 if (bind(listenfd, (struct sockaddr *) &servaddr, sizeof(servaddr)) != 0) { perror(\"bind\"); close(listenfd); return -1; } // 第3步：把socket设置为监听模式。 if (listen(listenfd, 3) != 0) { perror(\"listen\"); close(listenfd); return -1; } // 第4步：接受客户端的连接。 int clientfd; // 客户端的socket。 int socklen = sizeof(struct sockaddr_in); // struct sockaddr_in的大小 struct sockaddr_in clientaddr; // 客户端的地址信息。 // 从已准备好的连接队列中获取一个请求，如果队列为空，accept函数将阻塞等待 clientfd = accept(listenfd, (struct sockaddr *) &clientaddr, (socklen_t * ) & socklen); printf(\"客户端（%s）已连接,socket=%d.\\n\", inet_ntoa(clientaddr.sin_addr), clientfd); // 第5步：与客户端通信，接收客户端发过来的报文后，回复ok。 char buffer[1024]; while (1) { int iret; memset(buffer, 0, sizeof(buffer)); if ((iret = recv(clientfd, buffer, sizeof(buffer), 0)) 2、客户端的工作流程 1）创建客户端的socket。 2）向服务器发起连接请求。 3）与服务端通信，发送一个报文后等待回复，然后再发下一个报文。 4）不断的重复第3）步，直到全部的数据被发送完。 5）第4步：关闭socket，释放资源。 客户端示例（client.cpp） #include #include #include #include #include #include #include #include int main(int argc, char *argv[]) { if (argc != 3) { printf(\"Using:./client ip port\\nExample:./client 127.0.0.1 5005\\n\\n\"); return -1; } // 第1步：创建客户端的socket。 int sockfd; if ((sockfd = socket(AF_INET, SOCK_STREAM, 0)) == -1) { perror(\"socket\"); return -1; } // 第2步：向服务器发起连接请求。 struct hostent *h; if ((h = gethostbyname(argv[1])) == 0) // 指定服务端的ip地址。 { printf(\"gethostbyname failed.\\n\"); close(sockfd); return -1; } struct sockaddr_in servaddr; memset(&servaddr, 0, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_port = htons(atoi(argv[2])); // 指定服务端的通信端口。 memcpy(&servaddr.sin_addr, h->h_addr, h->h_length); if (connect(sockfd, (struct sockaddr *) &servaddr, sizeof(servaddr)) != 0) // 向服务端发起连接清求。 { perror(\"connect\"); close(sockfd); return -1; } char buffer[1024]; // 第3步：与服务端通信，发送一个报文后等待回复，然后再发下一个报文。 for (int ii = 0; ii 在运行程序之前，必须保证服务器的防火墙已经开通了网络访问策略（云服务器还需要登录云控制平台开通访问策略）。 先启动服务端程序server，服务端启动后，进入等待客户端连接状态，然后启动客户端。 客户端的输出如下： 服务端的输出如下： 四、注意事项 1、socket文件描述符 在UNIX系统中，一切输入输出设备皆文件，socket()函数的返回值其本质是一个文件描述符，是一个整数。 2、服务端程序绑定地址 如果服务器有多个网卡，多个IP地址，socket通信可以指定用其中一个地址来进行通信，也可以任意ip地址。 1）指定ip地址的代码 m_servaddr.sin_addr.s_addr = inet_addr(\"192.168.149.129\"); // 指定ip地址 2）任意ip地址的代码 m_servaddr.sin_addr.s_addr = htonl(INADDR_ANY); // 本主机的任意ip地址 在实际开发中，采用任意ip地址的方式比较多。 3、服务端程序绑定的通信端口 m_servaddr.sin_port = htons(5000); // 通信端口 4、客户端程序指定服务端的ip地址 struct hostent* h; if ( (h = gethostbyname(\"118.89.50.198\")) == 0 ) // 指定服务端的ip地址。 { printf(\"gethostbyname failed.\\n\"); close(sockfd); return -1; } 5、客户端程序指定服务端的通信端口 servaddr.sin_port = htons(5000); 6、send函数 send函数用于把数据通过socket发送给对端。不论是客户端还是服务端，应用程序都用send函数来向TCP连接的另一端发送数据。 函数声明：ssize_t send(int sockfd, const void *buf, size_t len, int flags); sockfd为已建立好连接的socket。 buf为需要发送的数据的内存地址，可以是C语言基本数据类型变量的地址，也可以数组、结构体、字符串，内存中有什么就发送什么。 len需要发送的数据的长度，为buf中有效数据的长度。 flags填0, 其他数值意义不大。 函数返回已发送的字符数。出错时返回-1，错误信息errno被标记。 注意，就算是网络断开，或socket已被对端关闭，send函数不会立即报错，要过几秒才会报错。 如果send函数返回的错误（ 7、recv函数 recv函数用于接收对端socket发送过来的数据。 recv函数用于接收对端通过socket发送过来的数据。不论是客户端还是服务端，应用程序都用recv函数接收来自TCP连接的另一端发送过来数据。 函数声明：ssize_t recv(int sockfd, void *buf, size_t len, int flags); sockfd为已建立好连接的socket。 buf为用于接收数据的内存地址，可以是C语言基本数据类型变量的地址，也可以数组、结构体、字符串，只要是一块内存就行了。 len需要接收数据的长度，不能超过buf的大小，否则内存溢出。 flags填0, 其他数值意义不大。 函数返回已接收的字符数。出错时返回-1，失败时不会设置errno的值。 如果socket的对端没有发送数据，recv函数就会等待，如果对端发送了数据，函数返回接收到的字符数。出错时返回-1。如果socket被对端关闭，返回值为0。 如果recv函数返回的错误（ 8、服务端有两个socket 对服务端来说，有两个socket，一个是用于监听的socket，还有一个就是客户端连接成功后，由accept函数创建的用于与客户端收发报文的socket。 9、程序退出时先关闭socket socket是系统资源，操作系统打开的socket数量是有限的，在程序退出之前必须关闭已打开的socket，就像关闭文件指针一样，就像delete已分配的内存一样，极其重要。 值得注意的是，关闭socket的代码不能只在main函数的最后，那是程序运行的理想状态，还应该在main函数的每个return之前关闭。 "},"C++/网络通信socket/02-数据类型和相关库函数.html":{"url":"C++/网络通信socket/02-数据类型和相关库函数.html","title":"数据类型和相关库函数","keywords":"","body":"datetime:2022/12/19 19:31 author:nzb 数据类型和相关的库函数 1、结构体 struct sockaddr { unsigned short sa_family; // 2字节地址类型， AF_xxx char sa_data[14]; // 14字节的端口和地址 }; struct in_addr { unsigned long s_addr; // 4字节地址，为什么不直接放sockaddr_in，可能是为了扩展性 }; // 上面的sockaddr不好操作，所以提供了sockaddr_in，地址和端口分开了 struct sockaddr_in { short int sin_family; // 2字节地址类型 unsigned short int sin_port; // 2字节端口号 struct in_addr sin_addr; // 4字节地址 unsigned char sin_zero[8]; // 为了保持与 struct sockaddr 一样的长度，方便强制转换 }; struct hostent { char *h_name; // 主机名 char **h_aliases; // 主机所有别名构成的字符串数组，统一IP可绑定多个域名 short h_addrtype; // 主机IP地址的类型，例如IPV4(AF_INET)还是IPV6 short h_length; // 主机IP地址长度，IPV4地址为4, IPV6地址则为16 char **h_addr_list; // 主机的IP地址，以网络字节序存储 }; #define h_addr h_addr_list[0] /* for backward compatibility */ // gethostbyname函数可以利用字符串格式的域名获得IP网络字节顺序地址 struct hostent *gethostbyname(const char * name); // 将一个字符串IP地址转换为一个32位的网络字节序IP地址，如果这个函数成功，函数的返回值非零，如果输入地址不正确则会返回零，使用这个函数并没有错误码存放在 *errno中，所以它的值会被忽略 int inet_aton(const char *cp, struct in_addr *inp); // 把网络字节序IP地址转换成字符串的IP地址 char *inet_ntoa(struct in_addr in); in_addr_t inet_addr(const char *cp); 2、库函数 2.1、socket函数 socket函数用于创建一个新的socket，也就是向系统申请一个socket资源。socket函数用户客户端和服务端。 函数声明：int socket(int domain, int type, int protocol); 参数说明 domain：协议域，又称协议族（family）。常用的协议族有AF_INET、AF_INET6、AF_LOCAL（或称AF_UNIX，Unix域Socket）、AF_ROUTE 等。协议族决定了socket的地址类型，在通信中必须采用对应的地址，如AF_INET决定了要用ipv4地址（32位的）与端口号（16位的）的组合、AF_UNIX决定了要用一个绝对路径名作为地址。 type ：指定socket类型。常用的socket类型有SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等。流式socket（SOCK_STREAM）是一种面向连接的socket，针对于面向连接的TCP服务应用。数据报式socket（SOCK_DGRAM）是一种无连接的socket，对应于无连接的UDP服务应用。 protocol：指定协议。常用协议有IPPROTO_TCP、IPPROTO_UDP、IPPROTO_STCP、IPPROTO_TIPC等，分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议。 第一个参数只能填AF_INET，第二个参数只能填SOCK_STREAM，第三个参数只能填0。 除非系统资料耗尽，socket函数一般不会返回失败。 返回值：成功则返回一个socket，失败返回-1，错误原因存于errno 中。 面试问题： 在一个程序里面最多打开多少个文件数？ 答案：1024个。可以搜索“linux一般打开文件的数量”。 2.2、gethostbyname函数 把ip地址或域名转换为hostent 结构体表达的地址。 函数声明：struct hostent *gethostbyname(const char *name); 参数name，域名或者主机名，例如\"192.168.1.3\"、\"www.freecplus.net\"等。 返回值：如果成功，返回一个hostent结构指针，失败返回NULL。 gethostbyname只用于客户端。 gethostbyname只是把字符串的ip地址转换为结构体的ip地址，只要地址格式没错，一般不会返回错误。失败时不会设置errno的值。 2.3、connect函数 向服务器发起连接请求。 函数声明：int connect(int sockfd, struct sockaddr * serv_addr, int addrlen); 函数说明 connect函数用于将参数sockfd 的socket 连至参数serv_addr 指定的服务端，参数addrlen为sockaddr的结构长度。 返回值：成功则返回0，失败返回-1，错误原因存于errno 中。 connect函数只用于客户端。 如果服务端的地址错了，或端口错了，或服务端没有启动，connect一定会失败。 2.4、bind函数 服务端把用于通信的地址和端口绑定到socket上。 函数声明: int bind(int sockfd, const struct sockaddr *addr,socklen_t addrlen); 参数sockfd，需要绑定的socket。 参数addr，存放了服务端用于通信的地址和端口。 参数addrlen表示addr结构体的大小。 返回值：成功则返回0，失败返回-1，错误原因存于errno 中。 如果绑定的地址错误，或端口已被占用，bind函数一定会报错，否则一般不会返回错误。 设置服务端socket的SO_REUSEADDR属性 服务端程序的端口释放后可能会处于TIME_WAIT状态，等待两分钟之后才能再被使用，SO_REUSEADDR是让端口释放后立即就可以被再次利用。 //设置SO_REUSEADDR选项 int opt=1;unsigned int len = sizeof(opt); setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &opt, len); 2.5、listen函数 listen函数把主动连接socket变为被动连接的socket，使得这个socket可以接受其它socket的连接请求，从而成为一个服务端的socket。 函数声明: int listen(int sockfd, int backlog); 参数sockfd是已经被bind过的socket。socket函数返回的socket是一个主动连接的socket，在服务端的编程中， 程序员希望这个socket可以接受外来的连接请求，也就是被动等待客户端来连接。由于系统默认时认为一个socket是主动连接的，所以需要通过某种方式来告诉系统， 程序员通过调用listen函数来完成这件事。 参数backlog，这个参数涉及到一些网络的细节，比较麻烦，填5、10都行，一般不超过30。 当调用listen之后，服务端的socket就可以调用accept来接受客户端的连接请求。 返回值：成功则返回0，失败返回-1，错误原因存于errno 中。 listen函数一般不会返回错误。 2.6、accept函数 服务端接受客户端的连接。 函数声明: int accept(int sockfd,struct sockaddr *addr,socklen_t *addrlen); 参数sockfd是已经被listen过的socket。 参数addr用于存放客户端的地址信息，用sockaddr结构体表达，如果不需要客户端的地址，可以填0。 参数addrlen用于存放addr参数的长度，如果addr为0，addrlen也填0。 accept函数等待客户端的连接，如果没有客户端连上来，它就一直等待，这种方式称之为阻塞。 accept等待到客户端的连接后，创建一个新的socket，函数返回值就是这个新的socket，服务端使用这个新的socket和客户端进行报文的收发。 返回值：成功则返回0，失败返回-1，错误原因存于errno 中。 accept在等待的过程中，如果被中断或其它的原因，函数返回-1，表示失败，如果失败，可以重新accept。 2.7、send函数 send函数用于把数据通过socket发送给对端。不论是客户端还是服务端，应用程序都用send函数来向TCP连接的另一端发送数据。 函数声明：ssize_t send(int sockfd, const void *buf, size_t len, int flags); sockfd为已建立好连接的socket。 buf为需要发送的数据的内存地址，可以是C语言基本数据类型变量的地址，也可以数组、结构体、字符串，内存中有什么就发送什么。 len需要发送的数据的长度，为buf中有效数据的长度。 flags填0, 其他数值意义不大。 函数返回已发送的字符数。出错时返回-1，错误信息errno被标记。 注意，就算是网络断开，或socket已被对端关闭，send函数不会立即报错，要过几秒才会报错。 如果send函数返回的错误（ 2.8、recv函数 recv函数用于接收对端socket发送过来的数据。 recv函数用于接收对端通过socket发送过来的数据。不论是客户端还是服务端，应用程序都用recv函数接收来自TCP连接的另一端发送过来数据。 函数声明：ssize_t recv(int sockfd, void *buf, size_t len, int flags); sockfd为已建立好连接的socket。 buf为用于接收数据的内存地址，可以是C语言基本数据类型变量的地址，也可以数组、结构体、字符串，只要是一块内存就行了。 len需要接收数据的长度，不能超过buf的大小，否则内存溢出。 flags填0, 其他数值意义不大。 函数返回已接收的字符数。出错时返回-1，失败时不会设置errno的值。 如果socket的对端没有发送数据，recv函数就会等待，如果对端发送了数据，函数返回接收到的字符数。出错时返回-1。如果socket被对端关闭，返回值为0。 如果recv函数返回的错误（ TCP报文分包和粘包 分包：发送方发送字符串\"hello world\", 接收方却接收到了两个字符串\"hello\" 和 \"world\"。 粘包：发送方发送两个字符串\"hello\" + \" world\", 接收方却一次性接收到了\"hello world\"。 但是TCP传输数据能保证几点： 顺序不变，例如发送方发送hello，接收方也一定顺序接收到hello，这个是TCP协议承诺的，因此这点成为我们解决分包和粘包问题的关键。 分割的包中间不会插入其他数据。 实际开发中，为了解决分包和粘包的问题，就一定要自定义一份协议，最常用的方法是：报文长度+报文内容：0011hello world listen()、connect()和accept()函数 服务端在调用listen()之前，客户端不能向服务端发起连接请求的。 服务端调用listen()函数后，服务端的socket开始监听客户端的连接。 客户端调用connect()函数向服务端发起连接请求。 在TCP底层，客户端和服务端握手后建立起通信通道，如果有多个客户端请求，在服务端就会形成一个已准备好的连接的队列。 服务端调用accept()函数从队列中获取一个已准备好的连接，函数返回一个新的socket，新的socket用于与客户端通信，listen的socket只负责监听客户端的连接请求。 listen的socket队列 内核会为listen状态的socket维护两个队列：不完全连接请求队列（SYN_RECV状态）和等待accept建立socket的队列（ESTABLISHED状态） 在Linux内核2.2之后，backlog参数的形为改变了，现在它指等待accept的完全建立的 socket的队列长度，而不是不完全连接请求的数量。 不完全连接队列的长度可以使用 /proc/sys/net/ipv4/tcp_max_syn_backlog设置（缺省值 128）。 backlog参数如果比/proc/sys/net/ipv4/tcp_max_syn_backlog,则截断。 "},"C++/网络通信socket/03-网络字节序与主机字节序.html":{"url":"C++/网络通信socket/03-网络字节序与主机字节序.html","title":"网络字节序与主机字节序","keywords":"","body":"datetime:2022/12/19 19:31 author:nzb 网络字节序与主机字节序 1.网络字节序与主机字节序 在Linux网络编程中，经常碰到网络字节序与主机字节序的相互转换。说到网络字节序与主机字节序需要清晰了解以下几个概念。 字节序，顾名思义，指字节在内存中存储的顺序。比如一个int32_t类型的数值占用4个字节，这4个字节在内存中的排列顺序就是字节序。字节序有两种： （1）小端字节序（Little endinan），数值低位存储在内存的低地址，高位存储在内存的高地址； （2）大端字节序（Big endian），数值高位存储在内存的低地址，低位存储在内存的高地址。 下面以32位位宽数值0x12345678为例，小端字节序与大端字节序具体的存储区别如下所示： 主机字节序，即CPU存储数据时采用的字节顺序。不同的CPU设计时采用的字节序是不同的，谈到字节序的问题，必然牵涉到两大CPU派系。 那就是Motorola的PowerPC系列CPU和Intel的x86与x86_64（该指令集由AMD率先设计推出）系列CPU。 PowerPC系列采用大端字节序（big endian）方式存储数据，而x86与x86_64系列则采用小端字节序（little endian）方式存储数据。 平常大多数PC与服务器如果使用的是Intel与AMD CPU，一般都是小端字节序（little endian） 网络字节序，是TCP/IP中规定好的一种数据表示格式，它与具体的CPU类型、操作系统等无关，从而可以保证数据在不同主机之间传输时能够被正确解释。 网络字节顺序采用大端字节序（big endian）排序方式。 如何具体判断本机的主机字节序呢？参考如下代码： //@ret：返回0小端字节序，返回1大端字节序 int dGetHostByteOrder() { uint32_t a = 0x12345678; uint8_t *p = (uint8_t *)(&a); if(*p==0x78) { return 0 } else { return 1; } } 2.网络字节序与主机字节序的相互转换 2.1常用系统调用 Linux socket网络编程中，经常会使用下面四个C标准库函数进行字节序间的转换。 #include uint32_t htonl(uint32_t hostlong); //把uint32_t类型(4字节)从主机序转换到网络序, host to network long uint16_t htons(uint16_t hostshort); //把uint16_t类型(2字节)从主机序转换到网络序，host to network short uint32_t ntohl(uint32_t netlong); //把uint32_t类型从网络序转换到主机序 uint16_t ntohs(uint16_t netshort); //把uint16_t类型从网络序转换到主机序 2.2 64位数值的转换 现在如果需要对64位类型数据进行主机字节序与网络字节序的转换，没有现成系统API可用，可以通过下面两种方法进行转换： 2.2.1使用移位 //主机序转网络序 unsigned long long htonll(unsigned long long val) { if(__BYTE_ORDER == __LITTLE_ENDIAN) { return (((unsigned long long )htonl((int)((val > 32))) > 32)); } else if (__BYTE_ORDER == __BIG_ENDIAN) { return val; } } //网络序转主机序 unsigned long long ntohll(unsigned long long val) { if (__BYTE_ORDER == __LITTLE_ENDIAN) { return (((unsigned long long )ntohl((int)((val > 32))) > 32)); } else if (__BYTE_ORDER == __BIG_ENDIAN) { return val; } } 2.2.2使用联合体union 根据联合体的特性：联合中所有成员引用的是内存中相同的位置，其长度为最长成员的长度。 typedef struct { unsigned int u32_h; unsigned int u32_l; }Int64_t; typedef union { unsigned long long u64; Int64_t st64; }Convert64_t; //主机序转网络序 unsigned long long htonll(unsigned long long val) { if (__BYTE_ORDER == __LITTLE_ENDIAN) { Convert64_t box_in, box_out; box_in.u64 = val; box_out.st64.u32_h = htonl(box_in.st64.u32_l); box_out.st64.u32_l = htonl(box_in.st64.u32_h); return box_out.u64; } else if (__BYTE_ORDER == __BIG_ENDIAN) { return val; } } //网络序转主机序 unsigned long long ntohll(unsigned long long val) { if (__BYTE_ORDER == __LITTLE_ENDIAN) { Convert64_t box_in, box_out; box_in.u64 = val; box_out.st64.u32_h = ntohl(box_in.st64.u32_l); box_out.st64.u32_l = ntohl(box_in.st64.u32_h); return box_out.u64; } else if(__BYTE_ORDER == __BIG_ENDIAN) { return val; } } 2.2.3使用编译器内置函数 #ifdef WIN32 #define ntohll(x) _byteswap_uint64 (x) #define htonll(x) _byteswap_uint64 (x) #else #if __BYTE_ORDER == __BIG_ENDIAN #define ntohll(x) (x) #define htonll(x) (x) #else #if __BYTE_ORDER == __LITTLE_ENDIAN #define ntohll(x) __bswap_64 (x) #define htonll(x) __bswap_64 (x) #endif #endif #endif "},"C++/网络通信socket/04-程序封装成类.html":{"url":"C++/网络通信socket/04-程序封装成类.html","title":"程序封装成类","keywords":"","body":"datetime:2022/12/28 14:37 author:nzb 程序封装成类 _cmpublic.h #ifndef _cmpublic_H #define _cmpublic_H #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include #include // 采用stl标准库的命名空间std using namespace std; #endif Writen()函数和Readn()函数 _freecplus.h // 从已经准备好的socket中读取数据。 // sockfd：已经准备好的socket连接。 // buffer：接收数据缓冲区的地址。 // n：本次接收数据的字节数。 // 返回值：成功接收到n字节的数据后返回true，socket连接不可用返回false。 bool Readn(const int sockfd,char *buffer,const size_t n); // 向已经准备好的socket中写入数据。 // sockfd：已经准备好的socket连接。 // buffer：待发送数据缓冲区的地址。 // n：待发送数据的字节数。 // 返回值：成功发送完n字节的数据后返回true，socket连接不可用返回false。 bool Writen(const int sockfd,const char *buffer,const size_t n); _freecplus.cpp bool Readn(const int sockfd, char *buffer, const size_t n) { int nLeft, nread, idx; nLeft = n; idx = 0; while (nLeft > 0) { if ((nread = recv(sockfd, buffer + idx, nLeft, 0)) 0) { if ((nwritten = send(sockfd, buffer + idx, nLeft, 0)) TcpWrite()函数和TcpRead()函数 _freecplus.h // 接收socket的对端发送过来的数据。 // sockfd：可用的socket连接。 // buffer：接收数据缓冲区的地址。 // ibuflen：本次成功接收数据的字节数。 // itimeout：接收等待超时的时间，单位：秒，缺省值是0-无限等待。 // 返回值：true-成功；false-失败，失败有两种情况：1）等待超时；2）socket连接已不可用。 bool TcpRead(const int sockfd,char *buffer,int *ibuflen,const int itimeout=0); // 向socket的对端发送数据。 // sockfd：可用的socket连接。 // buffer：待发送数据缓冲区的地址。 // ibuflen：待发送数据的字节数，如果发送的是ascii字符串，ibuflen取0，如果是二进制流数据，ibuflen为二进制数据块的大小。 // 返回值：true-成功；false-失败，如果失败，表示socket连接已不可用。 bool TcpWrite(const int sockfd,const char *buffer,const int ibuflen=0); _freecplus.cpp bool TcpRead(const int sockfd, char *buffer, int *ibuflen, const int itimeout) { if (sockfd == -1) return false; if (itimeout > 0) { fd_set tmpfd; FD_ZERO(&tmpfd); FD_SET(sockfd, &tmpfd); struct timeval timeout; timeout.tv_sec = itimeout; timeout.tv_usec = 0; int i; if ((i = select(sockfd + 1, &tmpfd, 0, 0, &timeout)) 服务端CTcpServer类 _freecplus.h // socket通信的服务端类 class CTcpServer { private: int m_socklen; // 结构体struct sockaddr_in的大小。 struct sockaddr_in m_clientaddr; // 客户端的地址信息。 struct sockaddr_in m_servaddr; // 服务端的地址信息。 public: int m_listenfd; // 服务端用于监听的socket。 int m_connfd; // 客户端连接上来的socket。 bool m_btimeout; // 调用Read和Write方法时，失败的原因是否是超时：true-超时，false-未超时。 int m_buflen; // 调用Read方法后，接收到的报文的大小，单位：字节。 CTcpServer(); // 构造函数。 // 服务端初始化。 // port：指定服务端用于监听的端口。 // 返回值：true-成功；false-失败，一般情况下，只要port设置正确，没有被占用，初始化都会成功。 bool InitServer(const unsigned int port); // 阻塞等待客户端的连接请求。 // 返回值：true-有新的客户端已连接上来，false-失败，Accept被中断，如果Accept失败，可以重新Accept。 bool Accept(); // 获取客户端的ip地址。 // 返回值：客户端的ip地址，如\"192.168.1.100\"。 char *GetIP(); // 接收客户端发送过来的数据。 // buffer：接收数据缓冲区的地址，数据的长度存放在m_buflen成员变量中。 // itimeout：等待数据的超时时间，单位：秒，缺省值是0-无限等待。 // 返回值：true-成功；false-失败，失败有两种情况：1）等待超时，成员变量m_btimeout的值被设置为true；2）socket连接已不可用。 bool Read(char *buffer, const int itimeout = 0); // 向客户端发送数据。 // buffer：待发送数据缓冲区的地址。 // ibuflen：待发送数据的大小，单位：字节，缺省值为0，如果发送的是ascii字符串，ibuflen取0，如果是二进制流数据，ibuflen为二进制数据块的大小。 // 返回值：true-成功；false-失败，如果失败，表示socket连接已不可用。 bool Write(const char *buffer, const int ibuflen = 0); // 关闭监听的socket，即m_listenfd，常用于多进程服务程序的子进程代码中。 void CloseListen(); // 关闭客户端的socket，即m_connfd，常用于多进程服务程序的父进程代码中。 void CloseClient(); ~CTcpServer(); // 析构函数自动关闭socket，释放资源。 }; _freecplus.cpp CTcpServer::CTcpServer() { m_listenfd = -1; m_connfd = -1; m_socklen = 0; m_btimeout = false; } bool CTcpServer::InitServer(const unsigned int port) { if (m_listenfd > 0) { close(m_listenfd); m_listenfd = -1; } if ((m_listenfd = socket(AF_INET, SOCK_STREAM, 0)) 0) { fd_set tmpfd; FD_ZERO(&tmpfd); FD_SET(m_connfd, &tmpfd); struct timeval timeout; timeout.tv_sec = itimeout; timeout.tv_usec = 0; m_btimeout = false; int i; if ((i = select(m_connfd + 1, &tmpfd, 0, 0, &timeout)) 0) { close(m_listenfd); m_listenfd = -1; } } void CTcpServer::CloseClient() { if (m_connfd > 0) { close(m_connfd); m_connfd = -1; } } CTcpServer::~CTcpServer() { CloseListen(); CloseClient(); } 客户端CTcpClient类 _freecplus.h // socket通信的客户端类 class CTcpClient { public: int m_sockfd; // 客户端的socket. char m_ip[21]; // 服务端的ip地址。 int m_port; // 与服务端通信的端口。 bool m_btimeout; // 调用Read和Write方法时，失败的原因是否是超时：true-超时，false-未超时。 int m_buflen; // 调用Read方法后，接收到的报文的大小，单位：字节。 CTcpClient(); // 构造函数。 // 向服务端发起连接请求。 // ip：服务端的ip地址。 // port：服务端监听的端口。 // 返回值：true-成功；false-失败。 bool ConnectToServer(const char *ip, const int port); // 接收服务端发送过来的数据。 // buffer：接收数据缓冲区的地址，数据的长度存放在m_buflen成员变量中。 // itimeout：等待数据的超时时间，单位：秒，缺省值是0-无限等待。 // 返回值：true-成功；false-失败，失败有两种情况：1）等待超时，成员变量m_btimeout的值被设置为true；2）socket连接已不可用。 bool Read(char *buffer, const int itimeout = 0); // 向服务端发送数据。 // buffer：待发送数据缓冲区的地址。 // ibuflen：待发送数据的大小，单位：字节，缺省值为0，如果发送的是ascii字符串，ibuflen取0，如果是二进制流数据，ibuflen为二进制数据块的大小。 // 返回值：true-成功；false-失败，如果失败，表示socket连接已不可用。 bool Write(const char *buffer, const int ibuflen = 0); // 断开与服务端的连接 void Close(); ~CTcpClient(); // 析构函数自动关闭socket，释放资源。 }; _freecplus.cpp CTcpClient::CTcpClient() { m_sockfd = -1; memset(m_ip, 0, sizeof(m_ip)); m_port = 0; m_btimeout = false; } bool CTcpClient::ConnectToServer(const char *ip, const int port) { if (m_sockfd != -1) { close(m_sockfd); m_sockfd = -1; } strcpy(m_ip, ip); m_port = port; struct hostent *h; struct sockaddr_in servaddr; if ((m_sockfd = socket(AF_INET, SOCK_STREAM, 0)) h_addr, h->h_length); if (connect(m_sockfd, (struct sockaddr *) &servaddr, sizeof(servaddr)) != 0) { close(m_sockfd); m_sockfd = -1; return false; } return true; } bool CTcpClient::Read(char *buffer, const int itimeout) { if (m_sockfd == -1) return false; if (itimeout > 0) { fd_set tmpfd; FD_ZERO(&tmpfd); FD_SET(m_sockfd, &tmpfd); struct timeval timeout; timeout.tv_sec = itimeout; timeout.tv_usec = 0; m_btimeout = false; int i; if ((i = select(m_sockfd + 1, &tmpfd, 0, 0, &timeout)) 0) close(m_sockfd); m_sockfd = -1; memset(m_ip, 0, sizeof(m_ip)); m_port = 0; m_btimeout = false; } CTcpClient::~CTcpClient() { Close(); } 简单服务端和客户端示例 _server.cpp #include \"_freecplus.h\" int main(int argc, char *argv[]) { if (argc != 2) { printf(\"Using:./demo48 port\\nExample:./demo48 5005\\n\\n\"); return -1; } CTcpServer TcpServer; // 创建服务端对象。 if (TcpServer.InitServer(atoi(argv[1])) == false) // 初始化TcpServer的通信端口。 { printf(\"TcpServer.InitServer(%s) failed.\\n\", argv[1]); return -1; } if (TcpServer.Accept() == false) // 等待客户端连接。 { printf(\"TcpServer.Accept() failed.\\n\"); return -1; } printf(\"客户端(%s)已连接。\\n\", TcpServer.GetIP()); char strbuffer[1024]; // 存放数据的缓冲区。 while (true) { memset(strbuffer, 0, sizeof(strbuffer)); //if (TcpServer.Read(strbuffer,300)==false) break; // 接收客户端发过来的请求报文。 if (TcpServer.Read(strbuffer, 10) == false) break; // 接收客户端发过来的请求报文。 printf(\"接收：%s\\n\", strbuffer); strcat(strbuffer, \"ok\"); // 在客户端的报文后加上\"ok\"。 printf(\"发送：%s\\n\", strbuffer); if (TcpServer.Write(strbuffer) == false) break; // 向客户端回应报文。 } printf(\"客户端已断开。\\n\"); // 程序直接退出，析构函数会释放资源。 } _client.cpp #include \"_freecplus.h\" int main(int argc, char *argv[]) { if (argc != 3) { printf(\"Using:./demo47 ip port\\nExample:./demo47 172.21.0.3 5005\\n\\n\"); return -1; } CTcpClient TcpClient; // 创建客户端的对象。 if (TcpClient.ConnectToServer(argv[1], atoi(argv[2])) == false) // 向服务端发起连接请求。 { printf(\"TcpClient.ConnectToServer(\\\"%s\\\",%s) failed.\\n\", argv[1], argv[2]); return -1; } char strbuffer[1024]; // 存放数据的缓冲区。 for (int ii = 0; ii "},"C++/网络通信socket/05-多进程网络服务端.html":{"url":"C++/网络通信socket/05-多进程网络服务端.html","title":"多进程网络服务端","keywords":"","body":"datetime:2022/12/29 14:37 author:nzb 多进程网络服务端 需要有信号和多进程相关知识 利用信号防止产生僵尸进程 僵尸进程： 进程使用fork 创建子进程，如果子进程退出，而父进程并没有调用 wait 获 waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。 避免僵尸进程的方法： 1.fork 两次用孙子进程去完成子进程的任务 2.用 wait() 函数使父进程阻塞 3.使用信号量，在 signal handler 中调用 waitpid , 这样父进程不用阻塞 server.cpp #include \"_freecplus.h\" CLogFile logfile; // 服务程序的运行日志。 CTcpServer TcpServer; // 创建服务端对象。 // 程序退出时调用的函数 void FathEXIT(int sig); // 父进程退出函数。 void ChldEXIT(int sig); // 子进程退出函数。 int main(int argc, char *argv[]) { if (argc != 3) { printf(\"Using:./mpserver port logfile\\nExample:./mpserver 5005 /tmp/mpserver.log\\n\\n\"); return -1; } // 关闭全部的信号 for (int ii = 0; ii 0) { TcpServer.CloseClient(); continue; } // 父进程返回到循环首部。 // 子进程重新设置退出信号。 signal(SIGINT, ChldEXIT); signal(SIGTERM, ChldEXIT); TcpServer.CloseListen(); // 以下是子进程，负责与客户端通信。 logfile.Write(\"客户端(%s)已连接。\\n\", TcpServer.GetIP()); char strbuffer[1024]; // 存放数据的缓冲区。 while (true) { memset(strbuffer, 0, sizeof(strbuffer)); if (TcpServer.Read(strbuffer, 50) == false) break; // 接收客户端发过来的请求报文。 logfile.Write(\"接收：%s\\n\", strbuffer); strcat(strbuffer, \"ok\"); // 在客户端的报文后加上\"ok\"。 logfile.Write(\"发送：%s\\n\", strbuffer); if (TcpServer.Write(strbuffer) == false) break; // 向客户端回应报文。 } logfile.Write(\"客户端已断开。\\n\"); // 程序直接退出，析构函数会释放资源。 ChldEXIT(-1); // 通信完成后，子进程退出。 } } // 父进程退出时调用的函数 void FathEXIT(int sig) { if (sig > 0) { signal(sig, SIG_IGN); signal(SIGINT, SIG_IGN); signal(SIGTERM, SIG_IGN); logfile.Write(\"catching the signal(%d).\\n\", sig); } kill(0, 15); // 通知其它的子进程退出。 logfile.Write(\"父进程退出。\\n\"); // 编写善后代码（释放资源、提交或回滚事务） TcpServer.CloseClient(); exit(0); } // 子进程退出时调用的函数 void ChldEXIT(int sig) { // 为什么大于0，因为可以这样使用 ChldEXIT(-1); // 通信完成后，子进程退出。 if (sig > 0) { signal(sig, SIG_IGN); signal(SIGINT, SIG_IGN); signal(SIGTERM, SIG_IGN); } logfile.Write(\"子进程退出。\\n\"); // 编写善后代码（释放资源、提交或回滚事务） TcpServer.CloseClient(); exit(0); } client.cpp #include \"_freecplus.h\" int main(int argc, char *argv[]) { if (argc != 3) { printf(\"Using:./demo47 ip port\\nExample:./demo47 172.21.0.3 5005\\n\\n\"); return -1; } CTcpClient TcpClient; // 创建客户端的对象。 if (TcpClient.ConnectToServer(argv[1], atoi(argv[2])) == false) // 向服务端发起连接请求。 { printf(\"TcpClient.ConnectToServer(\\\"%s\\\",%s) failed.\\n\", argv[1], argv[2]); return -1; } char strbuffer[1024]; // 存放数据的缓冲区。 for (int ii = 0; ii 增加业务逻辑 server.cpp #include \"_freecplus.h\" CLogFile logfile; CTcpServer TcpServer; // 创建服务端对象。 // 程序退出时调用的函数 void FathEXIT(int sig); // 父进程退出函数。 void ChldEXIT(int sig); // 子进程退出函数。 // 处理业务的主函数。 bool _main(const char *strrecvbuffer, char *strsendbuffer); // 心跳报文。 bool biz000(const char *strrecvbuffer, char *strsendbuffer); // 身份验证业务处理函数。 bool biz001(const char *strrecvbuffer, char *strsendbuffer); // 查询余客业务处理函数。 bool biz002(const char *strrecvbuffer, char *strsendbuffer); int main(int argc, char *argv[]) { if (argc != 3) { printf(\"Using:./mpserver_biz port logfile\\nExample:./mpserver_biz 5005 /tmp/mpserver_biz.log\\n\\n\"); return -1; } // 关闭全部的信号 for (int ii = 0; ii 0) { TcpServer.CloseClient(); continue; } // 父进程返回到循环首部。 // 子进程重新设置退出信号。 signal(SIGINT, ChldEXIT); signal(SIGTERM, ChldEXIT); TcpServer.CloseListen(); // 以下是子进程，负责与客户端通信。 logfile.Write(\"客户端(%s)已连接。\\n\", TcpServer.GetIP()); char strrecvbuffer[1024], strsendbuffer[1024]; // 存放数据的缓冲区。 while (true) { memset(strrecvbuffer, 0, sizeof(strrecvbuffer)); memset(strsendbuffer, 0, sizeof(strsendbuffer)); if (TcpServer.Read(strrecvbuffer, 30) == false) break; // 接收客户端发过来的请求报文。 logfile.Write(\"接收：%s\\n\", strrecvbuffer); // 处理业务的主函数。 if (_main(strrecvbuffer, strsendbuffer) == false) ChldEXIT(-1); logfile.Write(\"发送：%s\\n\", strsendbuffer); if (TcpServer.Write(strsendbuffer) == false) break; // 向客户端回应报文。 } logfile.Write(\"客户端已断开。\\n\"); // 程序直接退出，析构函数会释放资源。 ChldEXIT(-1); // 通信完成后，子进程退出。 } } // 父进程退出时调用的函数 void FathEXIT(int sig) { if (sig > 0) { signal(sig, SIG_IGN); signal(SIGINT, SIG_IGN); signal(SIGTERM, SIG_IGN); logfile.Write(\"catching the signal(%d).\\n\", sig); } kill(0, 15); // 通知其它的子进程退出。 logfile.Write(\"父进程退出。\\n\"); // 编写善后代码（释放资源、提交或回滚事务） TcpServer.CloseClient(); exit(0); } // 子进程退出时调用的函数 void ChldEXIT(int sig) { if (sig > 0) { signal(sig, SIG_IGN); signal(SIGINT, SIG_IGN); signal(SIGTERM, SIG_IGN); } logfile.Write(\"子进程退出。\\n\"); // 编写善后代码（释放资源、提交或回滚事务） TcpServer.CloseClient(); exit(0); } bool _main(const char *strrecvbuffer, char *strsendbuffer) // 处理业务的主函数。 { int ibizcode = -1; GetXMLBuffer(strrecvbuffer, \"bizcode\", &ibizcode); switch (ibizcode) { case 0: // 心跳 biz000(strrecvbuffer, strsendbuffer); break; case 1: // 身份验证。 biz001(strrecvbuffer, strsendbuffer); break; case 2: // 查询余额。 biz002(strrecvbuffer, strsendbuffer); break; default: logfile.Write(\"非法报文：%s\\n\", strrecvbuffer); return false; } return true; } // 身份验证业务处理函数。 bool biz001(const char *strrecvbuffer, char *strsendbuffer) { char username[51], password[51]; memset(username, 0, sizeof(username)); memset(password, 0, sizeof(password)); GetXMLBuffer(strrecvbuffer, \"username\", username, 50); GetXMLBuffer(strrecvbuffer, \"password\", password, 50); if ((strcmp(username, \"wucz\") == 0) && (strcmp(password, \"p@ssw0rd\") == 0)) sprintf(strsendbuffer, \"0成功。\"); else sprintf(strsendbuffer, \"-1用户名或密码不正确。\"); return true; } // 查询余额业务处理函数。 bool biz002(const char *strrecvbuffer, char *strsendbuffer) { char cardid[51]; memset(cardid, 0, sizeof(cardid)); GetXMLBuffer(strrecvbuffer, \"cardid\", cardid, 50); if (strcmp(cardid, \"62620000000001\") == 0) sprintf(strsendbuffer, \"0成功。100.50\"); else sprintf(strsendbuffer, \"-1卡号不存在。\"); return true; } // 心跳报文 bool biz000(const char *strrecvbuffer, char *strsendbuffer) { sprintf(strsendbuffer, \"0成功。\"); return true; } client.cpp #include \"_freecplus.h\" CTcpClient TcpClient; // 创建客户端的对象。 bool biz000(); // 发送心跳报文。 bool biz001(); // 身份验证 bool biz002(); // 余额查询 int main(int argc, char *argv[]) { if (argc != 3) { printf(\"Using:./demo47_biz ip port\\nExample:./demo47_biz 172.21.0.3 5005\\n\\n\"); return -1; } if (TcpClient.ConnectToServer(argv[1], atoi(argv[2])) == false) // 向服务端发起连接请求。 { printf(\"TcpClient.ConnectToServer(\\\"%s\\\",%s) failed.\\n\", argv[1], argv[2]); return -1; } /* // 身份验证 if (biz001()==false) { printf(\"biz001() failed.\\n\"); return -1; } sleep(10); biz002(); // 余额查询 sleep(5); biz002(); // 余额查询 */ for (int ii = 0; ii 1wuczp@ssw0rd\"); printf(\"发送：%s\\n\", strbuffer); if (TcpClient.Write(strbuffer) == false) return false; // 向服务端发送请求报文。 memset(strbuffer, 0, sizeof(strbuffer)); if (TcpClient.Read(strbuffer, 20) == false) return false; // 接收服务端的回应报文。 printf(\"接收：%s\\n\", strbuffer); int iretcode = -1; GetXMLBuffer(strbuffer, \"retcode\", &iretcode); if (iretcode == 0) { printf(\"身份验证成功。\\n\"); return true; } printf(\"身份验证失败。\\n\"); return false; } // 余额查询 bool biz002() { char strbuffer[1024]; // 存放数据的缓冲区。 memset(strbuffer, 0, sizeof(strbuffer)); snprintf(strbuffer, 1000, \"262620000000001\"); printf(\"发送：%s\\n\", strbuffer); if (TcpClient.Write(strbuffer) == false) return false; // 向服务端发送请求报文。 memset(strbuffer, 0, sizeof(strbuffer)); if (TcpClient.Read(strbuffer, 20) == false) return false; // 接收服务端的回应报文。 printf(\"接收：%s\\n\", strbuffer); int iretcode = -1; GetXMLBuffer(strbuffer, \"retcode\", &iretcode); if (iretcode == 0) { printf(\"查询余额成功。\\n\"); return true; } printf(\"查询余额失败。\\n\"); return false; } bool biz000() // 发送心跳报文。 { char strbuffer[1024]; // 存放数据的缓冲区。 memset(strbuffer, 0, sizeof(strbuffer)); snprintf(strbuffer, 1000, \"0\"); //printf(\"发送：%s\\n\",strbuffer); if (TcpClient.Write(strbuffer) == false) return false; // 向服务端发送请求报文。 memset(strbuffer, 0, sizeof(strbuffer)); if (TcpClient.Read(strbuffer, 20) == false) return false; // 接收服务端的回应报文。 //printf(\"接收：%s\\n\",strbuffer); return true; } "},"C++/网络通信socket/06-TCP长连接和短连接.html":{"url":"C++/网络通信socket/06-TCP长连接和短连接.html","title":"TCP长连接和短连接","keywords":"","body":"datetime:2022/12/29 15:46 author:nzb TCP长连接和短连接 client和server建立连接进行通信，通信完成后释放连接，建立连接时需要3次握手，释放连接需要4次挥手，连接的建立和释放都需要时间，server还有创建新进程或线程的开销 短连接 client/server间只进行一次或连续多次通信，通信完成后马上断开了，管理起来比较简单，不需要额外的控制手段。 长连接 client/server间需要多次通信，通信的频率和次数不确定，所以client和server需要保持这个连接。 根据不同的应用场景采用不同的策略，没有十全十美的旋转，只有合适的选择。 长连接的心跳机制 如果client与server采用长连接，在连接空闲时，client每若干秒向server发送一个心跳报文，server也回复一个心跳报文，确认连接继续生效中。 如果server在约定的时间内没有收到client的任何报文，则认为客户端已掉线，就主动断开连接，释放资源。 心跳报文建议在60秒之内，不要超过120秒 "},"C++/网络通信socket/07-多线程网络服务端.html":{"url":"C++/网络通信socket/07-多线程网络服务端.html","title":"多线程网络服务端","keywords":"","body":"datetime:2022/12/29 15:46 author:nzb 多线程网络服务端 server.cpp #include \"_freecplus.h\" void *pthmain(void *arg); // 线程主函数。 vector vpthid; // 存放线程id的容器。 void mainexit(int sig); // 信号2和15的处理函数。 void pthmainexit(void *arg); // 线程清理函数。 CLogFile logfile; // 服务程序的运行日志。 CTcpServer TcpServer; // 创建服务端对象。 // 处理业务的主函数。 bool _main(const char *strrecvbuffer, char *strsendbuffer); // 心跳报文。 bool biz000(const char *strrecvbuffer, char *strsendbuffer); // 身份验证业务处理函数。 bool biz001(const char *strrecvbuffer, char *strsendbuffer); // 查询余客业务处理函数。 bool biz002(const char *strrecvbuffer, char *strsendbuffer); int main(int argc, char *argv[]) { if (argc != 3) { printf(\"Using:./mtserver_biz port logfile\\nExample:./mtserver_biz 5005 /tmp/mtserver_biz.log\\n\\n\"); return -1; } // 关闭全部的信号 for (int ii = 0; ii 0成功。\"); else sprintf(strsendbuffer, \"-1用户名或密码不正确。\"); return true; } // 查询余额业务处理函数。 bool biz002(const char *strrecvbuffer, char *strsendbuffer) { char cardid[51]; memset(cardid, 0, sizeof(cardid)); GetXMLBuffer(strrecvbuffer, \"cardid\", cardid, 50); if (strcmp(cardid, \"62620000000001\") == 0) sprintf(strsendbuffer, \"0成功。100.50\"); else sprintf(strsendbuffer, \"-1卡号不存在。\"); return true; } // 心跳报文 bool biz000(const char *strrecvbuffer, char *strsendbuffer) { sprintf(strsendbuffer, \"0成功。\"); return true; } client.cpp #include \"_freecplus.h\" CTcpClient TcpClient; // 创建客户端的对象。 bool biz000(); // 发送心跳报文。 bool biz001(); // 身份验证 bool biz002(); // 余额查询 int main(int argc, char *argv[]) { if (argc != 3) { printf(\"Using:./demo47_biz ip port\\nExample:./demo47_biz 172.21.0.3 5005\\n\\n\"); return -1; } if (TcpClient.ConnectToServer(argv[1], atoi(argv[2])) == false) // 向服务端发起连接请求。 { printf(\"TcpClient.ConnectToServer(\\\"%s\\\",%s) failed.\\n\", argv[1], argv[2]); return -1; } /* // 身份验证 if (biz001()==false) { printf(\"biz001() failed.\\n\"); return -1; } sleep(10); biz002(); // 余额查询 sleep(5); biz002(); // 余额查询 */ for (int ii = 0; ii 1wuczp@ssw0rd\"); printf(\"发送：%s\\n\", strbuffer); if (TcpClient.Write(strbuffer) == false) return false; // 向服务端发送请求报文。 memset(strbuffer, 0, sizeof(strbuffer)); if (TcpClient.Read(strbuffer, 20) == false) return false; // 接收服务端的回应报文。 printf(\"接收：%s\\n\", strbuffer); int iretcode = -1; GetXMLBuffer(strbuffer, \"retcode\", &iretcode); if (iretcode == 0) { printf(\"身份验证成功。\\n\"); return true; } printf(\"身份验证失败。\\n\"); return false; } // 余额查询 bool biz002() { char strbuffer[1024]; // 存放数据的缓冲区。 memset(strbuffer, 0, sizeof(strbuffer)); snprintf(strbuffer, 1000, \"262620000000001\"); printf(\"发送：%s\\n\", strbuffer); if (TcpClient.Write(strbuffer) == false) return false; // 向服务端发送请求报文。 memset(strbuffer, 0, sizeof(strbuffer)); if (TcpClient.Read(strbuffer, 20) == false) return false; // 接收服务端的回应报文。 printf(\"接收：%s\\n\", strbuffer); int iretcode = -1; GetXMLBuffer(strbuffer, \"retcode\", &iretcode); if (iretcode == 0) { printf(\"查询余额成功。\\n\"); return true; } printf(\"查询余额失败。\\n\"); return false; } bool biz000() // 发送心跳报文。 { char strbuffer[1024]; // 存放数据的缓冲区。 memset(strbuffer, 0, sizeof(strbuffer)); snprintf(strbuffer, 1000, \"0\"); //printf(\"发送：%s\\n\",strbuffer); if (TcpClient.Write(strbuffer) == false) return false; // 向服务端发送请求报文。 memset(strbuffer, 0, sizeof(strbuffer)); if (TcpClient.Read(strbuffer, 20) == false) return false; // 接收服务端的回应报文。 //printf(\"接收：%s\\n\",strbuffer); return true; } "},"C++/网络通信socket/08-性能测试.html":{"url":"C++/网络通信socket/08-性能测试.html","title":"性能测试","keywords":"","body":"datetime:2022/12/29 17:46 author:nzb 性能测试 性能测试的重要性 在实际项目开发中，除了完成程序的功能，还需要测试性能。 在充分了解服务端的性能后，才能决定如何选择服务端的架构，还有网络带宽、硬件配置等。 服务端的性能指标是面试中必问的。 如果不了解系统的性能指标，面试官会认为您没有实际项目开发经验或对网络编程是一知半解。主要的性能指标如下： 1）服务端的并发能力 2）服务端的业务处理能力 3）客户端业务响应时效 4）网络带宽 重要的业务系统，最好是与系统管理员和网络管理员一起测试。 测试服务端并发性能 服务端最大并发量，即可以接受客户端的最大数量。 注意客户端业务请求不要太频繁。 重视CPU和内存使用率的变化(磁盘I/O, 网络I/O)。 测试服务端业务性能 服务端最大业务处理能力，即每秒可以处理的业务请求数量。 注意客户端的数量不要太多。 重视CPU和内存使用率的变化。 多进程和多线程服务端性能差异 对比维度 多进程 多线程 总结 数据共享、同步 数据共享复杂，需要用IPC；数据是分开的，同步简单 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 各有优势 内存、CPU 占用内存多，切换复杂，CPU利用率低 占用内存少，切换简单，CPU利用率高 线程占优 创建销毁、切换 创建销毁、切换复杂，速度慢 创建销毁、切换简单，速度很快 线程占优 编程、调试 编程简单，调试简单 编程复杂，调试复杂 进程占优 可靠性 进程间不会互相影响 一个线程挂掉将导致整个进程挂掉 进程占优 分布式 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 适应于多核分布式 进程占优 多进程和多线程如何选择？ 1）需要频繁创建销毁的优先用线程 这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的 2）需要进行大量计算的优先使用线程 所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。 这种原则最常见的是图像处理、算法处理。 3）强相关的处理用线程，弱相关的处理用进程 一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。 当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。 4）可能要扩展到多机分布的用进程，多核分布的用线程 需要提醒的是：虽然给了这么多的选择原则，但实际应用中基本上都是“进程+线程”的结合方式，千万不要真的陷入一种非此即彼的误区。 测试客户端的响应时间 客户端业务的响应时间，即发出业务请求与收到服务端回应的时间间隔，关系到用户体验。 测试环境包括： 业务的闲时/忙时； 不同的网络环境（局域网、互联网、移动通信网络） 测试网络带宽 测试的目的是根据业务需求，判断出对网络带宽要求。 测试网络的有效带宽，方法可以百度。 测试网络带宽能承受的业务量，不同的业务对带宽的利用率不一样。要求测试环境的各环节不能存在性能瓶颈，唯一瓶颈就是网络带宽。 注意： 只发送数据，不接收回应 上行和下行分开测试 "},"C++/网络通信socket/09-IO复用-select.html":{"url":"C++/网络通信socket/09-IO复用-select.html","title":"IO复用-select","keywords":"","body":"datetime:2022/12/30 11:00 author:nzb I/O复用-select 1、导语 多进程/线程并发模型，为每个socket分配一个进程/线程。 IO多路复用：通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。 应用：适用于针对大量的io请求的情况，对于服务器必须在同时处理来自客户端的大量的io操作的时候，就非常适合 与多进程和多线程技术相比，I/O多路复用技术的最大优势就是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。 目前支持I/O多路复用的系统调用有select, pselect, poll, epoll, 但他们本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 select, pselect, poll, epoll 都是属于IO设计模式Reactor的IO策略。 2、IO多路复用使用场景 IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合： 当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。 当一个客户同时处理多个套接口时，这种情况是可能的，但很少出现。 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。 3、select 3.1、select基本原理 select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。 3.2、select基本流程 3.3、select函数原型 该函数准许进程指示内核等待多个事件中的任何一个发送，并只在有一个或多个事件发生或经历一段指定的时间后才唤醒自己。函数原型如下： #include #include int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout); // 返回值：就绪描述符的数目，超时返回0，出错返回-1 // 函数参数介绍如下： //（1）第一个参数maxfdp1指定待测试的描述字个数，它的值是待测试的最大描述字加1（因此把该参数命名为maxfdp1）描述字0、1、2...(maxfdp1-1)均将被测试（文件描述符是从0开始的）。 //（2）中间的三个参数readset、writeset和exceptset指定我们要让内核测试读、写和异常条件的描述字。如果对某一个的条件不感兴趣，就可以把它设为空指针。 // writeset的write会阻塞，但是阻塞时间是非常短的，所以一般需要监听，设置为空 struct fd_set; //可以理解为一个集合，这个集合中存放的是文件描述符，可通过以下四个宏进行设置： void FD_ZERO(fd_set *fdset); //清空集合 void FD_SET(int fd, fd_set *fdset); //将一个给定的文件描述符加入集合之中 void FD_CLR(int fd, fd_set *fdset); //将一个给定的文件描述符从集合中删除 int FD_ISSET(int fd, fd_set *fdset); // 检查集合中指定的文件描述符是否可以读写 //（3）timeout指定等待的时间，告知内核等待所指定描述字中的任何一个就绪可花多少时间。其timeval结构用于指定这段时间的秒数和微秒数。 struct timeval { long tv_sec; //seconds long tv_usec; //microseconds }; /* 这个参数有三种可能： （1）永远等待下去：仅在有一个描述字准备好I/O时才返回。为此，把该参数设置为空指针NULL。 （2）等待一段固定时间：在有一个描述字准备好I/O时返回，但是不超过由该参数所指向的timeval结构中指定的秒数和微秒数。 （3）根本不等待：检查描述字后立即返回，这称为轮询。为此，该参数必须指向一个timeval结构，而且其中的定时器值必须为0。 */ 位图Bitmap的原理 3.4、select优点 跨平台。（几乎所有的平台都支持） 时间精度高。（ns级别） 3.6、select缺点 最大限制：单个进程能够监视的文件描述符的数量存在最大限制。(基于数组存储的赶脚)一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。它由FD_SETSIZE设置，32位机默认是1024个。64位机默认是2048. 时间复杂度： 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低，时间复杂度O(n)。 当套接字比较多的时候，每次select() 都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。它仅仅知道有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度 ，同时处理的流越多，无差别轮询时间就越长。 内存拷贝：需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。 3.7、 Select的超时机制 int maxfdp 是指集合中所有描述符的最大值加1 fd_set *readfds 监视是否有新的socket连接，或现有的描述符是否有数据可读。 fd_set *writefds 监视是否可以向描述符中写入数据，只要缓存没满，所监视的描述符都可以写，select立即返回。 fd_set *exceptfds 监视描述符中的异常，从未使用过 struct timeval *timeout 超时机制。 3.8、select模型会丢失事件和数据吗？ 答：不会。select采用水平触发的方式，如果报告fd后事件没有被处理或者数据没有被完全读取，那么下次select时会再次报告该id，也就是说select不会丢失事件和数据。 3.9、select的其它用途 在Unix（Linux）世界里，一切皆文件，文件就是一串二进制流，不管socket、管道、终端、设备等都是文件，一切都是流，在信息交换的过程中， 都是对这些流进行数据的收发操作，简称为I/O操作(input and output), 往流中读出数据，系统调用read，写入数据，系统调用write。 select是I/O复用函数，除了用于网络通信，还可以用于文件、管道、终端、设备等操作，但开发场景比较少。 3.7、示例代码 tcpselect.cpp #include #include #include #include #include #include #include // 初始化服务端的监听端口。 int initserver(int port); int main(int argc, char *argv[]) { if (argc != 2) { printf(\"usage: ./tcpselect port\\n\"); return -1; } // 初始化服务端用于监听的socket。 int listensock = initserver(atoi(argv[1])); printf(\"listensock=%d\\n\", listensock); if (listensock 0; ii--) { if (FD_ISSET(ii, &readfdset)) { maxfd = ii; break; } } printf(\"maxfd=%d\\n\", maxfd); } continue; } printf(\"recv(eventfd=%d,size=%d):%s\\n\", eventfd, isize, buffer); // 把收到的报文发回给客户端。 write(eventfd, buffer, strlen(buffer)); } } } return 0; } // 初始化服务端的监听端口。 int initserver(int port) { int sock = socket(AF_INET, SOCK_STREAM, 0); if (sock client.cpp #include #include #include #include #include #include #include #include int main(int argc, char *argv[]) { if (argc != 3) { printf(\"usage:./tcpclient ip port\\n\"); return -1; } int sockfd; struct sockaddr_in servaddr; char buf[1024]; if ((sockfd = socket(AF_INET, SOCK_STREAM, 0)) "},"C++/网络通信socket/10-IO复用-poll.html":{"url":"C++/网络通信socket/10-IO复用-poll.html","title":"IO复用-poll","keywords":"","body":"datetime:2022/12/30 17:11 author:nzb I/O复用-poll 4、poll 4.1、poll基本原理 - poll和select在本质上没有差别，管理多个描述符也是送行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 select采用fdse煤用bitmap , poll采用了数组. poll和select同样存在一个缺点就是，文件描述符的数组植整体复制于 用户态和内核态的地址空间之间，而不论这些文件描述符是否有事件， 它的开销随着文件描述符数量的增加而线性增大. 还有poll返回后，也需要历遍整个描述符的数组才能得到有事件的描 4.2、poll基本流程 类似select 4.3、poll函数原型 #include #include int poll(struct pollfd *fds, unsigned int nfds, int timeout); // （1）pollfd结构体定义如下： struct pollfd { int fd; /* 文件描述符 */ short events; /* 等待的事件 */ short revents; /* 实际发生了的事件 */ }; /* 每一个pollfd结构体指定了一个被监视的文件描述符。因此可以传递多个结构体，指示poll()监视多个文件描述符。 （2）events域是监视该文件描述符的事件掩码，由用户来设置这个域。 　　　　POLLIN　　　　　　　　 有数据可读。 　　　　POLLRDNORM　　　　　　有普通数据可读。 　　　　POLLRDBAND　　　　　　有优先数据可读。 　　　　POLLPRI　　　　　　　　有紧迫数据可读。 　　　　POLLOUT　　　　　　　　写数据不会导致阻塞。 　　　　POLLWRNORM　　　　　　写普通数据不会导致阻塞。 　　　　POLLWRBAND　　　　　　写优先数据不会导致阻塞。 　　　　POLLMSGSIGPOLL　　　　消息可用。 （3）revents域是文件描述符的操作结果事件掩码，内核在调用返回时设置这个域。events域中请求的任何事件都可能在revents域中返回。 　　 此外，revents域中还可能返回下列事件： 　　 　　　　POLLER　　 指定的文件描述符发生错误。 　　　　POLLHUP　　 指定的文件描述符挂起事件。 　　　　POLLNVAL　　指定的文件描述符非法。 　　 这些事件在events域中无意义，因为它们在合适的时候总是会从revents中返回。 　　 （4）举个栗子：要同时监视一个文件描述符是否可读和可写， 　　　　我们可以设置 events 为POLLIN | POLLOUT。 　　　　在poll返回时，我们可以检查revents中的标志，对应于文件描述符请求的events结构体。 　　　　如果POLLIN事件被设置，则文件描述符可以被读取而不阻塞。 　　　　如果POLLOUT被设置，则文件描述符可以写入而不导致阻塞。 　　　　这些标志并不是互斥的：它们可能被同时设置，表示这个文件描述符的读取和写入操作都会正常返回而不阻塞。 　　 （5）nfds参数是数组fds元素的个数。 （6）timeout参数指定等待的毫秒数，无论I/O是否准备好，poll都会返回。 　　　　timeout指定为负数值表示无限超时，使poll()一直挂起直到一个指定事件发生； 　　　　timeout为0指示poll调用立即返回并列出准备好I/O的文件描述符，但并不等待其它的事件。 　 （7）返回值和错误代码 　　 　　成功时，poll()返回结构体中revents域不为0的文件描述符个数； 　　如果在超时前没有任何事件发生，poll()返回0； 　　失败时，poll()返回-1， 　　　　并设置errno为下列值之一： 　　 　　　　EBADF　　 一个或多个结构体中指定的文件描述符无效。 　　 　　　　EFAULTfds　　 指针指向的地址超出进程的地址空间。 　　 　　　　EINTR　　　　 请求的事件之前产生一个信号，调用可以重新发起。 　　 　　　　EINVALnfds　　 参数超出PLIMIT_NOFILE值。 　　 　　　　ENOMEM　　 可用内存不足，无法完成请求。 */ 4.4、poll优点 没有最大连接数的限制。（基于链表来存储的） 4.5、poll缺点 时间复杂度： 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低，时间复杂度O(n)。 它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 内存拷贝：大量的fd数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 水平触发：如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 注意：select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。 事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 4.6、示例代码 tcpselect.cpp #include #include #include #include #include #include #include #include // ulimit -n #define MAXNFDS 1024 // 初始化服务端的监听端口。 int initserver(int port); int main(int argc, char *argv[]) { if (argc != 2) { printf(\"usage: ./tcppoll port\\n\"); return -1; } // 初始化服务端用于监听的socket。 int listensock = initserver(atoi(argv[1])); printf(\"listensock=%d\\n\", listensock); if (listensock MAXNFDS) { printf(\"clientsock(%d)>MAXNFDS(%d)\\n\", clientsock, MAXNFDS); close(clientsock); continue; } fds[clientsock].fd = clientsock; fds[clientsock].events = POLLIN; fds[clientsock].revents = 0; if (maxfd 0; ii--) { if (fds[ii].fd != -1) { maxfd = ii; break; } } printf(\"maxfd=%d\\n\", maxfd); } continue; } printf(\"recv(eventfd=%d,size=%d):%s\\n\", eventfd, isize, buffer); // 把收到的报文发回给客户端。 write(eventfd, buffer, strlen(buffer)); } } } return 0; } // 初始化服务端的监听端口。 int initserver(int port) { int sock = socket(AF_INET, SOCK_STREAM, 0); if (sock client.cpp #include #include #include #include #include #include #include #include int main(int argc, char *argv[]) { if (argc != 3) { printf(\"usage:./tcpclient ip port\\n\"); return -1; } int sockfd; struct sockaddr_in servaddr; char buf[1024]; if ((sockfd = socket(AF_INET, SOCK_STREAM, 0)) "},"C++/网络通信socket/11-IO复用-epoll.html":{"url":"C++/网络通信socket/11-IO复用-epoll.html","title":"IO复用-epoll","keywords":"","body":"datetime:2022/12/30 17:36 author:nzb I/O复用-epoll 5、epoll epoll是在2.6内核中提出的，是之前的select和poll的增强版本。是为处理大批量句柄而作了改进的poll。 epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的拷贝只需要一次。 5.1、epoll基本原理 epoll有两大特点： 边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。 事件驱动，每个事件关联上fd，使用事件就绪通知方式，通过 epoll_ctl 注册 fd，一旦该fd就绪，内核就会采用 callback 的回调机制来激活该fd，epoll_wait 便可以收到通知。 5.2、epoll基本流程 一棵红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。 执行 epoll_create内核在epoll文件系统中建了个file结点，（使用完，必须调用close()关闭，否则导致fd被耗尽） 在内核cache里建了红黑树存储epoll_ctl传来的socket， 在内核cache里建了rdllist双向链表存储准备就绪的事件。 执行 epoll_ctl如果增加socket句柄，检查红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，告诉内核如果这个句柄的中断到了，就把它放到准备就绪list链表里。 ps：所有添加到epoll中的事件都会与设备（如网卡）驱动程序建立回调关系，相应的事件发生时，会调用回调方法。 执行 epoll_wait立刻返回准备就绪表里的数据即可（将内核cache里双向列表中存储的准备就绪的事件 复制到用户态内存） 当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。 如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。 5.3、epoll函数原型 #include int epoll_create(int size); // 创建epoll的句柄，它本身就是一个fd int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 注册需要监视fd和事件 int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); // 等待事件发生 int epoll_create(int size); /*创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大。*/ // 这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值。 // 需要注意的是:　当创建好epoll句柄后，它就是会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，　　　　 // 所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); /* epoll的事件注册函数: 它不同与select()是在监听事件时告诉内核要监听什么类型的事件epoll的事件注册函数，而是在这里先注册要监听的事件类型。　 第一个参数 epfd 是epoll_create()的返回值，　　 第二个参数 op 表示动作，用三个宏来表示： EPOLL_CTL_ADD：注册新的fd到epfd中； EPOLL_CTL_MOD：修改已经注册的fd的监听事件； EPOLL_CTL_DEL：从epfd中删除一个fd； 　　 第三个参数是需要监听的fd，　　 第四个参数是告诉内核需要监听什么事，　　　　　　 struct epoll_event结构如下： */ struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; /* events可以是以下几个宏的集合： 　　　　　　 EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；　　　　　　 EPOLLOUT：表示对应的文件描述符可以写； 　　　　　　 EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； 　　　　　　 EPOLLHUP：表示对应的文件描述符被挂断； 　　　　　　 EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 　　　　　　 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 */ int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); /* 等待事件的产生　　　　 类似于select()调用。　　　　 参数 events用来从内核得到事件的集合，　　　　 参数 maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，　　　 参数 timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。　　　　 该函数返回需要处理的事件数目，如返回0表示已超时。 */ 5.4、epoll优点 没有最大连接数的限制。（基于 红黑树+双链表 来存储的:1G的内存上能监听约10万个端口） 时间复杂度低： 边缘触发和事件驱动，监听回调，时间复杂度O(1)。 只有活跃可用的fd才会调用callback函数；即epoll最大的优点就在于它只管“活跃”的连接，而跟连接总数无关，因此实际网络环境中，Epoll的效率就会远远高于select和poll。 内存拷贝：利用mmap()文件映射内存加速与内核空间的消息传递，减少拷贝开销。 5.5、epoll缺点 依赖于操作系统：Lunix 5.6、epoll应用场景 适合用epoll的应用场景 对于连接特别多，活跃的连接特别少 典型的应用场景为一个需要处理上万的连接服务器，例如各种app的入口服务器，例如qq 不适合epoll的场景 连接比较少，数据量比较大，例如ssh epoll 的惊群问题： 因为epoll 多用于多个连接，只有少数活跃的场景，但是万一某一时刻，epoll 等的上千个文件描述符都就绪了，这时候epoll 要进行大量的I/O，此时压力太大。 5.7、epoll两种模式 epoll对文件描述符的操作有两种模式：LT(level trigger) 和 ET(edge trigger)。LT是默认的模式，ET是“高速”模式。 LT（水平触发）模式下，只要有数据就触发，缓冲区剩余未读尽的数据会导致 epoll_wait都会返回它的事件； ET（边缘触发）模式下，只有新数据到来才触发，不管缓存区中是否还有数据，缓冲区剩余未读尽的数据不会导致epoll_wait返回。 5.7.1、LT模式 LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket 在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。 如果你不作任何操作，内核还是会继续通知你的,只要这个文件描述符还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作 5.7.2、ET模式 ET(edge-triggered)是高速工作方式，只支持no-block socket，在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。 然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了 (比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。 但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)。 在它检测到有 I/O 事件时，通过 epoll_wait 调用会得到有事件通知的文件描述符，对于每一个被通知的文件描述符，如可读，则必须将该文件描述符一直读到空， 让 errno 返回 EAGAIN （提示你的应用程序现在没有数据可读请稍后再试）为止，否则下次的 epoll_wait 不会返回余下的数据，会丢掉事件。 ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 注意： 1、在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符， 一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。 2、如果没有大量的idle-connection或者dead-connection，epoll的效率并不会比select/poll高很多， 但是当遇到大量的idle-connection，就会发现epoll的效率大大高于select/poll。 5.8、示例代码 tcpselect.cpp #include #include #include #include #include #include #include #include #include #include #include #define MAXEVENTS 100 // 把socket设置为非阻塞的方式。 int setnonblocking(int sockfd); // 初始化服务端的监听端口。 int initserver(int port); int main(int argc, char *argv[]) { if (argc != 2) { printf(\"usage:./tcpepoll port\\n\"); return -1; } // 初始化服务端用于监听的socket。 int listensock = initserver(atoi(argv[1])); printf(\"listensock=%d\\n\", listensock); if (listensock client.cpp #include #include #include #include #include #include #include #include int main(int argc, char *argv[]) { if (argc != 3) { printf(\"usage:./tcpclient ip port\\n\"); return -1; } int sockfd; struct sockaddr_in servaddr; char buf[1024]; if ((sockfd = socket(AF_INET, SOCK_STREAM, 0)) 5.9、select、poll、epoll区别 1、支持一个进程所能打开的最大连接数 select poll epoll 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。 poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 2、FD剧增后带来的IO效率问题 select poll epoll 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 同select 因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 3、消息传递方式 select poll epoll 内核需要将消息传递到用户空间，都需要内核拷贝动作 同select epoll通过mmap把对应设备文件片断映射到用户空间上, 消息传递不通过内核, 内存与设备文件同步数据. 总结： 1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善 3、 "},"C++/多进程/01-进程概述.html":{"url":"C++/多进程/01-进程概述.html","title":"进程概述","keywords":"","body":"datetime:2023/01/04 11:15 author:nzb 进程概述 程序和进程 程序是包含一系列信息的文件，这些信息描述了如何在运行时创建一个进程： 二进制格式标识：每个程序文件都包含用于描述可执行文件格式的元信息。内核利用此信息来解释文件中的其他信息。（ELF可执行连接格式） 机器语言指令：对程序算法进行编码。 程序入口地址：标识程序开始执行时的起始指令位置。 数据：程序文件包含的变量初始值和程序使用的字面量值（比如字符串）。 符号表及重定位表：描述程序中函数和变量的位置及名称。这些表格有多重用途，其中包括调试 和运行时的符号解析（动态链接）。 共享库和动态链接信息：程序文件所包含的一些字段，列出了程序运行时需要使用的共享库，以 及加载共享库的动态连接器的路径名。 其他信息：程序文件还包含许多其他信息，用以描述如何创建进程。 进程是正在运行的程序的实例。是一个具有一定独立功能的程序关于某个数据集合的一次运行活动。它是操作系统动态执行的基本单元，在传统的操作系统中，进程既是基本的分配单元，也是基本的执行单元。 可以用一个程序来创建多个进程，进程是由内核定义的抽象实体，并为该实体分配用以执行程序的各项系统资源。从内核的角度看，进程由用户内存空间和一系列内核数据结构组成，其中用户内存空间包含了程序代码及代码所使用的变量，而内核数据结 构则用于维护进程状态信息。记录在内核数据结构中的信息包括许多与进程相关的标 识号（IDs）、虚拟内存表、打开文件的描述符表、信号传递及处理的有关信息、进 程资源使用及限制、当前工作目录和大量的其他信息。 单道、多道程序设计 单道程序，即在计算机内存中只允许一个的程序运行。 多道程序设计技术是在计算机内存中同时存放几道相互独立的程序，使它们在管理程序控制下，相互穿插运行，两个或两个以上程序在计算机系统中同处于开始到结束之间的状态， 这些程序共享计算机系统资源。引入多道程序设计技术的根本目的是为了提高CPU的利用率。 对于一个单CPU系统来说，程序同时处于运行状态只是一种宏观上的概念，他们虽然都已经开始运行，但就微观而言，任意时刻，CPU上运行的程序只有一个。 在多道程序设计模型中，多个进程轮流使用CPUo而当下常见CPU为纳秒级，1秒可以执行大约10亿条指令。由于人眼的反应速度是毫秒级，所以看似同时在运行。 时间片 时间片(timeslice)又称为\"量子(quantum)\"或'处理器片(processor slice) 是操作系统分配给每个正在运行的进程微观上的一段CPU时间。事实上，虽然一台计 算机通常可能有多个CPU,但是同一个CPU永远不可能真正地同时运行多个任务。在 只考虑一个CPU的情况下，这些进程“看起来像\"同时运行的，实则是轮番穿插地运行， 由于时间片通常很短(在Linux上为5ms- 800ms) ,用户不会感觉到。 时间片由操作系统内核的调度程序分配给每个进程。首先，内核会给每个进程分配相等 的初始时间片，然后每个进程轮番地执行相应的时间，当所有进程都处于时间片耗尽的 状态时，内核会重新为每个进程计算并分配时间片，如此往复。 并行和并发 并行(parallel)：指在同一时刻，有多条指令在多个处理器上同时执行。 并发(concurrency)：指在同一时刻只能有一条指令执行，但多个进程指令被快速的 轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的, 只是把时间分成若干段，使多个进程快速交替的执行。 进程控制块(PCB) 为了管理进程，内核必须对每个进程所做的事情进行清楚的描述。内核为每个进程分 配一个PCB (Processing Control Block)进程控制块，维护进程相关的信息， Linux内核的进程控制块是task_struct 结构体。 在 /usr/src/linux-headers-xxx/include/linux/sched.h 文件中可以查 看struct task_struct结构体定义。其内部成员有很多，我们只需要掌握以下 部分即可： 进程id：系统中每个进程有唯一的id,用pid_t类型表示，其实就是一个非负整数 进程的状态：有就绪、运行、挂起、停止等状态 进程切换时需要保存和恢复的一些CPU寄存器 描述虚拟地址空间的信息 描述控制终端的信息 进程控制块(PCB) 当前工作目录(Current Working Directory) umask掩码 文件描述符表，包含很多指向file结构体的指针 和信号相关的信息 用户id和组id 会话(Session)和进程组 进程可以使用的资源上限(Resource Limit) 进程状态转换 进程的状态 进程状态反映进程执行过程的变化。这些状态随着进程的执行和外界条件的变化而转换。 在三态模型中，进程状态分为三个基本状态， 即就绪态，运行态，阻塞态。在五态模型 中，进程分为新建态、就绪态，运行态，阻塞态 ，终止态。 运行态：进程占有处理器正在运行 就绪态：进程具备运行条件，等待系统分配处理器以便运行。当进程已分配到除CPU以外的所有必要资源后，只要再获得CPU,便可立即执行。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列 阻塞态：又称为等待(wait)态或睡眠(sleep)态，指进程不具备运行条件，正在等待某个事件的完成 新建态：进程刚被创建时的状态，尚未进入就绪队列 终止态：进程完成任务到达正常结束点，或出现无法克服的错误而异常终止，或被操作系统及有终止权的进程所终止时所处的状态。进入终止态的进程以后不再执行，但依然保留在操作系 统中等待善后。一旦其他进程完成了对终止态进程的信息抽取之后，操作系统将删除该进程。 进程相关命令 查看进程: ps aux / ajx a：显示终端上的所有进程，包括其他用户的进程 u：显示进程的详细信息 X：显示没有控制终端的进程 j:列出与作业控制相关的信息 STAT参数意义: D 不可中断 Uninterruptible （usually 10） R 正在运行，或在队列中的进程 S（大写） 处于休眠状态 T 停止或被追踪 Z 僵尸进程 W 进入内存交换（从内核2.6开始无效） X 死掉的进程 高优先级 N 低优先级 L 有pages在内存中locked。用于实时或者自定义IO。 s 包含子进程 l 多线程 + 位于前台的进程组 实时显示进程动态: top可以在使用top命令时加上-d secs来指定显示信息更新的时间间隔，在top命令执行后，可以按以下按键对显示的结果进行排序： M 根据内存使用量排序 P 根据CPU占有率排序 T 根据进程运行时间长短排序 U 根据用户名来筛选进程 K 输入指定的PID杀死进程 杀死进程: kill [-signal] pid kill -l: 列出所有信号 kill -SIGKILL 进程ID kill -9 进程ID killall name: 根据进程名杀死进程 进程号和相关函数 每个进程都由进程号来标识，其类型为 pid_t(整型)，进程号的范围：0~32767。进程号总是唯一的，但可以重用。当一个进程终止后，其进程号就可以再次使用。 任何进程(除 init 进程)都是有另一个进程创建，该进程称为被创建进程的父进程，对应的进程号称为父进程号(PPID)。 进程组是一个或多个进程的集合。他们之间相互关联，进程组可以接收同一终端的各种信号，关联的进程有一个进程组号(PGID)。默认情况下，当前的进程号会当做当前的进程组号。 进程号和进程组相关函数 pid_t getpid(void); pid_t getppid(void); pid_t getpgid(pid_t pid); 进程创建 系统允许一个进程创建新进程，新进程即为子进程，子进程还可以创建新的子进程，形成进程树结构模型。 #include #include pid_t fork(void); 返回值： 成功：子进程中返回0,父进程中返回子进程ID 失败：返回-1 失败的两个主要原因： 当前系统的进程数已经达到了系统规定的上限，这时errno的值被设置为 EAGAIN 系统内存不足，这时errno的值被设置为ENOMEM fork（）读时共享，写时子进程才copy复制一份程序和虚拟地址空间，使得当父进程写的时候改变了物理地址，但是子进程指向的还是原来的物理空间指向的值，两者的物理空间指向的值可能不同。 实际上，更准确来说，Linux的fork()使用是通过写时拷贝(copy- on-write) 实现。 实时拷贝是一种可以推迟甚至避免拷贝数据的技术。 内核此时并不复制整个进程的地址空间，而是让父子进程共享同一个地址空间。 只用在需要写入的时候才会复制地址空间，从而使各个进行拥有各自的地址空间。 也就是说，资源的复制是在需要写入的时候才会进行，在此之前，只有以只读方式共享, 注意：fork之后父子进程共享文件。 fork产生的子进程与父进程相同的文件文件描述符指向相同的文件表，引用计数增加。 父子进程关系和GDB多进程调试 父子进程之间的关系 区别 fork()函数的返回值不同 父进程中：>0, 返回的子进程的ID 子进程中：=0 pcb中的一些数据 当前的进程的id pid 当前的进程的父进程的id ppid, 信号集 共同点 某些状态下：子进程刚被创建出来，还没有执行任何的写数据的操作 用户区的数据 文件描述符表 父子进程对变量是不是共享的？ 刚开始的时候，是一样的，共享的。如果修改了数据，不共享了。 读时共享，写时拷贝。 GDB多进程调试（面试常考） 使用GDB调试的时候，GDB默认只能跟踪一个进程，可以在fork函数调用之前，通 过指令设置GDB调试工具跟踪父进程或者是跟踪子进程，默认跟踪父进程。 设置调试父进程或者子进程：set follow-fork-mode [parent （默认）| child] 设置调试模式：set detach-on-fork [on | off] 默认为on,表示调试当前进程的时候，其它的进程继续运行，如果为off,调试当前进程的时候，其它进程被GDB挂起。 查看调试的进程：info inferiors切换当前调试的进程：inferior id使进程脱离 GDB 调试：detach inferiors id exec函数族 exec函数族介绍 exec函数族的作用是根据指定的文件名找到可执行文件，并用它来取代调用进程的内容，换句话说，就是在调用进程内部执行一个可执行文件。 exec函数族的函数执行成功后不会返回，因为调用进程的实体，包括代码段，数据段和堆栈等都已经被新的内容取代，只留下进程ID等一些表面上的信息仍保持原样, 颇有些神似''三十六计〃中的'' 金蝉脱壳〃。看上去还是旧的躯壳，却已经注入了新的灵 魂。只有调用失败了，它们才会返回-1,从原程序的调用点接着往下执行。 exec函数族作用图解 int execl (const char *path, const char *arg, . . ./* (char *) NULL */); 参数 path:需要指定的执行的文件的路径或者名称 a.out /home/nowcoder/a.out 推荐使用绝对路径 ./a.out hello world arg:是执行可执行文件所需要的参数列表 第一个参数一般没有什么作用，为了方便，一般写的是执行的程序的名称 从第二个参数开始往后，就是程序执行所需要的的参数列表。 参数最后需要以NULL结束(哨兵) int execlp (const char *file, const char *arg, ・・・ /* (char *) NULL */); 参数 file: a.out /home/nowcoder/a.out 推荐使用绝对路径 ./a.out hello world arg:是执行可执行文件所需要的参数列表 第一个参数一般没有什么作用，为了方便，一般写的是执行的程序E 从第二个参数开始往后，就是程序执行所需要的的参数列表。 参数最后需要以NULL结束(哨兵) 返回值： 只有当调用失败，才会有返回值，返回-1,并且设置errno 如果调用成功，没有返回值。 int execle(const char *path, const char *arg, ・・•/*, (char *) NULL, char *const envp[] */); int execv(const char *path, char *const argv[]); int execvp(const char *file, char *const argv[]); int execvpe(const char *file, char *const argv[], char *const envp[]); int execve (const char *filename, char *const argv[], char *const envp []); l(list) 参数地址列表，以空指针结尾 v(vector) 存有各参数地址的指针数组的地址 p(path) 按PATH环境变量指定的目录搜索可执行文件 e(environment) 存有环境变量字符串地址的指针数组的地址 示例代码 /* #include int execl(const char *path, const char *arg, ...); - 参数： - path:需要指定的执行的文件的路径或者名称 a.out /home/nowcoder/a.out 推荐使用绝对路径 ./a.out hello world - arg:是执行可执行文件所需要的参数列表 第一个参数一般没有什么作用，为了方便，一般写的是执行的程序的名称 从第二个参数开始往后，就是程序执行所需要的的参数列表。 参数最后需要以NULL结束（哨兵） - 返回值： 只有当调用失败，才会有返回值，返回-1，并且设置errno 如果调用成功，没有返回值。 */ #include #include int main() { // 创建一个子进程，在子进程中执行exec函数族中的函数 pid_t pid = fork(); if(pid > 0) { // 父进程 printf(\"i am parent process, pid : %d\\n\",getpid()); sleep(1); }else if(pid == 0) { // 子进程 // execl(\"hello\",\"hello\",NULL); execl(\"/bin/ps\", \"ps\", \"aux\", NULL); perror(\"execl\"); printf(\"i am child process, pid : %d\\n\", getpid()); } for(int i = 0; i /* #include int execlp(const char *file, const char *arg, ... ); - 会到环境变量中查找指定的可执行文件，如果找到了就执行，找不到就执行不成功。 - 参数： - file:需要执行的可执行文件的文件名 a.out ps - arg:是执行可执行文件所需要的参数列表 第一个参数一般没有什么作用，为了方便，一般写的是执行的程序的名称 从第二个参数开始往后，就是程序执行所需要的的参数列表。 参数最后需要以NULL结束（哨兵） - 返回值： 只有当调用失败，才会有返回值，返回-1，并且设置errno 如果调用成功，没有返回值。 int execv(const char *path, char *const argv[]); argv是需要的参数的一个字符串数组 char * argv[] = {\"ps\", \"aux\", NULL}; execv(\"/bin/ps\", argv); int execve(const char *filename, char *const argv[], char *const envp[]); char * envp[] = {\"/home/nowcoder\", \"/home/bbb\", \"/home/aaa\"}; */ #include #include int main() { // 创建一个子进程，在子进程中执行exec函数族中的函数 pid_t pid = fork(); if(pid > 0) { // 父进程 printf(\"i am parent process, pid : %d\\n\",getpid()); sleep(1); }else if(pid == 0) { // 子进程 execlp(\"ps\", \"ps\", \"aux\", NULL); printf(\"i am child process, pid : %d\\n\", getpid()); } for(int i = 0; i "},"C++/多进程/02-孤儿进程和僵尸进程.html":{"url":"C++/多进程/02-孤儿进程和僵尸进程.html","title":"孤儿进程和僵尸进程","keywords":"","body":"datetime:2023/01/06 14:30 author:nzb 孤儿进程和僵尸进程 进程退出 孤儿进程 父进程运行结束，但子进程还在运行(未运行结束)，这样的子进程就称为孤儿进程 (Orphan Process)。 每当出现一个孤儿进程的时候，内核就把孤儿进程的父进程设置为 init 而 init 进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束 了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。 因此孤儿进程并不会有什么危害。 僵尸进程 每个进程结束之后，都会释放自己地址空间中的用户区数据，内核区的PCB没有办 法自己释放掉，需要父进程去释放。 进程终止时，父进程尚未回收，子进程残留资源(PCB)存放于内核中，变成僵尸 (Zombie)进程。 僵尸进程不能被kill -9杀死。 这样就会导致一个问题，如果父进程不调用wait()或waitpid() 的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵尸进程，将因为没有可用的进程号而导致系统不能产生新 的进程，此即为僵尸进程的危害，应当避免。 exit函数 /* #include void exit(int status); #include void _exit(int status); status参数：是进程退出时的一个状态信息。父进程回收子进程资源的时候可以获取到。 */ #include #include #include int main() { printf(\"hello\\n\"); printf(\"world\"); // exit(0); _exit(0); return 0; } 孤儿进程 #include #include #include int main() { // 创建子进程 pid_t pid = fork(); // 判断是父进程还是子进程 if(pid > 0) { printf(\"i am parent process, pid : %d, ppid : %d\\n\", getpid(), getppid()); } else if(pid == 0) { sleep(1); // 当前是子进程 printf(\"i am child process, pid : %d, ppid : %d\\n\", getpid(),getppid()); } // for循环 for(int i = 0; i 僵尸进程 #include #include #include int main() { // 创建子进程 pid_t pid = fork(); // 判断是父进程还是子进程 if(pid > 0) { // 父进程死循环，子进程先退出，产生僵尸进程 while(1) { printf(\"i am parent process, pid : %d, ppid : %d\\n\", getpid(), getppid()); sleep(1); } } else if(pid == 0) { // 当前是子进程 printf(\"i am child process, pid : %d, ppid : %d\\n\", getpid(),getppid()); } // for循环 for(int i = 0; i wait函数 进程回收 在每个进程退出的时候，内核释放该进程所有的资源、包括打开的文件、占用的内存等。但是仍然为其保留一定的信息，这些信息主要指进程控制块PCB的信息（包括进程号、退出状态、运行时间等）。 父进程可以通过调用wait或waitpid得到它的退出状态同时彻底清除掉这个进程。 wait()和waitpid()函数的功能一样，区别在于，wait()函数会阻塞，waitpid()可以不设置阻塞，waitpid()还可以指定等待哪个子进程结束。 注意：一次wait()或waitpid()调用只能清理一个子进程，清理多个子进程应使用循环。 退出信息相关宏函数 WIFEXITED(status): 非0,进程正常退出 WEXITSTATUS (status): 如果上宏为真，获取进程退出的状态(exit的参数) WIFSIGNALED (status): 非0,进程异常终止 WTERMSIG (status): 如果上宏为真，获取使进程终止的信号编号 WIFSTOPPED (status): 非0,进程处于暂停状态 WSTOPSIG(status): 如果上宏为真，获取使进程暂停的信号的编号 WIFCONTINUED (status): 非0,进程暂停后已经继续运行 #include #include pid_t wait(int Iwstatus); 功能：等待任意一个子进程结束，如果任意一个子进程结束了 次函数会回收子进程 参数：int *wstatus 进程退出时的状态信息.传入的是一个int类型的地址，传出参数。 返回值： 成功：返回被回收的子进程的id 失败：-1 （所有的子进程都结束，调用函数失败） 调川wait函数的进程会被挂起（阳塞），直到它的一个子进程退出 如果没有子进程了，画数立刻返Ml，返回-1：如果子进程都已经结束了,也会立即返回。 waitpid函数 #include #include pid_t waitpid(pid_t pid, int *wstatus, int options); 功能：回收指定位程号的子进程. 可以设置是否阻塞。 参数： pid: pid > 0：某个子进程的pid pid = 0：回收当前进程组的所有子进程 pid = -1：回收所有的子进程.相当于wait() pid 0：返回子进程的id = 0： options=WNOHANG,表示还有子进程 = -1：错误，或者没有子进程了 /* #include #include pid_t waitpid(pid_t pid, int *wstatus, int options); 功能：回收指定进程号的子进程，可以设置是否阻塞。 参数： - pid: pid > 0 : 某个子进程的pid pid = 0 : 回收当前进程组的所有子进程 pid = -1 : 回收所有的子进程，相当于 wait() （最常用） pid 0 : 返回子进程的id = 0 : options=WNOHANG, 表示还有子进程活着 = -1 ：错误，或者没有子进程了 */ #include #include #include #include #include int main() { // 有一个父进程，创建5个子进程（兄弟） pid_t pid; // 创建5个子进程 for(int i = 0; i 0) { // 父进程 while(1) { printf(\"parent, pid = %d\\n\", getpid()); sleep(1); int st; // int ret = waitpid(-1, &st, 0); int ret = waitpid(-1, &st, WNOHANG); if(ret == -1) { break; } else if(ret == 0) { // 说明还有子进程存在 continue; } else if(ret > 0) { if(WIFEXITED(st)) { // 是不是正常退出 printf(\"退出的状态码：%d\\n\", WEXITSTATUS(st)); } if(WIFSIGNALED(st)) { // 是不是异常终止 printf(\"被哪个信号干掉了：%d\\n\", WTERMSIG(st)); } printf(\"child die, pid = %d\\n\", ret); } } } else if (pid == 0){ // 子进程 while(1) { printf(\"child, pid = %d\\n\",getpid()); sleep(1); } exit(0); } return 0; } "},"C++/多进程/03-守护进程.html":{"url":"C++/多进程/03-守护进程.html","title":"守护进程","keywords":"","body":"datetime:2023/03/08 11:00 author:nzb 守护进程 终端 在UNIX系统中，用户通过终端登录系统后得到一个shell进程，这个终端成为shell进程的控制终端(Controlling Terminal),进程中，控制终端是保存在PCB中的信息，而fork() 会复制PCB中的信息，因此由shell进程启动的其它进程的控制终端也是这个终端。 默认情况下(没有重定向)，每个进程的标准输入、标准输出和标准错误输出都指向控制终端，进程从标准输入读也就是读用户的键盘输入，进程往标准输出或标准错误输出写也就是输出到显示器上。 在控制终端输入一些特殊的控制键可以给前台进程发信号，例如Ctrl + C会产生SIGINT信号，Ctrl + \\会产生SIGQUIT信号。 进程组 进程组和会话在进程之间形成了一种两级层次关系：进程组是一组相关进程的集合，会话是一组相关进程组的集合。进程组和会话是为支持shell作业控制而定义的抽象概念， 用户通过shell能够交互式地在前台或后台运行命令。 进行组由一个或多个共享同一进程组标识符（PGID）的进程组成。一个进程组拥有一个进程组首进程，该进程是创建该组的进程，其进程ID为该进程组的ID, 新进程会继承其父进程所属的进程组IDO 进程组拥有一个生命周期，其开始时间为首进程创建组的时刻，结束时间为最后一个成员进程退出组的时刻。一个进程可能会因为终止而退出进程组， 也可能会因为加入了另外一个进程组而退出进程组。进程组首进程无需是最后一个离开进程组的成员。 会话 会话是一组进程组的集合。会话首进程是创建该新会话的进程，其进程ID会成为会话ID。新进程会继承其父进程的会话ID。 一个会话中的所有进程共享单个控制终端。控制终端会在会话首进程首次打开一个终端设备时被建立。一个终端最多可能会成为一个会话的控制终端。 在任一时刻，会话中的其中一个进程组会成为终端的前台进程组，其他进程组会成为后台进程组。只有前台进程组中的进程才能从控制终端中读取输入。 当用户在控制终端中输入终端字符生成信号后，该信号会被发送到前台进程组中的所有成员。 当控制终端的连接建立起来之后，会话首进程会成为该终端的控制进程。 进程组、会话操作函数 pid_t getpgrp(void); pid_t getpgid(pid_t pid); int setpgid(pid_t pid, pid_t pgid); pid_t getsid(pid_t pid); pid_t setsid(void); 守护进程 守护进程（Daemon Process）,也就是通常说的Daemon进程（精灵进程），是Linux中的后台服务进程。它是一个生存期较长的进程， 通常独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。一般采用以d结尾的名字。 守护进程具备下列特征 生命周期很长，守护进程会在系统启动的时候被创建并一直运行直至系统被关闭。 它在后台运行并且不拥有控制终端。没有控制终端确保了内核永远不会为守护进程自动生成任何控制信号以及终端相关的信号（如SIGINT、SIGQUIT） Linux的大多数服务器就是用守护进程实现的。比如，Internet服务器inetd，Web服务器httpd等。 守护进程的创建步骤 执行一个fork(),之后父进程退出，子进程继续执行。 子进程调用setsid()开启一个新会话。 清除进程的umask以确保当守护进程创建文件和目录时拥有所需的权限。 修改进程的当前工作目录，通常会改为根目录(/)。 关闭守护进程从其父进程继承而来的所有打开着的文件描述符。 在关闭了文件描述符0、1、2之后，守护进程通常会打开/dev/null并使用dup2()使所有这些描述符指向这个设备。 核心业务逻辑 代码 /* 写一个守护进程，每隔2s获取一下系统时间，将这个时间写入到磁盘文件中。 */ #include #include #include #include #include #include #include #include #include #include void work(int num) { // 捕捉到信号之后，获取系统时间，写入磁盘文件 time_t tm = time(NULL); struct tm * loc = localtime(&tm); // char buf[1024]; // sprintf(buf, \"%d-%d-%d %d:%d:%d\\n\",loc->tm_year,loc->tm_mon // ,loc->tm_mday, loc->tm_hour, loc->tm_min, loc->tm_sec); // printf(\"%s\\n\", buf); char * str = asctime(loc); int fd = open(\"time.txt\", O_RDWR | O_CREAT | O_APPEND, 0664); write(fd ,str, strlen(str)); close(fd); } int main() { // 1.创建子进程，退出父进程 pid_t pid = fork(); if(pid > 0) { exit(0); } // 2.将子进程重新创建一个会话 setsid(); // 3.设置掩码 umask(022); // 4.更改工作目录 chdir(\"/home/nowcoder/\"); // 5. 关闭、重定向文件描述符 int fd = open(\"/dev/null\", O_RDWR); dup2(fd, STDIN_FILENO); dup2(fd, STDOUT_FILENO); dup2(fd, STDERR_FILENO); // 6.业务逻辑 // 捕捉定时信号 struct sigaction act; act.sa_flags = 0; act.sa_handler = work; sigemptyset(&act.sa_mask); sigaction(SIGALRM, &act, NULL); struct itimerval val; val.it_value.tv_sec = 2; val.it_value.tv_usec = 0; val.it_interval.tv_sec = 2; val.it_interval.tv_usec = 0; // 创建定时器 setitimer(ITIMER_REAL, &val, NULL); // 不让进程结束 while(1) { sleep(10); } return 0; } "},"C++/多进程/04-进程间通信-管道.html":{"url":"C++/多进程/04-进程间通信-管道.html","title":"进程间通信-管道","keywords":"","body":"datetime:2023/01/09 11:40 author:nzb 进程间通信 1、进程间通信概念 进程是一个独立的资源分配单元，不同进程（这里所说的进程通常指的是用户进程）之间 的资源是独立的，没有关联，不能在一个进程中直接访问另一个进程的资源。 但是，进程不是孤立的，不同的进程需要进行信息的交互和状态的传递等，因此需要进程间通信（IPC： Inter Processes Communication ） 进程间通信的目的 数据传输：一个进程需要将它的数据发送给另一个进程。 通知事件：一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。 资源共享：多个进程之间共享同样的资源。为了做到这一点，需要内核提供互斥和同步机制。 进程控制：有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。 2、进程通信的几种方式 进程同步与进程通信很容易混淆，它们的区别在于： 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 1、管道(匿名管道) 管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。 它具有以下限制： 只支持半双工通信（单向交替传输）； 只能在父子进程或者兄弟进程中使用。 2、FIFO(有名管道)命名管道，去除了管道只能在父子进程中使用的限制。常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 3、信号 信号一般用于一些异常情况下的进程间通信，是一种异步通信，它的数据结构一般就是一个数字。 在Linux操作系统中，为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过kill -l命令，查看所有的信号。 运行在shell终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如 Ctrl+C产生 SIGINT 信号，表示终止该进程； Ctrl+Z产生 SIGTSTP 信号，表示停止该进程，但还未结束； 如果进程在后台运行，可以通过kill命令的方式给进程发送信号，但前提需要知道运行中的进程PID号，例如： kill -9 1050，表示给PID为1050的进程发送 SIGKILL 信号，用来立即结束该进程（例如：在任务管理器右键结束进程）； 所以，信号事件的来源主要有硬件来源(如键盘Ctrl+C)和软件来源(如kill命令)。 信号是进程间通信机制中唯一的异步通信机制 进程需要为信号设置相应的监听处理，当收到特定信号时，执行相应的操作，类似很多编程语言里的通知机制。 4、消息队列 相比于 FIFO，消息队列具有以下优点： 可独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 5、信号量：一个计数器，用于为多个进程提供对共享数据对象的访问。 6、共享内存 允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。 需要使用信号量用来同步对共享存储的访问。 多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。 7、套接字(socket)：用于不同机器间的进程通信 3、匿名管道 管道也叫无名（匿名）管道，它是是UNIX系统IPC （进程间通信）的最古老形式， 所有的UNIX系统都支持这种通信机制。 统计一个目录中文件的数目命令：ls | wc -l,为了执行该命令，shell创建了两 个进程来分别执行ls和wc。 3.1、管道的特点 的进程可以读取任意大小的数据块，而不管写入进程写入管道的数据块的大小是多少。 管道其实是一个在内核内存中维护的缓冲器，这个缓冲器的存储能力是有限的，不同的操作系统大小不一定相同。 管道拥有文件的特质：读操作、写操作，匿名管道没有文件实例，有名管道有文件实体，但不存储数据。可以按照操作文件的方式对管道进行操作。 一个管道是一个字节流，使用管道时不存在消息或者消息边界的概念，从管道读取数据的进程可以读取任意大小的数据块，而不管写入进程写入管道的数据块的大小是多少。 通过管道传递的数据是顺序的，从管道中读取出来的字节的顺序和它们被写入管道的顺序是完全一样的。 在管道中的数据的传递方向是单向的，一端用于写入，一端用于读取，管道是半双工的。 从管道读数据是一次性操作，数据一旦被读走，它就从管道中被抛弃，释放空间以便写更多的数据，在管道中无法使用lseek()来随机的访问数据。 匿名管道只能在具有公共祖先的进程(父进程与子进程，或者两个兄弟进程，具有亲缘关系)之间使用。 3.2、为什么可以使用管道进行进程间通信？ 3.3、管道的数据结构 逻辑上是环形的队列，实际数据结构不是环形的。 3.4、匿名管道的使用 创建匿名管道 #include int pipe(int pipefd[2]); 查看管道缓存大小命令 ulimit -a 查看管道缓存大小函数 #include long fpathconf(int fd, int name); /* #include int pipe(int pipefd[2]); 功能：创建一个匿名管道，用来进程间通信。 参数：int pipefd[2] 这个数组是一个传出参数。 pipefd[0] 对应的是管道的读端 pipefd[1] 对应的是管道的写端 返回值： 成功 0 失败 -1 管道默认是阻塞的：如果管道中没有数据，read阻塞，如果管道满了，write阻塞 注意：匿名管道只能用于具有关系的进程之间的通信（父子进程，兄弟进程） */ // 子进程发送数据给父进程，父进程读取到数据输出 #include #include #include #include #include int main() { // 在fork之前创建管道 int pipefd[2]; int ret = pipe(pipefd); if(ret == -1) { perror(\"pipe\"); exit(0); } // 创建子进程 pid_t pid = fork(); if(pid > 0) { // 父进程 printf(\"i am parent process, pid : %d\\n\", getpid()); // 关闭写端 close(pipefd[1]); // 从管道的读取端读取数据 char buf[1024] = {0}; while(1) { int len = read(pipefd[0], buf, sizeof(buf)); printf(\"parent recv : %s, pid : %d\\n\", buf, getpid()); // 向管道中写入数据 //char * str = \"hello,i am parent\"; //write(pipefd[1], str, strlen(str)); //sleep(1); } } else if(pid == 0){ // 子进程 printf(\"i am child process, pid : %d\\n\", getpid()); // 关闭读端 close(pipefd[0]); char buf[1024] = {0}; while(1) { // 向管道中写入数据 char * str = \"hello,i am child\"; write(pipefd[1], str, strlen(str)); //sleep(1); // int len = read(pipefd[0], buf, sizeof(buf)); // printf(\"child recv : %s, pid : %d\\n\", buf, getpid()); // bzero(buf, 1024); } } return 0; } #include #include #include #include #include int main() { int pipefd[2]; int ret = pipe(pipefd); // 获取管道的大小 long size = fpathconf(pipefd[0], _PC_PIPE_BUF); printf(\"pipe size : %ld\\n\", size); return 0; } 3.5、匿名管道通信案例 /* 实现 ps aux | grep xxx 父子进程间通信 子进程： ps aux, 子进程结束后，将数据发送给父进程 父进程：获取到数据，过滤 pipe() execlp() 子进程将标准输出 stdout_fileno 重定向到管道的写端。 dup2 */ #include #include #include #include #include #include int main() { // 创建一个管道 int fd[2]; int ret = pipe(fd); if(ret == -1) { perror(\"pipe\"); exit(0); } // 创建子进程 pid_t pid = fork(); if(pid > 0) { // 父进程 // 关闭写端 close(fd[1]); // 从管道中读取 char buf[1024] = {0}; int len = -1; while((len = read(fd[0], buf, sizeof(buf) - 1)) > 0) { // 过滤数据输出 printf(\"%s\", buf); memset(buf, 0, 1024); } wait(NULL); } else if(pid == 0) { // 子进程 // 关闭读端 close(fd[0]); // 文件描述符的重定向 stdout_fileno -> fd[1] dup2(fd[1], STDOUT_FILENO); // 执行 ps aux execlp(\"ps\", \"ps\", \"aux\", NULL); perror(\"execlp\"); exit(0); } else { perror(\"fork\"); exit(0); } return 0; } 3.6、管道的读写特点和管道设置为非阻塞的 管道的读写特点，使用管道时，需要注意以下几种特殊的情况（假设都是阻塞I/O操作） 1.所有的指向管道写端的文件描述符都关闭了（管道写端引用计数为0），有进程从管道的读端 读数据，那么管道中剩余的数据被读取以后，再次read会返回0，就像读到文件末尾一样。 2.如果有指向管道写端的文件描述符没有关闭（管道的写端引用计数大于0），而持有管道写端的进程 也没有往管道中写数据，这个时候有进程从管道中读取数据，那么管道中剩余的数据被读取后， 再次read会阻塞，直到管道中有数据可以读了才读取数据并返回。 3.如果所有指向管道读端的文件描述符都关闭了（管道的读端引用计数为0），这个时候有进程 向管道中写数据，那么该进程会收到一个信号SIGPIPE, 通常会导致进程异常终止。 4.如果有指向管道读端的文件描述符没有关闭（管道的读端引用计数大于0），而持有管道读端的进程 也没有从管道中读数据，这时有进程向管道中写数据，那么在管道被写满的时候再次write会阻塞， 直到管道中有空位置才能再次写入数据并返回。 总结 读管道 管道中有数据，read返回实际读到的字节数。 管道中无数据： 写端被全部关闭，read返回0（相当于读到文件的末尾） 写端没有完全关闭，read阻塞等待 写管道 管道读端全部被关闭，进程异常终止（进程收到SIGPIPE信号） 管道读端没有全部关闭： 管道已满，write阻塞 管道没有满，write将数据写入，并返回实际写入的字节数 #include #include #include #include #include #include /* 设置管道非阻塞 int flags = fcntl(fd[0], F_GETFL); // 获取原来的flag flags |= O_NONBLOCK; // 修改flag的值 fcntl(fd[0], F_SETFL, flags); // 设置新的flag */ int main() { // 在fork之前创建管道 int pipefd[2]; int ret = pipe(pipefd); if(ret == -1) { perror(\"pipe\"); exit(0); } // 创建子进程 pid_t pid = fork(); if(pid > 0) { // 父进程 printf(\"i am parent process, pid : %d\\n\", getpid()); // 关闭写端 close(pipefd[1]); // 从管道的读取端读取数据 char buf[1024] = {0}; int flags = fcntl(pipefd[0], F_GETFL); // 获取原来的flag flags |= O_NONBLOCK; // 修改flag的值 fcntl(pipefd[0], F_SETFL, flags); // 设置新的flag while(1) { int len = read(pipefd[0], buf, sizeof(buf)); printf(\"len : %d\\n\", len); printf(\"parent recv : %s, pid : %d\\n\", buf, getpid()); memset(buf, 0, 1024); sleep(1); } } else if(pid == 0){ // 子进程 printf(\"i am child process, pid : %d\\n\", getpid()); // 关闭读端 close(pipefd[0]); char buf[1024] = {0}; while(1) { // 向管道中写入数据 char * str = \"hello,i am child\"; write(pipefd[1], str, strlen(str)); sleep(5); } } return 0; } 4、有名管道介绍和使用 4.1、有名管道介绍 匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道(FIFO),也叫命名管道、FIFO文件。 有名管道(FIFO)不同于匿名管道之处在于它提供了一个路径名与之关联，以FIFO的文件形式存在于文件系统中，并且其打开方式与打开一个普通文件是一样的， 这样即使与FIFO的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过FIFO相互通信，因此，通过FIFO不相关的进程也能交换数据。 一旦打开了 FIFO,就能在它上面使用与操作匿名管道和其他文件的系统调用一样的I/O系统调用了(如read()、write ()和close ())。与管道一样，FIFO也有一 个写入端和读取端，并且从管道中读取数据的顺序与写入的顺序是一样的。FIFO的名称也由此而来：先入先出。 有名管道(FIFO)和匿名管道(pipe)有一些特点是相同的，不一样的地方在于 FIFO在文件系统中作为一个特殊文件存在，但FIFO中的内容却存放在内存中。 当使用FIFO的进程退出后，FIFO文件将继续保存在文件系统中以便以后使用。 FIFO有名字，不相关的进程可以通过打开有名管道进行通信。 4.2、有名管道的使用 通过命令创建有名管道：mkfifo名字 通过函数创建有名管道 #include #include int mkfifo(const char *pathname, mode_t mode); 一旦使用 mkfifo 创建了一个FIFO,就可以使用open打开它，常见的文件 I/O 函数都可用于 fifo 如：close、read、write、unlink 等。 FIFO严格遵循先进先出(First in First out),对管道及FIFO的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如lseek()等文件定位操作。 mkfifo.c /* 创建fifo文件 1.通过命令： mkfifo 名字 2.通过函数：int mkfifo(const char *pathname, mode_t mode); #include #include int mkfifo(const char *pathname, mode_t mode); 参数： - pathname: 管道名称的路径 - mode: 文件的权限 和 open 的 mode 是一样的 是一个八进制的数 返回值：成功返回0，失败返回-1，并设置错误号 */ #include #include #include #include #include int main() { // 判断文件是否存在 int ret = access(\"fifo1\", F_OK); if(ret == -1) { printf(\"管道不存在，创建管道\\n\"); ret = mkfifo(\"fifo1\", 0664); if(ret == -1) { perror(\"mkfifo\"); exit(0); } } return 0; } read.c #include #include #include #include #include #include // 从管道中读取数据 int main() { // 1.打开管道文件 int fd = open(\"test\", O_RDONLY); if(fd == -1) { perror(\"open\"); exit(0); } // 读数据 while(1) { char buf[1024] = {0}; int len = read(fd, buf, sizeof(buf)); if(len == 0) { printf(\"写端断开连接了...\\n\"); break; } printf(\"recv buf : %s\\n\", buf); } close(fd); return 0; } write.c #include #include #include #include #include #include #include // 向管道中写数据 /* 有名管道的注意事项： 1.一个为只读而打开一个管道的进程会阻塞，直到另外一个进程为只写打开管道 2.一个为只写而打开一个管道的进程会阻塞，直到另外一个进程为只读打开管道 读管道： 管道中有数据，read返回实际读到的字节数 管道中无数据： 管道写端被全部关闭，read返回0，（相当于读到文件末尾） 写端没有全部被关闭，read阻塞等待 写管道： 管道读端被全部关闭，进行异常终止（收到一个SIGPIPE信号） 管道读端没有全部关闭： 管道已经满了，write会阻塞 管道没有满，write将数据写入，并返回实际写入的字节数。 */ int main() { // 1.判断文件是否存在 int ret = access(\"test\", F_OK); if(ret == -1) { printf(\"管道不存在，创建管道\\n\"); // 2.创建管道文件 ret = mkfifo(\"test\", 0664); if(ret == -1) { perror(\"mkfifo\"); exit(0); } } // 3.以只写的方式打开管道 int fd = open(\"test\", O_WRONLY); if(fd == -1) { perror(\"open\"); exit(0); } // 写数据 for(int i = 0; i 4.3、有名管道实现简单版聊天功能 chatA.c #include #include #include #include #include #include #include int main() { // 1.判断有名管道文件是否存在 int ret = access(\"fifo1\", F_OK); if(ret == -1) { // 文件不存在 printf(\"管道不存在，创建对应的有名管道\\n\"); ret = mkfifo(\"fifo1\", 0664); if(ret == -1) { perror(\"mkfifo\"); exit(0); } } ret = access(\"fifo2\", F_OK); if(ret == -1) { // 文件不存在 printf(\"管道不存在，创建对应的有名管道\\n\"); ret = mkfifo(\"fifo2\", 0664); if(ret == -1) { perror(\"mkfifo\"); exit(0); } } // 2.以只写的方式打开管道fifo1 int fdw = open(\"fifo1\", O_WRONLY); if(fdw == -1) { perror(\"open\"); exit(0); } printf(\"打开管道fifo1成功，等待写入...\\n\"); // 3.以只读的方式打开管道fifo2 int fdr = open(\"fifo2\", O_RDONLY); if(fdr == -1) { perror(\"open\"); exit(0); } printf(\"打开管道fifo2成功，等待读取...\\n\"); char buf[128]; // 4.循环的写读数据 while(1) { memset(buf, 0, 128); // 获取标准输入的数据 fgets(buf, 128, stdin); // 写数据 ret = write(fdw, buf, strlen(buf)); if(ret == -1) { perror(\"write\"); exit(0); } // 5.读管道数据 memset(buf, 0, 128); ret = read(fdr, buf, 128); if(ret chatB.c #include #include #include #include #include #include #include int main() { // 1.判断有名管道文件是否存在 int ret = access(\"fifo1\", F_OK); if(ret == -1) { // 文件不存在 printf(\"管道不存在，创建对应的有名管道\\n\"); ret = mkfifo(\"fifo1\", 0664); if(ret == -1) { perror(\"mkfifo\"); exit(0); } } ret = access(\"fifo2\", F_OK); if(ret == -1) { // 文件不存在 printf(\"管道不存在，创建对应的有名管道\\n\"); ret = mkfifo(\"fifo2\", 0664); if(ret == -1) { perror(\"mkfifo\"); exit(0); } } // 2.以只读的方式打开管道fifo1 int fdr = open(\"fifo1\", O_RDONLY); if(fdr == -1) { perror(\"open\"); exit(0); } printf(\"打开管道fifo1成功，等待读取...\\n\"); // 3.以只写的方式打开管道fifo2 int fdw = open(\"fifo2\", O_WRONLY); if(fdw == -1) { perror(\"open\"); exit(0); } printf(\"打开管道fifo2成功，等待写入...\\n\"); char buf[128]; // 4.循环的读写数据 while(1) { // 5.读管道数据 memset(buf, 0, 128); ret = read(fdr, buf, 128); if(ret "},"C++/多进程/05-进程间通信-信号.html":{"url":"C++/多进程/05-进程间通信-信号.html","title":"进程间通信-信号","keywords":"","body":"datetime:2023/01/09 11:40 author:nzb 进程间通信 6、信号 概述 信号是Linux进程间通信的最古老的方式之一，是事件发生时对进程的通知机制，有时也称之为软件中断，它是在软件层次上对中断机制的一种模拟， 是一种异步通信的方式。信号可以导致一个正在运行的进程被另一个正在运行的异步进程中断，转而处理某一个突发事件 发往进程的诸多信号，通常都是源于内核。引发内核为进程产生信号的各类事件如下： 对于前台进程，用户可以通过输入特殊的终端字符来给它发送信号。比如输入Ctrl+C通常会给进程发送一个中断信号。 硬件发生异常，即硬件检测到一个错误条件并通知内核，随即再由内核发送相应信号给相关进程。比如执行一条异常的机器语言指令，诸如被0除，或者引用了无法访问的内存区域。 系统状态变化，比如alarm定时器到期将引起SIGALRM信号，进程执行的CPU时间超限，或者该进程的某个子进程退出。 运行kill命令或调用kill函数。 使用信号的两个主要目的是 让进程知道已经发生了一个特定的事情。 强迫进程执行它自己代码中的信号处理程序。 信号的特点 简单 不能携带大量信息 满足某个特定条件才发送 优先级比较高 LUNIX信号一览表(加粗牢记) 编号 信号名称 对应事件 默认动作 1 SIGHUP 用户退出shell时，由该shell启动的所有进程将 收到这个信号 终止进程(A) 2 SIGINT 当用户按下了＜Ctrl+C＞组合键时，用户终端向正在运行中的该终端后动的程序发出此信号 终止进程(A) 3 SIGQUIT 用户按下＜Ctrl+\\＞组合键时产生该信号，用户终端向正在运行中的由该终端启动的程序发出些信号 终止进程(C) 4 SIGILL CPU检测到某进程执行了非法指令 终止进程并产生core文件(C) 5 SIGTRAP 该信号由断点指令或其他trap指令产生 终止进程并产生core文件 6 SIGABRT 调用abort函数时产生该信号 终止进程并产生core文件(C) 7 SIGBUS 非法访问内存地址，包括内存对齐出错 终止进程并产生core文件 8 SIGFPE 在发生致命的运算错误时发出。不仅包括浮点运算 错误，还包括溢出及除数为0等所有的算法错误 终止进程并产生core文件(C) 9 SIGKILL 无条件终止进程。该信号不能被忽略，处理和阻塞 终止进程，可以杀死任何进程(AEF) 10 SIGUSE1 用户定义的信号。即程序员可以在程序中定义并使用该信号 终止进程(A) 11 SIGSEGV 指示进程进行了无效内存访问（段错误） 终止进程并产生core文件(C) 12 SIGUSR2 另外一个用户自定义信号，程序员可以在程序中 定义并使用该信号 终止进程(A) 13 SIGPIPE Broken pipe向一个没有读端的管道写数据 终止进程(A) 14 SIGALRM 定时器超时，超时的时间由系统调用alarm设置 终止进程(A) 15 SIGTERM 程序结束信号，与SIGKILL不同的是，该信号可 以被阻塞和终止。通常用来要示程序正常退出。 执行shell命令Kill时，缺省产生这个信号 终止进程(A) 16 SIGSTKFLT Linux早期版本出现的信号，现仍保留向后兼容 终止进程(A) 17 SIGCHLD 子进程结束时，父进程会收到这个信号 忽略这个信号(B) 18 SIGCONT 如果进程已停止，则使其继续运行 继续/忽略(D) 19 SIGSTOP 停止进程的执行。信号不能被忽略，处理和阻塞 为终止进程 20 SIGTSTP 停止终端交互进程的运行。按下＜ctrl+z＞组合键时发出这个信号 暂停进程(D) 21 SIGTTIN 后台进程读终端控制台 暂停进程(D) 22 SIGTTOU 该信号类似于SIGTTIN,在后台进程要向终端输出数据时发生 暂停进程(D) 23 SIGURG 套接字上有紧急数据时，向当前正在运行的进程发出些信号，报告有紧急数据到达。如网络带外数据到达 忽略该信号 24 SIGXCPU 进程执行时间超过了分配给该进程的CPU时间，系统产生该信号并 发送给该进程 终止进程 默认动作字母含义 A：默认动作是终止进程 B：默认动作是忽略此信号，将该信号丢弃，不做处理 C：默认的动作是终止进程并进行内核映像转储（core dump) ，内核映像转储将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。 D：默认动作是停止(暂停)进程，进入停止状态以后还能重新进行下去 E：信号不能被捕获 F：信号不能被忽略 信号的5种默认处理动作 查看信号的详细信息：man 7 signal 查看系统定义的信号列表：kill -l 前31个信号为常规信号，其余为实时信号。 信号的5中默认处理动作 Term 终止进程 Ign 当前进程忽略掉这个信号 Core 终止进程，并生成一个Core文件 Stop 暂停当前进程 Cont 继续执行当前被暂停的进程 信号的几种状态：产生、未决、递达 SIGKILL和SIGSTOP信号不能被捕捉、阻塞或者忽略，只能执行默认动作。 kill、raise、abort函数 int kill(pid_t pid, int sig); 功能：给任何的进程或者进程组pid, 发送任何的信号 sig 参数： pid ： > 0: 将信号发送给指定的进程 = 0: 将信号发送给当前的进程组 = -1: 将信号发送给每一个有权限接收这个信号的进程 : 这个pid=某个进程组的ID取反 （-12345） sig : 需要发送的信号的编号或者是宏值，0表示不发送任何信号 示例 kill(getppid(), 9); kill(getpid(), 9); int raise(int sig); 功能：给当前进程发送信号 参数： sig : 要发送的信号 返回值： 成功 0 失败 非0 示例：kill(getpid(), sig); void abort(void); 功能： 发送SIGABRT信号给当前的进程，杀死当前进程 示例：kill(getpid(), SIGABRT); #include #include #include #include int main() { pid_t pid = fork(); if(pid == 0) { // 子进程 int i = 0; for(i = 0; i 0) { // 父进程 printf(\"parent process\\n\"); sleep(2); printf(\"kill child process now\\n\"); kill(pid, SIGINT); } return 0; } 可靠信号与不可靠信号 信号分为不可靠信号(1-32)与不可靠信号(34-64) 不可靠信号有以下问题 每次信号处理完之后，就会恢复成默认处理（早期的signal函数，Linux2.6.35.6内核经验证已经不再恢复默认动作） 存在信号丢失的问题（进程收到的信号不作排队处理，相同的信号多次到来会合并为一个） 现在的Linux对信号进行了改进，因此，不可靠信号主要是指信号丢失 信号处理函数被中断 当一个信号到达后，调用处理函数，如果这时候有其它的信号发生，会中断之前的处理函数，等新的信息处理函数执行完成后再继续执行之前的处理函数 但是，同一个信号会排队阻塞 信号的阻塞 如果不希望在接到信号时中断当前的处理函数，也不希望忽略该信号，而是延时一段时间再处理这个信号，这种情况可以通过阻塞信号实现的 信号的阻塞和忽略信号是不同的，被阻塞的信号也不会影响进程的行为，信号只是暂时被阻止传递 进程忽略一个信号时，信号会被传递出去但进程会将信号丢弃 执行信号的处理动作称为信号递达（Delivery），信号从产生到递达之间的状态，称为信号未决（Pending） alarm函数 unsigned int alarm(unsigned int seconds); 功能：设置定时器（闹钟）。函数调用，开始倒计时，当倒计时为0的时候，函数会给当前的进程发送一个信号：SIGALARM 参数： seconds: 倒计时的时长，单位：秒。如果参数为0，定时器无效（不进行倒计时，不发信号）。取消一个定时器，通过alarm(0)。 返回值： 之前没有定时器，返回0 之前有定时器，返回之前的定时器剩余的时间 SIGALARM ：默认终止当前的进程，每一个进程都有且只有唯一的一个定时器。 alarm(10); -> 返回0 过了1秒 alarm(5); -> 返回9 alarm(100) -> 该函数是不阻塞的 #include #include int main() { int seconds = alarm(5); printf(\"seconds = %d\\n\", seconds); // 0 sleep(2); seconds = alarm(2); // 不阻塞 printf(\"seconds = %d\\n\", seconds); // 3 while(1) { } return 0; } // 1秒钟电脑能数多少个数？ #include #include /* 实际的时间 = 内核时间 + 用户时间 + 消耗的时间 进行文件IO操作的时候比较浪费时间 定时器，与进程的状态无关（自然定时法）。无论进程处于什么状态，alarm都会计时。 */ int main() { alarm(1); int i = 0; while(1) { printf(\"%i\\n\", i++); } return 0; } setitimer定时器函数 int setitimer(int which, const struct itimerval *new_value, struct itimerval *old_value); 功能：设置定时器（闹钟）。可以替代alarm函数。精度微妙us，可以实现周期性定时 参数： which : 定时器以什么时间计时 ITIMER_REAL: 真实时间，时间到达，发送 SIGALRM 常用 ITIMER_VIRTUAL: 用户时间，时间到达，发送 SIGVTALRM ITIMER_PROF: 以该进程在用户态和内核态下所消耗的时间来计算，时间到达，发送 SIGPROF new_value: 设置定时器的属性 struct itimerval { // 定时器的结构体 struct timeval it_interval; // 每个阶段的时间，间隔时间 struct timeval it_value; // 延迟多长时间执行定时器 }; struct timeval { // 时间的结构体 time_t tv_sec; // 秒数 suseconds_t tv_usec; // 微秒 }; 过10秒后，每个2秒定时一次 old_value：记录上一次的定时的时间参数，一般不使用，指定NULL 返回值： 成功 0 失败 -1 并设置错误号 #include #include #include // 过3秒以后，每隔2秒钟定时一次 int main() { struct itimerval new_value; // 设置间隔的时间 new_value.it_interval.tv_sec = 2; new_value.it_interval.tv_usec = 0; // 设置延迟的时间,3秒之后开始第一次定时 new_value.it_value.tv_sec = 3; new_value.it_value.tv_usec = 0; int ret = setitimer(ITIMER_REAL, &new_value, NULL); // 非阻塞的 printf(\"定时器开始了...\\n\"); if(ret == -1) { perror(\"setitimer\"); exit(0); } getchar(); return 0; } signal信号捕捉函数 typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler)：设置程序对信号的处理方式 signum：表示信号的编号 handler：信号的处理方式，有以下三种 SIG_IGN：忽略参数 signum 所指的信号 回调函数: 一个自定义的处理信号的函数，信号的编号为这个自定义函数的参数 需要程序员实现，提前准备好的，函数的类型根据实际需求，看函数指针的定义 不是程序员调用，而是当信号产生，由内核调用 函数指针是实现回调的手段，函数实现之后，将函数名放到函数指针的位置就可以了。 SIG_DFL：恢复参数signum所指信号的处理方法为默认值 返回值： 成功，返回上一次注册的信号处理函数的地址。第一次调用返回NULL 失败，返回SIG_ERR，设置错误号 SIGKILL、SIGSTOP不能被捕捉，不能被忽略。 #include #include #include #include void myalarm(int num) { printf(\"捕捉到了信号的编号是：%d\\n\", num); printf(\"xxxxxxx\\n\"); } // 过3秒以后，每隔2秒钟定时一次 int main() { // 注册信号捕捉 // signal(SIGALRM, SIG_IGN); // signal(SIGALRM, SIG_DFL); // void (*sighandler_t)(int); 函数指针，int类型的参数表示捕捉到的信号的值。 signal(SIGALRM, myalarm); struct itimerval new_value; // 设置间隔的时间 new_value.it_interval.tv_sec = 2; new_value.it_interval.tv_usec = 0; // 设置延迟的时间,3秒之后开始第一次定时 new_value.it_value.tv_sec = 3; new_value.it_value.tv_usec = 0; int ret = setitimer(ITIMER_REAL, &new_value, NULL); // 非阻塞的 printf(\"定时器开始了...\\n\"); if(ret == -1) { perror(\"setitimer\"); exit(0); } getchar(); return 0; } 信号集及相关函数 信号集 许多信号相关的系统调用都需要能表示一组不同的信号，多个信号可使用一个称之为信号集的数据结构来表示，其系统数据类型为sigset_t 在PCB中有两个非常重要的信号集。一个称之为”阻塞信号集”,另一个称之为”未决信号集”。这两个信号集都是内核使用位图机制来实现的。 但操作系统不允许我们直接对这两个信号集进行位操作。而需自定义另外一个集合，借助信号集操作函数来对PCB中的这两个信号集进行修改； 信号的“未决”是一种状态，指的是从信号的产生到信号被处理前的这一段时间。 信号的\"阻塞”是一个开关动作，指的是阻止信号被处理，但不是阻止信号产生。 信号的阻塞就是让系统暂时保留信号留待以后发送。由于另外有办法让系统忽略信号,所以一般情况下信号的阻塞只是暂时的，只是为了防止信号打断敏感的操作。 阻塞信号集和未决信号集 1.用户通过键盘 Ctrl + C, 产生2号信号SIGINT (信号被创建) 2.信号产生但是没有被处理 （未决） 在内核中将所有的没有被处理的信号存储在一个集合中 （未决信号集） SIGINT信号状态被存储在第二个标志位上 这个标志位的值为0， 说明信号不是未决状态 这个标志位的值为1， 说明信号处于未决状态 3.这个未决状态的信号，需要被处理，处理之前需要和另一个信号集（阻塞信号集），进行比较 阻塞信号集默认不阻塞任何的信号 如果想要阻塞某些信号需要用户调用系统的API 4.在处理的时候和阻塞信号集中的标志位进行查询，看是不是对该信号设置阻塞了 如果没有阻塞，这个信号就被处理 如果阻塞了，这个信号就继续处于未决状态，直到阻塞解除，这个信号就被处理 信号集相关的函数 int sigemptyset(sigset_t *set); 功能：清空信号集中的数据,将信号集中的所有的标志位置为0 参数： set：传出参数，需要操作的信号集 返回值： 成功返回0 失败返回-1 int sigfillset(sigset_t *set); 功能：将信号集中的所有的标志位置为1 参数： set：传出参数，需要操作的信号集 返回值： 成功返回0 失败返回-1 int sigaddset(sigset_t *set, int signum); 功能：设置信号集中的某一个信号对应的标志位为1，表示阻塞这个信号 参数： set：传出参数，需要操作的信号集 signum：需要设置阻塞的那个信号 返回值： 成功返回0 失败返回-1 int sigdelset(sigset_t *set, int signum); 功能：设置信号集中的某一个信号对应的标志位为0，表示不阻塞这个信号 参数： set：传出参数，需要操作的信号集 signum：需要设置不阻塞的那个信号 返回值： 成功返回0 失败返回-1 int sigismember(const sigset_t *set, int signum); 功能：判断某个信号是否阻塞 参数： set：需要操作的信号集 signum：需要判断的那个信号 返回值： 1 ： signum被阻塞 0 ： signum不阻塞 -1 ： 失败 #include #include int main() { // 创建一个信号集 sigset_t set; // 清空信号集的内容 sigemptyset(&set); // 判断 SIGINT 是否在信号集 set 里 int ret = sigismember(&set, SIGINT); if(ret == 0) { printf(\"SIGINT 不阻塞\\n\"); } else if(ret == 1) { printf(\"SIGINT 阻塞\\n\"); } // 添加几个信号到信号集中 sigaddset(&set, SIGINT); sigaddset(&set, SIGQUIT); // 判断SIGINT是否在信号集中 ret = sigismember(&set, SIGINT); if(ret == 0) { printf(\"SIGINT 不阻塞\\n\"); } else if(ret == 1) { printf(\"SIGINT 阻塞\\n\"); } // 判断SIGQUIT是否在信号集中 ret = sigismember(&set, SIGQUIT); if(ret == 0) { printf(\"SIGQUIT 不阻塞\\n\"); } else if(ret == 1) { printf(\"SIGQUIT 阻塞\\n\"); } // 从信号集中删除一个信号 sigdelset(&set, SIGQUIT); // 判断SIGQUIT是否在信号集中 ret = sigismember(&set, SIGQUIT); if(ret == 0) { printf(\"SIGQUIT 不阻塞\\n\"); } else if(ret == 1) { printf(\"SIGQUIT 阻塞\\n\"); } return 0; } sigprocmask函数使用 int sigprocmask(int how, const sigset_t *set, sigset_t *oldset); 功能：将自定义信号集中的数据设置到内核中（设置阻塞，解除阻塞，替换） 参数： how : 如何对内核阻塞信号集进行处理 SIG_BLOCK: 将用户设置的阻塞信号集添加到内核中，内核中原来的数据不变 假设内核中默认的阻塞信号集是mask， mask | set SIG_UNBLOCK: 根据用户设置的数据，对内核中的数据进行解除阻塞 mask &= ~set SIG_SETMASK: 覆盖内核中原来的值 set ：已经初始化好的用户自定义的信号集 oldset : 保存设置之前的内核中的阻塞信号集的状态，可以是 NULL 返回值： 成功：0 失败：-1，设置错误号：EFAULT、EINVAL int sigpending(sigset_t *set); 功能：获取内核中的未决信号集 参数： set：传出参数，保存的是内核中的未决信号集中的信息。 // 编写一个程序，把所有的常规信号（1-31）的未决状态打印到屏幕 // 设置某些信号是阻塞的，通过键盘产生这些信号 #include #include #include #include int main() { // 设置2、3号信号阻塞 sigset_t set; sigemptyset(&set); // 将2号和3号信号添加到信号集中 sigaddset(&set, SIGINT); sigaddset(&set, SIGQUIT); // 修改内核中的阻塞信号集 sigprocmask(SIG_BLOCK, &set, NULL); int num = 0; while(1) { num++; // 获取当前的未决信号集的数据 sigset_t pendingset; sigemptyset(&pendingset); sigpending(&pendingset); // 遍历前32位 for(int i = 1; i SIGCHLG信号 /* SIGCHLD信号产生的3个条件： 1.子进程结束 2.子进程暂停了 3.子进程继续运行 都会给父进程发送该信号，父进程默认忽略该信号。 使用SIGCHLD信号解决僵尸进程的问题。 */ #include #include #include #include #include #include void myFun(int num) { printf(\"捕捉到的信号 ：%d\\n\", num); // 回收子进程PCB的资源 // while(1) { // wait(NULL); // } while(1) { int ret = waitpid(-1, NULL, WNOHANG); if(ret > 0) { printf(\"child die , pid = %d\\n\", ret); } else if(ret == 0) { // 说明还有子进程或者 break; } else if(ret == -1) { // 没有子进程 break; } } } int main() { // 提前设置好阻塞信号集，阻塞SIGCHLD，因为有可能子进程很快结束，父进程还没有注册完信号捕捉 sigset_t set; sigemptyset(&set); sigaddset(&set, SIGCHLD); sigprocmask(SIG_BLOCK, &set, NULL); // 创建一些子进程 pid_t pid; for(int i = 0; i 0) { // 父进程 // 捕捉子进程死亡时发送的SIGCHLD信号 struct sigaction act; act.sa_flags = 0; act.sa_handler = myFun; sigemptyset(&act.sa_mask); sigaction(SIGCHLD, &act, NULL); // 注册完信号捕捉以后，解除阻塞 sigprocmask(SIG_UNBLOCK, &set, NULL); while(1) { printf(\"parent process pid : %d\\n\", getpid()); sleep(2); } } else if( pid == 0) { // 子进程 printf(\"child process pid : %d\\n\", getpid()); } return 0; } "},"C++/多进程/06-进程间通信-共享内存.html":{"url":"C++/多进程/06-进程间通信-共享内存.html","title":"进程间通信-共享内存","keywords":"","body":"datetime:2023/01/09 11:40 author:nzb 进程间通信 5、共享内存 共享内存有两种方式，即 shm（shared memory） 和 内存映射(mmap) 方式。前者直接共享物理内存，后者通过一个中间文件间接共享内存。 5.1、内存映射(mmap) 5.1.1、内存映射(mmap)是什么 内存映射(Memory-mapped I/O)是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。 实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上， 即完成了对文件的操作而不必再调用read,write 等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。 5.1.2、内存映射(mmap)和常规文件操作的区别 常规文件操作需要从磁盘到页缓存(处于内核空间，不能被用户进程直接寻址)，再到用户主存的两次数据拷贝。而mmap操控文件， 只需要从磁盘到用户主存的一次数据拷贝过程（创建新的虚拟内存区域，建议文件磁盘地址和虚拟内存区域映射，一次拷贝）。 5.1.3、内存映射(mmap)的优点 mmap系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问， 不必再调用read()，write()等操作。mmap并不分配空间, 只是将文件映射到调用进程的地址空间里, 然后你就可以用memcpy等操作写文件, 而不用write()了.写完后用msync()同步一下, 你所写的内容就保存到文件里了. 不过这种方式没办法增加文件的长度, 因为要映射的长度在调用mmap()的时候就决定了. 5.1.4、使用内存映射实现没有关系的进程间的通信案例 /* #include void *mmap(void *addr, size_t length, int prot, int flags,int fd, off_t offset); - 功能：将一个文件或者设备的数据映射到内存中 - 参数： - void *addr: NULL, 由内核指定 - length : 要映射的数据的长度，这个值不能为0。建议使用文件的长度。 获取文件的长度：stat lseek - prot : 对申请的内存映射区的操作权限 -PROT_EXEC ：可执行的权限 -PROT_READ ：读权限 -PROT_WRITE ：写权限 -PROT_NONE ：没有权限 要操作映射内存，必须要有读的权限。 PROT_READ、PROT_READ|PROT_WRITE - flags : - MAP_SHARED : 映射区的数据会自动和磁盘文件进行同步，进程间通信，必须要设置这个选项 - MAP_PRIVATE ：不同步，内存映射区的数据改变了，对原来的文件不会修改，会重新创建一个新的文件。（copy on write） - fd: 需要映射的那个文件的文件描述符 - 通过open得到，open的是一个磁盘文件 - 注意：文件的大小不能为0，open指定的权限不能和prot参数有冲突。 prot: PROT_READ open:只读/读写 prot: PROT_READ | PROT_WRITE open:读写 - offset：偏移量，一般不用。必须指定的是4k的整数倍，0表示不偏移。 - 返回值：返回创建的内存的首地址 失败返回MAP_FAILED，(void *) -1 int munmap(void *addr, size_t length); - 功能：释放内存映射 - 参数： - addr : 要释放的内存的首地址 - length : 要释放的内存的大小，要和mmap函数中的length参数的值一样。 */ /* 使用内存映射实现进程间通信： 1.有关系的进程（父子进程） - 还没有子进程的时候 - 通过唯一的父进程，先创建内存映射区 - 有了内存映射区以后，创建子进程 - 父子进程共享创建的内存映射区 2.没有关系的进程间通信 - 准备一个大小不是0的磁盘文件 - 进程1 通过磁盘文件创建内存映射区 - 得到一个操作这块内存的指针 - 进程2 通过磁盘文件创建内存映射区 - 得到一个操作这块内存的指针 - 使用内存映射区通信 注意：内存映射区通信，是非阻塞。 */ #include #include #include #include #include #include #include #include // 作业:使用内存映射实现没有关系的进程间的通信。 int main() { // 1.打开一个文件 int fd = open(\"test.txt\", O_RDWR); int size = lseek(fd, 0, SEEK_END); // 获取文件的大小 // 2.创建内存映射区 void *ptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); if(ptr == MAP_FAILED) { perror(\"mmap\"); exit(0); } // 3.创建子进程 pid_t pid = fork(); if(pid > 0) { wait(NULL); // 父进程 char buf[64]; strcpy(buf, (char *)ptr); printf(\"read data : %s\\n\", buf); }else if(pid == 0){ // 子进程 strcpy((char *)ptr, \"nihao a, son!!!\"); } // 关闭内存映射区 munmap(ptr, size); return 0; } 5.1.5、思考问题 如果对mmap的返回值(ptr)做++操作(ptr++), munmap是否能够成功? void * ptr = mmap(...); ptr++; // 可以对其进行++操作 munmap(ptr, len); // 错误,要保存地址 如果open时O_RDONLY, mmap时prot参数指定PROT_READ | PROT_WRITE会怎样? 答：错误，返回MAP_FAILED， open()函数中的权限建议和prot参数的权限保持一致。 如果文件偏移量为1000会怎样? 答：偏移量必须是4K的整数倍，返回MAP_FAILED mmap什么情况下会调用失败? 第2个参数：length = 0 第3个参数：prot 只指定了写权限 第3个参数 prot 指定了PROT_READ | PROT_WRITE，而第5个参数 fd 通过open函数时指定的 O_RDONLY / O_WRONLY 可以open的时候O_CREAT一个新文件来创建映射区吗? 可以的，但是创建的文件的大小如果为0的话，肯定不行 可以对新的文件进行扩展 lseek() truncate() mmap后关闭文件描述符，对mmap映射有没有影响？ int fd = open(\"XXX\"); mmap(,,,,fd,0); close(fd); 映射区还存在，创建映射区的fd被关闭，没有任何影响。 5.1.6、内存映射可以实现：1.进程通信；2.文件拷贝（但是不能拷贝太大的文件，一般也不用于文件拷贝） // 使用内存映射实现文件拷贝的功能 /* 思路： 1.对原始的文件进行内存映射 2.创建一个新文件（拓展该文件） 3.把新文件的数据映射到内存中 4.通过内存拷贝将第一个文件的内存数据拷贝到新的文件内存中 5.释放资源 */ #include #include #include #include #include #include #include #include int main() { // 1.对原始的文件进行内存映射 int fd = open(\"english.txt\", O_RDWR); if(fd == -1) { perror(\"open\"); exit(0); } // 获取原始文件的大小 int len = lseek(fd, 0, SEEK_END); // 2.创建一个新文件（拓展该文件） int fd1 = open(\"cpy.txt\", O_RDWR | O_CREAT, 0664); if(fd1 == -1) { perror(\"open\"); exit(0); } // 对新创建的文件进行拓展 truncate(\"cpy.txt\", len); write(fd1, \" \", 1); // 3.分别做内存映射 void * ptr = mmap(NULL, len, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); void * ptr1 = mmap(NULL, len, PROT_READ | PROT_WRITE, MAP_SHARED, fd1, 0); if(ptr == MAP_FAILED) { perror(\"mmap\"); exit(0); } if(ptr1 == MAP_FAILED) { perror(\"mmap\"); exit(0); } // 内存拷贝 memcpy(ptr1, ptr, len); // 释放资源 munmap(ptr1, len); munmap(ptr, len); close(fd1); close(fd); return 0; } 5.1.7、内存映射的匿名映射：不需要文件实体进程一个内存映射 /* 匿名映射：不需要文件实体进程一个内存映射 */ #include #include #include #include #include #include #include #include #include int main() { // 1.创建匿名内存映射区 int len = 4096; void * ptr = mmap(NULL, len, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0); if(ptr == MAP_FAILED) { perror(\"mmap\"); exit(0); } // 父子进程间通信 pid_t pid = fork(); if(pid > 0) { // 父进程 strcpy((char *) ptr, \"hello, world\"); wait(NULL); }else if(pid == 0) { // 子进程 sleep(1); printf(\"%s\\n\", (char *)ptr); } // 释放内存映射区 int ret = munmap(ptr, len); if(ret == -1) { perror(\"munmap\"); exit(0); } return 0; } 5.1.8、共享存储常用的接口 int shm_open(const char *name, int oflag, mode_t mode); //用于创建或者打开共享内存文件,操作的文件一定是位于tmpfs文件系统里的,存放目录就是/dev/shm void *mmap(void *addr, size_t length, int port, int flags, int fd, off_t offset); //将打开的文件映射到内存 int munmap(void *addr, size_t length); //取消内存映射 int shm_unlink(const char *name); //删除/dev/shm目录的文件 int ftruncate(int fd, off_t length); //重置文件大小 5.2、共享内存 共享内存区是最快的IPC形式。一旦这样的内存映射到共享它的进程的地址空间，这些进程间数据传递不再涉及到内核，换句话说是进程不再通过执行进入内核的系统调用来传递彼此的数据。 用管道或者消息队列传递数据 用共享内存传递数据 5.3、内存映射和共享内存的区别 1、mmap保存到实际硬盘，实际存储并没有反映到主存上。优点：储存量可以很大（多于主存）；缺点：进程间读取和写入速度要比主存的要慢。—— 每个进程在自己的虚拟地址空间中开辟出一块独立的空间进行映射 2、shm保存到物理存储器（主存），实际的储存量直接反映到主存上。优点，进程间访问速度（读写）比磁盘要快；缺点，储存量不能非常大—— 每个进程最终会映射到同一块物理内存 3、mmap系统调用并不是完全为了用于共享内存而设计的。它本身提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。 而Posix或系统V的共享内存IPC则纯粹用于共享目的，当然mmap() 实现共享内存也是其主要应用之一。 4、共享内存可以直接创建，内存映射需要磁盘文件（匿名映射除外） 5、数据安全 进程突然退出 共享内存还存在 内存映射区消失 运行进程的电脑死机，宕机了 数据存在在共享内存中，没有了 内存映射区的数据 ，由于磁盘文件中的数据还在，所以内存映射区的数据还存在。 6、生命周期 内存映射区：进程退出，内存映射区销毁 共享内存：进程退出，共享内存还在，标记删除（所有的关联的进程数为0），或者关机，如果一个进程退出，会自动和共享内存进行取消关联。 5.4、注意 1、物理内存和虚拟内存 物理内存是指由于安装内存条而获得的临时储存空间。主要作用是在计算机运行时为操作系统和各种程序提供临时储存。 虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），它通常是被分隔成多个物理内存碎片， 还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。 2、虚拟内存的工作模式 - 当每个进程创建的时候，内核会为进程分配4G的虚拟内存，当进程还没有开始运行时，这只是一个内存布局。实际上并不立即就把虚拟内存对应位置的程序数据和代码 （比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射）。这个时候数据和代码还是在磁盘上的。 当运行到对应的程序时，进程去寻找页表，发现页表中地址没有存放在物理内存上，而是在磁盘上，于是发生缺页异常，于是将磁盘上的数据拷贝到物理内存中。 另外在进程运行过程中，要通过malloc 来动态分配内存时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。 5.5、共享内存常用的接口 #include #include int shmget(key_t key, size_t size, int shmflg); 功能：创建一个新的共享内存段，或者获取一个既有的共享内存段的标识。新创建的内存段中的数据都会被初始化为0 参数： key : key_t类型是一个整形，通过这个找到或者创建一个共享内存。一般使用16进制表示(方便命令行查看)，非0值 size: 共享内存的大小 shmflg: 属性 访问权限 附加属性：创建/判断共享内存是不是存在 创建：IPC_CREAT 判断共享内存是否存在： IPC_EXCL , 需要和IPC_CREAT一起使用：IPC_CREAT | IPC_EXCL | 0664 返回值： 失败：-1 并设置错误号 成功：>0 返回共享内存的引用的ID，后面操作共享内存都是通过这个值。 void *shmat(int shmid, const void *shmaddr, int shmflg); 功能：和当前的进程进行关联 参数： shmid : 共享内存的标识（ID）,由shmget返回值获取 shmaddr: 申请的共享内存的起始地址，指定NULL，内核指定 shmflg : 对共享内存的操作 读 ： SHM_RDONLY, 必须要有读权限 读写： 0 返回值： 成功：返回共享内存的首（起始）地址。 失败：(void *) -1 int shmdt(const void *shmaddr); 功能：解除当前进程和共享内存的关联 参数： shmaddr：共享内存的首地址 返回值： 成功：0 失败：-1 int shmctl(int shmid, int cmd, struct shmid_ds *buf); 功能：对共享内存进行操作。删除共享内存，共享内存要删除才会消失，创建共享内存的进行被销毁了对共享内存是没有任何影响。 参数： shmid: 共享内存的ID cmd : 要做的操作 IPC_STAT : 获取共享内存的当前的状态 IPC_SET : 设置共享内存的状态 IPC_RMID: 标记共享内存被销毁 buf：需要设置或者获取的共享内存的属性信息 IPC_STAT : buf存储数据 IPC_SET : buf中需要初始化数据，设置到内核中 IPC_RMID : 没有用，NULL key_t ftok(const char *pathname,int proj_id); 功能：根据指定的路径名，和int值，生成一个共享内存的key 参数： pathname:指定一个存在的路径：/home/nowcoder/Linux/a.txt proj_id: int类型的值，但是这系统调用只会使用其中的1个字节，范围 ： 0-255 一般指定一个字符 'a' 问题1：操作系统如何知道一块共享内存被多少个进程关联？ 共享内存维护了一个结构体struct shmid_ds 这个结构体中有一个成员 shm_nattch shm_nattach 记录了关联的进程个数 问题2：可不可以对共享内存进行多次删除 shmctl 可以的 因为 shmctl 标记删除共享内存，不是直接删除 什么时候真正删除呢? 当和共享内存关联的进程数为0的时候，就真正被删除 当共享内存的key为0的时候，表示共享内存被标记删除了，如果一个进程和共享内存取消关联，那么这个进程就不能继续操作这个共享内存。也不能进行关联。 5.6、代码 write_shm.c #include #include #include #include int main() { // 1.创建一个共享内存 int shmid = shmget(100, 4096, IPC_CREAT|0664); printf(\"shmid : %d\\n\", shmid); // 2.和当前进程进行关联 void * ptr = shmat(shmid, NULL, 0); char * str = \"helloworld\"; // 3.写数据 memcpy(ptr, str, strlen(str) + 1); printf(\"按任意键继续\\n\"); getchar(); // 4.解除关联 shmdt(ptr); // 5.删除共享内存 shmctl(shmid, IPC_RMID, NULL); return 0; } read_shm.c #include #include #include #include int main() { // 1.获取一个共享内存 int shmid = shmget(100, 0, IPC_CREAT); printf(\"shmid : %d\\n\", shmid); // 2.和当前进程进行关联 void * ptr = shmat(shmid, NULL, 0); // 3.读数据 printf(\"%s\\n\", (char *)ptr); printf(\"按任意键继续\\n\"); getchar(); // 4.解除关联 shmdt(ptr); // 5.删除共享内存 shmctl(shmid, IPC_RMID, NULL); return 0; } 5.7、共享内存相关命令 ipcs -m：查看系统的共享内存，内容有键值(key)，共享内存编号(shmid)，创建者(owner)，权限(perms)，大小(bytes) root@tegra-ubuntu:/home/quicktron# ipcs -m ------ Shared Memory Segments -------- key shmid owner perms bytes nattch status 0x00000000 65536 quicktron 600 524288 2 dest 0x00000000 163841 quicktron 600 524288 2 dest 0x00000000 622594 quicktron 600 524288 2 dest 0x00000000 524291 quicktron 600 524288 2 dest 0x00000000 458756 quicktron 600 16777216 2 dest 0x00000000 655365 quicktron 600 524288 2 dest 0x00000000 753670 quicktron 600 524288 2 dest ipcrm -m [shmid]共享内存编号，可以手动删除共享内存 "},"C++/多进程/07-进程间通信-信号量.html":{"url":"C++/多进程/07-进程间通信-信号量.html","title":"进程间通信-信号量","keywords":"","body":"datetime:2023/03/09 15:44 author:nzb 进程间通信 信号量 信号量概念 信号量（信号灯）本质上是一个计数器,用于协调多个进程（包括但不限于父子进程）对共享数据对象的读/写。它不以传送数据为目 的，主要是用来保护共享资源（共享内存、消息队列、socket连接池、数据库连接池等），保证共享资源在一个时刻只有一个进程独享。 信号是是一个特殊的变量，只允许进程对它进行等待信号和发送信号操作。最简单的信号是是取值0和1的二元信号量，这是信号是最常 见的形式。 通用信号量（可以取多个正整数值）和信号量集方面的知识比较复杂，应用场景也比较少。 相关函数 Linux中提供了一组函数用于操作值号是，程序中需要包含以下头文件： #include #include #include semget函数 int semget(key_t key, int nsems, int semflg); 参数key是信号量的键值，typedef unsigned int key_t，是信号量在系统中的编号，不同信号量的编号不能相同，这一点由程序员保证。key用十六进制表示比较好，方便命令行查看。 参数nsems是创建信号量集中信号量的个数，该参数只在创建信号量集时有效，这里固定填1。 参数sem_flags是一组标志，如果希望信号量不存在时创建一个新的信号量，可以和值IPC_CREAT做按位或操作，如果没有设置IPC_CREAT标志并且信号量不存在，就会返回错误(errno的值为2，No such file or directory) 如果semget函数成功，返回信号量集的标识；失败返回-1，错误原因存在于error中 示例 int semid=semget(0x5000, 1, 0640 | IPC_CREAT);：获取键值为0x5000的信号量，如果该信号量不存在，就创建它 int semid=semget(0x5000, 1, 0640);：获取键值为0x5000的信号量，如果该信号量不存在，返回-1，error的值被设置为2 semctl函数 int semctl(int semid, int sem_num, int command, ...);：用来控制信号量（常用于设置信号量的初始值和销毁信号量） 参数semid是由 semget 函数返回的信号量标识 参数 sem_num 是信号量集数组上的下标，表示某一个信号量，填0 参数 cmd 是对信号量操作的命令种类，常用的有以下两个： IPC_RMID：销毁信号量，不需要第四个参数 SETVAL：初始化信号量的值（信号量成功创建后，需要设置初始值），这个值由第四个参数决定。第四个参数是一个自定义的共同体 示例 semctl(semid, 0, IPC_RMID);：销毁信号量 初始化信号量的值为1，信号量可用union semun sem_union; sem_union.val = 1; semctl(semid, 0, SETVAL, sem_union); semop函数 int semop(int semid, struct sembuf *sops, unsigned nsops); 参数 semid 是由 semget函数返回的信号量标识 参数 nsops 是操作信号量的个数，即 sops 结构变量的个数，设置它的为1（只对一个信号量的操作） 参数 sops 是一个结构体，如下struct sembuf { short sem_num; // 信号量集的个数，单个信号量设置为0 short sem_op; // 信号量在本次操作中需要改变的数据；-1：等待操作；1：发送操作 short sem_flg; // 把此标志设置为 SEM_UNDO，操作系统将跟踪这个信号量。如果当前进程退出时没有释放信号量，操作系统将释放信号量，避免资源被锁死。 } 示例 等待信号量的值变为1，如果等待成功，立即把信号量的值置为0 struct sembuf sem_b; sem_b.sem_num = 0; sem_b.sem_op = -1; sem_b.sem_flg = SEM_UNDO; semop(sem_id, &sem_b, 1); 把信号量的值设置为1 struct sembuf sem_b; sem_b.sem_num = 0; sem_b.sem_op = 1; sem_b.sem_flg = SEM_UNDO; semop(sem_id, &sem_b, 1); #include #include #include #include #include #include class CSEM { private: union semun // 用于信号灯操作的共同体 { int val; struct semid_ds *buf; unsigned short *arry; } int sem_id; // 信号灯描述符 public: bool init(key_t key); // 如果信号灯已存在，获取信号灯；如果信号灯不存在，则创建信号灯并初始化。 bool wait(); // 等待信号灯挂出 bool post(); // 挂出信号灯 bool destroy(); // 销毁信号灯 } int main(int argc, char *argv[]) { CSEM sem; // 初始信号灯 if(sem.init(0x5000) == false) {printf(\"sem.init failed.\\n\"); return -1;} printf(\"sem.init ok\\n\"); // 等待信号挂出，等待成功后，将持有锁 if (sem.wait() == false) {printf(\"sem.wait failed.\\n\"); return -1;} printf(\"sem.wait ok\\n\"); sleep(50); // 在sleep的过程中，运行其它的该程序将等待锁 // 挂出信号灯，释放锁 if(sem.post() == false) {printf(\"sem.post failed.\\n\"); return -1;} printf(\"sem.post ok\\n\"); // 销毁信号灯 if(sem.destory()==false) {printf(\"sem.destroy failed.\\n\"); return -1;} printf(\"sem.destroy ok\\n\"); } bool CSEM::init(key_t key) { if((sem_id=semget(key, 1, 0640)) == -1) { // 如果信号灯不存在，创建它 if(error == 2) { if((sem_id=semget(key, 1, 0640|IPC_CREAT)) == -1) {perror(\"init 1 semget()\"); return false;} // 信号灯创建成功后，还需要把它初始化成可用的状态 union semun sem_union; sem_union.val = 1; if(semctl(sem_id, 0, SETVAL, sem_union) 命令行查看 ipcs -s：查看系统的信号量 key：键值 semid：信号量编号 owner：创建者 perms：权限 nsems：信号量数 ipcrm sem [信号量编号]：手工删除信号量 利用信号量给共享内存加锁(TODO) 通用信号量和信号量集(TODO) "},"C++/多线程/01-多线程基础.html":{"url":"C++/多线程/01-多线程基础.html","title":"多线程基础","keywords":"","body":"datetime:2023/03/10 14:09 author:nzb 多线程 线程概述 概述 与进程(process)类似，线程(thread)是允许应用程序并发执行多个任务的一种机制。一个进程可以包含多个线程。同一个程序中的所有线程均会独立执行相同程序，且共 享同一份全局内存区域，其中包括初始化数据段、未初始化数据段，以及堆内存段。(传统意义上的UNIX进程只是多线程程序的一个特例，该进程只包含一个线程) 进程是CPU分配资源的最小单位，线程是操作系统调度执行的最小单位。 线程是轻量级的进程(LWP： Light Weight Process),在Linux环境下线程的本质仍是进程。 查看指定进程的LWP号：ps -Lf pid 线程和进程的区别 进程间的信息难以共享。由于除去只读代码段外，父子进程并未共享内存，因此必须采用一些进程间通信方式，在进程间进行信息交换。 调用fork()来创建进程的代价相对较高，即便利用写时复制技术，仍热需要复制诸如内存页表和文件描述符表之类的多种进程属性，这意味着fork()调用在时间上的开销依然不菲。 线程之间能够方便、快速地共享信息。只需将数据复制到共享(全局或堆)变量中即可。 创建线程比创建进程通常要快10倍甚至更多。线程间是共享虚拟地址空间的，无需采用写时复制来复制内存，也无需复制页表。 线程之间共享和非共享资源 共享资源 进程ID和父进程ID 进程组工D和会话工D 用户ID和用户组ID 文件描述符表 信号处置 文件系统的相关信息：文件权限掩码(umask)、当前工作目录 虚拟地址空间(除栈、.text) 非共享资源 线程ID 信号掩码 线程特有数据 error变量 实时调度策略和优先级 栈，本地变量和函数的调用链接信息 NPTL 当Linux最初开发时,在内核中并不能真正支持线程。但是它的确可以通过clone ()系统调用将进程作为可调度的实体。 这个调用创建了调用进程(calling process)的 一个拷贝，这个拷贝与调用进程共享相同的地址空间。LinuxThreads项目使用这个调用 来完全在用户空间模拟对线程的支持。不幸的是，这种方法有一些缺点，尤其是在信号处理、调度和进程间同步等方面都存在问题。另外，这个线程模型也不符合POSIX的要求。 要改进LinuxThreads,需要内核的支持，并且重写线程库。有两个相互竞争的项目开始 来满足这些要求。一个包括IBM的开发人员的团队开展了 NGPT (Next-Generation POSIX Threads)项目。同时，Red Hat的一些开发人员开展了 NPTL项目。NGPT 在2003年中期被放弃了，把这个领域完全留给了 NPTL。 NPTL,或称为 Native POSIX Thread Library,是 Linux 线程的一个新实现，它克服了 LinuxThreads的缺点，同时也符合POSIX的需求。与LinuxThreads相 比，它在性能和稳定性方面都提供了重大的改进。 查看当前 pthread 库版本：getconf GNU_LIBPTHREAD_VERSION 其他 查看线程：ps -xH | grep 进程名 查看进程：ps -ef | grep 进程名 main函数为主进程/主线程，创建的线程为子线程 线程资源是共享的，使用相同的地址共享全局变量和对象 不能在子线程中使用exit，否则整个进程会退出，一般使用pthread_exit(0) 子线程退出尽量不要使用return,否则会报错，可以写为 return (void *)0; #include #include #include void* handler1(void* arg); void* handler2(void* arg); int var=0; int main() { pthread_t pthid1,pthid2; if(pthread_create(&pthid1,NULL,handler1,NULL)!=0) { printf(\"创建线程pthid1失败\\n\"); return -1; } if(pthread_create(&pthid2,NULL,handler2,NULL)!=0) { printf(\"创建线程pthid2失败\\n\"); return -1; } printf(\"pthid1=%lu,pthid2=%lu\\n\",pthid1,pthid2); printf(\"等待子线程退出\\n\"); //pthread_join会使主进程阻塞在这里，用于调试 pthread_join(pthid1,NULL); printf(\"子线程1已退出\\n\"); pthread_join(pthid2,NULL); printf(\"子线程2已退出\\n\"); return 0; } void* handler1(void* arg) { for(int i=0;i 线程创建 一般情况下,main函数所在的线程我们称之为主线程（main线程），其余创建的线程称之为子线程。 程序中默认只有一个进程，fork()函数调用，2进程 程序中默认只有一个线程，pthread_create()函数调用，2个线程。 相关函数 int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); 功能：创建一个子线程 参数： thread：传出参数，线程创建成功后，子线程的线程ID被写到该变量中。 attr : 设置线程的属性，一般使用默认值，NULL start_routine : 函数指针，这个函数是子线程需要处理的逻辑代码 arg : 给第三个参数使用，传参 返回值： 成功：0 失败：返回错误号。这个错误号和之前errno不太一样。 获取错误号的信息： char * strerror(int errnum); #include #include #include #include void * callback(void * arg) { printf(\"child thread...\\n\"); printf(\"arg value: %d\\n\", *(int *)arg); return NULL; } int main() { pthread_t tid; int num = 10; // 创建一个子线程 int ret = pthread_create(&tid, NULL, callback, (void *)&num); if(ret != 0) { char * errstr = strerror(ret); printf(\"error : %s\\n\", errstr); } for(int i = 0; i 线程参数的传递 不能使用全局变量传参，因为线程跑起来，全局变量可能已经被改变了 数据类型的强制转换，用于线程的参数：指针8字节，int是4字节 int i=10; void* p=(void*)(long)i;：先转8字节的long，再转指针类型 int jj=(int)(long)p;：先转8字节的long，再转int类型 二级指针概念： #include #include #include void* handler1(void* arg); void* handler2(void* arg); void* handler3(void* arg); void* handler4(void* arg); void* handler5(void* arg); long var=0; int main() { pthread_t pthid1,pthid2,pthid3,pthid4,pthid5; if(pthread_create(&pthid1,NULL,handler1,(void*)var)!=0) { printf(\"创建线程pthid1失败\\n\"); return -1; } var++; if(pthread_create(&pthid2,NULL,handler2,(void*)var)!=0) { printf(\"创建线程pthid2失败\\n\"); return -1; } var++; if(pthread_create(&pthid3,NULL,handler3,(void*)var)!=0) { printf(\"创建线程pthid3失败\\n\"); return -1; } var++; if(pthread_create(&pthid4,NULL,handler4,(void*)var)!=0) { printf(\"创建线程pthid4失败\\n\"); return -1; } var++; if(pthread_create(&pthid5,NULL,handler5,(void*)var)!=0) { printf(\"创建线程pthid5失败\\n\"); return -1; } printf(\"pthid1=%lu,pthid2=%lu,pthid3=%lu,pthid4=%lu,pthid5=%lu\\n\",pthid1,pthid2,pthid3,pthid4,pthid5); printf(\"等待子线程退出\\n\"); //pthread_join会使主进程阻塞在这里，用于调试 pthread_join(pthid1,NULL); printf(\"子线程1已退出\\n\"); pthread_join(pthid2,NULL); printf(\"子线程2已退出\\n\"); pthread_join(pthid3,NULL); printf(\"子线程3已退出\\n\"); pthread_join(pthid4,NULL); printf(\"子线程4已退出\\n\"); pthread_join(pthid5,NULL); printf(\"子线程5已退出\\n\"); return 0; } void* handler1(void* arg) { for(int i=0;i 终止线程 void pthread_exit(void *retval); 功能：终止一个线程，在哪个线程中调用，就表示终止哪个线程 参数 retval:需要传递一个指针，作为一个返回值，可以在pthread_join()中获取到。 pthread_t pthread_self(void); 功能：获取当前的线程的线程ID int pthread_equal(pthread_t t1, pthread_t t2); 功能：比较两个线程ID是否相等 不同的操作系统，pthread_t类型的实现不一样，有的是无符号的长整型，有的是使用结构体去实现的。 #include #include #include void * callback(void * arg) { printf(\"child thread id : %ld\\n\", pthread_self()); // pthread_self当前进程的id return NULL; // pthread_exit(NULL); } int main() { // 创建一个子线程 pthread_t tid; int ret = pthread_create(&tid, NULL, callback, NULL); if(ret != 0) { char * errstr = strerror(ret); printf(\"error : %s\\n\", errstr); } // 主线程 for(int i = 0; i 连接已终止的线程 线程有两种状态：joinable,unjoinable joinable:当子线程主函数终止不会释放线程所占用的资源，线程为僵尸线 程，创建线程默认属性为joinable pthread_join会在主进程中阻塞线程，一般不会使用(多用于调试) 创建线程前，调用pthread_attr_setdetachstate将线程设为detached，这样线程退出时，系统自动回收线程资源。 分离前pthread_join返回值为0，分离后返回值为errror=22,Invalid argument 创建线程后调用pthread_detach将新的线程设置为detach状态 在线程主调函数里面调用pthread_detach(pthread_self()) #include #include #include #include void* handler1(void* arg); void* handler2(void* arg); int var=0; { pthread_t pthid1,pthid2; /* pthread_attr_t attr; pthread_attr_init(&attr); pthread_attr_setdetachstate(&attr,PTHREAD_CREATE_DETACHED); // 设置线程的属性。*/ if(pthread_create(&pthid1,NULL,handler1,NULL)!=0) { printf(\"创建线程pthid1失败\\n\"); return -1; } //pthread_detach(pthid1); if(pthread_create(&pthid2,NULL,handler2,NULL)!=0) { printf(\"创建线程pthid2失败\\n\"); return -1; } //pthread_detach(pthid2); printf(\"pthid1=%lu,pthid2=%lu\\n\",pthid1,pthid2); printf(\"等待子线程退出\\n\"); //pthread_join会使主进程阻塞在这里，用于调试 int ret=pthread_join(pthid1,NULL); printf(\"子线程1已退出:%d,%s\\n\",ret,strerror(ret)); // pthread_join(pthid2,NULL); printf(\"子线程2已退出\\n\"); sleep(10); return 0; } void* handler1(void* arg) { pthread_detach(pthread_self()); for(int i=0;i 相关函数 int pthread_join(pthread_t thread, void ** retval); 功能：和一个已经终止的线程进行连接 回收子线程的资源 这个函数是阻塞函数，调用一次只能回收一个子线程 一般在主线程中使用 参数： thread：需要回收的子线程的ID retval: 类型为二级指针，接收子线程退出时的返回值 返回值： 0 : 成功 非0 : 失败，返回的错误号 示例1 #include #include #include #include int value = 10; void * callback(void * arg) { printf(\"child thread id : %ld\\n\", pthread_self()); // sleep(3); // return NULL; // int value = 10; // 局部变量 pthread_exit((void *)&value); // return (void *)&value; } int main() { // 创建一个子线程 pthread_t tid; int ret = pthread_create(&tid, NULL, callback, NULL); if(ret != 0) { char * errstr = strerror(ret); printf(\"error : %s\\n\", errstr); } // 主线程 for(int i = 0; i 示例2 #include #include #include void* handler1(void* arg); void* handler2(void* arg); int var=0; int main() { pthread_t pthid1; if(pthread_create(&pthid1,NULL,handler1,NULL)!=0) { printf(\"创建线程pthid1失败\\n\"); return -1; } printf(\"pthid1=%lu\\n\",pthid1); printf(\"等待子线程退出\\n\"); //pthread_join会使主进程阻塞在这里，用于调试 int ret; int result=pthread_join(pthid1,(void** )&ret); printf(\"子线程1已退出(result=%d,ret=%d)\\n\",result,ret); return 0; } void* handler1(void* arg) { for(int i=0;i 线程的分离 一般情况下，线程终止后，其终止状态一直保留到其它线程调用 pthread_join 获取它的状态为止，但是线程也可以被置为detach状态，这样的线程一旦终止就立刻回收它占用的所有资源，而不保留终止状态 int pthread_detach(pthread_t thread); 功能：分离一个线程。被分离的线程在终止的时候，会自动释放资源返回给系统。 1.不能多次分离，会产生不可预料的行为。 2.不能去连接(pthread_join)一个已经分离的线程，会报错。 参数：需要分离的线程的ID 返回值： 成功：0 失败：返回错误号 #include #include #include #include void * callback(void * arg) { printf(\"chid thread id : %ld\\n\", pthread_self()); return NULL; } int main() { // 创建一个子线程 pthread_t tid; int ret = pthread_create(&tid, NULL, callback, NULL); if(ret != 0) { char * errstr = strerror(ret); printf(\"error1 : %s\\n\", errstr); } // 输出主线程和子线程的id printf(\"tid : %ld, main thread id : %ld\\n\", tid, pthread_self()); // 设置子线程分离,子线程分离后，子线程结束时对应的资源就不需要主线程释放 ret = pthread_detach(tid); if(ret != 0) { char * errstr = strerror(ret); printf(\"error2 : %s\\n\", errstr); } // 设置分离后，对分离的子线程进行连接 pthread_join() // ret = pthread_join(tid, NULL); // if(ret != 0) { // char * errstr = strerror(ret); // printf(\"error3 : %s\\n\", errstr); // } pthread_exit(NULL); return 0; } 线程取消 int pthread_cancel(pthread_t thread); 功能：取消线程（让线程终止）, 取消某个线程，可以终止某个线程的运行， 但是并不是立马终止，而是当子线程执行到一个取消点，线程才会终止。 取消点：系统规定好的一些系统调用，我们可以粗略的理解为从用户区到内核区的切换，这个位置称之为取消点。 线程返回值为-1 int pthread_setcancelstate(int state, int *oldstate); 其中state有两种状态： PTHREAD_CANCEL_ENABLE（缺省情况） PTHREAD_CANCEL_DISABLE 取消点（Cancellation points）:会产生I/O等待的函数 取消点设置函数：void pthread_testcancel(void); int pthread_setcanceltype(int type, int *oldtype); 取消类型有两种：延迟取消，立即取消 PTHREAD_CANCEL_DEFERRED（延迟） PTHREAD_CANCEL_ASYNCHRONOUS（立即） 应用于总线程获取多个线程的状态，一旦某个线程挂掉，总线程即cancel子线程 示例1 #include #include #include #include void * callback(void * arg) { printf(\"chid thread id : %ld\\n\", pthread_self()); for(int i = 0; i 示例2：立即取消 #include #include void* handler1(void* arg); void* handler2(void* arg); int var=0; int main() { pthread_t pthid1; if(pthread_create(&pthid1,NULL,handler1,NULL)!=0) { printf(\"创建线程pthid1失败\\n\"); return -1; } usleep(2); pthread_cancel(pthid1); printf(\"pthid1=%lu\\n\",pthid1); printf(\"等待子线程退出\\n\"); //pthread_join会使主进程阻塞在这里，用于调试 int ret; int result=pthread_join(pthid1,(void** )&ret); printf(\"子线程1已退出(result=%d,ret=%d)\\n\",result,ret); return 0; } void* handler1(void* arg) { // pthread_setcancelstate(PTHREAD_CANCEL_DISABLE,NULL); //pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED,NULL); pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS,NULL); int jj=0; for(int i=0;i 示例3：延迟取消 #include #include void* handler1(void* arg); void* handler2(void* arg); int var=0; int main() { pthread_t pthid1; if(pthread_create(&pthid1,NULL,handler1,NULL)!=0) { printf(\"创建线程pthid1失败\\n\"); return -1; } usleep(2); pthread_cancel(pthid1); printf(\"pthid1=%lu\\n\",pthid1); printf(\"等待子线程退出\\n\"); //pthread_join会使主进程阻塞在这里，用于调试 int ret; int result=pthread_join(pthid1,(void** )&ret); printf(\"子线程1已退出(result=%d,ret=%d)\\n\",result,ret); return 0; } void* handler1(void* arg) { // pthread_setcancelstate(PTHREAD_CANCEL_DISABLE,NULL); pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED,NULL); // pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS,NULL); int jj=0; for(int i=0;i 线程清理 子线程退出时可能需要执行善后工作，如释放资源和锁，回滚事务等 善后代码写在清理函数中，不写在主线程 清理函数定义：void pthread_cleanup_push(void (*routine)(void *), void *arg); 在下面示例中清理函数中关闭socket,将socket传给arg,将该socket进行关闭 void pthread_cleanup_pop(int execute); 当execute=0时，清理函数不被执行， execute=1清理函数被执行 当执行线程取消函数，会弹出清理函数，并且执行它 当执行pthread_exit（0）,也会弹出清理函数，并且执行它 #include #include #include void* handler1(void* arg); int var=0; void cleanfun1(void*); void cleanfun2(void*); void cleanfun3(void*); int main() { pthread_t pthid1; if(pthread_create(&pthid1,NULL,handler1,NULL)!=0) { printf(\"创建线程pthid1失败\\n\"); return -1; } printf(\"等待子线程退出\\n\"); //pthread_join会使主进程阻塞在这里，用于调试 sleep(2); pthread_cancel(pthid1); int ret; int result=pthread_join(pthid1,(void** )&ret); printf(\"子线程已退出(result=%d,ret=%d)\\n\",result,ret); return 0; } void* handler1(void* arg) { // 注册线程清理函数 int socketid=10; pthread_cleanup_push(cleanfun1,(void*)(long)socketid); pthread_cleanup_push(cleanfun2,NULL); pthread_cleanup_push(cleanfun3,NULL); for(int i=0;i 线程与信号 外部使用killl命令产生的信号，通常是SIGINT等控制信号，则会遍历所有线程，直到找到一个不阻塞的线程，然后调用处理（一般从主线程找起） 信号并不会中断线程，主进程，线程继续处理当信号到来时 多个线程程序中，在某一个线程中调用signal会改变所有线程中的信号处理函数 主进程向子线程发送信号用pthread_kill函数，当信号处理函数和和其他线程执行完，才会继续执行中断的线程 不存在对不同的线程设置不同处理函数的说法，正确的做法：设置一个公共的信号处理函数，并利用pthread_kill(pthread,2)对不同的信号进行中断，如果设置没有设置信号处理函数，则整个函数退出。 void* handler1(void* arg); void* handler2(void* arg); int var=0; void hanfunc(int arg); { // signal(2,hanfunc); signal(2,hanfunc); pthread_t pthid1,pthid2; if(pthread_create(&pthid1,NULL,handler1,NULL)!=0) { printf(\"创建线程pthid1失败\\n\"); return -1; } if(pthread_create(&pthid2,NULL,handler2,NULL)!=0) { printf(\"创建线程pthid2失败\\n\"); return -1; } sleep(1),pthread_kill(pthid2,2); printf(\"等待子线程退出\\n\"); //pthread_join会使主进程阻塞在这里，用于调试 int ret,ists; ret=pthread_join(pthid1,NULL); ret=pthread_join(pthid2,NULL); printf(\"子线程1已退出\\n\"); return 0; } void* handler1(void* arg) { for(int i=0;i 线程属性 int pthread_attr_init(pthread_attr_t *attr); 初始化线程属性变量 int pthread_attr_destroy(pthread_attr_t *attr); 释放线程属性的资源 int pthread_attr_getdetachstate(const pthread_attr_t *attr, int *detachstate); 获取线程分离的状态属性 int pthread_attr_setdetachstate(pthread_attr_t *attr, int detachstate); 设置线程分离的状态属性 #include #include #include #include void * callback(void * arg) { printf(\"chid thread id : %ld\\n\", pthread_self()); return NULL; } int main() { // 创建一个线程属性变量 pthread_attr_t attr; // 初始化属性变量 pthread_attr_init(&attr); // 设置属性 pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED); // 创建一个子线程 pthread_t tid; int ret = pthread_create(&tid, &attr, callback, NULL); if(ret != 0) { char * errstr = strerror(ret); printf(\"error1 : %s\\n\", errstr); } // 获取线程的栈的大小 size_t size; pthread_attr_getstacksize(&attr, &size); printf(\"thread stack size : %ld\\n\", size); // 输出主线程和子线程的id printf(\"tid : %ld, main thread id : %ld\\n\", tid, pthread_self()); // 释放线程属性资源 pthread_attr_destroy(&attr); pthread_exit(NULL); return 0; } "},"C++/多线程/02-线程同步.html":{"url":"C++/多线程/02-线程同步.html","title":"线程同步","keywords":"","body":"datetime:2023/03/10 14:09 author:nzb 线程同步 线程的主要优势在于，能够通过全局变量来共享信息。不过，这种便捷的共享是有代价 的：必须确保多个线程不会同时修改同一变量，或者某一线程不会读取正在由其他线程 修改的变量。 临界区是指访问某一共享资源的代码片段，并且这段代码的执行应为原子操作，也就是 同时访问同一共享资源的其他线程不应中断该片段的执行。 线程同步：即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进 行操作，直到该线程完成操作，其他线程才能对该内存地址进行操作，而其他线程则处 于等待状态。 线程同步方法 互斥锁 读写锁 条件变量 信号量 /* 使用多线程实现买票的案例。 有3个窗口，一共是100张票。 */ #include #include #include // 全局变量，所有的线程都共享这一份资源。 int tickets = 100; void * sellticket(void * arg) { // 卖票 while(tickets > 0) { usleep(6000); printf(\"%ld 正在卖第 %d 张门票\\n\", pthread_self(), tickets); tickets--; } return NULL; } int main() { // 创建3个子线程 pthread_t tid1, tid2, tid3; pthread_create(&tid1, NULL, sellticket, NULL); pthread_create(&tid2, NULL, sellticket, NULL); pthread_create(&tid3, NULL, sellticket, NULL); // 回收子线程的资源,阻塞 pthread_join(tid1, NULL); pthread_join(tid2, NULL); pthread_join(tid3, NULL); // 设置线程分离。 // pthread_detach(tid1); // pthread_detach(tid2); // pthread_detach(tid3); pthread_exit(NULL); // 退出主线程 return 0; } 注意：分离后join，会报错。 usleep(3000)：3000微秒。 互斥锁 为避免线程更新共享变量时出现问题，可以使用互斥量(mutex是mutual exclusion 的缩写)来确保同时仅有一个线程可以访问某项共享资源。可以使用互斥量来保证对任意共 享资源的原子访问。 互斥量有两种状态：已锁定(locked)和未锁定(unlocked) 0任何时候，至多只有一 个线程可以锁定该互斥量。试图对已经锁定的某一互斥量再次加锁，将可能阻塞线程或者报 错失败，具体取决于加锁时使用的方法。 一旦线程锁定互斥量，随即成为该互斥量的所有者.只有所有者才能给互斥量解锁。一般情 况下，对每一共享资源(可能由多个相关变量组成)会使用不同的互斥量，每一线程在访问 同一资源时将采用如下协议： 针对共享资源锁定互斥量 访问共享资源 对互斥量解锁 如果多个线程试图执行这一块代码（一个临界区），事实上只有一个线程能够持有该互斥 量（其他线程将遭到阻塞），即同时只有一个线程能够进入这段代码区域。 相关函数 互斥量的类型 pthread_mutex_t int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutex_attr_t *restrict attr); 初始化互斥量 参数 ： mutex：需要初始化的互斥量变量 attr：互斥量相关的属性，NULL restrict：C语言的修饰符，被修饰的指针，不能由另外的一个指针进行操作。 pthread_mutex_t *restrict mutex = xxx; pthread_mutex_t * mutex1 = mutex; int pthread_mutex_destroy(pthread_mutex_t *mutex); 释放互斥量的资源 int pthread_mutex_lock(pthread_mutex_t *mutex); 加锁，阻塞的，如果有一个线程加锁了，那么其他的线程只能阻塞等待 int pthread_mutex_trylock(pthread_mutex_t *mutex); 尝试加锁，如果加锁失败，不会阻塞，会直接返回。 int pthread_mutex_unlock(pthread_mutex_t *mutex); 解锁 #include #include #include // 全局变量，所有的线程都共享这一份资源。 int tickets = 1000; // 创建一个互斥量 pthread_mutex_t mutex; void * sellticket(void * arg) { // 卖票 while(1) { // 加锁 pthread_mutex_lock(&mutex); if(tickets > 0) { usleep(6000); printf(\"%ld 正在卖第 %d 张门票\\n\", pthread_self(), tickets); tickets--; }else { // 解锁 pthread_mutex_unlock(&mutex); break; } // 解锁 pthread_mutex_unlock(&mutex); } return NULL; } int main() { // 初始化互斥量 pthread_mutex_init(&mutex, NULL); // 创建3个子线程 pthread_t tid1, tid2, tid3; pthread_create(&tid1, NULL, sellticket, NULL); pthread_create(&tid2, NULL, sellticket, NULL); pthread_create(&tid3, NULL, sellticket, NULL); // 回收子线程的资源,阻塞 pthread_join(tid1, NULL); pthread_join(tid2, NULL); pthread_join(tid3, NULL); pthread_exit(NULL); // 退出主线程 // 释放互斥量资源 pthread_mutex_destroy(&mutex); return 0; } 死锁 有时，一个线程需要同时访问两个或更多不同的共享资源，而每个资源又都由不同的互 斥量管理。当超过一个线程加锁同一组互斥量时，就有可能发生死锁。 两个或两个以上的进程在执行过程中，因争夺共享资源而造成的一种互相等待的现象, 若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。 死锁的几种场景 忘记释放锁 重复加锁 多线程多锁，抢占锁资源 deadlock.c #include #include #include // 全局变量，所有的线程都共享这一份资源。 int tickets = 1000; // 创建一个互斥量 pthread_mutex_t mutex; void * sellticket(void * arg) { // 卖票 while(1) { // 加锁 pthread_mutex_lock(&mutex); pthread_mutex_lock(&mutex); if(tickets > 0) { usleep(6000); printf(\"%ld 正在卖第 %d 张门票\\n\", pthread_self(), tickets); tickets--; }else { // 解锁 pthread_mutex_unlock(&mutex); break; } // 解锁 pthread_mutex_unlock(&mutex); pthread_mutex_unlock(&mutex); } return NULL; } int main() { // 初始化互斥量 pthread_mutex_init(&mutex, NULL); // 创建3个子线程 pthread_t tid1, tid2, tid3; pthread_create(&tid1, NULL, sellticket, NULL); pthread_create(&tid2, NULL, sellticket, NULL); pthread_create(&tid3, NULL, sellticket, NULL); // 回收子线程的资源,阻塞 pthread_join(tid1, NULL); pthread_join(tid2, NULL); pthread_join(tid3, NULL); pthread_exit(NULL); // 退出主线程 // 释放互斥量资源 pthread_mutex_destroy(&mutex); return 0; } deadlock1.c(多线程多锁造成的死锁场景) #include #include #include // 创建2个互斥量 pthread_mutex_t mutex1, mutex2; void * workA(void * arg) { pthread_mutex_lock(&mutex1); sleep(1); pthread_mutex_lock(&mutex2); printf(\"workA....\\n\"); pthread_mutex_unlock(&mutex2); pthread_mutex_unlock(&mutex1); return NULL; } void * workB(void * arg) { pthread_mutex_lock(&mutex2); sleep(1); pthread_mutex_lock(&mutex1); printf(\"workB....\\n\"); pthread_mutex_unlock(&mutex1); pthread_mutex_unlock(&mutex2); return NULL; } int main() { // 初始化互斥量 pthread_mutex_init(&mutex1, NULL); pthread_mutex_init(&mutex2, NULL); // 创建2个子线程 pthread_t tid1, tid2; pthread_create(&tid1, NULL, workA, NULL); pthread_create(&tid2, NULL, workB, NULL); // 回收子线程资源 pthread_join(tid1, NULL); pthread_join(tid2, NULL); // 释放互斥量资源 pthread_mutex_destroy(&mutex1); pthread_mutex_destroy(&mutex2); return 0; } 读写锁 当有一个线程已经持有互斥锁时，互斥锁将所有试图进入临界区的线程都阻塞住。但是考 虑一种情形，当前持有互斥锁的线程只是要读访问共享资源，而同时有其它几个线程也想 读取这个共享资源，但是由于互斥锁的排它性，所有其它线程都无法获取锁，也就无法读 访问共享资源了，但是实际上多个线程同时读访问共享资源并不会导致问题。 在对数据的读写操作中，更多的是读操作，写操作较少，例如对数据库数据的读写应用。 为了满足当前能够允许多个读出，但只允许一个写入的需求，线程提供了读写锁来实现。 读写锁的特点 如果有其它线程读数据，则允许其它线程执行读操作，但不允许写操作。 如果有其它线程写数据，则其它线程都不允许读、写操作。 写是独占的，写的优先级高。 相关函数 读写锁的类型 pthread_rwlock_t int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr); int pthread_rwlock_destroy(pthread_rwlock_t *rwlock); int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock); int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock); int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock); int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock); int pthread_rwlock_unlock(pthread_rwlock_t *rwlock); /* 案例：8个线程操作同一个全局变量。 3个线程不定时写这个全局变量，5个线程不定时的读这个全局变量 */ #include #include #include // 创建一个共享数据 int num = 1; // pthread_mutex_t mutex; pthread_rwlock_t rwlock; void * writeNum(void * arg) { while(1) { pthread_rwlock_wrlock(&rwlock); num++; printf(\"++write, tid : %ld, num : %d\\n\", pthread_self(), num); pthread_rwlock_unlock(&rwlock); usleep(100); } return NULL; } void * readNum(void * arg) { while(1) { pthread_rwlock_rdlock(&rwlock); printf(\"===read, tid : %ld, num : %d\\n\", pthread_self(), num); pthread_rwlock_unlock(&rwlock); usleep(100); } return NULL; } int main() { pthread_rwlock_init(&rwlock, NULL); // 创建3个写线程，5个读线程 pthread_t wtids[3], rtids[5]; for(int i = 0; i 生产者和消费者模型 该模型采用链表结构实现。 /* 生产者消费者模型（粗略的版本） */ #include #include #include #include // 创建一个互斥量 pthread_mutex_t mutex; struct Node{ int num; struct Node *next; }; // 头结点 struct Node * head = NULL; void * producer(void * arg) { // 不断的创建新的节点，添加到链表中 while(1) { pthread_mutex_lock(&mutex); struct Node * newNode = (struct Node *)malloc(sizeof(struct Node)); newNode->next = head; head = newNode; newNode->num = rand() % 1000; printf(\"add node, num : %d, tid : %ld\\n\", newNode->num, pthread_self()); pthread_mutex_unlock(&mutex); usleep(100); } return NULL; } void * customer(void * arg) { while(1) { pthread_mutex_lock(&mutex); // 保存头结点的指针 struct Node * tmp = head; // 判断是否有数据 if(head != NULL) { // 有数据 head = head->next; printf(\"del node, num : %d, tid : %ld\\n\", tmp->num, pthread_self()); free(tmp); pthread_mutex_unlock(&mutex); usleep(100); } else { // 没有数据 pthread_mutex_unlock(&mutex); } } return NULL; } int main() { pthread_mutex_init(&mutex, NULL); // 创建5个生产者线程，和5个消费者线程 pthread_t ptids[5], ctids[5]; for(int i = 0; i 条件变量 条件变量的类型 pthread_cond_t int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr); int pthread_cond_destroy(pthread_cond_t *cond); int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex); 等待，调用了该函数，线程会阻塞，内部流程如下 释放了互斥锁 等待条件 条件被触发 给互斥锁加锁 其中：条件被触发和给互斥锁加锁是原子操作 int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex, const struct timespec *restrict abstime); 等待多长时间，调用了这个函数，线程会阻塞，直到指定的时间结束。 int pthread_cond_signal(pthread_cond_t *cond); 唤醒一个或者多个等待的线程 int pthread_cond_broadcast(pthread_cond_t *cond); 唤醒所有的等待的线程 注意：解决线程同步的方法有互斥锁和读写锁，条件变量不是锁，条件变量不用来解决线程同步的问题。 #include #include #include #include // 创建一个互斥量 pthread_mutex_t mutex; // 创建条件变量 pthread_cond_t cond; struct Node{ int num; struct Node *next; }; // 头结点 struct Node * head = NULL; void * producer(void * arg) { // 不断的创建新的节点，添加到链表中 while(1) { pthread_mutex_lock(&mutex); struct Node * newNode = (struct Node *)malloc(sizeof(struct Node)); newNode->next = head; head = newNode; newNode->num = rand() % 1000; printf(\"add node, num : %d, tid : %ld\\n\", newNode->num, pthread_self()); // 只要生产了一个，就通知消费者消费 pthread_cond_signal(&cond); pthread_mutex_unlock(&mutex); usleep(100); } return NULL; } void * customer(void * arg) { while(1) { pthread_mutex_lock(&mutex); // 保存头结点的指针 struct Node * tmp = head; // 判断是否有数据 if(head != NULL) { // 有数据 head = head->next; printf(\"del node, num : %d, tid : %ld\\n\", tmp->num, pthread_self()); free(tmp); pthread_mutex_unlock(&mutex); usleep(100); } else { // 没有数据，需要等待 // 当这个函数调用阻塞的时候，会对互斥锁进行解锁，当不阻塞的，继续向下执行，会重新加锁。 pthread_cond_wait(&cond, &mutex); pthread_mutex_unlock(&mutex); } } return NULL; } int main() { pthread_mutex_init(&mutex, NULL); pthread_cond_init(&cond, NULL); // 创建5个生产者线程，和5个消费者线程 pthread_t ptids[5], ctids[5]; for(int i = 0; i 信号量（信号灯） 信号量的类型 sem_t int sem_init(sem_t *sem, int pshared, unsigned int value); 初始化信号量 参数： sem : 信号量变量的地址 pshared : 0 用在线程间 ，非0 用在进程间 value : 信号量中的值 int sem_destroy(sem_t *sem); 释放资源 int sem_wait(sem_t *sem); 对信号量加锁，调用一次对信号量的值-1，如果值为0，就阻塞 int sem_trywait(sem_t *sem); int sem_timedwait(sem_t *sem, const struct timespec *abs_timeout); int sem_post(sem_t *sem); 对信号量解锁，调用一次对信号量的值+1 int sem_getvalue(sem_t *sem, int *sval); 注意：单独使用信号量不能让线程安全，需要配合使用互斥锁才能保证线程的安全。 /* sem_t psem; sem_t csem; init(psem, 0, 8); init(csem, 0, 0); producer() { sem_wait(&psem); sem_post(&csem) } customer() { sem_wait(&csem); sem_post(&psem) } */ #include #include #include #include #include // 创建一个互斥量 pthread_mutex_t mutex; // 创建两个信号量 sem_t psem; sem_t csem; struct Node{ int num; struct Node *next; }; // 头结点 struct Node * head = NULL; void * producer(void * arg) { // 不断的创建新的节点，添加到链表中 while(1) { sem_wait(&psem); pthread_mutex_lock(&mutex); struct Node * newNode = (struct Node *)malloc(sizeof(struct Node)); newNode->next = head; head = newNode; newNode->num = rand() % 1000; printf(\"add node, num : %d, tid : %ld\\n\", newNode->num, pthread_self()); pthread_mutex_unlock(&mutex); sem_post(&csem); } return NULL; } void * customer(void * arg) { while(1) { sem_wait(&csem); pthread_mutex_lock(&mutex); // 保存头结点的指针 struct Node * tmp = head; head = head->next; printf(\"del node, num : %d, tid : %ld\\n\", tmp->num, pthread_self()); free(tmp); pthread_mutex_unlock(&mutex); sem_post(&psem); } return NULL; } int main() { pthread_mutex_init(&mutex, NULL); sem_init(&psem, 0, 8); sem_init(&csem, 0, 0); // 创建5个生产者线程，和5个消费者线程 pthread_t ptids[5], ctids[5]; for(int i = 0; i "},"C++/多线程/03-多线程并发的网络服务.html":{"url":"C++/多线程/03-多线程并发的网络服务.html","title":"多线程并发的网络服务","keywords":"","body":"datetime:2023/03/21 15:52 author:nzb 多线程并发的网络服务端框架 服务端 #include \"../_freecplus.h\" void *pthmain(void *arg); CTcpServer TcpServer; // 创建服务端对象。 vector vpthid; // 存放线程id的容器。 void mainexit(int sig); // 信号2和15的处理函数。 // 线程清理函数。 void pthmainexit(void *arg); CLogFile logfile; int main(int argc, char *argv[]) { signal(2, mainexit); signal(15, mainexit); // 捕获信号2和15 logfile.Open(\"/tmp/demo48.log\", \"a+\"); if (TcpServer.InitServer(5858) == false) // 初始化TcpServer的通信端口。 { logfile.Write(\"TcpServer.InitServer(5858) failed.\\n\"); return -1; } while (true) { if (TcpServer.Accept() == false) // 等待客户端连接。 { logfile.Write(\"TcpServer.Accept() failed.\\n\"); return -1; } logfile.Write(\"客户端(%s)已连接。\\n\", TcpServer.GetIP()); pthread_t pthid; if (pthread_create(&pthid, NULL, pthmain, (void *) (long) TcpServer.m_connfd) != 0) { logfile.Write(\"pthread_create failed.\\n\"); return -1; } vpthid.push_back(pthid); // 把线程id保存到vpthid容器中。 } return 0; } void *pthmain(void *arg) { pthread_cleanup_push(pthmainexit, arg); // 设置线程清理函数。 pthread_detach(pthread_self()); // 分离线程。 pthread_setcanceltype(PTHREAD_CANCEL_DISABLE, NULL); // 设置取消方式为立即取消。 int sockfd = (int) (long) arg; // 与客户端的socket连接。 int ibuflen = 0; char strbuffer[1024]; // 存放数据的缓冲区。 while (true) { memset(strbuffer, 0, sizeof(strbuffer)); if (TcpRead(sockfd, strbuffer, &ibuflen, 300) == false) break; // 接收客户端发过来的请求报文。 logfile.Write(\"接收：%s\\n\", strbuffer); strcat(strbuffer, \"ok\"); // 在客户端的报文后加上\"ok\"。 logfile.Write(\"发送：%s\\n\", strbuffer); if (TcpWrite(sockfd, strbuffer) == false) break; // 向客户端回应报文。 } logfile.Write(\"客户端已断开。\\n\"); // 程序直接退出，析构函数会释放资源。 pthread_cleanup_pop(1); pthread_exit(0); } // 信号2和15的处理函数。 void mainexit(int sig) { logfile.Write(\"mainexit begin.\\n\"); // 关闭监听的socket。 TcpServer.CloseListen(); // 取消全部的线程。 for (int ii = 0; ii 客户端 #include \"../_freecplus.h\" int main(int argc, char *argv[]) { printf(\"pid=%d\\n\", getpid()); CTcpClient TcpClient; // 创建客户端的对象。 if (TcpClient.ConnectToServer(\"172.21.0.3\", 5858) == false) // 向服务端发起连接请求。 { printf(\"TcpClient.ConnectToServer(\\\"172.21.0.3\\\",5858) failed.\\n\"); return -1; } char strbuffer[1024]; // 存放数据的缓冲区。 for (int ii = 0; ii "},"C++/多线程/04-线程同步案例.html":{"url":"C++/多线程/04-线程同步案例.html","title":"线程同步案例","keywords":"","body":"datetime:2023/03/22 17:06 author:nzb 线程同步案例 互斥锁实现数据库连接池 服务端 /* * 编译指令：g++ -g -Wno-write-strings -o serverdb serverdb.cpp -I/oracle/home/rdbms/public -L/oracle/home/lib -L. -lclntsh /freecplus/db/oracle/_ooci.cpp /freecplus/_freecplus.cpp -lpthread -lm -lc */ #include \"/freecplus/_freecplus.h\" #include \"/freecplus/db/oracle/_ooci.h\" pthread_mutex_t mutexs[100]; // 用于数据库连接池的锁。 connection conns[100]; // 数据库连接池。 bool initconns(); // 初始化数据库连接池。 connection *getconn(); // 从连接池中获取一个数据库连接。 void freeconn(connection *in_conn); // 释放数据库连接。 void freeconns(); // 释放数据库连接池。 void *pthmain(void *arg); CTcpServer TcpServer; // 创建服务端对象。 vector vpthid; // 存放线程id的容器。 void mainexit(int sig); // 信号2和15的处理函数。 // 线程清理函数。 void pthmainexit(void *arg); CLogFile logfile; int main(int argc, char *argv[]) { signal(2, mainexit); signal(15, mainexit); // 捕获信号2和15 logfile.Open(\"/tmp/serverdb.log\", \"a+\"); if (TcpServer.InitServer(5858) == false) // 初始化TcpServer的通信端口。 { logfile.Write(\"TcpServer.InitServer(5858) failed.\\n\"); return -1; } if (initconns() == false) // 初始化数据库连接池。 { logfile.Write(\"initconns() failed.\\n\"); return -1; } while (true) { if (TcpServer.Accept() == false) // 等待客户端连接。 { logfile.Write(\"TcpServer.Accept() failed.\\n\"); return -1; } logfile.Write(\"客户端(%s)已连接。\\n\", TcpServer.GetIP()); pthread_t pthid; if (pthread_create(&pthid, NULL, pthmain, (void *) (long) TcpServer.m_connfd) != 0) { logfile.Write(\"pthread_create failed.\\n\"); return -1; } vpthid.push_back(pthid); // 把线程id保存到vpthid容器中。 } return 0; } void *pthmain(void *arg) { pthread_cleanup_push(pthmainexit, arg); // 设置线程清理函数。 pthread_detach(pthread_self()); // 分离线程。 pthread_setcanceltype(PTHREAD_CANCEL_DISABLE, NULL); // 设置取消方式为立即取消。 int sockfd = (int) (long) arg; // 与客户端的socket连接。 int ibuflen = 0; char strbuffer[1024]; // 存放数据的缓冲区。 while (true) { memset(strbuffer, 0, sizeof(strbuffer)); if (TcpRead(sockfd, strbuffer, &ibuflen, 300) == false) break; // 接收客户端发过来的请求报文。 logfile.Write(\"接收：%s\\n\", strbuffer); connection *conn = getconn(); // 获取一个数据库连接。 // 处理业务 sleep(2); freeconn(conn); // 释放一个数据库连接。 strcat(strbuffer, \"ok\"); // 在客户端的报文后加上\"ok\"。 logfile.Write(\"发送：%s\\n\", strbuffer); if (TcpWrite(sockfd, strbuffer) == false) break; // 向客户端回应报文。 } logfile.Write(\"客户端已断开。\\n\"); // 程序直接退出，析构函数会释放资源。 pthread_cleanup_pop(1); pthread_exit(0); } // 信号2和15的处理函数。 void mainexit(int sig) { logfile.Write(\"mainexit begin.\\n\"); // 关闭监听的socket。 TcpServer.CloseListen(); // 取消全部的线程。 for (int ii = 0; ii 客户端 #include \"../_freecplus.h\" int main(int argc, char *argv[]) { printf(\"pid=%d\\n\", getpid()); CTcpClient TcpClient; // 创建客户端的对象。 if (TcpClient.ConnectToServer(\"172.21.0.3\", 5858) == false) // 向服务端发起连接请求。 { printf(\"TcpClient.ConnectToServer(\\\"172.21.0.3\\\",5858) failed.\\n\"); return -1; } char strbuffer[1024]; // 存放数据的缓冲区。 for (int ii = 0; ii 用互斥锁和条件变量实现高速缓存 #include #include #include #include #include #include #include using namespace std; int mesgid = 1; // 消息的记数器。 // 缓存消息的结构体。 struct st_message { int mesgid; char message[1024]; } stmesg; vector vcache; // 用vector容器做缓存。 pthread_cond_t cond = PTHREAD_COND_INITIALIZER; // 声名并初始化条件变量。 pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; // 声名并初始化互斥锁。 // 消费者、出队线程主函数。 void *outcache(void *arg) { struct st_message stmesg; while (true) { pthread_mutex_lock(&mutex); // 加锁。 // 如果缓存为空，等待。 // 条件变量虚假唤醒。 while (vcache.size() == 0) { pthread_cond_wait(&cond, &mutex); } // 从缓存中获取第一条记录，然后删除该记录。 memcpy(&stmesg, &vcache[0], sizeof(struct st_message)); // 内存拷贝，再加速，使用链表 vcache.erase(vcache.begin()); pthread_mutex_unlock(&mutex); // 解锁。 // 以下是处理业务的代码。 printf(\"phid=%ld,mesgid=%d\\n\", pthread_self(), stmesg.mesgid); usleep(100); } } // 生产者、把生产的数据存入缓存。 void incache(int sig) { struct st_message stmesg; memset(&stmesg, 0, sizeof(struct st_message)); pthread_mutex_lock(&mutex); // 加锁。 // 生产数据，放入缓存。 stmesg.mesgid = mesgid++; vcache.push_back(stmesg); // 内存拷贝，再加速，使用链表 stmesg.mesgid = mesgid++; vcache.push_back(stmesg); stmesg.mesgid = mesgid++; vcache.push_back(stmesg); stmesg.mesgid = mesgid++; vcache.push_back(stmesg); stmesg.mesgid = mesgid++; vcache.push_back(stmesg); pthread_mutex_unlock(&mutex); // 解锁。 pthread_cond_broadcast(&cond); // 触发条件，激活全部的线程。 } int main() { signal(15, incache); // 接收15的信号，调用生产者函数。 pthread_t thid1, thid2, thid3; pthread_create(&thid1, NULL, outcache, NULL); pthread_create(&thid2, NULL, outcache, NULL); pthread_create(&thid3, NULL, outcache, NULL); pthread_join(thid1, NULL); pthread_join(thid2, NULL); pthread_join(thid3, NULL); return 0; } 用互斥锁和信号量实现高速缓存 #include #include #include #include #include #include #include #include using namespace std; int mesgid = 1; // 消息的记数器。 // 缓存消息的结构体。 struct st_message { int mesgid; char message[1024]; } stmesg; vector vcache; // 用vector容器做缓存。 sem_t sem; // 声明信号量。 pthread_mutex_t mutex; // 声名并初始化互斥锁。 // 消费者、出队线程主函数。 void *outcache(void *arg) { struct st_message stmesg; while (true) { while (vcache.size() == 0) { sem_wait(&sem); // 如果缓存中没有数据，等待信号。 printf(\"%ld wait ok.\\n\", pthread_self()); } pthread_mutex_lock(&mutex); // 加锁。 if (vcache.size() == 0) // 判断缓存中是否有数据。 { pthread_mutex_unlock(&mutex); continue; // 解锁，continue。 } // 从缓存中获取第一条记录，然后删除该记录。 memcpy(&stmesg, &vcache[0], sizeof(struct st_message)); vcache.erase(vcache.begin()); pthread_mutex_unlock(&mutex); // 解锁。 // 以下是处理业务的代码。 printf(\"phid=%ld,mesgid=%d\\n\", pthread_self(), stmesg.mesgid); usleep(100); } } // 生产者、把生产的数据存入缓存。 void incache(int sig) { struct st_message stmesg; memset(&stmesg, 0, sizeof(struct st_message)); pthread_mutex_lock(&mutex); // 加锁。 // 生产数据，放入缓存。 stmesg.mesgid = mesgid++; vcache.push_back(stmesg); stmesg.mesgid = mesgid++; vcache.push_back(stmesg); stmesg.mesgid = mesgid++; vcache.push_back(stmesg); stmesg.mesgid = mesgid++; vcache.push_back(stmesg); stmesg.mesgid = mesgid++; vcache.push_back(stmesg); stmesg.mesgid = mesgid++; vcache.push_back(stmesg); pthread_mutex_unlock(&mutex); // 解锁。 sem_post(&sem); // 信号加1。 sem_post(&sem); // 信号加1。 sem_post(&sem); // 信号加1。 sem_post(&sem); // 信号加1。 sem_post(&sem); // 信号加1。 sem_post(&sem); // 信号加1。 } int main() { signal(15, incache); // 接收15的信号，调用生产者函数。 sem_init(&sem, 0, 0); // 初始化信号量。 pthread_mutex_init(&mutex, NULL); // 初始化互斥锁。 pthread_t thid1, thid2, thid3; pthread_create(&thid1, NULL, outcache, NULL); pthread_create(&thid2, NULL, outcache, NULL); pthread_create(&thid3, NULL, outcache, NULL); pthread_join(thid1, NULL); pthread_join(thid2, NULL); pthread_join(thid3, NULL); return 0; } "},"BehaviorTree/入门/01-初始行为树.html":{"url":"BehaviorTree/入门/01-初始行为树.html","title":"初始行为树","keywords":"","body":"datetime:2023/05/11 15:12 author:nzb BT1：初识行为树 行为树是什么？ 行为树（BT，Behavior Tree）是一种 tree-structured control architecture，常用来做任务或状态管理。最先也最多应用于游戏领域，后来引入到机器人、自动驾驶等需要规划决策的领域。 行为树与有限状态机（FSM，Finite State Machine）、决策树（Decision Tree）等常被对比，他们在绝大多数情况下可以发挥同样的作用，并且可以相互转换。下面我罗列了一些显著的对比，在应用中会更有体会。后面的内容也会展开介绍BT的这些特性。 行为树怎么用？ 像上面提到的一样，FSM简单易用，绝大多数情况开发者都可以逐行逐字的手撕代码，从头实现一个个性化的状态机，只需定义清楚状态类别、跳转条件、每个状态的执行内容等，典型的就是switch-case。当然，也有很多开源库，可以提供更完善的代码实现，比如TinyFSM等。 对比之下，如果要自行实现行为树的话，工作量就要大一些。有很多优秀的开源实现，这里推荐BehaviorTree.CPP 基于C++14，支持ROS，也是ROS2-Navigation使用的库。本系列文章就以BehaviorTree.CPP为例，讲解行为树的概念和应用。 必读资料 A Survey of Behavior Trees in Robotics and AI Behavior trees for AI: How they work Behavior Trees in Robotics and AI: An Introduction The Behavior Tree Starter Kit "},"BehaviorTree/入门/02-行为树的基本知识点.html":{"url":"BehaviorTree/入门/02-行为树的基本知识点.html","title":"行为树的基本知识点","keywords":"","body":"datetime:2023/05/11 15:12 author:nzb BT2：行为树的基本知识点 xml文件 行为树按照xml文件格式来设计、书写和保存，如BehaviorTree.CPP/examples/t03_generic_ports.cpp中这样定义了一棵行为树： 图形化后如下图，表示依次执行4个action node。 而定义行为树的xml文件使用createTreeFromText()或createTreeFromFile()加载进来。函数定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/bt_factory.h，声明如下。这时会调用树中各nodes的构造函数。 Tree createTreeFromText(const std::string& text, Blackboard::Ptr blackboard = Blackboard::create()); Tree createTreeFromFile(const std::string& file_path, Blackboard::Ptr blackboard = Blackboard::create()); 使用方法如下： BehaviorTreeFactory factory; auto tree = factory.createTreeFromText(xml_text); tree.tickRoot(); tick() 类似于数据结构中“tree”的概念，行为树是控制任务执行流程的分层节点树。一个称为“ tick ”的信号，由开发者发送到树的根部并在树的节点中传播， 直到它到达树的底部——叶节点。接收到tick信号的节点会执行它的回调，即被设定的该节点的任务，然后向上返回执行的结果。在大多数开源库中， 该结果有且只有3种：成功完成SUCCESS，执行失败FAILURE，正在执行RUNNING。 节点种类 行为树主要有4种节点，其中的ControlNode和DecoratorNode常由库实现，而ConditionNode和ActionNode需开发者自行实现，即定义何种情况执行何种行为。 ControlNode：控制节点，有至少1个子节点，负责控制执行流程；可以细分成非常多的种类。 DecoratorNode：装饰节点，有且仅有1个子节点，负责重复执行子节点，或更改子节点的返回结果。 ConditionNode：条件节点，没有子节点，需要由开发者实现，不可以返回RUNNING，必须atomic and synchronous，负责任务执行的判断条件，不应该改变系统的状态。 ActionNode：动作节点，没有子节点，需要由开发者实现，负责执行具体任务。有同步和异步之分。 "},"BehaviorTree/入门/03-库中基本类型Tree和TreeNode.html":{"url":"BehaviorTree/入门/03-库中基本类型Tree和TreeNode.html","title":"基本类型Tree和TreeNode","keywords":"","body":"datetime:2023/05/11 15:12 author:nzb BT3：库中基本类型Tree和TreeNode 本文重点讲述BehaviorTree.CPP中的几个重要的基本的类定义，尤其是类所包含的数据。 Tree 定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/bt_factory.h。有3个重要的public成员变量。 public: // 保存树的所有node std::vector nodes; // 保存所有blackboard std::vector blackboard_stack; // 保存所有node注册信息 std::unordered_map manifests; 以BehaviorTree.CPP/examples/t06_subtree_port_remapping.cpp中的行为树为例，打印出以上3个容器的元素数量。 共有10个节点，2个blackboard（因为有2棵树），31个注册节点信息（可以理解为该tree认识31个节点，却只创建和包含了10个节点） 。 tree nodes count = 10 tree blackboard_stack count = 2 tree manifests count = 31 将节点的名称和注册节点信息的名称打印如下，可见一棵子树也会作为一个节点对待。而31个manifests中，就包含了BehaviorTree.CPP库提供的所有ControlNodes和DecoratorNodes， 以及示例用的SaySomething和MoveBase。 tree root node = main_sequence nodes[1] = main_sequence nodes[2] = SetBlackboard nodes[3] = MoveRobot nodes[4] = move_robot_main nodes[5] = SequenceStar nodes[6] = MoveBase nodes[7] = SetBlackboard nodes[8] = ForceFailure nodes[9] = SetBlackboard nodes[10] = SaySomething manifests[1] = SaySomething manifests[2] = Switch4 manifests[3] = Switch6 manifests[4] = BlackboardCheckDouble manifests[5] = BlackboardCheckInt manifests[6] = SubTree manifests[7] = KeepRunningUntilFailure manifests[8] = Switch5 manifests[9] = ReactiveSequence manifests[10] = Parallel manifests[11] = Delay manifests[12] = SetBlackboard manifests[13] = SequenceStar manifests[14] = Fallback manifests[15] = AlwaysSuccess manifests[16] = ReactiveFallback manifests[17] = Sequence manifests[18] = Switch3 manifests[19] = Switch2 manifests[20] = AlwaysFailure manifests[21] = IfThenElse manifests[22] = WhileDoElse manifests[23] = SubTreePlus manifests[24] = ForceSuccess manifests[25] = Inverter manifests[26] = BlackboardCheckString manifests[27] = RetryUntilSuccesful manifests[28] = ForceFailure manifests[29] = MoveBase manifests[30] = Repeat manifests[31] = Timeout TreeNode 定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/tree_node.h。注意区分name_和registration_ID_的区别。 private: const std::string name_; // 从xml获得的node名称，可没有，可重复 NodeStatus status_; // node的返回结果，即执行状态 std::condition_variable state_condition_variable_; mutable std::mutex state_mutex_; StatusChangeSignal state_change_signal_; // 订阅的信号 const uint16_t uid_; // 唯一ID NodeConfiguration config_; std::string registration_ID_; // 类型名称，一定与class name相同 以BehaviorTree.CPP/examples/t06_subtree_port_remapping.cpp中的行为树为例，打印出所有node的name和注册ID对比。 可见registration_ID_ 和node的class name相同（非强制，下篇讲解），而name可以随意指定，如nodes[4]，当不设置时默认是registration_ID_，如其中的nodes[2]和nodes[5]。 nodes[1].name=main_sequence, reg_id=Sequence nodes[2].name=SetBlackboard, reg_id=SetBlackboard nodes[3].name=MoveRobot, reg_id=SubTree nodes[4].name=move_robot_main, reg_id=Fallback nodes[5].name=SequenceStar, reg_id=SequenceStar nodes[6].name=MoveBase, reg_id=MoveBase nodes[7].name=SetBlackboard, reg_id=SetBlackboard nodes[8].name=ForceFailure, reg_id=ForceFailure nodes[9].name=SetBlackboard, reg_id=SetBlackboard nodes[10].name=SaySomething, reg_id=SaySomething NodeConfiguration中包含了blackboard的指针，和输入输出ports的映射信息。 typedef std::unordered_map PortsRemapping; struct NodeConfiguration { Blackboard::Ptr blackboard; PortsRemapping input_ports; // 输入port的映射关系 PortsRemapping output_ports; // 输出port的映射关系 }; 打印SaySomething的input_ports如下，没有output ports。 input port: message --- {move_result} 打印SetBlackboard的ports如下，该node比较特殊，output_key是个INOUT双向port，以后会单独介绍。 input port: output_key --- move_goal input port: value --- 1;2;3 output port: output_key --- move_goal TreeNode类中提供了2个容易迷惑的接口，1个是虚函数executeTick()，1个是纯虚函数tick()，那么开发者应该实现和调用哪一个呢？ public: /// The method that should be used to invoke tick() and setStatus(); virtual BT::NodeStatus executeTick(); protected: /// Method to be implemented by the user virtual BT::NodeStatus tick() = 0; executeTick()提供了默认实现，即先调用tick()然后设置返回的状态。而各种ControlNodes和DecoratorNodes， 都是在tick()中调用child_node_->executeTick()，所以开发者只需实现子类的tick()就好了。 NodeStatus TreeNode::executeTick() { const NodeStatus status = tick(); setStatus(status); return status; } 行为树执行时会是这样的逻辑： "},"BehaviorTree/入门/04-库中基本类型Factory和Blackboard.html":{"url":"BehaviorTree/入门/04-库中基本类型Factory和Blackboard.html","title":"基本类型Factory和Blackboard","keywords":"","body":"datetime:2023/05/11 15:12 author:nzb BT3：库中基本类型Factory和Blackboard BehaviorTreeFactory 定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/bt_factory.h，主要包含3个容器来保存数据。 /** * @brief The BehaviorTreeFactory is used to create instances of a * TreeNode at run-time. * Some node types are \"builtin\", whilst other are used defined and need * to be registered using a unique ID. */ class BehaviorTreeFactory { private: std::unordered_map builders_; std::unordered_map manifests_; std::set builtin_IDs_; } 以BehaviorTree.CPP/examples/t03_generic_ports.cpp为例，在构造BehaviorTreeFactory实例后立即打印这3个容器的元素的名称， 可以发现输出结果仅顺序不同，说明Factory构造后默认包含了内建的29个nodes。 builders[1]=Switch4 builders[2]=Switch6 builders[3]=BlackboardCheckDouble builders[4]=BlackboardCheckInt builders[5]=SubTree builders[6]=KeepRunningUntilFailure builders[7]=Switch5 builders[8]=ReactiveSequence builders[9]=Parallel builders[10]=Delay builders[11]=SetBlackboard builders[12]=SequenceStar builders[13]=Fallback builders[14]=AlwaysSuccess builders[15]=ReactiveFallback builders[16]=Sequence builders[17]=Switch3 builders[18]=Switch2 builders[19]=AlwaysFailure builders[20]=IfThenElse builders[21]=WhileDoElse builders[22]=SubTreePlus builders[23]=ForceSuccess builders[24]=Inverter builders[25]=BlackboardCheckString builders[26]=RetryUntilSuccesful builders[27]=ForceFailure builders[28]=Repeat builders[29]=Timeout manifests[1]=Switch4 manifests[2]=Switch6 manifests[3]=BlackboardCheckDouble manifests[4]=BlackboardCheckInt manifests[5]=SubTree manifests[6]=KeepRunningUntilFailure manifests[7]=Switch5 manifests[8]=ReactiveSequence manifests[9]=Parallel manifests[10]=Delay manifests[11]=SetBlackboard manifests[12]=SequenceStar manifests[13]=Fallback manifests[14]=AlwaysSuccess manifests[15]=ReactiveFallback manifests[16]=Sequence manifests[17]=Switch3 manifests[18]=Switch2 manifests[19]=AlwaysFailure manifests[20]=IfThenElse manifests[21]=WhileDoElse manifests[22]=SubTreePlus manifests[23]=ForceSuccess manifests[24]=Inverter manifests[25]=BlackboardCheckString manifests[26]=RetryUntilSuccesful manifests[27]=ForceFailure manifests[28]=Repeat manifests[29]=Timeout builtinNodes[1]=AlwaysFailure builtinNodes[2]=AlwaysSuccess builtinNodes[3]=BlackboardCheckDouble builtinNodes[4]=BlackboardCheckInt builtinNodes[5]=BlackboardCheckString builtinNodes[6]=Delay builtinNodes[7]=Fallback builtinNodes[8]=ForceFailure builtinNodes[9]=ForceSuccess builtinNodes[10]=IfThenElse builtinNodes[11]=Inverter builtinNodes[12]=KeepRunningUntilFailure builtinNodes[13]=Parallel builtinNodes[14]=ReactiveFallback builtinNodes[15]=ReactiveSequence builtinNodes[16]=Repeat builtinNodes[17]=RetryUntilSuccesful builtinNodes[18]=Sequence builtinNodes[19]=SequenceStar builtinNodes[20]=SetBlackboard builtinNodes[21]=SubTree builtinNodes[22]=SubTreePlus builtinNodes[23]=Switch2 builtinNodes[24]=Switch3 builtinNodes[25]=Switch4 builtinNodes[26]=Switch5 builtinNodes[27]=Switch6 builtinNodes[28]=Timeout builtinNodes[29]=WhileDoElse 在factory添加了2个node后，再次打印，builders和manifests就多了2个对应的元素。 factory.registerNodeType(\"CalculateGoal\"); factory.registerNodeType(\"PrintTarget\"); registerNodeType()的入参，就表明了实际节点类型T（CalculateGoal）在树中的名称（同样是CalculateGoal）。建议大家实际类型和入参ID相同，可以减少很多迷惑。 /** registerNodeType is the method to use to register your custom TreeNode. * * It accepts only classed derived from either ActionNodeBase, DecoratorNode, * ControlNode or ConditionNode. */ template void registerNodeType(const std::string& ID); 因此，在加载tree之前，开发者必须先将自定义的node注册进入factory，才能正确解析xml。1个factory可以包含多个tree。 auto tree = factory.createTreeFromText(xml_text); NodeBuilder NodeBuilder定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/bt_factory.h，使用了建造者模式，可以理解为模板化的node构造函数， 是偏特化的模板类定义。根据构造函数的参数个数区别，选择不同的builder，返回一个智能指针。 /// The term \"Builder\" refers to the Builder Pattern (https://en.wikipedia.org/wiki/Builder_pattern) typedef std::function(const std::string&, const NodeConfiguration&)> NodeBuilder; // 检查T是否有带参(const std::string&)的默认构造函数 template using has_default_constructor = typename std::is_constructible; // 检查T是否有带参(const std::string&, const NodeConfiguration&)的构造函数 template using has_params_constructor = typename std::is_constructible; // 对应T既有默认构造函数，又有带2个参数构造函数的情况，即上述2条判断都为true。注意make_unique的参数区分 // 定义了1个T类型的指针，默认值是nullptr。这不重要，重要的是enable_if的条件检查 template inline NodeBuilder CreateBuilder(typename std::enable_if::value && has_params_constructor::value>::type* = nullptr) { return [](const std::string& name, const NodeConfiguration& config) { // Special case. Use default constructor if parameters are empty if (config.input_ports.empty() && config.output_ports.empty() && has_default_constructor::value) { return std::make_unique(name); } return std::make_unique(name, config); }; } // 对应T只有带2参构造函数的情况，注意new的参数 template inline NodeBuilder CreateBuilder(typename std::enable_if::value && has_params_constructor::value>::type* = nullptr) { return [](const std::string& name, const NodeConfiguration& params) { return std::unique_ptr(new T(name, params)); }; } // 对应T只有默认构造函数（带1参）的情况，注意new的参数 template inline NodeBuilder CreateBuilder(typename std::enable_if::value && !has_params_constructor::value>::type* = nullptr) { return [](const std::string& name, const NodeConfiguration&) { return std::unique_ptr(new T(name)); }; } 语法参考资料 is_constructible - C++ Reference std::enable_if - cppreference.com std::enable_if 的几种用法 ← Yee C++11新特性--std::enable_if和SFINAE - 简书 Blackboard 定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/blackboard.h，是树中nodes传输数据的方式，所有nodes共享。 每棵树都有自己的blackboard，开发者需要显式的在不同的父树、子树的blackboard间创建映射关联。这个操作无需通过代码实现，只需要在xml中编辑。 同样，nodes执行顺序也是在xml中设定的，这使得调试时可以节省大量的程序编译时间。Blackboard类中存储数据的容器有3个。 private: std::unordered_map storage_; // 保存键值对 // 指向父blackboard的指针，会与本blackboard有重映射关系 std::weak_ptr parent_bb_; // weak_ptr可以避免循环引用 // 保存映射的内外对应关系 std::unordered_map internal_to_external_; Entry就是blackboard保存的1个元素。 struct Entry { Any value; // port存储的值 const PortInfo port_info; // port的其他信息，不含名字和值 } Port Port是节点间交换数据的机制，通过Blackboard的相同key联系起来。节点的ports的数量、名称、类型等，在编译时就已知了，体现在xml文件中。 如果一个节点有输入/输出port，必须在providedPorts()函数中声明。 获取port的值可以用getInput()，设置port的值可以用setOutput()。 typedef std::unordered_map PortsList; static PortsList providedPorts(); template Result getInput(const std::string& key, T& destination) const; template Optional getInput(const std::string& key) const; template Result setOutput(const std::string& key, const T& value); class PortInfo { private: PortDirection _type; const std::type_info* _info; // 将port输入/输出的string自动转换为指定类型的函数 StringConverter _converter; std::string description_; // port的含义描述 std::string default_value_; // port没有设置值时的默认值 } typedef std::function StringConverter; PortDirection分为INPUT、OUTPUT、INOUT 3种。开发者最好不要对输入的port和数据做任何假设，推荐在tick()中周期性的读取输入值，以应对外界变化， 而不是只在构造函数或初始化时只读取一次保存下来。保存历史信息会伤害行为树的reactive特性，使得节点的行为不仅与现在情景有关，还与过去有关。 template inline T convertFromString(StringView /*str*/); 当在xml中通过SetBlackboard设置port后，代码中运行getInput()会后台调用convertFromString()，将读入的string转换为对应的类型。 BehaviorTree.CPP/include/behaviortree_cpp_v3/basic_types.h中实现了StirngView向string, const char*, int, unsigned, long, unsigned long, float, double, vector, bool, NodeStatus, Nodetype, PortDirection等内建类型的转换。如果开发者想转换为自定义类型的话，可以参考basic_types.cpp的代码。 树中的nodes间互相读写port是不会触发convertFromString()的，毕竟这是一个string到type的单向转换。 // 转换为枚举类型 template <> NodeType convertFromString(StringView str) { if (str == \"Action\") return NodeType::ACTION; if (str == \"Condition\") return NodeType::CONDITION; if (str == \"Control\") return NodeType::CONTROL; if (str == \"Decorator\") return NodeType::DECORATOR; if (str == \"SubTree\" || str == \"SubTreePlus\") return NodeType::SUBTREE; return NodeType::UNDEFINED; } struct Position2D { double x, y; }; // 转换为自定义类型 template <> inline Position2D convertFromString(StringView str) { // real numbers separated by semicolons auto parts = splitString(str, ';'); if (parts.size() != 2) { throw RuntimeError(\"invalid input)\"); } else { Position2D output; output.x = convertFromString(parts[0]); output.y = convertFromString(parts[1]); return output; } } 参考链接 std::optional - cppreference.com std::any - cppreference.com C++17之std::any_janeqi1987的专栏-CSDN博客_std::any "},"BehaviorTree/入门/05-DecoratorNodes源码解析.html":{"url":"BehaviorTree/入门/05-DecoratorNodes源码解析.html","title":"DecoratorNodes源码解析","keywords":"","body":"datetime:2023/05/11 15:12 author:nzb BT5：DecoratorNodes源码解析 DecoratorNode基类 BehaviorTree.CPP中内建的装饰节点如下，都继承自 BehaviorTree.CPP\\include\\behaviortree_cpp_v3\\decorator_node.h 中的DecoratorNode类。 很明显，该类只有1个子节点。ROS中也定义了一些方便使用的ControlNodes和DecoratorNodes，可以导入使用。 class DecoratorNode : public TreeNode { protected: TreeNode* child_node_; ... ... } executeTick() 如果子节点状态为SUCCESS或FAILURE，调用子节点的resetStatus()，子节点状态变为IDEL BlackboardPreconditionNode 细分为3个节点：BlackboardCheckInt、BlackboardCheckDouble、BlackboardCheckString。顾名思义，该节点是检查blackboard的某个port的值是否符合预期的。 包含3个InputPort，当value_A和value_B的值相等时，执行子节点。否则，不执行子节点，并返回return_on_mismatch设定的值。 static PortsList providedPorts() { return {InputPort(\"value_A\"), InputPort(\"value_B\"), InputPort(\"return_on_mismatch\") }; } 源代码中使用==来判断2个变量的值，对于double类型不妥。 template inline NodeStatus BlackboardPreconditionNode::tick() { T value_A; T value_B; NodeStatus default_return_status = NodeStatus::FAILURE; setStatus(NodeStatus::RUNNING); if (getInput(\"value_A\", value_A) && getInput(\"value_B\", value_B) && value_B == value_A) { return child_node_->executeTick(); } if (child()->status() == NodeStatus::RUNNING) { haltChild(); } getInput(\"return_on_mismatch\", default_return_status); return default_return_status; } 示例： DelayNode 延时delay_msec毫秒后，执行子节点，并返回子节点的执行结果。延时期间，返回RUNNING。 static PortsList providedPorts() { return {InputPort(\"delay_msec\", \"Tick the child after a few milliseconds\")}; } 示例： ForceFailureNode 如果子节点执行后返回RUNNING，该节点返回RUNNING；否则，该节点返回FAILURE，即强制返回失败状态。 ForceSuccessNode与ForceFailureNode大同小异。 InverterNode 如果子节点执行后返回RUNNING，该节点返回RUNNING； 如果子节点执行后返回SUCCESS，该节点返回FAILURE； 如果子节点执行后返回FAILURE，该节点返回SUCCESS； 即对子节点的执行结果取反。 KeepRunningUntilFailureNode 如果子节点执行后返回RUNNING或SUCCESS，下次tick()继续执行子节点，直到子节点返回FAILURE。 RepeatNode 重复执行子节点NUM_CYCLES 次，若每次都返回 SUCCESS，该节点返回SUCCESS； 若子节点某次返回FAILURE，该节点不再重复执行子节点，立即返回FAILURE； 若子节点返回RUNNING，该节点也返回RUNNING。 static PortsList providedPorts() { return { InputPort(NUM_CYCLES, \"Repeat a succesful child up to N times. \" \"Use -1 to create an infinite loop.\") }; } 示例： RetryNode(RetryUntilSuccessful) 如果子节点执行后返回RUNNING，该节点返回RUNNING； 如果子节点执行后返回SUCCESS，重置子节点resetChild()，该节点返回SUCCESS，不再执行； 如果子节点执行后返回FAILURE 重置子节点resetChild()，子节点变回IDLE 再次尝试执行子节点，直到尝试了num_attempts次或-1直到成功； static PortsList providedPorts() { return { InputPort(NUM_ATTEMPTS, \"Execute again a failing child up to N times. \" \"Use -1 to create an infinite loop.\") }; } 示例： SubtreeNode 用来封装一个subtree，这样会有一个独立的blackboard，__shared_blackboard port的默认值是false，因此开发者要自行重映射端口。 但tick() 函数中并没有使用__shared_blackboard port，而是在 BehaviorTree.CPP\\src\\xml_parsing.cpp中使用的，这点要注意，SubtreePlusNode 的__autoremap port也是如此。 static PortsList providedPorts() { return { InputPort(\"__shared_blackboard\", false, \"If false (default) the subtree has its own blackboard and you\" \"need to do port remapping to connect it to the parent\") }; } SubtreePlusNode 控制重映射的强化版SubtreeNode。当__autoremap port为true时，会自动重映射名称相同的port。结合代码示例会更容易理解。 static PortsList providedPorts() { return { InputPort(\"__autoremap\", false, \"If true, all the ports with the same name will be remapped\") }; } 示例： 上面有3种重映射的实现方式。第1、2种是最常见的。 第1种将Subtree的blackboard的param entry映射到Parent tree的blackboard的myParam entry，将其值设置为字符串\"Hello\"。 第2种将Subtree的blackboard的param entry的值直接设置为字符串\"World\"。 第3种在Parent tree的blackboard中增加了param entry，没有指定映射到subtree的哪个port。但由于设定__autoremap=true， 该entry 会自动映射到subtree的blackboard的param entry。SaySomething节点会在其message port中获取到值为字符串“Auto remapped”。 TimeoutNode 在设置的msec 毫秒内，返回子节点执行的状态。若子节点返回FAILURE或SUCCESS，不再执行。如果超时，终止子节点执行，并返回FAILURE。 类中使用了TimerQueue 作为计时器，可以定时多个任务，比较有趣。 static PortsList providedPorts() { return { InputPort(\"msec\", \"After a certain amount of time, \" \"halt() the child if it is still running.\") }; } 示例： RateController 频率控制 参数：hz tick子节点条件 第一次节点处于IDLE状态 子节点是RUNNING状态 达到频率设置周期 返回 如果子节点执行后返回RUNNING，该节点返回RUNNING； 如果子节点执行后返回SUCCESS，该节点返回SUCCESS，重置开始时间； 如果子节点执行后返回FAILURE，该节点返回FAILURE； "},"BehaviorTree/入门/06-ControlNodes源码解析.html":{"url":"BehaviorTree/入门/06-ControlNodes源码解析.html","title":"ControlNodes源码解析","keywords":"","body":"datetime:2023/05/11 15:12 author:nzb BT6：ControlNodes源码解析 ControlNode基类 BehaviorTree.CPP中内建的控制节点如下，都继承自 BehaviorTree.CPP\\include\\behaviortree_cpp_v3\\control_node.h 中的ControlNode类。 很明显，该类有多个子节点，其执行顺序就是控制节点的核心内容。默认子节点是从左到右执行。 除了这些ControlNodes之外，其他开源库实现的个性化nodes，用起来也很方便，开发者可以自行导入。 class ControlNode : public TreeNode { protected: std::vector children_nodes_; ... ... } FallbackNode FallbackNode也被称为Selector，适用于“如果子节点返回FAILURE该怎么办？”的场景，类似逻辑或，众多子节点中只要有1个成功即可，若某1个失败，尝试下一个。 如果某个子节点返回RUNNING，返回RUNNING，且下次tick()时之前的子节点不会再执行。 如果某个子节点返回SUCCESS，返回SUCCESS。 如果某个子节点返回FAILURE，立即执行下一个子节点（不会等下一次tick()）。如果所有子节点返回FAILURE，返回FAILURE。 NodeStatus FallbackNode::tick() { const size_t children_count = children_nodes_.size(); setStatus(NodeStatus::RUNNING); while (current_child_idx_ executeTick(); switch (child_status) { case NodeStatus::RUNNING: { return child_status; } case NodeStatus::SUCCESS: { haltChildren(); current_child_idx_ = 0; return child_status; } case NodeStatus::FAILURE: { current_child_idx_++; } break; // 这里不会退出while循环 case NodeStatus::IDLE: { throw LogicError(\"A child node must never return IDLE\"); } } // end switch } // end while loop // The entire while loop completed. This means that all the children returned FAILURE. if (current_child_idx_ == children_count) { haltChildren(); current_child_idx_ = 0; } return NodeStatus::FAILURE; } ReactiveFallback 顾名思义，是FallbackNode的reactive版本，类似ParallelNode，最多含1个asynchronous node。 如果某个子节点返回RUNNING，返回RUNNING，且下次tick()时之前的子节点会再次执行，reactive所在。 如果某个子节点返回SUCCESS，不再执行，且返回SUCCESS。 如果某个子节点返回FAILURE，立即执行下一个子节点（不会等下一次tick()）。如果所有子节点返回FAILURE，返回FAILURE。 NodeStatus ReactiveFallback::tick() { size_t failure_count = 0; // 统计FAILURE的node个数 for (size_t index = 0; index executeTick(); switch (child_status) { case NodeStatus::RUNNING: { for (size_t i = index + 1; i ParallelNode 当返回SUCCESS的子节点个数>=THRESHOLD_SUCCESS时，返回SUCCESS。 当返回FAILURE的子节点个数>=THRESHOLD_FAILURE时，返回FAILURE。 当程序判断绝不可能SUCCESS时，返回FAILURE。如 failure_children_num > children_count - success_threshold_。 static PortsList providedPorts() { return {InputPort( THRESHOLD_SUCCESS, \"number of childen which need to succeed to trigger a SUCCESS\"), InputPort( THRESHOLD_FAILURE, 1, \"number of childen which need to fail to trigger a FAILURE\")}; } IfThenElseNode 有2或3个子节点，node1就是if判断的条件。如果node1返回SUCCESS，那么node2执行；否则，node3执行。如果没有node3，返回FAILURE。 该结点not reactive ，体现在一旦node1不返回RUNNING了，就进入了node2或node3的执行，以后tick()不会再执行node1了，也即不会再检查if条件的变化。 条件node1 node1条件为RUNNING，该节点返回RUNNING node1条件为SUCCESS，执行node2 node1条件为FAILURE，执行node3 node2和node2 返回RUNNING，该节点返回RUNNING，下次直接tick该节点，不会再tick node1 否则resetChildren()和重置child_idx，返回对应状态 NodeStatus IfThenElseNode::tick() { const size_t children_count = children_nodes_.size(); if (children_count != 2 && children_count != 3) { throw std::logic_error(\"IfThenElseNode must have either 2 or 3 children\"); } setStatus(NodeStatus::RUNNING); if (child_idx_ == 0) { NodeStatus condition_status = children_nodes_[0]->executeTick(); if (condition_status == NodeStatus::RUNNING) { return condition_status; } else if (condition_status == NodeStatus::SUCCESS) { child_idx_ = 1; } else if (condition_status == NodeStatus::FAILURE) { if (children_count == 3) { child_idx_ = 2; // 执行第3个node } else { return condition_status; // 直接返回FAILURE } } } // not an else 立即执行，不会等下一次tick() if (child_idx_ > 0) { NodeStatus status = children_nodes_[child_idx_]->executeTick(); if (status == NodeStatus::RUNNING) { return NodeStatus::RUNNING; } else { haltChildren(); child_idx_ = 0; return status; } } throw std::logic_error(\"Something unexpected happened in IfThenElseNode\"); } 示例： WhileDoElseNode 是IfThenElseNode的reactive版本。功能同上，reactive体现在每次tick()都会执行 node1，即检查if条件的变化。若node1返回值有SUCCESS、FAILURE 的切换变化， 就会打断node2或node3的执行，重新选择对应的node。 node1条件为RUNNING，该节点返回RUNNING node1条件为SUCCESS，halt掉node3，执行node2 node1条件为FAILURE，halt掉node2，执行node3 如果node2和node2返回RUNNING，该节点返回RUNNING，否则resetChildren()，返回对应状态 每次都会执行node1条件 NodeStatus WhileDoElseNode::tick() { const size_t children_count = children_nodes_.size(); // 源代码错误，应该是 if (children_count != 2 && children_count != 3) {} if (children_count != 3) { throw std::logic_error(\"WhileDoElse must have either 2 or 3 children\"); } setStatus(NodeStatus::RUNNING); // 每次tick()都会先执行第1个节点，即判断条件，reactive体现在此，及时响应外界变化 NodeStatus condition_status = children_nodes_[0]->executeTick(); if (condition_status == NodeStatus::RUNNING) { return condition_status; } NodeStatus status = NodeStatus::IDLE; // 根据第1个节点的返回值，执行对应节点，并终止另外的节点 if (condition_status == NodeStatus::SUCCESS) { haltChild(2); status = children_nodes_[1]->executeTick(); } else if (condition_status == NodeStatus::FAILURE) { haltChild(1); status = children_nodes_[2]->executeTick(); } if (status == NodeStatus::RUNNING) { return NodeStatus::RUNNING; } else { haltChildren(); return status; } } SwitchNode switch-case。blackboard的某个entry的值和哪个case的值相等，就执行哪个case。同样的，最后1个未指定值的case就是default默认执行的分支。 SwitchN有N个分支，必须指定N个子节点对应。reactive体现在每次tick()都会重新读取entry的值，选择对应的分支，并终止其他节点。 static PortsList providedPorts() { PortsList ports; ports.insert(BT::InputPort(\"variable\")); for (unsigned i = 0; i (case_str)); } return ports; } 示例： ManualSelectorNode 和用户交互，由用户选择特定的节点执行。使用较少，略。 "},"BehaviorTree/入门/07-ControlNodes源码解析之Sequence.html":{"url":"BehaviorTree/入门/07-ControlNodes源码解析之Sequence.html","title":"ControlNodes源码解析之Sequence","keywords":"","body":"datetime:2023/05/11 15:12 author:nzb BT7：ControlNodes源码解析之Sequence SequenceNode 最常见的control node，按从左到右的顺序依次执行子节点。 如果某个子节点返回RUNNING，返回RUNNING，且下次tick()时之前的子节点不会再执行。类内维护当前执行节点的标号current_child_idx_。 如果某个子节点返回SUCCESS，立即执行下一个子节点（不会等下一次tick()）。如果所有子节点返回SUCCESS，返回SUCCESS。 如果某个子节点返回FAILURE，返回FAILURE，并且复位所有成员变量（尤其注意current_child_idx_）。当再次tick()时，从头开始。 NodeStatus SequenceNode::tick() { const size_t children_count = children_nodes_.size(); setStatus(NodeStatus::RUNNING); while (current_child_idx_ executeTick(); switch (child_status) { case NodeStatus::RUNNING: { return child_status; } case NodeStatus::FAILURE: { // Reset on failure haltChildren(); current_child_idx_ = 0; return child_status; } case NodeStatus::SUCCESS: { current_child_idx_++; } break; case NodeStatus::IDLE: { throw LogicError(\"A child node must never return IDLE\"); } } // end switch } // end while loop // The entire while loop completed. This means that all the children returned SUCCESS. if (current_child_idx_ == children_count) { haltChildren(); current_child_idx_ = 0; } return NodeStatus::SUCCESS; } SequenceStarNode 同上，不同之处在于如果某个子节点返回FAILURE，返回FAILURE，终止所有节点的执行，但不复位current_child_idx_。所以当再次tick()时，从FAILURE的子节点开始。 NodeStatus SequenceStarNode::tick() { ... while (current_child_idx_ executeTick(); switch (child_status) { case NodeStatus::FAILURE: { // DO NOT reset current_child_idx_ on failure for (size_t i = current_child_idx_; i ReactiveSequence 是SequneceNode的reactive版本，和ParallelNode类似，常用来周期检查某个外部条件是否成立。类内不保存当前执行节点的标号。 如果某个子节点返回RUNNING，返回RUNNING，终止其他节点，下次tick()时从头开始执行。reactive所在。 如果某个子节点返回SUCCESS，立即执行下一个子节点（不会等下一次tick()）。如果所有子节点返回SUCCESS，返回SUCCESS。 如果某个子节点返回FAILURE，返回FAILURE，终止所有节点，下次tick()时从头开始执行。 NodeStatus ReactiveSequence::tick() { for (size_t index = 0; index executeTick(); switch (child_status) { case NodeStatus::RUNNING: { for (size_t i = index + 1; i 3种node的差异可以总结如下： "},"BehaviorTree/入门/08-ActionNode及同步和异步.html":{"url":"BehaviorTree/入门/08-ActionNode及同步和异步.html","title":"ActionNode及同步和异步","keywords":"","body":"datetime:2023/05/12 10:30 author:nzb BT8：ActionNode及同步、异步 定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/action_node.h，这个文件中定义了ActionNodeBase、SyncActionNode 、SimpleActionNode、AsyncActionNode、StatefulActionNode、CoroActionNode等类，开发者自己定义的action node一般都会继承其中一个基类。 ActionNodeBase 最通用的action node基类，子类要实现executeTick()、tick()、halt()等函数。 SyncActionNode 继承自ActionNodeBase，同步action node，不会返回RUNNING，无需开发者实现halt()。 NodeStatus SyncActionNode::executeTick() { auto stat = ActionNodeBase::executeTick(); if (stat == NodeStatus::RUNNING) { throw LogicError(\"SyncActionNode MUST never return RUNNING\"); } return stat; } virtual void halt() override final { setStatus(NodeStatus::IDLE); } SimpleActionNode 继承自SyncActionNode，常使用lambdas或std::bind构造std::function对象来构造SimpleActionNode，这个function就是tick()的内容。 这样开发者无需定义node，只需指定node的类型ID和tick()即可，SimpleConditionNode同理。 class SimpleActionNode : public SyncActionNode { public: typedef std::function TickFunctor; // You must provide the function to call when tick() is invoked SimpleActionNode(const std::string& name, TickFunctor tick_functor, const NodeConfiguration& config); ~SimpleActionNode() override = default; protected: virtual NodeStatus tick() override final; TickFunctor tick_functor_; // tick()执行的内容 }; NodeStatus SimpleActionNode::tick() { ... NodeStatus status = tick_functor_(*this); if (status != prev_status) { setStatus(status); } return status; } BehaviorTree.CPP/examples/t01_build_your_first_tree.cpp中有使用示例。 GripperInterface gripper; // open()是GripperInterface类的成员函数 factory.registerSimpleAction(\"OpenGripper\", std::bind(&GripperInterface::open, &gripper)); register函数不会调用node的构造函数，其作用是向BehaviorTreeFactory注册类型，创建构造函数匹配的builder。 // 不需要输入config void BehaviorTreeFactory::registerSimpleAction( const std::string& ID, const SimpleActionNode::TickFunctor& tick_functor, PortsList ports) { NodeBuilder builder = [tick_functor, ID](const std::string& name, const NodeConfiguration& config) { return std::make_unique(name, tick_functor, config); }; TreeNodeManifest manifest = {NodeType::ACTION, ID, std::move(ports)}; registerBuilder(manifest, builder); } void BehaviorTreeFactory::registerBuilder(const TreeNodeManifest& manifest, const NodeBuilder& builder) { auto it = builders_.find(manifest.registration_ID); if (it != builders_.end()) { throw BehaviorTreeException(\"ID [\", manifest.registration_ID, \"] already registered\"); } builders_.insert({manifest.registration_ID, builder}); manifests_.insert({manifest.registration_ID, manifest}); } AsyncActionNode 继承自ActionNodeBase，会在executeTick()函数中创建1个线程来执行tick()，通过halt_requested_变量监控节点是否被终止。 开发者需要在子类tick() 中周期性检查isHaltRequested()的返回值，以便及时终止执行。子类halt()要记得调用父类AsyncActionNode::halt()。 子类不必显式的返回RUNNING ，只需根据结果返回SUCCESS/FAILURE，未执行完成时会自动置位和返回RUNNING。 NodeStatus BT::AsyncActionNode::executeTick() { // send signal to other thread. // The other thread is in charge for changing the status if (status() == NodeStatus::IDLE) { setStatus(NodeStatus::RUNNING); halt_requested_ = false; thread_handle_ = std::async(std::launch::async, [this]() { try { setStatus(tick()); } catch (std::exception&) { std::cerr BehaviorTree.CPP/sample_nodes/movebase_node.h有AsyncActionNode的使用示例。 参考链接 （原创）用C++11的std::async代替线程的创建 std::async的使用总结 StatefulActionNode 继承自ActionNodeBase，像状态机的运行方式。如果节点在IDLE state就会调用onStart()，如果在RUNNING state就会调用onRunning()，如果被halt() 就会调用onHalted()。 class StatefulActionNode : public ActionNodeBase { public: StatefulActionNode(const std::string& name, const NodeConfiguration& config) : ActionNodeBase(name, config) {} // do not override this method NodeStatus tick() override final; // do not override this method void halt() override final; /// method to be called at the beginning. /// If it returns RUNNING, this becomes an asychronous node. virtual NodeStatus onStart() = 0; /// method invoked by a RUNNING action. virtual NodeStatus onRunning() = 0; /// when the method halt() is called and the action is RUNNING, this method is /// invoked. This is a convenient place todo a cleanup, if needed. virtual void onHalted() = 0; }; NodeStatus StatefulActionNode::tick() { const NodeStatus initial_status = status(); // 当前状态 if (initial_status == NodeStatus::IDLE) { NodeStatus new_status = onStart(); // 状态跳转 ... return new_status; } if (initial_status == NodeStatus::RUNNING) { NodeStatus new_status = onRunning(); // 状态跳转 ... return new_status; } // 当前状态不是IDLE、RUNNING，那么就是SUCCESS/FAILURE，可以直接返回结果 return initial_status; } void StatefulActionNode::halt() { if (status() == NodeStatus::RUNNING) { onHalted(); // 状态跳转 } setStatus(NodeStatus::IDLE); } CoroActionNode 理解不透，略。 "},"BehaviorTree/入门/09-各种调试工具介绍.html":{"url":"BehaviorTree/入门/09-各种调试工具介绍.html","title":"各种调试工具介绍","keywords":"","body":"datetime:2023/05/12 10:30 author:nzb BT9：各种调试工具介绍 1、Groot Groot是与BehaviorTree.CPP搭配使用的工具，分为Editor、Monitor、Log Replay 3种模式，具有行为树编辑、状态监控、历史log回放等功能。 GitHub Groot入门使用指引 在Groot中可以图形化的方式创建节点（node），为节点添加输入输出端口（port），可以像Visio一样拖动、连接节点，从而构造行为树，而无需在意节点代码是否完成。 将树保存、导出为xml文件，可以被BehaviorTree.CPP 的接口读入并解析。这样就可以避免开发者自行编写xml文件的复杂局面。 如BehaviorTree.CPP/examples/t03_generic_ports.cpp中这样定义了一棵行为树： 在Groot中依此创建，如图所示： 将其保存为xml文件，如下所示。和上段代码的区别在于缺失了blackboard entry的指定，增加了node的类型。其实这2段代码都可以被Groot加载和解析。 Simply print the target on console... 2、StdCoutLogger 作用：在终端打印行为树中的节点执行状态变化。 代码仅需在加载tree后添加StdCoutLogger类的1个实例（且只能有1个实例），运行效果如下： BehaviorTree.CPP/examples/t05_crossdoor.cpp中也有本文各工具的使用示例。 3、FileLogger 作用：行为树中的节点执行状态变化保存在文件中（必须是*.fbl格式文件），可以通过Groot打开并回放执行过程。 代码仅需在加载tree后添加FileLogger类的1个实例，运行效果如下： Groot选择Log Replay模式后加载bt_trace.fbl，如下。当选中左侧的节点时，右侧会通过线条的颜色来表示执行的状态（绿色-SUCCESS，橙色-RUNNING，青色-未执行）。 4、MinitraceLogger 作用：保存节点的执行时序。 代码仅需在加载tree后添加FileLogger类的1个实例（且只能有1个实例），运行效果如下： 生成的json文件内容如下： 5、PublisherZMQ 作用：在节点执行的同时发布其状态变化，在Groot中实时观察。 代码仅需在加载tree后添加PublisherZMQ类的1个实例（且只能有1个实例）。 Groot需要选择Monitor模式，并设置下列输入。如果行为树与Groot都在同一台机器运行的话，就自发自收，Server IP可以设置为“127.0.0.1”，Publisher Port设置为“1666 ”，Server Port设置为“1667”。 Groot会自动获得树的结构，无需用户手动加载，但是它会自动展开1棵树中的所有子树，使得界面内容非常密集，因此复杂的树并不方便观察。 6、printTreeRecursively内置函数 作用：层级打印树结构，默认打印在终端。 该函数定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/behavior_tree.h中，声明和运行效果如下。 void printTreeRecursively(const TreeNode* root_node); 7、debugMessage内置函数 打印不同的树之间的端口（port）映射关系，也可以反映出port是否被设置值。 该函数定义在BehaviorTree.CPP/include/behaviortree_cpp_v3/blackboard.h 中，BehaviorTree.CPP/examples/t06_subtree_port_remapping.cpp有代码示例。 void Blackboard::debugMessage() const { for (const auto& entry_it : storage_) { auto port_type = entry_it.second.port_info.type(); if (!port_type) { port_type = &(entry_it.second.value.type()); } std::cout \"; if (auto parent = parent_bb_.lock()) { auto remapping_it = internal_to_external_.find(entry_it.first); // if条件满足，说明有port外部映射 if (remapping_it != internal_to_external_.end()) { std::cout second "},"BehaviorTree/入门/10-Logger类实现原理解析（单例与观察者模式）.html":{"url":"BehaviorTree/入门/10-Logger类实现原理解析（单例与观察者模式）.html","title":"Logger类实现原理解析-单例与观察者模式","keywords":"","body":"datetime:2023/05/12 10:30 author:nzb BT10：Logger类实现原理解析（单例与观察者模式） 上一章中的StdCoutLogger、MinitraceLogger、PublisherZMQ，都只能创建1个实例。像是单例模式，却不是典型的令构造函数是private的实现方式，而是通过限定构造函数的执行次数实现的。 不同的logger都是监控node的状态变化，在恰当的时机执行对应的打印、发送、保存等任务，这是通过观察者模式实现的。 本文从这2个实现方法展开介绍。 基类 所有Logger都继承自StatusChangeLogger，该类定义在 BehaviorTree.CPP/include/behaviortree_cpp_v3/loggers/abstract_logger.h ，是一个纯虚基类。 // 所有logger的基类，纯虚基类 class StatusChangeLogger { public: StatusChangeLogger(TreeNode* root_node); virtual ~StatusChangeLogger() = default; // 当node发生状态变化时要执行的操作 virtual void callback(BT::Duration timestamp, const TreeNode& node, NodeStatus prev_status, NodeStatus status) = 0; // 保存或发送数据 virtual void flush() = 0; ... private: std::vector subscribers_; ... }; 在 StatusChangeLogger的构造函数中，遍历树的节点，为其绑定回调函数，即不同logger所实现的callback()函数，来实现具体的打印、发送、保存等操作。 inline StatusChangeLogger::StatusChangeLogger(TreeNode* root_node) { first_timestamp_ = std::chrono::high_resolution_clock::now(); // 对回调函数callback()的封装，执行配置选项对应的callback() auto subscribeCallback = [this](TimePoint timestamp, const TreeNode& node, NodeStatus prev, NodeStatus status) { if (enabled_ && (status != NodeStatus::IDLE || show_transition_to_idle_)) { if (type_ == TimestampType::ABSOLUTE) { // 真正的回调操作 this->callback(timestamp.time_since_epoch(), node, prev, status); } else { this->callback(timestamp - first_timestamp_, node, prev, status); } } }; // 增加订阅者，绑定回调函数 auto visitor = [this, subscribeCallback](TreeNode* node) { subscribers_.push_back( node->subscribeToStatusChange(std::move(subscribeCallback))); }; // 遍历树的所有节点 applyRecursiveVisitor(root_node, visitor); }applyRecursiveVisitor StatusChangeSignal应用了观察者模式。 using StatusChangeSignal = Signal; /** * @brief subscribeToStatusChange is used to attach a callback to a status change. * When StatusChangeSubscriber goes out of scope (it is a shared_ptr) the callback * is unsubscribed automatically. * @param callback The callback to be execute when status change. * @return the subscriber handle. */ TreeNode::StatusChangeSubscriber TreeNode::subscribeToStatusChange(TreeNode::StatusChangeCallback callback) { return state_change_signal_.subscribe(std::move(callback)); } //Call the visitor for each node of the tree, given a root. void applyRecursiveVisitor(TreeNode* root_node, const std::function& visitor); 子类 以StdCoutLogger为例，其他子类仅callback()实现的操作不同而已，调用逻辑是一致的 class StdCoutLogger : public StatusChangeLogger { static std::atomic ref_count; // 原子类型 public: StdCoutLogger(const BT::Tree& tree); ~StdCoutLogger() override; virtual void callback(Duration timestamp, const TreeNode& node, NodeStatus prev_status, NodeStatus status) override; virtual void flush() override; }; 单例的重点在于利用原子变量ref_count 的值变化，来监控调用构造函数的次数。这个语法知识可以参考链接 std::atomic StdCoutLogger::ref_count(false); StdCoutLogger::StdCoutLogger(const BT::Tree& tree) : StatusChangeLogger(tree.rootNode()) { bool expected = false; // 如果expected==ref_count，就令ref_count=true（第2个参数），并返回true； // 否则，将ref_count的值赋给expected，并返回false // 即，ref_count初始化为false。第1次执行构造函数时，ref_count会被置为true，并返回true // 后面再进入构造函数时，expected!=ref_count，会抛出异常。 if (!ref_count.compare_exchange_strong(expected, true)) { throw LogicError(\"Only one instance of StdCoutLogger shall be created\"); } } StdCoutLogger::~StdCoutLogger() { ref_count.store(false); } 观察者模式 TreeNode的状态变化，都要经由setStatus()函数实现。在该函数内，会在NodeStatus变化时，通知订阅了该消息的订阅者。 void TreeNode::setStatus(NodeStatus new_status) { NodeStatus prev_status; { std::unique_lock UniqueLock(state_mutex_); prev_status = status_; status_ = new_status; } if (prev_status != new_status) { // 当状态变化时，条件变量通知其他等待者 state_condition_variable_.notify_all(); // 通知该Signal的订阅者 state_change_signal_.notify(std::chrono::high_resolution_clock::now(), *this, prev_status, new_status); } } notify()通知到位的同时，会执行订阅者绑定的callback()。 template class Signal { public: using CallableFunction = std::function; using Subscriber = std::shared_ptr; void notify(CallableArgs... args) { for (size_t i = 0; i (std::move(func)); subscribers_.emplace_back(sub); return sub; } private: std::vector> subscribers_; }; PublisherZMQ JSON版本 bt_zmq_pub_json.h #ifndef _BT_ZMQ_PUB_JSON_H_ #define _BT_ZMQ_PUB_JSON_H_ #include \"map\" #include \"cppzmq/zmq.hpp\" #include \"rapidjson/stringbuffer.h\" #include \"rapidjson/writer.h\" #include \"rapidjson/document.h\" typedef rapidjson::Document JSON; typedef rapidjson::Value JValue; class PublisherJsonZMQ : public BT::StatusChangeLogger { static std::atomic ref_cnt; public: PublisherJsonZMQ(const BT::Tree &tree, unsigned max_msg_per_second = 25, unsigned publisher_port = 1666, unsigned server_port = 1667); virtual ~PublisherJsonZMQ(); private: virtual void callback(BT::Duration timestamp, const BT::TreeNode &node, BT::NodeStatus prev_status, BT::NodeStatus status) override; virtual void flush() override; void CreateJsonBehaviorTree(); void createStatusData(); const BT::Tree &tree_; // 树指针引用 JSON tree_data_; // 树数据 JSON status_transition_data_; // 状态和变更数据 JValue status_data_; // 当前树状态数据 JValue transition_data_; // 状态变更数据 std::chrono::microseconds min_time_between_msgs_; std::atomic_bool active_server_; std::thread thread_; std::mutex mutex_; std::atomic_bool send_pending_; std::condition_variable send_condition_variable_; std::future send_future_; struct Pimpl; Pimpl *zmq_; }; #endif bt_zmq_pub_json.cpp #include \"bt_zmq_pub_json.h\" const char *json_to_str(rapidjson::Document &json, rapidjson::StringBuffer &buffer) { rapidjson::Writer writer(buffer); json.Accept(writer); auto str_msg = buffer.GetString(); return str_msg; } std::atomic PublisherJsonZMQ::ref_cnt(false); struct PublisherJsonZMQ::Pimpl { Pimpl() : ctx(1), publisher(ctx, ZMQ_PUB), server(ctx, ZMQ_REP) {} zmq::context_t ctx; zmq::socket_t publisher; zmq::socket_t server; }; PublisherJsonZMQ::PublisherJsonZMQ(const BT::Tree &tree, unsigned max_msg_per_second, unsigned publisher_port, unsigned server_port) : StatusChangeLogger(tree.rootNode()), tree_(tree), min_time_between_msgs_(std::chrono::microseconds(1000 * 1000) / max_msg_per_second), send_pending_(false), zmq_(new Pimpl()), status_data_(rapidjson::kArrayType), transition_data_(rapidjson::kArrayType) { bool expected = false; if (!ref_cnt.compare_exchange_strong(expected, true)) { throw BT::LogicError(\"Only one instace of PublisherJsonZMQ shall be created\"); } if (publisher_port == server_port) { throw BT::LogicError(\"The TCP ports of the publisher and the server must be different\"); } // 创建json树 CreateJsonBehaviorTree(); char str[100]; sprintf(str, \"tcp://*:%d\", publisher_port); zmq_->publisher.bind(str); // 状态发布话题 pub sprintf(str, \"tcp://*:%d\", server_port); zmq_->server.bind(str); // 树数据rep int timeout_ms = 100; zmq_->server.set(zmq::sockopt::rcvtimeo, timeout_ms); active_server_ = true; // 启线程接收 req 请求 thread_ = std::thread([this]() { while (active_server_) { zmq::message_t req; try { zmq::recv_result_t received = zmq_->server.recv(req); if (received) { // to string rapidjson::StringBuffer buffer; auto tree_str = json_to_str(tree_data_, buffer); SPDLOG_DEBUG(\"behavior_tree-> {}\", tree_str); zmq::message_t reply(strlen(tree_str)); memcpy(reply.data(), tree_str, strlen(tree_str)); // send data zmq_->server.send(reply, zmq::send_flags::none); } } catch (zmq::error_t& err) { if (err.num() == ETERM) { SPDLOG_INFO(\"[PublisherZMQ] Server quitting.\"); } SPDLOG_ERROR(\"[PublisherZMQ] just died. Exception {} \", err.what()); active_server_ = false; } } }); } PublisherJsonZMQ::~PublisherJsonZMQ() { active_server_ = false; if (thread_.joinable()) { thread_.join(); } if (send_pending_) { send_condition_variable_.notify_all(); send_future_.get(); } flush(); zmq_->ctx.shutdown(); delete zmq_; ref_cnt = false; } void PublisherJsonZMQ::CreateJsonBehaviorTree() { rapidjson::Document::AllocatorType &allocator = tree_data_.GetAllocator(); tree_data_.SetObject(); // 当前所在树节点 JValue tree_nodes(rapidjson::kArrayType); BT::applyRecursiveVisitor(tree_.rootNode(), [&](BT::TreeNode *node) { // 子节点 JValue children_uid(rapidjson::kArrayType); // 控制节点 if (auto control = dynamic_cast(node)) { for (const auto &child : control->children()) { children_uid.PushBack(child->UID(), allocator); } } // 装饰节点 else if (auto decorator = dynamic_cast(node)) { const auto &child = decorator->child(); children_uid.PushBack(child->UID(), allocator); } // 节点输入端口 JValue ports(rapidjson::kArrayType); for (const auto &it : node->config().input_ports) { JValue port_obj(rapidjson::kObjectType); JValue key(it.first.c_str(), allocator); JValue val(it.second.c_str(), allocator); port_obj.AddMember(key, val, allocator); ports.PushBack(port_obj, allocator); } // 节点输出端口 for (const auto &it : node->config().output_ports) { JValue port_obj(rapidjson::kObjectType); JValue key(it.first.c_str(), allocator); JValue val(it.second.c_str(), allocator); port_obj.AddMember(key, val, allocator); ports.PushBack(port_obj, allocator); } // 树节点 JValue tn(rapidjson::kObjectType); tn.AddMember(\"uid\", node->UID(), allocator); tn.AddMember(\"children_uid\", children_uid, allocator); tn.AddMember(\"status\", static_cast(node->status()), allocator); JValue name(node->name().c_str(), allocator); JValue registration_name(node->registrationName().c_str(), allocator); tn.AddMember(\"name\", name, allocator); tn.AddMember(\"registration_name\", registration_name, allocator); tn.AddMember(\"ports\", ports, allocator); tree_nodes.PushBack(tn, allocator); }); // 所有节点模型 JValue node_models(rapidjson::kArrayType); for (const auto &node_it : tree_.manifests) { const auto &manifest = node_it.second; JValue port_models(rapidjson::kArrayType); // 节点端口 for (const auto &port_it : manifest.ports) { const auto &port_name = port_it.first; const auto &port = port_it.second; JValue port_model(rapidjson::kObjectType); JValue port_name_val(port_name.c_str(), allocator); port_model.AddMember(\"port_name\", port_name_val, allocator); port_model.AddMember(\"direction\", static_cast(port.direction()), allocator); JValue type_info(BT::demangle(port.type()).c_str(), allocator); port_model.AddMember(\"type_info\", type_info, allocator); JValue description(port.description().c_str(), allocator); port_model.AddMember(\"description\", description, allocator); port_models.PushBack(port_model, allocator); } // 节点信息 JValue node_model(rapidjson::kObjectType); JValue registration_id(manifest.registration_ID.c_str(), allocator); node_model.AddMember(\"registration_id\", registration_id, allocator); node_model.AddMember(\"node_type\", static_cast(manifest.type), allocator); node_model.AddMember(\"port_models\", port_models, allocator); node_models.PushBack(node_model, allocator); } // 树 tree_data_.AddMember(\"uid\", tree_.rootNode()->UID(), allocator); tree_data_.AddMember(\"tree_nodes\", tree_nodes, allocator); tree_data_.AddMember(\"node_models\", node_models, allocator); } // 更新状态 void PublisherJsonZMQ::createStatusData() { status_data_.SetArray(); rapidjson::Document::AllocatorType &allocator = status_transition_data_.GetAllocator(); // 递归获取当前树所有节点状态 BT::applyRecursiveVisitor(tree_.rootNode(), [&](BT::TreeNode *node) { JSON tmp(rapidjson::kObjectType); tmp.AddMember(\"uid\", node->UID(), allocator); tmp.AddMember(\"status\", static_cast(node->status()), allocator); status_data_.PushBack(tmp, allocator); }); } void PublisherJsonZMQ::callback(BT::Duration timestamp, const BT::TreeNode &node, BT::NodeStatus prev_status, BT::NodeStatus status) { rapidjson::Document::AllocatorType &allocator = status_transition_data_.GetAllocator(); JValue transition(rapidjson::kObjectType); int64_t usec = std::chrono::duration_cast(timestamp).count(); transition.AddMember(\"uid\", node.UID(), allocator); transition.AddMember(\"prev_status\", static_cast(prev_status), allocator); transition.AddMember(\"status\", static_cast(status), allocator); transition.AddMember(\"t_sec\", usec / 1000000, allocator); transition.AddMember(\"t_usec\", usec % 1000000, allocator); { std::unique_lock lock(mutex_); transition_data_.PushBack(transition, allocator); } if (!send_pending_.exchange(true)) { send_future_ = std::async(std::launch::async, [this]() { std::unique_lock lock(mutex_); const bool is_server_inactive = send_condition_variable_.wait_for( lock, min_time_between_msgs_, [this]() { return !active_server_; }); lock.unlock(); if (!is_server_inactive) { flush(); } }); } } void PublisherJsonZMQ::flush() { zmq::message_t message; { { std::unique_lock lock(mutex_); status_transition_data_.SetObject(); rapidjson::Document::AllocatorType &allocator = status_transition_data_.GetAllocator(); status_transition_data_.AddMember(\"status\", status_data_, allocator); status_transition_data_.AddMember(\"transition\", transition_data_, allocator); // to string rapidjson::StringBuffer buffer; auto status_transition_str = json_to_str(status_transition_data_, buffer); message.rebuild(strlen(status_transition_str)); memcpy(message.data(), status_transition_str, strlen(status_transition_str)); SPDLOG_DEBUG(\"pub status and transition-> {}\", status_transition_str); transition_data_.SetArray(); createStatusData(); } try { zmq_->publisher.send(message, zmq::send_flags::none); } catch (zmq::error_t &err) { if (err.num() == ETERM) { SPDLOG_INFO(\"[PublisherZMQ] Publisher quitting.\"); } SPDLOG_ERROR(\"[PublisherZMQ] just died. Exception {} \", err.what()); } send_pending_ = false; } } Groot 数据使用源码解析 源码路径：Groot/bt_editor/sidepanel_monitor.cpp // 订阅状态变更 void SidepanelMonitor::on_timer() { if( !_connected ) return; zmq::message_t msg; try{ while( _zmq_subscriber.recv(msg) ) { _msg_count++; ui->labelCount->setText( QString(\"Messages received: %1\").arg(_msg_count) ); const char* buffer = reinterpret_cast(msg.data()); // status数据长度 const uint32_t header_size = flatbuffers::ReadScalar( buffer ); // transitions 数组长度 const uint32_t num_transitions = flatbuffers::ReadScalar( &buffer[4+header_size] ); std::vector> node_status; // check uid in the index, if failed load tree from server try{ for(size_t offset = 4; offset (&buffer[offset]); _uid_to_index.at(uid); // 如果不存在就报错，树变了，重新请求树数据 } for(size_t t=0; t (&buffer[offset+8]); _uid_to_index.at(uid); } // 更新节点状态 for(size_t offset = 4; offset (&buffer[offset]); const uint16_t index = _uid_to_index.at(uid); AbstractTreeNode* node = _loaded_tree.node( index ); node->status = convert(flatbuffers::ReadScalar(&buffer[offset+2] )); } //qDebug() (&buffer[offset+8]); const uint16_t index = _uid_to_index.at(uid); NodeStatus status = convert(flatbuffers::ReadScalar(&buffer[offset+11] )); _loaded_tree.node(index)->status = status; node_status.push_back( {index, status} ); } } catch( std::out_of_range& err) { qDebug() lineEdit_address->setDisabled(false); _timer->stop(); connectionUpdate(false); return; } } // update the graphic part emit changeNodeStyle( \"BehaviorTree\", node_status ); // lock editing of nodes auto main_win = dynamic_cast( _parent ); main_win->lockEditing(true); } } catch( zmq::error_t& err) { qDebug() (reply.data()); auto fb_behavior_tree = Serialization::GetBehaviorTree( buffer ); auto res_pair = BuildTreeFromFlatbuffers( fb_behavior_tree ); _loaded_tree = std::move( res_pair.first ); _uid_to_index = std::move( res_pair.second ); // 键为uid，值为 _loaded_tree的nodes属性里面对应节点的索引 // add new models to registry for(const auto& tree_node: _loaded_tree.nodes()) { const auto& registration_ID = tree_node.model.registration_ID; if( BuiltinNodeModels().count(registration_ID) == 0) { addNewModel( tree_node.model ); } } try { loadBehaviorTree( _loaded_tree, \"BehaviorTree\" ); } catch (std::exception& err) { QMessageBox messageBox; messageBox.critical(this,\"Error Connecting to remote server\", err.what() ); messageBox.show(); return false; } std::vector> node_status; node_status.reserve(_loaded_tree.nodesCount()); // qDebug() "},"BehaviorTree/入门/11-行为树内外的数据传输.html":{"url":"BehaviorTree/入门/11-行为树内外的数据传输.html","title":"行为树内外的数据传输","keywords":"","body":"datetime:2023/05/12 10:30 author:nzb BT11：行为树内外的数据传输 行为树不是封闭的，对内有不同subtree、不同port间的数据传递，对外有调用方的状态或结果获取，毕竟很多情况调用方不会满足于只知道执行结果的成功与失败，还想知道为何失败等详细信息。 树内即ports之间 参考BehaviorTree.CPP/examples/t02_basic_ports.cpp 的示例。 类ThinkWhatToSay有1个string类型的OutputPort，并会在tick()时向该port写入值。 class ThinkWhatToSay : public BT::SyncActionNode { public: BT::NodeStatus tick() override { setOutput(\"text\", \"The answer is 42\"); return BT::NodeStatus::SUCCESS; } static BT::PortsList providedPorts() { return {BT::OutputPort(\"text\")}; } }; 类SaySomething有1个string类型的InputPort，并会在tick()时从该port读取值。 class SaySomething : public BT::SyncActionNode { public: BT::NodeStatus tick() override { auto msg = getInput(\"message\"); ... std::cout (\"message\")}; } }; ThinkWhatToSay和SaySomething，通过所在树的blackboard的1个名称为\"the_answer\"的entry进行数据读写传输。entry可以传输的数据的类型， 由port 限定。我们把blackboard的数量和包含的entry的名称打印出来，size=1因为没有子树，且只有1个名为\"the_answer\"的entry。 std::cout getKeys()) { std::cout 1 the_answer Blackboard 类Blackboard（以下简称BB或bb）有3个重要的数据成员：BT中数据的保存依赖于storage_（Entry集合），树间的映射依赖于parent_和internal_to_external_。 // 保存了blackboard的所有entry的信息，包含entry所对应的port的实时值 std::unordered_map storage_; // 指向父blackboard（父树的blackboard）的指针 // 若不是nullptr，说明该tree被其他树引用了，是subtree std::weak_ptr parent_bb_; // 保存了blackboard中向外（向父blackboard）重映射的port名称 std::unordered_map internal_to_external_; struct Entry { Any value; // port的值 const PortInfo port_info; // port的其他信息 Entry(const PortInfo& info) : port_info(info) {} Entry(Any&& other_any, const PortInfo& info) : value(std::move(other_any)), port_info(info) {} }; 我们可以理解为：node的数据读写通过port，但数据是放在对应着该port的Entry中，树中所有nodes的数据整体放在blackboard的storage_中。 这是通过xml 中如下语句实现的，EntryName就是storage_中元素的第1项string，“{EntryName}”是1个blackboard pointer。 上面的语句不涉及树之间的关系，所以对internal_to_external_没影响。 以BehaviorTree.CPP/examples/t02_basic_ports.cpp中的树为例，如上。当树构建第1个SaySomething节点时， 在XMLParser::Pimpl::createNodeFromXML()中，会将pair{message，666}存入该node.config_.input_ports中。 其中，config_ 是NodeConfiguration类型，input_ports是PortsRemapping类型，即unordered_map类型。 因为“666 ”是普通的字面字符串，不是blackboard pointer（不带花括号），就与blackboard无关，数据是静态的，node构建后就不会改变， 所以这个数据是存在node自身的数据结构中，当获取名为message 的port的值时，也不会去bb中查找。 struct NodeConfiguration { Blackboard::Ptr blackboard; PortsRemapping input_ports; // 输入port的映射关系 PortsRemapping output_ports; // 输出port的映射关系 }; 当树构建ThinkWhatToSay节点时，会将pair{text，{the_answer}}存入该node.config_.input_ports中。 发现\"{the_answer}\"是bb pointer ，就会把pair{the_answer, Entry}存入所在树的bb的storage_。此时Entry还未赋值， 因为树构建时节点并未运行tick()，也就没有对port 数据的任何操作，仅仅定义了关系。这样，通过text port读写值， 就变成了对bb的名为the_answer的Entry的操作，这就是所谓的树中节点间的数据传输靠共享的blackboard。 当树构建第2个SaySomething节点时，会将pair{message，{the_answer}}存入该node.config_.input_ports中。 因为bb的storage_ 中已经有名为the_answer的Entry了，无需再添加了，所以storage_和internal_to_external_不会有任何改变。 至此，ThinkWhatToSay通过text port向bb的the_answer entry写入值（setOutput()），而SaySomething通过message port从同一个bb 的the_answer entry读取值（getInput()），数据流和逻辑就一目了然了。 getInput() // 获取名为key的port的值 template inline Result TreeNode::getInput(const std::string& key, T& destination) const { auto remap_it = config_.input_ports.find(key); // 既然是读值，那么就应该是input port，就应该在config_.input_ports中 if (remap_it == config_.input_ports.end()) { return nonstd::make_unexpected( StrCat(\"getInput() failed because NodeConfiguration::input_ports \" \"does not contain the key: [\", key, \"]\")); } auto remapped_res = getRemappedKey(key, remap_it->second); try { if (!remapped_res) { // remapped_res空，说明remap_it->second目前只是普通的字面字符串 destination = convertFromString(remap_it->second); return {}; } const auto& remapped_key = remapped_res.value(); // 既然remapped_key是本bb的一个entry对应的port的名称，那么本bb必须是有效的非空的 if (!config_.blackboard) { return nonstd::make_unexpected( \"getInput() trying to access a Blackboard(BB) entry, but BB is invalid\"); } // 从本bb获取对应的entry的值，即port的值 const Any* val = config_.blackboard->getAny(static_cast(remapped_key)); if (val && val->empty() == false) { // 做类型转换 if (std::is_same::value == false && val->type() == typeid(std::string)) { destination = convertFromString(val->cast()); } else { destination = val->cast(); } return {}; } // 没有找到对应port的entry return nonstd::make_unexpected( StrCat(\"getInput() failed because it was unable to find the key [\", key, \"] remapped to [\", remapped_key, \"]\")); } catch (std::exception& err) { return nonstd::make_unexpected(err.what()); } } getInput(key)和setOutput(key)都是先去node的config_.input_ports或config_.output_ports中寻找匹配的key。找到后，得到其匹配的字符串str。 若str不是bb pointer（不带{}花括号），那就是字面字符串，就返回这个字符串，进行必要的类型转换。若str是bb pointer，得到bb entry名（去掉{}花括号）， 最后调用config_.blackboard->getAny(EntryName)读取值，或者调用config_.blackboard->set(EntryName) 设置值，所谓“值”，就是storage_.Entry.value。 // 获取名为key的port的值 Any* getAny(const std::string& key) { std::unique_lock lock(mutex_); // 如果父blackboard不为空，需要检查是否有向父blackboard的重映射 if (auto parent = parent_bb_.lock()) { auto remapping_it = internal_to_external_.find(key); // 找到了，说明存在向父blackboard的重映射 if (remapping_it != internal_to_external_.end()) { // 从父blackboard获取对应port名为 remapping_it->second 的entry的值 return parent->getAny(remapping_it->second); } } // 到这，说明父bb为空，或者名为key的port不存在重映射，那就从本bb获取值 auto it = storage_.find(key); // 若找到了，就返回本bb中对应port名为key的entry的值 return (it == storage_.end()) ? nullptr : &(it->second.value); } setOutput() // 设置名为key的port的值 template inline Result TreeNode::setOutput(const std::string& key, const T& value) { if (!config_.blackboard) { return nonstd::make_unexpected( \"setOutput() failed: trying to access a BB entry, but BB is invalid\"); } auto remap_it = config_.output_ports.find(key); // 既然是写值，那么就应该是output port，就应该在config_.output_ports中 if (remap_it == config_.output_ports.end()) { return nonstd::make_unexpected( StrCat(\"setOutput() failed: NodeConfiguration::output_ports \" \"does not contain the key: [\", key, \"]\")); } StringView remapped_key = remap_it->second; // 这种特殊情况先不管 if (remapped_key == \"=\") { remapped_key = key; } // 如果是bb指针，就把{name}改为name，就是去掉花括号 if (isBlackboardPointer(remapped_key)) { remapped_key = stripBlackboardPointer(remapped_key); } // 既然是写值，key一定对应着本bb的某个entry，从而使其他node可以通过bb共享这个数据 config_.blackboard->set(static_cast(remapped_key), value); return {}; } output_port和input_port的不同在于，output_port一定会对应着bb的一个entry。因为node之所以有output_port，就是想通过它向外传值， 让其他node 可以获得。所以上面代码中，即便remapped_key不是bb pointer也会是一个EntryName，也要调用config_.blackboard->set(key, value)。 // 设置名为key的port的值 template void set(const std::string& key, const T& value) { std::unique_lock lock(mutex_); auto it = storage_.find(key); // 如果父blackboard不为空，需要检查是否有向父blackboard的重映射 if (auto parent = parent_bb_.lock()) { auto remapping_it = internal_to_external_.find(key); // 找到了，说明存在向父blackboard的重映射 if (remapping_it != internal_to_external_.end()) { const auto& remapped_key = remapping_it->second; // 本bb中没有对应port的entry if (it == storage_.end()) { // 检查父bb中是否有对应的entry auto parent_info = parent->portInfo(remapped_key); if (parent_info) { // 从父bb中获取对应的entry的portinfo，保存到本bb的storage_中 storage_.insert({key, Entry(*parent_info)}); } else { // 父bb中没有对应port的entry，在本bb的storage_中添加entry，绑定空白的portinfo storage_.insert({key, Entry(PortInfo())}); } } // 向父bb的对应entry设置值 parent->set(remapped_key, value); return; } } // 到这，说明父bb为空，或者名为key的port不存在重映射 // 本bb有对应entry，检查数据类型是否匹配，并更新值 if (it != storage_.end()) { ... } else { // 本bb没有对应entry，就按输入值添加一个到storage_ storage_.emplace(key, Entry(Any(value), PortInfo())); } return; } SetBlackboard SetBlackboard是一个比较特殊的节点，因为它可以直接向所在tree的blackboard或父bb写入值。其双向port“output_key”，对应着bb的一个entry。 class SetBlackboard : public SyncActionNode { public: SetBlackboard(const std::string& name, const NodeConfiguration& config) : SyncActionNode(name, config) { setRegistrationID(\"SetBlackboard\"); } static PortsList providedPorts() { return { InputPort(\"value\", \"Value represented as a string. convertFromString must be \" \"implemented.\"), BidirectionalPort(\"output_key\", \"Name of the blackboard entry where the value \" \"should be written\")}; } private: virtual BT::NodeStatus tick() override { std::string key, value; if (!getInput(\"output_key\", key)) { throw RuntimeError(\"missing port [output_key]\"); } if (!getInput(\"value\", value)) { throw RuntimeError(\"missing port [value]\"); } setOutput(\"output_key\", value); return NodeStatus::SUCCESS; } }; 以 BehaviorTree.CPP/examples/t03_generic_ports.cpp 中的行为树为例，结合上述原理，当树构建SetBlackboard节点时， 该node.config_.input_ports 和node.config_.output_ports都会添加pair{output_key, OtherGoal}，因为output_key是INOUT port。 此时，BT的bb的storage_ 中不会添加对应的entry。直到构建第2个PrintTarget节点时，bb的storage_中才会添加{OtherGoal, Entry}。 为什么代码中tick()是调用setOutput(\"output_key\", value)，而不是setOutput(key, value)呢？这里key指通过getInput(\"output_key\", key) 获得的值。 因为在构建SetBlackboard节点时，output_ports添加的是pair{output_key, xxx}，即所有的对应关系、传递线索，是以output_key为准的。 对应关系在树构建时就已经确定了，在节点运行tick()时是不会变的，所以tick()中key的值没有发挥作用。 当然，不考虑SubTreePlus（没研究），我认为将SetBlackboard节点的output_key port由INOUT改为仅OUT也是可以的，验证下来也是OK的。 subtree之间 参考 BehaviorTree.CPP/examples/t06_basic_ports.cpp 的示例。 MainTree中包含1个MoveRobot subtree，所以有2个blackboard，blackboard[0]是MainTree的（一定是最外层树的），具有move_result和move_goal 2个entry， 而MoveRobot具有output和target 2个entry。在树运行之后，使用debugMessage()可以打印树之间的ports映射如下。full表明对应port 已经被设置值，可以被外部读取。 move_result (std::string) -> full move_goal (Pose2D) -> full -------------- output (std::string) -> remapped to parent [move_result] target (Pose2D) -> remapped to parent [move_goal] 如果我们调整下debugMessage()在树创建之后、运行之前，映射会变成什么样呢？ int main() { ... auto tree = factory.createTreeFromText(xml_text); // 在树创建之后、运行之前打印映射信息 std::cout debugMessage(); std::cout debugMessage(); std::cout get(\"move_goal\"); // std::cout 结果如下，可见MainTree的2个entry都没有设置值（empty），且MoveRobot subtree也少了1个entry信息，因为此时树未运行SetBlackboard节点， 自然也就不会创建出output entry。若读取empty的entry，就会发生异常。 move_result (std::string) -> empty move_goal (Pose2D) -> empty -------------- target (Pose2D) -> remapped to parent [move_goal] 深入解析 以BehaviorTree.CPP/examples/t06_subtree_port_remapping.cpp中的行为树为例。 当构建到MoveRobot节点时，识别到它是一个SubTreeNode。当__shared_blackboard=false时，会为该subtree创建一个独立的blackboard（称为子bb ），令其parent_bb_ 成员指针指向父bb（父tree的bb）。并且会在子bb的internal_to_external_中添加重映射{target，move_goal} 和 {output，move_result} 。然后递归进入MoveRobot subtree的各节点的构造。 当构建到MoveBase节点时，识别到target是一个bb pointer，但是节点所在树的bb（即子bb）是刚创建的，其storage_容器是空的，此时会调用子bb->setPortInfo() 来添加一个Entry。因为子bb的parent_bb_不为空，就要检查子bb的internal_to_external_中是否存在target向外的映射。若无，只需在子bb的storage_ 中添加名为target的Entry；若有，还要在父bb的storage_中添加名为move_goal的Entry。因为subtree的target映射到父树的move_goal。 void Blackboard::setPortInfo(std::string key, const PortInfo& info) { std::unique_lock lock(mutex_); // 有父bb，需要检查是否有向父bb的重映射 if (auto parent = parent_bb_.lock()) { auto remapping_it = internal_to_external_.find(key); if (remapping_it != internal_to_external_.end()) { // 有向父bb的重映射，向父bb传递portinfo parent->setPortInfo(remapping_it->second, info); } } // 到这，说明父bb为空，或者名为key的port不存在重映射 auto it = storage_.find(key); if (it == storage_.end()) { // 本bb无对应entry，使用输入的portinfo构造Entry并保存入storage_ storage_.insert({std::move(key), Entry(info)}); } else { // 本bb有对应entry，检查数据类型是否匹配，无需更新portinfo，因为创建一次后就不会改变 auto old_type = it->second.port_info.type(); if (old_type && old_type != info.type()) { throw LogicError( \"Blackboard::set() failed: once declared, the type of a port shall \" \"not change. Declared type [\", BT::demangle(old_type), \"] != current type [\", BT::demangle(info.type()), \"]\"); } } } 结尾有个小问题，上面是怎么识别到MoveRobot是SubTreeNode呢？ 在树的构建过程中，XMLParser::Pimpl::loadDocImpl()会统计xml语句中标签“BehaviorTree”的个数，并将其名称（树的ID）保存在XMLParser::Pimpl的成员变量tree_roots中。 XMLParser::Pimpl::createNodeFromXML()会检查node ID是否在tree_roots中。若在，就标记为subtree node，即type是SUBTREE。 树与调用方之间 本小节需要和上一小节结合起来看。 当debugMessage()打印key->full时，才可以在外部读取树的blackboard的entry的值。 while (status == NodeStatus::RUNNING) { status = tree.tickRoot(); SleepMS(1); // optional sleep to avoid \"busy loops\" } // 添加在树运行后和return之间，此时entry的值是保持的。 // 如果添加在树运行之前，可能会因为port还未被设置而读取触发异常。 auto p = tree.blackboard_stack[0]->get(\"move_goal\"); std::cout 运行上面的代码，我们会得到： get pose (1,2,3) // 是XML中SetBlackboard的结果 当debugMessage()打印key->empty时， 读取值抛出异常，参考上一小节被注释的代码。 terminate called after throwing an instance of 'std::runtime_error' what(): Any::cast failed because it is empty 当然，从外部设置entry的值并不受其是empty/full的影响。 Pose2D p, q; p.x = 10, p.y = 11, p.theta = 3.14; tree.blackboard_stack[0]->set(\"move_goal\", p); tree.blackboard_stack[0]->get(\"move_goal\", q); std::cout 运行上面的代码，我们会得到： get pose (10,11,3.14) "},"BehaviorTree/入门/12-从xml创建加载行为树的过程分析.html":{"url":"BehaviorTree/入门/12-从xml创建加载行为树的过程分析.html","title":"从xml创建加载行为树的过程分析","keywords":"","body":"datetime:2023/05/15 10:05 author:nzb BT12：从xml创建加载行为树的过程分析 本文主要分析BehaviorTree.CPP/src/xml_parsing.cpp 的内容，因为函数代码都很长，就省略了代码，可以与源文件对照理解，最好在各个阶段多加log单步调试。搞清楚行为树的解析、加载、构建过程， 有利于对其设计思路有更深刻的理解，但是对行为树的使用影响不大，可以跳过。 我认为行为树的精华在于blackboard的设计，实现了节点间、树间的数据共享，但代码层次较深，理解花费时间较多，待以后补充。 1、BehaviorTreeFactory::createTreeFromText() 树的加载和创建由createTreeFromText() 实现，该函数的第2个参数具有默认参数，即初创建的blackboard，是一个局部变量，但是由智能指针指向它。 因此，只要引用计数大于0，该变量仍然不会释放，可以访问得到。 Tree createTreeFromText(const std::string& text, Blackboard::Ptr blackboard = Blackboard::create()); Tree BehaviorTreeFactory::createTreeFromText(const std::string& text, Blackboard::Ptr blackboard) { XMLParser parser(*this); // 加载和解析文本，检查各项元素是否符合BT的概念要求。 parser.loadFromText(text); // 创建树和所有节点的实例，构造好树之间、节点之间的父子关系，port的映射关系等。 auto tree = parser.instantiateTree(blackboard); // 将树的节点信息绑定给树实例变量 tree.manifests = this->manifests(); return tree; } createTreeFromText() 主要有3部分。其中的manifests包含了树的所有节点类型信息，其实节点的builder和manifest在树建立之前已经通过register函数传给factory变量了。 template void registerNodeType(const std::string& ID, PortsList ports) { ... registerBuilder(CreateManifest(ID, ports), CreateBuilder()); } void BehaviorTreeFactory::registerBuilder(const TreeNodeManifest& manifest, const NodeBuilder& builder) { auto it = builders_.find(manifest.registration_ID); if (it != builders_.end()) { throw BehaviorTreeException(\"ID [\", manifest.registration_ID, \"] already registered\"); } builders_.insert({manifest.registration_ID, builder}); manifests_.insert({manifest.registration_ID, manifest}); } 2、XMLParser::loadFromText() 具体由XMLParser::Pimpl::loadDocImpl()执行，主要有如下几个步骤。 第1个for循环，递归加载本xml中所include的子树xml文件，先加载子树，再加载外层树，相当于深度优先搜索。 第2个for循环，遍历本xml文件中的树的名称或ID（相当于树的根节点），保存在类XMLParser::Pimpl的成员变量tree_roots中。 第3、4个for循环，将构造树之前就注册的所有节点，和2中读取的树的根节点，都存入局部变量std::set registered_nodes; 然后将其传入VerifyXML()。 VerifyXML()负责检查树的设计要求是否满足。检查项有： TreeNodesModel标签是否合法，主要用于Groot可视化。 各种node的子节点数量是否合法，是否有ID。比如ControlNode至少有1个子节点，DecoratorNode只有1个子节点，Subtree没有子节点。 是否有未注册的不认识的节点。 针对非subtree节点进行递归检查。 是否指定main_tree_to_execute 标签。如果有多个BehaviorTree，则必须指定main_tree_to_execute，如果只有1个BehaviorTree，就不需要指定。 3、XMLParser::instantiateTree() 分为2个部分。 构造了行为树的实例——局部变量output_tree，将传入的blackboard（即上文创建的智能指针指向的blackboard）保存入 output_tree.blackboard_stack。 调用recursivelyCreateTree()，传入主树（最外层树）的ID、tree局部变量、blackboard（还是刚才同一个智能指针）、TreeNode指针（空指针nullptr，作为根节点）。 Tree XMLParser::instantiateTree(const Blackboard::Ptr& root_blackboard) { Tree output_tree; ... // first blackboard output_tree.blackboard_stack.push_back(root_blackboard); _p->recursivelyCreateTree(main_tree_ID, output_tree, root_blackboard, TreeNode::Ptr()); return output_tree; } 接下来对recursivelyCreateTree()展开分析。 4、XMLParser::Pimpl::recursivelyCreateTree() 函数内递归执行recursiveStep()，注意第1个参数是父节点。 void BT::XMLParser::Pimpl::recursivelyCreateTree( const std::string& tree_ID, Tree& output_tree, Blackboard::Ptr blackboard, const TreeNode::Ptr& root_parent) { std::function recursiveStep; recursiveStep = [&](const TreeNode::Ptr& parent, const XMLElement* element) { ... }; auto root_element = tree_roots[tree_ID]->FirstChildElement(); // start recursion recursiveStep(root_parent, root_element); } recursiveStep()分为3部分。 调用XMLParser::Pimpl::createNodeFromXML()创建节点实例，将该实例保存在树的std::vector nodes 成员变量中。 如果该节点是SUBTREE类型的，细分SubtreeNode和SubtreePlusNode来处理。 如果是SubtreeNode，就根据__shared_blackboard的值来创建blackboard，并添加映射信息，然后递归调用recursivelyCreateTree()来创建子树。 如果是SubtreePlusNode，就根据__autoremap的值来创建blackboard的port的映射，然后递归调用recursivelyCreateTree()来创建子树。 如果该节点不是SUBTREE类型的，递归调用recursiveStep()，并把该节点作为接下来待创建节点的父节点。如果该节点没有其他包含的元素了，就不再递归了， 从recursiveStep() 返回，进而从recursivelyCreateTree()返回，进而从instantiateTree() 返回。 5、createNodeFromXML() 对非subtree的节点，将port映射的key和value保存入局部变量PortsRemapping port_remap。 对于有remap的节点，在blackboard中通过Blackboard::setPortInfo() 添加port映射信息， 并在父树的blackboard的相同key也保存相同port 信息。基于此，实现了父子树之间的blackboard对相同key的同一性关联。 使用manifest中保存的信息，初始化NodeConfiguration。即在NodeConfiguration的input_ports和output_ports集合中添加存在外部映射的port。 对于不存在外部映射的port，对其中的InputPort赋默认值，并存入NodeConfiguration的input_ports集合中。 config构造完成，调用 instantiateTreeNode() 来实例化子节点。 若传入的父节点有效，根据父节点的类型，为其添加子节点。 "},"BehaviorTree/入门/13-自定义的用于枚举类型的SwitchNode.html":{"url":"BehaviorTree/入门/13-自定义的用于枚举类型的SwitchNode.html","title":"自定义的用于枚举类型的SwitchNode","keywords":"","body":"datetime:2023/05/15 10:05 author:nzb BT13：自定义的用于枚举类型的SwitchNode 内建SwitchNode的局限 BehaviorTree.CPP中有内建的SwitchNode，定义在 BehaviorTree.CPP/include/behaviortree_cpp_v3/controls/switch_node.h。 但是其只能接收string类型的值，因为定义的input port就是string类型。 static PortsList providedPorts() { PortsList ports; ports.insert(BT::InputPort(\"variable\")); for (unsigned i = 0; i (case_str)); } return ports; } 这样用起来很不方便，大多数switch-case的逻辑都是和枚举值一起用的。因此我实现了一个自定义的control node，用来接收枚举类型的值，称为EnumSwitchNode。 改动很简单，只需将input port的类型改为模板，并检查输入类是枚举类型。 自定义的EnumSwitchNode #ifndef BTNODES_CONTROL_NODES_ENUM_SWITCH_NODE_H #define BTNODES_CONTROL_NODES_ENUM_SWITCH_NODE_H #include \"behaviortree_cpp_v3/control_node.h\" namespace BT { /** * @brief BehaviorTree.CPP的SwitchNode只能输入string类型的值 * 这里添加可以输入枚举类型的值 */ template class EnumSwitchNode : public ControlNode { public: EnumSwitchNode(const std::string& name, const BT::NodeConfiguration& config) : ControlNode::ControlNode(name, config), running_child_(-1) {} virtual ~EnumSwitchNode() override = default; void halt() override { running_child_ = -1; ControlNode::halt(); } static PortsList providedPorts() { PortsList ports; ports.insert(BT::InputPort(\"enum_variable\")); for (unsigned i = 0; i (case_str)); } return ports; } private: int running_child_; virtual BT::NodeStatus tick() override; }; template inline NodeStatus EnumSwitchNode::tick() { // 如果是非枚举类型，会编译报错 static_assert(std::is_enum::value, \"[registerNode]: accepts only enum classes!!!\"); constexpr const char* case_port_names[9] = {\"case_1\", \"case_2\", \"case_3\", \"case_4\", \"case_5\", \"case_6\", \"case_7\", \"case_8\", \"case_9\"}; if (childrenCount() != NUM_CASES + 1) { throw LogicError( \"Wrong number of children in EnumSwitchNode; \" \"must be (num_cases + default)\"); } T variable, value; int child_index = NUM_CASES; // default index; if (getInput(\"enum_variable\", variable)) { // check each case until you find a match for (unsigned index = 0; index executeTick(); if (ret == NodeStatus::RUNNING) { running_child_ = child_index; } else { haltChildren(); running_child_ = -1; } return ret; } } // namespace BT #endif // BTNODES_CONTROL_NODES_ENUM_SWITCH_NODE_H 应用示例 // 宠物类型 enum class PetType : uint8_t { UNDEFINED = 0, DOG, CAT, BIRD, }; 我们创建1个枚举类-宠物类型PetType，并实现由string向PetType转换的函数convertFromString()，它将会在读取xml中port值时自动调用。 template <> inline PetType BT::convertFromString(BT::StringView key) { auto parts = BT::splitString(key, ','); if (parts.size() != 1) { throw BT::RuntimeError(\"invalid input\"); } else { auto str = parts[0]; if (\"PetType::UNDEFINED\" == str) { return PetType::UNDEFINED; } else if (\"PetType::DOG\" == str) { return PetType::DOG; } else if (\"PetType::CAT\" == str) { return PetType::CAT; } else if (\"PetType::BIRD\" == str) { return PetType::BIRD; } else { throw BT::RuntimeError(std::string(\"invalid input, chars=\") + str.to_string()); } } } 创建1个简单的行为树，第1个SetBlackboard节点负责向{my_pet} entry写入枚举值，第2个SwitchNode负责根据读到的值，执行对应的分支来打印。 main()中，需要向factory注册用到的2种node: SaySomething和EnumSwitchNode，这里指定了其接受的枚举类型，还可以同时创建多个不同的EnumSwitchNode。 int main() { BT::BehaviorTreeFactory factory; factory.registerNodeType(\"SaySomething\"); // 注册要使用的枚举类switch node factory.registerNodeType>( \"EnumSwitch3_PetType\"); auto tree = factory.createTreeFromText(xml_text); tree.tickRoot(); return 0; } SaySomething node就是读取message port值并打印。 class SaySomething : public BT::SyncActionNode { public: SaySomething(const std::string& name, const BT::NodeConfiguration& config) : BT::SyncActionNode(name, config) {} // You must override the virtual function tick() BT::NodeStatus tick() override { auto msg = getInput(\"message\"); if (!msg) { throw BT::RuntimeError(\"missing required input [message]: \", msg.error()); } std::cout (\"message\")}; } }; 直接运行，会得到如下结果。大家可以改变{my_pet} entry的值来观察输出的变化。 SaySomething::tick()- wang...wang... "},"BehaviorTree/入门/14-registerSimpleNode相关数据传输.html":{"url":"BehaviorTree/入门/14-registerSimpleNode相关数据传输.html","title":"registerSimpleNode相关数据传输","keywords":"","body":"datetime:2023/06/02 16:21 author:nzb BT14：registerSimpleNode相关数据传输 代码 #include \"first_tree.h\" // using namespace DummyNodes; class ApproachObject : public BT::SyncActionNode { public: ApproachObject(const std::string &name) : BT::SyncActionNode(name, {}) {} BT::NodeStatus tick() override { std::cout name() (\"ktype\"), BT::InputPort(\"key\"), BT::InputPort(\"value\")}; } BT::NodeStatus tick() override { std::cout (\"ktype\"); auto key = getInput(\"key\"); auto value = getInput(\"value\"); std::cout getKeys(); for (auto i = vector.begin(); i != vector.end(); i++) { std::string key_v; self.config().blackboard->get(i->to_string(), key_v); std::cout debugMessage(); std::cout get(\"key1\", key1_v); std::cout \" set(\\\"key1\\\", \\\"789\\\");, the value is: 789, the blackboard key is 'key1' \\n\"; self.config().blackboard->set(\"key1\", \"789\"); self.config().blackboard->get(\"key1\", key1_v); std::cout get blackboard 'key1' value --->\" \" getKeys().size() second second (\"open2\").value() (\"open3\").value() (\"open4\").value() (\"ApproachObject\"); factory.registerNodeType(\"CustomCondition\"); GripperInterface gripper; BT::PortsList ports = {BT::InputPort(\"open1\"), BT::InputPort(\"open2\"), BT::OutputPort(\"open3\"), BT::InputPort(\"open4\")}; factory.registerSimpleAction(\"OpenGripper\", std::bind(&GripperInterface::open, gripper, std::placeholders::_1), ports); factory.registerSimpleAction(\"CloseGripper\", std::bind([&]() { return gripper.close(); })); auto tree = factory.createTreeFromFile(\"../src/study/xmls/001_ports_demo.xml\"); BT::PublisherZMQ pub_zmq(tree); tree.tickRootWhileRunning(); } 行为树 结果 --------------------CustomCondition---------------------- ktype: 321 key: -1;3;2 value: 789 --------------------CustomCondition---------------------- -------------------GripperInterface open start --------------------------- blackboard key is: key1 value is: 321 blackboard key is: key value is: -1;3;2 -------------------blackboard debugMessaget --------------------------- key1 (std::string) -> full key (std::string) -> full -------------------blackboard debugMessaget --------------------------- setOutput open3, the value is: 456, the blackboard key is 'key1' get blackboard 'key1' value --->456 self.config().blackboard->set(\"key1\", \"789\");, the value is: 789, the blackboard key is 'key1' self.config().blackboard->get blackboard 'key1' value --->789 setOutput open3, the value is: abc, the blackboard key is 'key1' self.getInput blackboard 'key1' value --->abc -------------------port and blackboard size --------------------------- input_post size: 3 output_ports size: 1 blackboard size: 2 -------------------port and blackboard size --------------------------- open1: open1_val open2: {key} open2: -1;3;2 open4: abc -------------------GripperInterface open end --------------------------- ApproachObject: approach_object GripperInterface::close 结论 OutputPort：只能setOutput操作 InputPort：只能getInput操作 registerSimpleAction 简单节点可以提供ports，但是在Groot工具中刚开始不显示，需要再xml中TreeNodesModel对应节点上加上参数，如上图的 CustomCondition节点一样 操作数据，前提条件函数需要添加一个节点参数，如： open(BT::TreeNode &self); factory.registerSimpleAction(\"OpenGripper\", std::bind(&GripperInterface::open, gripper, std::placeholders::_1), ports); std::placeholders::_1：占位使用 读取ports数据：self.getInput 写法1，指定类型：Position2D data = self.getInput(\"key\"); 写法2，先声明了数据：Position2D pos; self.getInput(\"key\", pos); 设置ports数据：self.setOutput 读取黑板数据：std::string key1_v; self.config().blackboard->get(\"key1\", key1_v); 设置黑板数据：self.config().blackboard->set(\"key1\", \"789\"); "},"Database/MySQL/计算机二级MySQL.html":{"url":"Database/MySQL/计算机二级MySQL.html","title":"计算机二级","keywords":"","body":"一、数据库基本概念 1、数据库设计的步骤 六个阶段：需求分析、概念结构设计、逻辑结构设计、物理结构设计、数据库实施、数据库运行与维护 二、MySQL编程语言 1、MySQL函数 1.1、聚合函数 count()：计数（对于除“*”以外的任何参数，返回所选集合中非null值的数目） sun()：求和 avg()：求平均数 max()：求最大值 min()：求最小值 1.2、数学函数 abs()：求绝对值 floor()：返回小于或等于参数的最大整数 rand()：返回0~1之间的随机数 truncate(x,y)：返回x保留到小数点后y为的值 sort(): 求参数的平方根 1.3、字符串函数 upper()和ucase()：把字符串所有字母变成大写字母 left(s,n)：返回字符串s的前n个字符 substring(s,n,len)：从字符串s的第n个位置开始获取长度为len的字符串 1.4、日期和时间函数 curdate()和current_date()：返回当前日期 curtime()和current_time()：获取当前时间 now()：获取当前日期和时间，current_timestamp()、localtime()、sysdate()、localtimestamp()同样可以获取当前日期和时间 1.5、其他函数 if(expr,v1,v2)：条件判断函数，如果表达式expr成立，则执行v1,否则执行v2 ifnull(v1,v2)：条件判断函数，如果表达式v1不为空，则显示v1的值,否则显示v2的值 version()：获取数据库的版本号 三、数据定义 1、定义数据库 1.1、创建数据库 create {database | schema} [if not exists] db_name [[default] character set [=] charset_name [[default] collate [=] collation_name]; 1.2、选择和查看数据库 use da_name; show {databases | schemas}; 1.3、修改数据库 alter {database | schema} [db_name] [[default] character set [=] charset_name [[default] collate [=] collation_name]; 数据库名可省略，表示修改当前数据库 1.4、删除数据库 drop {database | schema} [if exists] db_name; 2、定义表 2.1数据类型 2.1.1、数值类型 bit tinyint bool,boolean smallint mediumint int,integer bigint double decimal(m.d) 2.1.2、日期和时间类型 date:日期型，MySQL以“YYYY-MM-DD”格式显示date值 datetime:日期和时间类型，MySQL以“YYYY-MM-DD HH:MM:SS”格式显示datetime值 timestamp:时间戳 time:时间型,MySQL以“HH:MM:SS”格式显示time值 year两位或四位格式的年 2.1.3、字符串类型 char：定长字符串 varchar：可变长字符串 tinytext text 2.2、创建表 create table tbl_name ( 字段名1 数据类型 [列级完整性约束条件] [默认值] [,字段名2 数据类型 [列级完整性约束条件] [默认值] [,... ...] [,表级完整性约束条件] ) [engine=引擎类型]; 2.3、查看表 2.3.1、查看表名称 show tables [{from | in } db_name]; 2.3.2、查看数据表的基本结构 show columns {from | in } tb_name [from | in } db_name]; 或 desc tb_name; 2.3.3、查看数据表的详细结构 show create table tb_name; 2.4、修改表 2.4.1、添加字段 alter table tb_name add [column] 新字段名 数据类型 [约束条件] [first | after 已有字段名]; 2.4.2、修改字段 # 可改指定列的名称和数据类型，修改多个彼此用逗号分隔 alter table tb_name change [column] 原字段名 新字段名 数据类型 [约束条件]; # 修改或删除指定列的默认值 alter table tb_name alter [column] 字段名 {set | drop} default; # 修改列的数据类型，而不改名 alter table tb_name modify [column] 字段名 数据类型 [约束条件] [first | after 已有字段名]; 2.4.3、删除字段 alter table tb_name drop [column] 字段名; 2.5、重命名表 alter table 原表名 rename [to] 新表名; 或 rename table 原表名1 to 新表名1 [,原表名2 to 新表名2]......; 2.6、删除表 drop table [if exists] tb_name1 [,tb_name2]......; 3、数据的完整性约束 3.1、定义实体完整性 3.1.1、主键约束 一个表必须要有一个主键，且唯一不为空 3.2.2、完整性约束的命名 constraint {primary key(主键字段列表) | unique(候选键字段列表) |foreign key(外键字段列表) references tb_被参照的关系(表) (主键字段列表) | check(约束条件表达式)}; 3.2、定义参照完整性 外键需存在或为空 3.3、用户定义完整性 MySQL支持的几种用户定义完整性约束：非空约束，check约束和触发器 check约束： check(expr); 3.4、更新完整性约束 3.4.1、删除约束 alter table drop foreign key ; alter table drop primary key; alter table drop {约束名 | 候选键字段名}; 3.4.2、添加约束 alter table add [constraint ] primary key(主键字段); alter table add [constraint ] foreign key(外键字段名) references 被参照表(主键字段名); alter table add [constraint ] unique key(字段名); 四、数据查询 1、select语句 select [all | distinct | distinctrow] [,目标表达式2]... form [,] [group by [having ]] [order by [asc | desc]] [limit[m,]n] 2、单表查询 2.1、选择字段 select 目标表达式1, 目标表达式2,...,目标表达式n from 表名; select * form 表名; # 定义字段的别名 select 字段名 as 字段别名 from 表名; 2.2、选择指定的字段 select 目标表达式1, 目标表达式2, ... , 目标表达式n from 表名 where 查询条件; # 带between ...and... select 目标表达式1, 目标表达式2, ... , 目标表达式n from 表名 where expression [not] between expr1 and expr2; #带like关键字,换码字符也叫转义字符，如果字符串本身含有通配符_和%,就需要换码字符 select 目标表达式1, 目标表达式2, ... , 目标表达式n from 表名 where 字段名 [not] like ''[escape '']; #使用正则表达式查询 select 目标表达式1, 目标表达式2, ... , 目标表达式n from 表名 where 字段名 [not] [regexp | rlike] ; # 限制查询结果数目 limit 行数 offset 位置偏移数; 3、分组聚合查询 3.1、使用聚合函数 group by 字段列表 having ; 4、连接查询 4.1、交叉查询（笛卡尔积）:用得极少 select * from tb_name1 cross join tb_name2; 或 select * from tb_name1, tb_name2; 4.2、内连接 select 目标表达式1, 目标表达式2, ... , 目标表达式n from table1 [as] 别名1 [inner] join table2 [as] 别名2 on 连接条件 [where 过滤条件]; select 目标表达式1, 目标表达式2, ... , 目标表达式n from table1, table2 where 连接条件 [and 过滤条件]; 4.2.1、等值于非等值连接 [.] [.]; 4.2.2、自连接 使用自连接时，需要指定多个不同的别名，查询字段都有别名来限定 4.2.3、自然连接 两张表中的字段名都相同才可以使用，否则放回笛卡尔积结果 select 目标表达式1, 目标表达式2, ... , 目标表达式n from table1 [as] 别名1 natural join table2 [as] 别名2; 4.3、外连接 # 左外连接 select 目标表达式1, 目标表达式2, ... , 目标表达式n from table1 [as] 别名1 left [outer] join table2 [as] 别名2 on 连接条件 [where 过滤条件]; # 右外连接 select 目标表达式1, 目标表达式2, ... , 目标表达式n from table1 [as] 别名1 right [outer] join table2 [as] 别名2 on 连接条件 [where 过滤条件]; 5、子查询 子查询关键字：in, any, all, [not]exists, 必要时为表名加上别名 6、联合查询 select -from-where union [all] select -from-where [...union [all] select -from-where] 多个表查询联合起来，不使用all关键字，执行的时候去重，返回的行都是唯一的，使用all则不去重。 五、数据更新 1、插入数据 1.1、插入一条或多条 insert into table(字段名列表) values(值列表1), [,值列表2], ... ,[值列表n]; replace into table(字段名列表) values(值列表1), [,值列表2], ... ,[值列表n]; 1.2、插入查询结果 insert into table1(字段名列表) select (字段名列表) from table2 where(conditions); 2、修改数据记录 update table set 字段名1=值1, 字段名2=值2, ... , 字段名n=值n [where ]; 3、删除数据记录 delete from table [where]; truncate [table] tb_name; 六、索引 1、什么时候需要创建索引 a.主键自动建立唯一索引 b.频繁作为查询条件的字段应该创建索引 c.查询中排序的字段创建索引将大大提高排序的速度（索引就是排序加快速查找 d.查询中统计或者分组的字段； 2、什么时候不需要创建索引 a.频繁更新的字段不适合创建索引，因为每次更新不单单是更新记录，还会更新索引，保存索引文件 b.where条件里用不到的字段，不创建索引； c.表记录太少，不需要创建索引； d.经常增删改的表； e.数据重复且分布平均的字段，因此为经常查询的和经常排序的字段建立索引。注意某些数据包含大量重复数据，因此他建立索引就没有太大的效果，例如性别字段，只有男女，不适合建立索引。 3、索引的分类： a.普通索引：最基本的索引，它没有任何限制 b.唯一索引：索引列的值必须唯一，且不能为空，如果是组合索引，则列值的组合必须唯一。 c.主键索引：特殊的索引，唯一的标识一条记录，不能为空，一般用primary key来约束。 d.联合索引：在多个字段上建立索引，能够加速查询到速度 1、查看数据表上的索引 show {index | indexes | keys} {fron | in } tb_name [{from | in } db_name]; 2、创建索引 2.1、建表时创建 create table(字段名, 字段类型...) [constrint index_name] [unique] [index | key] [index_name](字段列名[长度]) [asc | aesc]; 2.2、使用create index create [unique] index index_name on tb_name(字段名[(长度)] [asc | desc] , ...); 2.3、使用alter table alter table tb_name add [unique | fulltext] [index|key] index_name(字段名[(长度)][asc|desc],...) 3、删除索引 drop index index_name on tb_name; alter table tb_name drop index index_name; 七、视图 1、创建视图 create [or replace] view view_name[(column_list)] as select_statement [with [cascaded | local] check option]; 2、删除视图 drop view [if exists] view_name[,view_name]...; 3、修改视图 alter view view_name [(column_list)] as select_statement [with [cascaded | local] check option]; 4、查看视图定义 show create view view_name\\G 八、触发器 1、创建触发器 create trigger trigger_name trigger_time(before|after) trigger_event(insert|update|delete) on tb_name for each row trigger_body; # 查看已有的触发器 show triggers [{from | in} db_name]; 2、删除触发器 drop trigger [if exists] [schema_name.]trigger_name; 3、使用触发器 在insert触发器中可以引用名为new的虚拟表来访问被插入的行 在delete触发器中可以引用名为old的虚拟表来访问被删除的行 在delete触发器中可以引用名为new的虚拟表来访问更新后的值 在delete触发器中可以引用名为old的虚拟表来访问更新前的值 例子： create trigger tg1 after update on tb_name1 for each row set new.col1 = old.col2; 九、事件(临时触发器) 1、创建事件 create event [if not exists] event_name on schedule 时间调度 [enable|disable|disable on slave] do event_body; 时间调度语法格式： at timestamp [+ interval interval]... | every interval [starts timestamp [+ interval interval]...] [ends timestamp [+ interval interval]...] interval语法格式 quantity {year | quarter | month | day | hour | minute | week | second | year_month | day_hour | day_minute| day_second | hour_minute | hour_second | minute_second} 例子： 每个月向表tb_1插入一条数据，该事件开始于下个月并且结束于2019年12月31日。 首先改变结束符：delimiter {% math %} create event if not exists event_insert on schedule every 1 month starts curdate() + interval 1 month ends '2019-12-31' do begin if year(curdate()) 2、修改事件 alter event event_name [on schedule 时间调度] [rename to new_name] [enable | disable | disable on slave] [do event_body]; 3、删除事件 drop event [if exists] event_name; 十、存储过程和存储函数 1、存储过程 1.1、创建存储过程 create procedure sp_name ([proc_parameter[,...]]) [characteristic...]routine_body 其中proc_parameter格式为 [in | out | inout]param_name type 分别对应输入、输出和输入/输出参数 其中routine_body为存储过程主体： 也称存储过程体，其中包含了在过程调用的时候必须执行的sql语句，这个部分以关键字begin开始，以关键字end结束。如存储过程体中只有一条sql语句，可以省略begin-end标志，另外begin-end可以嵌套。 1.2、存储过程体 1.2.1、局部变量 声明： declare var_name [,...] type [defautl value] ps:局部变量不同意用户变量，区别：局部变量声明时，在其前面没有使用“@”符号，并且它只能在声明它的begin-end语句块中使用，而用户变量前面使用“@”符号，存在整个会话中。 1.2.2、赋值 set var_name = expr[, var_name = expr]... 或 select 字段名 into var_name[,...] 查询源及条件; 1.2.3、流程控制语句 条件 if search_condition then statement_list [elseif search_condition then statement_list]... [else statement_list] end if; 或 case case_vale when when_value then statement_list [when when_value then statement_list] [else statement_list] end case; 或 case when search_condition then statement_list [when search_condition then statement_list] [else statement_list] end case; 循环 [begin_label:]while search_condition do statement_list end while[end_label]; 或 [begin_label:]repeat statement_list until search_condition end repeat[end_label]; 或 [begin_label:]loop statement_list end loop[end_label]; 1.2.4、游标 # 声明游标 declare cursor_name cursor for select_statement; # select_statement为一条select语句注意不能有into子句。 # 打开游标 open cursor_name; # 读取游标 fetch cursor_name into var_name[,var_name]...; # 关闭游标 close cursor_name; # 例子:统计行数 delimiter {% math %} create procedure sp_sum(out rows int) begin declare sno char; declare found boolean default true; declare cur cursor for select studentNo from tb_students; declare continue handler for not found set found = false; set rows = 0; open cur; fetch cur into sno; while found do set rows = rows +1; fetch cur into sno; end while; close cur; end{% endmath %} 1.3、调用存储过程 call sp_name([parameter[,...]]); call sp_name[()]; 1.4、删除存储过程 drop procedure [if exists] sp_name; 2、存储函数 2.1、与存储过程的区别 # 存储函数不能有输出参数，因为存储函数本身就是输出参数，而存储过程可以有输出参数 # 可以直接对存储函数进行调用，不需要使用call # 存储函数必须包含一条return语句，而这条语句不允许包含于存储过程中 2.1、创建存储函数 create function sp_name ([func_parameter[,...]]) returns type routine_body # 例子：根据给定的学号返回学生性别，如果没有则返回“没有该学生” delimiter {% math %} create function fn_student(sno char(10)) returns char(2) begin declare ssex char(2); select sex into ssex from student where studentNo = sno; if ssex is null then return (select \"没有该学生\"); else if ssex=\"女\" then return (select \"女\"); else return (select \"男\"); end if; end{% endmath %} 2.2、调用存储函数 select sp_name([func_parameter[,...]]); 2.3、删除存储函数 drop function [if exists] sp_name; 十一、访问控制与安全管理 1、用户账号与管理 1.1、创建用户账号 create user user_specification [,user_specification]...; 其中user_specification格式： user [indentified by [password] 'password' | identified with 指定认证的插件名称 [as 'auth_string']]; # 例子： create user 'zhangsan@localhost' identified by '123','lisi@localhost' identified by password 'password(字符串)返回的散列值'; 1.2、删除用户 drop user user_name [,user_name]...; 1.3、修改用户账号 rename user old_name to new_name [,old_name to new_name]...; 1.4、修改用户密码 set password [for user] = {password('new_password') | 'encryted password(表示已被password加密的口令值)' } # 如果不加for 则表示给当前用户改密码 2、账号权限管理 2.1、权限的授予 grant priv_type [(column_list)] [,priv_type[(column_list)]]... on [object_type] priv_level to user_specification [,user_specifition]... [require {none|ssl_option[[and]ssl_option]...}] [with with_option...] # priv_type 如：select、update、delete # 其中object_type格式为： table | function | procedure # priv_level格式为： * | *.* | db_name.tb_name | tb_name | db_name.routine_name # user_specifition格式同上面 说明该语句同样可以用来创建用户 # with_option格式为： grant option | max_queries_per_hour count #每小时查询数据库的次数 | max_updates_per_hour count #每小时可以修改数据库的次数 | max_connections_per_hour count #每小时可以连接数据库的次数 | max_user_connections count #同时连接数据库的最大用户数 例子： grant select(studentNo, studentName) on db_school.tb_student to 'lisi@localhost' identifie by '123'; grant all on *.* to 'zhangsan@loclhost' identified by '123'; grant create user on *.* to 'zhangsan@loclhost' identified by '123'; 2.2、权限的转移与限制 2.2.1、转移 with 子句指定为with grant option时，表示to 子句中所指定的所以用户都具有把自己所拥有的权限授予其他用户。 例子： grant select, update on db_school.tb_student to 'lisi@localhost' identified by '123' with grant option; 2.2.2、限制 with子句后面跟关键字 例子： grant delete on db_school.* to 'zhangsan@localhost' identified by '123' with MAX_QUERIES_PER_HOUR 1; 2.3、权限的撤销 # 回收某些特定的权限 revoke priv_type [(column_list)] [,priv_type[(column_list)]]... on [object_type] priv_level form user [,user]...; 或 # 回收特定用户的所有权限 revoke all privileges, grant option form user [,user]; 十二、备份与恢复 1、使用sql语句备份和恢复表数据 1.1、select into ... outfile语句导出备份 select * into outfile 'file_name ' [character set charset_name ] export_options | into dumpfile 'file_name'; # export_options格式： [fields [terminated by 'string'] [[optionally] enclosed by 'char'] [escaped by 'char'] ] [lines terminated by 'string'] 1.2、load data ...infile语句导入恢复 load data [low_priority | concurrent] [local] infile 'file_name.txt' [replace | ignore] into table tb_name [fields [terminated by 'string'] [[optionally] enclosed by 'char'] [escaped by 'char'] ] [lines [starting by 'string'] [terminated by 'string'] ] [IGNORE number LINES] [(col_name_or_user_var,...)] [set col_name = expr, ...]] 例子： # 导出 select * from db_school.tb_student into outfile 'C:\\BACKUP\\backupfiel.txt' fields terminated by ','optionally enclosed by '\"' lines terminated by '?'; # 导出 load data infile 'C:\\BACKUP\\backupfiel.txt' into table db_school.tb_student_copy fields terminated by ',' optionally enclosed by '\"' lines terminated by '?' 2、使用MySQL客服端实用程序备份和恢复数据 2.1、备份表 # 备份数据表 mysqldump [option] database [tables] > filename; # 备份数据库 mysqldump [option] database --database [option] DB1 [DB2 DB3...] > filename; # 备份整个数据库系统 msyqldump [option] --all-database [option] > fielname; # 例子： mysqldump -hlocalhost -uroot -p123 db_school.tb_table > c:\\backup\\file.sql; msyqldump -hlocalhost -uroot -p123 --database db_school > c:\\backup\\data.sql; msyqldump -uroot -p123 --all-database > c:\\backup\\alldata.sql; 2.2、使用mysql命令恢复数据 mysql -uroot -p123 tb_student 3、二进制日志文件的使用 3.1、查看二进制日志文件 msyqlbinlog [option] log_file... [> c:\\backup\\bin_log000001.txt]; 3.2、使用二进制文件恢复数据 msyqlbinlog [option] log_file... | msyql [option] # 例子 msyqlbinlog bin_log0001 | mysql -uroot -p123; 3.3、删除二进制日志文件 # 清除所有日志文件 reset master; # 删除指定的日志文件 purge {master | binary| logs to 'log_name': #删除某个时间之前的所有日志文件 purge {master | binary| logs before 'date'; 十三、MySQL数据库的应用编程 1、使用PHP进行MySQL数据库应用编程 1.1、mysql连接 # 非持久连接 mysql_connect([servername[, username[,password]]]); # 持久连接 mysql_pconnect([servername[, username[,password]]]); ps：如果msyql函数成功执行后连接成功，函数mysql_errno()和mysql_error会分别返回数值0和空字符串。 1.2、选择数据库 msyql_select_db(database[,connection]) 1.3、执行数据库操作 msyql_query(query[,connection]) ps:sql语句是以字符串的形式提交，且不以分号作为结束符。 1.4、数据结果读取 mysql_fetch_array(data[,array_type]) # array_type有： MYSQL_NUM:表示数值数组，功能与mysql_fetch_row(data)一样 MYSQL_ASSOC:表示关联数组，功能与mysql_fetch_assoc(data)一样 MYSQL_BOTH:表示同时产生关联数组和数字数组 mysql_fetch_row(data) msyql_fetch_assoc(data) 1.5、读取结果数目 mysql_num_rows(data) 1.6、读取指定记录号的记录 # 在结果集中随意移动记录的指针，也就是将记录指针直接指向某个记录，其中0指示结果集中的第一条记录。 mysql_data_seek(data,row) 1.7、关闭数据库 msyql_close([content]) # 例子： ’); mysql_select_db('db01',$con) or die('数据库选择失败！‘); mysql_query(\"set names 'gbk'\"); $sql = \"select studentname from tb_student\"; $sql = $sql.\"where studentNo = 200120\"; $result = mysql_query($sql, $con); if ($result){ echo \"学生查询成功！\" $array = mysql_fetch_array($result,MYSQL_NUM); if ($array){ echo \"读取到学生信息！\"; echo \"所查询的学生姓名为：\".$array[0]; } else echo \"没有查询到学生信息！\"; } else echo \"学生信息查询失败！\"; ?> "},"Database/MySQL/数据库三大范式.html":{"url":"Database/MySQL/数据库三大范式.html","title":"数据库三大范式","keywords":"","body":"数据库三大范式 第一范式（1NF）（原子不可分性） 所谓第一范式（1NF）是指在关系模型中，对于添加的一个规范要求，所有的域都应该是原子性的，即数据库表的每一列都是不可分割的原子数据项， 而不能是集合，数组，记录等非原子数据项。即实体中的某个属性有多个值时，必须拆分为不同的属性。 在符合第一范式（1NF）表中的每个域值只能是实体的一个属性或一个属性的一部分。简而言之，第一范式就是无重复的域。 说明：在任何一个关系数据库中，第一范式（1NF）是对关系模式的设计基本要求，一般设计中都必须满足第一范式（1NF）。 不过有些关系模型中突破了1NF的限制，这种称为非1NF的关系模型。换句话说，是否必须满足1NF的最低要求，主要依赖于所使用的关系模型。 第二范式（2NF）（消除非主键部分依赖） 在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖） 第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。 第二范式（2NF）要求数据库表中的每个实例或记录必须可以被唯一地区分。选取一个能区分每个实体的属性或属性组，作为实体的唯一标识。 例如在员工表中的身份证号码即可实现每个一员工的区分，该身份证号码即为候选键，任何一个候选键都可以被选作主键。 在找不到候选键时，可额外增加属性以实现区分，如果在员工关系中，没有对其身份证号进行存储，而姓名可能会在数据库运行的某个时间重复， 无法区分出实体时，设计辟如ID等不重复的编号以实现区分，被添加的编号或ID选作主键。（该主键的添加是在ER设计时添加，不是建库时随意添加） 第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在， 那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列， 以存储各个实例的唯一标识。简而言之，第二范式就是在第一范式的基础上属性完全依赖于主键。 第三范式（3NF）（消除传递依赖） 在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖） 第三范式（3NF）是第二范式（2NF）的一个子集，即满足第三范式（3NF）必须满足第二范式（2NF）。 简而言之，第三范式（3NF）要求一个关系中不包含已在其它关系已包含的非主关键字信息。 例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。 那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。 简而言之，第三范式就是属性不依赖于其它非主属性，也就是在满足2NF的基础上，任何非主属性不得传递依赖于主属性。 范式应用实例 第一范式（1NF） 数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。 在当前的任何关系数据库管理系统（DBMS）中，傻瓜也不可能做出不符合第一范式的数据库，因为这些DBMS不允许你把数据库表的一列再分成二列或多列。 因此，你想在现有的DBMS中设计出不符合第一范式的数据库都是不可能的。 首先我们确定一下要设计的内容包括那些。学号、学生姓名、年龄、性别、课程名称、课程学分、系别、学科成绩，系办地址、系办电话等信息。 为了简单我们暂时只考虑这些字段信息。我们对于这些信息，所关心的问题有如下几个方面。 学生有那些基本信息？ 学生选了那些课，成绩是什么？ 每个课的学分是多少？ 学生属于那个系，系的基本信息是什么？ 第二范式（2NF） 首先我们考虑，把所有这些信息放到一个表中（学号，学生姓名、年龄、性别、课程、课程学分、系别、学科成绩，系办地址、系办电话）下面存在如下的依赖关系。 (学号, 课程名称) → (姓名, 年龄, 成绩, 学分) 问题分析 姓名和年龄不依于课程，即不完全依赖于主属性因此不满足第二范式的要求，会产生如下问题： 数据冗余：同一门课程由n个学生选修，\"学分\"就重复n-1次；同一个学生选修了m门课程，姓名和年龄就重复了m-1次。 更新异常： 1）若调整了某门课程的学分，数据表中所有行的\"学分\"值都要更新，否则会出现同一门课程学分不同的情况。 2）假设要开设一门新的课程，暂时还没有人选修。这样，由于还没有\"学号\"关键字，课程名称和学分也无法记录入数据库。 删除异常 ：假设一批学生已经完成课程的选修，这些选修记录就应该从数据库表中删除。但是，与此同时，课程名称和学分信息也被删除了。很显然，这也会导致插入异常。 解决方案 把选课关系表SelectCourse改为如下三个表： 学生：Student（学号，姓名，年龄，性别，系别，系办地址、系办电话）； 课程：Course（课程名称,学分）； 选课关系：SelectCourse（学号，课程名称，成绩）。 第三范式（3NF） 接着看上面的学生表Student（学号，姓名，年龄，性别，系别，系办地址、系办电话），关键字为单一关键字\"学号\"，因为存在如下决定关系： （学号）→ （姓名，年龄，性别，系别，系办地址、系办电话 但是还存在下面的决定关系： （学号） → (系别）→（系办地点，系办电话） 即存在非关键字段\"系办地点\"、\"系办电话\"对关键字段\"学号\"的传递函数依赖。 它也会存在数据冗余、更新异常、插入异常和删除异常的情况。 根据第三范式把学生关系表分为如下两个表就可以满足第三范式了： 学生：（学号，姓名，年龄，性别，系别）； 系别：（系别，系办地址、系办电话）。 上面的数据库表就是符合I，Ⅱ，Ⅲ范式的，消除了数据冗余、更新异常、插入异常和删除异常。 "},"Database/MySQL/主从复制.html":{"url":"Database/MySQL/主从复制.html","title":"MySQL主从复制","keywords":"","body":"datetime:2019/9/5 10:01 author:nzb MySQL的主从复制 主从复制 两台数据库服务器(Linux服务器), IP分别为192.168.1.110和192.168.1.111,服务器上装上MySQL(版本为5.7) 打开主数据库配置文件：vim /etc/mysql/my.cnf, 加入以下内容后重启MySQL服务 [mysqld] log-bin=mysql-bin server-id=1 （默认为1，总之两台服务器要设置为不同的ID） 打开从数据库配置文件：vim /etc/mysql/my.cnf, 加入相同内容后将其中的 server-id 设为2（默认为1）然后重启MySQL服务 设192.168.1.110为主数据库, 在数据库中加入一个从服务器可以登录的用户, 语句如下： GRANT ALL PRIVILEGES ON *.* TO 'user'@'192.168.1.111' IDENTIFIED BY 'password' WITH GRANT OPTION;(或 GRANT REPLICATION SLAVE ON *.* TO 'username'@'192.168.1.111' IDENTIFIED BY 'password' WITH GRANT OPTION;) FLUSH PRIVILEGES; 完成后, 在192.168.1.111服务器上执行：mysql -h 192.168.1.110 -u用户名 -p密码, 查看连接是否成功 最后在主数据库中执行以下语句, 查询master状态：show master status; 可以看到以上结果，这儿只需要看 File 和 Position，其它的两个分别是白名单和黑名单，意思为同步哪几个数据库和不同步哪几个数据库，可自行根据需求进行设置。记录了前两个字段后，在从库上执行以下语句： CHANGE MASTER TO MASTER_HOST='192.168.1.110', MASTER_USER='user', MASTER_PASSWORD='password', MASTER_PORT='3306', MASTER_LOG_FILE='mysql-bin.000020', MASTER_LOG_POS=1441; 执行完成后, 在从数据库上继续执行以下语句： start slava; show slave status\\G; 这样，查看从服务器的状态，如果状态中的用红线标出来两个参数的值都为YES，那证明配置已经成功，否则可以检查一下具体问题出现在什么地方。 这样，就算配置完成了。在主库中新建数据库，新建一张表，插几条数据，到从库上查询一下看是否已经同步过来。 PS:如果失败，可以从以下几个方面去排查问题：　　 1.首先试一下主从服务器相互之间是否 PING 得通 2.试一下远程连接是否正确，如果连不上，则有可能是网卡不一致、防火墙没有放行 3306 端口 3.server-id 是否配成一致 4.bin-log 的信息是否正确 主主复制 上面说了主从复制的配置方法，现在接着上面的配置继续，然后实现双主复制，让以上的两个服务器互为主从。 在主服务器上配置 /etc/mysql/my.cnf 文件，配置如下,配置之后重启MYSQL服务: auto_increment_increment=2 #步进值auto_imcrement。一般有n台主MySQL就填n auto_increment_offset=1 #起始值。一般填第n台主MySQL。此时为第一台主MySQL binlog-ignore=mysql #忽略mysql库【一般都不写】 binlog-ignore=information_schema #忽略information_schema库【一般都不写】 在从服务器上配置 /etc/mysql/my.cnf 文件，配置如下, 配置之后重启MYSQL服务: auto_increment_increment=2 #步进值auto_imcrement。一般有n台主MySQL就填n auto_increment_offset=2 #起始值。一般填第n台主MySQL。此时为第二台主MySQL binlog-ignore=mysql #忽略mysql库【一般都不写】 binlog-ignore=information_schema #忽略information_schema库【一般都不写】 在从服务器上添加一个主服务器可以访问的用户，命令如下： GRANT REPLICATION SLAVE ON *.* TO 'user'@'192.168.1.110' IDENTIFIED BY 'password' with grant option ; FLUSH PRIVILEGES 建好之后在192.168.1.110服务器上访问从数据库, 测试是否成功，如果可以连上，则进行下一步，连不上的话，参考上面进行问题排查。 因为要互为主从，所以现在从服务器也是master ，所以也要查看一下状态：show master status; 查到相应的信息后，在原来的主服务器上执行以下命令（因为现在它现在也是另一台的从服务器） CHANGE MASTER TO MASTER_HOST='192.168.1.111', MASTER_USER='user', MASTER_PASSWORD='password', MASTER_LOG_FILE='mysql-bin.000021', MASTER_LOG_POS=1457; 执行完毕后，在原主库上继续执行如下语句： start slave; show slave status\\G; 同上，如果出现如下画面，则证明配置成功。 在两台服务器的MYSQL中分别进行一些建库、建表、插入、更新等操作，看一下另一台会不会进行同步，如果可以则证明主主配置成功，否则还是上面的排错方法，进行错误排查。 双主多从 现在已经是双主配置了，但是如果要进行读写分离，那么我们要再增加N台从库，如何做呢？非常简单，按如下操作即可： 新增加一台数据库服务器，192.168.1.112，数据库配置均与前两台相同 确定一下要将哪一台当作自己的主服务器，我们姑且设 192.168.1.110 为主服务器 在第三台服务器中编辑 /etc/mysql/my.cnf ，将其 server-id 设为 3（保证与前两个不一样即可），然后重启MYSQL服务 在主服务器中，增加一条用户记录，用于当前服务器对主库对的连接，代码如下： GRANT REPLICATION SLAVE ON *.* TO 'user'@'192.168.1.112' IDENTIFIED BY 'password'; FLUSH PRIVILEGES; 在 192.168.216.130 服务器上测试是否可以连接到主库: mysql -h 192.168.1.110 -u用户名 -p密码, 如果可以连上，则可以进行下一步，否则根据上面的提示排查问题。 在 192.168.216.130 服务器上查询 master 当前状态: show master status; 看到相关信息后，我们执行如下操作： CHANGE MASTER TO MASTER_HOST='192.168.1.110', MASTER_USER='user', MASTER_PASSWORD='password', MASTER_LOG_FILE='mysql-bin.000020', MASTER_LOG_POS=1441; 执行完毕后，在原主库上继续执行如下语句： start slave; show slave status\\G; 同上，如果出现如下画面，则证明配置成功。如果此处有问题，参考上面所提排查并解决问题。 此时我们在 192.168.1.110 上建库、建表、插入、更新、删除数据，在 另外两台上分别进行查看，发现均已经同步。 但是如果我们在 192.168.1.111 上做相应的操作，则发现只有 192.168.1.110 上进行了相应的同步，而 192.168.1.112 上的数据并未同步。 这是为什么呢？因为我们设置的主库是 192.168.1.110，所以在 192.168.1.111 进行数据操作的时候并未同步，这显然不符合我们的需求， 那么，我们要怎么修改呢？非常简单，在互为主从的两台服务器的配置文件中均加入以下语句：log-slave-updates=on 加上后将两台服务器的MYSQL重启，然后再进行测试，发现数据已经可以同步了。如果要再多加一些从服务器，和以上类似，现在我们做的是双主一从，我们可以再加N台从服务器，配置也是一样的。 至此，MYSQL主从复制、主主复制、双主多从配置我们均已经搞定！ Docker配置MySQL主从复制 下面还是基于Docker来演示如何配置MySQL主从复制。我们事先准备好MySQL的配置文件以及保存MySQL数据和运行日志的目录，然后通过Docker的数据卷映射来指定容器的配置、数据和日志文件的位置。 root └── mysql ├── master │ ├── conf | └── data └── slave-1 | ├── conf | └── data └── slave-2 | ├── conf | └── data └── slave-3 ├── conf └── data MySQL的配置文件（master和slave的配置文件需要不同的server-id）。 [mysqld] pid-file=/var/run/mysqld/mysqld.pid socket=/var/run/mysqld/mysqld.sock datadir=/var/lib/mysql log-error=/var/log/mysql/error.log server-id=1 log-bin=/var/log/mysql/mysql-bin.log expire_logs_days=30 max_binlog_size=256M symbolic-links=0 # slow_query_log=ON # slow_query_log_file=/var/log/mysql/slow.log # long_query_time=1 创建和配置master。 docker run -d -p 3306:3306 --name mysql-master \\ -v /root/mysql/master/conf:/etc/mysql/mysql.conf.d \\ -v /root/mysql/master/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7 docker exec -it mysql-master /bin/bash mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 1 Server version: 5.7.23-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> grant replication slave on *.* to 'slave'@'%' identified by 'iamslave'; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.00 sec) mysql> show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000003 | 590 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) mysql> quit Bye exit 上面创建Docker容器时使用的-v参数（--volume）表示映射数据卷，冒号前是宿主机的目录，冒号后是容器中的目录，这样相当于将宿主机中的目录挂载到了容器中。 创建和配置slave。 docker run -d -p 3308:3306 --name mysql-slave-1 \\ -v /root/mysql/slave-1/conf:/etc/mysql/mysql.conf.d \\ -v /root/mysql/slave-1/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ --link mysql-master:mysql-master mysql:5.7 docker run -d -p 3309:3306 --name mysql-slave-2 \\ -v /root/mysql/slave-2/conf:/etc/mysql/mysql.conf.d \\ -v /root/mysql/slave-2/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ --link mysql-master:mysql-master mysql:5.7 docker run -d -p 3310:3306 --name mysql-slave-3 \\ -v /root/mysql/slave-3/conf:/etc/mysql/mysql.conf.d \\ -v /root/mysql/slave-3/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ --link mysql-master:mysql-master mysql:5.7 docker exec -it mysql-slave-1 /bin/bash mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.23-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> reset slave; Query OK, 0 rows affected (0.02 sec) mysql> change master to master_host='mysql-master', master_user='slave', master_password='iamslave', master_log_file='mysql-bin.000003', master_log_pos=590; Query OK, 0 rows affected, 2 warnings (0.03 sec) mysql> start slave; Query OK, 0 rows affected (0.01 sec) mysql> show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: mysql57 Master_User: slave Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 590 Relay_Log_File: f352f05eb9d0-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 590 Relay_Log_Space: 534 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: 30c38043-ada1-11e8-8fa1-0242ac110002 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec) mysql> quit Bye exit 接下来可以如法炮制配置出slave2和slave3，这样就可以搭建起一个“一主带三从”的主从复制环境。上面创建创建容器时使用的--link参数用来配置容器在网络上的主机名（网络地址别名）。 配置好主从复制后，写数据的操作应该master上执行，而读数据的操作应该在slave上完成。为此，在Django项目中需要配置DATABASE_ROUTERS并通过自定义的主从复制路由类来实现读写分离操作，如下所示： DATABASE_ROUTERS = [ # 此处省略其他配置 'common.routers.MasterSlaveRouter', ] class MasterSlaveRouter(object): \"\"\"主从复制路由\"\"\" @staticmethod def db_for_read(model, **hints): \"\"\" Attempts to read auth models go to auth_db. \"\"\" return random.choice(('slave1', 'slave2', 'slave3')) @staticmethod def db_for_write(model, **hints): \"\"\" Attempts to write auth models go to auth_db. \"\"\" return 'default' @staticmethod def allow_relation(obj1, obj2, **hints): \"\"\" Allow relations if a model in the auth app is involved. \"\"\" return None @staticmethod def allow_migrate(db, app_label, model_name=None, **hints): \"\"\" Make sure the auth app only appears in the 'auth_db' database. \"\"\" return True 上面的内容参考了Django官方文档的DATABASE_ROUTERS配置，对代码进行了适当的调整。 "},"Database/NoSQL/01-NoSql入门.html":{"url":"Database/NoSQL/01-NoSql入门.html","title":"NoSql入门","keywords":"","body":"datetime:2019/10/29 16:41 author:nzb NoSQL入门 NoSQL概述 如今，大多数的计算机系统（包括服务器、PC、移动设备等）都会产生庞大的数据量。其实，早在2012年的时候，全世界每天产生的数据量就达到了2.5EB（艾字节，1EB\\approx10^{18}B）。这些数据有很大一部分是由关系型数据库来存储和管理的。 早在1970年，E.F.Codd发表了论述关系型数据库的著名论文“A relational model of data for large shared data banks”，这篇文章奠定了关系型数据库的基础并在接下来的数十年时间内产生了深远的影响。实践证明，关系型数据库是实现数据持久化最为重要的方式，它也是大多数应用在选择持久化方案时的首选技术。 NoSQL是一项全新的数据库革命性运动，虽然它的历史可以追溯到1998年，但是NoSQL真正深入人心并得到广泛的应用是在进入大数据时候以后，业界普遍认为NoSQL是更适合大数据存储的技术方案，这才使得NoSQL的发展达到了前所未有的高度。2012年《纽约时报》的一篇专栏中写到，大数据时代已经降临，在商业、经济及其他领域中，决策将不再基于经验和直觉而是基于数据和分析而作出。事实上，在天文学、气象学、基因组学、生物学、社会学、互联网搜索引擎、金融、医疗、社交网络、电子商务等诸多领域，由于数据过于密集和庞大，在数据的分析和处理上也遇到了前所未有的限制和阻碍，这一切都使得对大数据处理技术的研究被提升到了新的高度，也使得各种NoSQL的技术方案进入到了公众的视野。 NoSQL数据库按照其存储类型可以大致分为以下几类： 类型 部分代表 特点 列族数据库 HBaseCassandraHypertable 顾名思义是按列存储数据的。最大的特点是方便存储结构化和半结构化数据，方便做数据压缩，对针对某一列或者某几列的查询有非常大的I/O优势，适合于批量数据处理和即时查询。 文档数据库 MongoDBCouchDBElasticSearch 文档数据库一般用类JSON格式存储数据，存储的内容是文档型的。这样也就有机会对某些字段建立索引，实现关系数据库的某些功能，但不提供对参照完整性和分布事务的支持。 KV数据库 DynamoDBRedisLevelDB 可以通过key快速查询到其value，有基于内存和基于磁盘两种实现方案。 图数据库 Neo4JFlockDBJanusGraph 使用图结构进行语义查询的数据库，它使用节点、边和属性来表示和存储数据。图数据库从设计上，就可以简单快速的检索难以在关系系统中建模的复杂层次结构。 对象数据库 db4oVersant 通过类似面向对象语言的语法操作数据库，通过对象的方式存取数据。 说明：想了解更多的NoSQL数据库，可以访问http://nosql-database.org/。 Redis概述 Redis是一种基于键值对的NoSQL数据库，它提供了对多种数据类型（字符串、哈希、列表、集合、有序集合、位图等）的支持，能够满足很多应用场景的需求。Redis将数据放在内存中，因此读写性能是非常惊人的。与此同时，Redis也提供了持久化机制，能够将内存中的数据保存到硬盘上，在发生意外状况时数据也不会丢掉。此外，Redis还支持键过期、地理信息运算、发布订阅、事务、管道、Lua脚本扩展等功能，总而言之，Redis的功能和性能都非常强大，如果项目中要实现高速缓存和消息队列这样的服务，直接交给Redis就可以了。目前，国内外很多著名的企业和商业项目都使用了Redis，包括：Twitter、Github、StackOverflow、新浪微博、百度、优酷土豆、美团、小米、唯品会等。 Redis简介 2008年，一个名为Salvatore Sanfilippo的程序员为他开发的LLOOGG项目定制了专属的数据库（因为之前他无论怎样优化MySQL，系统性能已经无法再提升了），这项工作的成果就是Redis的初始版本。后来他将Redis的代码放到了全球最大的代码托管平台Github，从那以后，Redis引发了大量开发者的好评和关注，继而有数百人参与了Redis的开发和维护，这使得Redis的功能越来越强大和性能越来越好。 Redis是REmote DIctionary Server的缩写，它是一个用ANSI C编写的高性能的key-value存储系统，与其他的key-value存储系统相比，Redis有以下一些特点（也是优点）： Redis的读写性能极高，并且有丰富的特性（发布/订阅、事务、通知等）。 Redis支持数据的持久化（RDB和AOF两种方式），可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis支持多种数据类型，包括：string、hash、list、set，zset、bitmap、hyperloglog等。 Redis支持主从复制（实现读写分析）以及哨兵模式（监控master是否宕机并自动调整配置）。 Redis支持分布式集群，可以很容易的通过水平扩展来提升系统的整体性能。 Redis基于TCP提供的可靠传输服务进行通信，很多编程语言都提供了Redis客户端支持。 Redis的应用场景 高速缓存 - 将不常变化但又经常被访问的热点数据放到Redis数据库中，可以大大降低关系型数据库的压力，从而提升系统的响应性能。 排行榜 - 很多网站都有排行榜功能，利用Redis中的列表和有序集合可以非常方便的构造各种排行榜系统。 商品秒杀/投票点赞 - Redis提供了对计数操作的支持，网站上常见的秒杀、点赞等功能都可以利用Redis的计数器通过+1或-1的操作来实现，从而避免了使用关系型数据的update操作。 分布式锁 - 利用Redis可以跨多台服务器实现分布式锁（类似于线程锁，但是能够被多台机器上的多个线程或进程共享）的功能，用于实现一个阻塞式操作。 消息队列 - 消息队列和高速缓存一样，是一个大型网站不可缺少的基础服务，可以实现业务解耦和非实时业务削峰等特性，这些我们都会在后面的项目中为大家展示。 Redis的安装和配置 可以使用Linux系统的包管理工具（如yum）来安装Redis，也可以通过在Redis的官方网站下载Redis的源代码，解压缩解归档之后通过make工具对源代码进行构建并安装，在更新这篇文档时，Redis官方提供的最新稳定版本是Redis 5.0.4。 wget http://download.redis.io/releases/redis-5.0.4.tar.gz gunzip redis-5.0.4.tar.gz tar -xvf redis-5.0.4.tar cd redis-5.0.4 make && make install 在redis源代码目录下有一个名为redis.conf的配置文件，我们可以先查看一下该文件。 vim redis.conf 配置将Redis服务绑定到指定的IP地址和端口。 配置底层有多少个数据库。 配置Redis的持久化机制 - RDB。 配置Redis的持久化机制 - AOF。 配置访问Redis服务器的验证口令。 配置Redis的主从复制，通过主从复制可以实现读写分离。 配置慢查询。 上面这些内容就是Redis的基本配置，如果你对上面的内容感到困惑也没有关系，先把Redis用起来再回头去推敲这些内容就行了。如果想找一些参考书，《Redis开发与运维》是一本不错的入门读物，而《Redis实战》是不错的进阶读物。 Redis的服务器和客户端 接下来启动Redis服务器，下面的方式将以默认的配置启动Redis服务。 redis-server 如果希望修改Redis的配置（如端口、认证口令、持久化方式等），可以通过下面两种方式。 方式一：通过参数指定认证口令和AOF持久化方式。 redis-server --requirepass 1qaz2wsx --appendonly yes 方式二：通过指定的配置文件来修改Redis的配置。 redis-server /root/redis-5.0.4/redis.conf 下面我们使用第一种方式来启动Redis并将其置于后台运行，将Redis产生的输出重定向到名为redis.log的文件中。 redis-server --requirepass 1qaz2wsx > redis.log & 可以通过ps或者netstat来检查Redis服务器是否启动成功。 ps -ef | grep redis-server netstat -nap | grep redis-server 接下来，我们尝试用Redis客户端去连接服务器。 redis-cli 127.0.0.1:6379> auth 1qaz2wsx OK 127.0.0.1:6379> ping PONG 127.0.0.1:6379> Redis有着非常丰富的数据类型，也有很多的命令来操作这些数据，具体的内容可以查看Redis命令参考，在这个网站上，除了Redis的命令参考，还有Redis的详细文档，其中包括了通知、事务、主从复制、持久化、哨兵、集群等内容。 说明：上面的插图来自付磊和张益军先生编著的《Redis开发与运维》一书。 127.0.0.1:6379> set username admin OK 127.0.0.1:6379> get username \"admin\" 127.0.0.1:6379> set password \"123456\" ex 300 OK 127.0.0.1:6379> get password \"123456\" 127.0.0.1:6379> ttl username (integer) -1 127.0.0.1:6379> ttl password (integer) 286 127.0.0.1:6379> hset stu1 name hao (integer) 0 127.0.0.1:6379> hset stu1 age 38 (integer) 1 127.0.0.1:6379> hset stu1 gender male (integer) 1 127.0.0.1:6379> hgetall stu1 1) \"name\" 2) \"hao\" 3) \"age\" 4) \"38\" 5) \"gender\" 6) \"male\" 127.0.0.1:6379> hvals stu1 1) \"hao\" 2) \"38\" 3) \"male\" 127.0.0.1:6379> hmset stu2 name wang age 18 gender female tel 13566778899 OK 127.0.0.1:6379> hgetall stu2 1) \"name\" 2) \"wang\" 3) \"age\" 4) \"18\" 5) \"gender\" 6) \"female\" 7) \"tel\" 8) \"13566778899\" 127.0.0.1:6379> lpush nums 1 2 3 4 5 (integer) 5 127.0.0.1:6379> lrange nums 0 -1 1) \"5\" 2) \"4\" 3) \"3\" 4) \"2\" 5) \"1\" 127.0.0.1:6379> lpop nums \"5\" 127.0.0.1:6379> lpop nums \"4\" 127.0.0.1:6379> rpop nums \"1\" 127.0.0.1:6379> rpop nums \"2\" 127.0.0.1:6379> sadd fruits apple banana orange apple grape grape (integer) 4 127.0.0.1:6379> scard fruits (integer) 4 127.0.0.1:6379> smembers fruits 1) \"grape\" 2) \"orange\" 3) \"banana\" 4) \"apple\" 127.0.0.1:6379> sismember fruits apple (integer) 1 127.0.0.1:6379> sismember fruits durian (integer) 0 127.0.0.1:6379> sadd nums1 1 2 3 4 5 (integer) 5 127.0.0.1:6379> sadd nums2 2 4 6 8 (integer) 4 127.0.0.1:6379> sinter nums1 nums2 1) \"2\" 2) \"4\" 127.0.0.1:6379> sunion nums1 nums2 1) \"1\" 2) \"2\" 3) \"3\" 4) \"4\" 5) \"5\" 6) \"6\" 7) \"8\" 127.0.0.1:6379> sdiff nums1 nums2 1) \"1\" 2) \"3\" 3) \"5\" 127.0.0.1:6379> zadd topsinger 5234 zhangxy 1978 chenyx 2235 zhoujl 3520 xuezq (integer) 4 127.0.0.1:6379> zrange topsinger 0 -1 withscores 1) \"chenyx\" 2) \"1978\" 3) \"zhoujl\" 4) \"2235\" 5) \"xuezq\" 6) \"3520\" 7) \"zhangxy\" 8) \"5234\" 127.0.0.1:6379> zrevrange topsinger 0 -1 1) \"zhangxy\" 2) \"xuezq\" 3) \"zhoujl\" 4) \"chenyx\" 127.0.0.1:6379> geoadd pois 116.39738549206541 39.90862689286386 tiananmen 116.27172936413572 39.99 135172904494 yiheyuan 117.27766503308104 40.65332064313784 gubeishuizhen (integer) 3 127.0.0.1:6379> geodist pois tiananmen gubeishuizhen km \"111.5333\" 127.0.0.1:6379> geodist pois tiananmen yiheyuan km \"14.1230\" 127.0.0.1:6379> georadius pois 116.86499108288572 40.40149669363615 50 km withdist 1) 1) \"gubeishuizhen\" 2) \"44.7408\" 在Python程序中使用Redis 可以使用pip安装redis模块。redis模块的核心是名为Redis的类，该类的对象代表一个Redis客户端，通过该客户端可以向Redis服务器发送命令并获取执行的结果。上面我们在Redis客户端中使用的命令基本上就是Redis对象可以接收的消息，所以如果了解了Redis的命令就可以在Python中玩转Redis。 pip3 install redis python3 >>> import redis >>> client = redis.Redis(host='1.2.3.4', port=6379, password='1qaz2wsx') >>> client.set('username', 'admin') True >>> client.hset('student', 'name', 'hao') 1 >>> client.hset('student', 'age', 38) 1 >>> client.keys('*') [b'username', b'student'] >>> client.get('username') b'admin' >>> client.hgetall('student') {b'name': b'hao', b'age': b'38'} MongoDB概述 MongoDB简介 MongoDB是2009年问世的一个面向文档的数据库管理系统，由C++语言编写，旨在为Web应用提供可扩展的高性能数据存储解决方案。虽然在划分类别的时候后，MongoDB被认为是NoSQL的产品，但是它更像一个介于关系数据库和非关系数据库之间的产品，在非关系数据库中它功能最丰富，最像关系数据库。 MongoDB将数据存储为一个文档，一个文档由一系列的“键值对”组成，其文档类似于JSON对象，但是MongoDB对JSON进行了二进制处理（能够更快的定位key和value），因此其文档的存储格式称为BSON。关于JSON和BSON的差别大家可以看看MongoDB官方网站的文章《JSON and BSON》。 目前，MongoDB已经提供了对Windows、MacOS、Linux、Solaris等多个平台的支持，而且也提供了多种开发语言的驱动程序，Python当然是其中之一。 MongoDB的安装和配置 可以从MongoDB的官方下载链接下载MongoDB，官方为Windows系统提供了一个Installer程序，而Linux和MacOS则提供了压缩文件。下面简单说一下Linux系统如何安装和配置MongoDB。 wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-amazon-3.6.5.tgz gunzip mongodb-linux-x86_64-amazon-3.6.5.tgz mkdir mongodb-3.6.5 tar -xvf mongodb-linux-x86_64-amazon-3.6.5.tar --strip-components 1 -C mongodb-3.6.5/ export PATH=$PATH:~/mongodb-3.6.5/bin mkdir -p /data/db mongod --bind_ip 172.18.61.250 2018-06-03T18:03:28.232+0800 I CONTROL [initandlisten] MongoDB starting : pid=1163 port=27017 dbpath=/data/db 64-bit host=iZwz97tbgo9lkabnat2lo8Z 2018-06-03T18:03:28.232+0800 I CONTROL [initandlisten] db version v3.6.5 2018-06-03T18:03:28.232+0800 I CONTROL [initandlisten] git version: a20ecd3e3a174162052ff99913bc2ca9a839d618 2018-06-03T18:03:28.232+0800 I CONTROL [initandlisten] OpenSSL version: OpenSSL 1.0.0-fips29 Mar 2010 ... 2018-06-03T18:03:28.945+0800 I NETWORK [initandlisten] waiting for connections on port 27017 说明：上面的操作中，export命令是设置PATH环境变量，这样可以在任意路径下执行mongod来启动MongoDB服务器。MongoDB默认保存数据的路径是/data/db目录，为此要提前创建该目录。此外，在使用mongod启动MongoDB服务器时，--bind_ip参数用来将服务绑定到指定的IP地址，也可以用--port参数来指定端口，默认端口为27017。 MongoDB基本概念 我们通过与关系型数据库进行对照的方式来说明MongoDB中的一些概念。 SQL MongoDB 解释（SQL/MongoDB） database database 数据库/数据库 table collection 二维表/集合 row document 记录（行）/文档 column field 字段（列）/域 index index 索引/索引 table joins --- 表连接/嵌套文档 primary key primary key 主键/主键（_id字段） 通过Shell操作MongoDB 启动服务器后可以使用交互式环境跟服务器通信，如下所示。 mongo --host 172.18.61.250 MongoDB shell version v3.6.5 connecting to: mongodb://172.18.61.250:27017/ 查看、创建和删除数据库。 > // 显示所有数据库 > show dbs admin 0.000GB config 0.000GB local 0.000GB > // 创建并切换到school数据库 > use school switched to db school > // 删除当前数据库 > db.dropDatabase() { \"ok\" : 1 } > 创建、删除和查看集合。 > // 创建并切换到school数据库 > use school switched to db school > // 创建colleges集合 > db.createCollection('colleges') { \"ok\" : 1 } > // 创建students集合 > db.createCollection('students') { \"ok\" : 1 } > // 查看所有集合 > show collections colleges students > // 删除colleges集合 > db.colleges.drop() true > 说明：在MongoDB中插入文档时如果集合不存在会自动创建集合，所以也可以按照下面的方式通过创建文档来创建集合。 文档的CRUD操作。 > // 向students集合插入文档 > db.students.insert({stuid: 1001, name: '骆昊', age: 38}) WriteResult({ \"nInserted\" : 1 }) > // 向students集合插入文档 > db.students.save({stuid: 1002, name: '王大锤', tel: '13012345678', gender: '男'}) WriteResult({ \"nInserted\" : 1 }) > // 查看所有文档 > db.students.find() { \"_id\" : ObjectId(\"5b13c72e006ad854460ee70b\"), \"stuid\" : 1001, \"name\" : \"骆昊\", \"age\" : 38 } { \"_id\" : ObjectId(\"5b13c790006ad854460ee70c\"), \"stuid\" : 1002, \"name\" : \"王大锤\", \"tel\" : \"13012345678\", \"gender\" : \"男\" } > // 更新stuid为1001的文档 > db.students.update({stuid: 1001}, {'$set': {tel: '13566778899', gender: '男'}}) WriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 }) > // 插入或更新stuid为1003的文档 > db.students.update({stuid: 1003}, {'$set': {name: '白元芳', tel: '13022223333', gender: '男'}}, upsert=true) WriteResult({ \"nMatched\" : 0, \"nUpserted\" : 1, \"nModified\" : 0, \"_id\" : ObjectId(\"5b13c92dd185894d7283efab\") }) > // 查询所有文档 > db.students.find().pretty() { \"_id\" : ObjectId(\"5b13c72e006ad854460ee70b\"), \"stuid\" : 1001, \"name\" : \"骆昊\", \"age\" : 38, \"gender\" : \"男\", \"tel\" : \"13566778899\" } { \"_id\" : ObjectId(\"5b13c790006ad854460ee70c\"), \"stuid\" : 1002, \"name\" : \"王大锤\", \"tel\" : \"13012345678\", \"gender\" : \"男\" } { \"_id\" : ObjectId(\"5b13c92dd185894d7283efab\"), \"stuid\" : 1003, \"gender\" : \"男\", \"name\" : \"白元芳\", \"tel\" : \"13022223333\" } > // 查询stuid大于1001的文档 > db.students.find({stuid: {'$gt': 1001}}).pretty() { \"_id\" : ObjectId(\"5b13c790006ad854460ee70c\"), \"stuid\" : 1002, \"name\" : \"王大锤\", \"tel\" : \"13012345678\", \"gender\" : \"男\" } { \"_id\" : ObjectId(\"5b13c92dd185894d7283efab\"), \"stuid\" : 1003, \"gender\" : \"男\", \"name\" : \"白元芳\", \"tel\" : \"13022223333\" } > // 查询stuid大于1001的文档只显示name和tel字段 > db.students.find({stuid: {'$gt': 1001}}, {_id: 0, name: 1, tel: 1}).pretty() { \"name\" : \"王大锤\", \"tel\" : \"13012345678\" } { \"name\" : \"白元芳\", \"tel\" : \"13022223333\" } > // 查询name为“骆昊”或者tel为“13022223333”的文档 > db.students.find({'$or': [{name: '骆昊'}, {tel: '13022223333'}]}, {_id: 0, name: 1, tel: 1}).pretty() { \"name\" : \"骆昊\", \"tel\" : \"13566778899\" } { \"name\" : \"白元芳\", \"tel\" : \"13022223333\" } > // 查询学生文档跳过第1条文档只查1条文档 > db.students.find().skip(1).limit(1).pretty() { \"_id\" : ObjectId(\"5b13c790006ad854460ee70c\"), \"stuid\" : 1002, \"name\" : \"王大锤\", \"tel\" : \"13012345678\", \"gender\" : \"男\" } > // 对查询结果进行排序(1表示升序，-1表示降序) > db.students.find({}, {_id: 0, stuid: 1, name: 1}).sort({stuid: -1}) { \"stuid\" : 1003, \"name\" : \"白元芳\" } { \"stuid\" : 1002, \"name\" : \"王大锤\" } { \"stuid\" : 1001, \"name\" : \"骆昊\" } > // 在指定的一个或多个字段上创建索引 > db.students.ensureIndex({name: 1}) { \"createdCollectionAutomatically\" : false, \"numIndexesBefore\" : 1, \"numIndexesAfter\" : 2, \"ok\" : 1 } > 使用MongoDB可以非常方便的配置数据复制，通过冗余数据来实现数据的高可用以及灾难恢复，也可以通过数据分片来应对数据量迅速增长的需求。关于MongoDB更多的操作可以查阅官方文档 ，同时推荐大家阅读Kristina Chodorow写的《MongoDB权威指南》。 在Python程序中操作MongoDB 可以通过pip安装pymongo来实现对MongoDB的操作。 pip3 install pymongo python3 >>> from pymongo import MongoClient >>> client = MongoClient('mongodb://127.0.0.1:27017') >>> db = client.school >>> for student in db.students.find(): ... print('学号:', student['stuid']) ... print('姓名:', student['name']) ... print('电话:', student['tel']) ... 学号: 1001.0 姓名: 骆昊 电话: 13566778899 学号: 1002.0 姓名: 王大锤 电话: 13012345678 学号: 1003.0 姓名: 白元芳 电话: 13022223333 >>> db.students.find().count() 3 >>> db.students.remove() {'n': 3, 'ok': 1.0} >>> db.students.find().count() 0 >>> coll = db.students >>> from pymongo import ASCENDING >>> coll.create_index([('name', ASCENDING)], unique=True) 'name_1' >>> coll.insert_one({'stuid': int(1001), 'name': '骆昊', 'gender': True}) >>> coll.insert_many([{'stuid': int(1002), 'name': '王大锤', 'gender': False}, {'stuid': int(1003), 'name': '白元芳', 'gender': True}]) >>> for student in coll.find({'gender': True}): ... print('学号:', student['stuid']) ... print('姓名:', student['name']) ... print('性别:', '男' if student['gender'] else '女') ... 学号: 1001 姓名: 骆昊 性别: 男 学号: 1003 姓名: 白元芳 性别: 男 >>> 关于PyMongo更多的知识可以通过它的官方文档进行了解，也可以使用MongoEngine这样的库来简化Python程序对MongoDB的操作，除此之外，还有以异步I/O方式访问MongoDB的三方库motor都是不错的选择。 "},"Database/NoSQL/Redis/02-Redis安装与配置文件.html":{"url":"Database/NoSQL/Redis/02-Redis安装与配置文件.html","title":"Redis安装与配置文件","keywords":"","body":"datetime:2019/10/30 16:26 author:nzb Redis安装与配置文件 安装 Linux安装 可以使用Linux系统的包管理工具（如yum）来安装Redis，也可以通过在Redis的官方网站下载Redis的源代码，解压缩解归档之后通过make工具对源代码进行构建并安装，在更新这篇文档时，Redis官方提供的最新稳定版本是Redis 5.0.4。 wget http://download.redis.io/releases/redis-5.0.4.tar.gz gunzip redis-5.0.4.tar.gz tar -xvf redis-5.0.4.tar cd redis-5.0.4 make && make install Docker安装 搜索镜像 docker search redis 拉取镜像 docker pull redis 创建redis容器 docker run -d --name redis --restart always -p 6379:6379 -v /usr/local/redis/data:/data redis --requirepass \"123456\" --appendonly yes 创建redis容器（指定配置文件） docker run -d --name redis --restart always -p 6379:6379 -v /usr/local/redis/config:/usr/local/redis/conf/redis.conf -v /usr/local/redis/data:/data redis redis-server /usr/local/redis/conf/redis.conf --requirepass \"123456\" --appendonly yes docker run -d --name redis --restart always -p 6379:6379 -v /usr/local/redis/data:/data redis --requirepass \"123456\" --appendonly yes 参数说明： -p 6379:6379　　//容器redis端口6379映射宿主主机6379 --name redis　　//容器名字为redis -v /usr/local/redis/conf:/usr/local/redis/conf/redis.conf//docker镜像redis默认无配置文件，在宿主主机/usr/local/redis/conf下创建redis.conf配置文件，会将宿主机的配置文件复制到docker中(加上这参数会报错) -v /root/redis/redis01/data:/data　　//容器/data映射到宿主机 /usr/local/redis/data下 -d redis 　　//后台模式启动redis redis-server /usr/local/redis/conf/redis.conf//redis将以/usr/local/redis/conf/redis.conf为配置文件启动(加上这参数会报错) --appendonly yes　　//开启redis的AOF持久化，默认为false，不持久化 redis.conf配置文件详解 # Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no # 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid # 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口， 因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字 port 6379 # 绑定的主机地址 bind 127.0.0.1 # 当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 300 # 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning， 默认为verbose loglevel verbose # 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志 记录方式为标准输出，则日志将会发送给/dev/null logfile stdout # 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id databases 16 # 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 # 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 # 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间， 可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes # 指定本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb # 指定本地数据库存放目录 dir ./ # 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 slaveof # 当master服务设置了密码保护时，slav服务连接master的密码 masterauth # 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭 requirepass foobared # 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数， 如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端 返回max number of clients reached错误信息 maxclients 128 # 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key， 当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存， Value会存放在swap区 maxmemory # 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。 因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no appendonly no # 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof # 指定更新日志条件，共有3个可选值： no：表示等操作系统进行数据缓存同步到磁盘（快） always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） everysec：表示每秒同步一次（折衷，默认值） appendfsync everysec # 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上， 访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制） vm-enabled no # 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap # 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys), 也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-max-memory 0 # Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享， vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes； 如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 vm-page-size 32 # 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 vm-pages 134217728 # 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的， 可能会造成比较长时间的延迟。默认值为4 vm-max-threads 4 # 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 glueoutputbuf yes # 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 512 # 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍） activerehashing yes # 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf ----------------------------------------------------------------------------- # daemonize no 默认情况下， redis 不是在后台运行的，如果需要在后台运行，把该项的值更改为 yes daemonize yes # 当 redis 在后台运行的时候， Redis 默认会把 pid 文件放在 /var/run/redis.pid ，你可以配置到其他地址。 # 当运行多个 redis 服务时，需要指定不同的 pid 文件和端口 pidfile /var/run/redis_6379.pid # 指定 redis 运行的端口，默认是 6379 port 6379 # 在高并发的环境中，为避免慢客户端的连接问题，需要设置一个高速后台日志 tcp-backlog 511 # 指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求 # bind 192.168.1.100 10.0.0.1 # bind 127.0.0.1 # 设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接 # 0 是关闭此设置 timeout 0 # TCP keepalive # 在 Linux 上，指定值（秒）用于发送 ACKs 的时间。注意关闭连接需要双倍的时间。默认为 0 。 tcp-keepalive 0 # 指定日志记录级别，生产环境推荐 notice # Redis 总共支持四个级别： debug 、 verbose 、 notice 、 warning ，默认为 verbose # debug 记录很多信息，用于开发和测试 # varbose 有用的信息，不像 debug 会记录那么多 # notice 普通的 verbose ，常用于生产环境 # warning 只有非常重要或者严重的信息会记录到日志 loglevel notice # 配置 log 文件地址 # 默认值为 stdout ，标准输出，若后台模式会输出到 /dev/null 。 logfile /var/log/redis/redis.log # 可用数据库数 # 默认值为 16 ，默认数据库为 0 ，数据库范围在 0- （ database-1 ）之间 databases 16 ################################ 快照################################# # 保存数据到磁盘，格式如下 : # save # 指出在多长时间内，有多少次更新操作，就将数据同步到数据文件 rdb 。 # 相当于条件触发抓取快照，这个可以多个条件配合 # 比如默认配置文件中的设置，就设置了三个条件 # save 900 1 900 秒内至少有 1 个 key 被改变 # save 300 10 300 秒内至少有 300 个 key 被改变 # save 60 10000 60 秒内至少有 10000 个 key 被改变 save 900 1 save 300 10 save 60 10000 # 后台存储错误停止写。 stop-writes-on-bgsave-error yes # 存储至本地数据库时（持久化到 rdb 文件）是否压缩数据，默认为 yes rdbcompression yes # 对rdb数据进行校验,耗费CPU资源,默认为yes rdbchecksum yes # 本地持久化数据库文件名，默认值为 dump.rdb dbfilename dump.rdb # 工作目录 # 数据库镜像备份的文件放置的路径。 # 这里的路径跟文件名要分开配置是因为 redis 在进行备份时，先会将当前数据库的状态写入到一个临时文件中，等备份完成， # 再把该该临时文件替换为上面所指定的文件，而这里的临时文件和上面所配置的备份文件都会放在这个指定的路径当中。 # AOF文件也会存放在这个目录下面 # 注意这里必须制定一个目录而不是文件 dir /var/lib/redis-server/ ################################# 复制 ################################# # 主从复制 . 设置该数据库为其他数据库的从数据库 . # 设置当本机为 slav 服务时，设置 master 服务的 IP 地址及端口，在 Redis 启动时，它会自动从 master 进行数据同步 # slaveof # 当 master 服务设置了密码保护时 ( 用 requirepass 制定的密码 ) # slave 服务连接 master 的密码 # masterauth # 当从库同主机失去连接或者复制正在进行，从机库有两种运行方式： # 1) 如果 slave-serve-stale-data 设置为 yes( 默认设置 ) ，从库会继续响应客户端的请求 # 2) 如果 slave-serve-stale-data 是指为 no ，出去 INFO 和 SLAVOF 命令之外的任何请求都会返回一个 # 错误 \"SYNC with master in progress\" slave-serve-stale-data yes # 配置 slave 实例是否接受写。写 slave 对存储短暂数据（在同 master 数据同步后可以很容易地被删除）是有用的，但未配置的情况下，客户端写可能会发送问题。 # 从 Redis2.6 后，默认 slave 为 read-only slaveread-only yes # 从库会按照一个时间间隔向主库发送 PINGs. 可以通过 repl-ping-slave-period 设置这个时间间隔，默认是 10 秒 # repl-ping-slave-period 10 # repl-timeout 设置主库批量数据传输时间或者 ping 回复时间间隔，默认值是 60 秒 # 一定要确保 repl-timeout 大于 repl-ping-slave-period # repl-timeout 60 # 在 slave socket 的 SYNC 后禁用 TCP_NODELAY # 如果选择“ yes ” ,Redis 将使用一个较小的数字 TCP 数据包和更少的带宽将数据发送到 slave ， 但是这可能导致数据发送到 slave 端会有延迟 , 如果是 Linux kernel 的默认配置，会达到 40 毫秒 # 如果选择 \"no\" ，则发送数据到 slave 端的延迟会降低，但将使用更多的带宽用于复制 . repl-disable-tcp-nodelay no # 设置复制的后台日志大小。 # 复制的后台日志越大， slave 断开连接及后来可能执行部分复制花的时间就越长。 # 后台日志在至少有一个 slave 连接时，仅仅分配一次。 # repl-backlog-size 1mb # 在 master 不再连接 slave 后，后台日志将被释放。下面的配置定义从最后一个 slave 断开连接后需要释放的时间（秒）。 # 0 意味着从不释放后台日志 # repl-backlog-ttl 3600 # 如果 master 不能再正常工作，那么会在多个 slave 中，选择优先值最小的一个 slave 提升为 master ，优先值为 0 表示不能提升为 master 。 slave-priority 100 # 如果少于 N 个 slave 连接，且延迟时间 利用 LRU 算法移除设置过过期时间的 key (LRU: 最近使用 Least RecentlyUsed ) # allkeys-lru -> 利用 LRU 算法移除任何 key # volatile-random -> 移除设置过过期时间的随机 key # allkeys->random -> remove a randomkey, any key # volatile-ttl -> 移除即将过期的 key(minor TTL) # noeviction -> 不移除任何可以，只是返回一个写错误 # 注意：对于上面的策略，如果没有合适的 key 可以移除，当写的时候 Redis 会返回一个错误 # 默认是 : volatile-lru # maxmemory-policy volatile-lru # LRU 和 minimal TTL 算法都不是精准的算法，但是相对精确的算法 ( 为了节省内存 ) ，随意你可以选择样本大小进行检测。 # Redis 默认的灰选择 3 个样本进行检测，你可以通过 maxmemory-samples 进行设置 # maxmemory-samples 3 ############################## AOF############################### # 默认情况下， redis 会在后台异步的把数据库镜像备份到磁盘，但是该备份是非常耗时的，而且备份也不能很频繁，如果发生诸如拉闸限电、拔插头等状况，那么将造成比较大范围的数据丢失。 # 所以 redis 提供了另外一种更加高效的数据库备份及灾难恢复方式。 # 开启 append only 模式之后， redis 会把所接收到的每一次写操作请求都追加到 appendonly.aof 文件中，当 redis 重新启动时，会从该文件恢复出之前的状态。 # 但是这样会造成 appendonly.aof 文件过大，所以 redis 还支持了 BGREWRITEAOF 指令，对 appendonly.aof 进行重新整理。 # 你可以同时开启 asynchronous dumps 和 AOF appendonly no # AOF 文件名称 ( 默认 : \"appendonly.aof\") # appendfilename appendonly.aof # Redis 支持三种同步 AOF 文件的策略 : # no: 不进行同步，系统去操作 . Faster. # always: always 表示每次有写操作都进行同步 . Slow, Safest. # everysec: 表示对写操作进行累积，每秒同步一次 . Compromise. # 默认是 \"everysec\" ，按照速度和安全折中这是最好的。 # 如果想让 Redis 能更高效的运行，你也可以设置为 \"no\" ，让操作系统决定什么时候去执行 # 或者相反想让数据更安全你也可以设置为 \"always\" # 如果不确定就用 \"everysec\". # appendfsync always appendfsync everysec # appendfsync no # AOF 策略设置为 always 或者 everysec 时，后台处理进程 ( 后台保存或者 AOF 日志重写 ) 会执行大量的 I/O 操作 # 在某些 Linux 配置中会阻止过长的 fsync() 请求。注意现在没有任何修复，即使 fsync 在另外一个线程进行处理 # 为了减缓这个问题，可以设置下面这个参数 no-appendfsync-on-rewrite no-appendfsync-on-rewrite no # AOF 自动重写 # 当 AOF 文件增长到一定大小的时候 Redis 能够调用 BGREWRITEAOF 对日志文件进行重写 # 它是这样工作的： Redis 会记住上次进行些日志后文件的大小 ( 如果从开机以来还没进行过重写，那日子大小在开机的时候确定 ) # 基础大小会同现在的大小进行比较。如果现在的大小比基础大小大制定的百分比，重写功能将启动 # 同时需要指定一个最小大小用于 AOF 重写，这个用于阻止即使文件很小但是增长幅度很大也去重写 AOF 文件的情况 # 设置percentage 为 0 就关闭这个特性 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb ################################ LUASCRIPTING ############################# # 一个 Lua 脚本最长的执行时间为 5000 毫秒（ 5 秒），如果为 0 或负数表示无限执行时间。 lua-time-limit 5000 ################################LOW LOG################################ # Redis Slow Log 记录超过特定执行时间的命令。执行时间不包括 I/O 计算比如连接客户端，返回结果等，只是命令执行时间 # 可以通过两个参数设置 slow log ：一个是告诉 Redis 执行超过多少时间被记录的参数 slowlog-log-slower-than( 微妙 ) ， # 另一个是 slow log 的长度。当一个新命令被记录的时候最早的命令将被从队列中移除 # 下面的时间以微妙为单位，因此 1000000 代表一秒。 # 注意指定一个负数将关闭慢日志，而设置为 0 将强制每个命令都会记录 slowlog-log-slower-than 10000 # 对日志长度没有限制，只是要注意它会消耗内存 # 可以通过 SLOWLOG RESET 回收被慢日志消耗的内存 # 推荐使用默认值 128 ，当慢日志超过 128 时，最先进入队列的记录会被踢出 slowlog-max-len 128 ################################ 事件通知 ############################# # 当事件发生时， Redis 可以通知 Pub/Sub 客户端。 # 可以在下表中选择 Redis 要通知的事件类型。事件类型由单个字符来标识： # K Keyspace 事件，以 _keyspace@_ 的前缀方式发布 # E Keyevent 事件，以 _keysevent@_ 的前缀方式发布 # g 通用事件（不指定类型），像 DEL, EXPIRE, RENAME, … # $ String 命令 # s Set 命令 # h Hash 命令 # z 有序集合命令 # x 过期事件（每次 key 过期时生成） # e 清除事件（当 key 在内存被清除时生成） # A g$lshzxe 的别称，因此 ”AKE” 意味着所有的事件 # notify-keyspace-events 带一个由 0 到多个字符组成的字符串参数。空字符串意思是通知被禁用。 # 例子：启用 list 和通用事件： # notify-keyspace-events Elg # 默认所用的通知被禁用，因为用户通常不需要改特性，并且该特性会有性能损耗。 # 注意如果你不指定至少 K 或 E 之一，不会发送任何事件。 notify-keyspace-events “” ############################## 高级配置 ############################### # 当 hash 中包含超过指定元素个数并且最大的元素没有超过临界时， # hash 将以一种特殊的编码方式（大大减少内存使用）来存储，这里可以设置这两个临界值 # Redis Hash 对应 Value 内部实际就是一个 HashMap ，实际这里会有 2 种不同实现， # 这个 Hash 的成员比较少时 Redis 为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的 HashMap 结构，对应的 valueredisObject 的 encoding 为 zipmap, # 当成员数量增大时会自动转成真正的 HashMap, 此时 encoding 为 ht 。 hash-max-zipmap-entries 512 hash-max-zipmap-value 64 # 和 Hash 一样，多个小的 list 以特定的方式编码来节省空间。 # list 数据类型节点值大小小于多少字节会采用紧凑存储格式。 list-max-ziplist-entries 512 list-max-ziplist-value 64 # set 数据类型内部数据如果全部是数值型，且包含多少节点以下会采用紧凑格式存储。 set-max-intset-entries 512 # 和 hashe 和 list 一样 , 排序的 set 在指定的长度内以指定编码方式存储以节省空间 # zsort 数据类型节点值大小小于多少字节会采用紧凑存储格式。 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # Redis 将在每 100 毫秒时使用 1 毫秒的 CPU 时间来对 redis 的 hash 表进行重新 hash ，可以降低内存的使用 # 当你的使用场景中，有非常严格的实时性需要，不能够接受 Redis 时不时的对请求有 2 毫秒的延迟的话，把这项配置为 no 。 # 如果没有这么严格的实时性要求，可以设置为 yes ，以便能够尽可能快的释放内存 activerehashing yes # 客户端的输出缓冲区的限制，因为某种原因客户端从服务器读取数据的速度不够快， # 可用于强制断开连接（一个常见的原因是一个发布 / 订阅客户端消费消息的速度无法赶上生产它们的速度）。 # 可以三种不同客户端的方式进行设置： # normal -> 正常客户端 # slave -> slave 和 MONITOR 客户端 # pubsub -> 至少订阅了一个 pubsub channel 或 pattern 的客户端 # 每个 client-output-buffer-limit 语法 : # client-output-buffer-limit # 一旦达到硬限制客户端会立即断开，或者达到软限制并保持达成的指定秒数（连续）。 # 例如，如果硬限制为 32 兆字节和软限制为 16 兆字节 /10 秒，客户端将会立即断开 # 如果输出缓冲区的大小达到 32 兆字节，客户端达到 16 兆字节和连续超过了限制 10 秒，也将断开连接。 # 默认 normal 客户端不做限制，因为他们在一个请求后未要求时（以推的方式）不接收数据， # 只有异步客户端可能会出现请求数据的速度比它可以读取的速度快的场景。 # 把硬限制和软限制都设置为 0 来禁用该特性 client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb60 client-output-buffer-limit pubsub 32mb 8mb60 # Redis 调用内部函数来执行许多后台任务，如关闭客户端超时的连接，清除过期的 Key ，等等。 # 不是所有的任务都以相同的频率执行，但 Redis 依照指定的“ Hz ”值来执行检查任务。 # 默认情况下，“ Hz ”的被设定为 10 。 # 提高该值将在 Redis 空闲时使用更多的 CPU 时，但同时当有多个 key 同时到期会使 Redis 的反应更灵敏，以及超时可以更精确地处理。 # 范围是 1 到 500 之间，但是值超过 100 通常不是一个好主意。 # 大多数用户应该使用 10 这个预设值，只有在非常低的延迟的情况下有必要提高最大到 100 。 hz 10 # 当一个子节点重写 AOF 文件时，如果启用下面的选项，则文件每生成 32M 数据进行同步。 aof-rewrite-incremental-fsync yes "},"Database/NoSQL/Redis/01-Redis基础.html":{"url":"Database/NoSQL/Redis/01-Redis基础.html","title":"Redis基础","keywords":"","body":"datetime:2019/10/31 16:02 author:nzb Redis基础 应用场景 EXPIRE key seconds 限时的优惠活动信息 网站数据缓存(对于一些需要定时更新的数据,例如:积分排行榜) 手机验证码 限制网站访客访问频率(例如：1分钟最多访问10次) Redis键(key) DEL key 该命令用于在 key 存在时删除 key(所有类型都可以使用)。 DUMP key 序列化给定 key ，并返回被序列化的值。 EXISTS key 检查给定 key 是否存在。 EXPIRE key seconds 为给定 key 设置过期时间，以秒计。 EXPIREAT key timestamp EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。 PEXPIRE key milliseconds 设置 key 的过期时间以毫秒计。 PEXPIREAT key milliseconds-timestamp 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计 KEYS pattern 查找所有符合给定模式( pattern)的 key 。 MOVE key db 将当前数据库的 key 移动到给定的数据库 db 当中。 示例： # key 存在于当前数据库 redis> SELECT 0 # redis默认使用数据库 0，为了清晰起见，这里再显式指定一次。 OK redis> SET song \"secret base - Zone\" OK redis> MOVE song 1 # 将 song 移动到数据库 1 (integer) 1 redis> EXISTS song # song 已经被移走 (integer) 0 redis> SELECT 1 # 使用数据库 1 OK redis:1> EXISTS song # 证实 song 被移到了数据库 1 (注意命令提示符变成了\"redis:1\"，表明正在使用数据库 1) (integer) 1 # 当 key 不存在的时候 redis:1> EXISTS fake_key (integer) 0 redis:1> MOVE fake_key 0 # 试图从数据库 1 移动一个不存在的 key 到数据库 0，失败 (integer) 0 redis:1> select 0 # 使用数据库0 OK redis> EXISTS fake_key # 证实 fake_key 不存在 (integer) 0 # 当源数据库和目标数据库有相同的 key 时 redis> SELECT 0 # 使用数据库0 OK redis> SET favorite_fruit \"banana\" OK redis> SELECT 1 # 使用数据库1 OK redis:1> SET favorite_fruit \"apple\" OK redis:1> SELECT 0 # 使用数据库0，并试图将 favorite_fruit 移动到数据库 1 OK redis> MOVE favorite_fruit 1 # 因为两个数据库有相同的 key，MOVE 失败 (integer) 0 redis> GET favorite_fruit # 数据库 0 的 favorite_fruit 没变 \"banana\" redis> SELECT 1 OK redis:1> GET favorite_fruit # 数据库 1 的 favorite_fruit 也是 \"apple\" PERSIST key 移除 key 的过期时间，key 将持久保持。 示例 redis> SET mykey \"Hello\" OK redis> EXPIRE mykey 10 # 为 key 设置生存时间 (integer) 1 redis> TTL mykey (integer) 10 redis> PERSIST mykey # 移除 key 的生存时间 (integer) 1 redis> TTL mykey (integer) -1 PTTL key 以毫秒为单位返回 key 的剩余的过期时间。 TTL key 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。 示例 # 不存在的 key redis> FLUSHDB OK redis> TTL key (integer) -2 # key 存在，但没有设置剩余生存时间 redis> SET key value OK redis> TTL key (integer) -1 # 有剩余生存时间的 key redis> EXPIRE key 10086 (integer) 1 redis> TTL key (integer) 10084 RANDOMKEY 从当前数据库中随机返回一个 key 。 RENAME key newkey 修改 key 的名称 RENAMENX key newkey 仅当 newkey 不存在时，将 key 改名为 newkey 。 TYPE key 返回 key 所储存的值的类型。 key的命名规范 redis 单个key存入512M大小 key不要太长，尽量不要超过1024字节，这不仅消耗内存，而且降低查找的效率 key也不要太短，太短的话，key的可读性会降低 在一个项目中，key最好使用统一的命名模式，例如：user:123:password(推荐\":\"，不建议\"_\"，因为程序里面有的变量是以下划线连接的) Redis 字符串(String) SET key value SET 命令用于设置给定 key 的值。如果 key 已经存储其他值， SET 就覆写旧值，且无视类型。 GET key Get 命令用于获取指定 key 的值。如果 key 不存在，返回 nil 。如果key 储存的值不是字符串类型，返回一个错误。 SETNX key value只有在 key 不存在时设置 key 的值。应用于解决分布式锁方案之一 INCR key 将 key 中储存的数字值增一。 INCRBY key increment 将 key 所储存的值加上给定的增量值（increment） 。 DECR key 将 key 中储存的数字值减一。 DECRBY key decrement key 所储存的值减去给定的减量值（decrement） 。 INCRBYFLOAT key increment 将 key 所储存的值加上给定的浮点增量值（increment） 。 APPEND key value 如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾。 GETRANGE key start end 返回 key 中字符串值的子字符 GETSET key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。 GETBIT key offset 对 key 所储存的字符串值，获取指定偏移量上的位(bit)。 MGET key1 [key2..] 获取所有(一个或多个)给定 key 的值。 SETBIT key offset value 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。 SETEX key seconds value 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。 SETRANGE key offset value 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。 STRLEN key 返回 key 所储存的字符串值的长度。 MSET key value [key value ...] 同时设置一个或多个 key-value 对。 MSETNX key value [key value ...] 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。 PSETEX key milliseconds value 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。 应用场景 String通常应用于保存单个字符串或json字符串数据 因String是二进制安全的，所有完全可以把一个图片文件的内容作为字符串来存储 计算器(通常key-value缓存一样，常规计数：微博数，粉丝数) INCR等指令就具有原子操作的特性，所有完全可以利用redis的INCR、INCRBY、DECR、DECRBY等指令来实现原子计数的效果。 Redis 哈希(Hash) Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 Redis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。 HDEL key field1 [field2] 删除一个或多个哈希表字段 HEXISTS key field 查看哈希表 key 中，指定的字段是否存在。 HGET key field 获取存储在哈希表中指定字段的值。 HGETALL key 获取在哈希表中指定 key 的所有字段和值 HINCRBY key field increment 为哈希表 key 中的指定字段的整数值加上增量 increment 。 HINCRBYFLOAT key field increment 为哈希表 key 中的指定字段的浮点数值加上增量 increment 。 HKEYS key 获取所有哈希表中的字段 HLEN key 获取哈希表中字段的数量 HMGET key field1 [field2] 获取所有给定字段的值 HMSET key field1 value1 [field2 value2 ] 同时将多个 field-value (域-值)对设置到哈希表 key 中。 HSET key field value 将哈希表 key 中的字段 field 的值设为 value 。 HSETNX key field value 只有在字段 field 不存在时，设置哈希表字段的值。 HVALS key 获取哈希表中所有值 HSCAN key cursor [MATCH pattern] [COUNT count] 迭代哈希表中的键值对。 应用场景 常用与存储一个对象 为什么不用String存储一个对象？ 因为hash是最接近关系数据库结果的数据类型，可以将数据库一条记录或程序中一个对象转换成hashmap存放在redis中 Redis 列表(List) Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边） 一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。 BLPOP key1 [key2 ] timeout 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 BRPOP key1 [key2 ] timeout 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 BRPOPLPUSH source destination timeout 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 LINDEX key index 通过索引获取列表中的元素 LINSERT key BEFORE|AFTER pivot value 在列表的元素前或者后插入元素 LLEN key 获取列表长度 LPOP key 移出并获取列表的第一个元素 LPUSH key value1 [value2] 将一个或多个值插入到列表头部 LPUSHX key value 将一个值插入到已存在的列表头部 LRANGE key start stop 获取列表指定范围内的元素 LREM key count value 移除列表元素 LSET key index value 通过索引设置列表元素的值 LTRIM key start stop 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。 RPOP key 移除列表的最后一个元素，返回值为移除的元素。 RPOPLPUSH source destination 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 RPUSH key value1 [value2] 在列表中添加一个或多个值 RPUSHX key value 为已存在的列表添加值 应用场景(1、对数据量大的集合数据删减 2、任务队列 ) 对数据量大的集合数据删减：列表数据显示、关注列表、粉丝列表、留言评价等...分页、热点新闻(top)等。利用LANGE还可以很方便的实现分页的功能，在博客系统中，每片博文的评论也可以存入一个单独的list中。 任务队列(list通常用来实现一个消息队列，而且可以确保先后顺序，不必像MySQL那样需要通过ORDER BY 来进行排序) 任务队列介绍(生产者和消费者模式) 在处理Web客服端发送的命令请求时，某些操作的执行时间可能会比我们预期的更长一些，通过将待执行任务的相关信息放入队列里面，并在之后对队列进行处理，用户可以推迟执行那些需要一段时间才能完成的操作，这种将工作交给任务处理器来执行的做法被称为任务队列(task queue) 常用案例：订单系统的下单流程、用户系统登录注册短信等。 Redis 集合(Set) Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。 SADD key member1 [member2] 向集合添加一个或多个成员 SCARD key 获取集合的成员数 SDIFF key1 [key2] 返回给定所有集合的差集 SDIFFSTORE destination key1 [key2] 返回给定所有集合的差集并存储在 destination 中 SINTER key1 [key2] 返回给定所有集合的交集 SINTERSTORE destination key1 [key2] 返回给定所有集合的交集并存储在 destination 中 SISMEMBER key member 判断 member 元素是否是集合 key 的成员 SMEMBERS key 返回集合中的所有成员 SMOVE source destination member 将 member 元素从 source 集合移动到 destination 集合 SPOP key 移除并返回集合中的一个随机元素 SRANDMEMBER key [count] 返回集合中一个或多个随机数 SREM key member1 [member2] 移除集合中一个或多个成员 SUNION key1 [key2] 返回所有给定集合的并集 SUNIONSTORE destination key1 [key2] 所有给定集合的并集存储在 destination 集合中 SSCAN key cursor [MATCH pattern] [COUNT count] 迭代集合中的元素 应用场景 常应用于：对两个集合间的数据[计算]进行交集、并集、差集运算 1、以非常方便的实现如共同关注、共同喜好、二度好友等功能。对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存储到一个新的集合中。 2、利用唯一性，可以统计访问网站的所有独立 IP Redis 有序集合(sorted set) Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 有序集合的成员是唯一的,但分数(score)却可以重复。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。 ZADD key score1 member1 [score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的分数 ZCARD key 获取有序集合的成员数 ZCOUNT key min max 计算在有序集合中指定区间分数的成员数 ZINCRBY key increment member 有序集合中对指定成员的分数加上增量 increment ZINTERSTORE destination numkeys key [key ...] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中 ZLEXCOUNT key min max 在有序集合中计算指定字典区间内成员数量 ZRANGE key start stop [WITHSCORES] 通过索引区间返回有序集合指定区间内的成员 ZRANGEBYLEX key min max [LIMIT offset count] 通过字典区间返回有序集合的成员 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] 通过分数返回有序集合指定区间内的成员 ZRANK key member 返回有序集合中指定成员的索引 ZREM key member [member ...] 移除有序集合中的一个或多个成员 ZREMRANGEBYLEX key min max 移除有序集合中给定的字典区间的所有成员 ZREMRANGEBYRANK key start stop 移除有序集合中给定的排名区间的所有成员 ZREMRANGEBYSCORE key min max 移除有序集合中给定的分数区间的所有成员 ZREVRANGE key start stop [WITHSCORES] 返回有序集中指定区间内的成员，通过索引，分数从高到低 ZREVRANGEBYSCORE key max min [WITHSCORES] 返回有序集中指定分数区间内的成员，分数从高到低排序 ZREVRANK key member 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序 ZSCORE key member 返回有序集中，成员的分数值 ZUNIONSTORE destination numkeys key [key ...] 计算给定的一个或多个有序集的并集，并存储在新的 key 中 ZSCAN key cursor [MATCH pattern] [COUNT count] 迭代有序集合中的元素（包括元素成员和元素分值） 应用场景 常应用于：排行榜 比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。 比如一个存储全班同学成绩的Sorted Set，其集合value可以是同学的学号，而score就可以是其考试得分，这样在数据插入集合的时候，就已经进行了天然的排序。 还可以用Sorted Set来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 Redis 发布订阅 PSUBSCRIBE pattern [pattern ...] 订阅一个或多个符合给定模式的频道。 SUBSCRIBE channel [channel ...] 订阅给定的一个或多个频道的信息。 PUBLISH channel message 将信息发送到指定的频道。 PUBSUB subcommand [argument [argument ...]] 查看订阅与发布系统状态。 UNSUBSCRIBE [channel [channel ...]] 指退订给定的频道。 PUNSUBSCRIBE [pattern [pattern ...]] 退订所有给定模式的频道。 应用场景 这一功能最明显的用法就是构建实时消息系统，比如普通的即时聊天，群聊等功能 在一个博客网站中，有100个粉丝订阅了你，当你发布新文章，就可以推送消息给粉丝们。 微信公众号模式 Redis多数据库 Redis下，数据库是由一个整数索引标识，而不是由一个数据库名称。默认情况下，一个客户端连接到数据库0。 redis配置文件中下面的参数来控制数据库总数： database 16 //(从0开始 1 2 3 …15) select 数据库//数据库的切换 移动数据（将当前key移动另个库) move key名称 数据库 数据库清空： flushdb //清除当前数据库的所有key flushall //清除整个Redis的数据库所有key Redis 事务 Redis 事务可以一次执行多个命令， 并且带有以下三个重要的保证： 批量操作在发送 EXEC 命令前被放入队列缓存。 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。 一个事务从开始到执行会经历以下三个阶段： 开始事务。 命令入队。 执行事务。 单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。 事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。 DISCARD 取消事务，放弃执行事务块内的所有命令。 EXEC 执行所有事务块内的命令。 MULTI 标记一个事务块的开始。 UNWATCH 取消 WATCH 命令对所有 key 的监视。 WATCH key [key ...] 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 Redis数据淘汰策略redis.conf Redis官方给的警告，当内存不足时，Redis会根据配置的缓存策略淘汰部分Keys，以保证写入成功。当无淘汰策略时或没有找到适合淘汰的Key时，Redis直接返回out of memory错误。 最大缓存配置 在 redis 中，允许用户设置最大使用内存大小 maxmemory 512G redis 提供6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-lfu：从已设置过期的Keys中，删除一段时间内使用次数最少使用的 volatile-ttl：从已设置过期时间的数据集中挑选最近将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集中随机选择数据淘汰 allkeys-lru：从数据集中挑选最近最少使用的数据淘汰 allkeys-lfu：从所有Keys中，删除一段时间内使用次数最少使用的 allkeys-random：从数据集中随机选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据(不采用任何淘汰策略。默认即为此配置),针对写操作，返回错误信息 建议：了解了Redis的淘汰策略之后，在平时使用时应尽量主动设置/更新key的expire时间，主动剔除不活跃的旧数据，有助于提升查询性能 Redis持久化 数据存放于： 内存：高效、断电（关机）内存数据会丢失 硬盘：读写速度慢于内存，断电数据不会丢失 RDB RDB：是redis的默认持久化机制。 RDB相当于照快照，保存的是一种状态。 几十G数据 --> 几KB快照 快照是默认的持久化方式。这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。 优点： 快照保存数据极快、还原数据极快 适用于灾难备份 缺点：小内存机器不适合使用,RDB机制符合要求就会照快照 快照条件： 1、服务器正常关闭时 ./bin/redis-cli shutdown 2、key满足一定条件，会进行快照 save 900 1 //每900秒（15分钟）至少1个key发生变化，产生快照 save 300 10 //每300秒（5分钟）至少10个key发生变化，产生快照 save 60 10000 //每60秒（1分钟）至少10000个key发生变化，产生快照 AOF 由于快照方式是在一定间隔时间做一次的，所以如果redis 意外down 掉的话，就会丢失最后一次快照后的所有修改。如果应用要求不能丢失任何修改的话，可以采用aof 持久化方式。 Append-only file:aof 比快照方式有更好的持久化性，是由于在使用aof 持久化方式时,redis 会将每一个收到的写命令都通过write 函数追加到文件中(默认是appendonly.aof)。当redis 重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。 有三种方式如下（默认是：每秒 fsync 一次） appendonly yes //启用 aof 持久化方式 appendfsync always //收到写命令就立即写入磁盘，最慢，但是保证完全的持久化 appendfsync everysec //每秒钟写入磁盘一次，在性能和持久化方面做了很好的折中 appendfsync no //完全依赖 os，性能最好,持久化没保证 产生的问题： aof 的方式也同时带来了另一个问题。持久化文件会变的越来越大。例如我们调用 incr test命令 100 次，文件中必须保存全部的 100 条命令，其实有 99 条都是多余的。 redis缓存与数据库(MySQL)一致性方案 一、实时同步 对强一致要求比较高的，应采用实时同步方案，即查询缓存查询不到再从DB查询，保存到缓存；更新缓存时，先更新数据库，再将缓存的设置过期(建议不要去更新缓存内容，直接设置缓存过期)。 @Cacheable：查询时使用，注意Long类型需转换为Sting类型，否则会抛异常 @CachePut：更新时使用，使用此注解，一定会从DB上查询数据 @CacheEvict：删除时使用； @Caching：组合用法 二、异步队列 对于并发程度较高的，可采用异步队列的方式同步，可采用kafka等消息中间件处理消息生产和消费。 三、使用阿里的同步工具canal canal实现方式是模拟mysql slave和master的同步机制，监控DB bitlog的日志更新来触发缓存的更新，此种方法可以解放程序员双手，减少工作量，但在使用时有些局限性。 master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events，可以通过show binlog events进行查看）； slave将master的binary log events拷贝到它的中继日志(relay log)； slave重做中继日志中的事件，将改变反映它自己的数据。 canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议 mysql master收到dump请求，开始推送binary log给slave(也就是canal) canal解析binary log对象(原始为byte流) 四、采用UDF自定义函数的方式 面对mysql的API进行编程，利用触发器进行缓存同步，但UDF主要是c/c++语言实现，学习成本高。 总结： 穿透 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。 解决办法： 持久层查询不到就缓存空结果，查询时先判断缓存中是否exists(key) ,如果有直接返回空，没有则查询后返回， 注意insert时需清除查询的key，否则即便DB中有值也查询不到(当然也可以设置空缓存的过期时间） 雪崩 雪崩：缓存大量失效的时候，引发大量查询数据库。 解决办法： 用锁/分布式锁或者队列串行访问 缓存失效时间均匀分布 热点key 热点key:某个key访问非常频繁，当key失效的时候有大量线程来构建缓存，导致负载增加，系统崩溃。 解决办法： 使用锁，单机用synchronized,lock等，分布式用分布式锁。 缓存过期时间不设置，而是设置在key对应的value里。如果检测到存的时间超过过期时间则异步更新缓存。 在value设置一个比过期时间t0小的过期时间值t1，当t1过期的时候，延长t1并做更新缓存操作。 设置标签缓存，标签缓存设置过期时间，标签缓存过期后，需异步地更新实际缓存 "},"Database/NoSQL/Redis/03-Redis开发规范.html":{"url":"Database/NoSQL/Redis/03-Redis开发规范.html","title":"Redis开发规范","keywords":"","body":"datetime:2022/06/30 author:nzb Redis开发规范 一、键值设计 1. key名设计 (1)【建议】: 可读性和可管理性 以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id ugc:video:1 因为很多Redis客户端是根据冒号分类的。比如有几个Key：apps:app:1、apps:app:2和apps:app:3。Redis Desktop Manager能自动归类到apps目录下。如下图所示： (2)【建议】：简洁性 保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如： user:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}。 (3)【强制】：不要包含特殊字符 反例：包含空格、换行、单双引号以及其他转义字符 详细解析 2. value设计 (1)【强制】：拒绝bigkey(防止网卡流量、慢查询) string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。 这是因为Redis随着Value不断增长，在超过10KB后，有一个非常奇妙的性能拐点，如下图所示（图片来自Redis官网) 反例：一个包含200万个元素的list。 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法。 详细解析 (2)【推荐】：选择适合的数据类型。 例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡) 反例： set user:1:name tom set user:1:age 19 set user:1:favor football 正例: hmset user:1 name tom age 19 favor football 3.【推荐】：控制key的生命周期，redis不是垃圾桶。 建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。 二、命令使用 1.【推荐】 O(N)命令关注N的数量 例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。 2.【推荐】：禁用命令 禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 3.【推荐】合理使用select redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。 4.【推荐】使用批量操作提高效率 原生命令：例如mget、mset。 非原生命令：可以使用pipeline提高效率。 但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。 注意两者不同： 原生是原子操作，pipeline是非原子操作。 pipeline可以打包不同的命令，原生做不到 pipeline需要客户端和服务端同时支持。 5.【建议】Redis事务功能较弱，不建议过多使用 Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决) 6.【建议】Redis集群版本在使用Lua上有特殊要求： 1.所有key都应该由 KEYS 数组来传递redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，\"-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array\" 2.所有key，必须在1个slot上，否则直接返回error, \"-ERR eval/evalsha command keys must in same slot\" 7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。 monitor命令一般是用来观察redis服务端都在执行哪些命令并实时输出。例如在其他redis-cli中执行两个set命令，在monitor中监控结果如下： $ redis-cli -h 172.31.239.79 monitor OK 1638616687.781190 [15 172.19.0.3:55276] \"COMMAND\" 1638616687.781277 [15 172.19.0.3:55276] \"set\" \"name\" \"Charles\" 1638616687.789198 [15 172.19.0.3:55276] \"publish\" \"socket.io…..\" 之所以规范建议控制monitor命令的使用时间，是因为随着monitor命令执行时间越来越长，会导致越来越多的数据积压在输出缓冲区，从而导致输出缓冲区占用内存越来越大。而且，这种影响会由于Redis并发越高，而更加放大。 三、客户端使用 1.【推荐】避免多个应用使用一个Redis实例 正例：不相干的业务拆分，公共数据做服务化。 2.【推荐】使用带有连接池的数据库，可以有效控制连接，同时提高效率 3.【建议】高并发下建议客户端添加熔断功能 例如netflix hystrix 4.【推荐】设置合理的密码 如有必要可以使用SSL加密访问（阿里云Redis支持） 5.【建议】最大内存淘汰策略 根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。 默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。 其他策略如下： allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 allkeys-random：随机删除所有键，直到腾出足够空间为止。 volatile-random：随机删除过期键，直到腾出足够空间为止。 volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。 noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息 \"(error) OOM command not allowed when used memory\"，此时Redis只响应读操作。 四、相关工具 1.【推荐】数据同步 redis间数据同步可以使用：redis-port 2.【推荐】big key搜索 3.【推荐】热点key寻找 内部实现使用monitor，所以建议短时间使用 五 附录：删除 bigkey 下面操作可以使用pipeline加速。 redis 4.0已经支持key的异步删除，欢迎使用。 1. Hash删除: hscan + hdel 2. List删除: ltrim 3. Set删除: sscan + srem 4. SortedSet删除: zscan + zrem "},"MachineLearning/MatplotlibNumpyPandas/numpy基础.html":{"url":"MachineLearning/MatplotlibNumpyPandas/numpy基础.html","title":"numpy基础","keywords":"","body":"datetime:2020/8/1 13:28 author:nzb numpy基础 幕布numpy基础 幕布numpy方法 numpy用于数组计算 中文文档 import numpy as np import random 创建数组 a1 = np.array([1,2,3]) a2 = np.array(range(5)) a3 = np.arange(8) a4 = np.array(range(4), dtype='f4') a5 = np.array([1,0,1,0,1,0], dtype=bool) print(a1, a2, a3, sep='\\n') print(type(a1), type(a2), type(a3)) print(\"a3:dtype:\", a3.dtype) print(\"a4:dtype:\", a4.dtype) print(\"a5:dtype:\", a5.dtype) print(\"a1调整dtype前\",a1.dtype ) # a1.dtype = 'f2' a1 = a1.astype('float32') print(\"a1调整dtype后\",a1.dtype ) print(\"\\n\") # 保留小数点 a6 = np.array([random.random() for _ in range(10)]) print(a6) print(np.round(a6, 3)) [1 2 3] [0 1 2 3 4] [0 1 2 3 4 5 6 7] a3:dtype: int32 a4:dtype: float32 a5:dtype: bool a1调整dtype前 int32 a1调整dtype后 float32 [0.67067085 0.2306847 0.25868171 0.71041073 0.53141459 0.40654488 0.62679249 0.51855766 0.30907571 0.63072732] [0.671 0.231 0.259 0.71 0.531 0.407 0.627 0.519 0.309 0.631] 数据类型 形状 a7 = np.array([[1,2,3],[4,5,6]]) a8 = np.array([[[1,2,3],[4,5,6]],[[7,8,9],[4,5,6]] ]) print(a3, a7, a8, sep='\\n') print(a3.shape, a7.shape, a8.shape) [0 1 2 3 4 5 6 7] [[1 2 3] [4 5 6]] [[[1 2 3] [4 5 6]] [[7 8 9] [4 5 6]]] (8,) (2, 3) (2, 2, 3) a9 = np.arange(12) # 转换为2维， print(a9.reshape((3,4)), a9.reshape((2,6)), a9.reshape((2,2,3)), a9.reshape((2,3,2)), sep='\\n\\n\\n') [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[ 0 1 2 3 4 5] [ 6 7 8 9 10 11]] [[[ 0 1 2] [ 3 4 5]] [[ 6 7 8] [ 9 10 11]]] [[[ 0 1] [ 2 3] [ 4 5]] [[ 6 7] [ 8 9] [10 11]]] print(a9.reshape((12,)),a9.reshape((1,12)), a9.reshape((12,1)), sep='\\n\\n\\n') [ 0 1 2 3 4 5 6 7 8 9 10 11] [[ 0 1 2 3 4 5 6 7 8 9 10 11]] [[ 0] [ 1] [ 2] [ 3] [ 4] [ 5] [ 6] [ 7] [ 8] [ 9] [10] [11]] a10 = np.arange(12).reshape((2,2,3)) print(a10, a10.flatten(), sep='\\n\\n\\n') [[[ 0 1 2] [ 3 4 5]] [[ 6 7 8] [ 9 10 11]]] [ 0 1 2 3 4 5 6 7 8 9 10 11] 计算 a11 = np.arange(12).reshape((3,-1)) # nan：没有的意思 # infinity：无限，无穷的意思，所以这里是无限大的意思 print(a11, a11/2, a11/0, sep='\\n\\n\\n') [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[0. 0.5 1. 1.5] [2. 2.5 3. 3.5] [4. 4.5 5. 5.5]] [[nan inf inf inf] [inf inf inf inf] [inf inf inf inf]] C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide after removing the cwd from sys.path. C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide after removing the cwd from sys.path. 维度相同 a12 = np.arange(1,13).reshape((3,4)) a13 = np.arange(11, 23).reshape((3,4)) print(a12, a13, sep='\\n'*3) [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] [[11 12 13 14] [15 16 17 18] [19 20 21 22]] print(\"加：\", a12 + a13, end=\"\\n\"*3) print(\"减：\", a12 - a13, end=\"\\n\"*3) print(\"乘：\", a12 * a13, end=\"\\n\"*3) print(\"除：\", a12 / a13, end=\"\\n\"*3) 加： [[12 14 16 18] [20 22 24 26] [28 30 32 34]] 减： [[-10 -10 -10 -10] [-10 -10 -10 -10] [-10 -10 -10 -10]] 乘： [[ 11 24 39 56] [ 75 96 119 144] [171 200 231 264]] 除： [[0.09090909 0.16666667 0.23076923 0.28571429] [0.33333333 0.375 0.41176471 0.44444444] [0.47368421 0.5 0.52380952 0.54545455]] 维度不相同 需要有一个维度的相同 广播原则 如果两个数组的后缘维度（即从末尾开始算起的维度）的轴长度相符或其中一方的长度为1，则认为它们是广播兼容的，广播会在缺失和（或）长度为1的维度上进行 a14 = np.arange(6) a15 = np.arange(24).reshape((4,6)) a16 = np.arange(4).reshape((4,1)) a17 = np.arange(10) print(a14, a15, a16, a17, sep=\"\\n\"*3) [0 1 2 3 4 5] [[ 0 1 2 3 4 5] [ 6 7 8 9 10 11] [12 13 14 15 16 17] [18 19 20 21 22 23]] [[0] [1] [2] [3]] [0 1 2 3 4 5 6 7 8 9] # 维度不一样时会计算对应位置 print(a15-a14, a15-a16, sep='\\n'*3) [[ 0 0 0 0 0 0] [ 6 6 6 6 6 6] [12 12 12 12 12 12] [18 18 18 18 18 18]] [[ 0 1 2 3 4 5] [ 5 6 7 8 9 10] [10 11 12 13 14 15] [15 16 17 18 19 20]] # 维度不一样时会计算对应位置不一样也不一定可以计算 print(a15-a14, a15-a16, a15-a17, sep='\\n'*3) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in 1 # 维度不一样时会计算对应位置不一样也不一定可以计算 ----> 2 print(a15-a14, a15-a16, a15-a17, sep='\\n'*3) ValueError: operands could not be broadcast together with shapes (4,6) (10,) 轴 二维 axis=0：行 axis=1：列 三维 axis=0：行 aixs=1：列（每一行的每一列） aixs=2：块（每一行的每一列的每个元素） print(a10, np.sum(a10, axis=0), np.sum(a10, axis=1), np.sum(a10, axis=2), sep='\\n'*3) [[[ 0 1 2] [ 3 4 5]] [[ 6 7 8] [ 9 10 11]]] [[ 6 8 10] [12 14 16]] [[ 3 5 7] [15 17 19]] [[ 3 12] [21 30]] 转置 a18 = np.arange(24).reshape((4,6)) print(a18, a18.transpose(), a18.T, a18.swapaxes(1,0), sep='\\n'*3) [[ 0 1 2 3 4 5] [ 6 7 8 9 10 11] [12 13 14 15 16 17] [18 19 20 21 22 23]] [[ 0 6 12 18] [ 1 7 13 19] [ 2 8 14 20] [ 3 9 15 21] [ 4 10 16 22] [ 5 11 17 23]] [[ 0 6 12 18] [ 1 7 13 19] [ 2 8 14 20] [ 3 9 15 21] [ 4 10 16 22] [ 5 11 17 23]] [[ 0 6 12 18] [ 1 7 13 19] [ 2 8 14 20] [ 3 9 15 21] [ 4 10 16 22] [ 5 11 17 23]] 索引与切片 中文文档 # 一维（前闭后开） print(a2, a2[0], a2[2:5],a2[::-1], sep='\\n'*2) [0 1 2 3 4] 0 [2 3 4] [4 3 2 1 0] 三个点（ ... ）表示产生完整索引元组所需的冒号。例如，如果 x 是rank为5的数组（即，它具有5个轴），则： x[1,2,...] 相当于 x[1,2,:,:,:] x[...,3] 等效于 x[:,:,:,:,3] x[4,...,5,:] 等效于 x[4,:,:,5,:] # 多维 print(\"二维\",a12,a12[:2,:2], a12[:, 1:3],a12[[0, 1,2],[1,2,0]], sep='\\n'*2) print(\"三维\",a10, a10[:,:2,:2], a10[1,...],sep='\\n'*3) 二维 [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] [[1 2] [5 6]] [[ 2 3] [ 6 7] [10 11]] [2 7 9] 三维 [[[ 0 1 2] [ 3 4 5]] [[ 6 7 8] [ 9 10 11]]] [[[ 0 1] [ 3 4]] [[ 6 7] [ 9 10]]] [[ 6 7 8] [ 9 10 11]] index = np.where(a12 [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] (array([0, 0, 0, 0], dtype=int64), array([0, 1, 2, 3], dtype=int64)) [1 2 3 4] # 小于5的赋值为1，,大于等于5的赋值为0 # 三目运算符 print(np.where(a12 [[1 1 1 1] [0 0 0 0] [0 0 0 0]] 数据拼接 a1 = np.arange(12).reshape((2,6)) a2 = np.arange(12, 24).reshape((2,6)) # 竖直拼接 a3 = np.vstack((a1, a2)) # 水平拼接 a4 = np.hstack((a1, a2)) print(a3, a4, sep=\"\\n\"*3) [[ 0 1 2 3 4 5] [ 6 7 8 9 10 11] [12 13 14 15 16 17] [18 19 20 21 22 23]] [[ 0 1 2 3 4 5 12 13 14 15 16 17] [ 6 7 8 9 10 11 18 19 20 21 22 23]] 行列交换 a3 array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) # 行交换 a3[[1,2], :] = a3[[2,1], :] print(\"行交换\",a3, sep='\\n') # 列交换 a3[:, [0,2]] = a3[:,[2,0]] print(\"行交换\",a3, sep='\\n') 行交换 [[ 0 1 2 3 4 5] [12 13 14 15 16 17] [ 6 7 8 9 10 11] [18 19 20 21 22 23]] 行交换 [[ 2 1 0 3 4 5] [14 13 12 15 16 17] [ 8 7 6 9 10 11] [20 19 18 21 22 23]] import matplotlib.pyplot as plt %matplotlib inline a1 = np.random.rand(100) plt.scatter(range(100), a1) plt.show() nan和inf print(type(np.nan),np.nan == np.nan, np.nan is np.nan, sep=\"\\n\"*2) False True a1 = np.array([1,2,np.nan]) print(a1 != a1, np.count_nonzero(a1 != a1), sep=\"\\n\") print(np.isnan(a1)) print(\"求和：\", np.sum(a1)) a1[np.isnan(a1)]=0 print(a1) [False False True] 1 [False False True] 求和： nan [1. 2. 0.] np.isnan(a1) array([False, False, False]) a1 = np.array([1,2,np.nan]) a2 = np.arange(12).reshape((3,4)).astype(\"float\") a2[[1], 2:] = np.nan # 使用了 ~（取补运算符）来过滤 NaN。 a = np.array([np.nan, 1,2,np.nan,3,4,5]) print (a[~np.isnan(a)]) [1. 2. 3. 4. 5.] "},"MachineLearning/MatplotlibNumpyPandas/Pandas快速入门.html":{"url":"MachineLearning/MatplotlibNumpyPandas/Pandas快速入门.html","title":"pandas基础","keywords":"","body":"Pandas 中文文档 英文文档 Pandas概览 Pandas 是 Python 的核心数据分析支持库，提供了快速、灵活、明确的数据结构，旨在简单、直观地处理关系型、标记型数据。Pandas 的目标是成为 Python 数据分析实践与实战的必备高级工具，其长远目标是成为最强大、最灵活、可以支持任何语言的开源数据分析工具。经过多年不懈的努力，Pandas 离这个目标已经越来越近了。 Pandas 适用于处理以下类型的数据： 与 SQL 或 Excel 表类似的，含异构列的表格数据; 有序和无序（非固定频率）的时间序列数据; 带行列标签的矩阵数据，包括同构或异构型数据; 任意其它形式的观测、统计数据集, 数据转入 Pandas 数据结构时不必事先标记。 Pandas 的主要数据结构是 Series（一维数据）与 DataFrame（二维数据），这两种数据结构足以处理金融、统计、- 社会科学、工程等领域里的大多数典型用例。对于 R 用户，DataFrame 提供了比 R 语言 data.frame 更丰富的功能。Pandas 基于 NumPy 开发，可以与其它第三方科学计算支持库完美集成。 Pandas 就像一把万能瑞士军刀，下面仅列出了它的部分优势 ： 处理浮点与非浮点数据里的缺失数据，表示为 NaN； 大小可变：插入或删除 DataFrame 等多维对象的列； 自动、显式数据对齐：显式地将对象与一组标签对齐，也可以忽略标签，在 Series、DataFrame 计算时自动与数据对齐； 强大、灵活的分组（group by）功能：拆分-应用-组合数据集，聚合、转换数据； 把 Python 和 NumPy 数据结构里不规则、不同索引的数据轻松地转换为 DataFrame 对象； 基于智能标签，对大型数据集进行切片、花式索引、子集分解等操作； 直观地合并（merge）、连接（join）数据集； 灵活地重塑（reshape）、透视（pivot）数据集； 轴支持结构化标签：一个刻度支持多个标签； 成熟的 IO 工具：读取文本文件（CSV 等支持分隔符的文件）、Excel 文件、数据库等来源的数据，利用超快的 HDF5 格式保存 / 加载数据； 时间序列：支持日期范围生成、频率转换、移动窗口统计、移动窗口线性回归、日期位移等时间序列功能。 这些功能主要是为了解决其它编程语言、科研环境的痛点。处理数据一般分为几个阶段：数据整理与清洗、数据分析与建模、数据可视化与制表，Pandas 是处理数据的理想工具。 其它说明： Pandas 速度很快。Pandas 的很多底层算法都用 Cython 优化过。然而，为了保持通用性，必然要牺牲一些性能，如果专注某一功能，完全可以开发出比 Pandas 更快的专用工具。 Pandas 是 statsmodels 的依赖项，因此，Pandas 也是 Python 中统计计算生态系统的重要组成部分。 Pandas 已广泛应用于金融领域。 数据结构 维数 名称 描述 1 Series 带标签的一维同构数组 2 DataFrame 带标签的，大小可变的，二维异构表格 为什么有多个数据结构？ Pandas 数据结构就像是低维数据的容器。比如，DataFrame 是 Series 的容器，Series 则是标量的容器。使用这种方式，可以在容器中以字典的形式插入或删除对象。 此外，通用 API 函数的默认操作要顾及时间序列与截面数据集的方向。多维数组存储二维或三维数据时，编写函数要注意数据集的方向，这对用户来说是一种负担；如果不考虑 C 或 Fortran 中连续性对性能的影响，一般情况下，不同的轴在程序里其实没有什么区别。Pandas 里，轴的概念主要是为了给数据赋予更直观的语义，即用“更恰当”的方式表示数据集的方向。这样做可以让用户编写数据转换函数时，少费点脑子。 处理 DataFrame 等表格数据时，index（行）或 columns（列）比 axis 0 和 axis 1 更直观。用这种方式迭代 DataFrame 的列，代码更易读易懂： for col in df.columns: series = df[col] # do something with series 大小可变与数据复制 Pandas 所有数据结构的值都是可变的，但数据结构的大小并非都是可变的，比如，Series 的长度不可改变，但 DataFrame 里就可以插入列。 Pandas 里，绝大多数方法都不改变原始的输入数据，而是复制数据，生成新的对象。 一般来说，原始输入数据不变更稳妥。 十分钟入门Pandas 本节是帮助 Pandas 新手快速上手的简介。烹饪指南里介绍了更多实用案例。 本节以下列方式导入 Pandas 与 NumPy： import numpy as np import pandas as pd 生成对象 详见数据结构简介文档。 用值列表生成 Series 时，Pandas 默认自动生成整数索引： s = pd.Series([1, 2, 3, 4, 5, np.nan, 6, 8]) s 0 1.0 1 2.0 2 3.0 3 4.0 4 5.0 5 NaN 6 6.0 7 8.0 dtype: float64 用含日期时间索引与标签的Numpy数组生成DataFrame df1 = pd.date_range(start='20150101', periods=6) df1 DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04', '2015-01-05', '2015-01-06'], dtype='datetime64[ns]', freq='D') df2 = pd.DataFrame(np.random.randn(6, 4), index=df1, columns=list('ABCD')) df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-01 0.495777 -0.524296 -0.089971 1.640044 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 2015-01-04 0.565125 0.858778 0.138376 0.201316 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 2015-01-06 -0.224993 -1.253118 -0.195717 -0.623797 用Series字典对象生成DataFrame df3 = pd.DataFrame({ 'A': 1., 'B': pd.Timestamp('20150101'), 'C': pd.Series(1, index=list(range(4)), dtype='float32'), 'D': np.array([3] * 4, dtype='int32'), 'E': pd.Categorical(['test', 'train', 'test', 'train']), 'F': 'foo' }) df3 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E F 0 1.0 2015-01-01 1.0 3 test foo 1 1.0 2015-01-01 1.0 3 train foo 2 1.0 2015-01-01 1.0 3 test foo 3 1.0 2015-01-01 1.0 3 train foo DataFrame 的列有不同数据类型。 df3.dtypes A float64 B datetime64[ns] C float32 D int32 E category F object dtype: object IPython支持 tab 键自动补全列名与公共属性。下面是部分可自动补全的属性： df3. # df2.A df2.bool # df2.abs df2.boxplot # df2.add df2.C # df2.add_prefix df2.clip # df2.add_suffix df2.clip_lower # df2.align df2.clip_upper # df2.all df2.columns # df2.any df2.combine # df2.append df2.combine_first # df2.apply df2.compound # df2.applymap df2.consolidate # df2.D # 列 A、B、C、D 和 E 都可以自动补全；为简洁起见，此处只显示了部分属性。 File \"\", line 1 df3. ^ SyntaxError: invalid syntax 查看数据 详见基础用法文档。 下列代码说明如何查看 DataFrame 头部和尾部数据： df2.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-01 0.495777 -0.524296 -0.089971 1.640044 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 2015-01-04 0.565125 0.858778 0.138376 0.201316 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 df2.tail(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-04 0.565125 0.858778 0.138376 0.201316 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 2015-01-06 -0.224993 -1.253118 -0.195717 -0.623797 显示索引与列名 df2.index DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04', '2015-01-05', '2015-01-06'], dtype='datetime64[ns]', freq='D') df2.columns Index(['A', 'B', 'C', 'D'], dtype='object') DataFrame.to_numpy() 输出底层数据的 NumPy 对象。注意，DataFrame 的列由多种数据类型组成时，该操作耗费系统资源较大，这也是 Pandas 和 NumPy 的本质区别：NumPy 数组只有一种数据类型，DataFrame 每列的数据类型各不相同。调用 DataFrame.to_numpy() 时，Pandas 查找支持 DataFrame 里所有数据类型的 NumPy 数据类型。还有一种数据类型是 object，可以把 DataFrame 列里的值强制转换为 Python 对象。 下面的 df2 这个 DataFrame 里的值都是浮点数，DataFrame.to_numpy() 的操作会很快，而且不复制数据。 df2.to_numpy() array([[ 0.49577653, -0.5242963 , -0.08997072, 1.64004361], [ 2.01445165, -0.42293604, 0.99104484, -0.28133103], [ 0.88359618, -1.79480302, 0.57597891, -1.85652831], [ 0.56512531, 0.85877834, 0.13837606, 0.20131605], [-1.85407664, 0.36895609, -1.26782639, -2.46488774], [-0.22499319, -1.25311828, -0.19571662, -0.62379678]]) df3 这个 DataFrame 包含了多种类型，DataFrame.to_numpy() 操作就会耗费较多资源。 df3.to_numpy() array([[1.0, Timestamp('2015-01-01 00:00:00'), 1.0, 3, 'test', 'foo'], [1.0, Timestamp('2015-01-01 00:00:00'), 1.0, 3, 'train', 'foo'], [1.0, Timestamp('2015-01-01 00:00:00'), 1.0, 3, 'test', 'foo'], [1.0, Timestamp('2015-01-01 00:00:00'), 1.0, 3, 'train', 'foo']], dtype=object) 提醒： DataFrame.to_numpy() 的输出不包含行索引和列标签。 describe() 可以快速查看数据的统计摘要： df2.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D count 6.000000 6.000000 6.000000 6.000000 mean 0.313313 -0.461237 0.025314 -0.564197 std 1.288654 0.984132 0.772400 1.470442 min -1.854077 -1.794803 -1.267826 -2.464888 25% -0.044801 -1.070913 -0.169280 -1.548345 50% 0.530451 -0.473616 0.024203 -0.452564 75% 0.803978 0.170983 0.466578 0.080654 max 2.014452 0.858778 0.991045 1.640044 转置数据： print(df2) print(\"\\n-------------------转置后-------------------------\") df2.T A B C D 2015-01-01 0.495777 -0.524296 -0.089971 1.640044 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 2015-01-04 0.565125 0.858778 0.138376 0.201316 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 2015-01-06 -0.224993 -1.253118 -0.195717 -0.623797 -------------------转置后------------------------- .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 2015-01-01 2015-01-02 2015-01-03 2015-01-04 2015-01-05 2015-01-06 A 0.495777 2.014452 0.883596 0.565125 -1.854077 -0.224993 B -0.524296 -0.422936 -1.794803 0.858778 0.368956 -1.253118 C -0.089971 0.991045 0.575979 0.138376 -1.267826 -0.195717 D 1.640044 -0.281331 -1.856528 0.201316 -2.464888 -0.623797 按轴排序： df2.sort_index(axis=1, ascending=False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } D C B A 2015-01-01 1.640044 -0.089971 -0.524296 0.495777 2015-01-02 -0.281331 0.991045 -0.422936 2.014452 2015-01-03 -1.856528 0.575979 -1.794803 0.883596 2015-01-04 0.201316 0.138376 0.858778 0.565125 2015-01-05 -2.464888 -1.267826 0.368956 -1.854077 2015-01-06 -0.623797 -0.195717 -1.253118 -0.224993 按值排序： df2.sort_values(by='B') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 2015-01-06 -0.224993 -1.253118 -0.195717 -0.623797 2015-01-01 0.495777 -0.524296 -0.089971 1.640044 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 2015-01-04 0.565125 0.858778 0.138376 0.201316 选择 提醒： 选择、设置标准 Python / Numpy 的表达式已经非常直观，交互也很方便，但对于生产代码，我们还是推荐优化过的 Pandas 数据访问方法：.at、.iat、.loc 和 .iloc。 详见索引与选择数据、多层索引与高级索引文档。 获取数据 选择单列，产生Series，与df2.A等效： df2['A'] 2015-01-01 0.495777 2015-01-02 2.014452 2015-01-03 0.883596 2015-01-04 0.565125 2015-01-05 -1.854077 2015-01-06 -0.224993 Freq: D, Name: A, dtype: float64 用[]切片行： df2[0:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-01 0.495777 -0.524296 -0.089971 1.640044 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 df2['20150102': '20150103'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 按标签选择 详见按标签选择 用标签提取一行数据： df2.loc[df1[0]] A 0.495777 B -0.524296 C -0.089971 D 1.640044 Name: 2015-01-01 00:00:00, dtype: float64 用标签选择多列数据： df2.loc[:, ['A', 'B']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2015-01-01 0.495777 -0.524296 2015-01-02 2.014452 -0.422936 2015-01-03 0.883596 -1.794803 2015-01-04 0.565125 0.858778 2015-01-05 -1.854077 0.368956 2015-01-06 -0.224993 -1.253118 用标签切片，包含行与列结束点： df2.loc['20150102': '20150104', ['A', 'B']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2015-01-02 2.014452 -0.422936 2015-01-03 0.883596 -1.794803 2015-01-04 0.565125 0.858778 返回对象降维： df2.loc['20150102', ['A', 'B']] A 2.014452 B -0.422936 Name: 2015-01-02 00:00:00, dtype: float64 提取标量值： df2.loc[df1[0], 'A'] 0.4957765303321702 快速访问标量，与上述方法等效 df2.at[df1[0], 'A'] 0.4957765303321702 按位置选择 详见按位置选择 用整数位置选择： df2.iloc[3] A 0.565125 B 0.858778 C 0.138376 D 0.201316 Name: 2015-01-04 00:00:00, dtype: float64 类似Numpy/Python，用整数切片 df2.iloc[3:5, 0:2] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B 2015-01-04 0.565125 0.858778 2015-01-05 -1.854077 0.368956 类型Numpy/Python，用整数列表按位置切片： df2.iloc[[1, 2, 4], [0, 2]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A C 2015-01-02 2.014452 0.991045 2015-01-03 0.883596 0.575979 2015-01-05 -1.854077 -1.267826 显式整行切片 df2.iloc[1:3, :] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 显式整列切片： df2.iloc[:, 1:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } B C 2015-01-01 -0.524296 -0.089971 2015-01-02 -0.422936 0.991045 2015-01-03 -1.794803 0.575979 2015-01-04 0.858778 0.138376 2015-01-05 0.368956 -1.267826 2015-01-06 -1.253118 -0.195717 显式提取值： df2.iloc[1, 1] -0.4229360414145462 快速访问标量，与上述方法等效： df2.iat[1, 1] -0.4229360414145462 布尔索引 用单列的值选择数据： df2[df2.A > 0] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-01 0.495777 -0.524296 -0.089971 1.640044 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 2015-01-04 0.565125 0.858778 0.138376 0.201316 选择DataFrame里满足条件的值： df2[df2 > 0] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 2015-01-01 0.495777 NaN NaN 1.640044 2015-01-02 2.014452 NaN 0.991045 NaN 2015-01-03 0.883596 NaN 0.575979 NaN 2015-01-04 0.565125 0.858778 0.138376 0.201316 2015-01-05 NaN 0.368956 NaN NaN 2015-01-06 NaN NaN NaN NaN 用isin()筛选： df4 = df2.copy() df4['E'] = ['one', 'two', 'three', 'four', 'three', 'one'] df4 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 2015-01-01 0.495777 -0.524296 -0.089971 1.640044 one 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 two 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 three 2015-01-04 0.565125 0.858778 0.138376 0.201316 four 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 three 2015-01-06 -0.224993 -1.253118 -0.195717 -0.623797 one df4[df4['E'].isin(['two', 'four'])] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 two 2015-01-04 0.565125 0.858778 0.138376 0.201316 four 赋值 用索引自动对齐新增列的数据： s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range('20150101', periods=6)) df2['F'] = s1 print(df2) A B C D F 2015-01-01 0.495777 -0.524296 -0.089971 1.640044 1 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 3 2015-01-04 0.565125 0.858778 0.138376 0.201316 4 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 5 2015-01-06 -0.224993 -1.253118 -0.195717 -0.623797 6 按标签赋值： df2.at[df1[0], 'A'] = 0 df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2015-01-01 0.000000 -0.524296 -0.089971 1.640044 1 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 3 2015-01-04 0.565125 0.858778 0.138376 0.201316 4 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 5 2015-01-06 -0.224993 -1.253118 -0.195717 -0.623797 6 按位置赋值： df2.iat[0, 1] = 0 df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2015-01-01 0.000000 0.000000 -0.089971 1.640044 1 2015-01-02 2.014452 -0.422936 0.991045 -0.281331 2 2015-01-03 0.883596 -1.794803 0.575979 -1.856528 3 2015-01-04 0.565125 0.858778 0.138376 0.201316 4 2015-01-05 -1.854077 0.368956 -1.267826 -2.464888 5 2015-01-06 -0.224993 -1.253118 -0.195717 -0.623797 6 按Numpy数组赋值： df2.loc[:, \"D\"] = np.array([5] * len(df2)) df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2015-01-01 0.000000 0.000000 -0.089971 5 1 2015-01-02 2.014452 -0.422936 0.991045 5 2 2015-01-03 0.883596 -1.794803 0.575979 5 3 2015-01-04 0.565125 0.858778 0.138376 5 4 2015-01-05 -1.854077 0.368956 -1.267826 5 5 2015-01-06 -0.224993 -1.253118 -0.195717 5 6 用where条件赋值： 签名DataFrame.where()不同于numpy.where()。大致相当于。df1.where(m, df2)``````np.where(m, df1, df2) df5 = df2.copy() df5[df5 > 0] = -df5 df5 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2015-01-01 0.000000 0.000000 -0.089971 -5 -1 2015-01-02 -2.014452 -0.422936 -0.991045 -5 -2 2015-01-03 -0.883596 -1.794803 -0.575979 -5 -3 2015-01-04 -0.565125 -0.858778 -0.138376 -5 -4 2015-01-05 -1.854077 -0.368956 -1.267826 -5 -5 2015-01-06 -0.224993 -1.253118 -0.195717 -5 -6 缺失值 Pandas 主要用 np.nan 表示缺失数据。 计算时，默认不包含空值。详见缺失数据。 重建索引（reindex）可以更改、添加、删除指定轴的索引，并返回数据副本，即不更改原数据。 df6 = df2.reindex(index=df1[0:4], columns=list(df2.columns) + ['E']) df6.loc[df1[0]:df1[1], 'E'] = 1 df6 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2015-01-01 0.000000 0.000000 -0.089971 5 1 1.0 2015-01-02 2.014452 -0.422936 0.991045 5 2 1.0 2015-01-03 0.883596 -1.794803 0.575979 5 3 NaN 2015-01-04 0.565125 0.858778 0.138376 5 4 NaN 删除所有含缺失值得行： df6.dropna(how='any') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2015-01-01 0.000000 0.000000 -0.089971 5 1 1.0 2015-01-02 2.014452 -0.422936 0.991045 5 2 1.0 填充缺失值： df6.fillna(value=4) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2015-01-01 0.000000 0.000000 -0.089971 5 1 1.0 2015-01-02 2.014452 -0.422936 0.991045 5 2 1.0 2015-01-03 0.883596 -1.794803 0.575979 5 3 4.0 2015-01-04 0.565125 0.858778 0.138376 5 4 4.0 提取nan值得布尔掩码： pd.isna(df6) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F E 2015-01-01 False False False False False False 2015-01-02 False False False False False False 2015-01-03 False False False False False True 2015-01-04 False False False False False True 运算 详见二进制操作 统计 一般情况下，运算时排除缺失值。 描述性统计： df2.mean() A 0.230684 B -0.373854 C 0.025314 D 5.000000 F 3.500000 dtype: float64 在另一个轴(即,行)上执行同样的操作： df2.mean(1) 2015-01-01 1.182006 2015-01-02 1.916512 2015-01-03 1.532954 2015-01-04 2.112456 2015-01-05 1.449411 2015-01-06 1.865234 Freq: D, dtype: float64 不同维度对象运算时，要先对齐。此外，Pandas自动沿指定维度广播。 s2 = pd.Series([1, 3, 5, np.nan, 6, 8], index=df1).shift(2) s2 2015-01-01 NaN 2015-01-02 NaN 2015-01-03 1.0 2015-01-04 3.0 2015-01-05 5.0 2015-01-06 NaN Freq: D, dtype: float64 df2.sub(s2, axis='index') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2015-01-01 NaN NaN NaN NaN NaN 2015-01-02 NaN NaN NaN NaN NaN 2015-01-03 -0.116404 -2.794803 -0.424021 4.0 2.0 2015-01-04 -2.434875 -2.141222 -2.861624 2.0 1.0 2015-01-05 -6.854077 -4.631044 -6.267826 0.0 0.0 2015-01-06 NaN NaN NaN NaN NaN Apply函数 Apply函数处理数据 df2.apply(np.cumsum) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D F 2015-01-01 0.000000 0.000000 -0.089971 5 1 2015-01-02 2.014452 -0.422936 0.901074 10 3 2015-01-03 2.898048 -2.217739 1.477053 15 6 2015-01-04 3.463173 -1.358961 1.615429 20 10 2015-01-05 1.609096 -0.990005 0.347603 25 15 2015-01-06 1.384103 -2.243123 0.151886 30 21 df2.apply(lambda x: x.max() - x.min()) A 3.868528 B 2.653581 C 2.258871 D 0.000000 F 5.000000 dtype: float64 直方图 详见直方图与离散化。 s3 = pd.Series(np.random.randint(0, 7, size=10)) s3 0 6 1 3 2 4 3 0 4 2 5 3 6 1 7 6 8 4 9 3 dtype: int32 s3.value_counts() 3 3 6 2 4 2 2 1 1 1 0 1 dtype: int64 字符串方法 Series 的 str 属性包含一组字符串处理功能，如下列代码所示。注意，str 的模式匹配默认使用正则表达式。详见矢量字符串方法。 s4 = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat']) s4.str.lower() 0 a 1 b 2 c 3 aaba 4 baca 5 NaN 6 caba 7 dog 8 cat dtype: object 合并（Merge） 结合（Concat） Pandas 提供了多种将 Series、DataFrame 对象组合在一起的功能，用索引与关联代数功能的多种设置逻辑可执行连接（join）与合并（merge）操作。 详见合并。 concat() 用于连接 Pandas 对象： df7 = pd.DataFrame(np.random.randn(10, 4)) df7 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 0.510118 1.297539 -0.226940 -1.298777 1 -0.156357 -0.501054 -0.884452 -0.642022 2 -0.084234 0.522088 0.559494 0.614627 3 -1.877422 1.173498 -0.590322 1.283285 4 0.599235 -0.459644 -0.991115 0.602145 5 -0.918474 1.273175 0.391105 1.760057 6 1.454607 0.301366 0.569512 -0.853014 7 0.533967 2.432820 -0.116690 -1.042676 8 0.788732 0.988278 -0.317310 -0.555627 9 0.717240 -0.003718 2.191069 1.661000 # 分解为多组 pieces = [df7[:3], df7[3:7], df7[7:]] pd.concat(pieces) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 0.510118 1.297539 -0.226940 -1.298777 1 -0.156357 -0.501054 -0.884452 -0.642022 2 -0.084234 0.522088 0.559494 0.614627 3 -1.877422 1.173498 -0.590322 1.283285 4 0.599235 -0.459644 -0.991115 0.602145 5 -0.918474 1.273175 0.391105 1.760057 6 1.454607 0.301366 0.569512 -0.853014 7 0.533967 2.432820 -0.116690 -1.042676 8 0.788732 0.988278 -0.317310 -0.555627 9 0.717240 -0.003718 2.191069 1.661000 连接（join） SQL 风格的合并。 详见数据库风格连接。 left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]}) right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]}) print(left) print('-------------------') print(right) key lval 0 foo 1 1 foo 2 ------------------- key rval 0 foo 4 1 foo 5 pd.merge(left, right, on='key') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key lval rval 0 foo 1 4 1 foo 1 5 2 foo 2 4 3 foo 2 5 还有一个例子： left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]}) right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]}) print(left) print('-------------------') print(right) key lval 0 foo 1 1 bar 2 ------------------- key rval 0 foo 4 1 bar 5 pd.merge(left, right, on='key') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } key lval rval 0 foo 1 4 1 bar 2 5 追加（Append） 为 DataFrame 追加行。详见追加文档。 df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D']) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.288486 0.071832 -0.573014 -0.740909 1 -0.437346 -0.341157 0.652473 1.647469 2 -0.041598 1.400381 0.034764 0.030222 3 0.269048 0.363632 1.939811 0.371858 4 1.135352 -1.729701 1.319469 0.695883 5 0.024442 0.259727 -0.255833 -1.128733 6 1.310012 1.068041 -0.961124 0.513195 7 -0.811828 2.385519 -0.211693 -1.799050 s = df.iloc[3] df.append(s, ignore_index=True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.288486 0.071832 -0.573014 -0.740909 1 -0.437346 -0.341157 0.652473 1.647469 2 -0.041598 1.400381 0.034764 0.030222 3 0.269048 0.363632 1.939811 0.371858 4 1.135352 -1.729701 1.319469 0.695883 5 0.024442 0.259727 -0.255833 -1.128733 6 1.310012 1.068041 -0.961124 0.513195 7 -0.811828 2.385519 -0.211693 -1.799050 8 0.269048 0.363632 1.939811 0.371858 分组（Grouping） “group by” 指的是涵盖下列一项或多项步骤的处理流程： 分割：按条件把数据分割成多组； 应用：为每组单独应用函数； 组合：将处理结果组合成一个数据结构。 详见中文文档 官方 df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'], 'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'], 'C': np.random.randn(8), 'D': np.random.randn(8)}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 foo one 1.039872 0.388262 1 bar one -0.512593 1.288747 2 foo two 2.751863 -0.549265 3 bar three 1.826074 -0.152341 4 foo two 0.565190 1.234779 5 bar two -0.544772 -1.006594 6 foo one -0.232166 0.317457 7 foo three 1.150941 0.672226 先分组，再用sum函数计算每组的汇总数据 df.groupby('A').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C D A bar 0.768709 0.129812 foo 5.275699 2.063459 多列分组后，生成多层索引，也可以应用 sum 函数： df.groupby(['A', 'B']).sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C D A B bar one -0.512593 1.288747 three 1.826074 -0.152341 two -0.544772 -1.006594 foo one 0.807705 0.705719 three 1.150941 0.672226 two 3.317053 0.685514 重塑（Reshaping） 详见多层索引与重塑。 堆叠（Stack） tuples = list(zip(*[['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], ....: ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']])) index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second']) df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B']) df2 = df[:4] print(df, df2, sep='\\n' * 3) A B first second bar one 1.192086 -1.617945 two -0.541903 -0.763716 baz one 0.002802 -0.073066 two 1.086178 0.505617 foo one 0.495192 -1.072288 two 0.447279 -1.292418 qux one -0.317342 -0.857073 two 0.452839 0.217488 A B first second bar one 1.192086 -1.617945 two -0.541903 -0.763716 baz one 0.002802 -0.073066 two 1.086178 0.505617 # stack()方法把 DataFrame 列压缩至一层 stacked = df2.stack() stacked first second bar one A 1.192086 B -1.617945 two A -0.541903 B -0.763716 baz one A 0.002802 B -0.073066 two A 1.086178 B 0.505617 dtype: float64 # 压缩后的 DataFrame 或 Series 具有多层索引， stack() 的逆操作是 unstack()，默认为拆叠最后一层： stacked.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one 1.192086 -1.617945 two -0.541903 -0.763716 baz one 0.002802 -0.073066 two 1.086178 0.505617 stacked.unstack(1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } second one two first bar A 1.192086 -0.541903 B -1.617945 -0.763716 baz A 0.002802 1.086178 B -0.073066 0.505617 stacked.unstack(0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } first bar baz second one A 1.192086 0.002802 B -1.617945 -0.073066 two A -0.541903 1.086178 B -0.763716 0.505617 数据透视表（Pivot Tables） 详见数据透视表。 df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3, .....: 'B': ['A', 'B', 'C'] * 4, .....: 'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2, .....: 'D': np.random.randn(12), .....: 'E': np.random.randn(12)}) df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D E 0 one A foo 0.310437 0.596380 1 one B foo 1.015415 -0.658475 2 two C foo 0.526326 1.851567 3 three A bar 1.502380 -1.316516 4 one B bar -1.752622 0.461646 5 one C bar 0.888497 0.703693 6 two A foo -0.629228 0.718748 7 three B foo 2.389784 0.049419 8 one C foo -0.890217 0.858487 9 one A bar -0.261845 -1.190759 10 two B bar -0.040979 -0.877174 11 three C bar -0.216170 -0.865147 pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C bar foo A B one A -0.261845 0.310437 B -1.752622 1.015415 C 0.888497 -0.890217 three A 1.502380 NaN B NaN 2.389784 C -0.216170 NaN two A NaN -0.629228 B -0.040979 NaN C NaN 0.526326 时间序列(TimeSeries) Pandas 为频率转换时重采样提供了虽然简单易用，但强大高效的功能， 如，将秒级的数据转换为 5 分钟为频率的数据。这种操作常见于财务应用程序，但又不仅限于此。详见时间序列。 rng = pd.date_range('1/1/2020', periods=10, freq='S') ts = pd.Series(np.random.randint(0, 20, len(rng)), index=rng) print(rng, ts, sep='\\n' * 2) DatetimeIndex(['2020-01-01 00:00:00', '2020-01-01 00:00:01', '2020-01-01 00:00:02', '2020-01-01 00:00:03', '2020-01-01 00:00:04', '2020-01-01 00:00:05', '2020-01-01 00:00:06', '2020-01-01 00:00:07', '2020-01-01 00:00:08', '2020-01-01 00:00:09'], dtype='datetime64[ns]', freq='S') 2020-01-01 00:00:00 17 2020-01-01 00:00:01 0 2020-01-01 00:00:02 7 2020-01-01 00:00:03 12 2020-01-01 00:00:04 1 2020-01-01 00:00:05 15 2020-01-01 00:00:06 0 2020-01-01 00:00:07 10 2020-01-01 00:00:08 14 2020-01-01 00:00:09 8 Freq: S, dtype: int32 ts.resample('5Min').sum() 2020-01-01 84 Freq: 5T, dtype: int32 # 时区表示 rng = pd.date_range('2020/8/1', periods=5, freq='D') ts = pd.Series(np.random.randn(len(rng)), rng) ts_UTC = ts.tz_localize('UTC') print(ts, ts_UTC, sep='\\n' * 3) 2020-08-01 -0.938967 2020-08-02 0.056395 2020-08-03 -1.249805 2020-08-04 -0.300962 2020-08-05 -1.635329 Freq: D, dtype: float64 2020-08-01 00:00:00+00:00 -0.938967 2020-08-02 00:00:00+00:00 0.056395 2020-08-03 00:00:00+00:00 -1.249805 2020-08-04 00:00:00+00:00 -0.300962 2020-08-05 00:00:00+00:00 -1.635329 Freq: D, dtype: float64 # 转换成其他时区 ts_UTC.tz_convert('US/Eastern') 2020-07-31 20:00:00-04:00 -0.938967 2020-08-01 20:00:00-04:00 0.056395 2020-08-02 20:00:00-04:00 -1.249805 2020-08-03 20:00:00-04:00 -0.300962 2020-08-04 20:00:00-04:00 -1.635329 Freq: D, dtype: float64 # 转换时间段 rng = pd.date_range('2020/8/1', periods=5, freq='M') ts = pd.Series(np.random.randn(len(rng)), rng) ps = ts.to_period() pts = ps.to_timestamp() print(ts, ps, pts, sep='\\n' * 3) 2020-08-31 2.606606 2020-09-30 1.631934 2020-10-31 1.167378 2020-11-30 -0.376675 2020-12-31 -0.196782 Freq: M, dtype: float64 2020-08 2.606606 2020-09 1.631934 2020-10 1.167378 2020-11 -0.376675 2020-12 -0.196782 Freq: M, dtype: float64 2020-08-01 2.606606 2020-09-01 1.631934 2020-10-01 1.167378 2020-11-01 -0.376675 2020-12-01 -0.196782 Freq: MS, dtype: float64 可视化 详见可视化文档。 ts = pd.Series(np.random.randn(1000), index=pd.date_range('2020/1/1', periods=1000)) ts = ts.cumsum() ts.plot() DataFrame 的 plot() 方法可以快速绘制所有带标签的列： import matplotlib.pyplot as plt df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=['A', 'B', 'C', 'D']) df = df.cumsum() plt.figure(figsize=(30, 10), dpi=80) df.plot() plt.legend(loc='best') "},"MachineLearning/MatplotlibNumpyPandas/Pandas_merge_concat_append.html":{"url":"MachineLearning/MatplotlibNumpyPandas/Pandas_merge_concat_append.html","title":"pandas连接合并追加","keywords":"","body":"Pandas 连接合并追加操作 concat concat(objs, axis=0, join='outer', ignore_index: bool = False, keys = None, levels = None, names = None, verify_integrity: bool = False, sort: bool = False, copy: bool = True) 连接 2 个Series s1 = pd.DataFrame([1,2,3]) s2 = pd.DataFrame([4,6,5]) s1 0 0 1 1 2 2 3 s2 0 0 4 1 6 2 5 pd.concat([s1, s2]) 0 0 1 1 2 2 3 0 4 1 6 2 5 # 忽略索引 pd.concat([s1, s2], ignore_index=True) 0 0 1 1 2 2 3 3 4 4 6 5 5 连接 2个 DataFrame # 普通连接(行) df1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number']) df2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['letter', 'number']) df1 letter number 0 a 1 1 b 2 df2 letter number 0 c 3 1 d 4 pd.concat([df1, df2]) letter number 0 a 1 1 b 2 0 c 3 1 d 4 # 普通连接(列) pd.concat([df1, df2], axis=1) letter number letter number 0 a 1 c 3 1 b 2 d 4 # 如果字段不相同，填充 `Nan` df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']], columns=['letter', 'number', 'animal']) df3 letter number animal 0 c 3 cat 1 d 4 dog pd.concat([df1, df3], sort=False) letter number animal 0 a 1 NaN 1 b 2 NaN 0 c 3 cat 1 d 4 dog # 内连接(只连接相同字段) pd.concat([df1, df3], join='inner') letter number 0 a 1 1 b 2 0 c 3 1 d 4 # 排序后，列拼接 pd.concat([df1, df2], axis=1) letter number letter number 0 a 1 c 3 1 b 2 d 4 df2.sort_values('number', ascending=False, inplace=True) # 这一步至关重要 df2.reset_index(drop=True, inplace=True) pd.concat([df1, df2], axis=1) letter number letter number 0 a 1 d 4 1 b 2 c 3 merge merge(left, right, how: str = 'inner', on = None, left_on = None, right_on = None, left_index: bool = False, right_index: bool = False, sort: bool = False, suffixes = ('_x', '_y'), copy: bool = True, indicator: bool = False, validate = None) 普通合并 df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'], 'value': [1, 2, 3, 5]}) df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'], 'value': [5, 6, 7, 8]}) df1 lkey value 0 foo 1 1 bar 2 2 baz 3 3 foo 5 df2 rkey value 0 foo 5 1 bar 6 2 baz 7 3 foo 8 df1.merge(df2, left_on='lkey', right_on='rkey') lkey value_x rkey value_y 0 foo 1 foo 5 1 foo 1 foo 8 2 foo 5 foo 5 3 foo 5 foo 8 4 bar 2 bar 6 5 baz 3 baz 7 df1.merge(df2, left_on='lkey', right_on='rkey',suffixes=('_left', '_right')) lkey value_left rkey value_right 0 foo 1 foo 5 1 foo 1 foo 8 2 foo 5 foo 5 3 foo 5 foo 8 4 bar 2 bar 6 5 baz 3 baz 7 内、左、右连接 df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]}) df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]}) df1 a b 0 foo 1 1 bar 2 df2 a c 0 foo 3 1 baz 4 df1.merge(df2, how='inner', on='a') a b c 0 foo 1 3 df1.merge(df2, how='left', on='a') a b c 0 foo 1 3.0 1 bar 2 NaN df1.merge(df2, how='right', on='a') a b c 0 foo 1.0 3 1 baz NaN 4 # 相同值，但是不同的字段名，左连接 df3 = pd.DataFrame({'d': ['foo', 'baz'], 'c': [3, 4]}) df3 d c 0 foo 3 1 baz 4 df1.merge(df3, how='left', left_on='a', right_on='d') a b d c 0 foo 1 foo 3.0 1 bar 2 NaN NaN 笛卡尔积 df1 = pd.DataFrame({'left': ['foo', 'bar']}) df2 = pd.DataFrame({'right': [7, 8]}) df1 left 0 foo 1 bar df2 right 0 7 1 8 df1.merge(df2, how='cross') left right 0 foo 7 1 foo 8 2 bar 7 3 bar 8 append append(other, ignore_index=False, verify_integrity=False, sort=False) 普通追加 df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB')) df A B 0 1 2 1 3 4 df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB')) df2 A B 0 5 6 1 7 8 df.append(df2) A B 0 1 2 1 3 4 0 5 6 1 7 8 df.append(df2, ignore_index=True) A B 0 1 2 1 3 4 2 5 6 3 7 8 # 通过 for 循环追加 df = pd.DataFrame(columns=['A']) for i in range(5): df = df.append({'A': i}, ignore_index=True) df A 0 0 1 1 2 2 3 3 4 4 # 等价于 concat 连接，如下 pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],ignore_index=True) A 0 0 1 1 2 2 3 3 4 4 "},"MachineLearning/MatplotlibNumpyPandas/matplotlib基础.html":{"url":"MachineLearning/MatplotlibNumpyPandas/matplotlib基础.html","title":"matplotlib基础","keywords":"","body":"matplotlib基础 中文文档 import matplotlib.pyplot as plt import random import pandas as pd from matplotlib import font_manager as fm %matplotlib inline matplotlib设置中文字体 # 配置中文字体： my_font = fm.FontProperties(fname=r\"C:\\Users\\Admin\\AppData\\Local\\Microsoft\\FontCache\\CloudFonts\\TTC\\107373335009.ttc\") x = range(2, 26, 2) # x轴数据 y = list(range(22, 46, 2)) # y轴数据 random.shuffle(y) 基本用法 双击可查看大图 # 基本用法 plt.plot(x, y) # 绘制 plt.grid(alpha=0.5) # 绘制网格（会根据x和y轴的刻度间隔绘制） alpha:透明度：0-1 plt.show() # 展示 设置图标大小和分辨率 # 设置图标大小 # figure图形图标的意思，在这里指的是我们画的图 # 通过实例化一个figure并且传递参数，能够在后台自动使用该figure实例 # 在图形模糊的时候可以传入dpi参数，让图形更清晰（每一英寸上的像素点） fig = plt.figure(figsize=(20, 8), dpi=100) plt.plot(x, y) # 图片保存(还可以保存为svg这种矢量图格式，放大不会有锯齿) # plt.savefig(\"./t1.png\") plt.show() 设置x轴和y轴刻度间隔 # 设置x轴和y轴刻度间隔 # 当刻度太密集时候使用列表的步长（间隔取值）来取值，matplotlib会自动帮我们对应 plt.figure(figsize=(25, 15)) plt.subplot(3,3,1) plt.plot(x, y) plt.xticks(x) plt.grid() # 设置y的刻度 plt.yticks(range(min(y),max(y)+1)[::2]) plt.subplot(3,3,2) plt.plot(x, y) plt.xticks(range(2, 26)) plt.subplot(3,3,3) plt.plot(x, y) plt.xticks(range(2, 26, 3)) plt.subplot(3,3,4) plt.plot(x, y) _xtick_labels = [i+0.5 for i in range(2,26)] plt.xticks(_xtick_labels) plt.subplot(3,3,5) plt.plot(x, y) _xtick_labels = [i+0.5 for i in range(2,26)] plt.xticks(_xtick_labels[::3]) plt.subplot(3,3,6) plt.plot(x, y) # 需注意x绘制的是2到26的值，超过了就没有可以绘制了 plt.xticks(range(26, 50, 2)) plt.show() # 绘制11点到1点每一分钟的气温变化 tmp = [random.randint(20, 45) for _ in range(120)] minus = pd.date_range('2020-07-28 11:00:00', '2020-07-28 13:00:00', freq='T') minus DatetimeIndex(['2020-07-28 11:00:00', '2020-07-28 11:01:00', '2020-07-28 11:02:00', '2020-07-28 11:03:00', '2020-07-28 11:04:00', '2020-07-28 11:05:00', '2020-07-28 11:06:00', '2020-07-28 11:07:00', '2020-07-28 11:08:00', '2020-07-28 11:09:00', ... '2020-07-28 12:51:00', '2020-07-28 12:52:00', '2020-07-28 12:53:00', '2020-07-28 12:54:00', '2020-07-28 12:55:00', '2020-07-28 12:56:00', '2020-07-28 12:57:00', '2020-07-28 12:58:00', '2020-07-28 12:59:00', '2020-07-28 13:00:00'], dtype='datetime64[ns]', length=121, freq='T') x轴和y轴添加描述信息 plt.figure(figsize=(30, 10)) plt.plot(tmp) # x = range(120)[::2] # _xtick_labels = [\"a{0}\".format(i) for i in x] # plt.xticks(x ,_xtick_labels) # 刻度字符串映射 # 刻度数据长度和x轴数据长度需对应 # rotation=90旋转90度 plt.xticks(range(120)[::2], minus[::2], rotation=45, fontsize=15) plt.yticks(fontsize=20) plt.xlabel(\"时间\", fontproperties=my_font, fontsize=50) plt.ylabel(\"温度\", fontproperties=my_font, fontsize=50) plt.title(\"11点到1点每一分钟的气温变化\",fontproperties=my_font, fontsize=50) plt.show() 绘制多次图像很不同图像的差异 绘制的时候指定 color：颜色 linestyle：线条风格 linewidth：线条粗细 alpha：透明度 颜色字符 风格字符 r红色 -实线 g绿色 --虚线，破折线 b蓝色 -.点划线 w白色 :点虚线，虚线 ''留空或空格，无线条 c青色 m洋红 y黄色 k黑色 #00ff0016进制 0.8灰度值字符串 y_1 = [random.randint(1,50) for _ in range(25)] y_2 = [random.randint(1,50) for _ in range(25)] plt.figure(figsize=(20,10)) plt.plot(y_1, label=\"y1的线\", linestyle='-.') plt.plot(y_2, label=\"y2的线\", color='r') plt.grid(linestyle=\"--\") # 添加图例(展示上面的label) # prop：字体 # loc：位置 plt.legend(prop=my_font, loc=\"best\") plt.show() 散点图 y1 = [random.randint(20, 45) for _ in range(30)] y2 = [random.randint(20, 45) for _ in range(30)] x1 = range(1, 31) x2 = range(51, 81) plt.figure(figsize=(20,10),dpi=80) #散点图 plt.scatter(x1, y1, label=\"3月份\") plt.scatter(x2, y2, label=\"10月份\") # 修改x轴刻度 _x = list(x1) + list(x2) _xtick_label = [\"3月{0}日\".format(i) for i in x1] _xtick_label += [\"10月{0}日\".format(i-50) for i in x2] plt.xticks(_x[::2], _xtick_label[::2], fontproperties=my_font, rotation=45, fontsize=10) # 添加描述信息 plt.xlabel(\"时间\", fontproperties=my_font, fontsize=20) plt.ylabel(\"温度\", fontproperties=my_font, fontsize=20) # t添加图例 plt.legend(prop=my_font, handlelength=5, handleheight=5, fontsize=50) plt.show() 条形图 a = [\"战狼2\",\"速度与激情8\",\"功夫瑜伽\",\"西游伏妖篇\",\"变形金刚5：最后的骑士\",\"摔跤吧！爸爸\",\"加勒比海盗5：死无对证\",\"金刚：骷髅岛\",\"极限特工：终极回归\",\"生化危机6：终章\",\"乘风破浪\",\"神偷奶爸3\",\"智取威虎山\",\"大闹天竺\",\"金刚狼3：殊死一战\",\"蜘蛛侠：英雄归来\",\"悟空传\",\"银河护卫队2\",\"情圣\",\"新木乃伊\",] b=[56.01,26.94,17.53,16.49,15.45,12.96,11.8,11.61,11.28,11.12,10.49,10.3,8.75,7.55,7.32,6.99,6.88,6.86,6.58,6.23] x = range(len(a)) plt.figure(figsize=(20,10)) # width：宽度 plt.bar(x, b, width=0.5) # 修改x轴信息 plt.xticks(x, a, fontproperties=my_font, fontsize=15, rotation=90) plt.show() 横条形图 a = [\"战狼2\",\"速度与激情8\",\"功夫瑜伽\",\"西游伏妖篇\",\"变形金刚5：最后的骑士\",\"摔跤吧！爸爸\",\"加勒比海盗5：死无对证\",\"金刚：骷髅岛\",\"极限特工：终极回归\",\"生化危机6：终章\",\"乘风破浪\",\"神偷奶爸3\",\"智取威虎山\",\"大闹天竺\",\"金刚狼3：殊死一战\",\"蜘蛛侠：英雄归来\",\"悟空传\",\"银河护卫队2\",\"情圣\",\"新木乃伊\",] b=[56.01,26.94,17.53,16.49,15.45,12.96,11.8,11.61,11.28,11.12,10.49,10.3,8.75,7.55,7.32,6.99,6.88,6.86,6.58,6.23] x = range(len(a)) plt.figure(figsize=(20,10)) # height：宽度(因为是横条形图，所以是高度) plt.barh(x, b, height=0.5, color='orange') # 修改y轴信息(横条形图) plt.yticks(x, a, fontproperties=my_font, fontsize=20) # 网格 plt.grid() plt.show() 绘制多次条形图 a = [\"猩球崛起3：终极之战\",\"敦刻尔克\",\"蜘蛛侠：英雄归来\",\"战狼2\"] b_16 = [15746,312,4497,319] b_15 = [12357,156,2045,168] b_14 = [2358,399,2358,362] bar_width = 0.2 plt.figure(figsize=(20,10)) x16 = list(range(len(a))) x15 = [i+bar_width for i in x16] # 移动2个宽度 x14 = [i+bar_width*2 for i in x16] plt.bar(x16, b_16, width=bar_width, label=\"16日票房\") plt.bar(x15, b_15, width=bar_width, label=\"15日票房\") plt.bar(x14, b_14, width=bar_width, label=\"14日票房\") # 设置x刻度(因为刻度是在黄色上，即x15对应一下即可，x16和x14对应也可以就是标注会左右移动一点) plt.xticks(x15, a,fontproperties=my_font, fontsize=25) plt.grid() plt.legend(prop=my_font) plt.show() 直方图 组数：将数据分组，如果数据在100个以内，按数据多少分为5-12组 组距：指每个小组的两个端点的距离 组数 = 极值 / 组距 = (max(a) - min(a)) / bin_width 原始数据 如果是统计之后的数据，需要用条形图绘制 a=[131, 98, 125, 131, 124, 139, 131, 117, 128, 108, 135, 138, 131, 102, 107, 114, 119, 128, 121, 142, 127, 130, 124, 101, 110, 116, 117, 110, 128, 128, 115, 99, 136, 126, 134, 95, 138, 117, 111,78, 132, 124, 113, 150, 110, 117, 86, 95, 144, 105, 126, 130,126, 130, 126, 116, 123, 106, 112, 138, 123, 86, 101, 99, 136,123, 117, 119, 105, 137, 123, 128, 125, 104, 109, 134, 125, 127,105, 120, 107, 129, 116, 108, 132, 103, 136, 118, 102, 120, 114,105, 115, 132, 145, 119, 121, 112, 139, 125, 138, 109, 132, 134,156, 106, 117, 127, 144, 139, 139, 119, 140, 83, 110, 102,123,107, 143, 115, 136, 118, 139, 123, 112, 118, 125, 109, 119, 133,112, 114, 122, 109, 106, 123, 116, 131, 127, 115, 118, 112, 135,115, 146, 137, 116, 103, 144, 83, 123, 111, 110, 111, 100, 154,136, 100, 118, 119, 133, 134, 106, 129, 126, 110, 111, 109, 141,120, 117, 106, 149, 122, 122, 110, 118, 127, 121, 114, 125, 126,114, 140, 103, 130, 141, 117, 106, 114, 121, 114, 133, 137, 92,121, 112, 146, 97, 137, 105, 98, 117, 112, 81, 97, 139, 113,134, 106, 144, 110, 137, 137, 111, 104, 117, 100, 111, 101, 110,105, 129, 137, 112, 120, 113, 133, 112, 83, 94, 146, 133, 101,131, 116, 111, 84, 137, 115, 122, 106, 144, 109, 123, 116, 111,111, 133, 150] plt.figure(figsize=(20, 15)) # 计算组数 bin_width = 3 num_bins = (max(a) - min(a)) // bin_width # 频数分布直方图 plt.subplot(2,1,1) # 也可以传一个列表，长度为组数，值为分组依据，当组距不均匀的时候使用 plt.hist(a, num_bins) # 设置x刻度 plt.xticks(range(min(a), max(a) + bin_width, bin_width)) plt.xlabel(\"电影时长(分钟)\", fontproperties=my_font, fontsize=20) plt.ylabel(\"频数\", fontproperties=my_font, fontsize=30) plt.title(\"频数分布直方图\", fontproperties=my_font, fontsize=30) plt.grid() # 频率分布直方图（density=1） plt.subplot(2,1,2) plt.hist(a, num_bins, density=1) plt.xticks(range(min(a), max(a) + bin_width, bin_width)) plt.xlabel(\"电影时长(分钟)\", fontproperties=my_font, fontsize=20) plt.ylabel(\"频率\", fontproperties=my_font, fontsize=30) plt.title(\"频率分布直方图\", fontproperties=my_font, fontsize=30) plt.grid() plt.show() 统计后数据 在美国2004年人口普查发现有124 million的人在离家相对较远的地方工作。根据他们从家到上班地点所需要的时间,通过抽样统计(最后一列)出了下表的数据,这些数据能够绘制成直方图么? # 还有些疑问 interval = [0,5,10,15,20,25,30,35,40,45,60,90] width = [5,5,5,5,5,5,5,5,5,15,30,60] quantity = [836,2737,3723,3926,3596,1438,3273,642,824,613,215,47] plt.figure(figsize=(20,10), dpi=80) plt.bar(interval, quantity, width=width) x = interval _xtick_label = interval.append(150) plt.xticks(x, _xtick_label) # plt.grid() plt.show() "},"Web/Web前端概述.html":{"url":"Web/Web前端概述.html","title":"Web前端入门","keywords":"","body":"datetime:2019/5/17 17:12 author:nzb Web前端概述 说明：本文使用的部分插图来自Jon Duckett先生的HTML and CSS: Design and Build Websites一书，这是一本非常棒的前端入门书，有兴趣的读者可以在亚马逊或者其他网站上找到该书的购买链接。 HTML简史 1991年10月：一个非正式CERN（欧洲核子研究中心）文件首次公开18个HTML标签，这个文件的作者是物理学家蒂姆·伯纳斯-李，因此他是万维网的发明者，也是万维网联盟的主席。 1995年11月：HTML 2.0标准发布（RFC 1866）。 1997年1月：HTML 3.2作为W3C推荐标准发布。 1997年12月：HTML 4.0作为W3C推荐标准发布。 1999年12月：HTML4.01作为W3C推荐标准发布。 2008年1月：HTML5由W3C作为工作草案发布。 2011年5月：W3C将HTML5推进至“最终征求”（Last Call）阶段。 2012年12月：W3C指定HTML5作为“候选推荐”阶段。 2014年10月：HTML5作为稳定W3C推荐标准发布，这意味着HTML5的标准化已经完成。 HTML5新特性 引入原生多媒体支持（audio和video标签） 引入可编程内容（canvas标签） 引入语义Web（article、aside、details、figure、footer、header、nav、section、summary等标签） 引入新的表单控件（日历、邮箱、搜索、滑条等） 引入对离线存储更好的支持（localStorage和sessionStorage） 引入对定位、拖放、WebSocket、后台任务等的支持 使用标签承载内容 结构 head title meta body 文本 标题和段落 h1 ~ h6 p 上标和下标 sup sub 空白（白色空间折叠） 折行和水平标尺 br hr 语义化标签 加粗和强调 - strong 引用 - blockquote 缩写词和首字母缩写词 - abbr / acronym 引文 - cite 所有者联系信息 - address 内容的修改 - ins / del 列表（list） 有序列表（ordered list）- ol / li 无序列表（unordered list）- ul / li 定义列表（definition list）- dl / dt / dd 链接（anchor） 页面链接 锚链接 功能链接 图像（image） 图像存储位置 图像及其宽高 选择正确的图像格式 JPEG GIF PNG 矢量图 语义化标签 - figure / figcaption 表格（table） 基本的表格结构 - table / tr / td 表格的标题 - caption 跨行和跨列 - rowspan属性 / colspan属性 长表格 - thead / tbody / tfoot 表单（form） 重要属性 - action / method 表单控件（input）- type属性 文本框 - text / 密码框 - password / 数字框 - number 邮箱 - email / 电话 - tel / 日期 - date / 滑条 - range / URL - url / 搜索 - search 单选按钮 - radio / 复选按钮 - checkbox 文件上传 - file / 隐藏域（埋点）- hidden 提交按钮 - submit / 图像按钮 - image / 重置按钮 - reset 下拉列表 - select / option 文本域（多行文本）- textarea 组合表单元素 - fieldset / legend 音视频（audio / video） 视频格式和播放器 视频托管服务 添加视频的准备工作 video标签和属性 - autoplay / controls / loop / muted / preload / src audio标签和属性 - autoplay / controls / loop / muted / preload / src / width / height / poster 其他 文档类型 注释 属性 id class 块级元素 / 行级元素 内联框架（internal frame） 字符实体（实体替换符） 使用CSS渲染页面 简介 CSS的作用 CSS的工作原理 规则、属性和值 常用选择器 颜色（color） 如何指定颜色 颜色术语和颜色对比 背景色 文本（text / font） 文本的大小和字型(font-size / font-family) 粗细、样式、拉伸和装饰(font-weight / font-style / font-stretch / text-decoration) 行间距(line-height)、字母间距(letter-spacing)和单词间距(word-spacing) 对齐(text-align)方式和缩进(text-ident) 链接样式（:link / :visited / :active / :hover） CSS3新属性 阴影效果 - text-shadow 首字母和首行文本(:first-letter / :first-line) 响应用户 盒子（box model） 盒子大小的控制（width / height） 盒子的边框、外边距和内边距（border / margin / padding） 盒子的显示和隐藏（display / visibility） CSS3新属性 边框图像（border-image） 投影（border-shadow） 圆角（border-radius） 列表、表格和表单 列表的项目符号（list-style） 表格的边框和背景（border-collapse） 表单控件的外观 表单控件的对齐 浏览器的开发者工具 图像 控制图像的大小（display: inline-block） 对齐图像 背景图像（background / background-image / background-repeat / background-position） 布局 控制元素的位置（position / z-index） 普通流 相对定位 绝对定位 固定定位 浮动元素（float / clear） 网站布局 HTML5布局 适配屏幕尺寸 固定宽度布局 流体布局 布局网格 使用JavaScript控制行为 JavaScript基本语法 语句和注释 变量和数据类型 声明和赋值 简单数据类型和复杂数据类型 变量的命名规则 表达式和运算符 赋值运算符 算术运算符 比较运算符 逻辑运算符 分支结构 if...else... switch...cas...default... 循环结构 for循环 while循环 do...while循环 数组 创建数组 操作数组中的元素 函数 声明函数 调用函数 参数和返回值 匿名函数 立即调用函数 面向对象 对象的概念 创建对象的字面量语法 访问成员运算符 创建对象的构造函数语法 this关键字 添加和删除属性 delete关键字 标准对象 Number / String / Boolean / Symbol / Array / Function Date / Error / Math / RegEx / Object / Map / Set JSON / Promise / Generator / Reflect / Proxy BOM window对象的属性和方法 history对象 forward() / back() / go() location对象 navigator对象 screen对象 DOM DOM树 访问元素 getElementById() / querySelector() getElementsByClassName() / getElementsByTagName() / querySelectorAll() parentNode / previousSibling / nextSibling / children / firstChild / lastChild 操作元素 nodeValue innerHTML / textContent / createElement() / createTextNode() / appendChild() / insertBefore() / removeChild() className / id / hasAttribute() / getAttribute() / setAttribute() / removeAttribute() 事件处理 事件类型 UI事件：load / unload / error / resize / scroll 键盘事件：keydown / keyup / keypress 鼠标事件：click / dbclick / mousedown / mouseup / mousemove / mouseover / mouseout 焦点事件：focus / blur 表单事件：input / change / submit / reset / cut / copy / paste / select 事件绑定 HTML事件处理程序（不推荐使用，因为要做到标签与代码分离） 传统的DOM事件处理程序（只能附加一个回调函数） 事件监听器（旧的浏览器中不被支持） 事件流：事件捕获 / 事件冒泡 事件对象（低版本IE中的window.event） target（有些浏览器使用srcElement） type cancelable preventDefault() stopPropagation()（低版本IE中的cancelBubble） 鼠标事件 - 事件发生的位置 屏幕位置：screenX和screenY 页面位置：pageX和pageY 客户端位置：clientX和clientY 键盘事件 - 哪个键被按下了 keyCode属性（有些浏览器使用which） String.fromCharCode(event.keyCode) HTML5事件 DOMContentLoaded hashchange beforeunload JavaScript API 客户端存储 - localStorage和sessionStorage localStorage.colorSetting = '#a4509b'; localStorage['colorSetting'] = '#a4509b'; localStorage.setItem('colorSetting', '#a4509b'); 获取位置信息 - geolocation navigator.geolocation.getCurrentPosition(function(pos) { console.log(pos.coords.latitude) console.log(pos.coords.longitude) }) 从服务器获取数据 - Fetch API 绘制图形 - 的API 音视频 - 和的API 使用jQuery jQuery概述 Write Less Do More（用更少的代码来完成更多的工作） 使用CSS选择器来查找元素（更简单更方便） 使用jQuery方法来操作元素（解决浏览器兼容性问题、应用于所有元素并施加多个方法） 引入jQuery 下载jQuery的开发版和压缩版 从CDN加载jQuery window.jQuery || document.write('') 查找元素 选择器 * / element / #id / .class / selector1, selector2 ancestor descendant / parent>child / previous+next / previous~siblings 筛选器 基本筛选器：:not(selector) / :first / :last / :even / :odd / :eq(index) / :gt(index) / :lt(index) / :animated / :focus 内容筛选器：:contains('…') / :empty / :parent / :has(selector) 可见性筛选器：:hidden / :visible 子节点筛选器：:nth-child(expr) / :first-child / :last-child / :only-child 属性筛选器：[attribute] / [attribute='value'] / [attribute!='value'] / [attribute^='value'] / [attribute$='value'] / [attribute|='value'] / [attribute~='value'] 表单：:input / :text / :password / :radio / :checkbox / :submit / :image / :reset / :button / :file / :selected / :enabled / :disabled / :checked 执行操作 内容操作 获取/修改内容：html() / text() / replaceWith() / remove() 获取/设置元素：before() / after() / prepend() / append() / remove() / clone() / unwrap() / detach() / empty() / add() 获取/修改属性：attr() / removeAttr() / addClass() / removeClass() / css() 获取/设置表单值：val() 查找操作 查找方法：find() / parent() / children() / siblings() / next() / nextAll() / prev() / prevAll() 筛选器：filter() / not() / has() / is() / contains() 索引编号：eq() 尺寸和位置 尺寸相关：height() / width() / innerHeight() / innerWidth() / outerWidth() / outerHeight() 位置相关：offset() / position() / scrollLeft() / scrollTop() 特效和动画 基本动画：show() / hide() / toggle() 消失出现：fadeIn() / fadeOut() / fadeTo() / fadeToggle() 滑动效果：slideDown() / slideUp() / slideToggle() 自定义：delay() / stop() / animate() 事件 文档加载：ready() / load() 用户交互：on() / off() 链式操作 检测页面是否可用 $(document).ready(function() { }); $(function() { }); jQuery插件 jQuery Validation jQuery Treeview jQuery Autocomplete jQuery UI 避免和其他库的冲突 先引入其他库再引入jQuery的情况。 jQuery.noConflict(); jQuery(function() { jQuery('div').hide(); }); 先引入jQuery再引入其他库的情况。 jQuery(function() { jQuery('div').hide(); }); 使用Ajax Ajax是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。 原生的Ajax 基于jQuery的Ajax 加载内容 提交表单 前端框架 渐进式框架 - Vue.js 前后端分离开发（前端渲染）必选框架。 快速上手 引入Vue的JavaScript文件，我们仍然推荐从CDN服务器加载它。 数据绑定（声明式渲染 ）。 库存信息 const app = new Vue({ el: '#app', data: { product: 'iPhone X' } }); 条件与循环。 库存信息 - 已经售罄 const app = new Vue({ el: '#app', data: { products: [ {\"id\": 1, \"name\": \"iPhone X\", \"quantity\": 20}, {\"id\": 2, \"name\": \"华为 Mate20\", \"quantity\": 0}, {\"id\": 3, \"name\": \"小米 Mix3\", \"quantity\": 50} ] } }); 计算属性。 库存信息 - 已经售罄 库存总量：台 const app = new Vue({ el: '#app', data: { products: [ {\"id\": 1, \"name\": \"iPhone X\", \"quantity\": 20}, {\"id\": 2, \"name\": \"华为 Mate20\", \"quantity\": 0}, {\"id\": 3, \"name\": \"小米 Mix3\", \"quantity\": 50} ] }, computed: { totalQuantity() { return this.products.reduce((sum, product) => { return sum + product.quantity }, 0); } } }); 处理事件。 库存信息 - 已经售罄 增加库存 库存总量：台 const app = new Vue({ el: '#app', data: { products: [ {\"id\": 1, \"name\": \"iPhone X\", \"quantity\": 20}, {\"id\": 2, \"name\": \"华为 Mate20\", \"quantity\": 0}, {\"id\": 3, \"name\": \"小米 Mix3\", \"quantity\": 50} ] }, computed: { totalQuantity() { return this.products.reduce((sum, product) => { return sum + product.quantity }, 0); } } }); 用户输入。 库存信息 - 已经售罄 增加库存 库存总量：台 const app = new Vue({ el: '#app', data: { products: [ {\"id\": 1, \"name\": \"iPhone X\", \"quantity\": 20}, {\"id\": 2, \"name\": \"华为 Mate20\", \"quantity\": 0}, {\"id\": 3, \"name\": \"小米 Mix3\", \"quantity\": 50} ] }, computed: { totalQuantity() { return this.products.reduce((sum, product) => { return sum + product.quantity }, 0); } } }); 通过网络加载JSON数据。 库存信息 - 已经售罄 const app = new Vue({ el: '#app', data: { products: [] }， created() { fetch('https://jackfrued.top/api/products') .then(response => response.json()) .then(json => { this.products = json }); } }); 使用脚手架 - vue-cli Vue为商业项目开发提供了非常便捷的脚手架工具vue-cli，通过工具可以省去手工配置开发环境、测试环境和运行环境的步骤，让开发者只需要关注要解决的问题。 安装脚手架。 创建项目。 安装依赖包。 运行项目。 UI框架 - Element 基于Vue 2.0的桌面端组件库，用于构造用户界面，支持响应式布局。 引入Element的CSS和JavaScript文件。 一个简单的例子。 点我 开始使用Element吧 new Vue({ el: '#app', data: { visible: false, } }) 使用组件。 new Vue({ el: '#app', data: { tableData: [ { date: '2016-05-02', name: '王一霸', address: '上海市普陀区金沙江路 1518 弄' }, { date: '2016-05-04', name: '刘二狗', address: '上海市普陀区金沙江路 1517 弄' }, { date: '2016-05-01', name: '杨三萌', address: '上海市普陀区金沙江路 1519 弄' }, { date: '2016-05-03', name: '陈四吹', address: '上海市普陀区金沙江路 1516 弄' } ] } }) 报表框架 - ECharts 百度出品的开源可视化库，常用于生成各种类型的报表。 基于弹性盒子的CSS框架 - Bulma Bulma是一个基于Flexbox的现代化的CSS框架，其初衷就是移动优先（Mobile First），模块化设计，可以轻松用来实现各种简单或者复杂的内容布局，即使不懂CSS的开发者也能够使用它定制出漂亮的页面。 Bulma div { margin-top: 10px; } .column { color: #fff; background-color: #063; margin: 10px 10px; text-align: center; } 1 2 3 4 Primary Link Info Success Warning Danger 60% One Two Three Four Five Six Seven Eight Nine Ten Eleven Twelve 响应式布局框架 - Bootstrap 用于快速开发Web应用程序的前端框架，支持响应式布局。 特点 支持主流的浏览器和移动设备 容易上手 响应式设计 内容 网格系统 封装的CSS 现成的组件 JavaScript插件 可视化 "},"Web/HTML5/HTML5.html":{"url":"Web/HTML5/HTML5.html","title":"HTML5","keywords":"","body":"datetime:2019/7/1 9:43 author:nzb HTML5元素 元素指的是从开始标签到结束标签的所有代码 开始标签 元素内容 结束标签 this is my web page HTML元素语法： 元素的内容是开始标签与结束标签之间的内容 空元素在开始标签进行关闭 大多数HTML元素拥有属性 嵌套HTML元素 HTML5属性使用方法 标签可以拥有属性为元素提供更多的信息 属性以键值对的形式出现。 如：href=\"www.baidu.com\" 常用标签属性： :align对齐方式 :bgcolor背景颜色 :target规定在何处打开链接 通用属性 class：规定元素的类名 id：规定元素唯一id style：规定元素的样式 title：规定元素的额外信息 HTML5格式化 标签 描述 定义粗体文本 定义大号字,在HTML5取消采用CSS代替 定义着重文字 定义斜体字 定义小号字 定义加重语气 定义下标字 定义上标字 定义插入字 定义删除字 HTML5样式 标签： ：样式定义 ：资源引用 属性： rel=\"stylesheet\"：外部样式表 type=\"text/css\"：引入文档的类型 margin-left：边距 三种样式表插入方法： 外部样式表： 内部样式表： body{background-color: red} p{margin-left: 20px;} 内联样式表： HTML5链接 链接数据： 文本链接 图片链接 属性： href属性：指向另一个文档的链接 name属性：创建文档内的链接 img标签属性： alt：替换文本属性 width：宽 height：高 HTML5表格 标签 描述 定义表格 定义表格标题 定义表格的表头 定义表格的行 定义表格的单元 定义表格的页眉 定义表格的主体 定义表格的页脚 定义表格的列属性 没有边框的表格：不加border属性 表格中的表头：表头 空单元格：不书写内容即可 带有标题的表格：标题 表格内的标签： 单元4 单元5 苹果 香蕉 桃子 单元格边距：cellpadding=\"20\" 单元格间距：cellspacing=\"10\" 表格内背景颜色和图像：bgcolor=\"red\" HTML5列表 标签 描述 有序列表 无序列表 列表项 列表 列表项 描述 无序列表 使用标签：、 属性：disc、circle、square 有序列表 使用标签：、 属性：A、a、I、i、start 嵌套列表 使用标签：、、 自定义列表 使用标签：、、 HTML5块 HTML块元素 块元素在显示时，通常会以新行开始。 如：、、 HTML内联元素 内联元素通常不会以新行开始。 如：、、 HTML元素 元素也被称为块元素，其主要是组合HTML元素的容器 HTML元素 元素是内联元素，可作为文本的容器 HTML5布局 使用元素布局 div布局 body{ margin: 0px; } #container{ width: 100%; height: 950px; background-color: gray; } #heading{ width: 100%; height: 10%; background-color: #1b6d85; } #content_menu{ width: 30%; height: 80%; background-color: #5cb85c; /*从左到右浮动*/ float: left; } #content_body{ width: 70%; height: 80%; background-color: #8a6d3b; float: left; } #footing{ width: 100%; height: 10%; background-color: #985f0d; /*清除浮动*/ clear: both; } 头部 内容菜单 内容主体 底部 使用元素布局 table布局 这是头部 view code other 主体 右菜单 底部 HTML5表单 表单用于获取不同类型的用户输入 常用表单标签 表单 输入域 文本域 控制标签 定义域 域的标题 选择列表 选项组 下拉列表中的选项 按钮 HTML5框架 框架标签(frame):(HTML5已过时) 框架对于页面的设计有着很大的作用 框架集标签():(HTML5中已过时) 框架集标签定义如何将窗口分隔为框架 每一个frameset定义一系列行或列 rows/cols的值规定了每行或每列占据屏幕的面积 常用标签： noresize：固定框架大小 cols：列 rows：行 内联框架(HTML5主要使用的) iframe target属性： _self：当前frame打开 _blank：新窗口打开 _parent：父级frame打开 _top：当前窗口打开 frame.html frame 百度--> framea.html Title framea 百度一下 --> frameb.html Title frameb framec.html Title framec HTML5背景 背景标签： Background 背景颜色 Bgcolor 颜色： 颜色是由一个十六进制符号来定义，这个符号由红色、蓝色和绿色的值组成(RGB) 颜色值最小值：0(#00) 颜色值最大值：255(#FF) 红色：#FF0000 绿色：#00FF00 蓝色：#0000FF HTML5实体 实体 HTML中预留字符串必须被替换成字符实体。如：、& XHTML的规范化 什么是XHTML? XHTML指的是可扩展超文本标记语言 XHTML与HTML4.01几乎是相同的 XHTML是更严格更纯净的HTML版本 XHTML是以XML应用的方式定义的HTML XHTML得到所有主流浏览器的支持 为什么使用XHTML? 为了代码的完整性和良好性 文档声明： DTD：规定了使用通用标记语言的网页语法 三种XHTML文档类型 STRICT(严格类型) TRANSITIONAL(过度类型) FRAMESET(框架类型) XHTML元素语法： XHTML元素必须嵌套 XHTML元素必须始终关闭 XHTML元素必须小写 XHTML文档必须有一个根元素 XHTML属性语法规则： XHTML属性必须使用小写 XHTML属性值必须用引号包围 XHTML属性最小化也是禁止的 HTML5新特性 引入原生多媒体支持（audio和video标签） 视频格式和播放器 视频托管服务 添加视频的准备工作 video标签和属性 - autoplay / controls / loop / muted / preload / src audio标签和属性 - autoplay / controls / loop / muted / preload / src / width / height / poster 引入可编程内容（canvas标签） 引入语义Web（article、aside、details、figure、footer、header、nav、section、summary等标签） 引入新的表单控件（日历、邮箱、搜索、滑条等） 引入对离线存储更好的支持（localStorage和sessionStorage） 引入对定位、拖放、WebSocket、后台任务等的支持 HTML5新增的主体结构元素 article元素 article元素代表文档、页面或应用程序中独立的、完整的、可以独立被外部引用的内容。它可以是一篇博客或者报刊中的一篇文章，一篇论坛帖子、一段用户评论或独立的插件，或其他任何独立的内容。 article元素可以嵌套使用，也可以用来表示插件。 article元素 英雄联盟 欢迎来到英雄联盟 作者 评论 time 这是底部 这是一个内嵌页面 section元素 section元素用于对网站或应用程序中页面上的内容进行分块。一个section元素通常由其内容及标题组成。但section元素并非一个普通的容器元素；当一个容器需要被直接定义样式或通过脚本定义行为时，推荐使用div而非section元素。 section元素 苹果 这是一个苹果 苹果 这是一个苹果 红富士 这是苹果的一种 国光 这是苹果的一种 水果 苹果 内容 苹果 内容 苹果 内容 section与article的区别 section的作用强调对文章或页面进行分段、分块，而article元素强调独立性 section使用总结：1、不要将section元素作为设置样式的页面容器，那是div的工作。2、如果使用article、aside、nav元素更符合使用条件，那就不要使用section元素。3、没有标题内容，不要使用section元素。 nav元素 nav元素是一个可以用作页面导航的连接组，其中的导航元素链接到其他页面或当前页面的其他部分。并不是所有的连接组都要被放进nav元素，只需要将主要的、基本的连接组放进nav元素即可。nav的应用场景：传统导航栏、侧边导航栏、页内导航、翻页操作。 nav元素 主页 开发文档 html5与css3的历史 html5历史 css3历史 css3的历史 ... 删除 修改 版权声明 HTML5中不能使用menu元素代替nav元素 aside元素 -aside元素用来表示当前页面或文章的附属信息部分，它可以包含于当前页面或主要内容相关的引用、侧边栏、广告、导航条，以及其他类似的有区别于主要内容的部分。 aside元素 js入门 语法 文章的正文。。。 名词解释 语法：。。。。。。。 评论 2019-7-1 好好学习 time元素和微格式 time元素 2019-7-1 2019-7-1 2019-7-1 2019-7-1 苹果 发布时间 2019-7-1 舞会事件 2019-7-2 HTML5新增的非主体结构元素 header元素 Header元素是一种具有引导和导航作用的结构元素，通常放置整个页面或页面内的一个内容区域的标题，但是也可以包含其他内容列如数据表格，搜索表单或相关Logo图片！ header元素 it最新技术 信息 信息1 信息2 footer元素 footer元素可作为上层父级内容区块或是一个根区块的脚注。footer通常包括相关区块的脚注信息，如作者，相关阅读连接及其版权信息等。 footer元素 --> 版权信息 版权信息 版权信息 版权信息 --> 这是文章的底部 这是块底部 hgroup元素(已废除) hgroup元素是将标题及其子标题进行分组的元素。 hgroup元素通常被分为H1~H6元素进行分组，如一个内容区块的标题及其子元素算一组。 hgroup元素 这是文章标题 这是一个子标题 2019-7-1 这是内容 这是底部 address元素 address元素用来存放文档中呈现的联系信息，文档作者，等等的名字 网站链接 电子邮箱 真实地址 电话号码 等 address元素 a b c 百度一下 2019-7-1 网页编排规则 网页标题 文章主标题 文章子标题 文章正文 评论标题 评论正文 版权所有：hawen 表单新增元素与属性 表单内元素的form属性 在Html4中，表单内的从属元素必须写在表单内部，而在HTML5中，可以把它们书写在页面的任何地方，然后为该元素指定一个form属性，属性值为该表单的id。 这样九可以声明该元素从属于指定表单了。 表单内元素的formaction属性 在HTML4中，一个表单内的所有元素只能通过表单的action属性统一提交到另一个页面，而在HTML5中可以为所有的提交按钮。 表单内元素的formmethod属性 在HTML4中，一个表单内只有一个action属性用来对表单内所有元素统一指定提交页面，所以每个表单内也只有一个method属性来统一指定提交方法。 在HTML5中，可以使用formmethod属性来对每个表单元素分别指定不同的提交方法。 表单内元素的formenctype属性 在HTML4中，表单元素具有一个enctype属性，该属性用于指定在表单发送到服务器之前应该如何对表单内的数据进行编码。 application/x-www-from-urlencoded：编码方式把表单数据转换成一个字符串形式?a=value1&b=value2&c=value3,然后把这个字符串价到提交的目标URL地址后面。 该属性为表单enctype属性的默认属性值。 multipart/form-data:不对字符编码,在使用包含文件上传控件的表单时，必须使用该值。 text/plain:对表单数据中的空格被转换为\"+\",但不对表单数据中的特殊字符进行编码。 在HTML5中，可以使用formenctype属性对表单元素分别指定不同的编码方式。 文件: 表单内元素的formtarget属性 在HTML4中，表单元素具有一个target属性，该属性用于指定在何处打开表单提交后，所需要加载的页面。 _blank:在新的浏览器窗口中打开。 _self:默认值，在相同的框架中打开。 _parent:在当前框架的父框架中打开。 _top:在当前浏览器窗口中打开。 framename:在指定的框架中打开。 在HTML5中，可以对多个提交按钮分别使用formtarget属性来指定提交后在何处打开所需要加载的页面。 表单内元素的autofocus属性 文本框、选择框或按钮加上autofocus属性，当页面打开时，该控件自动获取光标焦点。一个页面上只能有一个控件具有autofocus属性。 表单内元素的required属性 HTML5中新增的required属性可以应用在大多数输入元素上，在提交时，将验证输入内容是否合法，如果不合法则不允许提交，同时在浏览器显示相应的提示信息。 表单内元素的labels属性 在HTML5中，为所有可使用label的表单元素，定义一个labels属性，属性值为一个NodeList对象，代表该元素所绑定的标签元素构成的集合。 var TxtName=document.getElementById(\"txt_name\"); alert(TxtName.labels.length); 名字: 标签的control属性 在HTML5中，可以在标签内部放置一个表单元素，并且通过该标签的control属性来访问该表单元素。 邮编: 请输入六位数字 function setValue(){ var label = document.getElementById('label'); var textbox = label.control; textbox.value='10010'; } 文本框的placeholder属性 placeholder是指当文本框处于微输入状态时显示的输入提示。 文本框的list属性 HTML5中,为增加了一个list属性，该属性的值为某个datalist的id。 datalist元素也是HTML5中新增的元素，该元素类似于选择框(Select元素),但是当用户想要设定的值不在选择列表之内时，允许自行输入。 datalist元素本身并不显示，而是当文本框获取焦点时以提示输入的方式显示。 你好 早上 文本框的AutoComplete属性 辅助输入所用的自动完成功能，时一个即节省输入时间又十分方便的功能。在HTML5之前，因为谁都可以看见输入的值，所以在安全方面存在缺陷。 对于autocomplete属性，可以指定\"on\"、\"off\"与\"\"(不指定)这三种值。在不进行指定时，使用浏览器的默认值。把该属性设为on时， 可以显示指定候补输入的数据列表。使用datalist元素与list属性提供候补输入的数据列表，在执行自动完成时， 可以将该datalist元素中的数据作为候补输入的数据在文本框中自动显示。 文本框的pattern属性 在HTML5中，对input元素使用pattern属性，并且将属性值设置某个格式的正则表达式时，在提交时会对这些进行检查，检查其内容是否符合给定格式。 文本框的SelectDirection属性 对input 元素和textarea 元素，HTML5增加了SelectionDirection属性。当用户在这两个元素中用户鼠标选取部分文字时， 可以使用属性来获取选取方向。正向选取:forward,反向选取为:backward。 复选框的indeterminate属性 对复选框checkbox元素来说，过去只有选取与非选取两种状态。在HTML5中，可以在Javascript脚本代码中对该元素使用indeterminate属性， 以说明复选框处于\"尚未明确是否选取的状态\"。indeterminate属性为boolean 类型 当为true 时，浏览器中的复选框将显示为不明状态。 需要注意的时，indeterminate属性与checked属性时两种不同的属性。因此，在判断复选框时，应该现判断indeterminate属性值，然后在判断checked属性值。 var cb = document.getElementById('cb'); cb.indeterminate = true; image提交按钮的height属性与width属性 针对类型为image的input元素，HTML5新增了两个属性，height、width分别用来指定图片的高、宽。 "},"Web/CSS/CSS.html":{"url":"Web/CSS/CSS.html","title":"CSS","keywords":"","body":"datetime:2019/7/2 9:40 author:nzb CSS基础语法 `selector { property:value }` 例：h1{color:red;font-size:14px;} 属性大于1个之后，属性之间用分号隔开，如果值大于一个单词，则需要加上引号：p{font-family:\"sans serif\"} 浏览器读取 CSS 的顺序是从上到下，这意味着，在发生冲突时，浏览器会使用最后的 CSS 声明。后面的会覆盖前面的。 id 声明都会覆盖 class 声明。行内样式会覆盖其他声明。 多情况下，你会使用 CSS 库，这些库可能会意外覆盖掉你自己的 CSS。所以当你需要确保某元素具有指定的 CSS 时，你可以使用 !important。 CSS高级语法 选择器分组： h1,h2,h3,h4,h5{color:red;} 继承：body{color:green} 派生选择器 通过依据元素在其位置的上下文关系来定义样式 address元素 li strong{ color: red; } strong{ color: gray; } 文章1 文章2 id选择器 id选择器可以为标有id的HTML元素指定特定的样式 id选择器以\"#\"来定义 目前比较常用的方式是id选择器常常用于建立派生选择器 address元素 #div1{ color: red; } #div1 a{ color: blue; } 这是一个div 这是超链接 类选择器 类选择器以一个点显示 class也可以作为派生选择器 address元素 .dclass p{ color: red; } 这是一个p标签 属性选择器 属性选择器：对带有指定属性的HTML元素设置样式 属性和值选择器 address元素 [title]{ color:red; } [title=te]{ color: blue; } 这是一个p标签 这是一个p标签 CSS背景 CSS允许应用纯色作为背景，也允许使用背景图像创建相当复杂的效果 属性 描述 backgroud-attachment 背景图是否或者随着页面的其余部分滚动 backgroud-color 设置元素的背景颜色 backgroud-image 把图片设置为背景 backgroud-position 设置背景图片的起始位置 backgroud-repeat 设置背景图片是否及如何重复 backgroud-size 规定背景图片的尺寸 backgroud-origin 规定背景图片的定位区域 backgroud-clip 规定背景的绘制区域 CSS文本 属性 描述 color 文本颜色 direction 文本方向 line-height 行高 letter-spacing 字符间距 text-align 对齐元素中的文本 text-decoration 向文本添加修饰 text-indent 缩进元素中文本的首行 text-transform 元素中的字母 unicode-bidi 设置文本方向 white-space 元素中空白的处理方式 word-spacing 字间距 CSS3文本效果 属性 描述 text-shadow 向文本添加阴影 word-wrap 规定文本的换行规则 CSS 字体 CSS字体属性定义文本的字体系列、大小、加粗、风格和变形 属性 描述 font-family 设置字体系列 font-size 设置字体的尺寸 font-style 设置字体风格 font-variant 以小型大写字体或正常字体显示文本 font-weight 设置字体的粗细 CSS链接 CSS链接的四种状态 a:link 普通的、未被访问的链接 a:visited 用户已访问的链接 a:hover 鼠标指针位于链接的上方 a:active 链接被点击的时刻 常见的链接方式 text-decoration 属性大多用于去掉链接中的下划线 设置背景颜色 -backgroud-color CSS列表 CSS列表属性允许你放置、改变列表标志，或者将图像作为列表项标志 属性 描述 list-style 简写列表项 list-style-image 列表项图像 list-style-position 列表标志位置 list-style-type 列表类型 CSS表格 指定CSS表格边框，使用border属性。 border-collapse 属性设置表格的边框是否被折叠成一个单一的边框或隔开： Width和height属性定义表格的宽度和高度。 表格中的文本对齐和垂直对齐属性。text-align属性设置水平对齐方式，向左，右，或中心： 表格填充：padding 表格颜色：color CSS轮廓 属性 描述 outline 设置轮廓属性 outline-color 设置轮廓的颜色 outline-style 设置轮廓的样式 outline-width 设置轮廓的宽度 CSS定位 CSS定位 改变元素在页面上的位置 CSS定位机制 普通流：元素按照其在HTML中的位置顺序决定排布的过程 浮动 绝对布局 CSS定位属性 属性 描述 position 把元素放在一个静态的、相对的、绝对的、或固定的位置中 top 元素向上的偏移量 left 元素向左的偏移量 right 元素向右的偏移量 bottom 元素向下的偏移量 overflow 设置元素溢出其区域发生的事情 clip 设置元素显示的形状 vertical-align 设置元素垂直对齐方式 z-index 设置元素的堆叠顺序 position 属性的五个值： static：HTML 元素的默认值，即没有定位，遵循正常的文档流对象。静态定位的元素不会受到 top, bottom, left, right影响。 relative：元素的位置相对于浏览器窗口是固定位置。即使窗口是滚动的它也不会移动： fixed：相对定位元素的定位是相对其正常位置。移动相对定位元素，但它原本所占的空间不会改变。相对定位元素经常被用来作为绝对定位元素的容器块。 absolute：绝对定位的元素的位置相对于最近的已定位父元素，如果元素没有已定位的父元素，那么它的位置相对于。absolute 定位使元素的位置与文档流无关，因此不占据空间。absolute 定位的元素和其他元素重叠。 sticky：sticky 英文字面意思是粘，粘贴，所以可以把它称之为粘性定位。position: sticky; 基于用户的滚动位置来定位。粘性定位的元素是依赖于用户的滚动，在 position:relative 与 position:fixed 定位之间切换。它的行为就像 position:relative; 而当页面滚动超出目标区域时，它的表现就像 position:fixed;，它会固定在目标位置。元素定位表现为在跨越特定阈值前为相对定位，之后为固定定位。这个特定阈值指的是 top, right, bottom 或 left 之一，换言之，指定 top, right, bottom 或 left 四个阈值其中之一，才可使粘性定位生效。否则其行为与相对定位相同。 重叠的元素 元素的定位与文档流无关，所以它们可以覆盖页面上的其它元素 z-index属性指定了一个元素的堆叠顺序（哪个元素应该放在前面，或后面） 一个元素可以有正数或负数的堆叠顺序： 具有更高堆叠顺序的元素总是在较低的堆叠顺序元素的前面。 注意： 如果两个定位元素重叠，没有指定z - index，最后定位在HTML代码中的元素将被显示在最前面。 CSS浮动 浮动： float属性可用的值： left：元素向左浮动 right：元素向右浮动 none：元素不浮动 inherit：从父级继承浮动属性 clear属性： 去掉浮动属性(包括继承来的属性) clear属性值： left、right：去掉元素向左、向右浮动 both：左右两侧去掉浮动 inherit：从父级继承来clear的值 盒子模型 概述 margin、border、padding、content部分组成 内边距 padding padding-top padding-bottom padding-right padding-left 边框 CSS边框 我们可以创建出效果出色的边框，并且可以应用于任何元素 边框的样式： boder-style：定义了10个不同的非继承样式，包括none none: 默认无边框 dotted: 定义一个点线边框 dashed: 定义一个虚线边框 solid: 定义实线边框 double: 定义两个边框。 两个边框的宽度和 border-width 的值相同 groove: 定义3D沟槽边框。效果取决于边框的颜色值 ridge: 定义3D脊边框。效果取决于边框的颜色值 inset:定义一个3D的嵌入边框。效果取决于边框的颜色值 outset: 定义一个3D突出边框。 效果取决于边框的颜色值 单边框样式 border-top-style border-right-style border-bottom-style border-left-style 边框宽度 border-width：可以指定长度值，比如 2px 或 0.1em(单位为 px, pt, cm, em 等)，或者使用 3 个关键字之一，它们分别是 thick 、medium（默认值） 和 thin。 单边框宽度 border-top-width border-right-width border-bottom-width border-left-width 边框颜色 border-color 单边框颜色 border-top-color border-right-color border-bottom-color border-left-color CSS3边框 border-image：设置所有边框图像的速记属性。 border-radius ：一个用于设置所有四个边框-*-半径属性的速记属性 box-shadow：附加一个或多个下拉框的阴影 外边距 属性 描述 margin 简写属性。在一个声明中设置所有外边距属性, 如margin：上下，左右。也可以auto自适应会居中 margin-bottom 设置元素的下外边距 margin-left 设置元素的左外边距 margin-right 设置元素的右外边距 margin-top 设置元素的上外边距 外边距合并 外边距合并就是第一个叠加的概念 盒子模型应用 盒子模型 *{ margin: 0px; padding: 0px; } .top{ width: 100%; height: 50px; background-color: black; } .top_content{ width: 75%; height: 50px; background-color: #8a6d3b; margin: 0px auto; } .body{ margin: 20px auto; width: 75%; height: 1500px; background-color: #9d9d9d; } .body_img{ width: 100%; height: 500px; background-color: #5bc0de; } .body_content{ width: 100%; height: 1000px; background-color: #985f0d; } .body_no{ width: 100%; height: 40px; background-color: #23527c; } .footing{ width: 75%; height: 400px; background-color: #a6e1ec; margin: 0 auto; } .footing_content{ width: 100%; height: 300px; background-color: #245269; } .footing_subnav{ width: 100%; height: 100px; background-color: #555555; } CSS对齐-水平&垂直对齐 元素居中对齐 要水平居中对齐一个元素(如 ), 可以使用 margin: auto;。 设置到元素的宽度将防止它溢出到容器的边缘。 元素通过指定宽度，并将两边的空外边距平均分配： 注意: 如果没有设置 width 属性(或者设置 100%)，居中对齐将不起作用。 文本居中对齐 如果仅仅是为了文本在元素内居中对齐，可以使用 text-align: center; 图片居中对齐 要让图片居中对齐, 可以使用 margin: auto; 并将它放到 块 元素中: 左右对齐 - 使用定位方式 我们可以使用 position: absolute; 属性来对齐元素: .right { position: absolute; right: 0px; width: 300px; border: 3px solid #73AD21; padding: 10px; } 注释：绝对定位元素会被从正常流中删除，并且能够交叠元素。 提示: 当使用 position 来对齐元素时, 通常 元素会设置 margin 和 padding 。 这样可以避免在不同的浏览器中出现可见的差异。 body { margin: 0; padding: 0; } .container { position: relative; width: 100%; } .right { position: absolute; right: 0px; width: 300px; background-color: #b0e0e6; } 左右对齐 - 使用 float 方式 我们也可以使用 float 属性来对齐元素 垂直居中对齐 - 使用 padding CSS 中有很多方式可以实现垂直居中对齐。 一个简单的方式就是头部顶部使用 padding 如果要水平和垂直都居中，可以使用 padding 和 text-align: center: 垂直居中 - 使用 line-height 垂直居中 - 使用 position 和 transform CSS尺寸 属性 描述 height 设置元素的高度 line-height 设置行高 max-height 设置元素的最大高度 max-width 设置元素的最大宽度 min-height 设置元素的最小高度 min-width 设置元素的最小宽度 width 设置元素的宽度 CSS分类 属性 描述 clear 设置一个元素的侧面是否允许其他的浮动元素 cursor 规定当指向某元素之上时显示的指针类型 display 设置是否及如何显示元素 float 定义元素在那个方向浮动 position 把元素放置到一个静态的、相对的、绝对的、固定的位置 visibility 设置元素是否看见或不可见 CSS中块级、内联元素的应用： 利用CSS我们可以摆脱上面表格里HTML标签归类的限制，自由地在不同标签/元素上应用我们需要的属性。 主要用的CSS样式有以下三个： display:block -- 显示为块级元素 display:inline -- 显示为内联元素 display:inline-block -- 显示为内联块元素，表现为同行显示并可修改宽高内外边距等属性 我们常将元素加上display:inline-block样式，原本垂直的列表就可以水平显示了。 导航栏 导航栏=链接列表 作为标准的HTML基础一个导航栏是必须的。在我们的例子中我们将建立一个标准的HTML列表导航栏。 导航条基本上是一个链接列表，所以使用 和 元素非常有意义 ul { list-style-type: none; margin: 0; padding: 0; width: 200px; background-color: #f1f1f1; } /*垂直导航栏*/ li a { display: block; color: #000; padding: 8px 16px; text-decoration: none; } /* 鼠标移动到选项上修改背景颜色 */ li a:hover { background-color: #555; color: white; } /*激活/当前导航条实例*/ .active { background-color: #4CAF50; color: white; } 主页 新闻 联系 关于 示例说明： display:block - 显示块元素的链接，让整体变为可点击链接区域（不只是文本），它允许我们指定宽度 width:60px - 块元素默认情况下是最大宽度。我们要指定一个60像素的宽度 水平导航栏 有两种方法创建横向导航栏。使用内联(inline)或浮动(float)的列表项。 这两种方法都很好，但如果你想链接到具有相同的大小，你必须使用浮动的方法。 CSS图片 圆角图片：border-radius: 8px; 椭圆形图片：border-radius: 50%; 缩略图：我们使用 border 属性来创建缩略图。 透明度：opacity。 Opacity属性值从0.0 - 1.0。值越小，使得元素更加透明。 选择器详解 元素选择器 选择器分组(以逗号分隔) 通配符：* 一般这样设置： `*{ margin:0px padding:0px }` 类选择器 class 选择器用于描述一组元素的样式，class 选择器有别于id选择器，class可以在多个元素中使用。 class 选择器在HTML中以class属性表示, 在 CSS 中，类选择器以一个点\".\"号显示： ID选择器 HTML元素以id属性来设置id选择器,CSS 中 id 选择器以 \"#\" 来定义 ID属性不要以数字开头，数字开头的ID在 Mozilla/Firefox 浏览器中不起作用。 属性选择器 属性选择器： `[title] { color:blue; }` 属性和值选择器： `[title=runoob] { border:5px solid green; }` 属性和值的选择器 - 多值： [title~=hello] { color:blue; } 后代选择器(以空格分隔) 选取所有 元素插入到 元素中： `div p { background-color:yellow; }` 子元素选择器(以大于号分隔) 选择了元素中所有直接子元素 ： `div>p { background-color:yellow; }` 相邻兄弟选择器(以加号分隔) 选取了所有位于 元素后的第一个 元素： `div+p { background-color:yellow; }` 后续兄弟选择器 选取了所有 元素之后的所有相邻兄弟元素 ： `div~p { background-color:yellow; }` 2D、3D转换(transform) 2D 转换： 移动：translate()：根据左(X轴)和顶部(Y轴)位置给定的参数，从当前元素位置移动。 旋转：rotate()：在一个给定度数顺时针旋转的元素。负值是允许的，这样是元素逆时针旋转。 div { transform: rotate(30deg); /*浏览器支持*/ -ms-transform: rotate(30deg); /* IE 9 */ -webkit-transform: rotate(30deg); /* Safari and Chrome */ } 缩放：scale()：该元素增加或减少的大小，取决于宽度（X轴）和高度（Y轴）的参数。 倾斜：skew()： 包含两个参数值，分别表示X轴和Y轴倾斜的角度，如果第二个参数为空，则默认为0，参数为负表示向相反方向倾斜。 skewX();表示只在X轴(水平方向)倾斜。 skewY();表示只在Y轴(垂直方向)倾斜。 matrix()： matrix()方法和2D变换方法合并成一个。 matrix 方法有六个参数，包含旋转，缩放，移动（平移）和倾斜功能。 3D转换： rotateX()：围绕其在一个给定度数X轴旋转的元素。 rotateY()：围绕其在一个给定度数Y轴旋转的元素 过渡 属性 描述 transition 简写属性，用于在一个属性中设置四个过渡属性 transition-property 规定应用过渡的 CSS 属性的名称 transition-duration 定义过渡效果花费的时间。默认是 0 transition-timing-function 规定过渡效果的时间曲线。默认是 \"ease\" transition-delay 规定过渡效果何时开始。默认是 0 /*在一个例子中使用所有过渡属性：*/ div { transition-property: width; transition-duration: 1s; transition-timing-function: linear; transition-delay: 2s; /* Safari */ -webkit-transition-property:width; -webkit-transition-duration:1s; -webkit-transition-timing-function:linear; -webkit-transition-delay:2s; } /*与上面的例子相同的过渡效果，但是使用了简写的 transition 属性：*/ div { transition: width 1s linear 2s; /* Safari */ -webkit-transition:width 1s linear 2s; } 动画 属性 描述 @keyframes 规定动画 animation 所有动画属性的简写属性，除了 animation-play-state 属性 animation-name 规定 @keyframes 动画的名称 animation-duration 规定动画完成一个周期所花费的秒或毫秒。默认是 0 animation-timing-function 规定动画的速度曲线。默认是 \"ease\" animation-fill-mode 规定当动画不播放时（当动画完成时，或当动画有一个延迟未开始播放时），要应用到元素的样式 animation-delay 规定过渡效果何时开始。默认是 0 animation-iteration-count 规定动画被播放的次数。默认是 1 animation-direction 规定动画是否在下一周期逆向地播放。默认是 \"normal\" animation-play-state 规定动画是否正在运行或暂停。默认是 \"running\" 菜鸟教程(runoob.com) div { width:100px; height:100px; background:red; position:relative; animation-name:myfirst; animation-duration:5s; animation-timing-function:linear; animation-delay:2s; animation-iteration-count:infinite; animation-direction:alternate; animation-play-state:running; /* Safari and Chrome: */ -webkit-animation-name:myfirst; -webkit-animation-duration:5s; -webkit-animation-timing-function:linear; -webkit-animation-delay:2s; -webkit-animation-iteration-count:infinite; -webkit-animation-direction:alternate; -webkit-animation-play-state:running; } /*与上面的动画相同，但是使用了简写的动画 animation 属性：*/ div { width:100px; height:100px; background:red; position:relative; animation:myfirst 5s linear 2s infinite alternate; /* Firefox: */ -moz-animation:myfirst 5s linear 2s infinite alternate; /* Safari and Chrome: */ -webkit-animation:myfirst 5s linear 2s infinite alternate; /* Opera: */ -o-animation:myfirst 5s linear 2s infinite alternate; } @keyframes myfirst { 0% {background:red; left:0px; top:0px;} 25% {background:yellow; left:200px; top:0px;} 50% {background:blue; left:200px; top:200px;} 75% {background:green; left:0px; top:200px;} 100% {background:red; left:0px; top:0px;} } @-webkit-keyframes myfirst /* Safari and Chrome */ { 0% {background:red; left:0px; top:0px;} 25% {background:yellow; left:200px; top:0px;} 50% {background:blue; left:200px; top:200px;} 75% {background:green; left:0px; top:200px;} 100% {background:red; left:0px; top:0px;} } 注意: 该实例在 Internet Explorer 9 及更早 IE 版本是无效的。 多列 column-count：指定了需要分割的列数。 column-fill： 指定如何填充列。 column-gap：指定了列与列间的间隙。 column-rule-style：指定了列与列间的边框样式。 column-rule-width：指定了两列的边框厚度 column-rule-color：指定了两列的边框颜色 column-rule：是 column-rule-* 所有属性的简写 column-span：指定元素要跨越多少列。 column-width：指定了列的宽度。 columns：设置 column-width 和 column-count 的简写 瀑布流 waterfall .container{ column-width: 200px; -webkit-column-width: 200px; -webkit-column-gap: 5px; } .container div{ width: 200px; margin: 5px; } .container p{ text-align: center; } 标签 标签 标签 标签 标签 标签 "},"Web/JavaScript/JavaScript基础.html":{"url":"Web/JavaScript/JavaScript基础.html","title":"JavaScript基础","keywords":"","body":"datetime:2019/7/3 15:48 author:nzb 语法与注释 JavaScript语句 JavaScript语句向浏览器发出的命令。语句的作用是告诉浏览器该做什么。 分号： 语句之间的分割是分号(;) 注意：分号是可选项，有时候看到不以分号隔开的。 JavaScript代码： 按照编写顺序依次执行 标识符： JavaScript标识符必须以字母、下划线或美元符号开始 JavaScript关键字 JavaScript对大小写敏感 空格 JavaScript会忽略多余的空格 代码换行 保留字 单行注释 // 多行注释 /**/ 变量和数据类型 变量是用来存储信息的“容器”，使用var来声明 例: var x=10; var y=10.1; var z=\"hello\"; 数据类型 字符串(String) 数字(Number) 布尔(Boolean) 数组(Array) var arr=['hello',1,2]; var arr=new Array('world',2,3); var arr=new Array(); arr[0]=4; arr[1]=5; arr[2]=6; 对象(Object) 空(null) 未定义 可以通过赋值为null的方式清除变量 运算符 赋值运算符 =、+=、-=、*=、/=、%= 算术运算符 +、-、*、/、++、-- 比较运算符 ==、===、!=、!==、>、=、 逻辑运算符 &&、||、！ 条件(三目)运算符 例：x 字符串操作 相加就是拼接，任何类型相加字符串都会转化为字符串然后拼接 分支结构 if...else... var i = 10; if(i>=10){ document.write(\"i大于等于10\"); }else{ document.write(\"i小于10\"); } // 可以无限嵌套 if(i>10){ document.write(\"i大于10\"); }else if(i switch...cas...default... var i = 5; switch (i){ case 1: document.write(\"i为1\"); break; case 2: document.write(\"i为2\"); break; default: document.write(\"条件不满足\"); }; 循环结构 for循环 var i=[1,2,3,4,5,6]; for(var j=0;j while循环 var i = 1; while (i do...while循环 var i = 1; do{ document.write(\"i\"); i++; }while (i 跳转语句 break continue return 函数 定义函数 定义函数： function 函数名(){ 函数体; (代码块) } 注意： JavaScript对大小写十分敏感，所以这里的function必须小写。在函数调用时，也必须按照函数的相同名称来调用函数。 调用函数 function demo() { var a = 10; var b = 20; var sum = a+b; alert(sum); } // 第一种调用方式 demo(); // 第二种调用方式 按钮 带参数的函数 参数的个数可以为任意多，每个参数通过\",\"隔开 function demo(a,b) { var sum = a+b; alert(sum); } demo(10,20); 带返回值的函数 function demo(a,b) { var sum = a+b; return sum; } var sum = demo(10,20); alert(sum) 局部变量和全局变量 局部变量：函数内部声明 全局变量：函数外部声明 var n = 10; m = 10; //全局变量 任何地方都可以使用 function demo() { var i = 10; //局部变量 只能在当前函数中使用 x = 10; // 全局变量 只要调用了该函数任何地方都可以使用 } demo(); alert(x); 异常捕获 异常 当JavaScript引擎执行JavaScript代码时，发生了错误，导致程序停止运行 异常抛出 当异常产生，并且将这个异常生成一个错误信息 异常捕获 try{ 发生异常的代码块; }catch(err){ 错误信息处理; } Throw语句： 通过throw语句创建一个自定义错误 提交 function demo() { try{ var e = document.getElementById(\"txt\").value; if(e==\"\"){ throw \"请输入\"; } }catch (e) { alert(e) } } 事件 什么是事件 事件是可以被JavaScript侦测到的行为 | 事件 | 描述 | |------|-----| | onClick | 单击事件 | | onMouseOver | 鼠标经过事件 | | onMouseOut | 鼠标移出事件 | | onChange | 文本内容改变事件 | | onSelect | 文本框选中事件 | | onFocus | 光标聚集事件 | | onBlur | 移开光标事件 | | onLoad | 网页加载事件 | | onUnload | 关闭网页事件 | 事件处理 事件类型 UI事件：load / unload / error / resize / scroll 键盘事件：keydown / keyup / keypress 鼠标事件：click / dbclick / mousedown / mouseup / mousemove / mouseover / mouseout 焦点事件：focus / blur 表单事件：input / change / submit / reset / cut / copy / paste / select 事件绑定 HTML事件处理程序（不推荐使用，因为要做到标签与代码分离） 传统的DOM事件处理程序（只能附加一个回调函数） 事件监听器（旧的浏览器中不被支持） 事件流：事件捕获 / 事件冒泡 事件对象（低版本IE中的window.event） target（有些浏览器使用srcElement）获取事件目标 type：获取事件类型 cancelable： preventDefault()：阻止事件默认行为 stopPropagation()（低版本IE中的cancelBubble）：阻止时间冒泡 鼠标事件 - 事件发生的位置 屏幕位置：screenX和screenY 页面位置：pageX和pageY 客户端位置：clientX和clientY 键盘事件 - 哪个键被按下了 keyCode属性（有些浏览器使用which） String.fromCharCode(event.keyCode) HTML5事件 DOMContentLoaded hashchange beforeunload DOM HTML DOM 当网页被加载时，浏览器会创建页面的文档对象模型(Document Object Model) DOM操作HTML JavaScript能够改变页面中的所有HTML元素 JavaScript能够改变页面中的所有HTML属性 JavaScript能够改变页面中的所有CSS样式 JavaScript能够改变页面中的所有事件作出反应 DOM操作HTML 改变 HTML 输出流 注意：绝对不要在文档加载完成之后使用document.write()。这会覆盖该文档 寻找元素： 通过id找到HTML元素 通过标签名找到HTML元素 改变 HTML 内容 使用属性：innerHTML document.getElementById(id).innerHTML=新的 HTML 改变 HTML 属性 使用属性：attribute document.getElementById(id).attribute=新属性值 document.getElementById(id).href=\"https://www.baidu.com\" document.getElementById(id).src=\"https://www.baidu.com\" DOM操作CSS 改变 HTML 样式 如需改变 HTML 元素的样式，请使用这个语法： document.getElementById(id).style.property=新样式 菜鸟教程(runoob.com) Hello World! Hello World! document.getElementById(\"p2\").style.color=\"blue\"; document.getElementById(\"p2\").style.fontFamily=\"Arial\"; document.getElementById(\"p2\").style.fontSize=\"larger\"; 以上段落通过脚本修改。 DOM EventListener addEventListener() addEventListener() 方法用于向指定元素添加事件句柄。 addEventListener() 方法添加的事件句柄不会覆盖已存在的事件句柄。 你可以向一个元素添加多个事件句柄。 你可以向同个元素添加多个同类型的事件句柄，如：两个 \"click\" 事件。 你可以向任何 DOM 对象添加事件监听，不仅仅是 HTML 元素。如： window 对象。 addEventListener() 方法可以更简单的控制事件（冒泡与捕获）。 当你使用 addEventListener() 方法时, JavaScript 从 HTML 标记中分离开来，可读性更强， 在没有控制HTML标记时也可以添加事件监听。 你可以使用 removeEventListener() 方法来移除事件的监听。 语法：element.addEventListener(event, function, useCapture); 第一个参数是事件的类型 (如 \"click\" 或 \"mousedown\"). 第二个参数是事件触发后调用的函数。 第三个参数是个布尔值用于描述事件是冒泡还是捕获。该参数是可选的。 注意：不要使用 \"on\" 前缀。 例如，使用 \"click\" ,而不是使用 \"onclick\"。 例：在用户点击按钮时触发监听事件： document.getElementById(\"myBtn\").addEventListener(\"click\", displayDate); removeEventListener() removeEventListener() 方法移除由 addEventListener() 方法添加的事件句柄: element.removeEventListener(\"mousemove\", myFunction); 事件冒泡或事件捕获？ 事件传递有两种方式：冒泡与捕获。 事件传递定义了元素事件触发的顺序。 如果你将 元素插入到 元素中，用户点击 元素, 哪个元素的 \"click\" 事件先被触发呢？ 在 冒泡 中，内部元素的事件会先被触发，然后再触发外部元素，即： 元素的点击事件先触发，然后会触发 元素的点击事件。 在 捕获 中，外部元素的事件会先被触发，然后才会触发内部元素的事件，即： 元素的点击事件先触发 ，然后再触发 元素的点击事件。 addEventListener() 方法可以指定 \"useCapture\" 参数来设置传递类型： addEventListener(event, function, useCapture); 默认值为 false, 即冒泡传递，当值为 true 时, 事件使用捕获传递。 浏览器支持 IE 8 及更早 IE 版本，Opera 7.0及其更早版本不支持 addEventListener() 和 removeEventListener() 方法。但是，对于这类浏览器版本可以使用 detachEvent() 方法来移除事件句柄: element.attachEvent(event, function); element.detachEvent(event, function); 例： var x = document.getElementById(\"myBtn\"); if (x.addEventListener) { // 所有主流浏览器，除了 IE 8 及更早版本 x.addEventListener(\"click\", myFunction); } else if (x.attachEvent) { // IE 8 及更早版本 x.attachEvent(\"onclick\", myFunction); } "},"Web/JavaScript/JavaScript对象.html":{"url":"Web/JavaScript/JavaScript对象.html","title":"JavaScript对象","keywords":"","body":"datetime:2019/7/4 15:38 author:nzb 对象 JavaScript 中的所有事物都是对象：字符串、数值、数组、函数... 对象只是一种特殊的数据。对象拥有属性和方法。 此外，JavaScript 允许自定义对象。 访问对象的属性 属性是与对象相关的值。 访问对象属性的语法是： objectName.propertyName 下面这个例子使用了 String 对象的 length 属性来获得字符串的长度： var message=\"Hello World!\"; var x=message.length; 在以上代码执行后，x 的值将是：12 访问对象的方法 方法是能够在对象上执行的动作。 您可以通过以下语法来调用方法： objectName.methodName() 下面这个例子使用了 String 对象的 toUpperCase() 方法来将文本转换为大写： var message=\"Hello world!\"; var x=message.toUpperCase(); 在以上代码执行后，x 的值将是：HELLO WORLD! 创建 JavaScript 对象 通过 JavaScript，您能够定义并创建自己的对象。 创建新对象有两种不同的方法： 定义并创建对象的实例 person=new Object(); person.firstname=\"John\"; person.lastname=\"Doe\"; person.age=50; person.eyecolor=\"blue\"; // 或 person={firstname:\"John\",lastname:\"Doe\",age:50,eyecolor:\"blue\"}; 使用函数来定义对象，然后创建新的对象实例 function person(firstname,lastname,age,eyecolor) { this.firstname=firstname; this.lastname=lastname; this.age=age; this.eyecolor=eyecolor; } 在JavaScript中，this通常指向的是我们正在执行的函数本身，或者是指向该函数所属的对象（运行时） 创建 JavaScript 对象实例 一旦您有了对象构造器，就可以创建新的对象实例，就像这样： var myFather=new person(\"John\",\"Doe\",50,\"blue\"); var myMother=new person(\"Sally\",\"Rally\",48,\"green\"); 把属性添加到 JavaScript 对象 person.firstname=\"John\"; person.lastname=\"Doe\"; person.age=30; person.eyecolor=\"blue\"; x=person.firstname; 在以上代码执行后，x 的值将是：John 把方法添加到 JavaScript 对象 function person(firstname,lastname,age,eyecolor) { this.firstname=firstname; this.lastname=lastname; this.age=age; this.eyecolor=eyecolor; this.changeName=changeName; function changeName(name) { this.lastname=name; } } String对象 String 对象用于处理已有的字符块。 一个字符串可以使用单引号或双引号。 字符串（String）使用长度属性length来计算字符串的长度。 字符串使用 indexOf() 来定位字符串中某一个指定的字符首次出现的位置。 var str=\"Hello world, welcome to the universe.\"; var n=str.indexOf(\"welcome\"); 如果没找到对应的字符函数返回-1 lastIndexOf() 方法在字符串末尾开始查找字符串出现的位置。 内容匹配：match()函数用来查找字符串中特定的字符，并且如果找到的话，则返回这个字符。 替换内容：replace() 方法在字符串中用某些字符替换另一些字符。 字符串大小写转换：字符串大小写转换使用函数 toUpperCase() / toLowerCase() 字符串转为数组：字符串使用split()函数转为数组。 特殊字符：Javascript 中可以使用反斜线（\\）插入特殊符号，如：撇号,引号等其他特殊符号。 | 代码 | 输出 | |------|-----| | \\' | 单引号 | | \\\" | 双引号 | | \\ | 斜杆 | | \\n | 换行 | | \\r | 回车 | | \\t | tab | | \\b | 空格 | | \\f | 换页 | 字符串属性和方法 属性: | 属性 | 描述 | |------|-----| | constructor | 对创建该对象的函数的引用 | | length | 字符串的长度 | | prototype | 允许您向对象添加属性和方法 | 方法: | 方法 | 描述 | |-----|------| | charAt() | 返回在指定位置的字符 | | charCodeAt() | 返回在指定的位置的字符的 Unicode 编码 | | concat() | 连接两个或更多字符串，并返回新的字符串 | | fromCharCode() | 将 Unicode 编码转为字符 | | indexOf() | 返回某个指定的字符串值在字符串中首次出现的位置 | | includes() | 查找字符串中是否包含指定的子字符串 | | lastIndexOf() | 从后向前搜索字符串，并从起始位置（0）开始计算返回字符串最后出现的位置 | | match() | 查找找到一个或多个正则表达式的匹配 | | repeat() | 复制字符串指定次数，并将它们连接在一起返回 | | replace() | 在字符串中查找匹配的子串， 并替换与正则表达式匹配的子串 | | search() | 查找与正则表达式相匹配的值 | | slice() | 提取字符串的片断，并在新的字符串中返回被提取的部分 | | split() | 把字符串分割为字符串数组 | | startsWith() | 查看字符串是否以指定的子字符串开头 | | substr() | 从起始索引号提取字符串中指定数目的字符 | | substring() | 提取字符串中两个指定的索引号之间的字符 | | toLowerCase() | 把字符串转换为小写 | | toUpperCase() | 把字符串转换为大写 | | trim() | 去除字符串两边的空白 | | toLocaleLowerCase() | 根据本地主机的语言环境把字符串转换为小写 | | toLocaleUpperCase() | 根据本地主机的语言环境把字符串转换为大写 | | valueOf() | 返回某个字符串对象的原始值 | | toString() | 返回一个字符串 | Date日期对象 Date() 方法获得当日的日期。 getFullYear() 获取年份。 getTime() 返回从 1970 年 1 月 1 日至今的毫秒数。 setFullYear() 设置具体的日期。 toUTCString() 将当日的日期（根据 UTC）转换为字符串。 getDay() 和数组来显示星期，而不仅仅是数字。 创建日期 Date 对象用于处理日期和时间。 可以通过 new 关键词来定义 Date 对象。以下代码定义了名为 myDate 的 Date 对象： 有四种方式初始化日期: new Date() // 当前日期和时间 new Date(milliseconds) //返回从 1970 年 1 月 1 日至今的毫秒数 new Date(dateString) new Date(year, month, day, hours, minutes, seconds, milliseconds) 上面的参数大多数都是可选的，在不指定的情况下，默认参数是0。 实例化一个日期的一些例子： var today = new Date() var d1 = new Date(\"October 13, 1975 11:13:00\") var d2 = new Date(79,5,24) var d3 = new Date(79,5,24,11,33,0) 设置日期 通过使用针对日期对象的方法，我们可以很容易地对日期进行操作。 在下面的例子中，我们为日期对象设置了一个特定的日期 (2010 年 1 月 14 日)： var myDate=new Date(); myDate.setFullYear(2010,0,14); 在下面的例子中，我们将日期对象设置为 5 天后的日期： var myDate=new Date(); myDate.setDate(myDate.getDate()+5); 注意: 如果增加天数会改变月份或者年份，那么日期对象会自动完成这种转换。 两个日期比较 日期对象也可用于比较两个日期。 下面的代码将当前日期与 2100 年 1 月 14 日做了比较： var x=new Date(); x.setFullYear(2100,0,14); var today = new Date(); if (x>today) { alert(\"今天是2100年1月14日之前\"); } else { alert(\"今天是2100年1月14日之后\"); } 字符串属性和方法 属性: | 属性 | 描述 | |------|-----| | constructor | 返回对创建此对象的 Date 函数的引用 | | prototype | 使您有能力向对象添加属性和方法 | 方法: | 方法 | 描述 | |-----|------| | getDate() | 从 Date 对象返回一个月中的某一天 (1 ~ 31) | | getDay() | 从 Date 对象返回一周中的某一天 (0 ~ 6) | | getFullYear() | 从 Date 对象以四位数字返回年份 | | getHours() | 返回 Date 对象的小时 (0 ~ 23) | | getMilliseconds() | 返回 Date 对象的毫秒(0 ~ 999) | | getMinutes() | 返回 Date 对象的分钟 (0 ~ 59) | | getMonth() | 从 Date 对象返回月份 (0 ~ 11) | | getSeconds() | 返回 Date 对象的秒数 (0 ~ 59) | | getTime() | 返回 1970 年 1 月 1 日至今的毫秒数 | | getTimezoneOffset() | 返回本地时间与格林威治标准时间 (GMT) 的分钟差 | | getUTCDate() | 根据世界时从 Date 对象返回月中的一天 (1 ~ 31) | | getUTCDay() | 根据世界时从 Date 对象返回周中的一天 (0 ~ 6) | | getUTCFullYear() | 根据世界时从 Date 对象返回四位数的年份 | | getUTCHours() | 根据世界时返回 Date 对象的小时 (0 ~ 23) | | getUTCMilliseconds() | 根据世界时返回 Date 对象的毫秒(0 ~ 999) | | getUTCMinutes() | 根据世界时返回 Date 对象的分钟 (0 ~ 59) | | getUTCMonth() | 根据世界时从 Date 对象返回月份 (0 ~ 11) | | getUTCSeconds() | 根据世界时返回 Date 对象的秒钟 (0 ~ 59) | | getYear() | 已废弃。 请使用 getFullYear() 方法代替 | | parse() | 返回1970年1月1日午夜到指定日期（字符串）的毫秒数 | | setDate() | 设置 Date 对象中月的某一天 (1 ~ 31) | | setFullYear() | 设置 Date 对象中的年份（四位数字） | | setHours() | 设置 Date 对象中的小时 (0 ~ 23) | | setMilliseconds() | 设置 Date 对象中的毫秒 (0 ~ 999) | | setMinutes() | 设置 Date 对象中的分钟 (0 ~ 59) | | setMonth() | 设置 Date 对象中月份 (0 ~ 11) | | setSeconds() | 设置 Date 对象中的秒钟 (0 ~ 59) | | setTime() setTime() | 方法以毫秒设置 Date 对象 | | setUTCDate() | 根据世界时设置 Date 对象中月份的一天 (1 ~ 31) | | setUTCFullYear() | 根据世界时设置 Date 对象中的年份（四位数字） | | setUTCHours() | 根据世界时设置 Date 对象中的小时 (0 ~ 23) | | setUTCMilliseconds() | 根据世界时设置 Date 对象中的毫秒 (0 ~ 999) | | setUTCMinutes() | 根据世界时设置 Date 对象中的分钟 (0 ~ 59) | | setUTCMonth() | 根据世界时设置 Date 对象中的月份 (0 ~ 11) | | setUTCSeconds() | setUTCSeconds() 方法用于根据世界时 (UTC) 设置指定时间的秒字段 | | setYear() | 已废弃。请使用 setFullYear() 方法代替。 | toDateString() | 把 Date 对象的日期部分转换为字符串 | | toGMTString() | 已废弃。请使用 toUTCString() 方法代替 | | toISOString() | 使用 ISO 标准返回字符串的日期格式 | | toJSON() | 以 JSON 数据格式返回日期字符串 | | toLocaleDateString() | 根据本地时间格式，把 Date 对象的日期部分转换为字符串 | | toLocaleTimeString() | 根据本地时间格式，把 Date 对象的时间部分转换为字符串 | | toLocaleString() | 据本地时间格式，把 Date 对象转换为字符串 | | toString() | 把 Date 对象转换为字符串 | | toTimeString() | 把 Date 对象的时间部分转换为字符串 | | toUTCString() | 根据世界时，把 Date 对象转换为字符串 | | UTC() | 根据世界时返回 1970 年 1 月 1 日 到指定日期的毫秒数 | | valueOf() | 返回 Date 对象的原始值 | Array对象 数组对象是使用单独的变量名来存储一系列的值。 数组可以用一个变量名存储所有的值，并且可以用变量名访问任何一个值。 数组中的每个元素都有自己的的ID，以便它可以很容易地被访问到。 创建一个数组 常规方式: var myCars=new Array(); myCars[0]=\"Saab\"; myCars[1]=\"Volvo\"; myCars[2]=\"BMW\"; 简洁方式: var myCars=new Array(\"Saab\",\"Volvo\",\"BMW\"); 字面: var myCars=[\"Saab\",\"Volvo\",\"BMW\"]; 访问数组 通过指定数组名以及索引号码，你可以访问某个特定的元素。 在一个数组中你可以有不同的对象 所有的JavaScript变量都是对象。数组元素是对象。函数是对象。 因此，你可以在数组中有不同的变量类型。 你可以在一个数组中包含对象元素、函数、数组 数组方法和属性 属性: | 属性 | 描述 | |------|-----| | constructor | 返回创建数组对象的原型函数 | | length | 设置或返回数组元素的个数 | | prototype | 允许你向数组对象添加属性或方法 | 方法: | 方法 | 描述 | |-----|------| | concat() | 连接两个或更多的数组，并返回结果 | | copyWithin() | 从数组的指定位置拷贝元素到数组的另一个指定位置中 | | entries() | 返回数组的可迭代对象 | | every() | 检测数值元素的每个元素是否都符合条件 | | fill() | 使用一个固定值来填充数组 | | filter() | 检测数值元素，并返回符合条件所有元素的数组 | | find() | 返回符合传入测试（函数）条件的数组元素 | | findIndex() | 返回符合传入测试（函数）条件的数组元素索引 | | forEach() | 数组每个元素都执行一次回调函数 | | from() | 通过给定的对象中创建一个数组 | | includes() | 判断一个数组是否包含一个指定的值 | | indexOf() | 搜索数组中的元素，并返回它所在的位置 | | isArray() | 判断对象是否为数组 | | join() | 把数组的所有元素放入一个字符串 | | keys() | 返回数组的可迭代对象，包含原始数组的键(key) | | lastIndexOf() | 搜索数组中的元素，并返回它最后出现的位置 | | map() | 通过指定函数处理数组的每个元素，并返回处理后的数组 | | pop() | 删除数组的最后一个元素并返回删除的元素 | | push() | 向数组的末尾添加一个或更多元素，并返回新的长度 | | reduce() | 将数组元素计算为一个值（从左到右） | | reduceRight() | 将数组元素计算为一个值（从右到左） | | reverse() | 反转数组的元素顺序 | | shift() | 删除并返回数组的第一个元素 | | slice() | 选取数组的的一部分，并返回一个新数组 | | some() | 检测数组元素中是否有元素符合指定条件 | | sort() | 对数组的元素进行排序 | | splice() | 从数组中添加或删除元素 | | toString() | 把数组转换为字符串，并返回结果 | | unshift() | 向数组的开头添加一个或更多元素，并返回新的长度 | | valueOf() | 返回数组对象的原始值 | Math对象 Math方法和属性 属性: | 属性 | 描述 | |------|-----| | E | 返回算术常量 e，即自然对数的底数（约等于2.718） | | LN2 | 返回 2 的自然对数（约等于0.693） | | LN10 | 返回 10 的自然对数（约等于2.302） | | LOG2E | 返回以 2 为底的 e 的对数（约等于 1.4426950408889634） | | LOG10E | 返回以 10 为底的 e 的对数（约等于0.434） | | PI | 返回圆周率（约等于3.14159） | | SQRT1_2 | 返回 2 的平方根的倒数（约等于 0.707） | | SQRT2 | 返回 2 的平方根（约等于 1.414） | 方法: | 方法 | 描述 | |-----|------| | abs(x) | 返回 x 的绝对值 | | acos(x) | 返回 x 的反余弦值 | | asin(x) | 返回 x 的反正弦值 | | atan(x) | 以介于 -PI/2 与 PI/2 弧度之间的数值来返回 x 的反正切值 | | atan2(y,x) | 返回从 x 轴到点 (x,y) 的角度（介于 -PI/2 与 PI/2 弧度之间） | | ceil(x) | 对数进行上舍入 | | cos(x) | 返回数的余弦 | | exp(x) | 返回 Ex 的指数 | | floor(x) | 对 x 进行下舍入 | | log(x) | 返回数的自然对数（底为e） | | max(x,y,z,...,n) | 返回 x,y,z,...,n 中的最高值 | | min(x,y,z,...,n) | 返回 x,y,z,...,n中的最低值 | | pow(x,y) | 返回 x 的 y 次幂 | | random() | 返回 0 ~ 1 之间的随机数 | | round(x) | 四舍五入 | | sin(x) | 返回数的正弦 | | sqrt(x) | 返回数的平方根 | | tan(x) | 返回角的正切 | DOM对象 HTML DOM 节点 在 HTML DOM (Document Object Model) 中 , 每一个元素都是 节点: 文档是一个文档节点。 所有的HTML元素都是元素节点。 所有 HTML 属性都是属性节点。 文本插入到 HTML 元素是文本节点。are text nodes。 注释是注释节点。 Document 对象 当浏览器载入 HTML 文档, 它就会成为 Document 对象。 Document 对象是 HTML 文档的根节点。 Document 对象使我们可以从脚本中对 HTML 页面中的所有元素进行访问。 提示：Document 对象是 Window 对象的一部分，可通过 window.document 属性对其进行访问。 Document 对象属性和方法 属性和方法 | 属性 / 方法 | 描述 | |------|------------| | document.activeElement | 返回当前获取焦点元素 | | document.addEventListener() | 向文档添加句柄 | | document.adoptNode(node) | 从另外一个文档返回 adapded 节点到当前文档 | | document.anchors | 返回对文档中所有 Anchor 对象的引用 | | document.applets | 返回对文档中所有 Applet 对象的引用。注意: HTML5 已不支持 元素 | | document.baseURI | 返回文档的绝对基础 URI | | document.body | 返回文档的body元素 | | document.close() | 关闭用 document.open() 方法打开的输出流，并显示选定的数据 | | document.cookie | 设置或返回与当前文档有关的所有 cookie | | document.createAttribute() | 创建一个属性节点 | | document.createComment() | createComment() 方法可创建注释节点 | | document.createDocumentFragment() | 创建空的 DocumentFragment 对象，并返回此对象 | | document.createElement() | 创建元素节点 | | document.createTextNode() | 创建文本节点 | | document.doctype | 返回与文档相关的文档类型声明 (DTD) | | document.documentElement | 返回文档的根节点 | | document.documentMode | 返回用于通过浏览器渲染文档的模式 | | document.documentURI | 设置或返回文档的位置 | | document.domain | 返回当前文档的域名 | | document.domConfig | 已废弃。返回 normalizeDocument() 被调用时所使用的配置 | | document.embeds | 返回文档中所有嵌入的内容（embed）集合 | | document.forms | 返回对文档中所有 Form 对象引用 | | document.getElementsByClassName() | 返回文档中所有指定类名的元素集合，作为 NodeList 对象 | | document.getElementById() | 返回对拥有指定 id 的第一个对象的引用 | | document.getElementsByName() | 返回带有指定名称的对象集合 | | document.getElementsByTagName() | 返回带有指定标签名的对象集合 | | document.images | 返回对文档中所有 Image 对象引用 | | document.implementation | 返回处理该文档的 DOMImplementation 对象 | | document.importNode() | 把一个节点从另一个文档复制到该文档以便应用 | | document.inputEncoding | 返回用于文档的编码方式（在解析时） | | document.lastModified | 返回文档被最后修改的日期和时间 | | document.links | 返回对文档中所有 Area 和 Link 对象引用 | | document.normalize() | 删除空文本节点，并连接相邻节点 | | document.normalizeDocument() | 删除空文本节点，并连接相邻节点的 | | document.open() | 打开一个流，以收集来自任何 document.write() 或 document.writeln() 方法的输出 | | document.querySelector() | 返回文档中匹配指定的CSS选择器的第一元素 | | document.querySelectorAll() | document.querySelectorAll() 是 HTML5中引入的新方法，返回文档中匹配的CSS选择器的所有元素节点列表 | | document.readyState | 返回文档状态 (载入中……) | | document.referrer | 返回载入当前文档的文档的 URL | | document.removeEventListener() | 移除文档中的事件句柄(由 addEventListener() 方法添加) | | document.renameNode() | 重命名元素或者属性节点 | | document.scripts | 返回页面中所有脚本的集合 | | document.strictErrorChecking | 设置或返回是否强制进行错误检查 | | document.title | 返回当前文档的标题 | | document.URL | 返回文档完整的URL | | document.write() | 向文档写 HTML 表达式 或 JavaScript 代码 | | document.writeln() | 等同于 write() 方法，不同的是在每个表达式之后写一个换行符 | 警告 !!! 在 W3C DOM核心，文档对象 继承节点对象的所有属性和方法。 很多属性和方法在文档中是没有意义的。 HTML 文档对象可以避免使用这些节点对象和属性： | 属性 / 方法 | 避免的原因 | |-------|----------------| | document.attributes | 文档没有该属性 | | document.hasAttributes() | 文档没有该属性 | | document.nextSibling | 文档没有下一节点 | | document.nodeName | 这个通常是 #document | | document.nodeType | 这个通常是 9(DOCUMENT_NODE) | | document.nodeValue | 文档没有一个节点值 | | document.ownerDocument | 文档没有主文档 | | document.ownerElement | 文档没有自己的节点 | | document.parentNode | 文档没有父节点 | | document.previousSibling | 文档没有兄弟节点 | | document.textContent | 文档没有文本节点 | 元素对象 在 HTML DOM 中, 元素对象代表着一个 HTML 元素。 元素对象 的 子节点可以是, 可以是元素节点，文本节点，注释节点。 NodeList 对象 代表了节点列表，类似于 HTML元素的子节点集合。 属性和方法 | 属性 / 方法 | 描述 | |------|------------| | element.accessKey | 设置或返回accesskey一个元素 | | element.addEventListener() | 向指定元素添加事件句柄 | | element.appendChild() | 为元素添加一个新的子元素 | | element.attributes | 返回一个元素的属性数组 | | element.childNodes | 返回元素的一个子节点的数组 | | element.children | 返回元素的子元素的集合 | | element.classList | 返回元素的类名，作为 DOMTokenList 对象。 | | element.className | 设置或返回元素的class属性 | | element.clientHeight | 在页面上返回内容的可视高度（不包括边框，边距或滚动条） | | element.clientWidth | 在页面上返回内容的可视宽度（不包括边框，边距或滚动条） | | element.cloneNode() | 克隆某个元素 | | element.compareDocumentPosition() | 比较两个元素的文档位置。 | | element.contentEditable | 设置或返回元素的内容是否可编辑 | | element.dir | 设置或返回一个元素中的文本方向 | | element.firstChild | 返回元素的第一个子节点 | | element.focus() | 设置文档或元素获取焦点 | | element.getAttribute() | 返回指定元素的属性值 | | element.getAttributeNode() | 返回指定属性节点 | | element.getElementsByTagName() | 返回指定标签名的所有子元素集合。 | | element. getElementsByClassName() | 返回文档中所有指定类名的元素集合，作为 NodeList 对象。 | | element.getFeature() | 返回指定特征的执行APIs对象。 | | element.getUserData() | 返回一个元素中关联键值的对象。 | | element.hasAttribute() | 如果元素中存在指定的属性返回 true，否则返回false。 | | element.hasAttributes() | 如果元素有任何属性返回true，否则返回false。 | | element.hasChildNodes() | 返回一个元素是否具有任何子元素 | | element.hasFocus() | 返回布尔值，检测文档或元素是否获取焦点 | | element.id | 设置或者返回元素的 id。 | | element.innerHTML | 设置或者返回元素的内容。 | | element.insertBefore() | 现有的子元素之前插入一个新的子元素 | | element.isContentEditable | 如果元素内容可编辑返回 true，否则返回false | | element.isDefaultNamespace() | 如果指定了namespaceURI 返回 true，否则返回 false。 | | element.isEqualNode() | 检查两个元素是否相等 | | element.isSameNode() | 检查两个元素所有有相同节点。 | | element.isSupported() | 如果在元素中支持指定特征返回 true。 | | element.lang | 设置或者返回一个元素的语言。 | | element.lastChild | 返回的最后一个子元素 | | element.namespaceURI | 返回命名空间的 URI。 | | element.nextSibling | 返回该元素紧跟的一个节点 | | element.nextElementSibling | 返回指定元素之后的下一个兄弟元素（相同节点树层中的下一个元素节点）。 | | element.nodeName | 返回元素的标记名（大写） | | element.nodeType | 返回元素的节点类型 | | element.nodeValue | 返回元素的节点值 | | element.normalize() | 使得此成为一个\"normal\"的形式，其中只有结构（如元素，注释，处理指令，CDATA节和实体引用）隔开Text节点，即元素（包括属性）下面的所有文本节点，既没有相邻的文本节点也没有空的文本节点 | | element.offsetHeight | 返回任何一个元素的高度包括边框和填充，但不是边距 | | element.offsetWidth | 返回元素的宽度，包括边框和填充，但不是边距 | | element.offsetLeft | 返回当前元素的相对水平偏移位置的偏移容器 | | element.offsetParent | 返回元素的偏移容器 | | element.offsetTop | 返回当前元素的相对垂直偏移位置的偏移容器 | | element.ownerDocument | 返回元素的根元素（文档对象） | | element.parentNode | 返回元素的父节点 | | element.previousSibling | 返回某个元素紧接之前元素 | | element.previousElementSibling | 返回指定元素的前一个兄弟元素（相同节点树层中的前一个元素节点）。 | | element.querySelector() | 返回匹配指定 CSS 选择器元素的第一个子元素 | | document.querySelectorAll() | 返回匹配指定 CSS 选择器元素的所有子元素节点列表 | | element.removeAttribute() | 从元素中删除指定的属性 | | element.removeAttributeNode() | 删除指定属性节点并返回移除后的节点。 | | element.removeChild() | 删除一个子元素 | | element.removeEventListener() | 移除由 addEventListener() 方法添加的事件句柄 | | element.replaceChild() | 替换一个子元素 | | element.scrollHeight | 返回整个元素的高度（包括带滚动条的隐蔽的地方） | | element.scrollLeft | 返回当前视图中的实际元素的左边缘和左边缘之间的距离 | | element.scrollTop | 返回当前视图中的实际元素的顶部边缘和顶部边缘之间的距离 | | element.scrollWidth | 返回元素的整个宽度（包括带滚动条的隐蔽的地方） | | element.setAttribute() | 设置或者改变指定属性并指定值。 | | element.setAttributeNode() | 设置或者改变指定属性节点。 | | element.setIdAttribute() | | | element.setIdAttributeNode() | | | element.setUserData() | 在元素中为指定键值关联对象。 | | element.style | 设置或返回元素的样式属性 | | element.tabIndex | 设置或返回元素的标签顺序。 | | element.tagName | 作为一个字符串返回某个元素的标记名（大写） | | element.textContent | 设置或返回一个节点和它的文本内容 | | element.title | 设置或返回元素的title属性 | | element.toString() | 一个元素转换成字符串 | | nodelist.item() | 返回某个元素基于文档树的索引 | | nodelist.length | 返回节点列表的节点数目。 | Attr(属性) 对象 在 HTML DOM 中, Attr 对象 代表一个 HTML 属性。 HTML属性总是属于HTML元素。 NamedNodeMap 对象 在 HTML DOM 中, the NamedNodeMap 对象 表示一个无顺序的节点列表。 我们可通过节点名称来访问 NamedNodeMap 中的节点。 属性和方法 | 属性 / 方法 | 描述 | |------|------------| | attr.isId | 如果属性是 ID 类型，则 isId 属性返回 true，否则返回 false。 | | attr.name | 返回属性名称 | | attr.value | 设置或者返回属性值 | | attr.specified | 如果属性被指定返回 true ，否则返回 false | | nodemap.getNamedItem() | 从节点列表中返回的指定属性节点。 | | nodemap.item() | 返回节点列表中处于指定索引号的节点。 | | nodemap.length | 返回节点列表的节点数目。 | | nodemap.removeNamedItem() | 删除指定属性节点 | | nodemap.setNamedItem() | 设置指定属性节点(通过名称) | DOM 4 警告 !!! 在 W3C DOM 内核中, Attr (属性) 对象继承节点对象的所有属性和方法 。 在 DOM 4 中, Attr (属性) 对象不再从节点对象中继承。 从长远的代码质量来考虑，在属性对象中你需要避免使用节点对象属性和方法: | 属性 / 方法 | 避免原因 | |------|------------| | attr.appendChild() | 属性没有子节点 | | attr.attributes | 属性没有属性 | | attr.baseURI | 使用 document.baseURI 替代 | | attr.childNodes | 属性没有子节点 | | attr.cloneNode() | 使用 attr.value 替代 | | attr.firstChild | 属性没有子节点 | | attr.hasAttributes() | 属性没有属性 | | attr.hasChildNodes | 属性没有子节点 | | attr.insertBefore() | 属性没有子节点 | | attr.isEqualNode() | 没有意义 | | attr.isSameNode() | 没有意义 | | attr.isSupported() | 通常为 true | | attr.lastChild | 属性没有子节点 | | attr.nextSibling | 属性没有兄弟节点 | | attr.nodeName | 使用 attr.name 替代 | | attr.nodeType | 通常为 2 (ATTRIBUTE-NODE) | | attr.nodeValue | 使用 attr.value 替代 | | attr.normalize() | 属性没有规范 | | attr.ownerDocument | 通常为你的 HTML 文档 | | attr.ownerElement | 你用来访问属性的 HTML 元素 | | attr.parentNode | 你用来访问属性的 HTML 元素 | | attr.previousSibling | 属性没有兄弟节点 | | attr.removeChild | 属性没有子节点 | | attr.replaceChild | 属性没有子节点 | | attr.textContent | 使用 attr.value 替代 | Console 对象 Console 对象提供了访问浏览器调试模式的信息到控制台。 方法 描述 assert() 如果断言为 false，则在信息到控制台输出错误信息。 clear() 清除控制台上的信息。 count() 记录 count() 调用次数，一般用于计数。 error() 输出错误信息到控制台 group() 在控制台创建一个信息分组。 一个完整的信息分组以 console.group() 开始，console.groupEnd() 结束 groupCollapsed() 在控制台创建一个信息分组。 类似 console.group() ，但它默认是折叠的。 groupEnd() 设置当前信息分组结束 info() 控制台输出一条信息 log() 控制台输出一条信息 table() 以表格形式显示数据 time() 计时器，开始计时间，与 timeEnd() 联合使用，用于算出一个操作所花费的准确时间。 timeEnd() 计时结束 trace() 显示当前执行的代码在堆栈中的调用路径。 warn() 输出警告信息，信息最前面加一个黄色三角，表示警告 CSS 样式声明对象(CSSStyleDeclaration) CSSStyleDeclaration 对象 CSSStyleDeclaration 对象表示一个 CSS 属性-值（property-value）对的集合。 CSSStyleDeclaration 对象属性 | 属性 | 描述 | |------|------------| | cssText | 设置或返回样式声明文本，cssText 对应的是 HTML 元素的 style 属性。 | | length | 返回样式中包含多少条声明。 | | parentRule | 返回包含当前规则的规则。 | CSSStyleDeclaration 对象方法 | 属性 | 描述 | |------|------------| | getPropertyPriority() | 返回指定的 CSS 属性是否设置了 \"important!\" 属性。 | | getPropertyValue() | 返回指定的 CSS 属性值。 | | item() | 通过索引方式返回 CSS 声明中的 CSS 属性名。 | | removeProperty() | 移除 CSS 声明中的 CSS 属性。 | | setProperty() | 在 CSS 声明块中新建或者修改 CSS 属性。 | DOM 事件 DOM： 指明使用的 DOM 属性级别。 鼠标事件 属性 描述 DOM onclick 当用户点击某个对象时调用的事件句柄。 2 oncontextmenu 在用户点击鼠标右键打开上下文菜单时触发 ondblclick 当用户双击某个对象时调用的事件句柄。 2 onmousedown 鼠标按钮被按下。 2 onmouseenter 当鼠标指针移动到元素上时触发。 2 onmouseleave 当鼠标指针移出元素时触发 2 onmousemove 鼠标被移动。 2 onmouseover 鼠标移到某元素之上。 2 onmouseout 鼠标从某元素移开。 2 onmouseup 鼠标按键被松开。 2 键盘事件 属性 描述 DOM onkeydown 某个键盘按键被按下。 2 onkeypress 某个键盘按键被按下并松开。 2 onkeyup 某个键盘按键被松开。 2 框架/对象（Frame/Object）事件 属性 描述 DOM onabort 图像的加载被中断。 ( ) 2 onbeforeunload 该事件在即将离开页面（刷新或关闭）时触发 2 onerror 在加载文档或图像时发生错误。 ( , 和 ) onhashchange 该事件在当前 URL 的锚部分发生修改时触发。 onload 一张页面或一幅图像完成加载。 2 onpageshow 该事件在用户访问页面时触发 onpagehide 该事件在用户离开当前网页跳转到另外一个页面时触发 onresize 窗口或框架被重新调整大小。 2 onscroll 当文档被滚动时发生的事件。 2 onunload 用户退出页面。 ( 和 ) 2 表单事件 属性 描述 DOM onblur 元素失去焦点时触发 2 onchange 该事件在表单元素的内容改变时触发( , , , 和 ) 2 onfocus 元素获取焦点时触发 2 onfocusin 元素即将获取焦点时触发 2 onfocusout 元素即将失去焦点时触发 2 oninput 元素获取用户输入时触发 3 onreset 表单重置时触发 2 onsearch 用户向搜索域输入文本时触发 ( ) onselect 用户选取文本时触发 ( 和 ) 2 onsubmit 表单提交时触发 2 剪贴板事件 属性 描述 DOM oncopy 该事件在用户拷贝元素内容时触发 oncut 该事件在用户剪切元素内容时触发 onpaste 该事件在用户粘贴元素内容时触发 打印事件 属性 描述 DOM onafterprint 该事件在页面已经开始打印，或者打印窗口已经关闭时触发 onbeforeprint 该事件在页面即将开始打印时触发 拖动事件 事件 描述 DOM ondrag 该事件在元素正在拖动时触发 ondragend 该事件在用户完成元素的拖动时触发 ondragenter 该事件在拖动的元素进入放置目标时触发 ondragleave 该事件在拖动元素离开放置目标时触发 ondragover 该事件在拖动元素在放置目标上时触发 ondragstart 该事件在用户开始拖动元素时触发 ondrop 该事件在拖动元素放置在目标区域时触发 多媒体（Media）事件 事件 描述 DOM onabort 事件在视频/音频（audio/video）终止加载时触发。 oncanplay 事件在用户可以开始播放视频/音频（audio/video）时触发。 oncanplaythrough 事件在视频/音频（audio/video）可以正常播放且无需停顿和缓冲时触发。 ondurationchange 事件在视频/音频（audio/video）的时长发生变化时触发。 onemptied 当期播放列表为空时触发 onended 事件在视频/音频（audio/video）播放结束时触发。 onerror 事件在视频/音频（audio/video）数据加载期间发生错误时触发。 onloadeddata 事件在浏览器加载视频/音频（audio/video）当前帧时触发触发。 onloadedmetadata 事件在指定视频/音频（audio/video）的元数据加载后触发。 onloadstart 事件在浏览器开始寻找指定视频/音频（audio/video）触发。 onpause 事件在视频/音频（audio/video）暂停时触发。 onplay 事件在视频/音频（audio/video）开始播放时触发。 onplaying 事件在视频/音频（audio/video）暂停或者在缓冲后准备重新开始播放时触发。 onprogress 事件在浏览器下载指定的视频/音频（audio/video）时触发。 onratechange 事件在视频/音频（audio/video）的播放速度发送改变时触发。 onseeked 事件在用户重新定位视频/音频（audio/video）的播放位置后触发。 onseeking 事件在用户开始重新定位视频/音频（audio/video）时触发。 onstalled 事件在浏览器获取媒体数据，但媒体数据不可用时触发。 onsuspend 事件在浏览器读取媒体数据中止时触发。 ontimeupdate 事件在当前的播放位置发送改变时触发。 onvolumechange 事件在音量发生改变时触发。 onwaiting 事件在视频由于要播放下一帧而需要缓冲时触发。 动画事件 事件 描述 DOM animationend 该事件在 CSS 动画结束播放时触发 animationiteration 该事件在 CSS 动画重复播放时触发 animationstart 该事件在 CSS 动画开始播放时触发 过渡事件 事件 描述 DOM transitionend 该事件在 CSS 完成过渡后触发。 其他事件 事件 描述 DOM onmessage 该事件通过或者从对象(WebSocket, Web Worker, Event Source 或者子 frame 或父窗口)接收到消息时触发 onmousewheel 已废弃。 使用 onwheel 事件替代 ononline 该事件在浏览器开始在线工作时触发。 onoffline 该事件在浏览器开始离线工作时触发。 onpopstate 该事件在窗口的浏览历史（history 对象）发生改变时触发。 onshow 该事件当 元素在上下文菜单显示时触发 onstorage 该事件在 Web Storage(HTML 5 Web 存储)更新时触发 ontoggle 该事件在用户打开或关闭 元素时触发 onwheel 该事件在鼠标滚轮在元素上下滚动时触发 事件对象 常量 | 静态变量 | 描述 | DOM | |------|------|------| | CAPTURING-PHASE | 当前事件阶段为捕获阶段(1) | 1 | | AT-TARGET | 当前事件是目标阶段,在评估目标事件(1) | 2 | | BUBBLING-PHASE | 当前的事件为冒泡阶段 (3) | 3 | 属性 | 属性 | 描述 | DOM | |------|------|------| | bubbles | 返回布尔值，指示事件是否是起泡事件类型。 | 2 | | cancelable | 返回布尔值，指示事件是否可拥可取消的默认动作。 | 2 | | currentTarget | 返回其事件监听器触发该事件的元素。 | 2 | | eventPhase | 返回事件传播的当前阶段。 | 2 | | target | 返回触发此事件的元素（事件的目标节点）。 | 2 | | timeStamp | 返回事件生成的日期和时间。 | 2 | | type | 返回当前 Event 对象表示的事件的名称。 | 2 | 方法 | 方法 | 描述 | DOM | |------|------|------| | initEvent() | 初始化新创建的 Event 对象的属性。 | 2 | | preventDefault() | 通知浏览器不要执行与事件关联的默认动作。 | 2 | | stopPropagation() | 不再派发事件。 | 2 | 目标事件对象 方法 | 方法 | 描述 | DOM | |------|------|------| | addEventListener() | 允许在目标事件中注册监听事件(IE8 = attachEvent()) | 2 | | dispatchEvent() | 允许发送事件到监听器上 (IE8 = fireEvent()) | 2 | | removeEventListener() | 运行一次注册在事件目标上的监听事件(IE8 = detachEvent()) | 2 | 事件监听对象 方法 | 方法 | 描述 | DOM | |------|------|------| | handleEvent() | 把任意对象注册为事件处理程序 | 2 | 文档事件对象 方法 | 方法 | 描述 | DOM | |------|------|------| | createEvent() | | 2 | 鼠标/键盘事件对象 属性 | 属性 | 描述 | DOM | |------|------|------| | altKey | 返回当事件被触发时，\"ALT\" 是否被按下。 | 2 | | button | 返回当事件被触发时，哪个鼠标按钮被点击。 | 2 | | clientX | 返回当事件被触发时，鼠标指针的水平坐标。 | 2 | | clientY | 返回当事件被触发时，鼠标指针的垂直坐标。 | 2 | | ctrlKey | 返回当事件被触发时，\"CTRL\" 键是否被按下。 | 2 | | Location | 返回按键在设备上的位置 | 3 | | charCode | 返回onkeypress事件触发键值的字母代码。 | 2 | | key | 在按下按键时返回按键的标识符。 | 3 | | keyCode | 返回onkeypress事件触发的键的值的字符代码，或者 onkeydown 或 onkeyup 事件的键的代码。 | 2 | | which | 返回onkeypress事件触发的键的值的字符代码，或者 onkeydown 或 onkeyup 事件的键的代码。 | 2 | | metaKey | 返回当事件被触发时，\"meta\" 键是否被按下。 | 2 | | relatedTarget | 返回与事件的目标节点相关的节点。 | 2 | | screenX | 返回当某个事件被触发时，鼠标指针的水平坐标。 | 2 | | screenY | 返回当某个事件被触发时，鼠标指针的垂直坐标。 | 2 | | shiftKey | 返回当事件被触发时，\"SHIFT\" 键是否被按下。 | 2 | 方法 | 方法 | 描述 | DOM | |------|------|------| | initMouseEvent() | 初始化鼠标事件对象的值 | 2 | | initKeyboardEvent() | 初始化键盘事件对象的值 | 3 | 浏览器对象 Window对象 Window 对象表示浏览器中打开的窗口。 如果文档包含框架（ 或 标签），浏览器会为 HTML 文档创建一个 window 对象，并为每个框架创建一个额外的 window 对象。 注意： 没有应用于 window 对象的公开标准，不过所有浏览器都支持该对象。 Window 对象属性 | 属性 | 描述 | |------|------------| | closed | 返回窗口是否已被关闭。 | | defaultStatus | 设置或返回窗口状态栏中的默认文本。 | | document | 对 Document 对象的只读引用。(请参阅对象) | | frames | 返回窗口中所有命名的框架。该集合是 Window 对象的数组，每个 Window 对象在窗口中含有一个框架。 | | history | 对 History 对象的只读引用。请参数 History 对象。 | | innerHeight | 返回窗口的文档显示区的高度。 | | innerWidth | 返回窗口的文档显示区的宽度。 | | localStorage | 在浏览器中存储 key/value 对。没有过期时间。 | | length | 设置或返回窗口中的框架数量。 | | location | 用于窗口或框架的 Location 对象。请参阅 Location 对象。 | | name | 设置或返回窗口的名称。 | | navigator | 对 Navigator 对象的只读引用。请参数 Navigator 对象。 | | opener | 返回对创建此窗口的窗口的引用。 | | outerHeight | 返回窗口的外部高度，包含工具条与滚动条。 | | outerWidth | 返回窗口的外部宽度，包含工具条与滚动条。 | | pageXOffset | 设置或返回当前页面相对于窗口显示区左上角的 X 位置。 | | pageYOffset | 设置或返回当前页面相对于窗口显示区左上角的 Y 位置。 | | parent | 返回父窗口。 | | screen | 对 Screen 对象的只读引用。请参数 Screen 对象。 | | screenLeft | 返回相对于屏幕窗口的x坐标 | | screenTop | 返回相对于屏幕窗口的y坐标 | | screenX | 返回相对于屏幕窗口的x坐标 | | sessionStorage | 在浏览器中存储 key/value 对。 在关闭窗口或标签页之后将会删除这些数据。 | | screenY | 返回相对于屏幕窗口的y坐标 | | self | 返回对当前窗口的引用。等价于 Window 属性。 | | status | 设置窗口状态栏的文本。 | | top | 返回最顶层的父窗口。 | Window 对象方法 | 方法 | 描述 | |------|------------| | alert() | 显示带有一段消息和一个确认按钮的警告框。 | | atob() | 解码一个 base-64 编码的字符串。 | | btoa() | 创建一个 base-64 编码的字符串。 | | blur() | 把键盘焦点从顶层窗口移开。 | | clearInterval() | 取消由 setInterval() 设置的 timeout。 | | clearTimeout() | 取消由 setTimeout() 方法设置的 timeout。 | | close() | 关闭浏览器窗口。 | | confirm() | 显示带有一段消息以及确认按钮和取消按钮的对话框。 | | createPopup() | 创建一个 pop-up 窗口。 | | focus() | 把键盘焦点给予一个窗口。 | | getSelection() | 返回一个 Selection 对象，表示用户选择的文本范围或光标的当前位置。 | | getComputedStyle() | 获取指定元素的 CSS 样式。 | | matchMedia() | 该方法用来检查 media query 语句，它返回一个 MediaQueryList对象。 | | moveBy() | 可相对窗口的当前坐标把它移动指定的像素。 | | moveTo() | 把窗口的左上角移动到一个指定的坐标。 | | open() | 打开一个新的浏览器窗口或查找一个已命名的窗口。 | | print() | 打印当前窗口的内容。 | | prompt() | 显示可提示用户输入的对话框。 | | resizeBy() | 按照指定的像素调整窗口的大小。 | | resizeTo() | 把窗口的大小调整到指定的宽度和高度。 | | scroll() | 已废弃。 该方法已经使用了 scrollTo() 方法来替代。 | | scrollBy() | 按照指定的像素值来滚动内容。 | | scrollTo() | 把内容滚动到指定的坐标。 | | setInterval() | 按照指定的周期（以毫秒计）来调用函数或计算表达式。 | | setTimeout() | 在指定的毫秒数后调用函数或计算表达式。 | | stop() | 停止页面载入。 | 计时器 计时事件 通过使用JavaScript，我们有能力做到在一个设定的时间间隔之后来执行代码，而不是在函数被调用后立即执行，我们称之为计时事件 计时方法： setInterval()：间隔指定的毫秒数不停地执行指定的代码 clearInterval()：用于停止setInterval()方法执行的函数代码 setTimeout()：暂停指定的毫秒数后执行指定的代码 clearTimeout()：用于停止执行setTimeout()方法的函数代码 History 对象 Histor对象包含用户（在浏览器窗口中）访问过的 URL。 History 对象是 window 对象的一部分，可通过 window.history 属性对其进行访问。 注意： 没有应用于History对象的公开标准，不过所有浏览器都支持该对象。 History 对象属性 | 属性 | 描述 | |------|------------| | length | 返回历史列表中的网址数 | History 对象方法 | 方法 | 描述 | |------|------------| | back() | 加载 history 列表中的前一个 URL | | forward() | 加载 history 列表中的下一个 URL | | go() | 加载 history 列表中的某个具体页面 | Location 对象 Location 对象包含有关当前 URL 的信息。 Location 对象是 window 对象的一部分，可通过 window.Location 属性对其进行访问。 注意： 没有应用于Location对象的公开标准，不过所有浏览器都支持该对象。 Location 对象属性 | 属性 | 描述 | |------|------------| | hash | 返回一个URL的锚部分 | | host | 返回一个URL的主机名和端口 | | hostname | 返回URL的主机名 | | href | 返回完整的URL | | pathname | 返回的URL路径名。 | | port | 返回一个URL服务器使用的端口号 | | protocol | 返回一个URL协议 | | search | 返回一个URL的查询部分 | Location 对象方法 | 方法 | 描述 | |------|------------| | assign() | 载入一个新的文档 | | reload() | 重新载入当前文档 | | replace() | 用新的文档替换当前文档 | Screen 对象 Screen 对象包含有关客户端显示屏幕的信息。 注意： 没有应用于 screen 对象的公开标准，不过所有浏览器都支持该对象。 Screen 对象属性 | 属性 | 描述 | |------|------------| | availHeight | 返回屏幕的高度（不包括Windows任务栏） | | availWidth | 返回屏幕的宽度（不包括Windows任务栏） | | colorDepth | 返回目标设备或缓冲器上的调色板的比特深度 | | height | 返回屏幕的总高度 | | pixelDepth | 返回屏幕的颜色分辨率（每象素的位数） | | width | 返回屏幕的总宽度 | "},"Web/JavaScript/JavaScript瀑布流.html":{"url":"Web/JavaScript/JavaScript瀑布流.html","title":"JavaScript瀑布流","keywords":"","body":"datetime:2019/7/5 11:40 author:nzb JavaScript实现瀑布流效果 滚动条到底可以一直加载 warterfall.html js瀑布流效果 myjs.js window.onload = function () { // window.onload() 方法用于在网页加载完毕后立刻执行的操作 imgLocation(\"container\", 'box'); var imgData = {\"data\":[{\"src\":\"../../res/waterfall1.jpg\"},{\"src\":\"../../res/waterfall2.jpg\"},{\"src\":\"../../res/waterfall3.jpg\"}, {\"src\":\"../../res/waterfall4.jpg\"},{\"src\":\"../../res/waterfall5.jpg\"}]}; // 模拟数据 window.onscroll = function () { if(checkFlag()){ //是否到底部 var cparent = document.getElementById(\"container\"); // 获取父级 (优化：因为很多地方用到可以分装成一个函数) for(var i=0;i mystyle.css *{ margin: 0px; padding: 0px; } #container{ position: relative; } .box{ padding: 5px; float: left; } .box_img{ padding: 5px; border: 1px solid #cccccc; box-shadow: 0 0 5px #cccccc; } .box_img img{ width: 150px; height: auto; } "},"Web/JavaScript/JavaScript面向对象.html":{"url":"Web/JavaScript/JavaScript面向对象.html","title":"JavaScript面向对象","keywords":"","body":"datetime:2019/7/5 16:23 author:nzb 面向对象编程 面向对象编程是用抽象方式创建基于现实世界模型的一种编程模式。它使用先前建立的范例，包括模块化，多态和封装几种技术。今天，许多流行的编程语言（如Java，JavaScript，C＃，C+ +，Python，PHP，Ruby和Objective-C）都支持面向对象编程（OOP）。 相对于「一个程序只是一些函数的集合，或简单的计算机指令列表。」的传统软件设计观念而言，面向对象编程可以看作是使用一系列对象相互协作的软件设计。 在 OOP 中，每个对象能够接收消息，处理数据和发送消息给其他对象。每个对象都可以被看作是一个拥有清晰角色或责任的独立小机器。 面向对象程序设计的目的是在编程中促进更好的灵活性和可维护性，在大型软件工程中广为流行。凭借其对模块化的重视，面向对象的代码开发更简单，更容易理解，相比非模块化编程方法 1, 它能更直接地分析, 编码和理解复杂的情况和过程。 术语 Namespace 命名空间 允许开发人员在一个独特，应用相关的名字的名称下捆绑所有功能的容器。 Class 类 定义对象的特征。它是对象的属性和方法的模板定义。 Object 对象 类的一个实例。 Property 属性 对象的特征，比如颜色。 Method 方法 对象的能力，比如行走。 Constructor 构造函数 对象初始化的瞬间，被调用的方法。通常它的名字与包含它的类一致。 Inheritance 继承 一个类可以继承另一个类的特征。 Encapsulation 封装 一种把数据和相关的方法绑定在一起使用的方法。 Abstraction 抽象 结合复杂的继承，方法，属性的对象能够模拟现实的模型。 Polymorphism 多态 多意为「许多」，态意为「形态」。不同类可以定义相同的方法或属性。 更多关于面向对象编程的描述，请参照维基百科的 面向对象编程 。 JavaScript面向对象编程 命名空间 命名空间是一个容器，它允许开发人员在一个独特的，特定于应用程序的名称下捆绑所有的功能。 在JavaScript中，命名空间只是另一个包含方法，属性，对象的对象。 注意：需要认识到重要的一点是：与其他面向对象编程语言不同的是，Javascript中的普通对象和命名空间在语言层面上没有区别。这点可能会让JavaScript初学者感到迷惑。 创造的JavaScript命名空间背后的想法很简单：一个全局对象被创建，所有的变量，方法和功能成为该对象的属性。使用命名空间也最大程度地减少应用程序的名称冲突的可能性。 我们来创建一个全局变量叫做 MYAPP // 全局命名空间 var MYAPP = MYAPP || {}; 在上面的代码示例中，我们首先检查MYAPP是否已经被定义（是否在同一文件中或在另一文件）。如果是的话，那么使用现有的MYAPP全局对象，否则，创建一个名为MYAPP的空对象用来封装方法，函数，变量和对象。 我们也可以创建子命名空间： // 子命名空间 MYAPP.event = {}; 下面是用于创建命名空间和添加变量，函数和方法的代码写法： // 给普通方法和属性创建一个叫做MYAPP.commonMethod的容器 MYAPP.commonMethod = { regExForName: \"\", // 定义名字的正则验证 regExForPhone: \"\", // 定义电话的正则验证 validateName: function(name){ // 对名字name做些操作，你可以通过使用“this.regExForname” // 访问regExForName变量 }, validatePhoneNo: function(phoneNo){ // 对电话号码做操作 } } // 对象和方法一起申明 MYAPP.event = { addListener: function(el, type, fn) { // 代码 }, removeListener: function(el, type, fn) { // 代码 }, getEvent: function(e) { // 代码 } // 还可以添加其他的属性和方法 } //使用addListener方法的写法: MYAPP.event.addListener(\"yourel\", \"type\", callback); 标准内置对象 JavaScript有包括在其核心的几个对象，例如，Math，Object，Array和String对象。下面的例子演示了如何使用Math对象的random()方法来获得一个随机数。 console.log(Math.random()); 注意：这里和接下来的例子都假设名为 console.log 的方法全局有定义。console.log 实际上不是 JavaScript 自带的。 查看 JavaScript 参考：全局对象 了解 JavaScript 内置对象的列表。 JavaScript 中的每个对象都是 Object 对象的实例且继承它所有的属性和方法。 自定义对象 类 JavaScript是一种基于原型的语言，它没类的声明语句，比如C+ +或Java中用的。这有时会对习惯使用有类申明语句语言的程序员产生困扰。相反，JavaScript可用方法作类。定义一个类跟定义一个函数一样简单。在下面的例子中，我们定义了一个新类Person。 function Person() { } // 或 var Person = function(){ } 对象（类的实例） 我们使用 new obj 创建对象 obj 的新实例, 将结果（obj 类型）赋值给一个变量方便稍后调用。 在下面的示例中，我们定义了一个名为Person的类，然后我们创建了两个Person的实例(person1 and person2). function Person() { } var person1 = new Person(); var person2 = new Person(); 注意：有一种新增的创建未初始化实例的实例化方法，请参考 Object.create 。 构造器 在实例化时构造器被调用 (也就是对象实例被创建时)。构造器是对象中的一个方法。 在JavaScript中函数就可以作为构造器使用，因此不需要特别地定义一个构造器方法，每个声明的函数都可以在实例化后被调用执行。 构造器常用于给对象的属性赋值或者为调用函数做准备。 在本文的后面描述了类中方法既可以在定义时添加，也可以在使用前添加。 在下面的示例中, Person类实例化时构造器调用一个 alert函数。 function Person() { alert('Person instantiated'); } var person1 = new Person(); var person2 = new Person(); 属性 (对象属性) 属性就是 类中包含的变量;每一个对象实例有若干个属性. 为了正确的继承，属性应该被定义在类的原型属性 (函数)中。 可以使用 关键字 this调用类中的属性, this是对当前对象的引用。 从外部存取(读/写)其属性的语法是: InstanceName.Property; 这与C++，Java或者许多其他语言中的语法是一样的 (在类中语法 this.Property 常用于set和get属性值) 在下面的示例中，我们为定义Person类定义了一个属性 firstName 并在实例化时赋初值。 function Person(firstName) { this.firstName = firstName; alert('Person instantiated'); } var person1 = new Person('Alice'); var person2 = new Person('Bob'); // Show the firstName properties of the objects alert('person1 is ' + person1.firstName); // alerts \"person1 is Alice\" alert('person2 is ' + person2.firstName); // alerts \"person2 is Bob\" 方法（对象属性） 方法与属性很相似， 不同的是：一个是函数，另一个可以被定义为函数。 调用方法很像存取一个属性, 不同的是add () 在方法名后面很可能带着参数. 为定义一个方法, 需要将一个函数赋值给类的 prototype 属性; 这个赋值给函数的名称就是用来给对象在外部调用它使用的。 在下面的示例中，我们给Person类定义了方法 sayHello()，并调用了它. function Person(firstName) { this.firstName = firstName; } Person.prototype.sayHello = function() { alert(\"Hello, I'm \" + this.firstName); }; var person1 = new Person(\"Alice\"); var person2 = new Person(\"Bob\"); // call the Person sayHello method. person1.sayHello(); // alerts \"Hello, I'm Alice\" person2.sayHello(); // alerts \"Hello, I'm Bob\" 在JavaScript中方法通常是一个绑定到对象中的普通函数, 这意味着方法可以在其所在context之外被调用。 思考下面示例中的代码: function Person(firstName) { this.firstName = firstName; } Person.prototype.sayHello = function() { alert(\"Hello, I'm \" + this.firstName); }; var person1 = new Person(\"Alice\"); var person2 = new Person(\"Bob\"); var helloFunction = person1.sayHello; person1.sayHello(); // alerts \"Hello, I'm Alice\" person2.sayHello(); // alerts \"Hello, I'm Bob\" helloFunction(); // alerts \"Hello, I'm undefined\" (or fails // with a TypeError in strict mode) console.log(helloFunction === person1.sayHello); // logs true console.log(helloFunction === Person.prototype.sayHello); // logs true helloFunction.call(person1); // logs \"Hello, I'm Alice\" 如上例所示, 所有指向sayHello函数的引用 ，包括 person1, Person.prototype, 和 helloFunction 等， 均引用了相同的函数. 在调用函数的过程中，this的值取决于我们怎么样调用函数. 在通常情况下，我们通过一个表达式person1.sayHello()来调用函数：即从一个对象的属性中得到所调用的函数。此时this被设置为我们取得函数的对象（即person1）。这就是为什么person1.sayHello() 使用了姓名“Alice”而person2.sayHello()使用了姓名“bob”的原因。 然而我们使用不同的调用方法时, this的值也就不同了。当从变量 helloFunction()中调用的时候， this就被设置成了全局对象 (在浏览器中即window)。由于该对象 (非常可能地) 没有firstName 属性, 我们得到的结果便是\"Hello, I'm undefined\". (这是松散模式下的结果， 在 严格模式中，结果将不同（此时会产生一个error）。 但是为了避免混淆，我们在这里不涉及细节) 。另外，我们可以像上例末尾那样，使用Function#call (或者Function#apply)显式的设置this的值。 更多有关信息请参考 Function#call and Function#apply 继承 创建一个或多个类的专门版本类方式称为继承（Javascript只支持单继承）。 创建的专门版本的类通常叫做子类，另外的类通常叫做父类。 在Javascript中，继承通过赋予子类一个父类的实例并专门化子类来实现。在现代浏览器中你可以使用 Object.create 实现继承. JavaScript 并不检测子类的 prototype.constructor (见 Object.prototype), 所以我们必须手动申明它. 在下面的例子中, 我们定义了 Student类作为 Person类的子类. 之后我们重定义了sayHello() 方法并添加了 sayGoodBye() 方法. // 定义Person构造器 function Person(firstName) { this.firstName = firstName; } // 在Person.prototype中加入方法 Person.prototype.walk = function(){ alert(\"I am walking!\"); }; Person.prototype.sayHello = function(){ alert(\"Hello, I'm \" + this.firstName); }; // 定义Student构造器 function Student(firstName, subject) { // 调用父类构造器, 确保(使用Function#call)\"this\" 在调用过程中设置正确 Person.call(this, firstName); // 初始化Student类特有属性 this.subject = subject; }; // 建立一个由Person.prototype继承而来的Student.prototype对象. // 注意: 常见的错误是使用 \"new Person()\"来建立Student.prototype. // 这样做的错误之处有很多, 最重要的一点是我们在实例化时 // 不能赋予Person类任何的FirstName参数 // 调用Person的正确位置如下，我们从Student中来调用它 Student.prototype = Object.create(Person.prototype); // See note below // 设置\"constructor\" 属性指向Student Student.prototype.constructor = Student; // 更换\"sayHello\" 方法 Student.prototype.sayHello = function(){ console.log(\"Hello, I'm \" + this.firstName + \". I'm studying \" + this.subject + \".\"); }; // 加入\"sayGoodBye\" 方法 Student.prototype.sayGoodBye = function(){ console.log(\"Goodbye!\"); }; // 测试实例: var student1 = new Student(\"Janet\", \"Applied Physics\"); student1.sayHello(); // \"Hello, I'm Janet. I'm studying Applied Physics.\" student1.walk(); // \"I am walking!\" student1.sayGoodBye(); // \"Goodbye!\" // Check that instanceof works correctly console.log(student1 instanceof Person); // true console.log(student1 instanceof Student); // true 对于“Student.prototype = Object.create(Person.prototype);”这一行，在不支持 Object.create方法的老JavaScript引擎中，可以使用一个\"polyfill\"（又名\"shim\"，查看文章链接），或者使用一个function来获得相同的返回值，就像下面： function createObject(proto) { function ctor() { } ctor.prototype = proto; return new ctor(); } // Usage: Student.prototype = createObject(Person.prototype); 封装 在上一个例子中，Student类虽然不需要知道Person类的walk()方法是如何实现的，但是仍然可以使用这个方法；Student类不需要明确地定义这个方法，除非我们想改变它。 这就叫做封装，对于所有继承自父类的方法，只需要在子类中定义那些你想改变的即可。 抽象 抽象是允许模拟工作问题中通用部分的一种机制。这可以通过继承（具体化）或组合来实现。 JavaScript通过继承实现具体化，通过让类的实例是其他对象的属性值来实现组合。 JavaScript Function 类继承自Object类（这是典型的具体化） 。Function.prototype的属性是一个Object实例（这是典型的组合）。 var foo = function(){}; console.log( 'foo is a Function: ' + (foo instanceof Function) ); // logs \"foo is a Function: true\" console.log( 'foo.prototype is an Object: ' + (foo.prototype instanceof Object) ); // logs \"foo.prototype is an Object: true\" 多态 就像所有定义在原型属性内部的方法和属性一样，不同的类可以定义具有相同名称的方法;方法是作用于所在的类中。并且这仅在两个类不是父子关系时成立（继承链中，一个类不是继承自其他类）。 注意 本文中所展示的面向对象编程技术不是唯一的实现方式，在JavaScript中面向对象的实现是非常灵活的。 同样的，文中展示的技术没有使用任何语言hacks，它们也没有模仿其他语言的对象理论实现。 JavaScript中还有其他一些更加先进的面向对象技术，但这些都超出了本文的介绍范围。 "},"Web/JavaScript/框架/Promise.html":{"url":"Web/JavaScript/框架/Promise.html","title":"Promise","keywords":"","body":"datetime:2019/12/5 15:03 author:nzb 接口调用方式 原生ajax 基于jQuery的ajax fetch axios 异步 JavaScript的执行环境是「单线程」 所谓单线程，是指JS引擎中负责解释和执行JavaScript代码的线程只有一个，也就是一次只能完成一项任务，这个任务执行完后才能执行下一个，它会「阻塞」其他任务。这个任务可称为主线程 异步模式可以一起执行多个任务 JS中常见的异步调用 定时任何 ajax 事件函数 promise 主要解决异步深层嵌套的问题 promise 提供了简洁的API 使得异步操作更加容易 /* 1. Promise基本使用 我们使用new来构建一个Promise Promise的构造函数接收一个参数，是函数，并且传入两个参数： resolve，reject， 分别表示异步操作执行成功后的回调函数和异步操作执行失败后的回调函数 */ var p = new Promise(function(resolve, reject){ //2. 这里用于实现异步任务 setTimeout setTimeout(function(){ var flag = false; if(flag) { //3. 正常情况 resolve('hello'); }else{ //4. 异常情况 reject('出错了'); } }, 100); }); // 5 Promise实例生成以后，可以用then方法指定resolved状态和reject状态的回调函数 // 在then方法中，你也可以直接return数据而不是Promise对象，在后面的then中就可以接收到数据了 p.then(function(data){ console.log(data) },function(info){ console.log(info) }); 基于Promise发送Ajax请求 JavaScript /* 基于Promise发送Ajax请求 */ function queryData(url) { # 1.1 创建一个Promise实例 var p = new Promise(function(resolve, reject){ var xhr = new XMLHttpRequest(); xhr.onreadystatechange = function(){ if(xhr.readyState != 4) return; if(xhr.readyState == 4 && xhr.status == 200) { # 1.2 处理正常的情况 resolve(xhr.responseText); }else{ # 1.3 处理异常情况 reject('服务器错误'); } }; xhr.open('get', url); xhr.send(null); }); return p; } # 注意： 这里需要开启一个服务 # 在then方法中，你也可以直接return数据而不是Promise对象，在后面的then中就可以接收到数据了 queryData('http://localhost:3000/data') .then(function(data){ console.log(data) # 1.4 想要继续链式编程下去 需要 return return queryData('http://localhost:3000/data1'); }) .then(function(data){ console.log(data); return queryData('http://localhost:3000/data2'); }) .then(function(data){ console.log(data) }); Jquery jquery中的promise $(function () { $(\"#btn\").on(\"click\", function () { $.ajax({ url: './data.json', type: 'get', dataType: 'json', //常见用法 // success: function (data) { // console.log(data) // } }) //promise用法 .then(function (data) { console.log(\"promise后数据\", data) }) }) }) Promise 基本API 实例方法 .then() 得到异步任务正确的结果 .catch() 获取异常信息 .finally() 成功与否都会执行（不是正式标准） /* Promise常用API-实例方法 */ // console.dir(Promise); function foo() { return new Promise(function(resolve, reject){ setTimeout(function(){ // resolve(123); reject('error'); }, 100); }) } // foo() // .then(function(data){ // console.log(data) // }) // .catch(function(data){ // console.log(data) // }) // .finally(function(){ // console.log('finished') // }); // -------------------------- // 两种写法是等效的 foo() .then(function(data){ # 得到异步任务正确的结果 console.log(data) },function(data){ # 获取异常信息 console.log(data) }) # 成功与否都会执行（不是正式标准） .finally(function(){ console.log('finished') }); 静态方法 .all() Promise.all方法接受一个数组作参数，数组中的对象（p1、p2、p3）均为promise实例（如果不是一个promise，该项会被用Promise.resolve转换为一个promise)。它的状态由这三个promise实例决定 .race() Promise.race方法同样接受一个数组作参数。当p1, p2, p3中有一个实例的状态发生改变（变为fulfilled或rejected），p的状态就跟着改变。并把第一个改变状态的promise的返回值，传给p的回调函数 ​ /* Promise常用API-对象方法 */ // console.dir(Promise) function queryData(url) { return new Promise(function(resolve, reject){ var xhr = new XMLHttpRequest(); xhr.onreadystatechange = function(){ if(xhr.readyState != 4) return; if(xhr.readyState == 4 && xhr.status == 200) { // 处理正常的情况 resolve(xhr.responseText); }else{ // 处理异常情况 reject('服务器错误'); } }; xhr.open('get', url); xhr.send(null); }); } var p1 = queryData('http://localhost:3000/a1'); var p2 = queryData('http://localhost:3000/a2'); var p3 = queryData('http://localhost:3000/a3'); Promise.all([p1,p2,p3]).then(function(result){ // all 中的参数 [p1,p2,p3] 和 返回的结果一 一对应[\"HELLO TOM\", \"HELLO JERRY\", \"HELLO SPIKE\"] console.log(result) //[\"HELLO TOM\", \"HELLO JERRY\", \"HELLO SPIKE\"] }) Promise.race([p1,p2,p3]).then(function(result){ // 由于p1执行较快，Promise的then()将获得结果'P1'。p2,p3仍在继续执行，但执行结果将被丢弃。 console.log(result) // \"HELLO TOM\" }) fetch Fetch API是新的ajax解决方案 Fetch会返回Promise fetch不是ajax的进一步封装，而是原生js，没有使用XMLHttpRequest对象。 fetch(url, options).then(） /* Fetch API 基本用法 fetch(url).then() 第一个参数请求的路径 Fetch会返回Promise 所以我们可以使用then 拿到请求成功的结果 */ fetch('http://localhost:3000/fdata').then(function(data){ // text()方法属于fetchAPI的一部分，它返回一个Promise实例对象，用于获取后台返回的数据 return data.text(); }).then(function(data){ // 在这个then里面我们能拿到最终的数据 console.log(data); }) fetch API 中的 HTTP 请求 fetch(url, options).then(） HTTP协议，它给我们提供了很多的方法，如POST，GET，DELETE，UPDATE，PATCH和PUT 默认的是 GET 请求 需要在 options 对象中 指定对应的 method method:请求使用的方法 post 和 普通 请求的时候 需要在options 中 设置 请求头 headers 和 body /* Fetch API 调用接口传递参数 */ #1.1 GET参数传递 - 传统URL 通过url ？ 的形式传参 fetch('http://localhost:3000/books?id=123', { # get 请求可以省略不写 默认的是GET method: 'get' }) .then(function(data) { # 它返回一个Promise实例对象，用于获取后台返回的数据 return data.text(); }).then(function(data) { # 在这个then里面我们能拿到最终的数据 console.log(data) }); #1.2 GET参数传递 restful形式的URL 通过/ 的形式传递参数 即 id = 456 和id后台的配置有关 fetch('http://localhost:3000/books/456', { # get 请求可以省略不写 默认的是GET method: 'get' }) .then(function(data) { return data.text(); }).then(function(data) { console.log(data) }); #2.1 DELETE请求方式参数传递 删除id 是 id=789 fetch('http://localhost:3000/books/789', { method: 'delete' }) .then(function(data) { return data.text(); }).then(function(data) { console.log(data) }); #3 POST请求传参 fetch('http://localhost:3000/books', { method: 'post', # 3.1 传递数据 body: 'uname=lisi&pwd=123', # 3.2 设置请求头 headers: { 'Content-Type': 'application/x-www-form-urlencoded' } }) .then(function(data) { return data.text(); }).then(function(data) { console.log(data) }); # POST请求传参 fetch('http://localhost:3000/books', { method: 'post', body: JSON.stringify({ uname: '张三', pwd: '456' }), headers: { 'Content-Type': 'application/json' } }) .then(function(data) { return data.text(); }).then(function(data) { console.log(data) }); # PUT请求传参 修改id 是 123 的 fetch('http://localhost:3000/books/123', { method: 'put', body: JSON.stringify({ uname: '张三', pwd: '789' }), headers: { 'Content-Type': 'application/json' } }) .then(function(data) { return data.text(); }).then(function(data) { console.log(data) }); fetchAPI 中 响应格式 用fetch来获取数据，如果响应正常返回，我们首先看到的是一个response对象，其中包括返回的一堆原始字节，这些字节需要在收到后，需要我们通过调用方法将其转换为相应格式的数据，比如JSON，BLOB或者TEXT等等 /* Fetch响应结果的数据格式 */ fetch('http://localhost:3000/json').then(function(data){ // return data.json(); // 将获取到的数据使用 json 转换对象 return data.text(); // // 将获取到的数据 转换成字符串 }).then(function(data){ // console.log(data.uname) // console.log(typeof data) var obj = JSON.parse(data); console.log(obj.uname,obj.age,obj.gender) }) axios 基于promise用于浏览器和node.js的http客户端 支持浏览器和node.js 支持promise 能拦截请求和响应 自动转换JSON数据 能转换请求和响应数据 axios基础用法 get和 delete请求传递参数 通过传统的url 以 ? 的形式传递参数 restful 形式传递参数 通过params 形式传递参数 post 和 put 请求传递参数 通过选项传递参数 通过 URLSearchParams 传递参数 # 1. 发送get 请求 axios.get('http://localhost:3000/adata').then(function(ret){ # 拿到 ret 是一个对象 所有的对象都存在 ret 的data 属性里面 // 注意data属性是固定的用法，用于获取后台的实际数据 // console.log(ret.data) console.log(ret) }) # 2. get 请求传递参数 # 2.1 通过传统的url 以 ? 的形式传递参数 axios.get('http://localhost:3000/axios?id=123').then(function(ret){ console.log(ret.data) }) # 2.2 restful 形式传递参数 axios.get('http://localhost:3000/axios/123').then(function(ret){ console.log(ret.data) }) # 2.3 通过params 形式传递参数 axios.get('http://localhost:3000/axios', { params: { id: 789 } }).then(function(ret){ console.log(ret.data) }) #3 axios delete 请求传参 传参的形式和 get 请求一样 axios.delete('http://localhost:3000/axios', { params: { id: 111 } }).then(function(ret){ console.log(ret.data) }) # 4 axios 的 post 请求 # 4.1 通过选项传递参数 axios.post('http://localhost:3000/axios', { uname: 'lisi', pwd: 123 }).then(function(ret){ console.log(ret.data) }) # 4.2 通过 URLSearchParams 传递参数 var params = new URLSearchParams(); params.append('uname', 'zhangsan'); params.append('pwd', '111'); axios.post('http://localhost:3000/axios', params).then(function(ret){ console.log(ret.data) }) #5 axios put 请求传参 和 post 请求一样 axios.put('http://localhost:3000/axios/123', { uname: 'lisi', pwd: 123 }).then(function(ret){ console.log(ret.data) }) axios 全局配置 # 配置公共的请求头 axios.defaults.baseURL = 'https://api.example.com'; # 配置 超时时间 axios.defaults.timeout = 2500; # 配置公共的请求头 axios.defaults.headers.common['Authorization'] = AUTH_TOKEN; # 配置公共的 post 的 Content-Type axios.defaults.headers.post['Content-Type'] = 'application/x-www-form-urlencoded'; axios 拦截器 请求拦截器 请求拦截器的作用是在请求发送前进行一些操作 例如在每个请求体里加上token，统一做了处理如果以后要改也非常容易 响应拦截器 响应拦截器的作用是在接收到响应后进行一些操作 例如在服务器返回登录状态失效，需要重新登录的时候，跳转到登录页 # 1. 请求拦截器 axios.interceptors.request.use(function(config) { console.log(config.url) # 1.1 任何请求都会经过这一步 在发送请求之前做些什么 config.headers.mytoken = 'nihao'; # 1.2 这里一定要return 否则配置不成功 return config; }, function(err){ #1.3 对请求错误做点什么 console.log(err) }) #2. 响应拦截器 axios.interceptors.response.use(function(res) { #2.1 在接收响应做些什么 var data = res.data; return data; }, function(err){ #2.2 对响应错误做点什么 console.log(err) }) async 和 await async作为一个关键字放到函数前面 任何一个async函数都会隐式返回一个promise await关键字只能在使用async定义的函数中使用 ​ await后面可以直接跟一个 Promise实例对象 ​ await函数不能单独使用 async/await 让异步代码看起来、表现起来更像同步代码 # 1. async 基础用法 # 1.1 async作为一个关键字放到函数前面 async function queryData() { # 1.2 await关键字只能在使用async定义的函数中使用 await后面可以直接跟一个 Promise实例对象 var ret = await new Promise(function(resolve, reject){ setTimeout(function(){ resolve('nihao') },1000); }) // console.log(ret.data) return ret; } # 1.3 任何一个async函数都会隐式返回一个promise 我们可以使用then 进行链式编程 queryData().then(function(data){ console.log(data) }) #2. async 函数处理多个异步函数 axios.defaults.baseURL = 'http://localhost:3000'; async function queryData() { # 2.1 添加await之后 当前的await 返回结果之后才会执行后面的代码 var info = await axios.get('async1'); #2.2 让异步代码看起来、表现起来更像同步代码 var ret = await axios.get('async2?info=' + info.data); return ret.data; } queryData().then(function(data){ console.log(data) }) 图书列表案例 1. 基于接口案例-获取图书列表 导入axios 用来发送ajax 把获取到的数据渲染到页面上 编号 名称 时间 操作 { {item.id} } { {item.name} } { {item.date } } 修改 | 删除 1. 导入axios /* 图书管理-添加图书 */ # 2 配置公共的url地址 简化后面的调用方式 axios.defaults.baseURL = 'http://localhost:3000/'; axios.interceptors.response.use(function(res) { return res.data; }, function(error) { console.log(error) }); var vm = new Vue({ el: '#app', data: { flag: false, submitFlag: false, id: '', name: '', books: [] }, methods: { # 3 定义一个方法 用来发送 ajax # 3.1 使用 async 来 让异步的代码 以同步的形式书写 queryData: async function() { // 调用后台接口获取图书列表数据 // var ret = await axios.get('books'); // this.books = ret.data; # 3.2 发送ajax请求 把拿到的数据放在books 里面 this.books = await axios.get('books'); } }, mounted: function() { # 4 mounted 里面 DOM已经加载完毕 在这里调用函数 this.queryData(); } }); 2 添加图书 获取用户输入的数据 发送到后台 渲染最新的数据到页面上 methods: { handle: async function(){ if(this.flag) { // 编辑图书 // 就是根据当前的ID去更新数组中对应的数据 this.books.some((item) => { if(item.id == this.id) { item.name = this.name; // 完成更新操作之后，需要终止循环 return true; } }); this.flag = false; }else{ # 1.1 在前面封装好的 handle 方法中 发送ajax请求 # 1.2 使用async 和 await 简化操作 需要在 function 前面添加 async var ret = await axios.post('books', { name: this.name }) # 1.3 根据后台返回的状态码判断是否加载数据 if(ret.status == 200) { # 1.4 调用 queryData 这个方法 渲染最新的数据 this.queryData(); } } // 清空表单 this.id = ''; this.name = ''; }, } 3 验证图书名称是否存在 添加图书之前发送请求验证图示是否已经存在 如果不存在 往后台里面添加图书名称 图书存在与否只需要修改submitFlag的值即可 watch: { name: async function(val) { // 验证图书名称是否已经存在 // var flag = this.books.some(function(item){ // return item.name == val; // }); var ret = await axios.get('/books/book/' + this.name); if(ret.status == 1) { // 图书名称存在 this.submitFlag = true; }else{ // 图书名称不存在 this.submitFlag = false; } } }, 4. 编辑图书 根据当前书的id 查询需要编辑的书籍 需要根据状态位判断是添加还是编辑 methods: { handle: async function(){ if(this.flag) { #4.3 编辑图书 把用户输入的信息提交到后台 var ret = await axios.put('books/' + this.id, { name: this.name }); if(ret.status == 200){ #4.4 完成添加后 重新加载列表数据 this.queryData(); } this.flag = false; }else{ // 添加图书 var ret = await axios.post('books', { name: this.name }) if(ret.status == 200) { // 重新加载列表数据 this.queryData(); } } // 清空表单 this.id = ''; this.name = ''; }, toEdit: async function(id){ #4.1 flag状态位用于区分编辑和添加操作 this.flag = true; #4.2 根据id查询出对应的图书信息 页面中可以加载出来最新的信息 # 调用接口发送ajax 请求 var ret = await axios.get('books/' + id); this.id = ret.id; this.name = ret.name; }, 5 删除图书 把需要删除的id书籍 通过参数的形式传递到后台 deleteBook: async function(id){ // 删除图书 var ret = await axios.delete('books/' + id); if(ret.status == 200) { // 重新加载列表数据 this.queryData(); } } "},"Web/JavaScript/框架/Vue.js基础.html":{"url":"Web/JavaScript/框架/Vue.js基础.html","title":"Vue.Js基础","keywords":"","body":"datetime:2019/7/15 10:09 author:nzb Vue.js Vue.js 是什么 Vue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。 Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与现代化的工具链以及各种支持类库结合使用时， Vue 也完全能够为复杂的单页应用提供驱动。 简单示例 Vue基础 { { msg } } // 2.创建一个Vue示例 // 当我们导入包后，浏览器的内存中就多了一个Vue的构造函数 // 这个new出来的vm对象就是MVVM中的VM调度者 var vm = new Vue({ el: '#app', // 表示element, 网页上需要控制的区域 // 这里的data就是MVVM中的M，用于保存页面的数据 data: { // 存储需要的数据。 msg: \"Hello world, I'm Vue.js!!!\" // 通过Vue指令，把数据渲染到页面，不需要再操作DOM元素。 // (前端Vue之类的框架，不提倡我们去手动操作DOM元素了) } }) 模板语法 Vue.js 使用了基于 HTML 的模板语法，允许开发者声明式地将 DOM 绑定至底层 Vue 实例的数据。所有 Vue.js 的模板都是合法的 HTML ，所以能被遵循规范的浏览器和 HTML 解析器解析。 在底层的实现上，Vue 将模板编译成虚拟 DOM 渲染函数。结合响应系统，Vue 能够智能地计算出最少需要重新渲染多少组件，并把 DOM 操作次数减到最少。 如果你熟悉虚拟 DOM 并且偏爱 JavaScript 的原始力量，你也可以不用模板，直接写渲染 (render) 函数，使用可选的 JSX 语法。 插值 文本 数据绑定最常见的形式就是使用“Mustache”语法 (双大括号) 的文本插值： Message: { { msg } } Mustache 标签将会被替代为对应数据对象上 msg 属性的值。无论何时，绑定的数据对象上 msg 属性发生了改变，插值处的内容都会更新。 通过使用 v-once 指令，你也能执行一次性地插值，当数据改变时，插值处的内容不会更新。但请留心这会影响到该节点上的其它数据绑定： 这个将不会改变: { { msg } } 原始HTML 双大括号会将数据解释为普通文本，而非 HTML 代码。为了输出真正的 HTML，你需要使用 v-html 指令： Using mustaches: { { rawHtml } } Using v-html directive: 这个 span 的内容将会被替换成为属性值 rawHtml，直接作为 HTML——会忽略解析属性值中的数据绑定。注意，你不能使用 v-html 来复合局部模板， 因为 Vue 不是基于字符串的模板引擎。反之，对于用户界面 (UI)，组件更适合作为可重用和可组合的基本单位。 注意：你的站点上动态渲染的任意 HTML 可能会非常危险，因为它很容易导致 XSS 攻击。请只对可信内容使用 HTML 插值，绝不要对用户提供的内容使用插值。 特性 Mustache 语法不能作用在 HTML 特性上，遇到这种情况应该使用 v-bind 指令： 对于布尔特性 (它们只要存在就意味着值为 true)，v-bind 工作起来略有不同，在这个例子中： Button 如果 isButtonDisabled 的值是 null、undefined 或 false，则 disabled 特性甚至不会被包含在渲染出来的 元素中。 使用 JavaScript 表达式 迄今为止，在我们的模板中，我们一直都只绑定简单的属性键值。但实际上，对于所有的数据绑定，Vue.js 都提供了完全的 JavaScript 表达式支持。 { { number + 1 } } { { ok ? 'YES' : 'NO' } } { { message.split('').reverse().join('') } } 这些表达式会在所属 Vue 实例的数据作用域下作为 JavaScript 被解析。有个限制就是，每个绑定都只能包含单个表达式，所以下面的例子都不会生效。 { { var a = 1 } } { { if (ok) { return message } } } 注意：模板表达式都被放在沙盒中，只能访问全局变量的一个白名单，如 Math 和 Date 。你不应该在模板表达式中试图访问用户定义的全局变量。 指令 指令 (Directives) 是带有 v- 前缀的特殊特性。指令特性的值预期是单个 JavaScript 表达式 (v-for 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM。回顾我们在介绍中看到的例子： 现在你看到我了 这里，v-if 指令将根据表达式 seen 的值的真假来插入/移除 元素。 参数 一些指令能够接收一个“参数”，在指令名称之后以冒号表示。例如，v-bind 指令可以用于响应式地更新 HTML 特性： ... 在这里 href 是参数，告知 v-bind 指令将该元素的 href 特性与表达式 url 的值绑定。 另一个例子是 v-on 指令，它用于监听 DOM 事件： ... 在这里参数是监听的事件名。我们也会更详细地讨论事件处理。 动态参数 从 2.6.0 开始，可以用方括号括起来的 JavaScript 表达式作为一个指令的参数： ... 这里的 attributeName 会被作为一个 JavaScript 表达式进行动态求值，求得的值将会作为最终的参数来使用。例如，如果你的 Vue 实例有一个 data 属性 attributeName，其值为 \"href\"，那么这个绑定将等价于 v-bind:href。 同样地，你可以使用动态参数为一个动态的事件名绑定处理函数： ... 同样地，当 eventName 的值为 \"focus\" 时，v-on:[eventName] 将等价于 v-on:focus。 对动态参数的值的约束 注意：动态参数表达式有一些语法约束，因为某些字符，例如空格和引号，放在 HTML 特性名里是无效的。同样，在 DOM 中使用模板时你需要回避大写键名。 例如，下面的代码是无效的： ... 变通的办法是使用没有空格或引号的表达式，或用计算属性替代这种复杂表达式。 另外，如果你在 DOM 中使用模板 (直接在一个 HTML 文件里撰写模板)，需要留意浏览器会把特性名全部强制转为小写： ... 修饰符 修饰符 (modifier) 是以半角句号 . 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定。例如，.prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault()： ... 事件修饰符： .stop 阻止冒泡 .prevent 阻止默认事件 .capture 添加事件侦听器时使用事件捕获模式 .self 只当事件在该元素本身（比如不是子元素）触发时触发回调 .once 事件只触发一次 例子 百度一下 var vm = new Vue({ el: '#app', data: {}, methods: { divclick(){ console.log('div'); }, btnclick(){ console.log('btn') }, noredirect(){ console.log('a') } }, }); 归纳常见指令 v-cloak：解决闪烁问题 当网速较慢时，vue加载较慢，插值表达式渲染的数据就会产生闪烁，使用v-cloak指令加上如上样式可以解决该问题 v-text：插入文本字符串 v-text默认就没有闪烁，但是会以文本字符串的方式覆盖所在元素的文本 v-html：插入html v-html与v-text的不同在于插入的是html。 v-bind：绑定属性 在vue中想要让属性如title等于data对象中的一个变量（键），会被直接当作字符串显示出来，这时就要用到v-bind，v-bind可以将绑定的属性值当作变量对待，在data对象中去找。 v-bind的三种用法： 直接使用指令v-bind 使用简化指令\":\" 在绑定的时候，拼接绑定内容：:title=\"btnTitle + ', 这是追加的内容'\" v-on：绑定方法,缩写：\"@\" 示例 +++++{ { msg } }----- ====== 123123 var vm = new Vue({ el: '#app', data: { msg: 'hello', msg2: '我是h1', mytitle: '这是一个自定义title', }, methods: { // 这个methods属性中定义了当前vue实例所有可用的方法 show: function () { alert(\"Hello!!!\") } } }) v-model：、实现双向数据绑定： { { message } } new Vue({ el: '#app', data: { message: 'Runoob!' } }) 注意：v-model 指令用来在 input、select、textarea、checkbox、radio 等表单控件元素上创建双向数据绑定，根据表单上的值，自动更新绑定的元素的值。 缩写 v- 前缀作为一种视觉提示，用来识别模板中 Vue 特定的特性。当你在使用 Vue.js 为现有标签添加动态行为 (dynamic behavior) 时， v- 前缀很有帮助，然而，对于一些频繁用到的指令来说，就会感到使用繁琐。 同时，在构建由 Vue 管理所有模板的单页面应用程序 (SPA - single page application) 时，v- 前缀也变得没那么重要了。 因此，Vue 为 v-bind 和 v-on 这两个最常用的指令，提供了特定简写： v-bind 缩写 ... ... v-on 缩写 ... ... 它们看起来可能与普通的 HTML 略有不同，但 : 与 @ 对于特性名来说都是合法字符，在所有支持 Vue 的浏览器都能被正确地解析。而且，它们不会出现在最终渲染的标记中。缩写语法是完全可选的，但随着你更深入地了解它们的作用，你会庆幸拥有它们。 在Vue中使用样式 使用class样式 数组 这是一个邪恶的H1 数组中使用三元表达式 这是一个邪恶的H1 数组中嵌套对象(对象就是键值对) 这是一个邪恶的H1 直接使用对象 这是一个邪恶的H1 var vm = new Vue({ el: '#app', data: { flag: true, classObj: {red:true, thin:true, italic:true, active:false}, }, methods: {}, }); 使用内联样式 直接在元素上通过 :style 的形式，书写样式对象 这是一个善良的H1 将样式对象，定义到 data 中，并直接引用到 :style 中 在data上定义样式： data: { h1StyleObj: { color: 'red', 'font-size': '40px', 'font-weight': '200' } } 在元素中，通过属性绑定的形式，将样式对象应用到元素中： 这是一个善良的H1 在 :style 中通过数组，引用多个 data 上的样式对象 在data上定义样式： data: { h1StyleObj: { color: 'red', 'font-size': '40px', 'font-weight': '200' }, h1StyleObj2: { fontStyle: 'italic' } } 在元素中，通过属性绑定的形式，将样式对象应用到元素中： 这是一个善良的H1 条件渲染 v-if 条件判断使用 v-if 指令： 现在你看到我了 菜鸟教程 学的不仅是技术，更是梦想！ 哈哈哈，打字辛苦啊！！！ new Vue({ el: '#app', data: { seen: true, ok: true } }) 你可以使用 v-else 指令来表示 v-if 的“else 块”： 0.5\"> Now you see me Now you don't v-else-if，顾名思义，充当 v-if 的“else-if 块”，可以连续使用： A B C Not A/B/C 注意：v-else，v-else-if 也必须紧跟在带 v-if 或者 v-else-if 的元素之后。 v-show Hello! 注意，v-show 不支持 元素，也不支持 v-else。 v-if vs v-show v-if 是“真正”的条件渲染，因为它会确保在切换过程中条件块内的事件监听器和子组件适当地被销毁和重建。 v-if 也是惰性的：如果在初始渲染时条件为假，则什么也不做——直到条件第一次变为真时，才会开始渲染条件块。 相比之下，v-show 就简单得多——不管初始条件是什么，元素总是会被渲染，并且只是简单地基于 CSS 进行切换。 一般来说，v-if 有更高的切换开销，而 v-show 有更高的初始渲染开销。因此，如果需要非常频繁地切换， 则使用 v-show 较好；如果在运行时条件很少改变，则使用 v-if 较好。 v-if 与 v-for 一起使用 不推荐同时使用 v-if 和 v-for。请查阅风格指南以获取更多信息。 当 v-if 与 v-for 一起使用时，v-for 具有比 v-if 更高的优先级。请查阅列表渲染指南 以获取详细信息。 列表渲染-循环 v-for迭代数组 { { parentMessage } } - { { index } } - { { item.message } } var example2 = new Vue({ el: '#example-2', data: { parentMessage: 'Parent', items: [ { message: 'Foo' }, { message: 'Bar' } ] } }) 第二个参数为当前项的索引。 v-for迭代对象中的属性 { { value } } new Vue({ el: '#v-for-object', data: { object: { title: 'How to do lists in Vue', author: 'Jane Doe', publishedAt: '2016-04-10' } } }) 你也可以提供第二个的参数为 property 名称 (也就是键名)： { { name } }: { { value } } 还可以用第三个参数作为索引： { { index } }. { { name } }: { { value } } v-for迭代数字 { { n } } 注意事项 2.2.0+ 的版本里，当在组件中使用 v-for 时，key 现在是必须的。 当 Vue 正在更新使用 v-for 渲染的元素列表时，它默认使用“就地更新”的策略。如果数据项的顺序被改变，Vue 将不会移动 DOM 元素来匹配数据项的顺序， 而是就地更新每个元素，并且确保它们在每个索引位置正确渲染。这个类似 Vue 1.x 的 track-by=\"$index\"。 这个默认的模式是高效的，但是只适用于不依赖子组件状态或临时 DOM 状态 (例如：表单输入值) 的列表渲染输出。 为了给 Vue 一个提示，以便它能跟踪每个节点的身份，从而重用和重新排序现有元素，你需要为每项提供一个唯一 key 属性： 建议尽可能在使用 v-for 时提供 key attribute，除非遍历输出的 DOM 内容非常简单，或者是刻意依赖默认行为以获取性能上的提升。 因为它是 Vue 识别节点的一个通用机制，key 并不仅与 v-for 特别关联。后面我们将在指南中看到，它还具有其它用途。 注意：不要使用对象或数组之类的非基本类型值作为 v-for 的 key。请用字符串或数值类型的值。 过滤器 Vue.js 允许你自定义过滤器，可被用于一些常见的文本格式化。过滤器可以用在两个地方：双花括号插值和 v-bind 表达式 (后者从 2.1.0+ 开始支持)。 过滤器应该被添加在 JavaScript 表达式的尾部，由“管道”符号指示： { { message | capitalize } } 你可以在一个组件的选项中定义本地的过滤器： filters: { capitalize: function (value) { if (!value) return '' value = value.toString() return value.charAt(0).toUpperCase() + value.slice(1) } } 或者在创建 Vue 实例之前全局定义过滤器： Vue.filter('capitalize', function (value) { if (!value) return '' value = value.toString() return value.charAt(0).toUpperCase() + value.slice(1) }) new Vue({ // ... }) 当全局过滤器和局部过滤器重名时，会采用局部过滤器。 过滤器可以串联： { { message | filterA | filterB } } 在这个例子中，filterA 被定义为接收单个参数的过滤器函数，表达式 message 的值将作为参数传入到函数中。然后继续调用同样被定义为接收单个参数的过滤器函数 filterB，将 filterA 的结果传递到 filterB 中。 过滤器是 JavaScript 函数，因此可以接收参数： { { message | filterA('arg1', arg2) } } 这里，filterA 被定义为接收三个参数的过滤器函数。其中 message 的值作为第一个参数，普通字符串 'arg1' 作为第二个参数，表达式 arg2 的值作为第三个参数。 事件处理 监听事件 可以用 v-on 指令监听 DOM 事件，并在触发时运行一些 JavaScript 代码。 示例： Add 1 The button above has been clicked { { counter } } times. var example1 = new Vue({ el: '#example-1', data: { counter: 0 } }) 事件处理方法 然而许多事件处理逻辑会更为复杂，所以直接把 JavaScript 代码写在 v-on 指令中是不可行的。因此 v-on 还可以接收一个需要调用的方法名称。 示例： Greet var example2 = new Vue({ el: '#example-2', data: { name: 'Vue.js' }, // 在 `methods` 对象中定义方法 methods: { greet: function (event) { // `this` 在方法里指向当前 Vue 实例 alert('Hello ' + this.name + '!') // `event` 是原生 DOM 事件 if (event) { alert(event.target.tagName) } } } }) // 也可以用 JavaScript 直接调用方法 example2.greet() // => 'Hello Vue.js!' 内联处理器中的方法 除了直接绑定到一个方法，也可以在内联 JavaScript 语句中调用方法： Say hi Say what new Vue({ el: '#example-3', methods: { say: function (message) { alert(message) } } }) 有时也需要在内联语句处理器中访问原始的 DOM 事件。可以用特殊变量 $event 把它传入方法： Submit // ... methods: { warn: function (message, event) { // 现在我们可以访问原生事件对象 if (event) event.preventDefault() alert(message) } } 事件修饰符 在事件处理程序中调用 event.preventDefault() 或 event.stopPropagation() 是非常常见的需求。尽管我们可以在方法中轻松实现这点，但更好的方式是：方法只有纯粹的数据逻辑，而不是去处理 DOM 事件细节。 为了解决这个问题，Vue.js 为 v-on 提供了事件修饰符。之前提过，修饰符是由点开头的指令后缀来表示的。 .stop .prevent .capture .self .once .passive ... ... 注意：使用修饰符时，顺序很重要；相应的代码会以同样的顺序产生。因此，用 v-on:click.prevent.self 会阻止所有的点击，而 v-on:click.self.prevent 只会阻止对元素自身的点击。 2.3.0 新增 Vue 还对应 addEventListener 中的 passive 选项提供了 .passive 修饰符。 ... 这个 .passive 修饰符尤其能够提升移动端的性能。 注意：不要把 .passive 和 .prevent 一起使用，因为 .prevent 将会被忽略，同时浏览器可能会向你展示一个警告。请记住，.passive 会告诉浏览器你不想阻止事件的默认行为。 按键修饰符 在监听键盘事件时，我们经常需要检查详细的按键。Vue 允许为 v-on 在监听键盘事件时添加按键修饰符： 你可以直接将 KeyboardEvent.key 暴露的任意有效按键名转换为 kebab-case 来作为修饰符。 在上述示例中，处理函数只会在 $event.key 等于 PageDown 时被调用。 按键码 keyCode 的事件用法已经被废弃了并可能不会被最新的浏览器支持。 使用 keyCode 特性也是允许的： 为了在必要的情况下支持旧浏览器，Vue 提供了绝大多数常用的按键码的别名： .enter .tab .delete (捕获“删除”和“退格”键) .esc .space .up .down .left .right 有一些按键 (.esc 以及所有的方向键) 在 IE9 中有不同的 key 值, 如果你想支持 IE9，这些内置的别名应该是首选。 你还可以通过全局 config.keyCodes 对象自定义按键修饰符别名： // 可以使用 v-on:keyup.f1 Vue.config.keyCodes.f1 = 112 系统修饰键 可以用如下修饰符来实现仅在按下相应按键时才触发鼠标或键盘事件的监听器。 .ctrl .alt .shift .meta 注意：在 Mac 系统键盘上，meta 对应 command 键 (⌘)。在 Windows 系统键盘 meta 对应 Windows 徽标键 (⊞)。在 Sun 操作系统键盘上，meta 对应实心宝石键 (◆)。在其他特定键盘上，尤其在 MIT 和 Lisp 机器的键盘、以及其后继产品，比如 Knight 键盘、space-cadet 键盘，meta 被标记为“META”。在 Symbolics 键盘上，meta 被标记为“META”或者“Meta”。 例如： Do something 请注意修饰键与常规按键不同，在和 keyup 事件一起用时，事件触发时修饰键必须处于按下状态。换句话说，只有在按住 ctrl 的情况下释放其它按键，才能触发 keyup.ctrl。而单单释放 ctrl 也不会触发事件。如果你想要这样的行为，请为 ctrl 换用 keyCode：keyup.17。 .exact 修饰符 .exact 修饰符允许你控制由精确的系统修饰符组合触发的事件。 A A A 鼠标按钮修饰符 .left .right .middle 这些修饰符会限制处理函数仅响应特定的鼠标按钮。 为什么在 HTML 中监听事件? 你可能注意到这种事件监听的方式违背了关注点分离 (separation of concern) 这个长期以来的优良传统。但不必担心，因为所有的 Vue.js 事件处理方法和表达式都严格绑定在当前视图的 ViewModel 上，它不会导致任何维护上的困难。实际上，使用 v-on 有几个好处： 扫一眼 HTML 模板便能轻松定位在 JavaScript 代码里对应的方法。 因为你无须在 JavaScript 里手动绑定事件，你的 ViewModel 代码可以是非常纯粹的逻辑，和 DOM 完全解耦，更易于测试。 当一个 ViewModel 被销毁时，所有的事件处理器都会自动被删除。你无须担心如何清理它们。 自定义指令 简介 除了核心功能默认内置的指令 (v-model 和 v-show)，Vue 也允许注册自定义指令。注意，在 Vue2.0 中，代码复用和抽象的主要形式是组件。 然而，有的情况下，你仍然需要对普通 DOM 元素进行底层操作，这时候就会用到自定义指令。举个聚焦输入框的例子。 当页面加载时，该元素将获得焦点 (注意：autofocus 在移动版 Safari 上不工作)。事实上，只要你在打开这个页面后还没点击过任何内容， 这个输入框就应当还是处于聚焦状态。现在让我们用指令来实现这个功能： // 注册一个全局自定义指令 `v-focus` Vue.directive('focus', { // 当被绑定的元素插入到 DOM 中时…… inserted: function (el) { // 聚焦元素 el.focus() } }) 如果想注册局部指令，组件中也接受一个 directives 的选项： directives: { focus: { // 指令的定义 inserted: function (el) { el.focus() } } } 然后你可以在模板中任何元素上使用新的 v-focus 属性，如下： 钩子函数 一个指令定义对象可以提供如下几个钩子函数 (均为可选)： bind：只调用一次，指令第一次绑定到元素时调用。在这里可以进行一次性的初始化设置。 inserted：被绑定元素插入父节点时调用 (仅保证父节点存在，但不一定已被插入文档中)。 update：所在组件的 VNode 更新时调用，但是可能发生在其子 VNode 更新之前。指令的值可能发生了改变，也可能没有。 但是你可以通过比较更新前后的值来忽略不必要的模板更新 (详细的钩子函数参数见下)。 componentUpdated：指令所在组件的 VNode 及其子 VNode 全部更新后调用。 unbind：只调用一次，指令与元素解绑时调用。 接下来我们来看一下钩子函数的参数 (即 el、binding、vnode 和 oldVnode)。 钩子函数参数 指令钩子函数会被传入以下参数： el：指令所绑定的元素，可以用来直接操作 DOM 。 binding：一个对象，包含以下属性： name：指令名，不包括 v- 前缀。 value：指令的绑定值，例如：v-my-directive=\"1 + 1\" 中，绑定值为 2。 oldValue：指令绑定的前一个值，仅在 update 和 componentUpdated 钩子中可用。无论值是否改变都可用。 expression：字符串形式的指令表达式。例如 v-my-directive=\"1 + 1\" 中，表达式为 \"1 + 1\"。 arg：传给指令的参数，可选。例如 v-my-directive:foo 中，参数为 \"foo\"。 modifiers：一个包含修饰符的对象。例如：v-my-directive.foo.bar 中，修饰符对象为 { foo: true, bar: true }。 vnode：Vue 编译生成的虚拟节点。移步 VNode API 来了解更多详情。 oldVnode：上一个虚拟节点，仅在 update 和 componentUpdated 钩子中可用。 注意：除了 el 之外，其它参数都应该是只读的，切勿进行修改。如果需要在钩子之间共享数据，建议通过元素的 dataset 来进行。 这是一个使用了这些属性的自定义钩子样例： Vue.directive('demo', { bind: function (el, binding, vnode) { var s = JSON.stringify el.innerHTML = 'name: ' + s(binding.name) + '' + 'value: ' + s(binding.value) + '' + 'expression: ' + s(binding.expression) + '' + 'argument: ' + s(binding.arg) + '' + 'modifiers: ' + s(binding.modifiers) + '' + 'vnode keys: ' + Object.keys(vnode).join(', ') } }) new Vue({ el: '#hook-arguments-example', data: { message: 'hello!' } }) 结果： name: \"demo\" value: \"hello!\" expression: \"message\" argument: \"foo\" modifiers: {\"a\":true,\"b\":true} vnode keys: tag, data, children, text, elm, ns, context, fnContext, fnOptions, fnScopeId, key, componentOptions, componentInstance, parent, raw, isStatic, isRootInsert, isComment, isCloned, isOnce, asyncFactory, asyncMeta, isAsyncPlaceholder 动态指令参数 指令的参数可以是动态的。例如，在 v-mydirective:[argument]=\"value\"中，argument 参数可以根据组件实例数据进行更新！这使得自定义指令可以在应用中被灵活使用。 例如你想要创建一个自定义指令，用来通过固定布局将元素固定在页面上。我们可以像这样创建一个通过指令值来更新竖直位置像素值的自定义指令： Scroll down the page Stick me 200px from the top of the page Vue.directive('pin', { bind: function (el, binding, vnode) { el.style.position = 'fixed' el.style.top = binding.value + 'px' } }) new Vue({ el: '#baseexample' }) 这会把该元素固定在距离页面顶部 200 像素的位置。但如果场景是我们需要把元素固定在左侧而不是顶部又该怎么办呢？这时使用动态参数就可以非常方便地根据每个组件实例来进行更新。 Scroll down inside this section ↓ I am pinned onto the page at 200px to the left. Vue.directive('pin', { bind: function (el, binding, vnode) { el.style.position = 'fixed' var s = (binding.arg == 'left' ? 'left' : 'top') el.style[s] = binding.value + 'px' } }) new Vue({ el: '#dynamicexample', data: function () { return { direction: 'left' } } }) 这样这个自定义指令现在的灵活性就足以支持一些不同的用例了。 函数简写 在很多时候，你可能想在 bind 和 update 时触发相同行为，而不关心其它的钩子。比如这样写: Vue.directive('color-swatch', function (el, binding) { el.style.backgroundColor = binding.value }) 对象字面量 如果指令需要多个值，可以传入一个 JavaScript 对象字面量。记住，指令函数能够接受所有合法的 JavaScript 表达式。 Vue.directive('demo', function (el, binding) { console.log(binding.value.color) // => \"white\" console.log(binding.value.text) // => \"hello!\" }) vue实例的生命周期 什么是生命周期：从Vue实例创建、运行、到销毁期间，总是伴随着各种各样的事件，这些事件，统称为生命周期！ 生命周期钩子：就是生命周期事件的别名而已； 生命周期钩子 = 生命周期函数 = 生命周期事件 主要的生命周期函数分类： 创建期间的生命周期函数： beforeCreate：实例刚在内存中被创建出来，此时，还没有初始化好 data 和 methods 属性 created：实例已经在内存中创建OK，此时 data 和 methods 已经创建OK，此时还没有开始 编译模板 beforeMount：此时已经完成了模板的编译，但是还没有挂载到页面中 mounted：此时，已经将编译好的模板，挂载到了页面指定的容器中显示 运行期间的生命周期函数： beforeUpdate：状态更新之前执行此函数， 此时 data 中的状态值是最新的，但是界面上显示的 数据还是旧的，因为此时还没有开始重新渲染DOM节点 updated：实例更新完毕之后调用此函数，此时 data 中的状态值 和 界面上显示的数据，都已经完成了更新，界面已经被重新渲染好了！ 销毁期间的生命周期函数： beforeDestroy：实例销毁之前调用。在这一步，实例仍然完全可用。 destroyed：Vue 实例销毁后调用。调用后，Vue 实例指示的所有东西都会解绑定，所有的事件监听器 vue-resource 实现 get, post, jsonp请求 除了 vue-resource 之外，还可以使用 axios 的第三方包实现实现数据的请求 之前的学习中，如何发起数据请求？ 常见的数据请求类型？ get post jsonp 测试的URL请求资源地址： get请求地址： http://vue.studyit.io/api/getlunbo post请求地址：http://vue.studyit.io/api/post jsonp请求地址：http://vue.studyit.io/api/jsonp JSONP的实现原理 由于浏览器的安全性限制，不允许AJAX访问 协议不同、域名不同、端口号不同的 数据接口，浏览器认为这种访问不安全； 可以通过动态创建script标签的形式，把script标签的src属性，指向数据接口的地址，因为script标签不存在跨域限制，这种数据获取方式，称作JSONP（注意：根据JSONP的实现原理，知晓，JSONP只支持Get请求）； 具体实现过程： 先在客户端定义一个回调方法，预定义对数据的操作； 再把这个回调方法的名称，通过URL传参的形式，提交到服务器的数据接口； 服务器数据接口组织好要发送给客户端的数据，再拿着客户端传递过来的回调方法名称，拼接出一个调用这个方法的字符串，发送给客户端去解析执行； 客户端拿到服务器返回的字符串之后，当作Script脚本去解析执行，这样就能够拿到JSONP的数据了； 带大家通过 Node.js ，来手动实现一个JSONP的请求例子； const http = require('http'); // 导入解析 URL 地址的核心模块 const urlModule = require('url'); const server = http.createServer(); // 监听 服务器的 request 请求事件，处理每个请求 server.on('request', (req, res) => { const url = req.url; // 解析客户端请求的URL地址 var info = urlModule.parse(url, true); // 如果请求的 URL 地址是 /getjsonp ，则表示要获取JSONP类型的数据 if (info.pathname === '/getjsonp') { // 获取客户端指定的回调函数的名称 var cbName = info.query.callback; // 手动拼接要返回给客户端的数据对象 var data = { name: 'zs', age: 22, gender: '男', hobby: ['吃饭', '睡觉', '运动'] }; // 拼接出一个方法的调用，在调用这个方法的时候，把要发送给客户端的数据，序列化为字符串，作为参数传递给这个调用的方法： var result = `${cbName}(${JSON.stringify(data)})`; // 将拼接好的方法的调用，返回给客户端去解析执行 res.end(result); } else { res.end('404'); } }); server.listen(3000, () => { console.log('server running at http://127.0.0.1:3000'); Vue.js Ajax(axios) Vue.js 2.0 版本推荐使用 axios 来完成 ajax 请求。 Axios 是一个基于 Promise 的 HTTP 库，可以用在浏览器和 node.js 中。 Github开源地址： https://github.com/axios/axios 安装方法 使用 cdn: 或 使用 npm: $ npm install axios 使用 bower: $ bower install axios 使用 yarn: $ yarn add axios GET方法 我们可以简单的读取 JSON 数据： new Vue({ el: '#app', data () { return { info: null } }, mounted () { axios .get('https://www.runoob.com/try/ajax/json_demo.json') .then(response => (this.info = response)) .catch(function (error) { // 请求失败处理 console.log(error); }); } }) 使用 response.data 读取 JSON 数据： 网站列表 { { site.name } } new Vue({ el: '#app', data () { return { info: null } }, mounted () { axios .get('https://www.runoob.com/try/ajax/json_demo.json') .then(response => (this.info = response.data.sites)) .catch(function (error) { // 请求失败处理 console.log(error); }); } }) GET 方法传递参数格式如下： // 直接在 URL 上添加参数 ID=12345 axios.get('/user?ID=12345') .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); // 也可以通过 params 设置参数： axios.get('/user', { params: { ID: 12345 } }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); POST方法 示例 new Vue({ el: '#app', data () { return { info: null } }, mounted () { axios .post('https://www.runoob.com/try/ajax/demo_axios_post.php') .then(response => (this.info = response)) .catch(function (error) { // 请求失败处理 console.log(error); }); } }) POST 方法传递参数格式如下： axios.post('/user', { firstName: 'Fred', // 参数 firstName lastName: 'Flintstone' // 参数 lastName }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); 执行多个并发请求 示例 function getUserAccount() { return axios.get('/user/12345'); } function getUserPermissions() { return axios.get('/user/12345/permissions'); } axios.all([getUserAccount(), getUserPermissions()]) .then(axios.spread(function (acct, perms) { // 两个请求现在都执行完成 })); axios API 可以通过向axios传递相关配置来创建请求 axios(config) // 发送 POST 请求 axios({ method: 'post', url: '/user/12345', data: { firstName: 'Fred', lastName: 'Flintstone' } }); // GET 请求远程图片 axios({ method:'get', url:'http://bit.ly/2mTM3nY', responseType:'stream' }) .then(function(response) { response.data.pipe(fs.createWriteStream('ada_lovelace.jpg')) }); axios(url[, config]) // 发送 GET 请求（默认的方法） axios('/user/12345'); 请求方法的别名 为方便使用，官方为所有支持的请求方法提供了别名，可以直接使用别名来发起请求： axios.request(config) axios.get(url[, config]) axios.delete(url[, config]) axios.head(url[, config]) axios.post(url[, data[, config]]) axios.put(url[, data[, config]]) axios.patch(url[, data[, config]]) 注意：在使用别名方法时， url、method、data 这些属性都不必在配置中指定。 并发 处理并发请求的助手函数 axios.all(iterable) axios.spread(callback) 创建实例 可以使用自定义配置创建一个axios实例： axios.create([config]) const instance = axios.create({ baseURL: 'https://some-domain.com/api/', timeout: 1000, headers: {'X-Custom-Header': 'foobar'} }); 实例方法 以下是可以的实例方法，指定的配置将与实例的配置合并 axios#request(config) axios#get(url[, config]) axios#delete(url[, config]) axios#head(url[, config]) axios#post(url[, data[, config]]) axios#put(url[, data[, config]]) axios#patch(url[, data[, config]]) 请求配置项 下面是创建请求时可用的配置选项，注意只有url是必需的。如果没有指定method，请求将默认使用get方法。 { // `url` 是用于请求的服务器 URL url: \"/user\", // `method` 是创建请求时使用的方法 method: \"get\", // 默认是 get // `baseURL` 将自动加在 `url` 前面，除非 `url` 是一个绝对 URL。 // 它可以通过设置一个 `baseURL` 便于为 axios 实例的方法传递相对 URL baseURL: \"https://some-domain.com/api/\", // `transformRequest` 允许在向服务器发送前，修改请求数据 // 只能用在 \"PUT\", \"POST\" 和 \"PATCH\" 这几个请求方法 // 后面数组中的函数必须返回一个字符串，或 ArrayBuffer，或 Stream transformRequest: [function (data) { // 对 data 进行任意转换处理 return data; }], // `transformResponse` 在传递给 then/catch 前，允许修改响应数据 transformResponse: [function (data) { // 对 data 进行任意转换处理 return data; }], // `headers` 是即将被发送的自定义请求头 headers: {\"X-Requested-With\": \"XMLHttpRequest\"}, // `params` 是即将与请求一起发送的 URL 参数 // 必须是一个无格式对象(plain object)或 URLSearchParams 对象 params: { ID: 12345 }, // `paramsSerializer` 是一个负责 `params` 序列化的函数 // (e.g. https://www.npmjs.com/package/qs, http://api.jquery.com/jquery.param/) paramsSerializer: function(params) { return Qs.stringify(params, {arrayFormat: \"brackets\"}) }, // `data` 是作为请求主体被发送的数据 // 只适用于这些请求方法 \"PUT\", \"POST\", 和 \"PATCH\" // 在没有设置 `transformRequest` 时，必须是以下类型之一： // - string, plain object, ArrayBuffer, ArrayBufferView, URLSearchParams // - 浏览器专属：FormData, File, Blob // - Node 专属： Stream data: { firstName: \"Fred\" }, // `timeout` 指定请求超时的毫秒数(0 表示无超时时间) // 如果请求花费了超过 `timeout` 的时间，请求将被中断 timeout: 1000, // `withCredentials` 表示跨域请求时是否需要使用凭证 withCredentials: false, // 默认的 // `adapter` 允许自定义处理请求，以使测试更轻松 // 返回一个 promise 并应用一个有效的响应 (查阅 [response docs](#response-api)). adapter: function (config) { /* ... */ }, // `auth` 表示应该使用 HTTP 基础验证，并提供凭据 // 这将设置一个 `Authorization` 头，覆写掉现有的任意使用 `headers` 设置的自定义 `Authorization`头 auth: { username: \"janedoe\", password: \"s00pers3cret\" }, // `responseType` 表示服务器响应的数据类型，可以是 \"arraybuffer\", \"blob\", \"document\", \"json\", \"text\", \"stream\" responseType: \"json\", // 默认的 // `xsrfCookieName` 是用作 xsrf token 的值的cookie的名称 xsrfCookieName: \"XSRF-TOKEN\", // default // `xsrfHeaderName` 是承载 xsrf token 的值的 HTTP 头的名称 xsrfHeaderName: \"X-XSRF-TOKEN\", // 默认的 // `onUploadProgress` 允许为上传处理进度事件 onUploadProgress: function (progressEvent) { // 对原生进度事件的处理 }, // `onDownloadProgress` 允许为下载处理进度事件 onDownloadProgress: function (progressEvent) { // 对原生进度事件的处理 }, // `maxContentLength` 定义允许的响应内容的最大尺寸 maxContentLength: 2000, // `validateStatus` 定义对于给定的HTTP 响应状态码是 resolve 或 reject promise 。如果 `validateStatus` 返回 `true` (或者设置为 `null` 或 `undefined`)，promise 将被 resolve; 否则，promise 将被 rejecte validateStatus: function (status) { return status &gt;= 200 &amp;&amp; status &lt; 300; // 默认的 }, // `maxRedirects` 定义在 node.js 中 follow 的最大重定向数目 // 如果设置为0，将不会 follow 任何重定向 maxRedirects: 5, // 默认的 // `httpAgent` 和 `httpsAgent` 分别在 node.js 中用于定义在执行 http 和 https 时使用的自定义代理。允许像这样配置选项： // `keepAlive` 默认没有启用 httpAgent: new http.Agent({ keepAlive: true }), httpsAgent: new https.Agent({ keepAlive: true }), // \"proxy\" 定义代理服务器的主机名称和端口 // `auth` 表示 HTTP 基础验证应当用于连接代理，并提供凭据 // 这将会设置一个 `Proxy-Authorization` 头，覆写掉已有的通过使用 `header` 设置的自定义 `Proxy-Authorization` 头。 proxy: { host: \"127.0.0.1\", port: 9000, auth: : { username: \"mikeymike\", password: \"rapunz3l\" } }, // `cancelToken` 指定用于取消请求的 cancel token // （查看后面的 Cancellation 这节了解更多） cancelToken: new CancelToken(function (cancel) { }) } 响应结构 axios请求的响应包含以下信息 { // `data` 由服务器提供的响应 data: {}, // `status` HTTP 状态码 status: 200, // `statusText` 来自服务器响应的 HTTP 状态信息 statusText: \"OK\", // `headers` 服务器响应的头 headers: {}, // `config` 是为请求提供的配置信息 config: {} } 使用then时，会接收下面这样的响应： axios.get(\"/user/12345\") .then(function(response) { console.log(response.data); console.log(response.status); console.log(response.statusText); console.log(response.headers); console.log(response.config); }); 在使用 catch 时，或传递 rejection callback 作为 then 的第二个参数时，响应可以通过 error 对象可被使用。 配置的默认值 你可以指定将被用在各个请求的配置默认值。 全局的axios默认值 axios.defaults.baseURL = 'https://api.example.com'; axios.defaults.headers.common['Authorization'] = AUTH_TOKEN; axios.defaults.headers.post['Content-Type'] = 'application/x-www-form-urlencoded'; 自定义实例默认值 // 创建实例时设置配置的默认值 var instance = axios.create({ baseURL: 'https://api.example.com' }); // 在实例已创建后修改默认值 instance.defaults.headers.common['Authorization'] = AUTH_TOKEN; 配置的优先顺序 配置会以一个优先顺序进行合并。这个顺序是：在 lib/defaults.js 找到的库的默认值，然后是实例的 defaults 属性，最后是请求的 config 参数。后者将优先于前者。这里是一个例子： // 使用由库提供的配置的默认值来创建实例 // 此时超时配置的默认值是 `0` var instance = axios.create(); // 覆写库的超时默认值 // 现在，在超时前，所有请求都会等待 2.5 秒 instance.defaults.timeout = 2500; // 为已知需要花费很长时间的请求覆写超时设置 instance.get('/longRequest', { timeout: 5000 }); 拦截器 在请求或响应被 then 或 catch 处理前拦截它们。 // 添加请求拦截器 axios.interceptors.request.use(function (config) { // 在发送请求之前做些什么 return config; }, function (error) { // 对请求错误做些什么 return Promise.reject(error); }); // 添加响应拦截器 axios.interceptors.response.use(function (response) { // 对响应数据做点什么 return response; }, function (error) { // 对响应错误做点什么 return Promise.reject(error); }); 如果你想在稍后移除拦截器，可以这样： var myInterceptor = axios.interceptors.request.use(function () {/*...*/}); axios.interceptors.request.eject(myInterceptor); 可以为自定义 axios 实例添加拦截器。 var instance = axios.create(); instance.interceptors.request.use(function () {/*...*/}); 错误处理： axios.get('/user/12345') .catch(function (error) { if (error.response) { // 请求已发出，但服务器响应的状态码不在 2xx 范围内 console.log(error.response.data); console.log(error.response.status); console.log(error.response.headers); } else { // Something happened in setting up the request that triggered an Error console.log('Error', error.message); } console.log(error.config); }); 可以使用 validateStatus 配置选项定义一个自定义 HTTP 状态码的错误范围。 axios.get('/user/12345', { validateStatus: function (status) { return status 取消 使用 cancel token 取消请求。 Axios 的 cancel token API 基于cancelable promises proposal 可以使用 CancelToken.source 工厂方法创建 cancel token，像这样： var CancelToken = axios.CancelToken; var source = CancelToken.source(); axios.get('/user/12345', { cancelToken: source.token }).catch(function(thrown) { if (axios.isCancel(thrown)) { console.log('Request canceled', thrown.message); } else { // 处理错误 } }); // 取消请求（message 参数是可选的） source.cancel('Operation canceled by the user.'); 还可以通过传递一个 executor 函数到 CancelToken 的构造函数来创建 cancel token： var CancelToken = axios.CancelToken; var cancel; axios.get('/user/12345', { cancelToken: new CancelToken(function executor(c) { // executor 函数接收一个 cancel 函数作为参数 cancel = c; }) }); // 取消请求 cancel(); 注意：可以使用同一个 cancel token 取消多个请求。 请求时使用 application/x-www-form-urlencoded axios 会默认序列化 JavaScript 对象为 JSON。 如果想使用 application/x-www-form-urlencoded 格式，你可以使用下面的配置。 浏览器 在浏览器环境，你可以使用 URLSearchParams API： const params = new URLSearchParams(); params.append('param1', 'value1'); params.append('param2', 'value2'); axios.post('/foo', params); URLSearchParams 不是所有的浏览器均支持。 除此之外，你可以使用 qs 库来编码数据: const qs = require('qs'); axios.post('/foo', qs.stringify({ 'bar': 123 })); // Or in another way (ES6), import qs from 'qs'; const data = { 'bar': 123 }; const options = { method: 'POST', headers: { 'content-type': 'application/x-www-form-urlencoded' }, data: qs.stringify(data), url, }; axios(options); Node.js 环境 在 node.js里, 可以使用 querystring 模块: const querystring = require('querystring'); axios.post('http://something.com/', querystring.stringify({ foo: 'bar' })); 当然，同浏览器一样，你还可以使用 qs 库。 Promises axios 依赖原生的 ES6 Promise 实现而被支持。 如果你的环境不支持 ES6 Promise，你可以使用 polyfill。 TypeScript支持 axios 包含 TypeScript 的定义。 import axios from \"axios\"; axios.get(\"/user?ID=12345\"); 案例 跑马灯 简易计算器 品牌管理案例 "},"Web/JavaScript/框架/Vue.js组件.html":{"url":"Web/JavaScript/框架/Vue.js组件.html","title":"Vue.Js组件","keywords":"","body":"datetime:2019/11/27 16:40 author:nzb Vue.js组件 基础 基本示例 简单示例 // 定义一个名为 button-counter 的新组件 Vue.component('button-counter', { data: function () { return { count: 0 } }, template: 'You clicked me { { count } } times.' }) new Vue({ el: '#components-demo' }) 组件是可复用的 Vue 实例，且带有一个名字：在这个例子中是 。我们可以在一个通过 new Vue 创建的 Vue 根实例中，把这个组件作为自定义元素来使用： 因为组件是可复用的 Vue 实例，所以它们与 new Vue 接收相同的选项，例如 data、computed、watch、methods 以及生命周期钩子等。仅有的例外是像 el 这样根实例特有的选项。 组件的复用 你可以将组件进行任意次数的复用： 注意当点击按钮时，每个组件都会各自独立维护它的 count。因为你每用一次组件，就会有一个它的新实例被创建。 data必须是一个函数 当我们定义这个 组件时，你可能会发现它的 data 并不是像这样直接提供一个对象： data: { count: 0 } 取而代之的是，一个组件的 data 选项必须是一个函数，因此每个实例可以维护一份被返回对象的独立的拷贝： data: function f() { return { count: 0 } } 组件的注册 通常一个应用会以一颗嵌套的组件树的形式来组织 例如，你可能会有页头、侧边栏、内容区等组件，每个组件又包含了其它的像导航链接、博文之类的组件。 为了能在模板中使用，这些组件必须先注册以便 Vue 能够识别。这里有两种组件的注册类型：全局注册和局部注册。 组件名 在注册一个组件的时候，我们始终需要给它一个名字。比如在全局注册的时候我们已经看到了： Vue.component('my-component-name', { /* ... */ }) 该组件名就是 Vue.component 的第一个参数。 你给予组件的名字可能依赖于你打算拿它来做什么。当直接在 DOM 中使用一个组件 (而不是在字符串模板或单文件组件) 的时候，我们强烈推荐遵循 W3C 规范中的自定义组件名 (字母全小写且必须包含一个连字符)。这会帮助你避免和当前以及未来的 HTML 元素相冲突。 你可以在风格指南中查阅到关于组件名的其它建议。 组件名大小写 使用kebab-case Vue.component('my-component-name', { /* ... */ }) 当使用 kebab-case (短横线分隔命名) 定义一个组件时，你也必须在引用这个自定义元素时使用 kebab-case，例如 。 使用 PascalCase Vue.component('MyComponentName', { /* ... */ }) 当使用 PascalCase (首字母大写命名) 定义一个组件时，你在引用这个自定义元素时两种命名法都可以使用。也就是说 和 都是可接受的。注意，尽管如此，直接在 DOM (即非字符串的模板) 中使用时只有 kebab-case 是有效的。 全局注册 到目前为止，我们只用过 Vue.component 来创建组件： Vue.component('my-component-name', { // ... 选项 ... }) 这些组件是全局注册的。也就是说它们在注册之后可以用在任何新创建的 Vue 根实例 (new Vue) 的模板中。比如： Vue.component('component-a', { /* ... */ }) Vue.component('component-b', { /* ... */ }) Vue.component('component-c', { /* ... */ }) new Vue({ el: '#app' }) 在所有子组件中也是如此，也就是说这三个组件在各自内部也都可以相互使用。 局部注册 全局注册往往是不够理想的。比如，如果你使用一个像 webpack 这样的构建系统，全局注册所有的组件意味着即便你已经不再使用一个组件了，它仍然会被包含在你最终的构建结果中。这造成了用户下载的 JavaScript 的无谓的增加。 在这些情况下，你可以通过一个普通的 JavaScript 对象来定义组件： var ComponentA = { /* ... */ } var ComponentB = { /* ... */ } var ComponentC = { /* ... */ } 然后在 components 选项中定义你想要使用的组件： new Vue({ el: '#app', components: { 'component-a': ComponentA, 'component-b': ComponentB } }) 对于 components 对象中的每个属性来说，其属性名就是自定义元素的名字，其属性值就是这个组件的选项对象。 注意局部注册的组件在其子组件中不可用。例如，如果你希望 ComponentA 在 ComponentB 中可用，则你需要这样写： var ComponentA = { /* ... */ } var ComponentB = { components: { 'component-a': ComponentA }, // ... } 或者如果你通过 Babel 和 webpack 使用 ES2015 模块，那么代码看起来更像： import ComponentA from './ComponentA.vue' export default { components: { ComponentA }, // ... } 注意在 ES2015+ 中，在对象中放一个类似 ComponentA 的变量名其实是 ComponentA: ComponentA 的缩写，即这个变量名同时是： 用在模板中的自定义元素的名称 包含了这个组件选项的变量名 通过 Prop 向子组件传递数据 早些时候，我们提到了创建一个博文组件的事情。问题是如果你不能向这个组件传递某一篇博文的标题或内容之类的我们想展示的数据的话，它是没有办法使用的。这也正是 prop 的由来。 Prop 是你可以在组件上注册的一些自定义特性。当一个值传递给一个 prop 特性的时候，它就变成了那个组件实例的一个属性。为了给博文组件传递一个标题，我们可以用一个 props 选项将其包含在该组件可接受的 prop 列表中： Vue.component('blog-post', { props: ['title'], template: '{ { title } }' }) 一个组件默认可以拥有任意数量的 prop，任何值都可以传递给任何 prop。在上述模板中，你会发现我们能够在组件实例中访问这个值，就像访问 data 中的值一样。 一个 prop 被注册之后，你就可以像这样把数据作为一个自定义特性传递进来： 然而在一个典型的应用中，你可能在 data 里有一个博文的数组： new Vue({ el: '#blog-post-demo', data: { posts: [ { id: 1, title: 'My journey with Vue' }, { id: 2, title: 'Blogging with Vue' }, { id: 3, title: 'Why Vue is so fun' } ] } }) 并想要为每篇博文渲染一个组件： 如上所示，你会发现我们可以使用 v-bind 来动态传递 prop。这在你一开始不清楚要渲染的具体内容，比如从一个 API 获取博文列表的时候，是非常有用的。 到目前为止，关于 prop 你需要了解的大概就这些了，如果你阅读完本页内容并掌握了它的内容，我们会推荐你再回来把 prop 读完。 单个根元素 当构建一个 组件时，你的模板最终会包含的东西远不止一个标题： { { title } } 最最起码，你会包含这篇博文的正文： { { title } } 然而如果你在模板中尝试这样写，Vue 会显示一个错误，并解释道 every component must have a single root element (每个组件必须只有一个根元素)。你可以将模板的内容包裹在一个父元素内，来修复这个问题，例如： { { title } } 看起来当组件变得越来越复杂的时候，我们的博文不只需要标题和内容，还需要发布日期、评论等等。为每个相关的信息定义一个 prop 会变得很麻烦： 所以是时候重构一下这个 组件了，让它变成接受一个单独的 post prop： Vue.component('blog-post', { props: ['post'], template: ` { { post.title } } ` }) 注意：上述的这个和一些接下来的示例使用了 JavaScript 的模板字符串来让多行的模板更易读。它们在 IE 下并没有被支持，所以如果你需要在不 (经过 Babel 或 TypeScript 之类的工具) 编译的情况下支持 IE，请使用折行转义字符取而代之。 现在，不论何时为 post 对象添加一个新的属性，它都会自动地在 内可用。 动态组件(组件切换) 有点时候，在不同组件之间进行动态切换是非常有用的，比如在一个多标签的界面里： 上述内容可以通过 Vue 的 元素加一个特殊的 is 特性来实现： 在上述示例中，currentTabComponent 可以包括 已注册组件的名字，或 一个组件的选项对象 你可以在这里查阅并体验完整的代码，或在这个版本了解绑定组件选项对象，而不是已注册组件名的示例。 到目前为止，关于动态组件你需要了解的大概就这些了，如果你阅读完本页内容并掌握了它的内容，我们会推荐你再回来把动态和异步组件读完。 多个组件的过渡动画 多个组件的过渡简单很多 - 我们不需要使用 key 特性。相反，我们只需要使用动态组件。 其中mode=\"out-in\"属性是先出后进 new Vue({ el: '#transition-components-demo', data: { view: 'v-a' }, components: { 'v-a': { template: 'Component A' }, 'v-b': { template: 'Component B' } } }) .component-fade-enter-active, .component-fade-leave-active { transition: opacity .3s ease; } .component-fade-enter, .component-fade-leave-to /* .component-fade-leave-active for below version 2.1.8 */ { opacity: 0; } 父组件向子组件传值 Document var vm = new Vue({ el: '#app', data:{ msg: '123父组件中的数据' }, methods: { }, components:{ 'com1':{ //子组件中，默认无法访问到父组件中的data和methods template: ' 这是子组件 { {parentmsg} }', //注意，组件中的所有props中的数据都是通过父组件传递给子组件的 //propes中的数据是只可读 props: ['parentmsg'] ,// 把父组件传递过来的parentmsg属性， 数组中，定义一下，这样才能用这个数据, //注意子组件中的data数据，并不是通过父组件传递过来的，而是子组件字有的，比如：子组件通过Ajax请求回来的值，可以放到data中 //dat a中的数据可读可写 data(){ return { title: '123', content: 'qqq' } }, methods: { change(){ this.parentmsg='被修改' } }, } } }) 父组件把方法传递给子组件 Document 子组件 //定义了一个字面类型的组件模板对象 var com2 = { template: '#temp1' , methods: { myclick(){ //当点击子组件方法的时候，如何拿到父组件传递过来的func方法 //emit是触发的意思 this.$emit('func', this.sonmsg) } }, data() { return { sonmsg: { name: 'aaa', age: 6 } } } } var vm = new Vue({ el: '#app', data: { datamsgFromSon: null }, methods: { show(data){ // console.log('调用了父组件身上的show方法'+data) console.log(data) this.datamsgFromSon = data }, }, components:{ com2 }, }) ref获取DOM元素和组件 Document 哈哈哈 拉拉 var login = { template: ' 登陆组件 ', data(){ return { msg: 'template msg' } }, methods: { show(){ console.log('调用了子组件的方法') } }, } var vm = new Vue({ el: '#app', data: { }, methods: { getElement(){ console.log(this.$refs.myh3.innerText) console.log(this.$refs.myLogin.msg) this.$refs.myLogin.show() } }, components:{ login } }) "},"Web/JavaScript/框架/Vue.js路由.html":{"url":"Web/JavaScript/框架/Vue.js路由.html","title":"Vue.Js路由","keywords":"","body":"datetime:2019/12/3 14:13 author:nzb Vue.js路由 什么是路由 后端路由：对于普通的网站，所有的超链接都是URL地址，所有的URL地址都对应服务器上对应的资源； 前端路由：对于单页面应用程序来说，主要通过URL中的hash(#号)来实现不同页面之间的切换，同时，hash有一个特点：HTTP请求中不会包含hash相关的内容；所以，单页面程序中的页面跳转主要用hash实现； 在单页面应用程序中，这种通过hash改变来切换页面的方式，称作前端路由（区别于后端路由）； 基本示例 Document .router-link-active, .myactive { color: red; font-weight: 800; font-style: italic; font-size: 80px; text-decoration: underline; background-color: green; } .v-enter, .v-leave-to { opacity: 0; transform: translateX(140px); } .v-enter-active, .v-leave-active { transition: all 0.5s ease; } 登陆 注册 登陆 注册 var login = { template: 'login' } var register = { template: '注册' } /* 1 创建一个路由对象， 当导入vue-router之后，在windows 全局对象中，就有了一个路由的构造函数叫做VueRouter 在new路由对象的时候，可以为构造函数传递一个配置对象 */ var routerObj = new VueRouter({ routes: [ //路由匹配规则 /* 每个路由规则都是一个对象，这个规则的对象必须有两个必须的属性 属性1：path 表示监听哪个路由链接地址 属性2：component，表示如果路由是前面匹配到的path，则展示component属性对应的组件 */ //注意：component的属性值必须是一个组件的模板对象 不能是组件的引用名称 //{ path: '/', component: login}, {path: '/', redirect: '/login'}, {path: '/login', component: login}, {path: '/register', component: register}], linkActiveClass: 'myactive' }) var vm = new Vue({ el: '#app', data: {}, methods: {}, //将路由规则对象， 注册到vm实例上，用来舰艇URL地址的变化，然后展示对应的组件 router: routerObj }) 重定向和别名 重定向 // 重定向也是通过 `routes` 配置来完成，下面例子是从 `/a` 重定向到 `/b`： const router = new VueRouter({ routes: [ {path: '/a', redirect: '/b'} ] }) //重定向的目标也可以是一个命名的路由： const router = new VueRouter({ routes: [ {path: '/a', redirect: {name: 'foo'}} ] }) // 甚至是一个方法，动态返回重定向目标： const router = new VueRouter({ routes: [ { path: '/a', redirect: to => { // 方法接收 目标路由 作为参数 // return 重定向的 字符串路径/路径对象 } } ] }) 注意导航守卫并没有应用在跳转路由上，而仅仅应用在其目标上。在下面这个例子中，为 /a 路由添加一个 beforeEach 或 beforeLeave 守卫并不会有任何效果。 其它高级用法，请参考例子。 别名 “重定向”的意思是，当用户访问 /a时，URL 将会被替换成 /b，然后匹配路由为 /b，那么“别名”又是什么呢？ /a 的别名是 /b，意味着，当用户访问 /b 时，URL 会保持为 /b，但是路由匹配则为 /a，就像用户访问 /a 一样。 上面对应的路由配置为： const router = new VueRouter({ routes: [ { path: '/a', component: A, alias: '/b' } ] }) “别名”的功能让你可以自由地将 UI 结构映射到任意的 URL，而不是受限于配置的嵌套路由结构。更多高级用法，请查看例子。 高亮，过渡动画，重定向示例 在路由规则中定义参数 在规则中定义参数： { path: '/register/:id', component:register } 通过 this.$route.params来获取路由中的参数： var register = Vue.extend({ template: '注册组件 --- { {this.$route.params.id} }' }); 路由嵌套 实际生活中的应用界面，通常由多层嵌套的组件组合而成。同样地，URL 中各段动态路径也按某种结构对应嵌套的各层组件，例如： 借助 vue-router，使用嵌套路由配置，就可以很简单地表达这种关系。 接着上节创建的 app： 这里的 是最顶层的出口，渲染最高级路由匹配到的组件。同样地，一个被渲染组件同样可以包含自己的嵌套 。例如，在 User 组件的模板添加一个 ： const User = { template: ` User { { $route.params.id } } ` } 要在嵌套的出口中渲染组件，需要在 VueRouter 的参数中使用 children 配置： const router = new VueRouter({ routes: [ { path: '/user/:id', component: User, children: [ { // 当 /user/:id/profile 匹配成功， // UserProfile 会被渲染在 User 的 中 path: 'profile', component: UserProfile }, { // 当 /user/:id/posts 匹配成功 // UserPosts 会被渲染在 User 的 中 path: 'posts', component: UserPosts } ] } ] }) 要注意，以 / 开头的嵌套路径会被当作根路径。 这让你充分的使用嵌套组件而无须设置嵌套的路径。 你会发现，children 配置就是像 routes 配置一样的路由配置数组，所以呢，你可以嵌套多层路由。 此时，基于上面的配置，当你访问 /user/foo 时，User 的出口是不会渲染任何东西，这是因为没有匹配到合适的子路由。如果你想要渲染点什么，可以提供一个 空的 子路由： const router = new VueRouter({ routes: [ { path: '/user/:id', component: User, children: [ // 当 /user/:id 匹配成功， // UserHome 会被渲染在 User 的 中 {path: '', component: UserHome}, // ...其他子路由 ] } ] }) 命名视图 示例实现经典布局 名称拼接案例 案例1：使用keyup 案例2：使用watch监听 使用watch监听路由变化 案例3：computed计算属性 watch、computed和methods之间的对比 computed属性的结果会被缓存，除非依赖的响应式属性变化才会重新计算。主要当作属性来使用； methods方法表示一个具体的操作，主要书写业务逻辑； watch一个对象，键是需要观察的表达式，值是对应回调函数。主要用来监听某些特定数据的变化，从而进行某些具体的业务逻辑操作；可以看作是computed和methods的结合体； "},"Web/JavaScript/框架/Vue.js过渡和动画.html":{"url":"Web/JavaScript/框架/Vue.js过渡和动画.html","title":"Vue.Js过渡和动画","keywords":"","body":"datetime:2019/11/26 9:19 author:nzb Vue.js过渡和动画 Vue 在插入、更新或者移除 DOM 时，提供多种不同方式的应用过渡效果。 包括以下工具： 在 CSS 过渡和动画中自动应用 class 可以配合使用第三方 CSS 动画库，如 Animate.css 在过渡钩子函数中使用 JavaScript 直接操作 DOM 可以配合使用第三方 JavaScript 动画库，如 Velocity.js 单元素/组件的过渡 简单例子 Toggle hello new Vue({ el: '#demo', data: { show: true } }) .fade-enter-active, .fade-leave-active { transition: opacity .5s; } .fade-enter, .fade-leave-to /* .fade-leave-active below version 2.1.8 */ { opacity: 0; } 过渡的类名 过渡其实就是一个淡入淡出的效果。Vue在元素显示与隐藏的过渡中，提供了 6 个 class 来切换： v-enter：定义进入过渡的开始状态。在元素被插入之前生效，在元素被插入之后的下一帧移除。 v-enter-active：定义进入过渡生效时的状态。在整个进入过渡的阶段中应用，在元素被插入之前生效，在过渡/动画完成之后移除。这个类可以被用来定义进入过渡的过程时间，延迟和曲线函数。 v-enter-to: 2.1.8版及以上 定义进入过渡的结束状态。在元素被插入之后下一帧生效 (与此同时 v-enter 被移除)，在过渡/动画完成之后移除。 v-leave: 定义离开过渡的开始状态。在离开过渡被触发时立刻生效，下一帧被移除。 v-leave-active：定义离开过渡生效时的状态。在整个离开过渡的阶段中应用，在离开过渡被触发时立刻生效，在过渡/动画完成之后移除。这个类可以被用来定义离开过渡的过程时间，延迟和曲线函数。 v-leave-to: 2.1.8版及以上 定义离开过渡的结束状态。在离开过渡被触发之后下一帧生效 (与此同时 v-leave 被删除)，在过渡/动画完成之后移除。 对于这些在过渡中切换的类名来说，如果你使用一个没有名字的 ，则 v- 是这些类名的默认前缀。如果你使用了 ，那么 v-enter 会替换为 my-transition-enter。 v-enter-active 和 v-leave-active 可以控制进入/离开过渡的不同的缓和曲线，在下面章节会有个示例说明。 自定义过渡的类名-使用第三方类库animate.css 我们可以通过以下特性来自定义过渡类名： enter-class enter-active-class enter-to-class (2.1.8+) leave-class leave-active-class leave-to-class (2.1.8+) 他们的优先级高于普通的类名，这对于 Vue 的过渡系统和其他第三方 CSS 动画库，如 Animate.css 结合使用十分有用。 示例： Toggle render hello new Vue({ el: '#example-3', data: { show: true } }) JavaScript钩子 // ... methods: { // -------- // 进入中 // -------- beforeEnter: function (el) { // ... }, // 当与 CSS 结合使用时 // 回调函数 done 是可选的 enter: function (el, done) { // ... done() }, afterEnter: function (el) { // ... }, enterCancelled: function (el) { // ... }, // -------- // 离开时 // -------- beforeLeave: function (el) { // ... }, // 当与 CSS 结合使用时 // 回调函数 done 是可选的 leave: function (el, done) { // ... done() }, afterLeave: function (el) { // ... }, // leaveCancelled 只用于 v-show 中 leaveCancelled: function (el) { // ... } } 这些钩子函数可以结合 CSS transitions/animations 使用，也可以单独使用。 注意： 当只用 JavaScript 过渡的时候，在 enter 和 leave 中必须使用 done 进行回调。否则，它们将被同步调用，过渡会立即完成。 推荐对于仅使用 JavaScript 过渡的元素添加 v-bind:css=\"false\"，Vue 会跳过 CSS 的检测。这也可以避免过渡过程中 CSS 的影响。 一个使用 Velocity.js 的简单例子： Toggle Demo new Vue({ el: '#example-4', data: { show: false }, methods: { beforeEnter: function (el) { el.style.opacity = 0 el.style.transformOrigin = 'left' }, enter: function (el, done) { Velocity(el, { opacity: 1, fontSize: '1.4em' }, { duration: 300 }) Velocity(el, { fontSize: '1em' }, { complete: done }) }, leave: function (el, done) { Velocity(el, { translateX: '15px', rotateZ: '50deg' }, { duration: 600 }) Velocity(el, { rotateZ: '100deg' }, { loop: 2 }) Velocity(el, { rotateZ: '45deg', translateY: '30px', translateX: '30px', opacity: 0 }, { complete: done }) } } }) 初始渲染的过渡 可以通过 appear 特性设置节点在初始渲染的过渡 这里默认和进入/离开过渡一样，同样也可以自定义 CSS 类名。 自定义 JavaScript 钩子： 在上面的例子中，无论是 appear 特性还是 v-on:appear 钩子都会生成初始渲染过渡。 多个元素/组件过渡 列表过渡 目前为止，关于过渡我们已经讲到： 单个节点 同一时间渲染多个节点中的一个 那么怎么同时渲染整个列表，比如使用 v-for ？在这种场景中，使用 组件。在我们深入例子之前，先了解关于这个组件的几个特点： 不同于 ，它会以一个真实元素呈现：默认为一个 。你也可以通过 tag 特性更换为其他元素。 过渡模式不可用，因为我们不再相互切换特有的元素。 内部元素 总是需要 提供唯一的 key 属性值。 CSS 过渡的类将会应用在内部的元素中，而不是这个组/容器本身。 列表的进入/离开过渡 Add Remove { { item } } new Vue({ el: '#list-demo', data: { items: [1,2,3,4,5,6,7,8,9], nextNum: 10 }, methods: { randomIndex: function () { return Math.floor(Math.random() * this.items.length) }, add: function () { this.items.splice(this.randomIndex(), 0, this.nextNum++) }, remove: function () { this.items.splice(this.randomIndex(), 1) }, } }) .list-item { display: inline-block; margin-right: 10px; } .list-enter-active, .list-leave-active { transition: all 1s; } .list-enter, .list-leave-to /* .list-leave-active for below version 2.1.8 */ { opacity: 0; transform: translateY(30px); } 这个例子有个问题，当添加和移除元素的时候，周围的元素会瞬间移动到他们的新布局的位置，而不是平滑的过渡，我们下面会解决这个问题。 列表的排序过渡 组件还有一个特殊之处。不仅可以进入和离开动画，还可以改变定位。要使用这个新功能只需了解新增的 v-move 特性，它会在元素的改变定位的过程中应用。像之前的类名一样，可以通过 name 属性来自定义前缀，也可以通过 move-class 属性手动设置。 v-move 对于设置过渡的切换时机和过渡曲线非常有用，你会看到如下的例子： Shuffle { { item } } new Vue({ el: '#flip-list-demo', data: { items: [1,2,3,4,5,6,7,8,9] }, methods: { shuffle: function () { this.items = _.shuffle(this.items) } } }) .flip-list-move { transition: transform 1s; } 列表的交错过渡 "},"Web/JavaScript/框架/jQuery-UI.html":{"url":"Web/JavaScript/框架/jQuery-UI.html","title":"JQuery UI","keywords":"","body":"datetime:2019/7/12 9:47 author:nzb 特效（Effects） API 描述 也属于类别 .addClass() 当动画样式改变时，为匹配的元素集合内的每个元素添加指定的 Class。 特效核心（Effects Core） | 方法重载（Method Overrides） 百叶窗特效（Blind Effect） 百叶窗特效（Blind Effect）通过将元素包裹在一个容器内，采用\"拉百叶窗\"效果来隐藏或显示元素。 反弹特效（Bounce Effect） 反弹特效（Bounce Effect）反弹一个元素。当与隐藏或显示一起使用时，最后一次或第一次反弹会呈现淡入/淡出效果。 剪辑特效（Clip Effect） 剪辑特效（Clip Effect）通过垂直或水平方向夹剪元素来隐藏或显示一个元素。 颜色动画（Color Animation） 使用 .animate() 实现颜色动画效果。 降落特效（Drop Effect） 降落特效（Drop Effect）通过单个方向滑动的淡入淡出来隐藏或显示一个元素。 Easing Easing函数指定动画在不同点上的行进速度。 .effect() 对一个元素应用动画特效。 特效核心（Effects Core） | 方法（Method） 爆炸特效（Explode Effect） 爆炸特效（Explode Effect）通过把元素裂成碎片来隐藏或显示一个元素。 淡入淡出特效（Fade Effect） 淡入淡出特效（Fade Effect）通过淡入淡出元素来隐藏或显示一个元素。 折叠特效（Fold Effect） 折叠特效（Fold Effect）通过折叠元素来隐藏或显示一个元素。 .hide() 使用自定义效果来隐藏匹配的元素。 特效核心（Effects Core） | 方法重载（Method Overrides） | 方法（Method） 突出特效（Highlight Effect） 突出特效（Highlight Effect）通过首先改变背景颜色来隐藏或显示一个元素。 膨胀特效（Puff Effect） 通过在缩放元素的同时隐藏元素来创建膨胀特效（Puff Effect）。 跳动特效（Pulsate Effect） 跳动特效（Pulsate Effect）通过跳动来隐藏或显示一个元素。 .removeClass() 当动画样式改变时，为匹配的元素集合内的每个元素移除指定的 Class。 特效核心（Effects Core） | 方法重载（Method Overrides） 缩放特效（Scale Effect） 按照某个百分比缩放元素。 震动特效（Shake Effect） 垂直或水平方向多次震动元素。 .show() 使用自定义效果来显示匹配的元素。 特效核心（Effects Core） | 方法重载（Method Overrides） | 方法（Method） 尺寸特效（Size Effect） 调整元素尺寸到指定宽度和高度。 滑动特效（Slide Effect） 把元素滑动出视区。 .switchClass() 当动画样式改变时，为匹配的元素集合内的每个元素添加和移除指定的 Class。 特效核心（Effects Core） .toggle() 使用自定义效果来显示或隐藏匹配的元素。 特效核心（Effects Core） | 方法重载（Method Overrides） | 方法（Method） .toggleClass() 当动画样式改变时，根据 Class 是否存在以及 switch 参数的值，为匹配的元素集合内的每个元素添加或移除一个或多个 Class。 特效核心（Effects Core） | 方法重载（Method Overrides） 转移特效（Transfer Effect） 把一个元素的轮廓转移到另一个元素。 特效核心（Effects Core） API 描述 也属于类别 .addClass() 当动画样式改变时，为匹配的元素集合内的每个元素添加指定的 Class。 特效（Effects） | 方法重载（Method Overrides） 颜色动画（Color Animation） 使用 .animate() 实现颜色动画效果。 .effect() 对一个元素应用动画特效。 特效（Effects） | 方法（Method） .hide() 使用自定义效果来隐藏匹配的元素。 特效（Effects） | 方法重载（Method Overrides） | 方法（Method） .removeClass() 当动画样式改变时，为匹配的元素集合内的每个元素移除指定的 Class。 特效（Effects） | 方法重载（Method Overrides） .show() 使用自定义效果来显示匹配的元素。 特效（Effects） | 方法重载（Method Overrides） | 方法（Method） .switchClass() 当动画样式改变时，为匹配的元素集合内的每个元素添加和移除指定的 Class。 特效（Effects） .toggle() 使用自定义效果来显示或隐藏匹配的元素。 特效（Effects） | 方法重载（Method Overrides） | 方法（Method） .toggleClass() 当动画样式改变时，根据 Class 是否存在以及 switch 参数的值，为匹配的元素集合内的每个元素添加或移除一个或多个 Class。 特效（Effects） | 方法重载（Method Overrides） 交互（Interactions） API 描述 也属于类别 可拖拽小部件（Draggable Widget） 允许使用鼠标移动元素。 可放置小部件（Droppable Widget） 为可拖拽小部件创建目标。 鼠标交互（Mouse Interaction） 基本交互层。 实用工具（Utilities） 可调整尺寸小部件（Resizable Widget） 使用鼠标改变元素的尺寸。 可选择小部件（Selectable Widget） 使用鼠标选择单个元素或一组元素。 可排序小部件（Sortable Widget） 使用鼠标调整列表中或者网格中元素的排序。 方法重载（Method Overrides） API 描述 也属于类别 .addClass() 当动画样式改变时，为匹配的元素集合内的每个元素添加指定的 Class。 特效（Effects） | 特效核心（Effects Core） .focus() 异步聚焦到一个元素。 方法（Method） | UI 核心（UI Core） .hide() 使用自定义效果来隐藏匹配的元素。 特效（Effects） | 特效核心（Effects Core） | 方法（Method） .position() 相对另一个元素定位一个元素。 方法（Method） | 实用工具（Utilities） .removeClass() 当动画样式改变时，为匹配的元素集合内的每个元素移除指定的 Class。 特效（Effects） | 特效核心（Effects Core） .show() 使用自定义效果来显示匹配的元素。 特效（Effects） | 特效核心（Effects Core） | 方法（Method） .toggle() 使用自定义效果来显示或隐藏匹配的元素。 特效（Effects） | 特效核心（Effects Core） | 方法（Method） .toggleClass() 当动画样式改变时，根据 Class 是否存在以及 switch 参数的值，为匹配的元素集合内的每个元素添加或移除一个或多个 Class。 特效（Effects） | 特效核心（Effects Core） 方法（Methods） API 描述 也属于类别 .disableSelection() 禁用选择匹配的元素集合内的文本内容。 UI 核心（UI Core） .effect() 对一个元素应用动画特效。 特效（Effects） | 特效核心（Effects Core） .enableSelection() 启用选择匹配的元素集合内的文本内容。 UI 核心（UI Core） .focus() 异步聚焦到一个元素。 方法重载（Method Overrides） | UI 核心（UI Core） .hide() 使用自定义效果来隐藏匹配的元素。 特效（Effects） | 特效核心（Effects Core） | 方法重载（Method Overrides） .position() 相对另一个元素定位一个元素。 方法重载（Method Overrides） | 实用工具（Utilities） .removeUniqueId() 为匹配的元素集合移除由 .uniqueId() 设置的 Id。 UI 核心（UI Core） .scrollParent() 获取最近的可滚动的祖先。 UI 核心（UI Core） .show() 使用自定义效果来显示匹配的元素。 特效（Effects） | 特效核心（Effects Core） | 方法重载（Method Overrides） .toggle() 使用自定义效果来显示或隐藏匹配的元素。 特效（Effects） | 特效核心（Effects Core） | 方法重载（Method Overrides） .uniqueId() 为匹配的元素集合生成并申请一个唯一的 Id。 UI 核心（UI Core） .zIndex() 为元素获取 z-index。 UI 核心（UI Core） 选择器（Selectors） API 描述 也属于类别 :data() Selector 选择数据已存储在指定的键下的元素。 UI 核心（UI Core） :focusable Selector 选择可被聚焦的元素。 UI 核心（UI Core） :tabbable Selector 选择用户可通过 tab 键聚焦的元素。 UI 核心（UI Core） 主题（Theming） API 描述 CSS 框架（CSS Framework） jQuery UI 使用的允许组件主题化的 Class 名称列表。 图标（Icons） jQuery UI 提供的图标列表。 堆叠元素（Stacking Elements） 一种处理 z-index 和堆叠元素的模式。 UI 核心（UI Core） API 描述 也属于类别 :data() Selector 选择数据已存储在指定的键下的元素。 选择器（Selectors） .disableSelection() 禁用选择匹配的元素集合内的文本内容。 方法（Methods） .enableSelection() 启用选择匹配的元素集合内的文本内容。 方法（Methods） .focus() 异步聚焦到一个元素。 方法重载（Method Overrides） 方法（Methods） :focusable Selector 选择可被聚焦的元素。 选择器（Selectors） jQuery.ui.keyCode 一个相对于数字值的关键代码描述的映射。 .removeUniqueId() 为匹配的元素集合移除由 .uniqueId() 设置的 Id。 方法（Methods） .scrollParent() 获取最近的可滚动的祖先。 方法（Methods） :tabbable Selector 选择用户可通过 tab 键聚焦的元素。 选择器（Selectors） .uniqueId() 为匹配的元素集合生成并申请一个唯一的 Id。 方法（Methods） .zIndex() 为元素获取 z-index。 方法（Methods） 实用工具（Utilities） API 描述 也属于类别 Easings Easing 函数指定动画在不同点上的行进速度。 部件库（Widget Factory） 使用与所有 jQuery UI 小部件相同的抽象化来创建有状态的 jQuery 插件。 小部件（Widgets） 插件桥（Widget Plugin Bridge） jQuery.widget.bridge() 方法是 jQuery 部件库（Widget Factory）的一部分。它扮演着由 $.widget() 创建的对象和 jQuery API 之间的中介。 小部件（Widgets） 鼠标交互（Mouse Interaction） 基本交互层。 交互（Interactions） .position() 相对另一个元素定位一个元素。 方法重载（Method Overrides） | 方法（Method） 小部件（Widgets） API 描述 也属于类别 折叠面板部件（Accordion Widget） 把一对标题和内容面板转换成折叠面板。 自动完成部件（Autocomplete Widget） 自动完成功能根据用户输入值进行搜索和过滤，让用户快速找到并从预设值列表中选择。 按钮部件（Button Widget） 可主题化的按钮和按钮集合。 日期选择器部件（Datepicker Widget） 从弹出框或在线日历选择一个日期。 对话框部件（Dialog Widget） 在一个交互覆盖层中打开内容。 部件库（Widget Factory） 使用与所有 jQuery UI 小部件相同的抽象化来创建有状态的 jQuery 插件。 实用工具（Utilities） 插件桥（Widget Plugin Bridge） jQuery.widget.bridge() 方法是 jQuery 部件库（Widget Factory）的一部分。它扮演着由 $.widget() 创建的对象和 jQuery API 之间的中介。 实用工具（Utilities） 菜单部件（Menu Widget） 带有鼠标和键盘交互的用于导航的可主题化菜单。 进度条部件（Progressbar Widget） 显示一个确定的或不确定的进程状态。 滑块部件（Slider Widget） 拖动手柄可以选择一个数值。 旋转器部件（Spinner Widget） 通过向上/向下按钮和箭头键处理，为输入数值增强文本输入功能。 标签页部件（Tabs Widget） 一种多面板的单内容区，每个面板与列表中的标题相关。 工具提示框部件（Tooltip Widget） 可自定义的、可主题化的工具提示框，替代原生的工具提示框。 "},"Web/JavaScript/框架/jQuery基础.html":{"url":"Web/JavaScript/框架/jQuery基础.html","title":"JQuery基础","keywords":"","body":"datetime:2019/7/10 13:43 author:nzb jQuery简介 jQuery 库可以通过一行简单的标记被添加到网页中。 什么是 jQuery ？ jQuery是一个JavaScript函数库。 jQuery是一个轻量级的\"写的少，做的多\"的JavaScript库。 jQuery库包含以下功能： HTML 元素选取 HTML 元素操作 CSS 操作 HTML 事件函数 JavaScript 特效和动画 HTML DOM 遍历和修改 AJAX Utilities 提示： 除此之外，Jquery还提供了大量的插件。 语法 jQuery 语法是通过选取 HTML 元素，并对选取的元素执行某些操作。 基础语法： $(selector).action() 美元符号定义 jQuery 选择符（selector）\"查询\"和\"查找\" HTML 元素 jQuery 的 action() 执行对元素的操作 实例: $(this).hide() - 隐藏当前元素 $(\"p\").hide() - 隐藏所有 元素 $(\"p.test\").hide() - 隐藏所有 class=\"test\" 的 元素 $(\"#test\").hide() - 隐藏所有 id=\"test\" 的元素 文档就绪事件 您也许已经注意到在我们的实例中的所有 jQuery 函数位于一个 document ready 函数中： $(document).ready(function(){ // 开始写 jQuery 代码... }); 这是为了防止文档在完全加载（就绪）之前运行 jQuery 代码，即在 DOM 加载完成后才可以对 DOM 进行操作。 如果在文档没有完全加载之前就运行函数，操作可能失败。下面是两个具体的例子： 试图隐藏一个不存在的元素 获得未完全加载的图像的大小 提示：简洁写法（与以上写法效果相同）: $(function(){ // 开始写 jQuery 代码... }); 以上两种方式你可以选择你喜欢的方式实现文档就绪后执行 jQuery 方法。 JavaScript 入口函数: window.onload = function () { // 执行代码 } jQuery 入口函数与 JavaScript 入口函数的区别： jQuery 的入口函数是在 html 所有标签(DOM)都加载之后，就会去执行。 JavaScript 的 window.onload 事件是等到所有内容，包括外部图片之类的文件加载完后，才会执行。 选择器 jQuery 选择器允许您对 HTML 元素组或单个元素进行操作。 jQuery 中所有选择器都以美元符号开头：$()。 元素选择器 用户点击按钮后，所有 元素都隐藏： $(document).ready(function(){ $(\"button\").click(function(){ $(\"p\").hide(); }); }); #id 选择器 当用户点击按钮后，有 id=\"test\" 属性的元素将被隐藏： $(document).ready(function(){ $(\"button\").click(function(){ $(\"#test\").hide(); }); }); .class 选择器 用户点击按钮后所有带有 class=\"test\" 属性的元素都隐藏： $(document).ready(function(){ $(\"button\").click(function(){ $(\".test\").hide(); }); }); 更多实例 语法 描述 $(\"*\") 选取所有元素 $(this) 选取当前 HTML 元素 $(\"p.intro\") 选取 class 为 intro 的 元素 $(\"p:first\") 选取第一个 元素 $(\"ul li:first\") 选取第一个 元素的第一个 元素 $(\"ul li:first-child\") 选取每个 元素的第一个 元素 $(\"[href]\") 选取带有 href 属性的元素 $(\"a[target='_blank']\") 选取所有 target 属性值等于 \"_blank\" 的 元素 $(\"a[target!='_blank']\") 选取所有 target 属性值不等于 \"_blank\" 的 元素 $(\":button\") 选取所有 type=\"button\" 的 元素 和 元素 $(\"tr:even\") 选取偶数位置的 元素 $(\"tr:odd\") 选取奇数位置的 元素 $(\"#id\", \".class\") 复合选择器 $(div p span) 层级选择器 //div下的p元素中的span元素 $(div>p) 父子选择器 //div下的所有p元素 $(div+p) 相邻元素选择器 //div后面的p元素(仅一个p) $(div~p) 兄弟选择器 //div后面的所有p元素(同级别) $(.p:last) 类选择器 加 过滤选择器 第一个和最后一个（first 或者 last） $(\"#mytable td:odd\") 层级选择 加 过滤选择器 奇偶（odd 或者 even） $(\"div p:eq(2)\") 索引选择器 div下的第三个p元素（索引是从0开始） $(\"a[href='www.baidu.com']\") 属性选择器 $(\"p:contains(test)\") // 内容过滤选择器，包含text内容的p元素 $(\":emtyp\") //内容过滤选择器，所有空标签（不包含子标签和内容的标签）parent 相反 $(\":hidden\") //所有隐藏元素 visible $(\"input:enabled\") //选取所有启用的表单元素 $(\":disabled\") //所有不可用的元素 $(\"input:checked\") //获取所有选中的复选框单选按钮等 $(\"select option:selected\") //获取选中的选项元素 关于 : 和 [] 这两个符号的理解 “：”：可以理解为种类的意思，如：p:first，p 的种类为第一个。 “[]” ：很自然的可以理解为属性的意思，如：[href] 选取带有 href 属性的元素。 $(\":button\") 为 jQuery 中表单选择器（貌似与过滤选择器同级），旨在选择所有的按钮，所以会找到 、 元素；而 $(\"button\") 则为基本选择器，旨在选择为 的标签。 : 即为 jQuery 的过滤选择器，语法类似于 css 中的伪类选择器；其过滤选择器大概可以分为基本过滤（p:first 之类）、内容过滤（:empty）、子元素过滤(:first-child)和属性过滤 [href] 选择器。 事件 页面对不同访问者的响应叫做事件。 事件处理程序指的是当 HTML 中发生某些事件时所调用的方法。 实例： 在元素上移动鼠标。 选取单选按钮 点击元素 在事件中经常使用术语\"触发\"（或\"激发\"）例如： \"当您按下按键时触发 keypress 事件\"。 常用的 jQuery 事件方法 $(document).ready() $(document).ready() 方法允许我们在文档完全加载完后执行函数。该事件方法在 jQuery 语法 章节中已经提到过。 click() click() 方法是当按钮点击事件被触发时会调用一个函数。 dblclick() 当双击元素时，会发生 dblclick 事件。 mouseenter() 当鼠标指针穿过元素时，会发生 mouseenter 事件。 mouseleave() 当鼠标指针离开元素时，会发生 mouseleave 事件。 mousedown() 当鼠标指针移动到元素上方，并按下鼠标按键时，会发生 mousedown 事件。 mouseup() 当在元素上松开鼠标按钮时，会发生 mouseup 事件。 hover() hover()方法用于模拟光标悬停事件。 当鼠标移动到元素上时，会触发指定的第一个函数(mouseenter);当鼠标移出这个元素时，会触发指定的第二个函数(mouseleave)。 focus() 当元素获得焦点时，发生 focus 事件。 当通过鼠标点击选中元素或通过 tab 键定位到元素时，该元素就会获得焦点。 blur() 当元素失去焦点时，发生 blur 事件。 on() 和 off() 绑定事件和解除绑定事件 笔记 一.keypress,keydown,keyup的区别: 1.keydown：在键盘上按下某键时发生,一直按着则会不断触发（opera浏览器除外）, 它返回的是键盘代码; 2.keypress：在键盘上按下一个按键，并产生一个字符时发生, 返回ASCII码。注意: shift、alt、ctrl等键按下并不会产生字符，所以监听无效 ,换句话说, 只有按下能在屏幕上输出字符的按键时keypress事件才会触发。若一直按着某按键则会不断触发。 3.keyup：用户松开某一个按键时触发, 与keydown相对, 返回键盘代码. 二.两种常用用法举例 案例1:获取按键代码或字符的ASCII码 $(window).keydown( function(event){ // 通过event.which可以拿到按键代码. 如果是keypress事件中,则拿到ASCII码. } ); 案例2:传递数据给事件处理函数 语法: jQueryObject.keypress( [[ data ,] handler ] ); data: 通过event.data传递给事件处理函数的任意数据; handler: 指定的事件处理函数; 举例: // 只允许按下的字母键生效, 65~90是所有大写字母的键盘代码范围. var validKeys = { start: 65, end: 90 }; $(\"#keys\").keypress( validKeys, function(event){ var keys = event.data; //拿到validKeys对象. return event.which >= keys.start && event.which 三.关于获取触发事件的说明： 1.获取事件对象 $(document).ready(function(){ $(window).keypress(function(event){ //获取事件对象，里面包含各种有用的信息。 console.log(event); //console.log(event.which); }); }); 2.keypress事件获取键入字符 $(window).keypress(function(event){ //event.which是获取ASCII码，前面的函数是将ASCII码转换成字符，空格键和Enter键输出均为空白。 console.log(String.fromCharCode(event.which)); //从event对象中key属性获取字符，但是Enter键的key值为\"Enter\"，空白键还是空白\" \"。 console.log(event.key); }); jQuery - noConflict() 方法 正如您已经了解到的，jQuery 使用 $ 符号作为 jQuery 的简写。 如果其他 JavaScript 框架也使用 $ 符号作为简写怎么办？ 其他一些 JavaScript 框架包括：MooTools、Backbone、Sammy、Cappuccino、Knockout、JavaScript MVC、Google Web Toolkit、Google Closure、Ember、Batman 以及 Ext JS。 其中某些框架也使用 $ 符号作为简写（就像 jQuery），如果您在用的两种不同的框架正在使用相同的简写符号，有可能导致脚本停止运行。 jQuery 的团队考虑到了这个问题，并实现了 noConflict() 方法。 noConflict() 方法会释放对 $ 标识符的控制，这样其他脚本就可以使用它了。 当然，您仍然可以通过全名替代简写的方式来使用 jQuery： $.noConflict(); jQuery(document).ready(function(){ jQuery(\"button\").click(function(){ jQuery(\"p\").text(\"jQuery 仍然在工作!\"); }); }); 您也可以创建自己的简写。noConflict() 可返回对 jQuery 的引用，您可以把它存入变量，以供稍后使用。请看这个例子： var jq = $.noConflict(); jq(document).ready(function(){ jq(\"button\").click(function(){ jq(\"p\").text(\"jQuery 仍然在工作!\"); }); }); 如果你的 jQuery 代码块使用 $ 简写，并且您不愿意改变这个快捷方式，那么您可以把 $ 符号作为变量传递给 ready 方法。这样就可以在函数内使用 $ 符号了 - 而在函数外，依旧不得不使用 \"jQuery\"： $.noConflict(); jQuery(document).ready(function($){ $(\"button\").click(function(){ $(\"p\").text(\"jQuery 仍然在工作!\"); }); }); HTML 获取内容和属性 获得内容： text()、html() 以及 val() 三个简单实用的用于 DOM 操作的 jQuery 方法： text() - 设置或返回所选元素的文本内容 html() - 设置或返回所选元素的内容（包括 HTML 标记） val() - 设置或返回表单字段的值 $(\"#btn1\").click(function(){ alert(\"Text: \" + $(\"#test\").text()); }); $(\"#btn2\").click(function(){ alert(\"HTML: \" + $(\"#test\").html()); }); $(\"#btn1\").click(function(){ alert(\"值为: \" + $(\"#test\").val()); }); 获取属性 - attr()：用于获取属性值。 $(\"button\").click(function(){ alert($(\"#runoob\").attr(\"href\")); }); 设置内容和属性 设置内容： text()、html() 以及 val() 我们将使用前一章中的三个相同的方法来设置内容： text() - 设置或返回所选元素的文本内容 html() - 设置或返回所选元素的内容（包括 HTML 标记） val() - 设置或返回表单字段的值 $(\"#btn1\").click(function(){ $(\"#test1\").text(\"Hello world!\"); }); $(\"#btn2\").click(function(){ $(\"#test2\").html(\"Hello world!\"); }); $(\"#btn3\").click(function(){ $(\"#test3\").val(\"RUNOOB\"); }); text()、html() 以及 val() 的回调函数 上面的三个 jQuery 方法：text()、html() 以及 val()，同样拥有回调函数。回调函数有两个参数：被选元素列表中当前元素的下标，以及原始（旧的）值。然后以函数新值返回您希望使用的字符串。 下面的例子演示带有回调函数的 text() 和 html()： $(\"#btn1\").click(function(){ $(\"#test1\").text(function(i,origText){ return \"旧文本: \" + origText + \" 新文本: Hello world! (index: \" + i + \")\"; }); }); $(\"#btn2\").click(function(){ $(\"#test2\").html(function(i,origText){ return \"旧 html: \" + origText + \" 新 html: Hello world! (index: \" + i + \")\"; }); }); 设置属性 - attr()：用于设置/改变属性值。 $(\"button\").click(function(){ $(\"#runoob\").attr(\"href\",\"http://www.runoob.com/jquery\"); }); attr() 方法也允许您同时设置多个属性。 下面的例子演示如何同时设置 href 和 title 属性： $(\"button\").click(function(){ $(\"#runoob\").attr({ \"href\" : \"http://www.runoob.com/jquery\", \"title\" : \"jQuery 教程\" }); }); attr() 的回调函数 jQuery 方法 attr()，也提供回调函数。回调函数有两个参数：被选元素列表中当前元素的下标，以及原始（旧的）值。然后以函数新值返回您希望使用的字符串。 下面的例子演示带有回调函数的 attr() 方法： $(\"button\").click(function(){ $(\"#runoob\").attr(\"href\", function(i,origValue){ return origValue + \"/jquery\"; }); }); 添加元素 添加新内容的四个 jQuery 方法： append() - 在被选元素的结尾插入内容 prepend() - 在被选元素的开头插入内容 after() - 在被选元素之后插入内容 before() - 在被选元素之前插入内容 append() 方法 jQuery append() 方法在被选元素的结尾插入内容（仍然该元素的内部）。 $(\"p\").append(\"追加文本\"); prepend() 方法 jQuery prepend() 方法在被选元素的开头插入内容。 $(\"p\").prepend(\"在开头追加文本\"); 通过 append() 和 prepend() 方法添加若干新元素 在上面的例子中，我们只在被选元素的开头/结尾插入文本/HTML。 不过，append() 和 prepend() 方法能够通过参数接收无限数量的新元素。可以通过 jQuery 来生成文本/HTML（就像上面的例子那样），或者通过 JavaScript 代码和 DOM 元素。 在下面的例子中，我们创建若干个新元素。这些元素可以通过 text/HTML、jQuery 或者 JavaScript/DOM 来创建。然后我们通过 append() 方法把这些新元素追加到文本中（对 prepend() 同样有效）： function appendText() { var txt1=\"文本。\"; // 使用 HTML 标签创建文本 var txt2=$(\"\").text(\"文本。\"); // 使用 jQuery 创建文本 var txt3=document.createElement(\"p\"); txt3.innerHTML=\"文本。\"; // 使用 DOM 创建文本 text with DOM $(\"body\").append(txt1,txt2,txt3); // 追加新元素 } jQuery after() 和 before() 方法 $(\"img\").after(\"在后面添加文本\"); $(\"img\").before(\"在前面添加文本\"); 通过 after() 和 before() 方法添加若干新元素 after() 和 before() 方法能够通过参数接收无限数量的新元素。可以通过 text/HTML、jQuery 或者 JavaScript/DOM 来创建新元素。 在下面的例子中，我们创建若干新元素。这些元素可以通过 text/HTML、jQuery 或者 JavaScript/DOM 来创建。然后我们通过 after() 方法把这些新元素插到文本中（对 before() 同样有效）： function afterText() { var txt1=\"I \"; // 使用 HTML 创建元素 var txt2=$(\"\").text(\"love \"); // 使用 jQuery 创建元素 var txt3=document.createElement(\"big\"); // 使用 DOM 创建元素 txt3.innerHTML=\"jQuery!\"; $(\"img\").after(txt1,txt2,txt3); // 在图片后添加文本 } append/prepend和after/before有什么区别？ append s1 $(\"p\").append('s2'); 结果是这样的: s1 s2 after s1 $(\"p\").after('s2'); 结果是这样的: s1 s2 总结： append/prepend 是在选择元素内部嵌入。 after/before 是在元素外面追加。 删除元素 使用以下两个 jQuery 方法： remove() - 删除被选元素（及其子元素） empty() - 从被选元素中删除子元素 jQuery remove() 方法：删除被选元素及其子元素。 $(\"#div1\").remove(); jQuery empty() 方法：删除被选元素的子元素。 $(\"#div1\").empty(); 过滤被删除的元素 jQuery remove() 方法也可接受一个参数，允许您对被删元素进行过滤。 该参数可以是任何 jQuery 选择器的语法。 下面的例子删除 class=\"italic\" 的所有 元素： $(\"p\").remove(\".italic\"); CSS CSS类和方法 jQuery 拥有若干进行 CSS 操作的方法。我们将学习下面这些： addClass() - 向被选元素添加一个或多个类 removeClass() - 从被选元素删除一个或多个类 toggleClass() - 对被选元素进行添加/删除类的切换操作 css() - 设置或返回样式属性 实例样式表 .important { font-weight:bold; font-size:xx-large; } .blue { color:blue; } addClass() 方法 $(\"button\").click(function(){ $(\"h1,h2,p\").addClass(\"blue\"); $(\"div\").addClass(\"important\"); }); // 或规定多个类： $(\"button\").click(function(){ $(\"body div:first\").addClass(\"important blue\"); }); removeClass() 方法 $(\"button\").click(function(){ $(\"h1,h2,p\").removeClass(\"blue\"); }); toggleClass() 方法 该方法对被选元素进行添加/删除类的切换操作： $(\"button\").click(function(){ $(\"h1,h2,p\").toggleClass(\"blue\"); }); css() 方法 设置或返回被选元素的一个或多个样式属性。 返回 CSS 属性 如需返回指定的 CSS 属性的值，请使用如下语法： css(\"propertyname\"); // 例 $(\"p\").css(\"background-color\"); 设置 CSS 属性 如需设置指定的 CSS 属性，请使用如下语法： css(\"propertyname\",\"value\"); // 例 $(\"p\").css(\"background-color\",\"yellow\"); 设置多个 CSS 属性 如需设置多个 CSS 属性，请使用如下语法： css({\"propertyname\":\"value\",\"propertyname\":\"value\",...}); // 例 $(\"p\").css({\"background-color\":\"yellow\",\"font-size\":\"200%\"}); CSS盒子模型(尺寸) jQuery 提供多个处理尺寸的重要方法： width() height() innerWidth() innerHeight() outerWidth() outerHeight() jQuery尺寸 width() 和 height() 方法 width() 方法设置或返回元素的宽度（不包括内边距、边框或外边距）。 height() 方法设置或返回元素的高度（不包括内边距、边框或外边距）。 $(\"button\").click(function(){ var txt=\"\"; txt+=\"div 的宽度是: \" + $(\"#div1\").width() + \"\"; txt+=\"div 的高度是: \" + $(\"#div1\").height(); $(\"#div1\").html(txt); }); innerWidth() 和 innerHeight() 方法 innerWidth() 方法返回元素的宽度（包括内边距）。 innerHeight() 方法返回元素的高度（包括内边距）。 $(\"button\").click(function(){ var txt=\"\"; txt+=\"div 宽度，包含内边距: \" + $(\"#div1\").innerWidth() + \"\"; txt+=\"div 高度，包含内边距: \" + $(\"#div1\").innerHeight(); $(\"#div1\").html(txt); }); outerWidth() 和 outerHeight() 方法 outerWidth() 方法返回元素的宽度（包括内边距和边框）。 outerHeight() 方法返回元素的高度（包括内边距和边框）。 $(\"button\").click(function(){ var txt=\"\"; txt+=\"div 宽度，包含内边距和边框: \" + $(\"#div1\").outerWidth() + \"\"; txt+=\"div 高度，包含内边距和边框: \" + $(\"#div1\").outerHeight(); $(\"#div1\").html(txt); }); 效果 隐藏和显示 hide() 和 show() 使用 hide() 和 show() 方法来隐藏和显示 HTML 元素： $(\"#hide\").click(function(){ $(\"p\").hide(); }); $(\"#show\").click(function(){ $(\"p\").show(); }); 语法: $(selector).hide(speed,callback); $(selector).show(speed,callback); 可选的 speed 参数规定隐藏/显示的速度，可以取以下值：\"slow\"、\"fast\" 或毫秒。 可选的 callback 参数是隐藏或显示完成后所执行的函数名称。 对于可选的 callback 参数，有以下两点说明： 1.$(selector)选中的元素的个数为n个，则callback函数会执行n次；当 callback 函数加上括号时，函数立即执行，只会调用一次， 如果不加括号，元素显示或隐藏后调用函数，才会调用多次。 2.callback函数名后加括号，会立刻执行函数体，而不是等到显示/隐藏完成后才执行； 3.callback既可以是函数名，也可以是匿名函数； 下面的例子演示了带有 speed 参数的 hide() 方法： $(\"button\").click(function(){ $(\"p\").hide(1000); }); 下面的例子演示了带有 speed 参数的 hide() 方法，并使用回调函数： $(document).ready(function(){ $(\".hidebtn\").click(function(){ $(\"div\").hide(1000,\"linear\",function(){ alert(\"Hide() 方法已完成!\"); }); }); }); 第二个参数是一个字符串，表示过渡使用哪种缓动函数。（译者注：jQuery自身提供\"linear\" 和 \"swing\"，其他可以使用相关的插件）。 toggle() 使用 toggle() 方法来切换 hide() 和 show() 方法。显示被隐藏的元素，并隐藏已显示的元素： $(\"button\").click(function(){ $(\"p\").toggle(); }); 语法: $(selector).toggle(speed,callback); 可选的 speed 参数规定隐藏/显示的速度，可以取以下值：\"slow\"、\"fast\" 或毫秒。 可选的 callback 参数是隐藏或显示完成后所执行的函数名称。 淡入淡出 jQuery 拥有下面四种 fade 方法： fadeIn() fadeOut() fadeToggle() fadeTo() fadeIn() 方法：用于淡入已隐藏的元素。 语法: $(selector).fadeIn(speed,callback); 可选的 speed 参数规定效果的时长。它可以取以下值：\"slow\"、\"fast\" 或毫秒。. 可选的 callback 参数是 fading 完成后所执行的函数名称。 下面的例子演示了带有不同参数的 fadeIn() 方法： $(\"button\").click(function(){ $(\"#div1\").fadeIn(); $(\"#div2\").fadeIn(\"slow\"); $(\"#div3\").fadeIn(3000); }); fadeOut() 方法：用于淡出可见元素。 语法: $(selector).fadeOut(speed,callback); 可选的 speed 参数规定效果的时长。它可以取以下值：\"slow\"、\"fast\" 或毫秒。 可选的 callback 参数是 fading 完成后所执行的函数名称。 下面的例子演示了带有不同参数的 fadeOut() 方法： $(\"button\").click(function(){ $(\"#div1\").fadeOut(); $(\"#div2\").fadeOut(\"slow\"); $(\"#div3\").fadeOut(3000); }); fadeToggle() 方法： jQuery fadeToggle() 方法可以在 fadeIn() 与 fadeOut() 方法之间进行切换。 如果元素已淡出，则 fadeToggle() 会向元素添加淡入效果。 如果元素已淡入，则 fadeToggle() 会向元素添加淡出效果。 语法: $(selector).fadeToggle(speed,callback); 可选的 speed 参数规定效果的时长。它可以取以下值：\"slow\"、\"fast\" 或毫秒。 可选的 callback 参数是 fading 完成后所执行的函数名称。 下面的例子演示了带有不同参数的 fadeToggle() 方法： $(\"button\").click(function(){ $(\"#div1\").fadeToggle(); $(\"#div2\").fadeToggle(\"slow\"); $(\"#div3\").fadeToggle(3000); }); fadeTo() 方法 jQuery fadeTo() 方法允许渐变为给定的不透明度（值介于 0 与 1 之间）。 语法: 必需的 speed 参数规定效果的时长。它可以取以下值：\"slow\"、\"fast\" 或毫秒。 fadeTo() 方法中必需的 opacity 参数将淡入淡出效果设置为给定的不透明度（值介于 0 与 1 之间）。 可选的 callback 参数是该函数完成后所执行的函数名称。 下面的例子演示了带有不同参数的 fadeTo() 方法： $(\"button\").click(function(){ $(\"#div1\").fadeTo(\"slow\",0.15); $(\"#div2\").fadeTo(\"slow\",0.4); $(\"#div3\").fadeTo(\"slow\",0.7); }); 滑动 jQuery 拥有以下滑动方法： slideDown() slideUp() slideToggle() slideDown() 方法 jQuery slideDown() 方法用于向下滑动元素。 语法: $(selector).slideDown(speed,callback); 可选的 speed 参数规定效果的时长。它可以取以下值：\"slow\"、\"fast\" 或毫秒。 可选的 callback 参数是滑动完成后所执行的函数名称。 下面的例子演示了 slideDown() 方法： $(\"#flip\").click(function(){ $(\"#panel\").slideDown(); }); slideUp() 方法 jQuery slideUp() 方法用于向上滑动元素。 语法: $(selector).slideUp(speed,callback); 可选的 speed 参数规定效果的时长。它可以取以下值：\"slow\"、\"fast\" 或毫秒。 可选的 callback 参数是滑动完成后所执行的函数名称。 下面的例子演示了 slideUp() 方法： $(\"#flip\").click(function(){ $(\"#panel\").slideUp(); }); slideToggle() 方法 jQuery slideToggle() 方法可以在 slideDown() 与 slideUp() 方法之间进行切换。 如果元素向下滑动，则 slideToggle() 可向上滑动它们。 如果元素向上滑动，则 slideToggle() 可向下滑动它们。 $(selector).slideToggle(speed,callback); 可选的 speed 参数规定效果的时长。它可以取以下值：\"slow\"、\"fast\" 或毫秒。 可选的 callback 参数是滑动完成后所执行的函数名称。 下面的例子演示了 slideToggle() 方法： $(\"#flip\").click(function(){ $(\"#panel\").slideToggle(); }); 动画 animate() 方法 用于创建自定义动画。 语法： $(selector).animate({params},speed,callback); 必需的 params 参数定义形成动画的 CSS 属性。 可选的 speed 参数规定效果的时长。它可以取以下值：\"slow\"、\"fast\" 或毫秒。 可选的 callback 参数是动画完成后所执行的函数名称。 下面的例子演示 animate() 方法的简单应用。它把 元素往右边移动了 250 像素： $(\"button\").click(function(){ $(\"div\").animate({left:'250px'}); }); 默认情况下，所有 HTML 元素都有一个静态位置，且无法移动。 如需对位置进行操作，要记得首先把元素的 CSS position 属性设置为 relative、fixed 或 absolute！ 操作多个属性 生成动画的过程中可同时使用多个属性： 实例 $(\"button\").click(function(){ $(\"div\").animate({ left:'250px', opacity:'0.5', height:'150px', width:'150px' }); }); 使用相对值 也可以定义相对值（该值相对于元素的当前值）。需要在值的前面加上 += 或 -=： $(\"button\").click(function(){ $(\"div\").animate({ left:'250px', height:'+=150px', width:'+=150px' }); }); 使用预定义的值 甚至可以把属性的动画值设置为 \"show\"、\"hide\" 或 \"toggle\"： $(\"button\").click(function(){ $(\"div\").animate({ height:'toggle' }); }); 使用队列功能 默认地，jQuery 提供针对动画的队列功能。 这意味着如果您在彼此之后编写多个 animate() 调用，jQuery 会创建包含这些方法调用的\"内部\"队列。然后逐一运行这些 animate 调用。 $(\"button\").click(function(){ var div=$(\"div\"); div.animate({height:'300px',opacity:'0.4'},\"slow\"); div.animate({width:'300px',opacity:'0.8'},\"slow\"); div.animate({height:'100px',opacity:'0.4'},\"slow\"); div.animate({width:'100px',opacity:'0.8'},\"slow\"); }); // 下面的例子把 元素往右边移动了 100 像素，然后增加文本的字号： $(\"button\").click(function(){ var div=$(\"div\"); div.animate({left:'100px'},\"slow\"); div.animate({fontSize:'3em'},\"slow\"); }); 可以用 animate() 方法来操作所有 CSS 属性吗？ 是的，几乎可以！不过，需要记住一件重要的事情：当使用 animate() 时，必须使用 Camel 标记法书写所有的属性名，比如，必须使用 paddingLeft 而不是 padding-left，使用 marginRight 而不是 margin-right，等等。 同时，色彩动画并不包含在核心 jQuery 库中。 如果需要生成颜色动画，您需要从 jquery.com 下载 颜色动画 插件。 停止动画 stop() 方法 用于停止动画或效果，在它们完成之前。 stop() 方法适用于所有 jQuery 效果函数，包括滑动、淡入淡出和自定义动画。 语法: $(selector).stop(stopAll,goToEnd); 可选的 stopAll 参数规定是否应该清除动画队列。默认是 false，即仅停止活动的动画，允许任何排入队列的动画向后执行。 可选的 goToEnd 参数规定是否立即完成当前动画。默认是 false。 因此，默认地，stop() 会清除在被选元素上指定的当前动画。 下面的例子演示 stop() 方法，不带参数： $(\"#stop\").click(function(){ $(\"#panel\").stop(); }); 动画队列停止动画测试，只停止当前正在进行的动画，停止当前动画后，队列中的下一个动画开始进行： $(document).ready(function(){ $(\"#flip\").click(function(){ $(\"#panel\").slideDown(5000); $(\"#panel\").slideUp(5000); }); $(\"#stop\").click(function(){ $(\"#panel\").stop(); }); }); 可以在 stop() 中设置 stopAll 的参数为 true，这样就可以停止所有动画效果而不是只停止当前动画： $(document).ready(function(){ $(\"#flip\").click(function(){ $(\"#panel\").slideDown(5000); $(\"#panel\").slideUp(5000); }); $(\"#stop\").click(function(){ $(\"#panel\").stop(true); }); }); Callback(回调) 方法 Callback 函数在当前动画 100% 完成之后执行。 jQuery 动画的问题 许多 jQuery 函数涉及动画。这些函数也许会将 speed 或 duration 作为可选参数。 例子：$(\"p\").hide(\"slow\") speed 或 duration 参数可以设置许多不同的值，比如 \"slow\", \"fast\", \"normal\" 或毫秒。 实例 以下实例在隐藏效果完全实现后回调函数: $(\"button\").click(function(){ $(\"p\").hide(\"slow\",function(){ alert(\"段落现在被隐藏了\"); }); }); 以下实例没有回调函数，警告框会在隐藏效果完成前弹出： $(\"button\").click(function(){ $(\"p\").hide(1000); alert(\"段落现在被隐藏了\"); }); 被立即停止的动画不会触发回调，被立即完成的动画会触发回调。 $(document).ready(function(){ $(\"button\").click(function(){ $(\"p\").hide(3000,function(){ alert(\"段落现在被隐藏了\"); }); }); $(\"#happy\").click(function(){ $(\"p\").stop(false,true); }); }); 如果动画有队列的话，想实现其快速完成所有动画并停止，就要相应的与队列数对应条数的停止语句。 $(document).ready(function(){ $(\"#start\").click(function(){ $(\"div\").animate({left:'300px'},5000); $(\"div\").animate({fontSize:'3em'},5000); }); $(\"#stop1\").click(function(){ $(\"div\").stop(); }); $(\"#stop2\").click(function(){ $(\"div\").stop(true); }); $(\"#stop3\").click(function(){ $(\"div\").stop(false,true); $(\"div\").stop(false,true); }); }); 链(Chaining) 通过 jQuery，可以把动作/方法链接在一起。 Chaining 允许我们在一条语句中运行多个 jQuery 方法（在相同的元素上）。 直到现在，我们都是一次写一条 jQuery 语句（一条接着另一条）。 不过，有一种名为链接（chaining）的技术，允许我们在相同的元素上运行多条 jQuery 命令，一条接着另一条。 提示： 这样的话，浏览器就不必多次查找相同的元素。 如需链接一个动作，您只需简单地把该动作追加到之前的动作上。 下面的例子把 css()、slideUp() 和 slideDown() 链接在一起。\"p1\" 元素首先会变为红色，然后向上滑动，再然后向下滑动： $(\"#p1\").css(\"color\",\"red\").slideUp(2000).slideDown(2000); 如果需要，我们也可以添加多个方法调用。 提示：当进行链接时，代码行会变得很长。不过，jQuery 语法不是很严格；您可以按照希望的格式来写，包含换行和缩进。 如下书写也可以很好地运行： $(\"#p1\").css(\"color\",\"red\") .slideUp(2000) .slideDown(2000); jQuery - AJAX 简介 AJAX 是与服务器交换数据的技术，它在不重载全部页面的情况下，实现了对部分网页的更新。 什么是 AJAX？ AJAX = 异步 JavaScript 和 XML（Asynchronous JavaScript and XML）。 简短地说，在不重载整个网页的情况下，AJAX 通过后台加载数据，并在网页上进行显示。 使用 AJAX 的应用程序案例：谷歌地图、腾讯微博、优酷视频、人人网等等。 您可以在 jQuery Ajax 参考手册学会 jQuery Ajax 的具体应用。 您可以在菜鸟教程中的 AJAX 教程中学到更多有关 AJAX 的知识。 关于 jQuery 与 AJAX jQuery 提供多个与 AJAX 有关的方法。 通过 jQuery AJAX 方法，您能够使用 HTTP Get 和 HTTP Post 从远程服务器上请求文本、HTML、XML 或 JSON - 同时您能够把这些外部数据直接载入网页的被选元素中。 如果没有 jQuery，AJAX 编程还是有些难度的。 编写常规的 AJAX 代码并不容易，因为不同的浏览器对 AJAX 的实现并不相同。这意味着您必须编写额外的代码对浏览器进行测试。不过，jQuery 团队为我们解决了这个难题，我们只需要一行简单的代码，就可以实现 AJAX 功能。 AJAX load() 方法 jQuery load() 方法 jQuery load() 方法是简单但强大的 AJAX 方法。 load() 方法从服务器加载数据，并把返回的数据放入被选元素中。 语法: $(selector).load(URL,data,callback); 必需的 URL 参数规定您希望加载的 URL。 可选的 data 参数规定与请求一同发送的查询字符串键/值对集合。 可选的 callback 参数是 load() 方法完成后所执行的函数名称。 这是示例文件（\"demo_test.txt\"）的内容： jQuery AJAX 是个非常棒的功能！ 这是段落的一些文本。 下面的例子会把文件 \"demo_test.txt\" 的内容加载到指定的 元素中： $(\"#div1\").load(\"demo_test.txt\"); 也可以把 jQuery 选择器添加到 URL 参数。 下面的例子把 \"demo_test.txt\" 文件中 id=\"p1\" 的元素的内容，加载到指定的 元素中： 实例 $(\"#div1\").load(\"demo_test.txt #p1\"); 可选的 callback 参数规定当 load() 方法完成后所要允许的回调函数。回调函数可以设置不同的参数： responseTxt - 包含调用成功时的结果内容 statusTXT - 包含调用的状态 xhr - 包含 XMLHttpRequest 对象 下面的例子会在 load() 方法完成后显示一个提示框。如果 load() 方法已成功，则显示\"外部内容加载成功！\"，而如果失败，则显示错误消息： $(\"button\").click(function(){ $(\"#div1\").load(\"demo_test.txt\",function(responseTxt,statusTxt,xhr){ if(statusTxt==\"success\") alert(\"外部内容加载成功!\"); if(statusTxt==\"error\") alert(\"Error: \"+xhr.status+\": \"+xhr.statusText); }); }); 为了避免多页面情形下的代码重复，可以利用 load() 方法，将重复的部分（例如导航栏）放入单独的文件，使用下列方法进行导入： //1.当前文件中要插入的地方使用此结构： //2.***.html中放入内容，用html格式仅仅因为会有编辑器的书写辅助。。 //3.代码： $(\".include\").each(function() { if (!!$(this).attr(\"file\")) { var $includeObj = $(this); $(this).load($(this).attr(\"file\"), function(html) { $includeObj.after(html).remove(); //加载的文件内容写入到当前标签后面并移除当前标签 }) } }); 或者在index文件里只写重复部分，剩下的一股脑放各自单独文件 load() 进来~ AJAX get() 和 post() 方法 jQuery get() 和 post() 方法用于通过 HTTP GET 或 POST 请求从服务器请求数据。 HTTP 请求：GET vs. POST 两种在客户端和服务器端进行请求-响应的常用方法是：GET 和 POST。 GET - 从指定的资源请求数据 POST - 向指定的资源提交要处理的数据 GET 基本上用于从服务器获得（取回）数据。注释：GET 方法可能返回缓存数据。 POST 也可用于从服务器获取数据。不过，POST 方法不会缓存数据，并且常用于连同请求一起发送数据。 $.get() 方法 通过 HTTP GET 请求从服务器上请求数据。 语法： $.get(URL,callback); 必需的 URL 参数规定您希望请求的 URL。 可选的 callback 参数是请求成功后所执行的函数名。 下面的例子使用 $.get() 方法从服务器上的一个文件中取回数据： $(\"button\").click(function(){ $.get(\"demo_test.php\",function(data,status){ alert(\"数据: \" + data + \"\\n状态: \" + status); }); }); $.get() 的第一个参数是我们希望请求的 URL（\"demo_test.php\"）。 第二个参数是回调函数。第一个回调参数存有被请求页面的内容，第二个回调参数存有请求的状态。 $.post() 方法 通过 HTTP POST 请求向服务器提交数据。 语法: $.post(URL,data,callback); 必需的 URL 参数规定您希望请求的 URL。 可选的 data 参数规定连同请求发送的数据。 可选的 callback 参数是请求成功后所执行的函数名。 下面的例子使用 $.post() 连同请求一起发送数据： $(\"button\").click(function(){ $.post(\"/try/ajax/demo_test_post.php\", { name:\"菜鸟教程\", url:\"http://www.runoob.com\" }, function(data,status){ alert(\"数据: \\n\" + data + \"\\n状态: \" + status); }); }); $.post() 的第一个参数是我们希望请求的 URL (\"demo_test_post.php\")。 然后我们连同请求（name 和 url）一起发送数据。 \"demo_test_post.php\" 中的 PHP 脚本读取这些参数，对它们进行处理，然后返回结果。 第三个参数是回调函数。第一个回调参数存有被请求页面的内容，而第二个参数存有请求的状态。 遍历 祖先 这些 jQuery 方法很有用，它们用于向上遍历 DOM 树： parent() parents() parentsUntil() parent() 方法 parent() 方法返回被选元素的直接父元素。 该方法只会向上一级对 DOM 树进行遍历。 下面的例子返回每个 元素的的直接父元素： $(document).ready(function(){ $(\"span\").parent(); }); parents() 方法 parents() 方法返回被选元素的所有祖先元素，它一路向上直到文档的根元素 ()。 下面的例子返回所有 元素的所有祖先： $(document).ready(function(){ $(\"span\").parents(); }); 您也可以使用可选参数来过滤对祖先元素的搜索。 下面的例子返回所有 元素的所有祖先，并且它是 元素： $(document).ready(function(){ $(\"span\").parents(\"ul\"); }); parentsUntil() 方法 parentsUntil() 方法返回介于两个给定元素之间的所有祖先元素。 下面的例子返回介于 与 ` 元素之间的所有祖先元素： $(document).ready(function(){ $(\"span\").parentsUntil(\"div\"); }); 后代 下面是两个用于向下遍历 DOM 树的 jQuery 方法： children() find() children() 方法 children() 方法返回被选元素的所有直接子元素。 该方法只会向下一级对 DOM 树进行遍历。 下面的例子返回每个 元素的所有直接子元素： $(document).ready(function(){ $(\"div\").children(); }); 您也可以使用可选参数来过滤对子元素的搜索。 下面的例子返回类名为 \"1\" 的所有 元素，并且它们是 的直接子元素： $(document).ready(function(){ $(\"div\").children(\"p.1\"); }); find() 方法 find() 方法返回被选元素的后代元素，一路向下直到最后一个后代。 下面的例子返回属于 后代的所有 元素： $(document).ready(function(){ $(\"div\").find(\"span\"); }); 下面的例子返回 的所有后代： $(document).ready(function(){ $(\"div\").find(\"*\"); }); 同胞(siblings) 有许多有用的方法让我们在 DOM 树进行水平遍历： siblings() next() nextAll() nextUntil() prev() prevAll() prevUntil() siblings() 方法 siblings() 方法返回被选元素的所有同胞元素。 下面的例子返回 h2> 的所有同胞元素： $(document).ready(function(){ $(\"h2\").siblings(); }); 您也可以使用可选参数来过滤对同胞元素的搜索。 下面的例子返回属于 的同胞元素的所有 元素： $(document).ready(function(){ $(\"h2\").siblings(\"p\"); }); next() 方法 next() 方法返回被选元素的下一个同胞元素。 该方法只返回一个元素。 下面的例子返回 的下一个同胞元素： $(document).ready(function(){ $(\"h2\").next(); }); nextAll() 方法 nextAll() 方法返回被选元素的所有跟随的同胞元素。 下面的例子返回 的所有跟随的同胞元素： $(document).ready(function(){ $(\"h2\").nextAll(); }); nextUntil() 方法 nextUntil() 方法返回介于两个给定参数之间的所有跟随的同胞元素。 下面的例子返回介于 与 元素之间的所有同胞元素： $(document).ready(function(){ $(\"h2\").nextUntil(\"h6\"); }); prev(), prevAll() & prevUntil() 方法 prev(), prevAll() 以及 prevUntil() 方法的工作方式与上面的方法类似，只不过方向相反而已：它们返回的是前面的同胞元素（在 DOM 树中沿着同胞之前元素遍历，而不是之后元素遍历）。 过滤 缩小搜索元素的范围 三个最基本的过滤方法是：first(), last() 和 eq()，它们允许您基于其在一组元素中的位置来选择一个特定的元素。 其他过滤方法，比如 filter() 和 not() 允许您选取匹配或不匹配某项指定标准的元素。 first() 方法 first() 方法返回被选元素的首个元素。 下面的例子选取首个 元素内部的第一个 元素： $(document).ready(function(){ $(\"div p\").first(); }); last() 方法 last() 方法返回被选元素的最后一个元素。 下面的例子选择最后一个 元素中的最后一个 元素： $(document).ready(function(){ $(\"div p\").last(); }); eq() 方法 eq() 方法返回被选元素中带有指定索引号的元素。 索引号从 0 开始，因此首个元素的索引号是 0 而不是 1。下面的例子选取第二个 元素（索引号 1）： $(document).ready(function(){ $(\"p\").eq(1); }); filter() 方法 filter() 方法允许您规定一个标准。不匹配这个标准的元素会被从集合中删除，匹配的元素会被返回。 下面的例子返回带有类名 \"url\" 的所有 元素： $(document).ready(function(){ $(\"p\").filter(\".url\"); }); not() 方法 not() 方法返回不匹配标准的所有元素。 提示：not() 方法与 filter() 相反。 下面的例子返回不带有类名 \"url\" 的所有 元素： $(document).ready(function(){ $(\"p\").not(\".url\"); }); "},"Web/JavaScript/框架/jQuery方法大全.html":{"url":"Web/JavaScript/框架/jQuery方法大全.html","title":"JQuery方法大全","keywords":"","body":"datetime:2019/7/10 15:29 author:nzb 选择器 选择器 实例 选取 * $(\"*\") 所有元素 #id $(\"#lastname\") id=\"lastname\" 的元素 .class $(\".intro\") class=\"intro\" 的所有元素 .class,.class $(\".intro,.demo\") class 为 \"intro\" 或 \"demo\" 的所有元素 element $(\"p\") 所有 元素 el1,el2,el3 $(\"h1,div,p\") 所有 、 和 元素 :first $(\"p:first\") 第一个 元素 :last $(\"p:last\") 最后一个 元素 :even $(\"tr:even\") 所有偶数 元素，索引值从 0 开始，第一个元素是偶数 (0)，第二个元素是奇数 (1)，以此类推。 :odd $(\"tr:odd\") 所有奇数 元素，索引值从 0 开始，第一个元素是偶数 (0)，第二个元素是奇数 (1)，以此类推。 :first-child $(\"p:first-child\") 属于其父元素的第一个子元素的所有 元素 :first-of-type $(\"p:first-of-type\") 属于其父元素的第一个 元素的所有 元素 :last-child $(\"p:last-child\") 属于其父元素的最后一个子元素的所有 元素 :last-of-type $(\"p:last-of-type\") 属于其父元素的最后一个 元素的所有 元素 :nth-child(n) $(\"p:nth-child(2)\") 属于其父元素的第二个子元素的所有 元素 :nth-last-child(n) $(\"p:nth-last-child(2)\") 属于其父元素的第二个子元素的所有 元素，从最后一个子元素开始计数 :nth-of-type(n) $(\"p:nth-of-type(2)\") 属于其父元素的第二个 元素的所有 元素 :nth-last-of-type(n) $(\"p:nth-last-of-type(2)\") 属于其父元素的第二个 元素的所有 元素，从最后一个子元素开始计数 :only-child $(\"p:only-child\") 属于其父元素的唯一子元素的所有 元素 :only-of-type $(\"p:only-of-type\") 属于其父元素的特定类型的唯一子元素的所有 元素 parent > child $(\"div > p\") 元素的直接子元素的所有 元素 parent descendant $(\"div p\") 元素的后代的所有 元素 element + next $(\"div + p\") 每个 元素相邻的下一个 元素 element ~ siblings $(\"div ~ p\") 元素同级的所有 元素 :eq(index) $(\"ul li:eq(3)\") 列表中的第四个元素（index 值从 0 开始） :gt(no) $(\"ul li:gt(3)\") 列举 index 大于 3 的元素 :lt(no) $(\"ul li:lt(3)\") 列举 index 小于 3 的元素 :not(selector) $(\"input:not(:empty)\") 所有不为空的输入元素 :header $(\":header\") 所有标题元素 , ... :animated $(\":animated\") 所有动画元素 :focus $(\":focus\") 当前具有焦点的元素 :contains(text) $(\":contains('Hello')\") 所有包含文本 \"Hello\" 的元素 :has(selector) $(\"div:has(p)\") 所有包含有 元素在其内的 元素 :empty $(\":empty\") 所有空元素 :parent $(\":parent\") 匹配所有含有子元素或者文本的父元素。 :hidden $(\"p:hidden\") 所有隐藏的 元素 :visible $(\"table:visible\") 所有可见的表格 :root $(\":root\") 文档的根元素 :lang(language) $(\"p:lang(de)\") 所有 lang 属性值为 \"de\" 的 元素 [attribute] $(\"[href]\") 所有带有 href 属性的元素 [attribute=value] $(\"[href='default.htm']\") 所有带有 href 属性且值等于 \"default.htm\" 的元素 [attribute!=value] $(\"[href!='default.htm']\") 所有带有 href 属性且值不等于 \"default.htm\" 的元素 [attribute$=value] $(\"[href$='.jpg']\") 所有带有 href 属性且值以 \".jpg\" 结尾的元素 [attribute|=value] $(\"[title|='Tomorrow']\") 所有带有 title 属性且值等于 'Tomorrow' 或者以 'Tomorrow' 后跟连接符作为开头的字符串 [attribute^=value] $(\"[title^='Tom']\") 所有带有 title 属性且值以 \"Tom\" 开头的元素 [attribute~=value] $(\"[title~='hello']\") 所有带有 title 属性且值包含单词 \"hello\" 的元素 [attribute*=value] $(\"[title*='hello']\") 所有带有 title 属性且值包含字符串 \"hello\" 的元素 [name=value]、[name2=value2] $(\"input[id][name$='man']\") 带有 id 属性，并且 name 属性以 man 结尾的输入框 :input $(\":input\") 所有 input 元素 :text $(\":text\") 所有带有 type=\"text\" 的 input 元素 :password $(\":password\") 所有带有 type=\"password\" 的 input 元素 :radio $(\":radio\") 所有带有 type=\"radio\" 的 input 元素 :checkbox $(\":checkbox\") 所有带有 type=\"checkbox\" 的 input 元素 :submit $(\":submit\") 所有带有 type=\"submit\" 的 input 元素 :reset $(\":reset\") 所有带有 type=\"reset\" 的 input 元素 :button $(\":button\") 所有带有 type=\"button\" 的 input 元素 :image $(\":image\") 所有带有 type=\"image\" 的 input 元素 :file $(\":file\") 所有带有 type=\"file\" 的 input 元素 :enabled $(\":enabled\") 所有启用的元素 :disabled $(\":disabled\") 所有禁用的元素 :selected $(\":selected\") 所有选定的下拉列表元素 :checked $(\":checked\") 所有选中的复选框选项 .selector $(selector).selector 在jQuery 1.7中已经不被赞成使用。返回传给jQuery()的原始选择器 :target $( \"p:target\" ) 选择器将选中ID和URI中一个格式化的标识符相匹配的元素 jQuery 事件方法 方法 描述 bind() 向元素添加事件处理程序 blur() 添加/触发失去焦点事件 change() 添加/触发 change 事件 click() 添加/触发 click 事件 dblclick() 添加/触发 double click 事件 delegate() 向匹配元素的当前或未来的子元素添加处理程序 die() 在版本 1.9 中被移除。移除所有通过 live() 方法添加的事件处理程序 error() 在版本 1.8 中被废弃。添加/触发 error 事件 event.currentTarget 在事件冒泡阶段内的当前 DOM 元素 event.data 包含当前执行的处理程序被绑定时传递到事件方法的可选数据 event.delegateTarget 返回当前调用的 jQuery 事件处理程序所添加的元素 event.isDefaultPrevented() 返回指定的 event 对象上是否调用了 event.preventDefault() event.isImmediatePropagationStopped() 返回指定的 event 对象上是否调用了 event.stopImmediatePropagation() event.isPropagationStopped() 返回指定的 event 对象上是否调用了 event.stopPropagation() event.namespace 返回当事件被触发时指定的命名空间 event.pageX 返回相对于文档左边缘的鼠标位置 event.pageY 返回相对于文档上边缘的鼠标位置 event.preventDefault() 阻止事件的默认行为 event.relatedTarget 返回当鼠标移动时哪个元素进入或退出 event.result 包含由被指定事件触发的事件处理程序返回的最后一个值 event.stopImmediatePropagation() 阻止其他事件处理程序被调用 event.stopPropagation() 阻止事件向上冒泡到 DOM 树，阻止任何父处理程序被事件通知 event.target 返回哪个 DOM 元素触发事件 event.timeStamp 返回从 1970 年 1 月 1 日到事件被触发时的毫秒数 event.type 返回哪种事件类型被触发 event.which 返回指定事件上哪个键盘键或鼠标按钮被按下 event.metaKey 事件触发时 META 键是否被按下 focus() 添加/触发 focus 事件 focusin() 添加事件处理程序到 focusin 事件 focusout() 添加事件处理程序到 focusout 事件 hover() 添加两个事件处理程序到 hover 事件 keydown() 添加/触发 keydown 事件 keypress() 添加/触发 keypress 事件 keyup() 添加/触发 keyup 事件 live() 在版本 1.9 中被移除。添加一个或多个事件处理程序到当前或未来的被选元素 load() 在版本 1.8 中被废弃。添加一个事件处理程序到 load 事件 mousedown() 添加/触发 mousedown 事件 mouseenter() 添加/触发 mouseenter 事件 mouseleave() 添加/触发 mouseleave 事件 mousemove() 添加/触发 mousemove 事件 mouseout() 添加/触发 mouseout 事件 mouseover() 添加/触发 mouseover 事件 mouseup() 添加/触发 mouseup 事件 off() 移除通过 on() 方法添加的事件处理程序 on() 向元素添加事件处理程序 one() 向被选元素添加一个或多个事件处理程序。该处理程序只能被每个元素触发一次 $.proxy() 接受一个已有的函数，并返回一个带特定上下文的新的函数 ready() 规定当 DOM 完全加载时要执行的函数 resize() 添加/触发 resize 事件 scroll() 添加/触发 scroll 事件 select() 添加/触发 select 事件 submit() 添加/触发 submit 事件 toggle() 在版本 1.9 中被移除。添加 click 事件之间要切换的两个或多个函数 trigger() 触发绑定到被选元素的所有事件 triggerHandler() 触发绑定到被选元素的指定事件上的所有函数 unbind() 从被选元素上移除添加的事件处理程序 undelegate() 从现在或未来的被选元素上移除事件处理程序 unload() 在版本 1.8 中被废弃。添加事件处理程序到 unload 事件 contextmenu() 添加事件处理程序到 contextmenu 事件 $.holdReady() 用于暂停或恢复.ready() 事件的执行 jQuery 效果方法 方法 描述 animate() 对被选元素应用\"自定义\"的动画 clearQueue() 对被选元素移除所有排队函数（仍未运行的） delay() 对被选元素的所有排队函数（仍未运行）设置延迟 dequeue() 移除下一个排队函数，然后执行函数 fadeIn() 逐渐改变被选元素的不透明度，从隐藏到可见 fadeOut() 逐渐改变被选元素的不透明度，从可见到隐藏 fadeTo() 把被选元素逐渐改变至给定的不透明度 fadeToggle() 在 fadeIn() 和 fadeOut() 方法之间进行切换 finish() 对被选元素停止、移除并完成所有排队动画 hide() 隐藏被选元素 queue() 显示被选元素的排队函数 show() 显示被选元素 slideDown() 通过调整高度来滑动显示被选元素 slideToggle() slideUp() 和 slideDown() 方法之间的切换 slideUp() 通过调整高度来滑动隐藏被选元素 stop() 停止被选元素上当前正在运行的动画 toggle() hide() 和 show() 方法之间的切换 jQuery HTML / CSS 方法 方法 描述 addClass() 向被选元素添加一个或多个类名 after() 在被选元素后插入内容 append() 在被选元素的结尾插入内容 appendTo() 在被选元素的结尾插入 HTML 元素 attr() 设置或返回被选元素的属性/值 before() 在被选元素前插入内容 clone() 生成被选元素的副本 css() 为被选元素设置或返回一个或多个样式属性 detach() 移除被选元素（保留数据和事件） empty() 从被选元素移除所有子节点和内容 hasClass() 检查被选元素是否包含指定的 class 名称 height() 设置或返回被选元素的高度 html() 设置或返回被选元素的内容 innerHeight() 返回元素的高度（包含 padding，不包含 border） innerWidth() 返回元素的宽度（包含 padding，不包含 border） insertAfter() 在被选元素后插入 HTML 元素 insertBefore() 在被选元素前插入 HTML 元素 offset() 设置或返回被选元素的偏移坐标（相对于文档） offsetParent() 返回第一个定位的祖先元素 outerHeight() 返回元素的高度（包含 padding 和 border） outerWidth() 返回元素的宽度（包含 padding 和 border） position() 返回元素的位置（相对于父元素） prepend() 在被选元素的开头插入内容 prependTo() 在被选元素的开头插入 HTML 元素 prop() 设置或返回被选元素的属性/值 remove() 移除被选元素（包含数据和事件） removeAttr() 从被选元素移除一个或多个属性 removeClass() 从被选元素移除一个或多个类 removeProp() 移除通过 prop() 方法设置的属性 replaceAll() 把被选元素替换为新的 HTML 元素 replaceWith() 把被选元素替换为新的内容 scrollLeft() 设置或返回被选元素的水平滚动条位置 scrollTop() 设置或返回被选元素的垂直滚动条位置 text() 设置或返回被选元素的文本内容 toggleClass() 在被选元素中添加/移除一个或多个类之间切换 unwrap() 移除被选元素的父元素 val() 设置或返回被选元素的属性值（针对表单元素） width() 设置或返回被选元素的宽度 wrap() 在每个被选元素的周围用 HTML 元素包裹起来 wrapAll() 在所有被选元素的周围用 HTML 元素包裹起来 wrapInner() 在每个被选元素的内容周围用 HTML 元素包裹起来 $.escapeSelector() 转义CSS选择器中有特殊意义的字符或字符串 $.cssHooks 提供了一种方法通过定义函数来获取和设置特定的CSS值 jQuery 遍历方法 方法 描述 add() 把元素添加到匹配元素的集合中 addBack() 把之前的元素集添加到当前集合中 andSelf() 在版本 1.8 中被废弃。addBack() 的别名 children() 返回被选元素的所有直接子元素 closest() 返回被选元素的第一个祖先元素 contents() 返回被选元素的所有直接子元素（包含文本和注释节点） each() 为每个匹配元素执行函数 end() 结束当前链中最近的一次筛选操作，并把匹配元素集合返回到前一次的状态 eq() 返回带有被选元素的指定索引号的元素 filter() 把匹配元素集合缩减为匹配选择器或匹配函数返回值的新元素 find() 返回被选元素的后代元素 first() 返回被选元素的第一个元素 has() 返回拥有一个或多个元素在其内的所有元素 is() 根据选择器/元素/jQuery 对象检查匹配元素集合，如果存在至少一个匹配元素，则返回 true last() 返回被选元素的最后一个元素 map() 把当前匹配集合中的每个元素传递给函数，产生包含返回值的新 jQuery 对象 next() 返回被选元素的后一个同级元素 nextAll() 返回被选元素之后的所有同级元素 nextUntil() 返回介于两个给定参数之间的每个元素之后的所有同级元素 not() 从匹配元素集合中移除元素 offsetParent() 返回第一个定位的父元素 parent() 返回被选元素的直接父元素 parents() 返回被选元素的所有祖先元素 parentsUntil() 返回介于两个给定参数之间的所有祖先元素 prev() 返回被选元素的前一个同级元素 prevAll() 返回被选元素之前的所有同级元素 prevUntil() 返回介于两个给定参数之间的每个元素之前的所有同级元素 siblings() 返回被选元素的所有同级元素 slice() 把匹配元素集合缩减为指定范围的子集 jQuery AJAX 方法 方法 描述 $.ajax() 执行异步 AJAX 请求 $.ajaxPrefilter() 在每个请求发送之前且被 $.ajax() 处理之前，处理自定义 Ajax 选项或修改已存在选项 $.ajaxSetup() 为将来的 AJAX 请求设置默认值 $.ajaxTransport() 创建处理 Ajax 数据实际传送的对象 $.get() 使用 AJAX 的 HTTP GET 请求从服务器加载数据 $.getJSON() 使用 HTTP GET 请求从服务器加载 JSON 编码的数据 $.getScript() 使用 AJAX 的 HTTP GET 请求从服务器加载并执行 JavaScript $.param() 创建数组或对象的序列化表示形式（可用于 AJAX 请求的 URL 查询字符串） $.post() 使用 AJAX 的 HTTP POST 请求从服务器加载数据 ajaxComplete() 规定 AJAX 请求完成时运行的函数 ajaxError() 规定 AJAX 请求失败时运行的函数 ajaxSend() 规定 AJAX 请求发送之前运行的函数 ajaxStart() 规定第一个 AJAX 请求开始时运行的函数 ajaxStop() 规定所有的 AJAX 请求完成时运行的函数 ajaxSuccess() 规定 AJAX 请求成功完成时运行的函数 load() 从服务器加载数据，并把返回的数据放置到指定的元素中 serialize() 编码表单元素集为字符串以便提交 serializeArray() 编码表单元素集为 names 和 values 的数组 jQuery 杂项方法 jQuery 杂项方法 方法 描述 data() 向被选元素附加数据，或者从被选元素获取数据 each() 为每个匹配元素执行函数 get() 获取由选择器指定的 DOM 元素 index() 从匹配元素中搜索给定元素 $.noConflict() 释放变量 $ 的 jQuery 控制权 $.param() 创建数组或对象的序列化表示形式（可在生成 AJAX 请求时用于 URL 查询字符串中） removeData() 移除之前存放的数据 size() 在版本 1.8 中被废弃。返回被 jQuery 选择器匹配的 DOM 元素的数量 toArray() 以数组的形式检索所有包含在 jQuery 集合中的所有 DOM 元素 pushStack() 将一个DOM元素集合加入到jQuery栈 $.when() 提供一种方法来执行一个或多个对象的回调函数 jQuery 实用工具 方法 描述 $.boxModel 在版本 1.8 中被废弃。检测浏览器是否使用W3C的CSS盒模型渲染当前页面 $.browser 在版本 1.9 中被废弃。返回用户当前使用的浏览器的相关信息 $.contains() 判断另一个DOM元素是否是指定DOM元素的后代 $.each() 遍历指定的对象和数组 $.extend() 将一个或多个对象的内容合并到目标对象 $.fn.extend() 为jQuery扩展一个或多个实例属性和方法 $.globalEval() 全局性地执行一段JavaScript代码 $.grep() 过滤并返回满足指定函数的数组元素 $.inArray() 在数组中查找指定值并返回它的索引值（如果没有找到，则返回-1） $.isArray() 判断指定参数是否是一个数组 $.isEmptyObject() 检查对象是否为空（不包含任何属性） $.isFunction() 判断指定参数是否是一个函数 $.isNumeric() 判断指定参数是否是一个数字值 $.isPlainObject() 判断指定参数是否是一个纯粹的对象 $.isWindow() 判断指定参数是否是一个窗口 $.isXMLDoc() 判断一个DOM节点是否位于XML文档中，或者其本身就是XML文档 $.makeArray() 将一个类似数组的对象转换为真正的数组对象 $.map() 指定函数处理数组中的每个元素(或对象的每个属性)，并将处理结果封装为新的数组返回 $.merge() 合并两个数组内容到第一个数组 $.noop() 一个空函数 $.now() 返回当前时间 $.parseHTML() 将HTML字符串解析为对应的DOM节点数组 $.parseJSON() 将符合标准格式的JSON字符串转为与之对应的JavaScript对象 $.parseXML() 将字符串解析为对应的XML文档 $.trim() 去除字符串两端的空白字符 $.type() 确定JavaScript内置对象的类型 $.unique() 在jQuery 3.0中被弃用。对DOM元素数组进行排序，并移除重复的元素 $.uniqueSort() 对DOM元素数组进行排序，并移除重复的元素 $.data() 在指定的元素上存取数据，并返回设置值 $.hasData() 确定一个元素是否有相关的jQuery数据 $.sub() 创建一个新的jQuery副本，其属性和方法可以修改，而不会影响原来的jQuery对象 $.speed 创建一个包含一组属性的对象用来定义自定义动画 $.htmlPrefilter() 通过jQuery操作方法修改和过滤HTML字符串 $.readyException() 处理包裹在jQuery()中函数同步抛出的错误 jQuery 回调对象 方法 描述 $.Callbacks() 一个多用途的回调列表对象，用来管理回调函数列表 callbacks.add() 在回调列表中添加一个回调或回调的集合 callbacks.disable() 禁用回调列表中的回调函数 callbacks.disabled() 确定回调列表是否已被禁用 callbacks.empty() 从列表中清空所有的回调 callbacks.fire() 传入指定的参数调用所有的回调 callbacks.fired() 确定回调是否至少已经调用一次 callbacks.firewith() 给定的上下文和参数访问列表中的所有回调 callbacks.has() 判断回调列表中是否添加过某回调函数 callbacks.lock() 锁定当前状态的回调列表 callbacks.locked() 判断回调列表是否被锁定 callbacks.remove() 从回调列表中的删除一个回调或回调集合 jQuery 延迟对象 方法 描述 $.Deferred() 返回一个链式实用对象方法来注册多个回调 deferred.always() 当Deferred（延迟）对象被受理或被拒绝时，调用添加的处理程序 deferred.done() 当Deferred（延迟）对象被受理时，调用添加的处理程序 deferred.fail() 当Deferred（延迟）对象被拒绝时，调用添加的处理程序 deferred.isRejected() 从jQuery1.7开始已经过时，确定 Deferred 对象是否已被拒绝 deferred.isResolved() 从jQuery1.7开始已经过时，确定 Deferred 对象是否已被解决 deferred.notify() 给定一个参数，调用正在延迟对象上进行的回调函数( progressCallbacks ) deferred.notifyWith() 给定上下文和参数，调用正在延迟对象上进行的回调函数( progressCallbacks ) deferred.pipe() 过滤 and/or 链式延迟对象的工具方法 deferred.progress() 当Deferred（延迟）对象生成进度通知时，调用添加处理程序 deferred.promise() 返回 Deferred(延迟)的 Promise 对象 deferred.reject() 拒绝 Deferred（延迟）对象，并根据给定的参数调用任何 failCallbacks 回调函数 deferred.rejectWith() 拒绝 Deferred（延迟）对象，并根据给定的 context 和 args 参数调用任何 failCallbacks 回调函数 deferred.resolve() 解决Deferred（延迟）对象，并根据给定的参数调用任何 doneCallbacks 回调函数 deferred.resolveWith() 解决Deferred（延迟）对象，并根据给定的context 和 args 参数调用任何 doneCallbacks 回调函数 deferred.state() 确定一个Deferred（延迟）对象的当前状态 deferred.then() 当Deferred（延迟）对象解决，拒绝或仍在进行中时，调用添加处理程序 .promise() 返回一个 Promise 对象，观察某种类型被绑定到集合的所有行动，是否已被加入到队列中 jQuery 属性 方法 描述 context 在版本 1.10 中被废弃。包含被传递到 jQuery 的原始上下文 jquery 包含 jQuery 的版本号 jQuery.fx.interval 改变以毫秒计的动画运行速率 jQuery.fx.off 对所有动画进行全局禁用或启用 jQuery.support 包含表示不同浏览器特性或漏洞的属性集（主要用于 jQuery 的内部使用） length 包含 jQuery 对象中元素的数目 jQuery.cssNumber 包含所有可以不使用单位的CSS属性的对象 "},"Web/RESTful.html":{"url":"Web/RESTful.html","title":"RESTful规范","keywords":"","body":"restful api设计（规范，建议） 1、API与用户的通信协议，总是使用HTTPs协议（推荐使用）。 2、域名 --https://api.example.com 尽量将API部署在专用域名（会存在跨域问题） --https://example.org/api/ API很简单 3、版本 --URL，如：https://api.example.com/v1/、https://example.org/api/v1/ --请求头 跨域时，引发发送多次请求 4、路径，视网络上任何东西都是资源，均使用名词表示（可复数） --https://api.example.com/v1/zoos --https://api.example.com/v1/animals --https://api.example.com/v1/employees 5、method --GET ：从服务器取出资源（一项或多项） --POST ：在服务器新建一个资源 --PUT ：在服务器更新资源（客户端提供改变后的完整资源） --PATCH ：在服务器更新资源（客户端提供改变的属性） --DELETE ：从服务器删除资源 6、过滤，通过在url上传参的形式传递搜索条件 --https://api.example.com/v1/zoos?limit=10：指定返回记录的数量 --https://api.example.com/v1/zoos?offset=10：指定返回记录的开始位置 --https://api.example.com/v1/zoos?page=2&per_page=100：指定第几页，以及每页的记录数 --https://api.example.com/v1/zoos?sortby=name&order=asc：指定返回结果按照哪个属性排序，以及排序顺序 --https://api.example.com/v1/zoos?animal_type_id=1：指定筛选条件 7、状态码 + 自定义code --200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。 --201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。 --202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务） --204 NO CONTENT - [DELETE]：用户删除数据成功。 --400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。 --401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。 --403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。 --404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。 --406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。 --410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。 --422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。 --500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 8、错误处理，状态码是4xx时，应返回错误信息，error当做key。 { error: \"Invalid API key\" } 9、返回结果，针对不同操作，服务器向用户返回的结果应该符合以下规范。 GET /collection：返回资源对象的列表（数组） GET /collection/resource：返回单个资源对象 POST /collection：返回新生成的资源对象 PUT /collection/resource：返回完整的资源对象 PATCH /collection/resource：返回完整的资源对象 DELETE /collection/resource：返回一个空文档 10、Hypermedia API，RESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。 {\"link\": { \"rel\": \"collection https://www.example.com/zoos\", \"href\": \"https://api.example.com/zoos\", \"title\": \"List of zoos\", \"type\": \"application/vnd.yourformat+json\" }} "},"ROS/基础/00-Windows安装rospy.html":{"url":"ROS/基础/00-Windows安装rospy.html","title":"Windows安装rospy","keywords":"","body":"datetime:2023/02/06 16:30 author:nzb Windows安装rospy ros 相关包下载链接，官方链接 ，采用轮子方法安装 安装依赖顺序 1、catkin 2、roslib 3、genmsg（roscpp依赖） 4、genpy（roscpp依赖） 5、roscpp（rospy依赖） 6、std_msgs（rospy依赖） 7、rosgraph_msgs（rospy依赖） 8、rosgraph（rospy依赖） 9、rospy 10、rosmaster 设置系统环境变量 ROS_LOG_DIR=C:\\Users\\lenovo\\.ros\\log # 日志路径 ROS_MASTER_URI=http://172.31.242.34:11311/ # master uri ROS_ROOT=C:\\Users\\lenovo\\.ros # ros 根目录 修改环境变量后需要重启IDE 不改环境变量也可跑，需要配置执行参数 master.py import rosmaster if __name__ == '__main__': rosmaster.rosmaster_main([\"--core\"]) 配置运行参数，该处未配置才会取系统环境变量的 日志配置 目录：ROS_ROOT目录下建立config目录，里面新建python_logging.conf 配置文件，配置文件配置说明官方链接 # -*- encoding: utf8 -*- [loggers] keys = root, fileLogger, rotatingFileLogger [handlers] keys = consoleHandler, fileHandler, rotatingFileHandler [formatters] keys = simpleFormatter [logger_root] level = DEBUG handlers = consoleHandler, fileHandler [logger_fileLogger] level = DEBUG handlers = fileHandler qualname = fileLogger propagate = 0 [logger_rotatingFileLogger] level = DEBUG handlers = consoleHandler, rotatingFileHandler qualname = rotatingFileLogger propagate = 0 [handler_consoleHandler] class = StreamHandler level = DEBUG formatter = simpleFormatter args = (sys.stdout, ) [handler_fileHandler] class = FileHandler level = DEBUG formatter = simpleFormatter args = ('C:/Users/lenovo/.ros/log/logging.log', 'a') [handler_rotatingFileHandler] class = handlers.RotatingFileHandler level = WARNING formatter = simpleFormatter args = (\"C:/Users/lenovo/.ros/log/rotating_logging.log\", \"a\", 1*1024*1024, 5) [formatter_simpleFormatter] #format=%(asctime)s - %(name)s - %(levelname)s - %(message)s format = %(asctime)s - %(module)s - %(thread)d - %(levelname)s:%(message)s datefmt = %Y-%m-%d %H:%M:%S "},"ROS/基础/01-什么是ROS.html":{"url":"ROS/基础/01-什么是ROS.html","title":"什么是ROS","keywords":"","body":"datetime:2022/04/23 18:00 author:nzb 什么是ROS? 中间件/类操作系统 硬件抽象 底层设备控制 常用函数的实现 进程间消息传递 包管理 官方的定义：ROS = 框架 + 工具 + 功能 + 社区 框架 分布式 节点(进程)管理 节点(进程)间通信 工具 仿真 数据可视化 图形界面 数据记录 功能 控制 规划 视觉 建图 社区 软件包管理 文档 教程 ROS 安装和配置 主要使用官方提供的网站按步骤安装就可以了： kinetic/Installation/Ubuntu - ROS Wiki 重德智能开源库（此视频开源库）： 链接1 链接2 开发环境使用：roboware studio sdn.net/lxj362343/article/details/118885315 "},"ROS/基础/02-Catkin工作空间与编译系统.html":{"url":"ROS/基础/02-Catkin工作空间与编译系统.html","title":"Catkin工作空间编译系统","keywords":"","body":"datetime:2022/04/23 18:00 author:nzb Catkin工作空间和编译系统 上图文件夹及文件说明 src：package 源代码(该文件就是我们写代码的所在的文件夹) build：cmake&catkin 缓存和中间文件 devel：目标文件 catkin：ROS 定制的编译构建系统，对 cmake 的扩展。 catkin 工作空间：组织和管理功能包的文件夹，以 catkin 工具编译 $ source /opt/ros/noetic/setup.bash # 建立工作站 $ mkdir -p ~/catkin_ws/src $ cd ~/catkin_ws/ # 回到工作站 $ catkin_make # 编译 //$ catkin_make -DPYTHON_EXECUTABLE=/usr/bin/python3 $ source devel/setup.bash # 编译完成后要 source 刷新环境 $ echo $ROS_PACKAGE_PATH /home/youruser/catkin_ws/src:/opt/ros/kinetic/share 编译后结构目录 package ROS 软件的基本组织形式 catkin 编译的基本单元 一个 package 可以包含多个可执行文件（节点） cmake简单介绍 CMakeLists.txt：规定 catkin 编译的规则，例如：源文件、依赖项、目标文件 如果没有cmake基础的可以去看《cmake实践》 ，好像和《CMake Practice》是同一本书只是不同叫法或者是中英文叫法而已。 package.xml简单介绍 package.xml：定义 package 的属性，例如：包名、版本号、作者、依赖等 manifest.xml：rosbuild 编译采用的包信息清单，类似 catkin 的 package.xml 代码文件 一般代码文件可以是脚本（shell、Python）或者C++文件。 package结构示意图： package还有有自定义通信格式的文件，包括消息（msg），服务（srv），动作（action）等 这时候package结构就像下面这样了 package还有launch文件，配置文件（yaml）。launch用于每次可以运行多个可执行文件。 这时候package结构图如下 总体框架（视频缺少config文件，我添加上去了） 常用命令 Metapackage 把一系列包组织起来，安装使用方便 "},"ROS/基础/03-ROS通信架构上.html":{"url":"ROS/基础/03-ROS通信架构上.html","title":"ROS通信架构上","keywords":"","body":"datetime:2022/04/24 10:04 author:nzb ROS 通信架构(上) Master 和 Node Node 在ROS的世界里，最小的进程单元就是节点（node）。一个软件包里可以有多个可执行文件，可执行文件在运行之后就成了一个进程(process)，这个进程在ROS中就叫做节点。 从程序角度来说，node就是一个可执行文件（通常为C++编译生成的可执行文件、Python脚本）被执行，加载到了内存之中；从功能角度来说，通常一个node负责者机器人的某一个单独的功能。由于机器人的功能模块非常复杂，我们往往不会把所有功能都集中到一个node上，而会采用分布式的方式，把鸡蛋放到不同的篮子里。例如有一个node来控制底盘轮子的运动，有一个node驱动摄像头获取图像，有一个node驱动激光雷达，有一个node根据传感器信息进行路径规划……这样做可以降低程序发生崩溃的可能性，试想一下如果把所有功能都写到一个程序中，模块间的通信、异常处理将会很麻烦。 节点(node)相当一个个程序 ROS 的进程 pkg 里的可执行文件运行的实例 node启动命令 rosrun [--prefix cmd] [--debug] pkg_name node_name [ARGS] rosrun将会寻找PACKAGE下的名为EXECUTABLE的可执行程序，将可选参数ARGS传入。 例如在GDB下运行ros程序： rosrun --prefix 'gdb -ex run --args' pkg_name node_name 常用命令 rosnode命令 作用 rosnode list 列出当前运行的node信息 rosnode info node_name 显示出node的详细信息 rosnode kill node_name 结束某个node rosnode ping 测试连接节点 rosnode machine 列出在特定机器或列表机器上运行的节点 rosnode cleanup 清除不可到达节点的注册信息 以上命令中常用的为前三个，在开发调试时经常会需要查看当前node以及node信息，所以请记住这些常用命令。如果你想不起来，也可以通过rosnode help来查看rosnode命令的用法。 Master 由于机器人的元器件很多，功能庞大，因此实际运行时往往会运行众多的node，负责感知世界、控制运动、决策和计算等功能。那么如何合理的进行调配、管理这些node？这就要利用ROS提供给我们的节点管理器master, master在整个网络通信架构里相当于管理中心，管理着各个node。node首先在master处进行注册，之后master会将该node纳入整个ROS程序中。node之间的通信也是先由master进行“牵线”，才能两两的进行点对点通信。当ROS程序启动时，第一步首先启动master，由节点管理器处理依次启动node。 master相当一个管家，用来管理各个节点 每个 node 启动时都要想 master 注册 管理 node 之间的通信 启动 roscore roscore：启动 ros master master：节点管理器 rosout：日志输出 parameter server：参数服务器 通常我们运行ROS，就是按照这样的顺序启动，有时候节点太多，我们会选择用launch文件来启动，下一小节会有介绍。 Master、Node之间以及Node之间的关系如下图所示： launch文件 简介 机器人是一个系统工程，通常一个机器人运行操作时要开启很多个node，对于一个复杂的机器人的启动操作应该怎么做呢？当然，我们并不需要每个节点依次进行rosrun，ROS为我们提供了一个命令能一次性启动master和多个node。该命令是： roslaunch pkg_name file_name.launch roslaunch命令首先会自动进行检测系统的roscore有没有运行，也即是确认节点管理器是否在运行状态中，如果master没有启动，那么roslaunch就会首先启动master，然后再按照launch的规则执行。launch文件里已经配置好了启动的规则。 所以roslaunch就像是一个启动工具，能够一次性把多个节点按照我们预先的配置启动起来，减少我们在终端中一条条输入指令的麻烦。 写法与格式 launch文件同样也遵循着xml格式规范，是一种标签文本，它的格式包括以下标签： 参考链接 示例 launch文件的写法和格式看起来内容比较复杂，我们先来介绍一个最简单的例子如下： 这是官网给出的一个最小的例子，文本中的信息是，它启动了一个单独的节点talker,该节点是包rospy_tutorials软件包中的节点。 然而实际中的launch文件要复杂很多，我们以Ros-Academy-for-Beginners中的robot_sim_demo为例： 这个launch文件相比上一个简单的例子来说，内容稍微有些复杂，它的作用是：启动gazebo模拟器，导入参数内容，加入机器人模型。 小结对于初学者，我们不要求掌握每一个标签是什么作用，但至少应该有一个印象。如果我们要进行自己写launch文件，可以先从改launch文件的模板入手，基本可以满足普通项目的要求。 pr2机器人要启动的节点 Topic 简介 ROS的通信方式是ROS最为核心的概念，ROS系统的精髓就在于它提供的通信架构。ROS的通信方式有以下四种： Topic 主题 Service 服务 Parameter Service 参数服务器 Actionlib 动作库 Topic ROS中的通信方式中，topic是常用的一种。对于实时性、周期性的消息，使用topic来传输是最佳的选择。topic是一种点对点的单向通信方式，这里的“点”指的是node，也就是说node之间可以通过topic方式来传递信息。topic要经历下面几步的初始化过程：首先，publisher节点和subscriber节点都要到节点管理器进行注册，然后publisher会发布topic，subscriber在master的指挥下会订阅该topic，从而建立起sub-pub之间的通信。注意整个过程是单向的。其结构示意图如下： Subscriber接收消息会进行处理，一般这个过程叫做回调(Callback)。所谓回调就是提前定义好了一个处理函数（写在代码中），当有消息来就会触发这个处理函数，函数会对消息进行处理。 上图就是ROS的topic通信方式的流程示意图。topic通信属于一种异步的通信方式。下面我们通过一个示例来了解下如何使用topic通信。 通信示例 参考下图，我们以摄像头画面的发布、处理、显示为例讲讲topic通信的流程。在机器人上的摄像头拍摄程序是一个node（圆圈表示,我们记作node1），当node1运行启动之后，它作为一个Publisher就开始发布topic。比如它发布了一个topic（方框表示），叫做/camera_rgb，是rgb颜色信息，即采集到的彩色图像。同时，node2假如是图像处理程序,它订阅了/camera_rgb这个topic，经过节点管理器的介绍，它就能建立和摄像头节点（node1）的连接。 那么怎么样来理解“异步”这个概念呢？在node1每发布一次消息之后，就会继续执行下一个动作，至于消息是什么状态、被怎样处理，它不需要了解；而对于node2图像处理程序，它只管接收和处理/camera_rgb上的消息，至于是谁发来的，它不会关心。所以node1、node2两者都是各司其责，不存在协同工作，我们称这样的通信方式是异步的。 ROS是一种分布式的架构，一个topic可以被多个节点同时发布，也可以同时被多个节点接收。比如在这个场景中用户可以再加入一个图像显示的节点，我们在想看看摄像头节点的画面，则可以用自己的笔记本连接到机器人上的节点管理器，然后在自己的电脑上启动图像显示节点。 这就体现了分布式系统通信的好处：扩展性好、软件复用率高。 总结三点： topic通信方式是异步的，发送时调用publish()方法，发送完成立即返回，不用等待反馈。 subscriber通过回调函数的方式来处理消息。 topic可以同时有多个subscribers，也可以同时有多个publishers。ROS中这样的例子有：/rosout、/tf等等。 操作命令 在实际应用中，我们应该熟悉topic的几种使用命令，下表详细的列出了各自的命令及其作用。 命令 作用 rostopic list 列出当前所有的topic rostopic info topic_name 显示某个topic的属性信息 rostopic echo topic_name 显示某个topic的内容 rostopic pub topic_name ... 向某个topic发布内容 rostopic bw topic_name 查看某个topic的带宽 rostopic hz topic_name 查看某个topic的频率 rostopic find topic_type 查找某个类型的topic rostopic type topic_name 查看某个topic的类型(msg) 如果你一时忘记了命令的写法，可以通过rostopic help或rostopic command -h查看具体用法。 Message 简介topic有很严格的格式要求，比如上节的摄像头进程中的rgb图像topic，它就必然要遵循ROS中定义好的rgb图像格式。这种数据格式就是Message。Message按照定义解释就是topic内容的数据类型，也称之为topic的格式标准。这里和我们平常用到的Massage直观概念有所不同，这里的Message不单单指一条发布或者订阅的消息，也指定为topic的格式标准。 结构与类型基本的msg包括bool、int8、int16、int32、int64(以及uint)、float、float64、string、time、duration、header、可变长数组array[]、固定长度数组array[C] 。那么具体的一个msg是怎么组成的呢？我们用一个具体的msg来了解，例如上例中的msg sensor_msg/image,位置存放在sensor_msgs/msg/image.msg里,它的结构如下： std_msg/Header header uint32 seq time stamp string frame_id uint32 height uint32 width string encoding uint8 is_bigendian uint32 step uint8[] data 观察上面msg的定义，是不是很类似C语言中的结构体呢？通过具体的定义图像的宽度，高度等等来规范图像的格式。所以这就解释了Message不仅仅是我们平时理解的一条一条的消息，而且更是ROS中topic的格式规范。或者可以理解msg是一个“类”，那么我们每次发布的内容可以理解为“对象”，这么对比来理解可能更加容易。 我们实际通常不会把Message概念分的那么清，通常说Message既指的是类，也是指它的对象。而msg文件则相当于类的定义了。 操作命令rosmsg的命令相比topic就比较少了，只有两个如下： rosmsg命令 作用 rosmsg list 列出系统上所有的msg rosmsg show msg_name 显示某个msg的内容 小结 topic的通信方式是ROS中比较常见的单向异步通信方式，它在很多时候的通信是比较易用且高效的。但是有些需要交互的通信时该方式就显露出自己的不足之处了，后续我们会介绍双向同步的通信方式service。 常见message 本小节主要介绍常见的message类型，包括std_msgs, sensor_msgs, nav_msgs, geometry_msgs等 Vector3.msg #文件位置:geometry_msgs/Vector3.msg float64 x float64 y float64 z Accel.msg #定义加速度项，包括线性加速度和角加速度 #文件位置:geometry_msgs/Accel.msg Vector3 linear Vector3 angular Header.msg #定义数据的参考时间和参考坐标 #文件位置:std_msgs/Header.msg uint32 seq #数据ID time stamp #数据时间戳 string frame_id #数据的参考坐标系 Echos.msg #定义超声传感器 #文件位置:自定义msg文件 Header header uint16 front_left uint16 front_center uint16 front_right uint16 rear_left uint16 rear_center uint16 rear_right Quaternion.msg #消息代表空间中旋转的四元数 #文件位置:geometry_msgs/Quaternion.msg float64 x float64 y float64 z float64 w Imu.msg #消息包含了从惯性原件中得到的数据，加速度为m/^2，角速度为rad/s #如果所有的测量协方差已知，则需要全部填充进来如果只知道方差，则 #只填充协方差矩阵的对角数据即可 #位置：sensor_msgs/Imu.msg Header header Quaternion orientation float64[9] orientation_covariance Vector3 angular_velocity float64[9] angular_velocity_covariance Vector3 linear_acceleration float64[] linear_acceleration_covariance LaserScan.msg #平面内的激光测距扫描数据，注意此消息类型仅仅适配激光测距设备 #如果有其他类型的测距设备(如声呐)，需要另外创建不同类型的消息 #位置：sensor_msgs/LaserScan.msg Header header #时间戳为接收到第一束激光的时间 float32 angle_min #扫描开始时的角度(单位为rad) float32 angle_max #扫描结束时的角度(单位为rad) float32 angle_increment #两次测量之间的角度增量(单位为rad) float32 time_increment #两次测量之间的时间增量(单位为s) float32 scan_time #两次扫描之间的时间间隔(单位为s) float32 range_min #距离最小值(m) float32 range_max #距离最大值(m) float32[] ranges #测距数据(m,如果数据不在最小数据和最大数据之间，则抛弃) float32[] intensities #强度，具体单位由测量设备确定，如果仪器没有强度测量，则数组为空即可 Point.msg #空间中的点的位置 #文件位置:geometry_msgs/Point.msg float64 x float64 y float64 z Pose.msg #消息定义自由空间中的位姿信息，包括位置和指向信息 #文件位置:geometry_msgs/Pose.msg Point position Quaternion orientation PoseStamped.msg #定义有时空基准的位姿 #文件位置：geometry_msgs/PoseStamped.msg Header header Pose pose PoseWithCovariance.msg #表示空间中含有不确定性的位姿信息 #文件位置：geometry_msgs/PoseWithCovariance.msg Pose pose float64[36] covariance Power.msg #表示电源状态，是否开启 #文件位置：自定义msg文件 Header header bool power ###################### bool ON = 1 bool OFF = 0 Twist.msg #定义空间中物体运动的线速度和角速度 #文件位置：geometry_msgs/Twist.msg Vector3 linear Vector3 angular TwistWithCovariance.msg #消息定义了包含不确定性的速度量，协方差矩阵按行分别表示： #沿x方向速度的不确定性，沿y方向速度的不确定性，沿z方向速度的不确定性 #绕x转动角速度的不确定性，绕y轴转动的角速度的不确定性，绕z轴转动的 #角速度的不确定性 #文件位置：geometry_msgs/TwistWithCovariance.msg Twist twist float64[36] covariance #分别表示[x; y; z; Rx; Ry; Rz] Odometry.msg #消息描述了自由空间中位置和速度的估计值 #文件位置：nav_msgs/Odometry.msg Header header string child_frame_id PoseWithCovariance pose TwistWithCovariance twist "},"ROS/基础/04-ROS通信架构下.html":{"url":"ROS/基础/04-ROS通信架构下.html","title":"ROS通信架构下","keywords":"","body":"datetime:2022/04/24 10:04 author:nzb ROS 通信架构(下) Service 上一章我们介绍了ROS的通信方式中的topic(主题)通信，我们知道topic是ROS中的一种单向的异步通信方式。然而有些时候单向的通信满足不了通信要求，比如当一些节点只是临时而非周期性的需要某些数据，如果用topic通信方式时就会消耗大量不必要的系统资源，造成系统的低效率高功耗。 这种情况下，就需要有另外一种请求-查询式的通信模型。这节我们来介绍ROS通信中的另一种通信方式——service(服务)。 工作原理 简介 为了解决以上问题，service方式在通信模型上与topic做了区别。Service通信是双向的，它不仅可以发送消息，同时还会有反馈。所以service包括两部分，一部分是请求方（Clinet），另一部分是应答方/服务提供方（Server）。这时请求方（Client）就会发送一个request，要等待server处理，反馈回一个reply，这样通过类似“请求-应答”的机制完成整个服务通信。 这种通信方式的示意图如下： Node B是server（应答方），提供了一个服务的接口，叫做/Service，我们一般都会用string类型来指定service的名称，类似于topic。Node A向Node B发起了请求，经过处理后得到了反馈。 过程 Service是同步通信方式，所谓同步就是说，此时Node A发布请求后会在原地等待reply，直到Node B处理完了请求并且完成了reply，Node A才会继续执行。Node A等待过程中，是处于阻塞状态的成通信。这样的通信模型没有频繁的消息传递，没有冲突与高系统资源的占用，只有接受请求才执行服务，简单而且高效。 topic VS service 我们对比一下这两种最常用的通信方式，加深我们对两者的理解和认识，具体见下表： 名称 Topic Service 通信方式 异步通信 同步通信 实现原理 TCP/IP TCP/IP 通信模型 Publish-Subscribe Request-Reply 映射关系 Publish-Subscribe(多对多) Request-Reply（多对一） 特点 接受者收到数据会回调（Callback） 远程过程调用（RPC）服务器端的服务 应用场景 连续、高频的数据发布 偶尔使用的功能/具体的任务 举例 激光雷达、里程计发布数据 开关传感器、拍照、逆解计算 注意：远程过程调用(Remote Procedure Call，RPC),可以简单通俗的理解为在一个进程里调用另一个进程的函数。 操作命令 在实际应用中，service通信方式的命令时rosservice，具体的命令参数如下表： rosservice 命令 作用 rosservice list 显示服务列表 rosservice info 打印服务信息 rosservice type 打印服务类型 rosservice uri 打印服务ROSRPC uri rosservice find 按服务类型查找服务 rosservice call 使用所提供的args调用服务 rosservice args 打印服务参数 小结 本节我们详细介绍了service通信方式，建议与topic通信方式进行对比记忆，这样我们能更深的理解这两种通信方式，也能在以后的学习工作中更加合理使用每个通信方式，获得更高的效率。 Srv 简介 类似msg文件，srv文件是用来描述服务（service数据类型的，service通信的数据格式定义在*.srv中。它声明了一个服务，包括请求(request)和响应（reply）两部分。其格式声明如下： 举例： msgs_demo/srv/DetectHuman.srv bool start_detect --- my_pkg/HumanPose[] pose_data msgs_demo/msg/HumanPose.msg std_msgs/Header header string uuid int32 number_of_joints my_pkg/JointPose[]joint_data msgs_demo/msg/JointPose.msg string joint_name geometry_msgs/Pose pose floar32 confidence 以DetectHUman.srv文件为例，该服务例子取自OpenNI的人体检测ROS软件包。它是用来查询当前深度摄像头中的人体姿态和关节数的。srv文件格式很固定，第一行是请求的格式，中间用---隔开，第三行是应答的格式。在本例中，请求为是否开始检测，应答为一个数组，数组的每个元素为某个人的姿态（HumanPose）。而对于人的姿态，其实是一个msg，所以srv可以嵌套msg在其中，但它不能嵌套srv。 操作命令 具体的操作指令如下表： rossrv 命令 作用 rossrv show 显示服务描述 rossrv list 列出所有服务 rossrv md5 显示服务md5sum rossrv package 列出包中的服务 rossrv packages 列出包含服务的包 修改部分文件 定义完了msg、srv文件，还有重要的一个步骤就是修改package.xml和修改CMakeList.txt。这些文件需要添加一些必要的依赖等，例如： ** message_generation ** ** message_runtime ** 上述文本中“**”所引就是新添加的依赖。又例如： find_package(...roscpp rospy std_msgs ** message_generation **) catkin_package( ... CATJIN_DEPENDS ** message_runtime ** ... ...) add_message_file( FILES ** DetectHuman.srv ** ** HumanPose.msg ** ** JointPos.msg **) ** generate_messages(DEPENDENCIES std_msgs) ** 添加的这些内容指定了srv或者msg在编译或者运行中需要的依赖。具体的作用我们初学者可不深究，我们需要了解的是，无论我们自定义了srv,还是msg，修改上述部分添加依赖都是必不可少的一步。 常见srv类型 本小节介绍常见的srv类型及其定义 srv类型相当于两个message通道，一个发送，一个接收 AddTwoInts.srv #对两个整数求和，虚线前是输入量，后是返回量 #文件位置：自定义srv文件 int32 a int32 b --- int32 sum Empty.srv #文件位置：std_srvs/Empty.srv #代表一个空的srv类型 --- GetMap.srv #文件位置:nav_msgs/GetMap.srv #获取地图，注意请求部分为空 --- nav_msgs/OccupancyGrid map GetPlan.srv #文件位置:nav_msgs/GetPlan.srv #得到一条从当前位置到目标点的路径 geometry_msgs/PoseStamped start #起始点 geometry_msgs/PoseStamped goal #目标点 float32 tolerance #到达目标点的x，y方向的容错距离 --- nav_msgs/Path plan SetBool.srv #文件位置：std_srvs/SetBools.srv bool data # 启动或者关闭硬件 --- bool success # 标示硬件是否成功运行 string message # 运行信息 SetCameraInfo.srv #文件位置:sensor_msgs/SetCameraInfo.srv #通过给定的CameraInfo相机信息，来对相机进行标定 sensor_msgs/CameraInfo camera_info #相机信息 --- bool success #如果调用成功，则返回true string status_message #给出调用成功的细节 SetMap.srv #文件位置：nav_msgs/SetMap.srv #以初始位置为基准，设定新的地图 nav_msgs/OccupancyGrid map geometry_msgs/PoseWithCovarianceStamped initial_pose --- bool success TalkerListener.srv #文件位置: 自定义srv文件 --- bool success # 标示srv是否成功运行 string message # 信息，如错误信息等 Trigger.srv #文件位置:std_srvs/Trigger.srv --- bool success # 标示srv是否成功运行 string message # 信息，如错误信息等 Parameter server 简介 前文介绍了ROS中常见的两种通信方式——主题和服务，这节介绍另外一种通信方式——参数服务器（parameter server）。与前两种通信方式不同，参数服务器也可以说是特殊的“通信方式”。特殊点在于参数服务器是节点存储参数的地方、用于配置参数，全局共享参数。参数服务器使用互联网传输，在节点管理器中运行，实现整个通信过程。 参数服务器，作为ROS中另外一种数据传输方式，有别于topic和service，它更加的静态。参数服务器维护着一个数据字典，字典里存储着各种参数和配置。 字典简介 何为字典，其实就是一个个的键值对，我们小时候学习语文的时候，常常都会有一本字典，当遇到不认识的字了我们可以查部首查到这个字，获取这个字的读音、意义等等，而这里的字典可以对比理解记忆。键值kay可以理解为语文里的“部首”这个概念，每一个key都是唯一的，参照下图： 每一个key不重复，且每一个key对应着一个value。也可以说字典就是一种映射关系，在实际的项目应用中，因为字典的这种静态的映射特点，我们往往将一些不常用到的参数和配置放入参数服务器里的字典里，这样对这些数据进行读写都将方便高效。 维护方式，参数服务器的维护方式非常的简单灵活，总的来讲有三种方式： 命令行维护 launch文件内读写 node源码 下面我们来一一介绍这三种维护方式。 命令行维护 使用命令行来维护参数服务器，主要使用rosparam语句来进行操作的各种命令，如下表： rosparam 命令 作用 rosparam set param_key param_value 设置参数 rosparam get param_key 显示参数 rosparam load file_name 从文件加载参数 rosparam dump file_name 保存参数到文件 rosparam delete 删除参数 rosparam list 列出参数名称 load&&dump文件 load和dump文件需要遵守YAML格式，YAML格式具体示例如下： name:'Zhangsan' age:20 gender:'M' score{Chinese:80,Math:90} score_history:[85,82,88,90] 简明解释。就是“名称+：+值”这样一种常用的解释方式。一般格式如下： key : value 遵循格式进行定义参数。其实就可以把YAML文件的内容理解为字典，因为它也是键值对的形式。 launch文件内读写 launch文件中有很多标签，而与参数服务器相关的标签只有两个，一个是，另一个是。这两个标签功能比较相近，但一般只设置一个参数 观察上例比如的param就定义了一个key和一个value，交给了参数服务器维护。而param只给出了key，没有直接给出value，这里的value是由后没的脚本运行结果作为value进行定义的。而rosparam的典型用法，先指定一个YAML文件，然后施加command,其效果等于rosparam load file_name 。 node源码 除了上述最常用的两种读写参数服务器的方法，还有一种就是修改ROS的源码，也就是利用API来对参数服务器进行操作。具体内容我们学习完后面章节再进行介绍。 参数类型 ROS参数服务器为参数值使用XMLRPC数据类型，其中包括:strings, integers, floats, booleans, lists, dictionaries, iso8601 dates, and base64-encoded data。 Action 简介 Actionlib是ROS中一个很重要的库，类似service通信机制，actionlib也是一种请求响应机制的通信方式，actionlib主要弥补了service通信的一个不足，就是当机器人执行一个长时间的任务时，假如利用service通信方式，那么publisher会很长时间接受不到反馈的reply，致使通信受阻。当service通信不能很好的完成任务时候，actionlib则可以比较适合实现长时间的通信过程，actionlib通信过程可以随时被查看过程进度，也可以终止请求，这样的一个特性，使得它在一些特别的机制中拥有很高的效率。 通信原理 Action的工作原理是client-server模式，也是一个双向的通信模式。通信双方在ROS Action Protocol下通过消息进行数据的交流通信。client和server为用户提供一个简单的API来请求目标（在客户端）或通过函数调用和回调来执行目标（在服务器端）。 工作模式的结构示意图如下： 通信双方在ROS Action Protocal下进行交流通信是通过接口来实现,如下图: 我们可以看到,客户端会向服务器发送目标指令和取消动作指令,而服务器则可以给客户端发送实时的状态信息,结果信息,反馈信息等等,从而完成了service没法做到的部分. Action 规范 利用动作库进行请求响应，动作的内容格式应包含三个部分，目标、反馈、结果。 目标 机器人执行一个动作，应该有明确的移动目标信息，包括一些参数的设定，方向、角度、速度等等。从而使机器人完成动作任务。 反馈 在动作进行的过程中，应该有实时的状态信息反馈给服务器的实施者，告诉实施者动作完成的状态，可以使实施者作出准确的判断去修正命令。 结果 当运动完成时，动作服务器把本次运动的结果数据发送给客户端，使客户端得到本次动作的全部信息，例如可能包含机器人的运动时长，最终姿势等等。 Action规范文件格式 Action规范文件的后缀名是.action，它的内容格式如下： # Define the goal uint32 dishwasher_id # Specify which dishwasher we want to use --- # Define the result uint32 total_dishes_cleaned --- # Define a feedback message float32 percent_complete Action实例详解 Actionlib是一个用来实现action的一个功能包集。我们在demo中设置一个场景，执行一个搬运的action，搬运过程中客户端会不断的发回反馈信息，最终完成整个搬运过程． 首先写handling.action文件,类比如上的格式.包括三个部分,目标,结果,反馈.如下: # Define the goal uint32 handling_id --- # Define the result uint32 Handling_completed --- # Define a feedback message float32 percent_complete 写完之后修改文件夹里CmakeLists.txt如下内容: find_package(catkin REQUIRED genmsg actionlib_msgs actionlib) add_action_files(DIRECTORY action FILES DoDishes.action) generate_messages(DEPENDENCIES actionlib_msgs) add_action_files(DIRECTORY action FILES Handling.action) generate_messages( DEPENDENCIES actionlib_msgs) 修改package.xml,添加所需要的依赖如下: actionlib actionlib_msgs actionlib actionlib_msgs 然后回到工作空间 catkin_ws进行编译. 本例中设置的的action,定义了一个搬运的例子,首先写客户端,实现功能发送action请求,包括进行目标活动,或者目标活动.之后写服务器,实验返回客户端活动当前状态信息,结果信息,和反馈信息.从而实现action.本例测试结果截图如下: 常见action类型 本小节介绍常见的action类型以及其定义 AddTwoInts.action #文件位置:自定义action文件 #表示将两个整数求和 int64 a int64 b --- int64 sum --- AutoDocking.action #文件位置:自定义action文件 #goal --- #result string text --- #feedback string state string text GetMap.action #文件位置:nav_msgs/GetMap.action #获取地图信息，响应部分为空 --- nav_msgs/OccupancyGrid map --- #无返回部分 MoveBase.action #文件位置:geometry_msgs/MoveBase.action geometry_msgs/PoseStamped target_pose --- --- geometry_msgs/PoseStamped base_position 小结 至此，ROS通信架构的四种通信方式就介绍结束，我们可以对比学习这四种通信方式，去思考每一种通信的优缺点和适用条件，在正确的地方用正确的通信方式，这样整个ROS的通信会更加高效，机器人也将更加的灵活和智能。机器人学会了通信，也就相当于有了“灵魂”。 "},"ROS/基础/05-常用工具.html":{"url":"ROS/基础/05-常用工具.html","title":"常用工具","keywords":"","body":"datetime:2022/04/25 10:51 author:nzb 常用工具 Gazebo 简介 ROS中的工具就是帮助我们完成一系列的操作，使得我们的工作更加轻松高效。ROS工具的功能大概有以下几个方向：仿真、调试、可视化。本节课我们要学习的Gazebo就是实现了仿真的功能，而调试与可视化由Rviz、rqt来实现，我们下节再依次介绍。 认识 Gazebo 对于Gazebo,大家可能并不陌生，因为我们在前面的学习过程中已经数次用到这个仿真环境，无论是在topic通信还是在service通信中，我们的demo都是在Gazebo中实现。 Gazebo是一个机器人仿真工具，模拟器，也是一个独立的开源机器人仿真平台。当今市面上还有其他的仿真工具例如V—Rep、Webots等等。但是Gazebo不仅开源，也是是兼容ROS最好的仿真工具。 Gazebo的功能很强大，最大的优点是对ROS的支持很好，因为Gazebo和ROS都由OSRF（Open Source Robotics Foundation）开源机器人组织来维护，Gazebo支持很多开源的物理引擎比如最典型的ODE。可以进行机器人的运动学、动力学仿真，能够模拟机器人常用的传感器（如激光雷达、摄像头、IMU等），也可以加载自定义的环境和场景。 仿真的意义 仿真不仅仅只是做出一个很酷的3D场景，更重要的是给机器人一个逼近现实的虚拟物理环境，比如光照条件、物理距离等等。设定好具体的参数，让机器人完成我们设定的目标任务。比如一些有危险因素的测试，就可以让机器人在仿真的环境中去完成，例如无人车在交通环境复杂的交通要道的效果，我们就可以在仿真的环境下测试各种情况无人车的反应与效果，如车辆的性能、驾驶的策略、车流人流的行为模式等，又或者各种不可控因素如雨雪天气，突发事故，车辆故障等，从而收集结果参数指标信息等等，只有更大程度的逼近现实，才能得出车辆的真实效果。直到无人车在仿真条件下做到万无一失，才能放心的投放到真实环境中去使用，这即避免了危险因素对实验者的威胁，也节约了时间和资源，这就是仿真的意义。 通常一些不依赖于具体硬件的算法和场景都可以在Gazebo上仿真，例如图像识别、传感器数据融合处理、路径规划、SLAM等任务完全可以在Gazebo上仿真实现，大大减轻了对硬件的依赖。 演示 和我们前面的实例测试一样，我们打开教材的模拟场景，输入roslaunch robot_sim_demo robot_spawn_launch 操作说明 平移：鼠标左键 旋转：鼠标滚轮中键 放缩：鼠标滚轮 -界面左侧是控制面板 导入模型就在控制面板的insert,可以直接拖入模拟空间，也可以按需自制模型拖入。小结 虽然Gazebo目前的功能还称不上强大，同时还存在着一些BUG，但是对于我们的入门学习也已经是足够了，随着版本的更新，Gazebo也在越来越强大。 RViz 简介 本节课介绍的是我们在ROS开发中非常常用的一个工具，基本上的调试和开发都离不开这个工具——RViz(the Robit Visualization tool)机器人可视化工具，可视化的作用是直观的，它极大的方便了监控和调试等操作。 演示 依然打开教材的模拟场景，输入roslaunch robot_sim_demo robot_spawn_launch，之后在命令行打开新的终端直接输入$ rviz 打开工具。 和Gazebo一样，也会显示出一个3D环境，不过操作上有所不同，具体操作如下： 平移：鼠标滚轮中键 旋转：鼠标左键 放缩：鼠标滚轮 左侧控制面板，可以添加插件 RViz的插件种类繁多功能强大，非常适合我们开发调试ROS程序。 差异 虽然从界面上来看，RViz和Gazebo非常相似，但实际上两者有着很大的不同，Gazebo实现的是仿真，提供一个虚拟的世界，RViz实现的是可视化，呈现接收到的信息。左侧的插件相当于是一个个的subscriber,RViz接收信息，并且显示。所以RViz和Gazebo有本质的差异。 小结 RViz和Gazebo是我们常用的ROS工具，更好的利用这些工具是我们ROS进阶的基础。具体的操作和使用可以参考我们的官方演示视频，跟着视频去实战演练，熟悉这两个工具。 rqt 简介 rqt是一个基于qt开发的可视化工具，拥有扩展性好、灵活易用、跨平台等特点，主要作用和RViz一致都是可视化，但是和RViz相比，rqt要高级一个层次，。 命令 rqt_graph :显示通信架构 rqt_plot ：绘制曲线 rqt_console ：查看日志 rqt_graph rqt_graph是来显示通信架构，也就是我们上一章所讲的内容节点、主题等等，当前有哪些Node和topic在运行，消息的流向是怎样，都能通过这个语句显示出来。此命令由于能显示系统的全貌，所以非常的常用。 rqt_plot rqt_plot将一些参数，尤其是动态参数以曲线的形式绘制出来。当我们在开发时查看机器人的原始数据，我们就能利用rqt_plot将这些原始数据用曲线绘制出来，非常的直观，利于我们分析数据。 rqt_console rqt_console里存在一些过滤器，我们可以利用它方便的查到我们需要的日志。 实例测试 首先打开我们教材的模拟场景，输入roslaunch robot_sim_demo robot_spawn_launch 输入命令语句rqt_graph,显示出了当前环境下运行的Node和topic，十分直观的看到通信结构以及消息流向。注意在椭圆形的代表节点，矩形代表topic。 输入命令语句rqt_plot,显示出曲线坐标窗口，在上方输入框里添加或者删除topic，比如我们查看速度，可以在框里设置好topic后，移动机器人，就可以看到自动绘制的线速度或者角速度曲线。 输入命令语句rqt_console，显示日志的输出，配合rqt_logger_level查看日志的级别。 小结 rqt_graph这个功能是强大的，它使得我们初学者可以直观的看到ROS的通信架构和信息流，方便我们理解的同时，也使得我们能够最快的纠错等等。rqt_plot绘制数据曲线图，也是极大的帮助我们了解数据的变化态势，理解数据流的作用，用曲线来显示我们的操作，精确直观。rqt_console配合rqt_logger_level，查看日志，对于查找错误和DeBug都有很大帮助。 Rosbag 简介 rosbag是一个这是一套用于记录和回放ROS主题的工具。它旨在提高性能，并避免消息的反序列化和重新排序。rosbag package提供了命令行工具和代码API，可以用C++或者python来编写包。而且rosbag命令行工具和代码API是稳定的，始终保持向后的兼容性。 命令 rosbag对软件包来操作，一个包是ROS用于存储ROS消息数据的文件格式，rosbag命令可以记录、回放和操作包。指令列表如下： 命令 作用 cheak 确定一个包是否可以在当前系统中进行，或者是否可以迁移。 decompress 压缩一个或多个包文件。 filter 解压一个或多个包文件。 fix 在包文件中修复消息，以便在当前系统中播放。 help 获取相关命令指示帮助信息 info 总结一个或多个包文件的内容。 play 以一种时间同步的方式回放一个或多个包文件的内容。 record 用指定主题的内容记录一个包文件。 reindex 重新索引一个或多个包文件。 参考链接 小结 rosbag通过命令行能够对软件包进行很多的操作，更重要的拥有代码API，可以对包进行重新编写。增加一个ROS API，用于通过服务调用与播放和录制节点进行交互。 Rosbridge 简介 Rosbridge是一个用在ROS系统和其他系统之间的一个功能包,就像是它的名字一样,起到一个\"桥梁\"的作用,使得ros系统和其他系统能够进行交互.Rosbridge为非ROS程序提供了一个JSON API,有许多与Rosbridge进行交互的前端，包括一个用于Web浏览器交互的WebSocket服务器。Rosbridge_suite是一个包含Rosbridge的元程序包，用于Rosbridge的各种前端程序包（如WebSocket程序包）和帮助程序包。 协议和实现 Rosbridge主要包含两部分内容:协议(Potocol)和实现(Implementation) 协议 Ｒosbridge Protocol提供了非ROS程序与ROS通信的具体的格式规范，规范基于JSON格式,包括订阅topic，发布message,调用server，设置参数，压缩消息等等．例如订阅topic的格式规范如下： { \"op\": \"subscribe\", \"topic\": \"/cmd_vel\", \"type\": \"geometry_msgs/Twist\" } 此规范与所用的编程语言和传输方式无关，任何可以发送JSON格式的语音和传输方式都可以Rosbridge protocol进行交流，并且与ROS进行交互． 实现 Rosbridge_suite元程序包是实现Ｒosbridge　Protocol并提供WebSocket传输层的包的集合。 这些软件包包括： Rosbridge_library : 核心rosbridge软件包。Rosbridge_library负责获取JSON字符串并将命令发送到ROS，反过来接收处理ROS发过来的信息，将之转换为JSON字符串，并将结果转交给非ROS程序。 rosapi : 通过服务调用来访问某些ROS操作，这些服务通常为ROS客户端库保留的服务．这些操作包括获取和设置参数，获取主题列表等等。 rosbridge_server : 虽然Rosbridge_library提供JSON到ROS转换，但它将传输层留给其他人。Rosbridge_server提供了一个WebSocket连接，所以浏览器可以与ROS“交谈”。Roslibjs是一个浏览器的JavaScript库，可以通过rosbridge_server与ROS进行交流。 安装与使用 安装 Rosbridge是基于ROS的，首先要确保自己正确的安装完成了ROS之后可以启动终端执行命令： sudo apt-get install ros- -rosbridge-server 中间的为自己的ROS版本，依照自己的版本进行安装． 使用 关于更深入的使用，可以参考本课程的视频课程，简单的入门使用可以参考链接如下： 参考链接 moveit! 简介 2012年，一款叫做moveit!的移动操作软件诞生了，moveit！最初在Willow Garage由Sachin Chitta，Ioan Sucan，Gil E. Jones，Acorn Pooley，Suat Gedikli，Dave Hershberger开发，它融合了研究者在运动规划、操纵、3D感知、运动学、控制和导航方面的最新进展，为操作者提供了一个易于使用的平台，使用它可以开发先进的机器人应用，也被广泛应用于工业，商业，研发和其他领域。由于以上特性，moveit！一跃成为在机器人上最广泛使用的开源操作软件，截止2017年，已经被用于超过65台机器人。 moveit!视频链接 使用 moveit!的使用通过为用户提供接口来调用它，包括C++、Python、GUI三种接口。ROS中的move_group节点充当整合器，整合多个独立组件，提供ROS风格的Action和service。move_group通过ROS topic和action与机器人通讯，获取机器人的位置、节点等状态，获取数据再传递给机器人的控制器。 move_group节点获取到节点状态信息或者机器人变换信息时候，会通过控制器的接口去处理这些信息，比如进行坐标转换、规划场景、3D感知。另外，move_group的结构比较容易扩展，不仅具有独立的能力如抓放，运动规划，也可扩展自公共类，但实际作为独立的插件运行。moveit!系统结构图如下： 官网链接 "},"ROS/基础/06-roscpp.html":{"url":"ROS/基础/06-roscpp.html","title":"roscpp","keywords":"","body":"datetime:2022/04/25 10:51 author:nzb Client Library与roscpp Client Library简介 ROS为机器人开发者们提供了不同语言的编程接口，比如C++接口叫做roscpp，Python接口叫做rospy，Java接口叫做rosjava。尽管语言不通，但这些接口都可以用来创建topic、service、param，实现ROS的通信功能。Clinet Lirary有点类似开发中的Helper Class，把一些常用的基本功能做了封装。 目前ROS支持的Clinet Library包括： Client Library 介绍 roscpp ROS的C++库，是目前最广泛应用的ROS客户端库，执行效率高 rospy ROS的Python库，开发效率高，通常用在对运行时间没有太大要求的场合，例如配置、初始化等操作 roslisp ROS的LISP库 roscs Mono/.NET.库，可用任何Mono/.NET语言，包括C#，Iron Python， Iron Ruby等 rosgo ROS Go语言库 rosjava ROS Java语言库 rosnodejs Javascript客户端库 ... ... 目前最常用的只有roscpp和rospy，而其余的语言版本基本都还是测试版。 从开发客户端库的角度看，一个客户端库，至少需要能够包括master注册、名称管理、消息收发等功能。这样才能给开发者提供对ROS通信架构进行配置的方法。 整个ROS包括的packages如下，你可以看到roscpp、rospy处于什么位置。 roscpp roscpp位于/opt/ros/kinetic之下，用C++实现了ROS通信。在ROS中，C++的代码是通过catkin这个编译系统（扩展的CMake）来进行编译构建的。所以简单地理解，你也可以把roscpp就当作为一个C++的库，我们创建一个CMake工程，在其中include了roscpp等ROS的libraries，这样就可以在工程中使用ROS提供的函数了。 通常我们要调用ROS的C++接口，首先就需要#include 。 roscpp的主要部分包括： ros::init() : 解析传入的ROS参数，创建node第一步需要用到的函数 ros::NodeHandle : 和topic、service、param等交互的公共接口 ros::master : 包含从master查询信息的函数 ros::this_node：包含查询这个进程(node)的函数 ros::service：包含查询服务的函数 ros::param：包含查询参数服务器的函数，而不需要用到NodeHandle ros::names：包含处理ROS图资源名称的函数 具体可见：http://docs.ros.org/api/roscpp/html/index.html 以上功能可以分为以下几类： Initialization and Shutdown 初始与关闭 Topics 话题 Services 服务 Parameter Server 参数服务器 Timers 定时器 NodeHandles 节点句柄 Callbacks and Spinning 回调和自旋（或者翻译叫轮询？） Logging 日志 Names and Node Information 名称管理 Time 时钟 Exception 异常 看到这么多接口，千万别觉得复杂，我们日常开发并不会用到所有的功能，你只需对要有一些印象，掌握几个比较常见和重要的用法就足够了。下面我们来介绍关键的用法。 节点初始、关闭以及NodeHandle 当执行一个ROS程序，就被加载到了内存中，就成为了一个进程，在ROS里叫做节点。每一个ROS的节点尽管功能不同，但都有必不可少的一些步骤，比如初始化、销毁，需要通行的场景通常都还需要节点的句柄。 这一节我们来学习Node最基本的一些操作。 初始化节点 对于一个C++写的ROS程序，之所以它区别于普通C++程序，是因为代码中做了两层工作： 调用了ros::init()函数，从而初始化节点的名称和其他信息，一般我们ROS程序一开始都会以这种方式开始。 创建ros::NodeHandle对象，也就是节点的句柄，它可以用来创建Publisher、Subscriber以及做其他事情。 句柄(Handle) 这个概念可以理解为一个“把手”，你握住了门把手，就可以很容易把整扇门拉开，而不必关心门是什么样子。NodeHandle就是对节点资源的描述，有了它你就可以操作这个节点了，比如为程序提供服务、监听某个topic上的消息、访问和修改param等等。 关闭节点 通常我们要关闭一个节点可以直接在终端上按Ctrl+C，系统会自动触发SIGINT句柄来关闭这个进程。 你也可以通过调用ros::shutdown()来手动关闭节点，但通常我们很少这样做。 以下是一个节点初始化、关闭的例子。 #include int main(int argc, char** argv) { ros::init(argc, argv, \"your_node_name\"); ros::NodeHandle nh; //....节点功能 //.... ros::spin();//用于触发topic、service的响应队列 return 0; } 这段代码是最常见的一个ROS程序的执行步骤，通常要启动节点，获取句柄，而关闭的工作系统自动帮我们完成，如果有特殊需要你也可以自定义。你可能很关心句柄可以用来做些什么，接下来我们来看看NodeHandle常用的成员函数。 NodeHandle常用成员函数 NodeHandle是Node的句柄，用来对当前节点进行各种操作。在ROS中，NodeHandle是一个定义好的类，通过include，我们可以创建这个类，以及使用它的成员函数。 NodeHandle常用成员函数包括： //创建话题的publisher ros::Publisher advertise(const string &topic, uint32_t queue_size, bool latch=false); //第一个参数为发布话题的名称 //第二个是消息队列的最大长度，如果发布的消息超过这个长度而没有被接收，那么就的消息就会出队。通常设为一个较小的数即可。 //第三个参数是是否锁存。某些话题并不是会以某个频率发布，比如/map这个topic，只有在初次订阅或者地图更新这两种情况下，/map才会发布消息。这里就用到了锁存。 //创建话题的subscriber ros::Subscriber subscribe(const string &topic, uint32_t queue_size, void(*)(M)); //第一个参数是订阅话题的名称 //第二个参数是订阅队列的长度，如果受到的消息都没来得及处理，那么新消息入队，就消息就会出队 //第三个参数是回调函数指针，指向回调函数来处理接收到的消息 //创建服务的server，提供服务 ros::ServiceServer advertiseService(const string &service, bool(*srv_func)(Mreq &, Mres &)); //第一个参数是service名称 //第二个参数是服务函数的指针，指向服务函数。指向的函数应该有两个参数，分别接受请求和响应。 //创建服务的client ros::ServiceClient serviceClient(const string &service_name, bool persistent=false); //第一个函数式service名称 //第二个参数用于设置服务的连接是否持续，如果为true，client将会保持与远程主机的连接，这样后续的请求会快一些。通常我们设为flase //查询某个参数的值 bool getParam(const string &key, std::string &s); bool getParam (const std::string &key, double &d) const； bool getParam (const std::string &key, int &i) const； //从参数服务器上获取key对应的值，已重载了多个类型 //给参数赋值 void setParam (const std::string &key, const std::string &s) const； void setParam (const std::string &key, const char *s) const; void setParam (const std::string &key, int i) const; //给key对应的val赋值，重载了多个类型的val 可以看出，NodeHandle对象在ROS C++程序里非常重要，各种类型的通信都需要用NodeHandle来创建完成。 下面我们具体来看topic、service和param这三种基本通信方式的写法。 topic in roscpp Topic通信 Topic是ROS里一种异步通信的模型，一般是节点间分工明确，有的只负责发送，有的只负责接收处理。对于绝大多数的机器人应用场景，比如传感器数据收发，速度控制指令的收发，Topic模型是最适合的通信方式。 为了讲明白topic通信的编程思路，我们首先来看topic_demo中的代码,这个程序是一个消息收发的例子： 自定义一个类型为gps的消息（包括位置x，y和工作状态state信息），一个node以一定频率发布模拟的gps消息，另一个node接收并处理，算出到原点的距离。 源代码见ROS-Academy-for-Beginners/topic_demo 创建gps消息 在代码中，我们会用到自定义类型的gps消息，因此就需要来自定义gps消息，在msg路径下创建gps.msg： 见topic_demo/msg/gps.msg string state #工作状态 float32 x #x坐标 float32 y #y坐标 以上就定义了一个gps类型的消息，你可以把它理解成一个C语言中的结构体，类似于 struct gps { string state; float32 x; float32 y; } 在程序中对一个gps消息进行创建修改的方法和对结构体的操作一样。 当你创建完了msg文件，记得修改CMakeLists.txt和package.xml，从而让系统能够编译自定义消息。 在CMakeLists.txt中需要改动 find_package(catkin REQUIRED COMPONENTS roscpp std_msgs message_generation #需要添加的地方 ) add_message_files(FILES gps.msg) #catkin在cmake之上新增的命令，指定从哪个消息文件生成 generate_messages(DEPENDENCIES std_msgs) #catkin新增的命令，用于生成消息 #DEPENDENCIES后面指定生成msg需要依赖其他什么消息，由于gps.msg用到了flaot32这种ROS标准消息，因此需要再把std_msgs作为依赖 package.xml中需要的改动 message_generation message_runtime 当你完成了以上所有工作，就可以回到工作空间，然后编译了。编译完成之后会在devel路径下生成gps.msg对应的头文件，头文件按照C++的语法规则定义了topic_demo::gps类型的数据。 要在代码中使用自定义消息类型，只要#include ，然后声明，按照对结构体操作的方式修改内容即可。 topic_demo::gps mygpsmsg; mygpsmsg.x = 1.6; mygpsmsg.y = 5.5; mygpsmsg.state = \"working\"; 消息发布节点 定义完了消息，就可以开始写ROS代码了。通常我们会把消息收发的两端分成两个节点来写，一个节点就是一个完整的C++程序。 见topic_demo/src/talker.cpp #include #include //自定义msg产生的头文件 int main(int argc, char **argv) { ros::init(argc, argv, \"talker\"); //用于解析ROS参数，第三个参数为本节点名 ros::NodeHandle nh; //实例化句柄，初始化node topic_demo::gps msg; //自定义gps消息并初始化 ... ros::Publisher pub = nh.advertise(\"gps_info\", 1); //创建publisher，往\"gps_info\"话题上发布消息 ros::Rate loop_rate(1.0); //定义发布的频率，1HZ while (ros::ok()) //循环发布msg { ... //处理msg pub.publish(msg);//以1Hz的频率发布msg loop_rate.sleep();//根据前面的定义的loop_rate,设置1s的暂停 } return 0; } 机器人上几乎所有的传感器，几乎都是按照固定频率发布消息这种通信方式来传输数据，只是发布频率和数据类型的区别。 消息接收节点 见topic_demo/src/listener.cpp #include #include #include void gpsCallback(const topic_demo::gps::ConstPtr &msg) { std_msgs::Float32 distance; //计算离原点(0,0)的距离 distance.data = sqrt(pow(msg->x,2)+pow(msg->y,2)); ROS_INFO(\"Listener: Distance to origin = %f, state: %s\",distance.data,msg->state.c_str()); //输出 } int main(int argc, char **argv) { ros::init(argc, argv, \"listener\"); ros::NodeHandle n; ros::Subscriber sub = n.subscribe(\"gps_info\", 1, gpsCallback); //设置回调函数gpsCallback ros::spin(); //ros::spin()用于调用所有可触发的回调函数，将进入循环，不会返回，类似于在循环里反复调用spinOnce() //而ros::spinOnce()只会去触发一次 return 0; } 在topic接收方，有一个比较重要的概念，就是回调(CallBack)，在本例中，回调就是预先给gps_info 话题传来的消息准备一个回调函数，你事先定义好回调函数的操作，本例中是计算到原点的距离。只有当有消息来时，回调函数才会被触发执行。具体去触发的命令就是ros::spin()，它会反复的查看有没有消息来，如果有就会让回调函数去处理。 因此千万不要认为，只要指定了回调函数，系统就回去自动触发，你必须ros::spin()或者ros::spinOnce()才能真正使回调函数生效。 CMakeLists.txt文件修改 在CMakeLists.txt添加以下内容，生成可执行文件 add_executable(talker src/talker.cpp) #生成可执行文件talker add_dependencies(talker topic_demo_generate_messages_cpp) #表明在编译talker前，必须先生编译完成自定义消息 #必须添加add_dependencies，否则找不到自定义的msg产生的头文件 #表明在编译talker前，必须先生编译完成自定义消息 target_link_libraries(talker ${catkin_LIBRARIES}) #链接 add_executable(listener src/listener.cpp ) #声称可执行文件listener add_dependencies(listener topic_demo_generate_messages_cpp) target_link_libraries(listener ${catkin_LIBRARIES})#链接 以上cmake语句告诉catkin编译系统如何去编译生成我们的程序。这些命令都是标准的cmake命令，如果不理解，请查阅cmake教程。 之后经过catkin_make，一个自定义消息+发布接收的基本模型就完成了。 扩展：回调函数与spin()方法 回调函数在编程中是一种重要的方法，在维基百科上的解释是： In computer programming, a callback is any executable code that is passed as an argument to other code, which is expected to call back (execute) the argument at a given time. 回调函数作为参数被传入到了另一个函数中（在本例中传递的是函数指针），在未来某个时刻（当有新的message到达），就会立即执行。Subscriber接收到消息，实际上是先把消息放到一个队列 中去，如图所示。队列的长度在Subscriber构建的时候设置好了。当有spin函数执行，就会去处理消息队列中队首的消息。 spin具体处理的方法又可分为阻塞/非阻塞,单线程/多线程，在ROS函数接口层面我们有4种spin的方式： spin方法 阻塞 线程 ros::spin() 阻塞 单线程 ros::spinOnce() 非阻塞 单线程 ros::MultiThreadedSpin() 阻塞 多线程 ros::AsyncMultiThreadedSpin() 非阻塞 多线程 阻塞与非阻塞的区别我们已经讲了，下面来看看单线程与多线程的区别： 我们常用的spin()、spinOnce()是单个线程逐个处理回调队列里的数据。有些场合需要用到多线程分别处理，则可以用到MultiThreadedSpin()、AsyncMultiThreadedSpin()。 service in roscpp Service通信 Service是一种请求-反馈的通信机制。请求的一方通常被称为客户端，提供服务的一方叫做服务器端。Service机制相比于Topic的不同之处在于： 消息的传输是双向的，有反馈的，而不是单一的流向。 消息往往不会以固定频率传输，不连续，而是在需要时才会向服务器发起请求。 在ROS中如何请求或者提供一个服务，我们来看service_demo的代码：一个节点发出服务请求（姓名，年龄），另一个节点进行服务响应，答复请求。 创建Greeting服务 创建service_demo/Greeting.srv文件，内容包括： string name #短横线上边部分是服务请求的数据 int32 age --- #短横线下面是服务回传的内容。 string feedback srv格式的文件创建后，也需要修改CMakeLissts.txt,在其中加入 add_service_files(FILES Greeting.srv) 其余与添加msg的改动一样。然后进行catkin_make，系统就会生成在代码中可用的Greeting类型。在代码中使用,只需要#include ，然后即可创建该类型的srv。 service_demo::Greeting grt; //grt分为grt.request和grt.response两部分 grt.request.name = \"HAN\"; //不能用grt.name或者grt.age来访问 grt.request.age = \"20\"; ... 新生成的Greeting类型的服务，其结构体的风格更为明显，可以这么理解，一个Greeting服务结构体中嵌套了两个结构体，分别是请求和响应： struct Greeting { struct Request { string name; int age; }request; struct Response { string feedback; }response; } 创建提供服务节点(server) service_demo/srv/server.cpp内容如下： #include #include bool handle_function(service_demo::Greeting::Request &req, service_demo::Greeting::Response &res){ //显示请求信息 ROS_INFO(“Request from %s with age %d”, req.name.c_str(), req.age); //处理请求，结果写入response res.feedback = “Hi ” + req.name + “. I’m server!”; //返回true，正确处理了请求 return true; } int main(int argc, char** argv){ ros::init(argc, argv, “greetings_server”); //解析参数，命名节点 ros::NodeHandle nh; //创建句柄，实例化node ros::ServiceServer service = nh.advertiseService(“greetings”, handle_function); //写明服务的处理函数 ros::spin(); return 0; } 在以上代码中，服务的处理操作都写在handle_function() 中，它的输入参数就是Greeting的Request和Response两部分，而非整个Greeting对象。通常在处理函数中，我们对Requst数据进行需要的操作，将结果写入到Response中。在roscpp中，处理函数返回值是bool型，也就是服务是否成功执行。不要理解成输入Request，返回Response，在rospy中是这样的。 创建服务请求节点(client) service_demo/srv/client.cpp内容如下： # include \"ros/ros.h\" # include \"service_demo/Greeting.h\" int main(int argc, char **argv) { ros::init(argc, argv, \"greetings_client\");// 初始化，节点命名为\"greetings_client\" ros::NodeHandle nh; ros::ServiceClient client = nh.serviceClient(\"greetings\"); // 定义service客户端，service名字为“greetings”，service类型为Service_demo // 实例化srv，设置其request消息的内容，这里request包含两个变量，name和age，见Greeting.srv service_demo::Greeting srv; srv.request.name = \"HAN\"; srv.request.age = 20; if (client.call(srv)) { // 注意我们的response部分中的内容只包含一个变量response，另，注意将其转变成字符串 ROS_INFO(\"Response from server: %s\", srv.response.feedback.c_str()); } else { ROS_ERROR(\"Failed to call service Service_demo\"); return 1; } return 0; } 以上代码比较关键的地方有两处，一个是建立一个ServiceClient，另一个是开始调用服务。建立client需要用nh.serviceClient(\"greetings\") ，指明服务的类型和服务的名称。而调用时可以直接用client.call(srv)，返回结果不是response，而是是否成功调用远程服务。 CMakeLists.txt和pacakge.xml修改方法和topic_demo修改方法类似，不再赘述。 param in roscpp Parameter Server 严格来说，param并不能称作一种通信方式，因为它往往只是用来存储一些静态的设置，而不是动态变化的。所以关于param的操作非常轻巧，非常简单。 关于param的API，roscpp为我们提供了两套，一套是放在ros::paramnamespace下，另一套是在ros::NodeHandle下，这两套API的操作完全一样，用哪一个取决于你的习惯。 param_demo 我们来看看在C++中如何进行param_demo的操作，param_demo/param.cpp文件，内容包括： #include int main(int argc, char **argv){ ros::init(argc, argv, \"param_demo\"); ros::NodeHandle nh; int parameter1, parameter2, parameter3, parameter4, parameter5; //Get Param的三种方法 //① ros::param::get()获取参数“param1”的value，写入到parameter1上 bool ifget1 = ros::param::get(\"param1\", parameter1); //② ros::NodeHandle::getParam()获取参数，与①作用相同 bool ifget2 = nh.getParam(\"param2\",parameter2); //③ ros::NodeHandle::param()类似于①和② //但如果get不到指定的param，它可以给param指定一个默认值(如33333) nh.param(\"param3\", parameter3, 33333); if(ifget1) //param是否取得 ... //Set Param //① ros::param::set()设置参数 parameter4 = 4; ros::param::set(\"param4\", parameter4); //② ros::NodeHandle::setParam()设置参数 parameter5 = 5; nh.setParam(\"param5\",parameter5); //Check Param //① ros::NodeHandle::hasParam() bool ifparam5 = nh.hasParam(\"param5\"); //② ros::param::has() bool ifparam6 = ros::param::has(\"param6\"); //Delete Param //① ros::NodeHandle::deleteParam() bool ifdeleted5 = nh.deleteParam(\"param5\"); //② ros::param::del() bool ifdeleted6 = ros::param::del(\"param6\"); ... } 以上是roscpp中对param进行增删改查所有操作的方法，非常直观。 param_demo中的launch文件 实际项目中我们对参数进行设置，尤其是添加参数，一般都不是在程序中，而是在launch文件中。因为launch文件可以方便的修改参数，而写成代码之后，修改参数必须重新编译。 因此我们会在launch文件中将param都定义好，比如这个demo正确的打开方式应该是roslaunch param_demo param_demo_cpp.launch param_demo/launch/param_demo_cpp.launch内容为： param3: 3 param4: 4 param5: 5 通过和两个标签我们设置好了5个param，从而在之前的代码中进行增删改查的操作。 命名空间对param的影响 在实际的项目中，实例化句柄时，经常会看到两种不同的写法 ros::NodeHandle n; ros::NodeHandle nh(\"~\");` 这两种写法有什么不同呢？以本教学报的name_demo为例。在本节launch文件夹的demo.launch定义两个参数，一个全局serial 他的数值是5,一个是局部的serial，他的数值是10. 在name_demo.cpp中，我们分别尝试了，利用全局命名空间句柄提取全局的param和局部的param，以及在局部命名空间下的句柄提取全局的param和局部的param，详细的代码如下： #include int main(int argc, char* argv[]) { int serial_number = -1;//serial_number初始化 ros::init(argc, argv, \"name_demo\");//node初始化 /*创建命名空间*/ //n 是全局命名空间 ros::NodeHandle n; //nh 是局部命名空间 ros::NodeHandle nh(\"~\"); /*全局命名空间下的Param*/ ROS_INFO(\"global namespace\"); //提取全局命名空间下的参数serial n.getParam(\"serial\", serial_number); ROS_INFO(\"global_Serial was %d\", serial_number); //提取局部命名空间下的参数serial n.getParam(\"name_demo/serial\", serial_number);//在全局命名空间下，要提取局部命名空间下的参数，需要添加node name ROS_INFO(\"global_to_local_Serial was %d\", serial_number); /*局部命名空间下的Param*/ ROS_INFO(\"local namespace\"); //提取局部命名空间下的参数serial nh.getParam(\"serial\", serial_number); ROS_INFO(\"local_Serial was %d\", serial_number); //提取全局命名空间下的参数serial nh.getParam(\"/serial\", serial_number);//在局部命名空间下，要提取全局命名空间下的参数，需要添加“/” ROS_INFO(\"local_to_global_Serial was %d\", serial_number); ros::spin(); return 0; } 最后的结果 [ INFO] [1525095241.802257811]: global namespace [ INFO] [1525095241.803512501]: global_Serial was 5 [ INFO] [1525095241.804515959]: global_to_local_Serial was 10 [ INFO] [1525095241.804550167]: local namespace [ INFO] [1525095241.805126562]: local_Serial was 10 [ INFO] [1525095241.806137701]: local_to_global_Serial was 5 时钟 Time 与 Duration ROS里经常用到的一个功能就是时钟，比如计算机器人移动距离、设定一些程序的等待时间、设定计时器等等。roscpp同样给我们提供了时钟方面的操作。 具体来说，roscpp里有两种时间的表示方法，一种是时刻（ros:: Time），一种是时长（ros::Duration）。无论是Time还是Duration都具有相同的表示方法： int32 sec int32 nsec Time/Duration都由秒和纳秒组成。 要使用Time和Duration，需要#include 和#include ros::Time begin = ros::Time::now(); //获取当前时间 ros::Time at_some_time1(5,20000000); //5.2s ros::Time at_some_time2(5.2) //同上，重载了float类型和两个uint类型的构造函数 ros::Duration one_hour(60*60,0); //1h double secs1 = at_some_time1.toSec();//将Time转为double型时间 double secs2 = one_hour.toSec();//将Duration转为double型时间 Time和Duration表示的概念并不相同，Time指的是某个时刻，而Duration指的是某个时段，尽管他们的数据结构都相同，但是用在不同的场景下。 ROS为我们重载了Time、Duration类型之间的加减运算，比如: ros::Time t1 = ros::Time::now() - ros::Duration(5.5); //t1是5.5s前的时刻，Time加减Duration返回都是Time ros::Time t2 = ros::Time::now() + ros::Duration(3.3);//t2是当前时刻往后推3.3s的时刻 ros::Duration d1 = t2 - t1;//从t1到t2的时长，两个Time相减返回Duration类型 ros::Duration d2 = d1 -ros::Duration(0,300);//两个Duration相减，还是Duration 以上是Time、Duration之间的加减运算，要注意没有Time+Time的做法。 sleep 通常在机器人任务执行中可能有需要等待的场景，这时就要用到sleep功能，roscpp中提供了两种sleep的方法： ros::Duration(0.5).sleep(); //用Duration对象的sleep方法休眠 ros::Rate r(10); //10HZ while(ros::ok()) { r.sleep(); //定义好sleep的频率，Rate对象会自动让整个循环以10hz休眠，即使有任务执行占用了时间 } Timer Rate的功能是指定一个频率，让某些动作按照这个频率来循环执行。与之类似的是ROS中的定时器Timer，它是通过设定回调函数和触发时间来实现某些动作的反复执行，创建方法和topic中的subscriber很像。 void callback1(const ros::TimerEvent&) { ROS_INFO(\"Callback 1 triggered\"); } void callback2(const ros::TimerEvent&) { ROS_INFO(\"Callback 2 triggered\"); } int main(int argc, char **argv) { ros::init(argc, argv, \"talker\"); ros::NodeHandle n; ros::Timer timer1 = n.createTimer(ros::Duration(0.1), callback1); //timer1每0.1s触发一次callback1函数 ros::Timer timer2 = n.createTimer(ros::Duration(1.0), callback2); //timer2每1.0s触发一次callback2函数 ros::spin(); //千万别忘了spin，只有spin了才能真正去触发回调函数 return 0; } 日志和异常 Log ROS为开发者和用户提供了一套日志记录和输出系统，这套系统的实现方式是基于topic，也就是每个节点都会把一些日志信息发到一个统一的topic上去，这个topic就是/rosout。 rosout 本身也是一个node，它专门负责进行日志的记录。我们在启动master的时候，系统就会附带启动rosout。 在roscpp中进行日志的输出，需要先include ,这个头文件包括了五个级别的日志输出接口，分别是： DEBUG INFO WARN ERROR FATAL 用法非常简单： ROS_DEBUG(\"The velocity is %f\", vel); ROS_WARN(\"Warn: the use is deprecated.\"); ROS_FATAL(\"Cannot start this node.\"); ... 当然也可以在一些特定场景，特定条件下输出，不过对于普通开发者来说可能用不到这么复杂的功能。具体可参考：http://wiki.ros.org/roscpp/Overview/Logging Exception roscpp中有两种异常类型，当有以下两种错误时，就会抛出异常： ros::InvalidNodeNameException 当无效的基础名称传给ros::init(),通常是名称中有/,就会触发 ros::InvalidNameExcaption 当无效名称传给了roscpp "},"ROS/基础/07-rospy.html":{"url":"ROS/基础/07-rospy.html","title":"rospy","keywords":"","body":"datetime:2022/04/25 10:51 author:nzb rospy与主要接口 rospy vs roscpp rospy是Python版本的ROS客户端库，提供了Python编程需要的接口，你可以认为rospy就是一个Python的模块(Module) 。这个模块位于/opt/ros/kineetic/lib/python2.7/dist-packages/rospy之中。 rospy包含的功能与roscpp相似，都有关于node、topic、service、param、time相关的操作。但同时rospy和roscpp也有一些区别： rospy没有一个NodeHandle，像创建publisher、subscriber等操作都被直接封装成了rospy中的函数或类，调用起来简单直观。 rospy一些接口的命名和roscpp不一致，有些地方需要开发者注意，避免调用错误。 相比于C++的开发，用Python来写ROS程序开发效率大大提高，诸如显示、类型转换等细节不再需要我们注意，节省时间。但Python的执行效率较低，同样一个功能用Python运行的耗时会高于C++。因此我们开发SLAM、路径规划、机器视觉等方面的算法时，往往优先选择C++。 ROS中绝大多数基本指令，例如rostopic,roslaunch都是用python开发的，简单轻巧。 ROS中Python代码的组织方式 要介绍rospy，就不得不提Python代码在ROS中的组织方式。通常来说，Python代码有两种组织方式，一种是单独的一个Python脚本，适用于简单的程序，另一种是Python模块，适合体量较大的程序。 单独的Python脚本 对于一些小体量的ROS程序，一般就是一个Python文件，放在script/路径下，非常简单。 your_package |- script/ |- your_script.py |-... Python模块 当程序的功能比较复杂，放在一个脚本里搞不定时，就需要把一些功能放到Python Module里，以便其他的脚本来调用。ROS建议我们按照以下规范来建立一个Python的模块： your_package |- src/ |-your_package/ |- _init_.py |- modulefiles.py |- scripts/ |- your_script.py |- setup.py 在src下建立一个与你的package同名的路径，其中存放_init_.py以及你的模块文件。这样就建立好了ROS规范的Python模块，你可以在你的脚本中调用。 如果你不了解init.py 的作用，可以参考这篇博客 ROS中的这种Python模块组织规范与标准的Python模块规范并不完全一致，你当然可以按照Python的标准去建立一个模块，然后在你的脚本中调用，但是我们还是建议按照ROS推荐的标准来写，这样方便别人去阅读。 通常我们常用的ROS命令，大多数其实都是一个个Python模块，源代码存放在ros_comm 仓库的tools路径下你可以看到每一个命令行工具（如rosbag、rosmsg）都是用模块的形式组织核心代码，然后在script/下建立一个脚本来调用模块。 常用rospy的API 这里分类整理了rospy常见的一些用法，请你浏览一遍，建立一个初步的影响。 具体API 请查看 Node相关 返回值 方法 作用 rospy.init_node(name, argv=None, anonymous=False) 注册和初始化node MasterProxy rospy.get_master() 获取master的句柄 bool rospy.is_shutdown() 节点是否关闭 rospy.on_shutdown(fn) 在节点关闭时调用fn函数 str get_node_uri() 返回节点的URI str get_name() 返回本节点的全名 str get_namespace() 返回本节点的名字空间 ... ... ... Topic相关 函数： 返回值 方法 作用 [[str, str]] get_published_topics() 返回正在被发布的所有topic名称和类型 Message wait_for_message(topic, topic_type, time_out=None) 等待某个topic的message spin() 触发topic或service的回调/处理函数，会阻塞直到关闭节点 ... ... ... Publisher类： 返回值 方法 作用 __init__(self, name, data_class, queue_size=None) 构造函数 publish(self, msg) 发布消息 str unregister(self) 停止发布 ... ... ... Subscriber类： 返回值 方法 作用 __init__(self, name, data_class, call_back=None, queue_size=None) 构造函数 unregister(self, msg) 停止订阅 ... ... ... Service相关 函数： 返回值 方法 作用 wait_for_service(service, timeout=None) 阻塞直到服务可用 ... ... ... Service类(server)： 返回值 方法 作用 __init__(self, name, service_class, handler) 构造函数，handler为处理函数，service_class为srv类型 shutdown(self) 关闭服务的server ... ... ... ServiceProxy类(client)： 返回值 方法 作用 __init__(self, name, service_class) 构造函数，创建client call(self, args, *kwds) 发起请求 __call__(self, args, *kwds) 同上 close(self) 关闭服务的client ... ... ... Param相关 函数： 返回值 方法 作用 XmlRpcLegalValue get_param(param_name, default=_unspecified) 获取参数的值 [str] get_param_names() 获取参数的名称 set_param(param_name, param_value) 设置参数的值 delete_param(param_name) 删除参数 bool has_param(param_name) 参数是否存在于参数服务器上 str search_param() 搜索参数 ... ... ... 时钟相关 函数： 返回值 方法 作用 Time get_rostime() 获取当前时刻的Time对象 float get_time() 返回当前时间，单位秒 sleep(duration) 执行挂起 ... ... ... Time类： 返回值 方法 作用 __init__(self, secs=0, nsecs=0) 构造函数 Time now() 静态方法 返回当前时刻的Time对象 ... ... ... Duration类： 返回值 方法 作用 __init__(self, secs=0, nsecs=0) 构造函数 ... ... ... topic in rospy 与roscpp类似，我们用python来写一个节点间消息收发的demo，同样还是创建一个自定义的gps类型的消息，一个节点发布模拟的gps信息，另一个接收和计算距离原点的距离。 自定义消息的生成 gps.msg定义如下： string state #工作状态 float32 x #x坐标 float32 y #y坐标 我们需要修改CMakeLists.txt文件，方法见5.3节，这里需要强调一点的就是，对创建的msg进行catkin_make 会在~/catkin_ws/devel/lib/python2.7/dist-packages/topic_demo下生成msg模块（module）。 有了这个模块，我们就可以在python程序中from topic_demo.msg import gps,从而进行gps类型消息的读写。 消息发布节点 与C++的写法类似，我们来看topic用Python如何编写程序，见topic_demo/scripts/pytalker.py： import rospy # 导入自定义的数据类型 from topic_demo.msg import gps def talker(): # Publisher 函数第一个参数是话题名称，第二个参数 数据类型，现在就是我们定义的msg 最后一个是缓冲区的大小 # queue_size: None（不建议） #这将设置为阻塞式同步收发模式！ # queue_size: 0（不建议）#这将设置为无限缓冲区模式，很危险！ # queue_size: 10 or more #一般情况下，设为10 。queue_size太大了会导致数据延迟不同步。 pub = rospy.Publisher('gps_info', gps, queue_size=10) rospy.init_node('pytalker', anonymous=True) # 更新频率是1hz rate = rospy.Rate(1) x = 1.0 y = 2.0 state = 'working' while not rospy.is_shutdown(): # 计算距离 rospy.loginfo('Talker: GPS: x=%f ,y= %f', x, y) pub.publish(gps(state, x, y)) x = 1.03 * x y = 1.01 * y rate.sleep() if __name__ == '__main__': talker() 以上代码与C++的区别体现在这几个方面： rospy创建和初始化一个node，不再需要用NodeHandle。rospy中没有设计NodeHandle这个句柄，我们创建topic、service等等操作都直接用rospy里对应的方法就行。 rospy中节点的初始化并一定得放在程序的开头，在Publisher建立后再初始化也没问题。 消息的创建更加简单，比如gps类型的消息可以直接用类似于构造函数的方式gps(state,x,y)来创建。 日志的输出方式不同，C++中是ROS_INFO()，而Python中是rospy.loginfo() 判断节点是否关闭的函数不同，C++用的是ros::ok()而Python中的接口是rospy.is_shutdown() 通过以上的区别可以看出，roscpp和rospy的接口并不一致，在名称上要尽量避免混用。在实现原理上，两套客户端库也有各自的实现，并没有基于一个统一的核心库来开发。这也是ROS在设计上不足的地方。 ROS2就解决了这个问题，ROS2中的客户端库包括了rclcpp(ROS Clinet Library C++)、rclpy(ROS Client Library Python) ,以及其他语言的版本，他们都是基于一个共同的核心ROS客户端库rcl来开发的，这个核心库由C语言实现。 消息订阅节点 见topic_demo/scripts/pylistener.py： import rospy import math # 导入mgs from topic_demo.msg import gps # 回调函数输入的应该是msg def callback(gps): distance = math.sqrt(math.pow(gps.x, 2) + math.pow(gps.y, 2)) rospy.loginfo('Listener: GPS: distance=%f, state=%s', distance, gps.state) def listener(): rospy.init_node('pylistener', anonymous=True) # Subscriber函数第一个参数是topic的名称，第二个参数是接受的数据类型 第三个参数是回调函数的名称 rospy.Subscriber('gps_info', gps, callback) rospy.spin() if __name__ == '__main__': listener() 在订阅节点的代码里，rospy与roscpp有一个不同的地方：rospy里没有spinOnce()，只有spin()。 建立完talker和listener之后，经过catkin_make，就完成了python版的topic通信模型。 Service in rospy 本节用python来写一个节点间，利用Service通信的demo，与5.4类似，创建一个节点，发布模拟的gps信息，另一个接收和计算距离原点的距离。 srv文件 在5.4节，我们已经说过要建立一个名为Greeting.srv的服务文件，内容如下： string name #短横线上边部分是服务请求的数据 int32 age --- #短横线下面是服务回传的内容 string feedback 然后修改CMakeLists.txt 文件。ROS的catkin编译系统会将你自定义的msg、srv（甚至还有action）文件自动编译构建，生成对应的C++、Python、LISP等语言下可用的库或模块。许多初学者错误地以为，只要建立了一个msg或srv文件，就可以直接在程序中使用，这是不对的，必须在CMakeLists.txt 中添加关于消息创建、指定消息/服务文件那几个宏命令。 创建提供服务节点(server) 见service_demo/scripts/server_demo.py： import rospy from service_demo.srv import * def server_srv(): # 初始化节点，命名为 \"greetings_server\" rospy.init_node(\"greetings_server\") # 定义service的server端，service名称为\"greetings\"， service类型为Greeting # 收到的request请求信息将作为参数传递给handle_function进行处理 s = rospy.Service(\"greetings\", Greeting, handle_function) rospy.loginfo(\"Ready to handle the request:\") # 阻塞程序结束 rospy.spin() def handle_function(req): # 注意我们是如何调用request请求内容的，是将其认为是一个对象的属性，在我们定义 # 的Service_demo类型的service中，request部分的内容包含两个变量，一个是字符串类型的name，另外一个是整数类型的age rospy.loginfo('Request from %s with age %d', req.name, req.age) # 返回一个Service_demo.Response实例化对象，其实就是返回一个response的对象，其包含的内容为我们在Service_demo.srv中定义的 # response部分的内容，我们定义了一个string类型的变量feedback，因此，此处实例化时传入字符串即可 return GreetingResponse(\"Hi %s. I' server!\" % req.name) # 如果单独运行此文件，则将上面定义的server_srv作为主函数运行 if __name__ == \"__main__\": server_srv() 以上代码中可以看出Python和C++在ROS服务通信时，server端的处理函数有区别： C++的handle_function() 传入的参数是整个srv对象的request和response两部分，返回值是bool型，显示这次服务是否成功的处理，也就是： bool handle_function(service_demo::Greeting::Request &req, service_demo::Greeting::Response &res){ ... return true; } 而Python的handle_function()传入的只有request，返回值是response，即： def handle_function(req): ... return GreetingResponse(\"Hi %s. I' server!\"%req.name) 这也是ROS在两种语言编程时的差异之一。相比来说Python的这种思维方式更加简单，符合我们的思维习惯。 创建服务请求节点(client) service_demo/srv/client.cpp内容如下： import rospy from service_demo.srv import * def client_srv(): rospy.init_node('greetings_client') # 等待有可用的服务 \"greetings\" rospy.wait_for_service(\"greetings\") try: # 定义service客户端，service名称为“greetings”，service类型为Greeting greetings_client = rospy.ServiceProxy(\"greetings\", Greeting) # 向server端发送请求，发送的request内容为name和age,其值分别为\"HAN\", 20 # 此处发送的request内容与srv文件中定义的request部分的属性是一致的 # resp = greetings_client(\"HAN\",20) resp = greetings_client.call(\"HAN\", 20) rospy.loginfo(\"Message From server:%s\" % resp.feedback) except rospy.ServiceException, e: rospy.logwarn(\"Service call failed: %s\" % e) # 如果单独运行此文件，则将上面函数client_srv()作为主函数运行 if __name__ == \"__main__\": client_srv() 以上代码中greetings_client.call(\"HAN\",20)等同于greetings_client(\"HAN\",20)。 param与time param_demo 相比roscpp中有两套对param操作的API，rospy关于param的函数就显得简单多了，包括了增删查改等用法： rospy.get_param() rospy.set_param() rospy.has_param() rospy.delete_param() rospy.search_param() rospy.get_param_names() 下面我们来看看param_demo里的代码： import rospy def param_demo(): rospy.init_node(\"param_demo\") rate = rospy.Rate(1) while (not rospy.is_shutdown()): # get param parameter1 = rospy.get_param(\"/param1\") parameter2 = rospy.get_param(\"/param2\", default=222) rospy.loginfo('Get param1 = %d', parameter1) rospy.loginfo('Get param2 = %d', parameter2) # delete param rospy.delete_param('/param2') # set param rospy.set_param('/param2', 2) # check param ifparam3 = rospy.has_param('/param3') if (ifparam3): rospy.loginfo('/param3 exists') else: rospy.loginfo('/param3 does not exist') # get all param names params = rospy.get_param_names() rospy.loginfo('param list: %s', params) rate.sleep() if __name__ == \"__main__\": param_demo() time_demo 时钟 rospy中的关于时钟的操作和roscpp是一致的，都有Time、Duration和Rate三个类。 首先，Time和Duration前者标识的是某个时刻（例如今天22:00），而Duration表示的是时长(例如一周) 。但他们具有相同的结构（秒和纳秒）： int32 secs int32 secs 创建Time和Duration rospy中的Time和Duration的构造函数类似，都是_init_(self,secs=0, nsecs=0),指定秒和纳秒(1ns = 10^-9 s) time_now1 = rospy.get_rostime() # 当前时刻的Time对象 返回Time对象 time_now2 = rospy.Time.now() # 同上 time_now3 = rospy.get_time() # 得到当前时间，返回float 4单位秒 time_4 = rospy.Time(5) # 创建5s的时刻 duration = rospy.Duration(3 * 60) # 创建3min时长 关于Time、Duration之间的加减法和类型转换，和roscpp中的完全一致，请参考5.6节，此处不再重复。 sleep duration.sleep() # 挂起 rospy.sleep(duration) # 同上，这两种方式效果完全一致 loop_rate = Rate(5) # 利用Rate来控制循环频率 while (rospy.is_shutdown()): loop_rate.sleep() # 挂起，会考虑上次loop_rate.sleep的时间 关于sleep的方法，Rate类中的sleep主要用来保持一个循环按照固定的频率，循环中一般都是发布消息、执行周期性任务的操作。这里的sleep会考虑上次sleep的时间，从而使整个循环严格按照指定的频率。 定时器Timer rospy里的定时器和roscpp中的也类似，只不过不是用句柄来创建，而是直接rospy.Timer(Duration, callback)，第一个参数是时长，第二个参数是回调函数。 def my_callback(event): print 'Timer called at ' + str(event.current_real) rospy.Timer(rospy.Duration(2), my_callback) # 每2s触发一次callback函数 rospy.spin() 同样不要忘了rospy.spin()，只有spin才能触发回调函数。 回调函数的传入值是TimerEvent类型，该类型包括以下几个属性： rospy.TimerEvent last_expected 理想情况下为上一次回调应该发生的时间 last_real 上次回调实际发生的时间 current_expected 本次回调应该发生的时间 current_real 本次回调实际发生的时间 last_duration 上次回调所用的时间（结束-开始） "},"ROS/进阶/源码分析/00-ros-logs.html":{"url":"ROS/进阶/源码分析/00-ros-logs.html","title":"ros-logs","keywords":"","body":"datetime:2023/01/30 11:41 author:nzb ROS 日志 roscore 日志 [roslaunch][INFO] 2023-01-16 14:40:47,556: Checking log directory for disk usage. This may take awhile. Press Ctrl-C to interrupt [roslaunch][INFO] 2023-01-16 14:40:47,601: Done checking log file disk usage. Usage is [roslaunch.pmon][INFO] 2023-01-16 14:40:48,723: start_process_monitor: ProcessMonitor started [roslaunch.parent][INFO] 2023-01-16 14:40:48,723: starting parent XML-RPC server [roslaunch.server][INFO] 2023-01-16 14:40:48,723: starting roslaunch XML-RPC server [roslaunch.server][INFO] 2023-01-16 14:40:48,724: waiting for roslaunch XML-RPC server to initialize [xmlrpc][INFO] 2023-01-16 14:40:48,724: XML-RPC server binding to 0.0.0.0:0 [xmlrpc][INFO] 2023-01-16 14:40:48,725: Started XML-RPC server [http://192.168.111.111:35647/] [xmlrpc][INFO] 2023-01-16 14:40:48,726: xml rpc node: starting XML-RPC server [roslaunch][INFO] 2023-01-16 14:40:48,737: started roslaunch server http://192.168.111.111:35647/ [roslaunch.parent][INFO] 2023-01-16 14:40:48,738: ... parent XML-RPC server started [roslaunch][INFO] 2023-01-16 14:40:48,739: master.is_running[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:48,751: auto-starting new master [roslaunch][INFO] 2023-01-16 14:40:48,752: create_master_process: rosmaster, /opt/ros/melodic/share/ros, 11311, 3, None, False [roslaunch][INFO] 2023-01-16 14:40:48,752: process[master]: launching with args [['rosmaster', '--core', '-p', '11311', '-w', '3']] [roslaunch.pmon][INFO] 2023-01-16 14:40:48,753: ProcessMonitor.register[master] [roslaunch.pmon][INFO] 2023-01-16 14:40:48,753: ProcessMonitor.register[master] complete [roslaunch][INFO] 2023-01-16 14:40:48,753: process[master]: starting os process [roslaunch][INFO] 2023-01-16 14:40:48,753: process[master]: start w/ args [['rosmaster', '--core', '-p', '11311', '-w', '3', '__log:=/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/master.log']] [roslaunch][INFO] 2023-01-16 14:40:48,754: process[master]: cwd will be [/root/.ros] [roslaunch][INFO] 2023-01-16 14:40:49,535: process[master]: started with pid [46] [roslaunch][INFO] 2023-01-16 14:40:49,536: master.is_running[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:49,638: master.is_running[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:49,739: master.is_running[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:49,840: master.is_running[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:49,942: master.is_running[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:50,043: master.is_running[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:50,048: master.is_running[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:50,051: ROS_MASTER_URI=http://192.168.111.111:11311/ [roslaunch][INFO] 2023-01-16 14:40:50,054: setting /run_id to b598afc4-9568-11ed-b4d9-00044bde2742 [roslaunch][INFO] 2023-01-16 14:40:50,057: setting /roslaunch/uris/host_192_168_111_111__35647' to http://192.168.111.111:35647/ [roslaunch][INFO] 2023-01-16 14:40:50,064: ... preparing to launch node of type [rosout/rosout] [roslaunch][INFO] 2023-01-16 14:40:50,064: create_node_process: package[rosout] type[rosout] machine[Machine(name[] env_loader[None] address[localhost] ssh_port[22] user[None] assignable[True] timeout[10.0])] master_uri[http://192.168.111.111:11311/] [roslaunch][INFO] 2023-01-16 14:40:50,065: process[rosout-1]: env[{'ROS_DISTRO': 'melodic', 'ROS_IP': '192.168.111.111', 'ROS_PACKAGE_PATH': '/opt/ros/melodic/share', 'PATH': '/opt/ros/melodic/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'CMAKE_PREFIX_PATH': '/opt/ros/melodic', 'ROS_LOG_FILENAME': '/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/roslaunch-tegra-ubuntu-29.log', 'LANG': 'C.UTF-8', 'TERM': 'xterm', 'SHLVL': '1', 'LD_LIBRARY_PATH': '/opt/ros/melodic/lib', 'ROS_MASTER_URI': 'http://192.168.111.111:11311/', 'HOME': '/root', 'ROS_PYTHON_VERSION': '2', 'PYTHONPATH': '/opt/ros/melodic/lib/python2.7/dist-packages', 'ROS_ROOT': '/opt/ros/melodic/share/ros', 'PKG_CONFIG_PATH': '/opt/ros/melodic/lib/pkgconfig', 'LC_ALL': 'C.UTF-8', '_': '/usr/bin/nohup', 'HOSTNAME': 'tegra-ubuntu', 'ROSLISP_PACKAGE_DIRECTORIES': '', 'PWD': '/', 'ROS_ETC_DIR': '/opt/ros/melodic/etc/ros', 'ROS_VERSION': '1'}] [roslaunch][INFO] 2023-01-16 14:40:50,095: process[rosout-1]: args[[u'/opt/ros/melodic/lib/rosout/rosout', u'__name:=rosout']] [roslaunch][INFO] 2023-01-16 14:40:50,096: ... created process [rosout-1] [roslaunch.pmon][INFO] 2023-01-16 14:40:50,096: ProcessMonitor.register[rosout-1] [roslaunch.pmon][INFO] 2023-01-16 14:40:50,097: ProcessMonitor.register[rosout-1] complete [roslaunch][INFO] 2023-01-16 14:40:50,097: ... registered process [rosout-1] [roslaunch][INFO] 2023-01-16 14:40:50,097: process[rosout-1]: starting os process [roslaunch][INFO] 2023-01-16 14:40:50,098: process[rosout-1]: start w/ args [[u'/opt/ros/melodic/lib/rosout/rosout', u'__name:=rosout', u'__log:=/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/rosout-1.log']] [roslaunch][INFO] 2023-01-16 14:40:50,098: process[rosout-1]: cwd will be [/root/.ros] [roslaunch][INFO] 2023-01-16 14:40:50,847: process[rosout-1]: started with pid [59] [roslaunch][INFO] 2023-01-16 14:40:50,848: ... successfully launched [rosout-1] [roslaunch][INFO] 2023-01-16 14:40:50,849: load_parameters starting ... [roslaunch][INFO] 2023-01-16 14:40:50,858: ... load_parameters complete [roslaunch][INFO] 2023-01-16 14:40:50,858: launch_nodes: launching local nodes ... [roslaunch][INFO] 2023-01-16 14:40:50,858: ... launch_nodes complete [roslaunch.pmon][INFO] 2023-01-16 14:40:50,858: registrations completed [roslaunch.parent][INFO] 2023-01-16 14:40:50,859: ... roslaunch parent running, waiting for process exit [roslaunch][INFO] 2023-01-16 14:40:50,859: spin master 日志 [rosmaster.main][INFO] 2023-01-16 14:40:49,996: initialization complete, waiting for shutdown [rosmaster.main][INFO] 2023-01-16 14:40:49,996: Starting ROS Master Node [xmlrpc][INFO] 2023-01-16 14:40:49,999: XML-RPC server binding to 0.0.0.0:11311 [rosmaster.master][INFO] 2023-01-16 14:40:50,000: Master initialized: port[11311], uri[http://192.168.111.111:11311/] [xmlrpc][INFO] 2023-01-16 14:40:50,000: Started XML-RPC server [http://192.168.111.111:11311/] [xmlrpc][INFO] 2023-01-16 14:40:50,001: xml rpc node: starting XML-RPC server [rosmaster.master][INFO] 2023-01-16 14:40:50,056: +PARAM [/run_id] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:50,059: +PARAM [/roslaunch/uris/host_192_168_111_111__35647] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:50,856: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:50,856: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:51,065: +SERVICE [/rosout/get_loggers] /rosout http://192.168.111.111:38431/ [rosmaster.master][INFO] 2023-01-16 14:40:51,067: +SERVICE [/rosout/set_logger_level] /rosout http://192.168.111.111:38431/ [rosmaster.master][INFO] 2023-01-16 14:40:51,072: +PUB [/rosout_agg] /rosout http://192.168.111.111:38431/ [rosmaster.master][INFO] 2023-01-16 14:40:51,078: +SUB [/rosout] /rosout http://192.168.111.111:38431/ [rosmaster.master][INFO] 2023-01-16 14:40:51,157: +PARAM [/roslaunch/uris/host_192_168_111_111__33083] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:51,165: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:51,165: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:51,166: +PARAM [/robot_description] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:51,166: +PARAM [/robot_state_publisher/publish_frequency] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:40:52,534: +PUB [/rosout] /joint_state_publisher http://192.168.111.111:41129/ [rosmaster.master][INFO] 2023-01-16 14:40:52,542: +SERVICE [/joint_state_publisher/get_loggers] /joint_state_publisher http://192.168.111.111:41129/ [rosmaster.master][INFO] 2023-01-16 14:40:52,546: +SERVICE [/joint_state_publisher/set_logger_level] /joint_state_publisher http://192.168.111.111:41129/ [rosmaster.master][INFO] 2023-01-16 14:40:52,577: +PUB [/joint_states] /joint_state_publisher http://192.168.111.111:41129/ [rosmaster.master][INFO] 2023-01-16 14:40:52,604: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/'] [rosmaster.master][INFO] 2023-01-16 14:40:52,833: +PUB [/rosout] /robot_state_publisher http://192.168.111.111:43717/ [rosmaster.master][INFO] 2023-01-16 14:40:52,834: +SERVICE [/robot_state_publisher/get_loggers] /robot_state_publisher http://192.168.111.111:43717/ [rosmaster.master][INFO] 2023-01-16 14:40:52,835: +SERVICE [/robot_state_publisher/set_logger_level] /robot_state_publisher http://192.168.111.111:43717/ [rosmaster.master][INFO] 2023-01-16 14:40:52,844: +PUB [/tf] /robot_state_publisher http://192.168.111.111:43717/ [rosmaster.master][INFO] 2023-01-16 14:40:52,846: +PUB [/tf_static] /robot_state_publisher http://192.168.111.111:43717/ [rosmaster.master][INFO] 2023-01-16 14:40:52,857: +SUB [/joint_states] /robot_state_publisher http://192.168.111.111:43717/ [rosmaster.master][INFO] 2023-01-16 14:40:52,945: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/']: sec=0.34, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:40:52,945: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/'] [rosmaster.master][INFO] 2023-01-16 14:40:52,948: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:20,906: +PARAM [/roslaunch/uris/host_192_168_111_111__45309] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:20,915: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:20,915: +PARAM [/scans_concat_filter/output_frame_id] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:20,916: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:20,916: +PARAM [/scans_concat_filter/input_topics] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,195: +PARAM [/roslaunch/uris/host_192_168_111_111__35101] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,205: +PARAM [/rear/r2000_node/samples_per_scan] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,205: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,205: +PARAM [/rear/r2000_node/frame_id] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,206: +PARAM [/front/r2000_node/scan_frequency] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,206: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,207: +PARAM [/rear/r2000_node/scan_frequency] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,207: +PARAM [/rear/r2000_node/scanner_ip] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,207: +PARAM [/front/r2000_node/frame_id] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,208: +PARAM [/front/r2000_node/scanner_ip] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:21,208: +PARAM [/front/r2000_node/samples_per_scan] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:22,026: +PUB [/rosout] /front/r2000_node http://192.168.111.111:45843/ [rosmaster.master][INFO] 2023-01-16 14:41:22,028: +SERVICE [/front/r2000_node/get_loggers] /front/r2000_node http://192.168.111.111:45843/ [rosmaster.master][INFO] 2023-01-16 14:41:22,029: +SERVICE [/front/r2000_node/set_logger_level] /front/r2000_node http://192.168.111.111:45843/ [rosmaster.master][INFO] 2023-01-16 14:41:22,057: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/'] [rosmaster.master][INFO] 2023-01-16 14:41:22,059: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:22,154: +PUB [/rosout] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:22,155: +SERVICE [/scans_concat_filter/get_loggers] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:22,156: +SERVICE [/scans_concat_filter/set_logger_level] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:22,160: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/'] [rosmaster.master][INFO] 2023-01-16 14:41:22,162: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:22,169: +SUB [/tf] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:22,207: +SUB [/tf_static] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:22,472: +PUB [/front/scan_dense] /front/r2000_node http://192.168.111.111:45843/ [rosmaster.master][INFO] 2023-01-16 14:41:22,475: +PUB [/front/scan] /front/r2000_node http://192.168.111.111:45843/ [rosmaster.master][INFO] 2023-01-16 14:41:22,483: +PUB [/front/r2000_node/diagno_msg] /front/r2000_node http://192.168.111.111:45843/ [rosmaster.master][INFO] 2023-01-16 14:41:22,509: +SUB [/front/r2000_node/control_command] /front/r2000_node http://192.168.111.111:45843/ [rosmaster.master][INFO] 2023-01-16 14:41:22,858: +PUB [/rosout] /rear/r2000_node http://192.168.111.111:39017/ [rosmaster.master][INFO] 2023-01-16 14:41:22,859: +SERVICE [/rear/r2000_node/get_loggers] /rear/r2000_node http://192.168.111.111:39017/ [rosmaster.master][INFO] 2023-01-16 14:41:22,861: +SERVICE [/rear/r2000_node/set_logger_level] /rear/r2000_node http://192.168.111.111:39017/ [rosmaster.master][INFO] 2023-01-16 14:41:22,864: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/'] [rosmaster.master][INFO] 2023-01-16 14:41:22,867: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:23,240: +SUB [/front/scan] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:23,247: +SUB [/rear/scan] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:23,277: +PUB [/cloud] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:23,287: +SUB [/odom] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:23,289: +PUB [/front_t] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:23,292: +PUB [/rear_t] /scans_concat_filter http://192.168.111.111:39961/ [rosmaster.master][INFO] 2023-01-16 14:41:23,313: +PUB [/rear/scan_dense] /rear/r2000_node http://192.168.111.111:39017/ [rosmaster.master][INFO] 2023-01-16 14:41:23,316: +PUB [/rear/scan] /rear/r2000_node http://192.168.111.111:39017/ [rosmaster.master][INFO] 2023-01-16 14:41:23,318: +PUB [/rear/r2000_node/diagno_msg] /rear/r2000_node http://192.168.111.111:39017/ [rosmaster.master][INFO] 2023-01-16 14:41:23,330: +SUB [/rear/r2000_node/control_command] /rear/r2000_node http://192.168.111.111:39017/ [rosmaster.master][INFO] 2023-01-16 14:41:23,367: publisherUpdate[/rear/scan] -> http://192.168.111.111:39961/ ['http://192.168.111.111:39017/'] [rosmaster.master][INFO] 2023-01-16 14:41:23,384: +PARAM [/roslaunch/uris/host_192_168_111_111__45005] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:23,390: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:23,391: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:23,391: +PARAM [/obstacle_detection/obstacle_source] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:23,490: +PUB [/rosout] /slam_hal http://192.168.111.111:41995/ [rosmaster.master][INFO] 2023-01-16 14:41:23,491: +SERVICE [/slam_hal/get_loggers] /slam_hal http://192.168.111.111:41995/ [rosmaster.master][INFO] 2023-01-16 14:41:23,494: +SERVICE [/slam_hal/set_logger_level] /slam_hal http://192.168.111.111:41995/ [rosmaster.master][INFO] 2023-01-16 14:41:23,500: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/'] [rosmaster.master][INFO] 2023-01-16 14:41:23,502: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:23,504: +PUB [/odom] /slam_hal http://192.168.111.111:41995/ [rosmaster.master][INFO] 2023-01-16 14:41:23,512: +PUB [/dsp_pos] /slam_hal http://192.168.111.111:41995/ [rosmaster.master][INFO] 2023-01-16 14:41:23,526: +SUB [/cur_pose] /slam_hal http://192.168.111.111:41995/ [rosmaster.master][INFO] 2023-01-16 14:41:23,744: publisherUpdate[/rear/scan] -> http://192.168.111.111:39961/ ['http://192.168.111.111:39017/']: sec=0.38, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:23,745: publisherUpdate[/odom] -> http://192.168.111.111:39961/ ['http://192.168.111.111:41995/'] [rosmaster.master][INFO] 2023-01-16 14:41:23,747: publisherUpdate[/odom] -> http://192.168.111.111:39961/ ['http://192.168.111.111:41995/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:34,941: +PARAM [/roslaunch/uris/host_192_168_111_111__35333] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:34,949: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:34,950: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:38,019: +PUB [/rosout] /charging_pile_recognition http://192.168.111.111:42095/ [rosmaster.master][INFO] 2023-01-16 14:41:38,020: +SERVICE [/charging_pile_recognition/get_loggers] /charging_pile_recognition http://192.168.111.111:42095/ [rosmaster.master][INFO] 2023-01-16 14:41:38,021: +SERVICE [/charging_pile_recognition/set_logger_level] /charging_pile_recognition http://192.168.111.111:42095/ [rosmaster.master][INFO] 2023-01-16 14:41:38,037: +SUB [/tf] /charging_pile_recognition http://192.168.111.111:42095/ [rosmaster.master][INFO] 2023-01-16 14:41:38,043: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/'] [rosmaster.master][INFO] 2023-01-16 14:41:38,049: +SUB [/tf_static] /charging_pile_recognition http://192.168.111.111:42095/ [rosmaster.master][INFO] 2023-01-16 14:41:38,055: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/']: sec=0.01, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:38,060: +SUB [/cloud] /charging_pile_recognition http://192.168.111.111:42095/ [rosmaster.master][INFO] 2023-01-16 14:41:38,072: +SERVICE [/GetChargingPilePose] /charging_pile_recognition http://192.168.111.111:42095/ [rosmaster.master][INFO] 2023-01-16 14:41:46,985: +PARAM [/roslaunch/uris/host_tegra_ubuntu__43647] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:46,993: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:46,993: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:46,994: +PARAM [/operate_qslam_c/config_file] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:48,255: +PUB [/rosout] /operate_qslam_c http://tegra-ubuntu:32835/ [rosmaster.master][INFO] 2023-01-16 14:41:48,262: +SERVICE [/operate_qslam_c/get_loggers] /operate_qslam_c http://tegra-ubuntu:32835/ [rosmaster.master][INFO] 2023-01-16 14:41:48,264: +SERVICE [/operate_qslam_c/set_logger_level] /operate_qslam_c http://tegra-ubuntu:32835/ [rosmaster.master][INFO] 2023-01-16 14:41:48,270: +SUB [/quicktron/switch_mode] /operate_qslam_c http://tegra-ubuntu:32835/ [rosmaster.master][INFO] 2023-01-16 14:41:48,273: +SERVICE [/quicktron/increment_mapping] /operate_qslam_c http://tegra-ubuntu:32835/ [rosmaster.master][INFO] 2023-01-16 14:41:48,275: +SERVICE [/convert_map] /operate_qslam_c http://tegra-ubuntu:32835/ [rosmaster.master][INFO] 2023-01-16 14:41:48,278: +SERVICE [/operate_qslam_c] /operate_qslam_c http://tegra-ubuntu:32835/ [rosmaster.master][INFO] 2023-01-16 14:41:48,303: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/'] [rosmaster.master][INFO] 2023-01-16 14:41:48,306: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:41:58,455: +PARAM [/roslaunch/uris/host_192_168_111_111__46555] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:58,474: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:58,474: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:58,503: +PARAM [/roslaunch/uris/host_192_168_111_111__44533] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:58,512: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:58,513: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:58,529: +PARAM [/roslaunch/uris/host_192_168_111_111__35149] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:58,540: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:58,540: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:41:59,926: +PUB [/rosout] /operate_qslam_m http://192.168.111.111:45739/ [rosmaster.master][INFO] 2023-01-16 14:41:59,936: +SERVICE [/operate_qslam_m/get_loggers] /operate_qslam_m http://192.168.111.111:45739/ [rosmaster.master][INFO] 2023-01-16 14:41:59,940: +SERVICE [/operate_qslam_m/set_logger_level] /operate_qslam_m http://192.168.111.111:45739/ [rosmaster.master][INFO] 2023-01-16 14:41:59,950: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/'] [rosmaster.master][INFO] 2023-01-16 14:41:59,952: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:00,112: +PUB [/rosout] /operate_qslam_a http://192.168.111.111:41973/ [rosmaster.master][INFO] 2023-01-16 14:42:00,128: +SERVICE [/operate_qslam_a/get_loggers] /operate_qslam_a http://192.168.111.111:41973/ [rosmaster.master][INFO] 2023-01-16 14:42:00,137: +SERVICE [/operate_qslam_a/set_logger_level] /operate_qslam_a http://192.168.111.111:41973/ [rosmaster.master][INFO] 2023-01-16 14:42:00,153: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/'] [rosmaster.master][INFO] 2023-01-16 14:42:00,158: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:00,278: +PUB [/rosout] /operate_cold_start http://192.168.111.111:40973/ [rosmaster.master][INFO] 2023-01-16 14:42:00,281: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/'] [rosmaster.master][INFO] 2023-01-16 14:42:00,284: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:00,299: +SERVICE [/operate_cold_start/get_loggers] /operate_cold_start http://192.168.111.111:40973/ [rosmaster.master][INFO] 2023-01-16 14:42:00,306: +SERVICE [/operate_cold_start/set_logger_level] /operate_cold_start http://192.168.111.111:40973/ [rosmaster.master][INFO] 2023-01-16 14:42:00,309: +SERVICE [/operate_cold_start] /operate_cold_start http://192.168.111.111:40973/ [rosmaster.master][INFO] 2023-01-16 14:42:01,828: +PARAM [/roslaunch/uris/host_192_168_111_111__33225] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:01,842: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:01,842: +PARAM [/use_sim_time] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:01,842: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:01,843: +PARAM [/mekf_node/cfg_file_path] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,102: +PARAM [/roslaunch/uris/host_192_168_111_111__42169] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,116: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,117: +PARAM [/use_sim_time] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,117: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,118: +PARAM [/map_server_new/config_dir] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,584: +PARAM [/roslaunch/uris/host_192_168_111_111__43933] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,598: +PARAM [/use_sim_time] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,598: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,599: +PARAM [/cold_start_node/load_state_filename] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,599: +PARAM [/cold_start_node/configuration_directory] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,600: +PARAM [/cold_start_node/barcode_priority] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,600: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,601: +PARAM [/cold_start_node/init_theta] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,601: +PARAM [/cold_start_node/configuration_basename] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,607: +PARAM [/cold_start_node/reflector_priority] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,607: +PARAM [/cold_start_node/init_y] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,608: +PARAM [/cold_start_node/init_x] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:42:02,671: +SERVICE [/operate_qslam_m_new] /operate_qslam_m http://192.168.111.111:45739/ [rosmaster.master][INFO] 2023-01-16 14:42:02,674: +SERVICE [/operate_qslam_m] /operate_qslam_m http://192.168.111.111:45739/ [rosmaster.master][INFO] 2023-01-16 14:42:03,309: +PUB [/rosout] /map_server_new http://192.168.111.111:34787/ [rosmaster.master][INFO] 2023-01-16 14:42:03,312: +SERVICE [/map_server_new/get_loggers] /map_server_new http://192.168.111.111:34787/ [rosmaster.master][INFO] 2023-01-16 14:42:03,314: +SERVICE [/map_server_new/set_logger_level] /map_server_new http://192.168.111.111:34787/ [rosmaster.master][INFO] 2023-01-16 14:42:03,331: +SERVICE [/reload_map_service_with_init_pose] /map_server_new http://192.168.111.111:34787/ [rosmaster.master][INFO] 2023-01-16 14:42:03,335: +SERVICE [/static_map] /map_server_new http://192.168.111.111:34787/ [rosmaster.master][INFO] 2023-01-16 14:42:03,336: +PUB [/map_metadata] /map_server_new http://192.168.111.111:34787/ [rosmaster.master][INFO] 2023-01-16 14:42:03,337: +PUB [/map] /map_server_new http://192.168.111.111:34787/ [rosmaster.master][INFO] 2023-01-16 14:42:03,338: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/'] [rosmaster.master][INFO] 2023-01-16 14:42:03,341: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:04,282: +SERVICE [/operate_qslam_a] /operate_qslam_a http://192.168.111.111:41973/ [rosmaster.master][INFO] 2023-01-16 14:42:04,314: +PUB [/rosout] /odom_tf http://192.168.111.111:33181/ [rosmaster.master][INFO] 2023-01-16 14:42:04,316: +SERVICE [/odom_tf/get_loggers] /odom_tf http://192.168.111.111:33181/ [rosmaster.master][INFO] 2023-01-16 14:42:04,317: +SERVICE [/odom_tf/set_logger_level] /odom_tf http://192.168.111.111:33181/ [rosmaster.master][INFO] 2023-01-16 14:42:04,320: +PUB [/tf] /odom_tf http://192.168.111.111:33181/ [rosmaster.master][INFO] 2023-01-16 14:42:04,327: +SUB [/tf] /odom_tf http://192.168.111.111:33181/ [rosmaster.master][INFO] 2023-01-16 14:42:04,341: +SUB [/tf_static] /odom_tf http://192.168.111.111:33181/ [rosmaster.master][INFO] 2023-01-16 14:42:04,347: +SUB [/odom] /odom_tf http://192.168.111.111:33181/ [rosmaster.master][INFO] 2023-01-16 14:42:04,347: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/'] [rosmaster.master][INFO] 2023-01-16 14:42:04,355: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/']: sec=0.01, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:04,356: publisherUpdate[/tf] -> http://192.168.111.111:39961/ ['http://192.168.111.111:43717/', 'http://192.168.111.111:33181/'] [rosmaster.master][INFO] 2023-01-16 14:42:04,357: publisherUpdate[/tf] -> http://192.168.111.111:39961/ ['http://192.168.111.111:43717/', 'http://192.168.111.111:33181/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:04,358: publisherUpdate[/tf] -> http://192.168.111.111:42095/ ['http://192.168.111.111:43717/', 'http://192.168.111.111:33181/'] [rosmaster.master][INFO] 2023-01-16 14:42:04,770: publisherUpdate[/tf] -> http://192.168.111.111:42095/ ['http://192.168.111.111:43717/', 'http://192.168.111.111:33181/']: sec=0.41, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:16,918: +SUB [/cur_pose] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,922: +SUB [/robot_mode] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,924: +SUB [/cold_start_status] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,928: +SUB [/map_cloud] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,931: +SUB [/scan_matched_points2] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,934: +SUB [/barcode] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,937: +SUB [/barcode_poses_list] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,940: +SUB [/carto_pose_confidence] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,943: +SUB [/ipu_pos] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,946: +SUB [/landmarks] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,949: +SUB [/map] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,952: +SUB [/mapping_process] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,955: +SUB [/dsp_pos] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,957: +SUB [/reflector_pose_with_confidence] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:16,961: +SUB [/landmark_poses_list] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:17,015: +PUB [/rosout] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:17,025: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/'] [rosmaster.master][INFO] 2023-01-16 14:42:17,028: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:17,029: +SERVICE [/StateCenter/get_loggers] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:17,032: +SERVICE [/StateCenter/set_logger_level] /StateCenter http://192.168.111.111:38243/ [rosmaster.master][INFO] 2023-01-16 14:42:18,699: +PUB [/rosout] /UdpBarrier http://192.168.111.111:40901/ [rosmaster.master][INFO] 2023-01-16 14:42:18,707: +SERVICE [/UdpBarrier/get_loggers] /UdpBarrier http://192.168.111.111:40901/ [rosmaster.master][INFO] 2023-01-16 14:42:18,710: +SERVICE [/UdpBarrier/set_logger_level] /UdpBarrier http://192.168.111.111:40901/ [rosmaster.master][INFO] 2023-01-16 14:42:18,719: +SUB [/new_obstacles] /UdpBarrier http://192.168.111.111:40901/ [rosmaster.master][INFO] 2023-01-16 14:42:18,724: +SUB [/obstacle_detection_all_sensors/sensor_states] /UdpBarrier http://192.168.111.111:40901/ [rosmaster.master][INFO] 2023-01-16 14:42:18,743: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/'] [rosmaster.master][INFO] 2023-01-16 14:42:18,745: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:25,158: +SUB [/error_status] /upper_computer_withWebUI http://192.168.111.111:42321/ [rosmaster.master][INFO] 2023-01-16 14:42:25,170: +SUB [/cold_start_status] /upper_computer_withWebUI http://192.168.111.111:42321/ [rosmaster.master][INFO] 2023-01-16 14:42:25,258: +PUB [/rosout] /upper_computer_withWebUI http://192.168.111.111:42321/ [rosmaster.master][INFO] 2023-01-16 14:42:25,278: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/'] [rosmaster.master][INFO] 2023-01-16 14:42:25,280: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:25,301: +SERVICE [/upper_computer_withWebUI/get_loggers] /upper_computer_withWebUI http://192.168.111.111:42321/ [rosmaster.master][INFO] 2023-01-16 14:42:25,313: +SERVICE [/upper_computer_withWebUI/set_logger_level] /upper_computer_withWebUI http://192.168.111.111:42321/ [rosmaster.master][INFO] 2023-01-16 14:42:25,318: +SUB [/error_msg] /upper_computer_withWebUI http://192.168.111.111:42321/ [rosmaster.master][INFO] 2023-01-16 14:42:28,033: +PUB [/rosout] /Communication http://192.168.111.111:42289/ [rosmaster.master][INFO] 2023-01-16 14:42:28,039: +SERVICE [/Communication/get_loggers] /Communication http://192.168.111.111:42289/ [rosmaster.master][INFO] 2023-01-16 14:42:28,042: +SERVICE [/Communication/set_logger_level] /Communication http://192.168.111.111:42289/ [rosmaster.master][INFO] 2023-01-16 14:42:28,043: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/'] [rosmaster.master][INFO] 2023-01-16 14:42:28,045: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 14:42:28,219: +SERVICE [/RcsOnline] /Communication http://192.168.111.111:42289/ [rosmaster.master][INFO] 2023-01-16 14:42:28,221: +SERVICE [/RcsOffline] /Communication http://192.168.111.111:42289/ [rosmaster.master][INFO] 2023-01-16 14:59:59,187: +PARAM [/roslaunch/uris/host_172_31_242_250__35161] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:59:59,194: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:59:59,194: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:59:59,195: +PARAM [/obstacle_detection_all_sensors/use_slam_pos] by /roslaunch [rosmaster.master][INFO] 2023-01-16 14:59:59,195: +PARAM [/obstacle_detection_all_sensors/filter_distance] by /roslaunch [rosmaster.master][INFO] 2023-01-16 15:00:00,624: +SERVICE [/obstacle_detection_all_sensors/get_loggers] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:00,626: +SERVICE [/obstacle_detection_all_sensors/set_logger_level] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:00,628: +SERVICE [/obstacle_detection_all_sensors/barrier_operation] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:00,630: +PUB [/obstacle_detection_all_sensors/sensor_states] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:00,633: publisherUpdate[/obstacle_detection_all_sensors/sensor_states] -> http://192.168.111.111:40901/ ['http://172.31.242.250:38867/'] [rosmaster.master][INFO] 2023-01-16 15:00:00,637: publisherUpdate[/obstacle_detection_all_sensors/sensor_states] -> http://192.168.111.111:40901/ ['http://172.31.242.250:38867/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:00:19,342: +PUB [/rosout] /barrier_operation_client http://172.31.242.250:42379/ [rosmaster.master][INFO] 2023-01-16 15:00:19,344: +SERVICE [/barrier_operation_client/get_loggers] /barrier_operation_client http://172.31.242.250:42379/ [rosmaster.master][INFO] 2023-01-16 15:00:19,346: +SERVICE [/barrier_operation_client/set_logger_level] /barrier_operation_client http://172.31.242.250:42379/ [rosmaster.master][INFO] 2023-01-16 15:00:19,359: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/', 'http://172.31.242.250:42379/'] [rosmaster.master][INFO] 2023-01-16 15:00:19,359: +PUB [/new_obstacles] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:19,362: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/', 'http://172.31.242.250:42379/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:00:19,362: +PUB [/oa_box] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:19,363: publisherUpdate[/new_obstacles] -> http://192.168.111.111:40901/ ['http://172.31.242.250:38867/'] [rosmaster.master][INFO] 2023-01-16 15:00:19,364: +PUB [/oa_concave] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:19,366: publisherUpdate[/new_obstacles] -> http://192.168.111.111:40901/ ['http://172.31.242.250:38867/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:00:19,367: +PUB [/error_msg] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:19,367: publisherUpdate[/error_msg] -> http://192.168.111.111:42321/ ['http://172.31.242.250:38867/'] [rosmaster.master][INFO] 2023-01-16 15:00:19,369: +PUB [/obstacle_detection_all_sensors/raw_cloud] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:19,370: +PUB [/obstacle_detection_all_sensors/area_filter_cloud] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:19,371: publisherUpdate[/error_msg] -> http://192.168.111.111:42321/ ['http://172.31.242.250:38867/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:00:19,372: +PUB [/obstacles_list] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:19,379: +SUB [/front/scan] /obstacle_detection_all_sensors http://172.31.242.250:38867/ [rosmaster.master][INFO] 2023-01-16 15:00:21,567: -PUB [/rosout] /barrier_operation_client http://172.31.242.250:42379/ [rosmaster.master][INFO] 2023-01-16 15:00:21,569: -SERVICE [/barrier_operation_client/get_loggers] /barrier_operation_client rosrpc://172.31.242.250:48941 [rosmaster.master][INFO] 2023-01-16 15:00:21,570: -SERVICE [/barrier_operation_client/set_logger_level] /barrier_operation_client rosrpc://172.31.242.250:48941 [rosmaster.master][INFO] 2023-01-16 15:00:21,577: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/'] [rosmaster.master][INFO] 2023-01-16 15:00:21,579: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:19:44,197: +PARAM [/roslaunch/uris/host_172_31_242_250__42507] by /roslaunch [rosmaster.master][INFO] 2023-01-16 15:19:44,205: +PARAM [/rosversion] by /roslaunch [rosmaster.master][INFO] 2023-01-16 15:19:44,205: +PARAM [/rosdistro] by /roslaunch [rosmaster.master][INFO] 2023-01-16 15:19:44,206: +PARAM [/obstacle_detection_all_sensors/use_slam_pos] by /roslaunch [rosmaster.master][INFO] 2023-01-16 15:19:44,206: +PARAM [/obstacle_detection_all_sensors/filter_distance] by /roslaunch [rosmaster.master][INFO] 2023-01-16 15:19:45,090: +SERVICE [/obstacle_detection_all_sensors/get_loggers] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:45,092: +SERVICE [/obstacle_detection_all_sensors/set_logger_level] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:45,094: +SERVICE [/obstacle_detection_all_sensors/barrier_operation] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:45,096: +PUB [/obstacle_detection_all_sensors/sensor_states] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:45,108: publisherUpdate[/obstacle_detection_all_sensors/sensor_states] -> http://192.168.111.111:40901/ ['http://172.31.242.250:38283/'] [rosmaster.master][INFO] 2023-01-16 15:19:45,111: publisherUpdate[/obstacle_detection_all_sensors/sensor_states] -> http://192.168.111.111:40901/ ['http://172.31.242.250:38283/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:19:50,471: +PUB [/rosout] /barrier_operation_client http://172.31.242.250:32811/ [rosmaster.master][INFO] 2023-01-16 15:19:50,474: +SERVICE [/barrier_operation_client/get_loggers] /barrier_operation_client http://172.31.242.250:32811/ [rosmaster.master][INFO] 2023-01-16 15:19:50,475: +SERVICE [/barrier_operation_client/set_logger_level] /barrier_operation_client http://172.31.242.250:32811/ [rosmaster.master][INFO] 2023-01-16 15:19:50,486: +PUB [/new_obstacles] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:50,488: +PUB [/oa_box] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:50,489: +PUB [/oa_concave] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:50,490: +PUB [/error_msg] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:50,491: +PUB [/obstacle_detection_all_sensors/raw_cloud] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:50,492: +PUB [/obstacle_detection_all_sensors/area_filter_cloud] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:50,493: +PUB [/obstacles_list] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:50,501: +SUB [/front/scan] /obstacle_detection_all_sensors http://172.31.242.250:38283/ [rosmaster.master][INFO] 2023-01-16 15:19:50,522: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/', 'http://172.31.242.250:32811/'] [rosmaster.master][INFO] 2023-01-16 15:19:50,525: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/', 'http://172.31.242.250:32811/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:19:50,525: publisherUpdate[/new_obstacles] -> http://192.168.111.111:40901/ ['http://172.31.242.250:38283/'] [rosmaster.master][INFO] 2023-01-16 15:19:50,528: publisherUpdate[/new_obstacles] -> http://192.168.111.111:40901/ ['http://172.31.242.250:38283/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:19:50,528: publisherUpdate[/error_msg] -> http://192.168.111.111:42321/ ['http://172.31.242.250:38283/'] [rosmaster.master][INFO] 2023-01-16 15:19:50,531: publisherUpdate[/error_msg] -> http://192.168.111.111:42321/ ['http://172.31.242.250:38283/']: sec=0.00, result=[1, '', 0] [rosmaster.master][INFO] 2023-01-16 15:19:52,633: -PUB [/rosout] /barrier_operation_client http://172.31.242.250:32811/ [rosmaster.master][INFO] 2023-01-16 15:19:52,635: -SERVICE [/barrier_operation_client/get_loggers] /barrier_operation_client rosrpc://172.31.242.250:41817 [rosmaster.master][INFO] 2023-01-16 15:19:52,636: -SERVICE [/barrier_operation_client/set_logger_level] /barrier_operation_client rosrpc://172.31.242.250:41817 [rosmaster.master][INFO] 2023-01-16 15:19:52,639: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/'] [rosmaster.master][INFO] 2023-01-16 15:19:52,641: publisherUpdate[/rosout] -> http://192.168.111.111:38431/ ['http://192.168.111.111:41129/', 'http://192.168.111.111:43717/', 'http://192.168.111.111:45843/', 'http://192.168.111.111:39961/', 'http://192.168.111.111:39017/', 'http://192.168.111.111:41995/', 'http://192.168.111.111:42095/', 'http://tegra-ubuntu:32835/', 'http://192.168.111.111:45739/', 'http://192.168.111.111:41973/', 'http://192.168.111.111:40973/', 'http://192.168.111.111:34787/', 'http://192.168.111.111:33181/', 'http://192.168.111.111:38243/', 'http://192.168.111.111:40901/', 'http://192.168.111.111:42321/', 'http://192.168.111.111:42289/']: sec=0.00, result=[1, '', 0] roslaunch 日志 [roslaunch][INFO] 2023-01-16 14:40:50,148: Checking log directory for disk usage. This may take awhile. Press Ctrl-C to interrupt [roslaunch][INFO] 2023-01-16 14:40:50,170: Done checking log file disk usage. Usage is [roslaunch.pmon][INFO] 2023-01-16 14:40:51,128: start_process_monitor: ProcessMonitor started [roslaunch.parent][INFO] 2023-01-16 14:40:51,128: starting parent XML-RPC server [roslaunch.server][INFO] 2023-01-16 14:40:51,128: starting roslaunch XML-RPC server [roslaunch.server][INFO] 2023-01-16 14:40:51,129: waiting for roslaunch XML-RPC server to initialize [xmlrpc][INFO] 2023-01-16 14:40:51,129: XML-RPC server binding to 0.0.0.0:0 [xmlrpc][INFO] 2023-01-16 14:40:51,130: Started XML-RPC server [http://192.168.111.111:33083/] [xmlrpc][INFO] 2023-01-16 14:40:51,131: xml rpc node: starting XML-RPC server [roslaunch][INFO] 2023-01-16 14:40:51,143: started roslaunch server http://192.168.111.111:33083/ [roslaunch.parent][INFO] 2023-01-16 14:40:51,144: ... parent XML-RPC server started [roslaunch][INFO] 2023-01-16 14:40:51,145: master.is_running[http://192.168.111.111:11311] [roslaunch][INFO] 2023-01-16 14:40:51,148: master.is_running[http://192.168.111.111:11311] [roslaunch][INFO] 2023-01-16 14:40:51,151: ROS_MASTER_URI=http://192.168.111.111:11311 [roslaunch][INFO] 2023-01-16 14:40:51,156: setting /roslaunch/uris/host_192_168_111_111__33083' to http://192.168.111.111:33083/ [roslaunch][INFO] 2023-01-16 14:40:51,159: load_parameters starting ... [roslaunch][INFO] 2023-01-16 14:40:51,167: ... load_parameters complete [roslaunch][INFO] 2023-01-16 14:40:51,168: launch_nodes: launching local nodes ... [roslaunch][INFO] 2023-01-16 14:40:51,168: ... preparing to launch node of type [joint_state_publisher/joint_state_publisher] [roslaunch][INFO] 2023-01-16 14:40:51,169: create_node_process: package[joint_state_publisher] type[joint_state_publisher] machine[Machine(name[] env_loader[None] address[localhost] ssh_port[22] user[None] assignable[True] timeout[10.0])] master_uri[http://192.168.111.111:11311] [roslaunch][INFO] 2023-01-16 14:40:51,169: process[joint_state_publisher-1]: env[{'ROS_DISTRO': 'melodic', 'ROS_IP': '192.168.111.111', 'ROS_PACKAGE_PATH': '/opt/ros/melodic/share', 'PATH': '/opt/ros/melodic/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'CMAKE_PREFIX_PATH': '/opt/ros/melodic', 'ROS_LOG_FILENAME': '/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/roslaunch-tegra-ubuntu-30.log', 'LANG': 'C.UTF-8', 'TERM': 'xterm', 'SHLVL': '1', 'LD_LIBRARY_PATH': '/opt/ros/melodic/lib', 'ROS_MASTER_URI': 'http://192.168.111.111:11311', 'HOME': '/root', 'ROS_PYTHON_VERSION': '2', 'PYTHONPATH': '/opt/ros/melodic/lib/python2.7/dist-packages', 'ROS_ROOT': '/opt/ros/melodic/share/ros', 'PKG_CONFIG_PATH': '/opt/ros/melodic/lib/pkgconfig', 'LC_ALL': 'C.UTF-8', '_': '/usr/bin/nohup', 'HOSTNAME': 'tegra-ubuntu', 'ROSLISP_PACKAGE_DIRECTORIES': '', 'PWD': '/', 'ROS_ETC_DIR': '/opt/ros/melodic/etc/ros', 'ROS_VERSION': '1'}] [roslaunch][INFO] 2023-01-16 14:40:51,203: process[joint_state_publisher-1]: args[[u'/opt/ros/melodic/lib/joint_state_publisher/joint_state_publisher', u'__name:=joint_state_publisher']] [roslaunch][INFO] 2023-01-16 14:40:51,203: ... created process [joint_state_publisher-1] [roslaunch.pmon][INFO] 2023-01-16 14:40:51,204: ProcessMonitor.register[joint_state_publisher-1] [roslaunch.pmon][INFO] 2023-01-16 14:40:51,204: ProcessMonitor.register[joint_state_publisher-1] complete [roslaunch][INFO] 2023-01-16 14:40:51,204: ... registered process [joint_state_publisher-1] [roslaunch][INFO] 2023-01-16 14:40:51,205: process[joint_state_publisher-1]: starting os process [roslaunch][INFO] 2023-01-16 14:40:51,205: process[joint_state_publisher-1]: start w/ args [[u'/opt/ros/melodic/lib/joint_state_publisher/joint_state_publisher', u'__name:=joint_state_publisher', u'__log:=/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/joint_state_publisher-1.log']] [roslaunch][INFO] 2023-01-16 14:40:51,205: process[joint_state_publisher-1]: cwd will be [/root/.ros] [roslaunch][INFO] 2023-01-16 14:40:51,957: process[joint_state_publisher-1]: started with pid [78] [roslaunch][INFO] 2023-01-16 14:40:51,958: ... successfully launched [joint_state_publisher-1] [roslaunch][INFO] 2023-01-16 14:40:51,958: ... preparing to launch node of type [robot_state_publisher/robot_state_publisher] [roslaunch][INFO] 2023-01-16 14:40:51,959: create_node_process: package[robot_state_publisher] type[robot_state_publisher] machine[Machine(name[] env_loader[None] address[localhost] ssh_port[22] user[None] assignable[True] timeout[10.0])] master_uri[http://192.168.111.111:11311] [roslaunch][INFO] 2023-01-16 14:40:51,959: process[robot_state_publisher-2]: env[{'ROS_DISTRO': 'melodic', 'ROS_IP': '192.168.111.111', 'ROS_PACKAGE_PATH': '/opt/ros/melodic/share', 'PATH': '/opt/ros/melodic/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'CMAKE_PREFIX_PATH': '/opt/ros/melodic', 'ROS_LOG_FILENAME': '/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/roslaunch-tegra-ubuntu-30.log', 'LANG': 'C.UTF-8', 'TERM': 'xterm', 'SHLVL': '1', 'LD_LIBRARY_PATH': '/opt/ros/melodic/lib', 'ROS_MASTER_URI': 'http://192.168.111.111:11311', 'HOME': '/root', 'ROS_PYTHON_VERSION': '2', 'PYTHONPATH': '/opt/ros/melodic/lib/python2.7/dist-packages', 'ROS_ROOT': '/opt/ros/melodic/share/ros', 'PKG_CONFIG_PATH': '/opt/ros/melodic/lib/pkgconfig', 'LC_ALL': 'C.UTF-8', '_': '/usr/bin/nohup', 'HOSTNAME': 'tegra-ubuntu', 'ROSLISP_PACKAGE_DIRECTORIES': '', 'PWD': '/', 'ROS_ETC_DIR': '/opt/ros/melodic/etc/ros', 'ROS_VERSION': '1'}] [roslaunch][INFO] 2023-01-16 14:40:51,963: process[robot_state_publisher-2]: args[[u'/opt/ros/melodic/lib/robot_state_publisher/robot_state_publisher', u'__name:=robot_state_publisher']] [roslaunch][INFO] 2023-01-16 14:40:51,964: ... created process [robot_state_publisher-2] [roslaunch.pmon][INFO] 2023-01-16 14:40:51,964: ProcessMonitor.register[robot_state_publisher-2] [roslaunch.pmon][INFO] 2023-01-16 14:40:51,964: ProcessMonitor.register[robot_state_publisher-2] complete [roslaunch][INFO] 2023-01-16 14:40:51,965: ... registered process [robot_state_publisher-2] [roslaunch][INFO] 2023-01-16 14:40:51,965: process[robot_state_publisher-2]: starting os process [roslaunch][INFO] 2023-01-16 14:40:51,965: process[robot_state_publisher-2]: start w/ args [[u'/opt/ros/melodic/lib/robot_state_publisher/robot_state_publisher', u'__name:=robot_state_publisher', u'__log:=/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/robot_state_publisher-2.log']] [roslaunch][INFO] 2023-01-16 14:40:51,966: process[robot_state_publisher-2]: cwd will be [/root/.ros] [roslaunch][INFO] 2023-01-16 14:40:52,695: process[robot_state_publisher-2]: started with pid [79] [roslaunch][INFO] 2023-01-16 14:40:52,695: ... successfully launched [robot_state_publisher-2] [roslaunch][INFO] 2023-01-16 14:40:52,696: ... launch_nodes complete [roslaunch.pmon][INFO] 2023-01-16 14:40:52,696: registrations completed [roslaunch.parent][INFO] 2023-01-16 14:40:52,696: ... roslaunch parent running, waiting for process exit [roslaunch][INFO] 2023-01-16 14:40:52,696: spin joint_state_publisher 节点日志 [rospy.client][INFO] 2023-01-16 14:40:52,427: init_node, name[/joint_state_publisher], pid[78] [xmlrpc][INFO] 2023-01-16 14:40:52,428: XML-RPC server binding to 0.0.0.0:0 [xmlrpc][INFO] 2023-01-16 14:40:52,429: Started XML-RPC server [http://192.168.111.111:41129/] [rospy.init][INFO] 2023-01-16 14:40:52,429: ROS Slave URI: [http://192.168.111.111:41129/] [rospy.impl.masterslave][INFO] 2023-01-16 14:40:52,430: _ready: http://192.168.111.111:41129/ [xmlrpc][INFO] 2023-01-16 14:40:52,432: xml rpc node: starting XML-RPC server [rospy.registration][INFO] 2023-01-16 14:40:52,431: Registering with master node http://192.168.111.111:11311 [rospy.init][INFO] 2023-01-16 14:40:52,530: registered with master [rospy.rosout][INFO] 2023-01-16 14:40:52,531: initializing /rosout core topic [rospy.rosout][INFO] 2023-01-16 14:40:52,535: connected to core topic /rosout [rospy.simtime][INFO] 2023-01-16 14:40:52,539: /use_sim_time is not set, will not subscribe to simulated time [/clock] topic [rospy.internal][INFO] 2023-01-16 14:40:53,150: topic[/rosout] adding connection to [/rosout], count 0 [rospy.internal][INFO] 2023-01-16 14:40:53,274: topic[/joint_states] adding connection to [/robot_state_publisher], count 0 "},"ROS/进阶/源码分析/01-roscore与Master启动.html":{"url":"ROS/进阶/源码分析/01-roscore与Master启动.html","title":"roscore与Master启动","keywords":"","body":"datetime:2023/01/16 16:30 author:nzb 1、ros 系统的启动 roscore class map roscore map rospy class map rospy map 该文章分析roslaunch是如何调用这个rosmaster脚本，将roscore，roslaunch，rosmaster联系起来的 启动脚本 #!/bin/bash set -e # setup ros environment source \"/opt/ros/$ROS_DISTRO/setup.bash\" nohup roscore >/logs/roscore.log 2>&1 & # 启动master nohup roslaunch /set_urdf.launch --wait >/logs/set_urdf.log 2>&1 & # 启动节点 exec \"$@\" set_urdf.launch文件 已经运行了ros环境下的相关进程 UID PID PPID C STIME TTY TIME CMD root 1 0 0 09:43 pts/0 00:00:00 /bin/bash root 31 1 0 09:43 pts/0 00:02:12 /usr/bin/python /opt/ros/melodic/bin/roscore root 32 1 0 09:43 pts/0 00:02:12 /usr/bin/python /opt/ros/melodic/bin/roslaunch /set_urdf.launch --wait root 48 31 0 09:43 ? 00:03:04 /usr/bin/python /opt/ros/melodic/bin/rosmaster --core -p 11311 -w 3 __log:=/root/.ros/log/769ca6bc-96d1-11ed-8514-8ec2aee29851/master.log root 65 31 0 09:43 ? 00:01:38 /opt/ros/melodic/lib/rosout/rosout __name:=rosout __log:=/root/.ros/log/769ca6bc-96d1-11ed-8514-8ec2aee29851/rosout-1.log root 94 32 1 09:43 ? 00:05:17 python2 /opt/ros/melodic/lib/joint_state_publisher/joint_state_publisher __name:=joint_state_publisher __log:=/root/.ros/log/769ca6bc-96d1-11ed-8514-8ec2aee29851/joint_state_publisher-1.log root 98 32 0 09:43 ? 00:01:36 /opt/ros/melodic/lib/robot_state_publisher/robot_state_publisher __name:=robot_state_publisher __log:=/root/.ros/log/769ca6bc-96d1-11ed-8514-8ec2aee29851/robot_state_publisher-2.log root 1713 0 0 14:46 pts/1 00:00:01 bash root 2663 1713 0 16:09 pts/1 00:00:00 ps -ef 从进程可以看出 根据父进程ID，可以看出启动脚本执行了roscore和roslaunch两个脚本 roscore 子进程启动了rosmaster 子进程启动了rosout roslaunch 子进程启动了joint_state_publisher 子进程启动了robot_state_publisher 1.1、roscore与Master启动 1.1.1、启动roscore(MasterNode) 执行 roscore 会启动下面三个程序: a ROS Master（主节点） a ROS Parameter Server（参数服务器） a rosout logging node（日志节点） 1.1.2、roscore 脚本 对应的可执行文件是/opt/ros/melodic/bin/roscore, 这是一个python脚本，主要做了2个事情： 解析roscore入参 调用roslaunch.main(['roscore', '--core'] + sys.argv[1:]) #!/usr/bin/python import sys from optparse import OptionParser from rosmaster.master_api import NUM_WORKERS NAME = 'roscore' def _get_optparse(): parser = OptionParser(usage=\"usage: %prog [options]\", prog=NAME, description=\"roscore will start up a ROS Master, a ROS Parameter Server and a rosout logging node\", epilog=\"See http://wiki.ros.org/roscore\" ) parser.add_option(\"-p\", \"--port\", dest=\"port\", default=None, help=\"master port. Only valid if master is launched\", metavar=\"PORT\") parser.add_option(\"-v\", action=\"store_true\", dest=\"verbose\", default=False, help=\"verbose printing\") parser.add_option(\"-w\", \"--numworkers\", dest=\"num_workers\", default=NUM_WORKERS, type=int, help=\"override number of worker threads\", metavar=\"NUM_WORKERS\") parser.add_option(\"-t\", \"--timeout\", dest=\"timeout\", help=\"override the socket connection timeout (in seconds).\", metavar=\"TIMEOUT\") parser.add_option(\"--master-logger-level\", dest=\"master_logger_level\", default=False, type=str, help=\"set rosmaster.master logger level ('debug', 'info', 'warn', 'error', 'fatal')\") return parser parser = _get_optparse() (options, args) = parser.parse_args(sys.argv[1:]) if len(args) > 0: parser.error(\"roscore does not take arguments\") import roslaunch roslaunch.main(['roscore', '--core'] + sys.argv[1:]) 1.1.3、MasterNode 启动流程 1.1.3.1、 创建ROSLaunchParent 源码路径：ros\\melodic\\lib\\python2.7\\dist-packages\\roslaunch\\__init__.py def main(argv=sys.argv): # .... logger = logging.getLogger('roslaunch') # 对应日志：[roslaunch][INFO] 2023-01-18 14:57:35,627: roslaunch starting with args ['roscore', '--core'] # args是上面roscore传进来的参数 logger.info(\"roslaunch starting with args %s\" % str(argv)) # 对应日志：[roslaunch][INFO] 2023-01-18 14:57:35,628: roslaunch env is {'ROS_DISTRO': 'melodic', # 'ROS_IP': '192.168.111.111', 'HOME': '/root', 'PATH': '/opt/ros/melodic/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', # 'ROS_PACKAGE_PATH': '/opt/ros/melodic/share', 'CMAKE_PREFIX_PATH': '/opt/ros/melodic', 'LD_LIBRARY_PATH': '/opt/ros/melodic/lib', # 'LANG': 'C.UTF-8', 'TERM': 'xterm', 'SHLVL': '1', 'ROS_LOG_FILENAME': '/root/.ros/log/769ca6bc-96d1-11ed-8514-8ec2aee29851/roslaunch-quicktron-RK-1753.log', # 'ROS_MASTER_URI': 'http://192.168.111.111:11311', 'ROS_PYTHON_VERSION': '2', 'PYTHONPATH': '/opt/ros/melodic/lib/python2.7/dist-packages', # 'ROS_ROOT': '/opt/ros/melodic/share/ros', 'PKG_CONFIG_PATH': '/opt/ros/melodic/lib/pkgconfig', 'LC_ALL': 'C.UTF-8', '_': '/opt/ros/melodic/bin/roscore', # 'HOSTNAME': 'quicktron-RK', 'ROSLISP_PACKAGE_DIRECTORIES': '', 'PWD': '/', 'ROS_ETC_DIR': '/opt/ros/melodic/etc/ros', 'ROS_VERSION': '1',...} logger.info(\"roslaunch env is %s\" % os.environ) if options.child_name: logger.info('starting in child mode') # ... else: logger.info('starting in server mode') ... # This is a roslaunch parent, spin up parent server and launch processes. # args are the roslaunch files to load from . import parent as roslaunch_parent # force a port binding spec if we are running a core if options.core: options.port = options.port or DEFAULT_MASTER_PORT p = roslaunch_parent.ROSLaunchParent(uuid, args, roslaunch_strs=roslaunch_strs, is_core=options.core, port=options.port, local_only=options.local_only, verbose=options.verbose, force_screen=options.force_screen, force_log=options.force_log, num_workers=options.num_workers, timeout=options.timeout, master_logger_level=options.master_logger_level, show_summary=not options.no_summary, force_required=options.force_required) p.start() p.spin() roscore.xml 配置文件 1.1.3.2、执行start 源码路径：ros\\melodic\\lib\\python2.7\\dist-packages\\roslaunch\\parent.py class ROSLaunchParent(object): def _start_pm(self): # 全局函数，start_process_monitor，移到这里方便过流程，源码路径：ros\\melodic\\lib\\python2.7\\dist-packages\\roslaunch\\pmon.py _pmons = [] _pmon_counter = 0 def start_process_monitor(): global _pmon_counter _pmon_counter += 1 name = \"ProcessMonitor-%s\" % _pmon_counter logger.info(\"start_process_monitor: creating ProcessMonitor\") process_monitor = ProcessMonitor(name) # 继承于Thread try: _shutdown_lock.acquire() _pmons.append(process_monitor) process_monitor.start() logger.info(\"start_process_monitor: ProcessMonitor started\") finally: _shutdown_lock.release() return process_monitor self.pm = start_process_monitor() def _start_infrastructure(self): # 配置文件，roscore.xml if self.config is None: self._load_config() # 启动进程管理 if self.pm is None: self._start_pm() # 启动 roslaunch 运行程序和 XMLRPC 服务 # 依赖：进程管理 if self.server is None: # 1、ROSLaunchParentNode类的继承关系 # 继承关系：xmlrpc.XmlRpcNode -> ROSLaunchNode -> ROSLaunchParentNode # 父类XmlRpcNode最后实例化了XMLRPC：self.server = ThreadingXMLRPCServer((bind_address, port), log_requests) # ROSLaunchParentNode 构造函数里面初始化了 ROSLaunchParentHandler，传给父类用于XMLRPC注册实例，供远程调用 # 2、ROSLaunchParentHandler类的继承关系 # 继承关系：xmlrpc.XmlRpcHandler —> ROSLaunchBaseHandler -> ROSLaunchParentHandler # 该handle用于XMLRPC注册实例，self.server.register_instance(self.handler) self.server = roslaunch.server.ROSLaunchParentNode(self.config, self.pm) self.server.start() # 启动远程基础服务，依赖：配置，进程管理和XMLRPC 服务 # 目前还未知道该方法作用，TODO，待完善 self._start_remote() def start(self, auto_terminate=True): # 加载配置文件，启动 XMLRPC 服务端和进程监控服务 self._start_infrastructure() # 初始化实际的运行程序 # 依赖：配置、进程管理、服务和远程运行程序 # self._init_runner() self.runner = roslaunch.launch.ROSLaunchRunner(self.run_id, self.config, server_uri=self.server.uri, pmon=self.pm, is_core=self.is_core, remote_runner=self.remote_runner, is_rostest=self.is_rostest, num_workers=self.num_workers, timeout=self.timeout, master_logger_level=self.master_logger_level) # 开始启动核心：master + core 节点基于 core.xml配置文件 self.runner.launch() # 1、master 启动流程 # -> self._setup() # -> self._launch_master() # 启动master # -> p = create_master_process() # 创建启动master进程，p为LocalProcess实例，里面指定了的脚本就是 rosmaster # -> self.pm.register_core_proc(p) 或 self.pm.register(p) 提交给进程管理 # -> p.start() # -> subprocess.Popen() # 执行了 rosmaster 脚本 # 2、core 启动流程（rosout 节点就是该处启动，读取配置文件roscore.xml） # -> self._launch_master() 启动成功后 # -> self._launch_core_nodes() # -> self.launch_node(node, core=True) # -> p = create_node_process() # 创建节点进程，p为LocalProcess实例 # -> self.pm.register_core_proc(p) 或 self.pm.register(p) 提交给进程管理 # -> p.start() # -> subprocess.Popen() # 通知进程监视器我们已完成进程注册 if auto_terminate: self.pm.registrations_complete() if self.process_listeners: for l in self.process_listeners: self.runner.pm.add_process_listener(l) # Add listeners to server as well, otherwise they won't be # called when a node on a remote machine dies. self.server.add_process_listener(l) 1.2、rosmaster 脚本 对应的脚本文件路径是/opt/ros/melodic/bin/rosmaster, 这是一个python脚本，从上面得知是通过subprocess.Popen()执行的 import rosmaster rosmaster.rosmaster_main() 1.2.1、main.py 源码路径：ros\\melodic\\lib\\python2.7\\dist-packages\\rosmaster\\main.py # -*-: encoding: utf8 -*- import os import sys import parser import rosmaster.master def rosmaster_main(argv=sys.argv, stdout=sys.stdout, env=os.environ): # ... 解析命令参数 options, args = parser.parse_args(argv[1:]) # only arg that zenmaster supports is __log remapping of logfilename for arg in args: if not arg.startswith('__log:='): parser.error(\"unrecognized arg: %s\" % arg) configure_logging() # rosmaster进程默认监听端口 # DEFAULT_MASTER_PORT=11311 # default port for master's to bind to port = rosmaster.master.DEFAULT_MASTER_PORT if options.port: port = int(options.port) logger.info(\"Starting ROS Master Node\") # 创建Master对象，启动XmlRpcNode # NUM_WORKERS = 3, 用于发送发布更新的通知的线程数 # number of threads we use to send publisher_update notifications master = rosmaster.master.Master(port, options.num_workers) master.start() # 开启 import time while master.ok(): time.sleep(.1) 1.2.2、master.py 源码路径：ros\\melodic\\lib\\python2.7\\dist-packages\\rosmaster\\master.py # -*- encoding: utf8 -*- import logging import time import rosgraph.xmlrpc import rosmaster.master_api DEFAULT_MASTER_PORT = 11311 # default port for master's to bind to class Master(object): def __init__(self, port=DEFAULT_MASTER_PORT, num_workers=rosmaster.master_api.NUM_WORKERS): self.port = port self.num_workers = num_workers def start(self): \"\"\" Start the ROS Master. \"\"\" # 创建一个class ROSMasterHandler(object)对象 self.handler = rosmaster.master_api.ROSMasterHandler(self.num_workers) # 创建一个XmlRpcNode对象 self.master_node = rosgraph.xmlrpc.XmlRpcNode(self.port, self.handler) # 调用XmlRpcNode的start(),其实是新启动一个线程，启动 XMLRPC 服务，端口为11311 self.master_node.start() # poll for initialization while not self.master_node.uri: time.sleep(0.0001) self.uri = self.master_node.uri logging.getLogger('rosmaster.master').info(\"Master initialized: port[%s], uri[%s]\", self.port, self.uri) 1.2.3、master_api.py 源码路径：ros\\melodic\\lib\\python2.7\\dist-packages\\rosmaster\\master_api.py # Master Implementation class ROSMasterHandler(object): \"\"\" XML-RPC handler for ROS master APIs. API routines for the ROS Master Node. The Master Node is a superset of the Slave Node and contains additional API methods for creating and monitoring a graph of slave nodes. By convention, ROS nodes take in caller_id as the first parameter of any API call. The setting of this parameter is rarely done by client code as ros::msproxy::MasterProxy automatically inserts this parameter (see ros::client::getMaster()). \"\"\" def __init__(self, num_workers=NUM_WORKERS): \"\"\"ctor.\"\"\" self.uri = None self.done = False # .... 1.2.4、xmlrpc.py 源码路径：ros\\melodic\\lib\\python2.7\\dist-packages\\rosgraph\\xmlrpc.py # -*- encoding: utf8 -*- class XmlRpcNode(object): \"\"\" Generic XML-RPC node. Handles the additional complexity of binding an XML-RPC server to an arbitrary port. XmlRpcNode is initialized when the uri field has a value. \"\"\" def __init__(self, port=0, rpc_handler=None, on_run_error=None): \"\"\" XML RPC Node constructor :param port: port to use for starting XML-RPC API. Set to 0 or omit to bind to any available port, ``int`` :param rpc_handler: XML-RPC API handler for node, `XmlRpcHandler` :param on_run_error: function to invoke if server.run() throws Exception. Server always terminates if run() throws, but this enables cleanup routines to be invoked if server goes down, as well as include additional debugging. ``fn(Exception)`` \"\"\" # 调用父类构造函数 super(XmlRpcNode, self).__init__() # ① 构造函数传进来的rpc_handler self.handler = rpc_handler # ... def start(self): \"\"\" Initiate a thread to run the XML RPC server. Uses thread.start_new_thread. \"\"\" # ② 启动新线程，线程函数为run() _thread.start_new_thread(self.run, ()) def run(self): self._run() def _run_init(self): logger = logging.getLogger('xmlrpc') try: log_requests = 0 port = self.port or 0 # 0 = any bind_address = rosgraph.network.get_bind_address() logger.info(\"XML-RPC server binding to %s:%d\" % (bind_address, port)) self.server = ThreadingXMLRPCServer((bind_address, port), log_requests) self.port = self.server.server_address[1] # set the port to whatever server bound to if not self.port: self.port = self.server.socket.getsockname()[1] # Python 2.4 assert self.port, \"Unable to retrieve local address binding\" # #528: semi-complicated logic for determining XML-RPC URI # - if ROS_IP/ROS_HOSTNAME is set, use that address # - if the hostname returns a non-localhost value, use that # - use whatever rosgraph.network.get_local_address() returns uri = None override = rosgraph.network.get_address_override() if override: uri = 'http://%s:%s/' % (override, self.port) else: try: hostname = socket.gethostname() if hostname and not hostname == 'localhost' and not hostname.startswith( '127.') and hostname != '::': uri = 'http://%s:%s/' % (hostname, self.port) except: pass if not uri: uri = 'http://%s:%s/' % (rosgraph.network.get_local_address(), self.port) self.set_uri(uri) # log打印Started XML-RPC server [http://lyf:11311/] logger.info(\"Started XML-RPC server [%s]\", self.uri) # ③这里最主要的是下面两个函数，将handler注册到xml-rpc， # handler是个rosmaster.master_api.ROSMasterHandler对象 self.server.register_multicall_functions() # 可同时调用多个注册方法 self.server.register_instance(self.handler) # 注册实例 # ... def _run(self): \"\"\" Main processing thread body. :raises: :exc:`socket.error` If server cannot bind \"\"\" self._run_init() while not self.is_shutdown: # ④ 服务端开始监听运行 self.server.serve_forever() 1.2.5、总结 通过上面的代码分析可以看到rosmaster的整个执行流程： rosmaster命令行脚本执行rosmaster_main()； 启动了一个新的线程来启动xml-rpc server(rosmaster)； xml-rpc server注册了一个类为ROSMasterHandler，定义了rpc的方法。 1.3、Master启动汇总 roscore脚本调用launch主方法，launch是主进程（进程名是roscore），然后启动子进程master，master启动HTTP服务。 launch：是使用python编写实现的一个工具，是roscore启动的主进程； master: 是使用python编写实现的一个HTTP服务，属于launch的一个子进程； 参数服务：使用字典类型的内存对象来保存； Topic发布订阅信息：使用字典类型的内存对象来保存； 服务通讯：使用python的SimpleXMLRPCServer启动了http服务器(默认端口号11311 )，以接受PubNode&SubNode的服务注册和参数服务处理， 具体的master所有提供的功能实现在rosmaster.master_api.ROSMasterHandler。 Master中的参数服务、Topic订阅和注册信息都是使用最基本的字典内存对象维护self.parameters = {}.## { key: [(caller_id, caller_api)] }self.map = {}self.service_api_map = None "},"ROS/进阶/源码分析/02-roslaunch.html":{"url":"ROS/进阶/源码分析/02-roslaunch.html","title":"roslaunch","keywords":"","body":"datetime:2023/01/19 15:41 author:nzb 2、roslaunch roslaunch 主要功能用于启动节点，rosmaster也是使用该模块启动 2.1、roslaunch 脚本 对应的可执行脚本路径是ros/melodic/bin/roslaunch, 这是一个python脚本 import roslaunch roslaunch.main() 2.2、节点启动流程 2.2.1、 创建ROSLaunchParent 源码路径：ros\\melodic\\lib\\python2.7\\dist-packages\\roslaunch\\__init__.py def main(argv=sys.argv): # .... logger = logging.getLogger('roslaunch') # 对应日志：[roslaunch][INFO] 2023-01-16 14:40:50,171: roslaunch starting with args ['/opt/ros/melodic/bin/roslaunch', '/set_urdf.launch', '--wait'] # args是上面roscore传进来的参数 logger.info(\"roslaunch starting with args %s\" % str(argv)) # 对应日志：[roslaunch][INFO] 2023-01-18 14:57:35,628: roslaunch env is {'ROS_DISTRO': 'melodic', # 'ROS_IP': '192.168.111.111', 'HOME': '/root', 'PATH': '/opt/ros/melodic/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', # 'ROS_PACKAGE_PATH': '/opt/ros/melodic/share', 'CMAKE_PREFIX_PATH': '/opt/ros/melodic', 'LD_LIBRARY_PATH': '/opt/ros/melodic/lib', # 'LANG': 'C.UTF-8', 'TERM': 'xterm', 'SHLVL': '1', 'ROS_LOG_FILENAME': '/root/.ros/log/769ca6bc-96d1-11ed-8514-8ec2aee29851/roslaunch-quicktron-RK-1753.log', # 'ROS_MASTER_URI': 'http://192.168.111.111:11311', 'ROS_PYTHON_VERSION': '2', 'PYTHONPATH': '/opt/ros/melodic/lib/python2.7/dist-packages', # 'ROS_ROOT': '/opt/ros/melodic/share/ros', 'PKG_CONFIG_PATH': '/opt/ros/melodic/lib/pkgconfig', 'LC_ALL': 'C.UTF-8', '_': '/opt/ros/melodic/bin/roscore', # 'HOSTNAME': 'quicktron-RK', 'ROSLISP_PACKAGE_DIRECTORIES': '', 'PWD': '/', 'ROS_ETC_DIR': '/opt/ros/melodic/etc/ros', 'ROS_VERSION': '1',...} logger.info(\"roslaunch env is %s\" % os.environ) if options.child_name: logger.info('starting in child mode') # ... else: logger.info('starting in server mode') ... # This is a roslaunch parent, spin up parent server and launch processes. # args are the roslaunch files to load from . import parent as roslaunch_parent # force a port binding spec if we are running a core if options.core: options.port = options.port or DEFAULT_MASTER_PORT p = roslaunch_parent.ROSLaunchParent(uuid, args, roslaunch_strs=roslaunch_strs, is_core=options.core, port=options.port, local_only=options.local_only, verbose=options.verbose, force_screen=options.force_screen, force_log=options.force_log, num_workers=options.num_workers, timeout=options.timeout, master_logger_level=options.master_logger_level, show_summary=not options.no_summary, force_required=options.force_required) p.start() p.spin() set_urdf.launch文件 2.2.2、joint_state_publisher启动流程 启动相关日志 [roslaunch][INFO] 2023-01-16 14:40:51,168: launch_nodes: launching local nodes ... [roslaunch][INFO] 2023-01-16 14:40:51,168: ... preparing to launch node of type [joint_state_publisher/joint_state_publisher] [roslaunch][INFO] 2023-01-16 14:40:51,169: create_node_process: package[joint_state_publisher] type[joint_state_publisher] machine[Machine(name[] env_loader[None] address[localhost] ssh_port[22] user[None] assignable[True] timeout[10.0])] master_uri[http://192.168.111.111:11311] [roslaunch][INFO] 2023-01-16 14:40:51,169: process[joint_state_publisher-1]: env[{'ROS_DISTRO': 'melodic', 'ROS_IP': '192.168.111.111', 'ROS_PACKAGE_PATH': '/opt/ros/melodic/share', 'PATH': '/opt/ros/melodic/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'CMAKE_PREFIX_PATH': '/opt/ros/melodic', 'ROS_LOG_FILENAME': '/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/roslaunch-tegra-ubuntu-30.log', 'LANG': 'C.UTF-8', 'TERM': 'xterm', 'SHLVL': '1', 'LD_LIBRARY_PATH': '/opt/ros/melodic/lib', 'ROS_MASTER_URI': 'http://192.168.111.111:11311', 'HOME': '/root', 'ROS_PYTHON_VERSION': '2', 'PYTHONPATH': '/opt/ros/melodic/lib/python2.7/dist-packages', 'ROS_ROOT': '/opt/ros/melodic/share/ros', 'PKG_CONFIG_PATH': '/opt/ros/melodic/lib/pkgconfig', 'LC_ALL': 'C.UTF-8', '_': '/usr/bin/nohup', 'HOSTNAME': 'tegra-ubuntu', 'ROSLISP_PACKAGE_DIRECTORIES': '', 'PWD': '/', 'ROS_ETC_DIR': '/opt/ros/melodic/etc/ros', 'ROS_VERSION': '1'}] [roslaunch][INFO] 2023-01-16 14:40:51,203: process[joint_state_publisher-1]: args[[u'/opt/ros/melodic/lib/joint_state_publisher/joint_state_publisher', u'__name:=joint_state_publisher']] [roslaunch][INFO] 2023-01-16 14:40:51,203: ... created process [joint_state_publisher-1] [roslaunch.pmon][INFO] 2023-01-16 14:40:51,204: ProcessMonitor.register[joint_state_publisher-1] [roslaunch.pmon][INFO] 2023-01-16 14:40:51,204: ProcessMonitor.register[joint_state_publisher-1] complete [roslaunch][INFO] 2023-01-16 14:40:51,204: ... registered process [joint_state_publisher-1] [roslaunch][INFO] 2023-01-16 14:40:51,205: process[joint_state_publisher-1]: starting os process [roslaunch][INFO] 2023-01-16 14:40:51,205: process[joint_state_publisher-1]: start w/ args [[u'/opt/ros/melodic/lib/joint_state_publisher/joint_state_publisher', u'__name:=joint_state_publisher', u'__log:=/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/joint_state_publisher-1.log']] [roslaunch][INFO] 2023-01-16 14:40:51,205: process[joint_state_publisher-1]: cwd will be [/root/.ros] [roslaunch][INFO] 2023-01-16 14:40:51,957: process[joint_state_publisher-1]: started with pid [78] [roslaunch][INFO] 2023-01-16 14:40:51,958: ... successfully launched [joint_state_publisher-1] [roslaunch][INFO] 2023-01-16 14:40:51,958: ... preparing to launch node of type [robot_state_publisher/robot_state_publisher] ......robot_state_publisher节点启动相关日志 [roslaunch][INFO] 2023-01-16 14:40:52,696: ... launch_nodes complete 前面相关启动跟rosmaster一样，实例化配置、进程管理、XML-RPC等等 class ROSLaunchParent(object): def start(self, auto_terminate=True): # self._init_runner() self.runner = roslaunch.launch.ROSLaunchRunner(self.run_id, self.config, server_uri=self.server.uri, pmon=self.pm, is_core=self.is_core, remote_runner=self.remote_runner, is_rostest=self.is_rostest, num_workers=self.num_workers, timeout=self.timeout, master_logger_level=self.master_logger_level) self.runner.launch() # joint_state_publisher启动流程 启动流程 # -> self._launch_nodes() # -> self.launch_node(node) # -> p = create_node_process() # 创建启动进程，p为LocalProcess实例 # -> self.pm.register(p) 提交给进程管理 # -> p.start() # -> subprocess.Popen() # 执行joint_state_publisher脚本，脚本路径：/opt/ros/melodic/lib/joint_state_publisher/joint_state_publisher def launch_node(self, node, core=False): \"\"\" Launch a single node locally. Remote launching is handled separately by the remote module. If node name is not assigned, one will be created for it. @param node Node: node to launch @param core bool: if True, core node @return obj, bool: Process handle, successful launch. If success, return actual Process instance. Otherwise return name. \"\"\" self.logger.info(\"... preparing to launch node of type [%s/%s]\", node.package, node.type) # TODO: should this always override, per spec?. I added this # so that this api can be called w/o having to go through an # extra assign machines step. if node.machine is None: node.machine = self.config.machines[''] if node.name is None: node.name = rosgraph.names.anonymous_name(node.type) master = self.config.master import roslaunch.node_args try: process = create_node_process(self.run_id, node, master.uri) except roslaunch.node_args.NodeParamsException as e: self.logger.error(e) printerrlog(\"ERROR: cannot launch node of type [%s/%s]: %s\" % (node.package, node.type, str(e))) if node.name: return node.name, False else: return \"%s/%s\" % (node.package, node.type), False self.logger.info(\"... created process [%s]\", process.name) if core: self.pm.register_core_proc(process) else: self.pm.register(process) node.process_name = process.name # store this in the node object for easy reference self.logger.info(\"... registered process [%s]\", process.name) # note: this may raise FatalProcessLaunch, which aborts the entire launch success = process.start() if not success: if node.machine.name: printerrlog(\"launch of %s/%s on %s failed\" % (node.package, node.type, node.machine.name)) else: printerrlog(\"local launch of %s/%s failed\" % (node.package, node.type)) else: self.logger.info(\"... successfully launched [%s]\", process.name) return process, success def create_node_process(run_id, node, master_uri): \"\"\" Factory for generating processes for launching local ROS nodes. Also registers the process with the L{ProcessMonitor} so that events can be generated when the process dies. @param run_id: run_id of launch @type run_id: str @param node: node to launch. Node name must be assigned. @type node: L{Node} @param master_uri: API URI for master node @type master_uri: str @return: local process instance @rtype: L{LocalProcess} @raise NodeParamsException: If the node's parameters are improperly specific \"\"\" # [roslaunch][INFO] 2023-01-16 14:40:51,169: create_node_process: package[joint_state_publisher] # type[joint_state_publisher] machine[Machine(name[] env_loader[None] address[localhost] ssh_port[22] user[None] assignable[True] timeout[10.0])] master_uri[http://192.168.111.111:11311] _logger.info(\"create_node_process: package[%s] type[%s] machine[%s] master_uri[%s]\", node.package, node.type, node.machine, master_uri) # check input args machine = node.machine if machine is None: raise RLException(\"Internal error: no machine selected for node of type [%s/%s]\" % (node.package, node.type)) if not node.name: raise ValueError(\"node name must be assigned\") # - setup env for process (vars must be strings for os.environ) env = setup_env(node, machine, master_uri) if not node.name: raise ValueError(\"node name must be assigned\") # we have to include the counter to prevent potential name # collisions between the two branches name = \"%s-%s\" % (rosgraph.names.ns_join(node.namespace, node.name), _next_counter()) if name[0] == '/': name = name[1:] # [roslaunch][INFO] 2023-01-16 14:40:51,169: process[joint_state_publisher-1]: # env[{'ROS_DISTRO': 'melodic', 'ROS_IP': '192.168.111.111', 'ROS_PACKAGE_PATH': '/opt/ros/melodic/share', # 'PATH': '/opt/ros/melodic/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', # 'CMAKE_PREFIX_PATH': '/opt/ros/melodic', 'ROS_LOG_FILENAME': '/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/roslaunch-tegra-ubuntu-30.log', # 'LANG': 'C.UTF-8', 'TERM': 'xterm', 'SHLVL': '1', 'LD_LIBRARY_PATH': '/opt/ros/melodic/lib', # 'ROS_MASTER_URI': 'http://192.168.111.111:11311', 'HOME': '/root', 'ROS_PYTHON_VERSION': '2', # 'PYTHONPATH': '/opt/ros/melodic/lib/python2.7/dist-packages', 'ROS_ROOT': '/opt/ros/melodic/share/ros', # 'PKG_CONFIG_PATH': '/opt/ros/melodic/lib/pkgconfig', 'LC_ALL': 'C.UTF-8', '_': '/usr/bin/nohup', # 'HOSTNAME': 'tegra-ubuntu', 'ROSLISP_PACKAGE_DIRECTORIES': '', 'PWD': '/', 'ROS_ETC_DIR': '/opt/ros/melodic/etc/ros', # 'ROS_VERSION': '1'}] _logger.info('process[%s]: env[%s]', name, env) args = create_local_process_args(node, machine) # [roslaunch][INFO] 2023-01-16 14:40:51,203: process[joint_state_publisher-1]: # args[[u'/opt/ros/melodic/lib/joint_state_publisher/joint_state_publisher', u'__name:=joint_state_publisher']] _logger.info('process[%s]: args[%s]', name, args) # default for node.output not set is 'log' log_output = node.output != 'screen' _logger.debug('process[%s]: returning LocalProcess wrapper') return LocalProcess(run_id, node.package, name, args, env, log_output, respawn=node.respawn, respawn_delay=node.respawn_delay, required=node.required, cwd=node.cwd) class LocalProcess(Process): \"\"\" Process launched on local machine \"\"\" def start(self): \"\"\" Start the process. @raise FatalProcessLaunch: if process cannot be started and it is not likely to ever succeed \"\"\" super(LocalProcess, self).start() try: self.lock.acquire() if self.started: _logger.info(\"process[%s]: restarting os process\", self.name) else: _logger.info(\"process[%s]: starting os process\", self.name) self.started = self.stopped = False full_env = self.env # _configure_logging() can mutate self.args try: logfileout, logfileerr = self._configure_logging() except Exception as e: _logger.error(traceback.format_exc()) printerrlog(\"[%s] ERROR: unable to configure logging [%s]\" % (self.name, str(e))) # it's not safe to inherit from this process as # rostest changes stdout to a StringIO, which is not a # proper file. logfileout, logfileerr = subprocess.PIPE, subprocess.PIPE if self.cwd == 'node': cwd = os.path.dirname(self.args[0]) elif self.cwd == 'cwd': cwd = os.getcwd() elif self.cwd == 'ros-root': cwd = get_ros_root() else: cwd = rospkg.get_ros_home() if not os.path.exists(cwd): try: os.makedirs(cwd) except OSError: # exist_ok=True pass # [roslaunch][INFO] 2023-01-16 14:40:51,205: process[joint_state_publisher-1]: start w/ # args [[u'/opt/ros/melodic/lib/joint_state_publisher/joint_state_publisher', # u'__name:=joint_state_publisher', u'__log:=/root/.ros/log/b598afc4-9568-11ed-b4d9-00044bde2742/joint_state_publisher-1.log']] # [roslaunch][INFO] 2023-01-16 14:40:51,205: process[joint_state_publisher-1]: cwd will be [/root/.ros] _logger.info(\"process[%s]: start w/ args [%s]\", self.name, self.args) _logger.info(\"process[%s]: cwd will be [%s]\", self.name, cwd) try: preexec_function = os.setsid close_file_descriptor = True except AttributeError: preexec_function = None close_file_descriptor = False try: self.popen = subprocess.Popen(self.args, cwd=cwd, stdout=logfileout, stderr=logfileerr, env=full_env, close_fds=close_file_descriptor, preexec_fn=preexec_function) except OSError as e: self.started = True # must set so is_alive state is correct _logger.error(\"OSError(%d, %s)\", e.errno, e.strerror) if e.errno == errno.ENOEXEC: # Exec format error raise FatalProcessLaunch( \"Unable to launch [%s]. \\nIf it is a script, you may be missing a '#!' declaration at the top.\" % self.name) elif e.errno == errno.ENOENT: # no such file or directory raise FatalProcessLaunch(\"\"\"Roslaunch got a '%s' error while attempting to run: %s Please make sure that all the executables in this command exist and have executable permission. This is often caused by a bad launch-prefix.\"\"\" % (e.strerror, ' '.join(self.args))) else: raise FatalProcessLaunch(\"unable to launch [%s]: %s\" % (' '.join(self.args), e.strerror)) self.started = True # Check that the process is either still running (poll returns # None) or that it completed successfully since when we # launched it above (poll returns the return code, 0). poll_result = self.popen.poll() if poll_result is None or poll_result == 0: self.pid = self.popen.pid # [roslaunch][INFO] 2023-01-16 14:40:51,957: process[joint_state_publisher-1]: started with pid [78] printlog_bold(\"process[%s]: started with pid [%s]\" % (self.name, self.pid)) return True else: printerrlog(\"failed to start local process: %s\" % (' '.join(self.args))) return False finally: self.lock.release() 2.3、roslaunch 包分析 2.3.1、python distutils distutils可以用来在Python环境中构建和安装额外的模块。新的模块可以是纯python的，也可以是用C/C++写的扩展模块，或者可以是Python包，包中包含了由C和Python编写的模块。 对于模块开发者以及需要安装模块的使用者来说，distutils的使用都很简单，作为一个开发者，除了编写源码之外，还需要： 编写setup脚本（一般是setup.py）； 编写一个setup配置文件（可选）； 创建一个源码发布； 创建一个或多个构建（二进制）发布（可选）; 一个setup.py的简单例子 from distutils.core import setup setup(name='Distutils', version='1.0', description='Python Distribution Utilities', author='Greg Ward', author_email='xxx@python.net', url='https://www.python.org/sigs/distutils-sig/', packages=['distutils', 'distutils.command'], ) 关于distutils的具体用法，可以参考官方文档 2.3.2、roslaunch 包结构分析 roslaunch的setup.py from distutils.core import setup from catkin_pkg.python_setup import generate_distutils_setup # 参数收集，返回到d,dict d = generate_distutils_setup( packages=['roslaunch'], package_dir={'': 'src'}, scripts=['scripts/roscore', 'scripts/roslaunch', 'scripts/roslaunch-complete', 'scripts/roslaunch-deps', 'scripts/roslaunch-logs'], requires=['genmsg', 'genpy', 'roslib', 'rospkg'] ) # 序列解包 setup(**d) 而其中的catkin_pkg，其git地址为https://github.com/ros-infrastructure/catkin_pkg.git 功能介绍如下 catkin_pkg Standalone Python library for the Catkin package system. 下面是generate_distutils_setup()函数的实现，这里用到了**在函数定义时的参数收集功能(dict)， 其核心功能就是将package.xml文件中的内容解析放到一个字典中，然后返回。( 而且还要加上输入参数kwargs，输入参数kwargs中收集的key如果在package.xml中有，则值必须一样，如果没有，则添加到返回值中) # catkin_pkg\\src\\catkin_pkg\\python_setup.py from .package import InvalidPackage, parse_package def generate_distutils_setup(package_xml_path=os.path.curdir, **kwargs): \"\"\" Extract the information relevant for distutils from the package manifest. The following keys will be set: The \"name\" and \"version\" are taken from the eponymous tags. A single maintainer will set the keys \"maintainer\" and \"maintainer_email\" while multiple maintainers are merged into the \"maintainer\" fields (including their emails). Authors are handled likewise. The first URL of type \"website\" (or without a type) is used for the \"url\" field. The \"description\" is taken from the eponymous tag if it does not exceed 200 characters. If it does \"description\" contains the truncated text while \"description_long\" contains the complete. All licenses are merged into the \"license\" field. :param kwargs: All keyword arguments are passed through. The above mentioned keys are verified to be identical if passed as a keyword argument :returns: return dict populated with parsed fields and passed keyword arguments :raises: :exc:`InvalidPackage` :raises: :exc:`IOError` \"\"\" package = parse_package(package_xml_path) data = {} data['name'] = package.name data['version'] = package.version # either set one author with one email or join all in a single field if len(package.authors) == 1 and package.authors[0].email is not None: data['author'] = package.authors[0].name data['author_email'] = package.authors[0].email else: data['author'] = ', '.join( [('%s ' % (a.name, a.email) if a.email is not None else a.name) for a in package.authors]) # either set one maintainer with one email or join all in a single field if len(package.maintainers) == 1: data['maintainer'] = package.maintainers[0].name data['maintainer_email'] = package.maintainers[0].email else: data['maintainer'] = ', '.join(['%s ' % (m.name, m.email) for m in package.maintainers]) # either set the first URL with the type 'website' or the first URL of any type websites = [url.url for url in package.urls if url.type == 'website'] if websites: data['url'] = websites[0] elif package.urls: data['url'] = package.urls[0].url if len(package.description) 而，package.xml中都是一些distutils中setup()函数执行时需要的一些参数，用xml进行可配置化。 roslaunch 1.13.0 roslaunch is a tool for easily launching multiple ROS nodes locally and remotely via SSH, as well as setting parameters on the Parameter Server. It includes options to automatically respawn processes that have already died. roslaunch takes in one or more XML configuration files (with the .launch extension) that specify the parameters to set and nodes to launch, as well as the machines that they should be run on. Dirk Thomas BSD http://ros.org/wiki/roslaunch Ken Conley catkin python-paramiko python-rospkg python-yaml rosclean rosgraph_msgs roslib rosmaster rosout rosparam rosunit rosbuild setup()函数的输入参数中，scripts的解释如下， So far we have been dealing with pure and non-pure Python modules, which are usually not run by themselves but imported by scripts. Scripts are files containing Python source code, intended to be started from the command line. Scripts don’t require Distutils to do anything very complicated. 到目前为止，我们一直在处理纯和非纯Python模块，这些模块通常不是自己运行的，而是由脚本导入的。 脚本是包含python源代码的文件，旨在从命令行启动。脚本不需要Distutils做任何非常复杂的事情 所以，python 模块主要是用来被其他模块去import，而script是为了直接在命令行执行，类似于应用程序。 而roscore就是这样一个需要在命令行执行的脚本(程序) scripts = ['scripts/roscore', 'scripts/roslaunch', 'scripts/roslaunch-complete', 'scripts/roslaunch-deps', 'scripts/roslaunch-logs'] 而roscore最终会去import roslaunch package，去调用其中的main函数。 # ros_comm\\tools\\roslaunch\\scripts\\roscore import roslaunch roslaunch.main(['roscore', '--core'] + sys.argv[1:]) "},"ROS/进阶/源码分析/03-process_monitoring.html":{"url":"ROS/进阶/源码分析/03-process_monitoring.html","title":"process_monitoring","keywords":"","body":"datetime:2023/01/30 16:48 author:nzb 3、进程监控管理(process monitoring) roslaunch中有个小功能类似于android init进程中的service重启功能，如果该进程在创建时有respawn属性，则在该进程dead后需要将其重启起来，起到一个进程监控的作用，相关源码位于ros\\melodic\\lib\\python2.7\\dist-packages\\roslaunch\\pmon.py 。 下面分析下其主要功能 3.1、进程类 class Process(object): \"\"\" Basic process representation for L{ProcessMonitor}. Must be subclassed to provide actual start()/stop() implementations. Constructor *must* be called from the Python Main thread in order for signal handlers to register properly. \"\"\" def __init__(self, package, name, args, env, respawn=False, respawn_delay=0.0, required=False): # ①进程的属性，respawn为是否需要重启 self.respawn = respawn self.respawn_delay = respawn_delay self.required = required Process()类就是ProcessMonitor()所监控的进程需要去继承的基类，可以设置dead后是否需要重启属性。 通过调用start_process_monitor()函数可以启动一个ProcessMonitor线程 子类：LocalProcess、DeadProcess、ChildROSLaunchProcess 3.2、进程监控类 class ProcessMonitor(Thread): def __init__(self, name=\"ProcessMonitor\"): Thread.__init__(self, name=name) # ①所监控的进程 self.procs = [] # #885: ensure core procs self.core_procs = [] def register(self, p): \"\"\" Register process with L{ProcessMonitor} @param p: Process @type p: L{Process} @raise RLException: if process with same name is already registered \"\"\" logger.info(\"ProcessMonitor.register[%s]\" % p.name) e = None with self.plock: if self.has_process(p.name): e = RLException(\"cannot add process with duplicate name '%s'\" % p.name) elif self.is_shutdown: e = RLException(\"cannot add process [%s] after process monitor has been shut down\" % p.name) else: # ② 将进程注册到ProcessMonitor，即添加到procs self.procs.append(p) # ③ProcessMonitor线程的线程函数 def run(self): \"\"\" thread routine of the process monitor. NOTE: you must still call mainthread_spin or mainthread_spin_once() from the main thread in order to pick up main thread work from the process monitor. \"\"\" try: # don't let exceptions bomb thread, interferes with exit try: self._run() except: pass finally: self._post_run() # ④ProcessMonitor线程的线程函数的主体 def _run(self): \"\"\" Internal run loop of ProcessMonitor \"\"\" plock = self.plock dead = [] respawn = [] while not self.is_shutdown: # while循环，pmon关闭开关 with plock: # copy self.procs procs = self.procs[:] # ... # 监控中的进程 for p in procs: try: if not p.is_alive(): exit_code_str = p.get_exit_description() # ⑤ 这个进程是必须的，如果这个必须的进程dead掉了，pmon自己也关闭 # 将self.is_shutdown 设置为 True # ros master 的就是必须的进程 if p.required: self.is_shutdown = True elif not p in respawn: # ... dead.append(p) # ... except Exception as e: # ... dead.append(p) for d in dead: try: # when should_respawn() returns 0.0, bool(0.0) evaluates to False # work around this by checking if the return value is False if d.should_respawn() is not False: respawn.append(d) # 添加到需要重启的列表 else: self.unregister(d) # stop process, don't accumulate errors d.stop([]) # save process data to dead list with plock: self.dead_list.append(DeadProcess(d)) except: pass # dead check is to make sure that ProcessMonitor at least # waits until its had at least one process before exiting if self._registrations_complete and dead and not self.procs and not respawn: printlog(\"all processes on machine have died, roslaunch will exit\") self.is_shutdown = True del dead[:] _respawn = [] for r in respawn: try: if self.is_shutdown: break if r.should_respawn() 3.3、启动流程 开启函数 _pmons = [] _pmon_counter = 0 def start_process_monitor(): global _pmon_counter if _shutting_down: #logger.error(\"start_process_monitor: cannot start new ProcessMonitor (shutdown initiated)\") return None _pmon_counter += 1 name = \"ProcessMonitor-%s\"%_pmon_counter logger.info(\"start_process_monitor: creating ProcessMonitor\") process_monitor = ProcessMonitor(name) try: # prevent race condition with pmon_shutdown() being triggered # as we are starting a ProcessMonitor (i.e. user hits ctrl-C # during startup) _shutdown_lock.acquire() _pmons.append(process_monitor) process_monitor.start() logger.info(\"start_process_monitor: ProcessMonitor started\") finally: _shutdown_lock.release() return process_monitor 脚本(roscore、roslaunch)执行，导入roslaunch，运行main函数 实例化ROSLaunchParent() 执行实例start() -> self._start_infrastructure() -> self._start_pm() 执行函数start_process_monitor()，返回ProcessMonitor的实例，并执行start()，该类继承Thread ProcessMonitor的run方法注释说明了，我们必须在主线程中调用ProcessMonitor的mainthread_spin()或mainthread_spin_once()方法，才能让进程监控功能开启 执行ROSLaunchParent()实例的spin()方法 执行self.runner.spin()，runner是ROSLaunchRunner的实例 spin()方法里面执行了self.pm.mainthread_spin(), pm为ProcessMonitor实例，对应了上面必须主线程启动 通过pmon.py的代码分析，pmon.py肯定是在一个进程的主线程中去import，调用start_process_monitor()函数就会产生一个pmon，然后把需要监控的进程(线程) 注册到pmon中，主线程会有多个pmon保存在全局_pmons = []中。 答疑：为什么必须调用ProcessMonitor的mainthread_spin()或mainthread_spin_once()方法？ mainthread_spin()函数注释：run() occurs in a separate thread and cannot do certain signal-related work. The main thread of the application must call mainthread_spin() or mainthread_spin_once() in order to perform these jobs. mainthread_spin() blocks until the process monitor is complete. 因为run()函数是一个单独的线程，用于监控进程，不能执行信号相关的操作，所以需要再主线中调用这2个方法，来执行信号相关的操作 "},"ROS/进阶/源码分析/04-topic.html":{"url":"ROS/进阶/源码分析/04-topic.html","title":"topic","keywords":"","body":"datetime:2023/02/07 17:18 author:nzb 4、topic 4.1、流程 执行顺序：rosmaster -> topic_demo_node_1 -> topic_demo_node_2 topic_demo_node_1节点初始化 topic_demo_2 订阅 topic_demo_1 发布 topic_demo_node_2节点初始化 topic_demo_1 订阅 topic_demo_2 发布 4.1.1、topic_demo_node_1(topic_demo_node_2) 节点初始化流程 init_node() -> start_node()：初始化启动节点 init_tcpros() -> init_tcpros_server() -> _tcpros_server=TCPROSServer()：只是初始化(未启动) _tcpros_server 并设置topic_connection_handler和service_connection_handler XmlRpcNode() -> start() -> _run_init()：初始化XmlRpc服务相关信息 ROSHandler()._ready() RegManager().start()：开线程向ros_master注册节点 RegistrationListeners().add_listener(self)：把RegManager()实例添加到RegistrationListeners() 实例的listeners属性中，用于更新状态 run()：死循环，一个一个取updates属性的数据，开线程连接topic _connect_topic_thread() -> ROSHandler()._connect_topic()：下面有完整流程 serve_forever()：开启XmlRpc服务 4.1.2、topic_demo_node_1 中发布订阅流程 前置条件：上面节点已经初始化完成 4.1.2.1 订阅 topic_demo_2 Subscriber() 父类的构造函数中执行_TopicManager() -> acquire_impl() -> _add()：创建_SubscriberImpl实例 RegistrationListeners()->notify_added() 遍历RegistrationListeners()实例的listeners属性，其值都是RegManager()实例 执行RegManager()实例的reg_added() -> xmlrpcapi(master_uri).registerSubscriber()：向ros_master注册订阅 主节点：master_api.ROSMasterHandler().registerSubscriber() 注册订阅：RegistrationManager().register_subscriber() _register() _register_node_api()：创建或更新节点信息 Registrations().register()：更新Registrations()实例的map或service_api_map属性 map数据内容为：{ key: [(caller_id, caller_api)] }：key为topic名称，caller_id 为节点名称（ID），caller_api为节点XmlRpc服务接口 service_api_map数据内容为：{ key: (caller_id, caller_api) }：key为服务名称，caller_id 为节点名称（ID），caller_api为TCPROS服务链接 返回发布的节点列表：ROSMasterHandler().RegistrationManager().publishers.get_apis()：返回对应topic 的发布节点XmlRpc列表，publishers为Registrations实例， publisher_update()：rosmaster节点会返回发布该topic的所有XmlRpc链接列表，此操作会更新updates属性，目前node_2还未初始化，所以到这就结束了 4.1.2.2 发布 topic_demo_1 Publisher() 父类的构造函数中执行_TopicManager() -> acquire_impl() -> _add()：创建_PublisherImpl实例 RegistrationListeners()->notify_added() 遍历RegistrationListeners()实例的listeners属性，其值都是RegManager()实例 执行RegManager()实例的reg_added() -> xmlrpcapi(master_uri).registerPublisher()：向ros_master注册发布 master_api.ROSMasterHandler().registerPublisher() 注册发布：RegistrationManager().register_publisher() _register() _register_node_api()：创建或更新节点信息 Registrations().register()：更新Registrations()实例的map或service_api_map属性 map数据内容为：{ key: [(caller_id, caller_api)] }：key为topic名称，caller_id 为节点ID，caller_api为节点XmlRpc服务接口 service_api_map数据内容为：{ key: (caller_id, caller_api) }：key为服务名称，caller_id 为节点ID，caller_api为节点XmlRpc服务接口 pub_uris = self.publishers.get_apis(topic)：获取发布节点XmlRpc服务接口 sub_uris = self.subscribers.get_apis(topic)：获取订阅节点XmlRpc服务接口 通知订阅节点并返回订阅节点列表：_notify_topic_subscribers() -> publisher_update_task()：目前node_2 还未初始化，所以还没有订阅，如果有走下面流程 xmlrpcapi(api).publisherUpdate('/master', topic, pub_uris) api为订阅节点的XmlRpc接口 该方法通知对应节点更新发布节点的XmlRpc链接：ROSHandler().publisherUpdate() RegManager().publisher_update()：更新RegManager实例的updates属性 updates属性，在RegManager实例方法run中一直监听创建连接线程，_connect_topic_thread Publisher().publish(String(\"topic_demo_1\"))：开启循环发送数据 _PublisherImpl().publish() -> QueuedConnection().write_data() -> TCPROSTransport().write_data() -> self.socket.sendall(data)：socket发送数据 4.1.3、topic_demo_node_2 中发布订阅流程 前置条件：上面节点已经初始化完成 4.1.3.1 订阅 topic_demo_1 初始化跟上面的订阅 topic_demo_2流程一样，最后rosmaster会返回发布该topic的所有XmlRpc链接列表，最后更新updates属性 topic_demo_node_2节点初始化流程中，RegManager().start()：开线程向ros_master注册节点，最后执行了死循环run() topic, uris = self.updates.pop()：从updates取出topic和XmlRpc链接 get_topic_manager().check_all()：移除异常断连的连接 self._connect_topic_thread(topic, uri)：遍历urls启连接topic线程，每个topic启一个线程 ROSHandler()._connect_topic(topic, uri) xmlrpcapi(pub_uri, cache=False).requestTopic()：请求发布节点的接口 以下为发布节点内的操作 TCPROSHandler().init_publisher() -> start_tcpros_server()：开启节点启动时初始化的TCPROSServer() TCPROSServer().start_server() -> TCPServer().start() -> 启线程执行run() accept()接收TCP客户端 TCPROSServer()._tcp_server_callback(client_sock, client_addr) read_ros_handshake_header()：读取请求头 根据请求头区分topic或service，执行topic_connection_handler或service_connection_handler topic：TCPROSHandler().topic_connection_handler() _TopicManager()._PublisherImpl：通过topic获取到对应实例，实例有数据类型等参数 protocol = TCPROSPub()：数据传输协议 transport = TCPROSTransport()：TCPROS 用于topic和service交互 _PublisherImpl().add_connection(transport)：父类对比连接者的XmlRpc接口或socker 描述符，看是否已经存在连接，存在移除，否则重新添加 c = QueuedConnection(c, self.queue_size)：实例化队列连接，内部启线程死循环执行_run ，使用TCPROSTransport().write_data发送队列数据 service：rospy.impl.tcpros_service.service_connection_handler() 发布节点返回给订阅节点：['TCPROS', 'pf2gf7kc', 60978]，通讯协议、ip、端口 收到发布节点的结果后订阅节点操作 TCPROSHandler().create_transport() _TopicManager()._SubscriberImpl：通过topic获取到对应订阅实例，实例有数据类型等参数 protocol = TCPROSSub()：数据传输协议 启线程执行robust_connect_subscriber 参数：TCPROSTransport连接实例、目标IP、目标端口、发布者XmlRpc链接、回调函数、topic名称 TCPROSTransport().connect：socket连接，一直尝试，失败会检测发布者发布链接列表实例数量是否改变了 连接成功执行：TCPROSTransport().receive_loop(receive_cb)：receive_cb用户指定的回调函数，该函数死循环接收数据，然后执行回调函数 _SubscriberImpl().add_connection(transport)：父类对比连接者的XmlRpc接口或socker 描述符，看是否已经存在连接，存在移除，否则重新添加，添加成功开启线程 4.1.4、rosout发布初始化 init_node() init_rosout() -> Publisher()：初始化/rosout用于发布日志 Publisher父类的构造函数中执行_TopicManager() -> acquire_impl() -> _add()：创建_PublisherImpl或_SubscriberImpl实例 RegistrationListeners()->notify_added() 遍历RegistrationListeners()实例的listeners属性，其值都是RegManager()实例 执行RegManager()实例的reg_added() -> xmlrpcapi(master_uri).registerPublisher()：向ros_master注册发布 master_api.ROSMasterHandler().registerPublisher() RegistrationManager().register_publisher() _notify_topic_subscribers() -> publisher_update_task() xmlrpcapi(api).publisherUpdate('/master', topic, pub_uris) api为rosout的XmlRpc接口 该方法通知rosout节点更新发布节点的XmlRpc链接 ROSHandler().publisherUpdate() RegManager().publisher_update()：更新RegManager实例的updates属性 updates属性，在RegManager实例方法run中一直监听创建连接线程，_connect_topic_thread 4.2、代码 master.py import rosmaster if __name__ == '__main__': rosmaster.rosmaster_main([\"--core\"]) topic_demo_node_1.py import threading import rospy from std_msgs.msg import String def talker(): pub = rospy.Publisher('topic_demo_1', String, queue_size=10) # 更新频率是1hz rate = rospy.Rate(1) while not rospy.is_shutdown(): # 计算距离 pub.publish(String(\"topic_demo_1\")) rate.sleep() def callback(data): rospy.loginfo(data) def main(): # 订阅 rospy.Subscriber('topic_demo_2', String, callback) # 发布 threading.Thread(target=talker).start() if __name__ == '__main__': rospy.init_node('topic_demo_node_1', anonymous=True, log_level=rospy.DEBUG) main() rospy.spin() topic_demo_node_2.py import threading import rospy from std_msgs.msg import String def talker(): pub = rospy.Publisher('topic_demo_2', String, queue_size=10) # 更新频率是1hz rate = rospy.Rate(1) while not rospy.is_shutdown(): # 计算距离 pub.publish(String(\"topic_demo_2\")) rate.sleep() def callback(data): rospy.loginfo(data) def main(): # 订阅 rospy.Subscriber('topic_demo_1', String, callback) # 发布 threading.Thread(target=talker).start() if __name__ == '__main__': rospy.init_node('topic_demo_node_2', anonymous=True, log_level=rospy.DEBUG) main() rospy.spin() 4.3、日志 # rosmaster 启动日志 2023-02-09 14:44:08 - main - 25908 - INFO : initialization complete, waiting for shutdown 2023-02-09 14:44:08 - main - 25908 - INFO : Starting ROS Master Node 2023-02-09 14:44:08 - xmlrpc - 27172 - INFO : XML-RPC server binding to 0.0.0.0:11311 2023-02-09 14:44:08 - xmlrpc - 27172 - INFO : Started XML-RPC server [http://pf2gf7kc:11311/] 2023-02-09 14:44:08 - xmlrpc - 27172 - INFO : xml rpc node: starting XML-RPC server 2023-02-09 14:44:08 - master - 25908 - INFO : Master initialized: port[11311], uri[http://pf2gf7kc:11311/] # topic_demo_node_1 启动日志(开始) 2023-02-09 14:45:10 - client - 19492 - INFO : init_node, name[/topic_demo_node_1_12044_1675925110198], pid[12044] 2023-02-09 14:45:10 - xmlrpc - 20232 - INFO : XML-RPC server binding to 0.0.0.0:0 2023-02-09 14:45:10 - xmlrpc - 20232 - INFO : Started XML-RPC server [http://pf2gf7kc:60976/] 2023-02-09 14:45:10 - init - 19492 - INFO : ROS Slave URI: [http://pf2gf7kc:60976/] 2023-02-09 14:45:10 - masterslave - 20232 - INFO : _ready: http://pf2gf7kc:60976/ 2023-02-09 14:45:10 - registration - 26880 - INFO : Registering with master node http://127.0.0.1:11311/ 2023-02-09 14:45:10 - xmlrpc - 20232 - INFO : xml rpc node: starting XML-RPC server 2023-02-09 14:45:10 - registration - 26880 - DEBUG : No topics to register with master node http://127.0.0.1:11311/ 2023-02-09 14:45:10 - init - 19492 - INFO : registered with master 2023-02-09 14:45:10 - rosout - 19492 - INFO : initializing /rosout core topic 2023-02-09 14:45:10 - topics - 19492 - DEBUG : tm._add: /rosout, rosgraph_msgs/Log, pub 2023-02-09 14:45:10 - registration - 19492 - DEBUG : master.registerPublisher(/topic_demo_node_1_12044_1675925110198, /rosout, rosgraph_msgs/Log, http://pf2gf7kc:60976/) 2023-02-09 14:45:10 - master_api - 26800 - INFO : +PUB [/rosout] /topic_demo_node_1_12044_1675925110198 http://pf2gf7kc:60976/ 2023-02-09 14:45:10 - rosout - 19492 - INFO : connected to core topic /rosout 2023-02-09 14:45:10 - simtime - 19492 - INFO : /use_sim_time is not set, will not subscribe to simulated time [/clock] topic 2023-02-09 14:45:10 - client - 19492 - DEBUG : init_node, name[/topic_demo_node_1_12044_1675925110198], pid[12044] 2023-02-09 14:45:10 - tcpros_base - 19492 - DEBUG : binding to 0.0.0.0 0 2023-02-09 14:45:10 - tcpros_base - 19492 - DEBUG : bound to 0.0.0.0 60978 2023-02-09 14:45:10 - tcpros_service - 19492 - DEBUG : ... service URL is rosrpc://pf2gf7kc:60978 2023-02-09 14:45:10 - tcpros_service - 19492 - DEBUG : [/topic_demo_node_1_12044_1675925110198/get_loggers]: new Service instance 2023-02-09 14:45:10 - registration - 19492 - DEBUG : master.registerService(/topic_demo_node_1_12044_1675925110198, /topic_demo_node_1_12044_1675925110198/get_loggers, rosrpc://pf2gf7kc:60978, http://pf2gf7kc:60976/) 2023-02-09 14:45:10 - master_api - 26800 - INFO : +SERVICE [/topic_demo_node_1_12044_1675925110198/get_loggers] /topic_demo_node_1_12044_1675925110198 http://pf2gf7kc:60976/ 2023-02-09 14:45:10 - tcpros_service - 19492 - DEBUG : ... service URL is rosrpc://pf2gf7kc:60978 2023-02-09 14:45:10 - tcpros_service - 19492 - DEBUG : [/topic_demo_node_1_12044_1675925110198/set_logger_level]: new Service instance 2023-02-09 14:45:10 - registration - 19492 - DEBUG : master.registerService(/topic_demo_node_1_12044_1675925110198, /topic_demo_node_1_12044_1675925110198/set_logger_level, rosrpc://pf2gf7kc:60978, http://pf2gf7kc:60976/) 2023-02-09 14:45:10 - master_api - 26800 - INFO : +SERVICE [/topic_demo_node_1_12044_1675925110198/set_logger_level] /topic_demo_node_1_12044_1675925110198 http://pf2gf7kc:60976/ 2023-02-09 14:45:10 - topics - 19492 - DEBUG : tm._add: /topic_demo_2, std_msgs/String, sub 2023-02-09 14:45:10 - registration - 19492 - DEBUG : master.registerSubscriber(/topic_demo_node_1_12044_1675925110198, /topic_demo_2, std_msgs/String, http://pf2gf7kc:60976/) 2023-02-09 14:45:10 - master_api - 26800 - INFO : +SUB [/topic_demo_2] /topic_demo_node_1_12044_1675925110198 http://pf2gf7kc:60976/ 2023-02-09 14:45:10 - topics - 24104 - DEBUG : tm._add: /topic_demo_1, std_msgs/String, pub 2023-02-09 14:45:10 - registration - 24104 - DEBUG : master.registerPublisher(/topic_demo_node_1_12044_1675925110198, /topic_demo_1, std_msgs/String, http://pf2gf7kc:60976/) 2023-02-09 14:45:10 - client - 19492 - DEBUG : node[/topic_demo_node_1_12044_1675925110198, http://pf2gf7kc:60976/] entering spin(), pid[12044] 2023-02-09 14:45:10 - master_api - 26800 - INFO : +PUB [/topic_demo_1] /topic_demo_node_1_12044_1675925110198 http://pf2gf7kc:60976/ # topic_demo_node_2 启动日志(开始) 2023-02-09 14:46:29 - client - 20676 - INFO : init_node, name[/topic_demo_node_2_26108_1675925189526], pid[26108] 2023-02-09 14:46:29 - xmlrpc - 9668 - INFO : XML-RPC server binding to 0.0.0.0:0 2023-02-09 14:46:29 - xmlrpc - 9668 - INFO : Started XML-RPC server [http://pf2gf7kc:61018/] 2023-02-09 14:46:29 - masterslave - 9668 - INFO : _ready: http://pf2gf7kc:61018/ 2023-02-09 14:46:29 - registration - 13684 - INFO : Registering with master node http://127.0.0.1:11311/ 2023-02-09 14:46:29 - xmlrpc - 9668 - INFO : xml rpc node: starting XML-RPC server 2023-02-09 14:46:29 - registration - 13684 - DEBUG : No topics to register with master node http://127.0.0.1:11311/ 2023-02-09 14:46:29 - init - 20676 - INFO : ROS Slave URI: [http://pf2gf7kc:61018/] 2023-02-09 14:46:29 - init - 20676 - INFO : registered with master 2023-02-09 14:46:29 - rosout - 20676 - INFO : initializing /rosout core topic 2023-02-09 14:46:29 - topics - 20676 - DEBUG : tm._add: /rosout, rosgraph_msgs/Log, pub 2023-02-09 14:46:29 - registration - 20676 - DEBUG : master.registerPublisher(/topic_demo_node_2_26108_1675925189526, /rosout, rosgraph_msgs/Log, http://pf2gf7kc:61018/) 2023-02-09 14:46:29 - master_api - 12808 - INFO : +PUB [/rosout] /topic_demo_node_2_26108_1675925189526 http://pf2gf7kc:61018/ 2023-02-09 14:46:29 - rosout - 20676 - INFO : connected to core topic /rosout 2023-02-09 14:46:29 - simtime - 20676 - INFO : /use_sim_time is not set, will not subscribe to simulated time [/clock] topic 2023-02-09 14:46:29 - client - 20676 - DEBUG : init_node, name[/topic_demo_node_2_26108_1675925189526], pid[26108] 2023-02-09 14:46:29 - tcpros_base - 20676 - DEBUG : binding to 0.0.0.0 0 2023-02-09 14:46:29 - tcpros_base - 20676 - DEBUG : bound to 0.0.0.0 61020 2023-02-09 14:46:29 - tcpros_service - 20676 - DEBUG : ... service URL is rosrpc://pf2gf7kc:61020 2023-02-09 14:46:29 - tcpros_service - 20676 - DEBUG : [/topic_demo_node_2_26108_1675925189526/get_loggers]: new Service instance 2023-02-09 14:46:29 - registration - 20676 - DEBUG : master.registerService(/topic_demo_node_2_26108_1675925189526, /topic_demo_node_2_26108_1675925189526/get_loggers, rosrpc://pf2gf7kc:61020, http://pf2gf7kc:61018/) 2023-02-09 14:46:29 - master_api - 12808 - INFO : +SERVICE [/topic_demo_node_2_26108_1675925189526/get_loggers] /topic_demo_node_2_26108_1675925189526 http://pf2gf7kc:61018/ 2023-02-09 14:46:29 - tcpros_service - 20676 - DEBUG : ... service URL is rosrpc://pf2gf7kc:61020 2023-02-09 14:46:29 - tcpros_service - 20676 - DEBUG : [/topic_demo_node_2_26108_1675925189526/set_logger_level]: new Service instance 2023-02-09 14:46:29 - registration - 20676 - DEBUG : master.registerService(/topic_demo_node_2_26108_1675925189526, /topic_demo_node_2_26108_1675925189526/set_logger_level, rosrpc://pf2gf7kc:61020, http://pf2gf7kc:61018/) 2023-02-09 14:46:29 - master_api - 12808 - INFO : +SERVICE [/topic_demo_node_2_26108_1675925189526/set_logger_level] /topic_demo_node_2_26108_1675925189526 http://pf2gf7kc:61018/ 2023-02-09 14:46:29 - topics - 20676 - DEBUG : tm._add: /topic_demo_1, std_msgs/String, sub 2023-02-09 14:46:29 - registration - 20676 - DEBUG : master.registerSubscriber(/topic_demo_node_2_26108_1675925189526, /topic_demo_1, std_msgs/String, http://pf2gf7kc:61018/) 2023-02-09 14:46:29 - master_api - 12808 - INFO : +SUB [/topic_demo_1] /topic_demo_node_2_26108_1675925189526 http://pf2gf7kc:61018/ 2023-02-09 14:46:29 - topics - 26340 - DEBUG : tm._add: /topic_demo_2, std_msgs/String, pub 2023-02-09 14:46:29 - masterslave - 26820 - DEBUG : connect[/topic_demo_1]: calling requestTopic(/topic_demo_node_2_26108_1675925189526, /topic_demo_1, [['TCPROS']]) 2023-02-09 14:46:29 - registration - 26340 - DEBUG : master.registerPublisher(/topic_demo_node_2_26108_1675925189526, /topic_demo_2, std_msgs/String, http://pf2gf7kc:61018/) 2023-02-09 14:46:29 - client - 20676 - DEBUG : node[/topic_demo_node_2_26108_1675925189526, http://pf2gf7kc:61018/] entering spin(), pid[26108] 2023-02-09 14:46:29 - master_api - 12808 - INFO : +PUB [/topic_demo_2] /topic_demo_node_2_26108_1675925189526 http://pf2gf7kc:61018/ # 收发topic 2023-02-09 14:46:29 - master_api - 24928 - INFO : publisherUpdate[/topic_demo_2] -> http://pf2gf7kc:60976/ ['http://pf2gf7kc:61018/'] 2023-02-09 14:46:33 - masterslave - 1644 - DEBUG : requestTopic('/topic_demo_node_2_26108_1675925189526', '/topic_demo_1', [['TCPROS']]) 2023-02-09 14:46:33 - masterslave - 1644 - DEBUG : requestTopic[/topic_demo_1]: choosing protocol TCPROS 2023-02-09 14:46:33 - masterslave - 1644 - DEBUG : requestTopic('/topic_demo_node_2_26108_1675925189526', '/topic_demo_1', [['TCPROS']]) returns (1, 'ready on pf2gf7kc:60978', ['TCPROS', 'pf2gf7kc', 60978]) 2023-02-09 14:46:33 - masterslave - 26820 - DEBUG : connect[/topic_demo_1]: requestTopic returned protocol list ['TCPROS', 'pf2gf7kc', 60978] 2023-02-09 14:46:33 - core - 26820 - INFO : topic[/topic_demo_1] adding connection to [http://pf2gf7kc:60976/], count 0 2023-02-09 14:46:33 - tcpros_base - 25744 - DEBUG : connecting to pf2gf7kc 60978 2023-02-09 14:46:33 - tcpros_base - 25744 - DEBUG : [/topic_demo_1]: writing header 2023-02-09 14:46:33 - tcpros_base - 23760 - DEBUG : [/topic_demo_1]: writing header 2023-02-09 14:46:33 - tcpros_base - 25744 - DEBUG : receive_loop for [/topic_demo_1] 2023-02-09 14:46:33 - core - 23760 - INFO : topic[/topic_demo_1] adding connection to [/topic_demo_node_2_26108_1675925189526], count 0 2023-02-09 14:46:33 - masterslave - 9492 - DEBUG : publisherUpdate('/master', '/topic_demo_2', ['http://pf2gf7kc:61018/']) 2023-02-09 14:46:33 - masterslave - 9492 - DEBUG : publisherUpdate('/master', '/topic_demo_2', ['http://pf2gf7kc:61018/']) returns (1, '', 0) 2023-02-09 14:46:33 - masterslave - 13884 - DEBUG : connect[/topic_demo_2]: calling requestTopic(/topic_demo_node_1_12044_1675925110198, /topic_demo_2, [['TCPROS']]) 2023-02-09 14:46:33 - master_api - 24928 - INFO : publisherUpdate[/topic_demo_2] -> http://pf2gf7kc:60976/ ['http://pf2gf7kc:61018/']: sec=4.07, result=[1, '', 0] 2023-02-09 14:46:34 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:35 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:36 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:37 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:37 - masterslave - 27052 - DEBUG : requestTopic('/topic_demo_node_1_12044_1675925110198', '/topic_demo_2', [['TCPROS']]) 2023-02-09 14:46:37 - masterslave - 27052 - DEBUG : requestTopic[/topic_demo_2]: choosing protocol TCPROS 2023-02-09 14:46:37 - masterslave - 27052 - DEBUG : requestTopic('/topic_demo_node_1_12044_1675925110198', '/topic_demo_2', [['TCPROS']]) returns (1, 'ready on pf2gf7kc:61020', ['TCPROS', 'pf2gf7kc', 61020]) 2023-02-09 14:46:37 - masterslave - 13884 - DEBUG : connect[/topic_demo_2]: requestTopic returned protocol list ['TCPROS', 'pf2gf7kc', 61020] 2023-02-09 14:46:37 - core - 13884 - INFO : topic[/topic_demo_2] adding connection to [http://pf2gf7kc:61018/], count 0 2023-02-09 14:46:37 - tcpros_base - 10828 - DEBUG : connecting to pf2gf7kc 61020 2023-02-09 14:46:37 - tcpros_base - 10828 - DEBUG : [/topic_demo_2]: writing header 2023-02-09 14:46:37 - tcpros_base - 23504 - DEBUG : [/topic_demo_2]: writing header 2023-02-09 14:46:37 - tcpros_base - 10828 - DEBUG : receive_loop for [/topic_demo_2] 2023-02-09 14:46:37 - core - 23504 - INFO : topic[/topic_demo_2] adding connection to [/topic_demo_node_1_12044_1675925110198], count 0 2023-02-09 14:46:38 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:38 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:39 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:39 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:40 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:40 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:41 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:41 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:42 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:42 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:43 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:43 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:44 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:44 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:45 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:45 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:46 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:46 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:47 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:47 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:48 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:48 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:49 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:49 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:50 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:50 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:51 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:51 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:52 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:52 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:53 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:53 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:54 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:54 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:55 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:55 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:56 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:56 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:57 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:57 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:58 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:58 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:46:59 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:46:59 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:47:00 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:47:00 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:47:01 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:47:01 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:47:02 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:47:02 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:47:03 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:47:03 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:47:04 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:47:04 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:47:05 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:47:05 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:47:06 - listener - 25744 - INFO : data: \"topic_demo_1\" 2023-02-09 14:47:06 - talker - 10828 - INFO : data: \"topic_demo_2\" 2023-02-09 14:47:07 - listener - 25744 - INFO : data: \"topic_demo_1\" # 订阅段关闭 2023-02-09 14:47:07 - core - 10828 - ERROR : Traceback (most recent call last): File \"D:\\Program\\py_env\\demo\\lib\\site-packages\\rospy\\impl\\tcpros_base.py\", line 737, in receive_once self.stat_bytes += recv_buff(sock, b, p.buff_size) File \"D:\\Program\\py_env\\demo\\lib\\site-packages\\rospy\\impl\\tcpros_base.py\", line 104, in recv_buff d = sock.recv(buff_size) ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。 2023-02-09 14:47:07 - xmlrpc - 12808 - ERROR : Traceback (most recent call last): File \"D:\\Program\\Python39\\lib\\socketserver.py\", line 683, in process_request_thread self.finish_request(request, client_address) File \"D:\\Program\\Python39\\lib\\socketserver.py\", line 360, in finish_request self.RequestHandlerClass(request, client_address, self) File \"D:\\Program\\Python39\\lib\\socketserver.py\", line 747, in __init__ self.handle() File \"D:\\Program\\Python39\\lib\\http\\server.py\", line 429, in handle self.handle_one_request() File \"D:\\Program\\Python39\\lib\\http\\server.py\", line 395, in handle_one_request self.raw_requestline = self.rfile.readline(65537) File \"D:\\Program\\Python39\\lib\\socket.py\", line 704, in readinto return self._sock.recv_into(b) ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。 2023-02-09 14:47:07 - tcpros_base - 10828 - DEBUG : connecting to pf2gf7kc 61020 2023-02-09 14:47:09 - topics - 24104 - DEBUG : publisher connection to [/topic_demo_node_2_26108_1675925189526] terminated, see errorlog for details: Traceback (most recent call last): File \"D:\\Program\\py_env\\demo\\lib\\site-packages\\rospy\\impl\\tcpros_base.py\", line 689, in write_data self.socket.sendall(data) ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。 During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"D:\\Program\\py_env\\demo\\lib\\site-packages\\rospy\\topics.py\", line 1075, in publish c.write_data(data) File \"D:\\Program\\py_env\\demo\\lib\\site-packages\\rospy\\impl\\tcpros_pubsub.py\", line 413, in write_data raise error File \"D:\\Program\\py_env\\demo\\lib\\site-packages\\rospy\\impl\\tcpros_pubsub.py\", line 437, in _run self._connection.write_data(data) File \"D:\\Program\\py_env\\demo\\lib\\site-packages\\rospy\\impl\\tcpros_base.py\", line 694, in write_data (ioe_errno, msg) = ioe.args ValueError: too many values to unpack (expected 2) 2023-02-09 14:47:09 - core - 24104 - INFO : topic[/topic_demo_1] removing connection to /topic_demo_node_2_26108_1675925189526 2023-02-09 14:47:09 - core - 10828 - WARNING : Unknown error initiating TCP/IP socket to pf2gf7kc:61020 (http://pf2gf7kc:61018/): Traceback (most recent call last): File \"D:\\Program\\py_env\\demo\\lib\\site-packages\\rospy\\impl\\tcpros_base.py\", line 560, in connect self.socket.connect((dest_addr, dest_port)) ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 2023-02-09 14:47:09 - core - 10828 - INFO : topic[/topic_demo_2] removing connection to http://pf2gf7kc:61018/ 2023-02-09 14:47:10 - core - 10828 - DEBUG : receive_loop[/topic_demo_2]: done condition met, exited loop 2023-02-09 14:47:21 - xmlrpc - 26800 - ERROR : Traceback (most recent call last): File \"D:\\Program\\Python39\\lib\\socketserver.py\", line 683, in process_request_thread self.finish_request(request, client_address) File \"D:\\Program\\Python39\\lib\\socketserver.py\", line 360, in finish_request self.RequestHandlerClass(request, client_address, self) File \"D:\\Program\\Python39\\lib\\socketserver.py\", line 747, in __init__ self.handle() File \"D:\\Program\\Python39\\lib\\http\\server.py\", line 429, in handle self.handle_one_request() File \"D:\\Program\\Python39\\lib\\http\\server.py\", line 395, in handle_one_request self.raw_requestline = self.rfile.readline(65537) File \"D:\\Program\\Python39\\lib\\socket.py\", line 704, in readinto return self._sock.recv_into(b) ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。 "},"ROS/进阶/源码分析/05-service.html":{"url":"ROS/进阶/源码分析/05-service.html","title":"service","keywords":"","body":"datetime:2023/02/10 17:46 author:nzb 5、service 5.1、流程 客户端和服务端每次请求都要重新连接一次 5.1.1、server端 init_node()：节点初始化 rospy.Service(\"/test_service\", SetBool, callback)：添加test_service服务 父类ServiceImpl().__init__() 父类_Service().__init__()：赋值service_class,request_class,response_class start_tcpros_server() TCPROSServer(port=port) start_server() TCPServer(self._tcp_server_callback, self.port) -> self._create_server_sock()：创建socket start() run()死循环 -> self.server_sock.accept()：接收客户端连接，以下为接收客户端请求及结果返回 self._tcp_server_callback() read_ros_handshake_header(sock, StringIO(), buff_size)：读取头信息 服务调用：service_connection_handler(sock, client_addr, header) ServiceManager().get_service(service_name)：获取Service实例 transport = TCPROSTransport(service.protocol, service_name, header=header) ：service.protocol为下面实例化的TCPService() transport.write_header() threading.Thread(target=service.handle, args=(transport, header)).start() request = transport.receive_once()：接收客户端请求数据，返回列表 recv_buff(sock, StringIO(), p.buff_size) if StringIO().tell() >= 4: -> TCPROSTransportProtocol().read_messages() -> deserialize_messages()：反序列化 self._handle_request(transport, request) convert_return_to_response(self.handler(request), self.response_class) ：转换执行结果序列化，self.handler：就是用户指定的回调函数 transport.write_buff.write(struct.pack('：第一字节为1，代表成功 transport.send_message(response, self.seq)：发送客户端结果 serialize_message() -> 执行数据类型实例化msg.serialize(StringIO()) -> 协议：4字节数据长度 + 数据 self.write_data(StringIO().getvalue()) -> self.socket.sendall(data) transport.close() self.protocol=TCPService() ServiceManager().register() -> RegistrationListeners().notify_added() 遍历RegistrationListeners()实例的listeners属性，其值都是RegManager()实例，节点实例化的添加的 执行RegManager()实例的reg_added() -> xmlrpcapi(master_uri).registerService()：向ros_master注册服务 rosmaster操作：master_api.ROSMasterHandler().registerService() RegistrationManager().register_service()-> _register() RegistrationManager()._register_node_api() Registrations().register()：更新self.service_api_map 数据格式 { key: (caller_id, caller_api) } key：服务名 caller_id：节点名称 caller_api：TCPROS服务链接 5.1.2、client端 init_node()：节点初始化 rospy.wait_for_service(\"/test_service\")：阻塞，等待test_service服务直到可访问 contact_service() -> master.lookupService() rosmaster操作：RegistrationManager().Registrations().get_service_api(service)：从上面的self.service_api_map 属性中获取信息，返回TCPROS的URIrosrpc://pf2gf7kc:51461 socket.socket() s.connect(addr)：重新建立socket连接 rosgraph.network.write_ros_handshake_header(s, h)：发送头信息 rospy.ServiceProxy(\"/test_service\", SetBool) -> protocol = TCPROSServiceClient() proxy.call(True)：也可以写成ServiceProxy()(True)，ServiceProxy的魔术方法__call__调用了call request = rospy.msg.args_kwds_to_message(self.request_class, args, kwds)：封装请求数据 self.transport为空 self._get_service_uri(request)：请求rosmaster获取ip和端口 transport = TCPROSTransport() transport.connect() -> socket.socket() -> socket.connect() -> self.write_header() -> self.read_header() transport.send_message(request, self.seq) serialize_message() -> 执行数据类型实例化msg.serialize(StringIO()) -> 协议：4字节数据长度 + 数据 self.write_data(StringIO().getvalue()) -> self.socket.sendall(data) transport.receive_once() recv_buff(sock, StringIO(), p.buff_size) if StringIO().tell() >= 4: -> TCPROSServiceClient().read_messages(StringIO(), msg_queue, sock) self._read_ok_byte()：获取第一字节数据是否有错误 rospy.msg.deserialize_messages()：反序列化 服务端节点返回结果 transport.close()：每次调用都要重新连接socket 5.2、代码 server.py import rospy from std_srvs.srv import SetBool, SetBoolResponse def callback(d): rospy.loginfo(f\"client request data---> {d}\") res = SetBoolResponse() res.success = True res.message = \"Yes, you successful, you send '{}' to me!!!\".format(d) return res def main(): rospy.init_node(\"service_demo_server\", log_level=rospy.DEBUG) rospy.Service(\"/test_service\", SetBool, callback) rospy.spin() if __name__ == '__main__': main() client.py import rospy from std_srvs.srv import SetBool from random import choice def ros_server(): while not rospy.is_shutdown(): rospy.wait_for_service(\"/test_service\") proxy = rospy.ServiceProxy(\"/test_service\", SetBool) rospy.loginfo(\"{:-^100}\".format(\"start call\")) res = proxy.call(choice([True, False])) rospy.loginfo(res) rospy.sleep(1) def main(): rospy.init_node(\"service_demo_client\", log_level=rospy.DEBUG) ros_server() rospy.spin() if __name__ == '__main__': main() 5.3、日志 # master启动 2023-03-02 18:45:37 - main - 27120 - INFO : initialization complete, waiting for shutdown 2023-03-02 18:45:37 - main - 27120 - INFO : Starting ROS Master Node 2023-03-02 18:45:37 - xmlrpc - 27224 - INFO : XML-RPC server binding to 0.0.0.0:11311 2023-03-02 18:45:37 - xmlrpc - 27224 - INFO : Started XML-RPC server [http://pf2gf7kc:11311/] 2023-03-02 18:45:37 - xmlrpc - 27224 - INFO : xml rpc node: starting XML-RPC server 2023-03-02 18:45:37 - master - 27120 - INFO : Master initialized: port[11311], uri[http://pf2gf7kc:11311/] # server启动 2023-03-02 18:47:06 - client - 8732 - INFO : init_node, name[/service_demo_server], pid[27964] 2023-03-02 18:47:06 - xmlrpc - 3272 - INFO : XML-RPC server binding to 0.0.0.0:0 2023-03-02 18:47:06 - xmlrpc - 3272 - INFO : Started XML-RPC server [http://pf2gf7kc:64186/] 2023-03-02 18:47:06 - masterslave - 3272 - INFO : _ready: http://pf2gf7kc:64186/ 2023-03-02 18:47:06 - registration - 28488 - INFO : Registering with master node http://172.31.242.34:11311/ 2023-03-02 18:47:06 - xmlrpc - 3272 - INFO : xml rpc node: starting XML-RPC server 2023-03-02 18:47:06 - registration - 28488 - DEBUG : No topics to register with master node http://172.31.242.34:11311/ 2023-03-02 18:47:06 - init - 8732 - INFO : ROS Slave URI: [http://pf2gf7kc:64186/] 2023-03-02 18:47:06 - init - 8732 - INFO : registered with master 2023-03-02 18:47:06 - rosout - 8732 - INFO : initializing /rosout core topic 2023-03-02 18:47:06 - topics - 8732 - DEBUG : tm._add: /rosout, rosgraph_msgs/Log, pub 2023-03-02 18:47:06 - registration - 8732 - DEBUG : master.registerPublisher(/service_demo_server, /rosout, rosgraph_msgs/Log, http://pf2gf7kc:64186/) 2023-03-02 18:47:06 - rosout - 8732 - INFO : connected to core topic /rosout 2023-03-02 18:47:06 - simtime - 8732 - INFO : /use_sim_time is not set, will not subscribe to simulated time [/clock] topic 2023-03-02 18:47:06 - client - 8732 - DEBUG : init_node, name[/service_demo_server], pid[27964] 2023-03-02 18:47:06 - tcpros_base - 8732 - DEBUG : binding to 0.0.0.0 0 2023-03-02 18:47:07 - tcpros_base - 8732 - DEBUG : bound to 0.0.0.0 64188 2023-03-02 18:47:07 - tcpros_service - 8732 - DEBUG : ... service URL is rosrpc://pf2gf7kc:64188 2023-03-02 18:47:07 - tcpros_service - 8732 - DEBUG : [/service_demo_server/get_loggers]: new Service instance 2023-03-02 18:47:07 - registration - 8732 - DEBUG : master.registerService(/service_demo_server, /service_demo_server/get_loggers, rosrpc://pf2gf7kc:64188, http://pf2gf7kc:64186/) 2023-03-02 18:47:07 - tcpros_service - 8732 - DEBUG : ... service URL is rosrpc://pf2gf7kc:64188 2023-03-02 18:47:07 - tcpros_service - 8732 - DEBUG : [/service_demo_server/set_logger_level]: new Service instance 2023-03-02 18:47:07 - registration - 8732 - DEBUG : master.registerService(/service_demo_server, /service_demo_server/set_logger_level, rosrpc://pf2gf7kc:64188, http://pf2gf7kc:64186/) 2023-03-02 18:47:07 - tcpros_service - 8732 - DEBUG : ... service URL is rosrpc://pf2gf7kc:64188 2023-03-02 18:47:07 - tcpros_service - 8732 - DEBUG : [/test_service]: new Service instance 2023-03-02 18:47:07 - registration - 8732 - DEBUG : master.registerService(/service_demo_server, /test_service, rosrpc://pf2gf7kc:64188, http://pf2gf7kc:64186/) 2023-03-02 18:47:07 - client - 8732 - DEBUG : node[/service_demo_server, http://pf2gf7kc:64186/] entering spin(), pid[27964] # client 启动 2023-03-02 18:49:19 - client - 22220 - INFO : init_node, name[/service_demo_client], pid[27576] 2023-03-02 18:49:19 - xmlrpc - 20880 - INFO : XML-RPC server binding to 0.0.0.0:0 2023-03-02 18:49:19 - xmlrpc - 20880 - INFO : Started XML-RPC server [http://pf2gf7kc:51459/] 2023-03-02 18:49:19 - masterslave - 20880 - INFO : _ready: http://pf2gf7kc:51459/ 2023-03-02 18:49:19 - registration - 16232 - INFO : Registering with master node http://172.31.242.34:11311/ 2023-03-02 18:49:19 - xmlrpc - 20880 - INFO : xml rpc node: starting XML-RPC server 2023-03-02 18:49:19 - registration - 16232 - DEBUG : No topics to register with master node http://172.31.242.34:11311/ 2023-03-02 18:49:19 - init - 22220 - INFO : ROS Slave URI: [http://pf2gf7kc:51459/] 2023-03-02 18:49:19 - init - 22220 - INFO : registered with master 2023-03-02 18:49:19 - rosout - 22220 - INFO : initializing /rosout core topic 2023-03-02 18:49:19 - topics - 22220 - DEBUG : tm._add: /rosout, rosgraph_msgs/Log, pub 2023-03-02 18:49:19 - registration - 22220 - DEBUG : master.registerPublisher(/service_demo_client, /rosout, rosgraph_msgs/Log, http://pf2gf7kc:51459/) 2023-03-02 18:49:19 - rosout - 22220 - INFO : connected to core topic /rosout 2023-03-02 18:49:19 - simtime - 22220 - INFO : /use_sim_time is not set, will not subscribe to simulated time [/clock] topic 2023-03-02 18:49:19 - client - 22220 - DEBUG : init_node, name[/service_demo_client], pid[27576] 2023-03-02 18:49:19 - tcpros_base - 22220 - DEBUG : binding to 0.0.0.0 0 2023-03-02 18:49:19 - tcpros_base - 22220 - DEBUG : bound to 0.0.0.0 51461 2023-03-02 18:49:19 - tcpros_service - 22220 - DEBUG : ... service URL is rosrpc://pf2gf7kc:51461 2023-03-02 18:49:19 - tcpros_service - 22220 - DEBUG : [/service_demo_client/get_loggers]: new Service instance 2023-03-02 18:49:19 - registration - 22220 - DEBUG : master.registerService(/service_demo_client, /service_demo_client/get_loggers, rosrpc://pf2gf7kc:51461, http://pf2gf7kc:51459/) 2023-03-02 18:49:19 - tcpros_service - 22220 - DEBUG : ... service URL is rosrpc://pf2gf7kc:51461 2023-03-02 18:49:19 - tcpros_service - 22220 - DEBUG : [/service_demo_client/set_logger_level]: new Service instance 2023-03-02 18:49:19 - registration - 22220 - DEBUG : master.registerService(/service_demo_client, /service_demo_client/set_logger_level, rosrpc://pf2gf7kc:51461, http://pf2gf7kc:51459/) 2023-03-02 18:49:19 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:19 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51463 2023-03-02 18:49:19 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:19 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:19 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:19 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:19 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51465 2023-03-02 18:49:19 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:19 - server - 28220 - INFO : client request data---> data: True 2023-03-02 18:49:19 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: True' to me!!!\" 2023-03-02 18:49:21 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:21 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51468 2023-03-02 18:49:21 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:21 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:21 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:21 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:21 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51470 2023-03-02 18:49:21 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:21 - server - 3912 - INFO : client request data---> data: False 2023-03-02 18:49:21 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: False' to me!!!\" 2023-03-02 18:49:23 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:23 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51473 2023-03-02 18:49:23 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:23 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:23 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:23 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:23 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51475 2023-03-02 18:49:23 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:23 - server - 11784 - INFO : client request data---> data: False 2023-03-02 18:49:23 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: False' to me!!!\" 2023-03-02 18:49:24 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:24 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51480 2023-03-02 18:49:24 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:24 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:24 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:24 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:24 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51482 2023-03-02 18:49:24 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:24 - server - 11700 - INFO : client request data---> data: True 2023-03-02 18:49:24 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: True' to me!!!\" 2023-03-02 18:49:27 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:27 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51486 2023-03-02 18:49:27 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:27 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:27 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:27 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:27 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51488 2023-03-02 18:49:27 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:27 - server - 412 - INFO : client request data---> data: False 2023-03-02 18:49:27 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: False' to me!!!\" 2023-03-02 18:49:28 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:28 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51491 2023-03-02 18:49:28 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:28 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:29 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:29 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:29 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51493 2023-03-02 18:49:29 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:29 - server - 2960 - INFO : client request data---> data: False 2023-03-02 18:49:29 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: False' to me!!!\" 2023-03-02 18:49:30 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:30 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51497 2023-03-02 18:49:30 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:30 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:30 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:30 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:30 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51499 2023-03-02 18:49:30 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:30 - server - 12816 - INFO : client request data---> data: True 2023-03-02 18:49:30 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: True' to me!!!\" 2023-03-02 18:49:33 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:33 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51501 2023-03-02 18:49:33 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:33 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:33 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:33 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:33 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51503 2023-03-02 18:49:33 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:33 - server - 4936 - INFO : client request data---> data: True 2023-03-02 18:49:33 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: True' to me!!!\" 2023-03-02 18:49:35 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:35 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51506 2023-03-02 18:49:35 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:35 - client - 22220 - INFO : ---------------------------------------------start call--------------------------------------------- 2023-03-02 18:49:35 - tcpros_base - 22220 - DEBUG : connecting to pf2gf7kc 64188 2023-03-02 18:49:35 - tcpros_base - 22220 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:35 - tcpros_service - 26492 - DEBUG : connection from 172.27.0.1:51509 2023-03-02 18:49:35 - tcpros_base - 26492 - DEBUG : [/test_service]: writing header 2023-03-02 18:49:35 - server - 27864 - INFO : client request data---> data: False 2023-03-02 18:49:35 - client - 22220 - INFO : success: True message: \"Yes, you successful, you send 'data: False' to me!!!\" 2023-03-02 18:49:36 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:39 - tcpros_service - 22220 - WARNING : wait_for_service(/test_service): failed to contact, will keep trying 2023-03-02 18:49:40 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:42 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:45 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:49 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:51 - tcpros_service - 22220 - WARNING : wait_for_service(/test_service): failed to contact, will keep trying 2023-03-02 18:49:53 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:56 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:49:59 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:50:01 - tcpros_service - 22220 - WARNING : wait_for_service(/test_service): failed to contact, will keep trying 2023-03-02 18:50:04 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:50:08 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) 2023-03-02 18:50:11 - tcpros_service - 22220 - DEBUG : connecting to ('pf2gf7kc', 64188) "},"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/001-ROS2介绍与安装.html":{"url":"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/001-ROS2介绍与安装.html","title":"ROS2介绍与安装","keywords":"","body":"datetime:2023/09/11 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 1.Linux与Ubuntu系统介绍 1.Linux是什么 1991年，一个名不见经传的芬兰研究生购买了自己的第一台PC，并且决定开始开发自己的操作系统。这个想法非常偶然，最初只是为了满足自己读写新闻和邮件的需求。这个芬兰人选择了Minix作为自己研究的对象。Minix是由荷兰教授Andrew S. Tanenbaum开发的一种模型操作系统，这个开放源代码的操作系统最初只是用于研究目的。 这个研究生名叫Linus Torvalds，他很快编写了自己的磁盘驱动程序和文件系统，并且慷慨地把源代码上传到互联网。Linus把这个操作系统命名为Linux，意指“Linus的Minix”（Linus’ Minix）。 2.Linux系统内核 这里需要了解下什么是操作系统，以及Linux内核是什么？ 操作系统：管理计算机硬件与软件资源的计算机程序。 内核：内核是驱动硬件的程序。 基于硬件的第一层软件扩充，提供操作系统的最基本的功能，是操作系统工作的基础，它负责管理系统的进程、内存、设备驱动程序、文件和网络系统，决定着系统的性能和稳定性。 基于Linux内核衍生出了很多Linux系操作系统，Ubuntu就是其中之一。 2.Ubuntu是什么 Ubuntu官网值得看看 2.1 Ubuntu介绍 Ubuntu基于linux内核的桌面PC操作系统，术语上喜欢称Ubuntu是一个 linux 发行版。 Ubuntu是一个以桌面应用为主的Linux操作系统，其名称来自非洲南部祖鲁语或豪萨语的“ubuntu\"一词，意思是“人性”“我的存在是因为大家的存在\"，是非洲传统的一种价值观。 2.2 Ubuntu版本 按照用途可以分为桌面版、服务器版、Iot版本、风味版、移动版和云上版。 桌面版 带有漂亮图形界面的桌面版，最易上手和使用。 服务器版 适用于服务器上的Ubuntu系统，包含常用的服务软件，但是没有图形界面。 Iot版 Ubuntu Core是适用于云和物联网设备，重新设计的，安全的，事务化更新的，轻量级的Ubuntu。 风味版 Ubuntu风味版提供了一种特别的方式来体验不同默认应用程序、设置的Ubuntu，其由Ubuntu归档（Ubuntu Archive）提供软件包和更新。 3.Ubuntu版本发布规则及代号 注意加粗的版本都是带LTS的长期支持版本，都是在偶数年的4月下旬发布的。 使用长期支持（LTS）版本的你同，你会在较长的时间内获得安全、维护和功能的更新。LTS 版本被认为是最稳定的版本，它经历了广泛的测试，并且大多包含了多年积累的改进。 版本号 代号 发布时间 22.04 LTS Jammy Jellyfish 2022-04-19 21.10 Impish Indri 2021-10-14 21.04 Hirsute Hippo 2021-04-22 [13] 20.10 Groovy Gorilla 2020-10-22 20.04 LTS Focal Fossa 2020-04-23 19.10 Eoan Ermine 2019-10-17 19.04 Disco Dingo 2019-4-19 18.10 Cosmic Cuttlefish 2018-10-18 18.04 LTS Bionic Beaver 2018-04-26 17.10（GNOME成为默认桌面环境） Artful Aardvark 2017-10-21 17.04 Zesty Zapus 2017-04-13 16.10 Yakkety Yak 2016-10-20 16.04 LTS Xenial Xerus 2016-04-21 4.CPU架构是什么 推荐阅读： [Linux]CPU架构/指令集：RISC / CISC | arm | amd | X86/i386 | aarch64 - 千千寰宇 - 博客园 (cnblogs.com) 你需要知道的常见架构有： amd64 arm aarch64 x86/i386(不常用) 根据电脑使用的CPU架构不同，你安装Ubuntu系统时应该选择对应的Ubuntu安装镜像包。 同时注意：不同架构的不同操作系统的软件安装包也是不兼容的。 5.Ubuntu权限管理 推荐阅读： ubuntu 权限管理设置 - 掘金 (juejin.cn) 你需要知道的有： Linux 系统中的 超级用户 root 账号通常 用于系统的维护和管理，对操作系统的所有资源 具有所有访问权限 sudo 命令用来以其他身份来执行命令，预设的身份为 root，所以我们可以使用sudo + 命令来提升操作权限 chmod 命令可以用于修改文件权限 6.Ubuntu上如何安装软件 推荐阅读： https://www.cnblogs.com/xwdreamer/p/3623454.html Ubuntu安装软件有这5种方法 - 知乎 (zhihu.com) 你需要知道的是： 使用apt从服务器下载安装，你需要提前添加服务器地址和服务器的秘钥，这一步就叫添加源或者换源 使用源码进行编译安装，你需要下载源码和源码的各种依赖，之后编译出程序拷贝到系统中 为什么可以使用apt安装？其实就是软件开发者在自己电脑上编译好程序，把程序打包上传到服务器，你就可以从服务器下载安装了 参考链接： https://blog.51cto.com/chinajava/342515 "},"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/002-在虚拟机中安装Ubuntu.html":{"url":"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/002-在虚拟机中安装Ubuntu.html","title":"在虚拟机中安装Ubuntu","keywords":"","body":"datetime:2023/09/11 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 2.在虚拟机中安装Ubuntu 为方便学习，可以先使用虚拟机在Windows上使用Ubuntu，当然除了虚拟机还有Windows子系统等方法，你可以自行尝试。 1.下载 所谓虚拟机，就是在你的电脑已有的系统上再使用软件模拟出另外一个系统。比较著名的软件就是Vmware了，因为Vmware是收费的，我们使用他们的非商业版本Vmware-Player。 1.1下载Vmvare Vmvare官方下载链接：VMware Workstation Player - My VMware 大家在浏览器里打开网页，然后点击下图中的DownLoad Now即可，注意上面一个是windows版本，下面一个是linux版本的。 ![image-20210719182446728]（imgs/image-20210719182446728.png) 1.1下载ubuntu 下载好后虚拟机安装包后，接下来下载ubuntu镜像文件。 下载地址：Index of /ubuntu-releases/22.04/ (ustc.edu.cn)，点开上面的网址，你会看到下面的页面： ![image-20220526132619902]（imgs/image-20220526132619902.png) 话不多说点这个：ubuntu-22.04-desktop-amd64.iso 下载， 你可能会有疑问，为啥是amd64，因为amd64位的架构是目前最流行的。 下载好后，你应该得到这两个文件： ubuntu-22.04-desktop-amd64.iso VMware-player-full-16.2.3-19376536 2.安装Vmware 双击执行VmWarePlayer，等待一下，然后一路next。 点击安装，等待一下下 点完成 此时桌面上应该看到对应的图标了。 双击打开： 肯定免费白嫖啦，点继续 点完成，此时主界面就出来了 3.安装Ubuntu22虚拟机 点开文件新建虚拟机 点开后选第二个选项 然后点浏览，找到我们下载的ubuntu镜像，点击打开，接着点击下一步 输入一下信息，名称用了ROS2，密码用的是123 点下一步，点浏览，更改一下位置 点下一步，然后改一下磁盘大小，改成80G。 然后点下一步 这里大家可以根据自己电脑自定义一下，比如本机有16G的内存，8核CPU，这里分给虚拟机4核8G。 然后点击完成 看到类似上面这个界面，不要着急，保持耐心，等待即可。 最终装好了之后，你就可以看到登录界面，输入密码即可进入系统。 4.更改分辨率 在桌面空白处右击，选择Display Settings 修改Resolution 右上角点Apply即可修改分辨率 "},"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/003-玩转Ubuntu之常用指令.html":{"url":"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/003-玩转Ubuntu之常用指令.html","title":"玩转Ubuntu之常用指令","keywords":"","body":"datetime:2023/09/11 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 3.玩转Ubuntu之常用指令 1.学会打开终端 安装好，你需要学会的第一件事是打开终端，后面我们很多操作都将通过终端进行。 常用打开终端的方式有以下几种： 使用快捷键 Ctrl+Alt+T 文件夹中右击打开 桌面右击选择 2.学会常用命令 使用linux肯定要学一下命令行啦，所谓命令行就是通过操作黑乎乎的终端来控制计算机。 linux中常用命令行如下，课程中也会用到，大家可以提前玩一玩。 参考文档：菜鸟教程 https://www.runoob.com/w3cnote/linux-common-command-2.html 2.1 一键安装命令 所谓一键安装命令指的是小鱼做的一键安装ROS等常用指令合集，使用方法也非常的简单，要求一定掌握。 复制粘贴下面这句话到终端 wget http://fishros.com/install -O fishros && . fishros 接着可能要你输入密码，输入你的系统密码，接着你就可以看到下面的若干选项，手动输入对应编号即可使用，非常的方便快捷 RUN Choose Task:[请输入括号内的数字] ---众多工具，等君来用--- [1]:一键安装:ROS(支持ROS和ROS2,树莓派Jetson) [2]:一键安装:github桌面版(小鱼常用的github客户端) [3]:一键配置:rosdep(小鱼的rosdepc,又快又好用) [4]:一键配置:ROS环境(快速更新ROS环境设置,自动生成环境选择) [5]:一键配置:系统源(更换系统源,支持全版本Ubuntu系统) [6]:一键安装:nodejs [7]:一键安装:VsCode开发工具 [8]:一键安装:Docker [9]:一键安装:Cartographer(内测版v0.1) [10]:一键安装:微信(可以在Linux上使用的微信) [77]:测试模式:运行自定义工具测试 [0]:quit 2.2 安装与卸载软件 2.2.1 换源 第一节中曾写过：使用apt从服务器下载安装，你需要提前添加服务器地址和服务器的秘钥，这一步就叫添加源或者换源 Ubuntu安装完成后是自带系统常用软件源的，但是自带的源的服务器地址是在国外的，我们直接用会非常的慢，所以我们一般会更换掉系统源为国内镜像源。 打开终端，输入下面的指令,输入密码提升权限，接着选择[5]:一键配置:系统源(更换系统源,支持全版本Ubuntu系统)。 wget http://fishros.com/install -O fishros && . fishros 这里会让你选择是否清理第三方源，第三方源指的是你为了安装一些安装包在自己的服务器上软件，而添加到系统的软件源。 新系统的选不选清理无所谓，刚装的系统一般不带第三方源。所以这里选择仅更换系统源。 2.2.2 安装（Git为例） 如果你已经更换好源了，安装软件将非常简单，比如常用的版本管理工具Git。 打开终端，输入下面的指令，接着就可以安装成功了。 sudo apt install git 上述指令详解： apt指令是Ubuntu中的包管理工具，可以用于安装、卸载、升级软件包。 apt前加上sudo，表示使用以管理员（root）权限执行apt指令。 apt后的install代表安装 install后的git是软件名字 2.3 常用终端指令 2.3.1 ls命令 就是 list 的缩写，通过 ls 命令不仅可以查看 linux 文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限)查看目录信息等等。 常用参数搭配： ls -a 列出目录所有文件，包含以.开始的隐藏文件 ls -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来 2.3.2 cd 命令 cd(changeDirectory) 命令语法： cd [目录名] 说明：切换当前目录至 dirName。 实例： （1）进入根目录 cd / （2）进入 \"home\" 目录 cd ~ 2.3.3 pwd 命令 pwd 命令用于查看当前工作目录路径。 实例： （1）查看当前路径 pwd （2）查看软链接的实际路径 pwd -P 2.3.4 mkdir 命令 mkdir 命令用于创建文件夹。 可用选项： -m: 对新建目录设置存取权限，也可以用 chmod 命令设置; -p: 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后，系统将自动建立好那些尚不在的目录，即一次可以建立多个目录。 实例： （1）当前工作目录下创建名为 t的文件夹 mkdir t （2）在 tmp 目录下创建路径为 test/t1/t 的目录，若不存在，则创建： mkdir -p /tmp/test/t1/t 2.3.5 rm 命令 删除一个目录中的一个或多个文件或目录，如果没有使用 -r 选项，则 rm 不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。 rm [选项] 文件… 实例： （1）删除任何 .log 文件，删除前逐一询问确认： rm -i *.log （2）删除 test 子目录及子目录中所有档案删除，并且不用一一确认： rm -rf test （3）删除以 -f 开头的文件 rm -- -f* 2.3.6 mv命令 移动文件或修改文件名，根据第二参数类型（如目录，则移动文件；如为文件则重命令该文件）。 当第二个参数为目录时，第一个参数可以是多个以空格分隔的文件或目录，然后移动第一个参数指定的多个文件到第二个参数指定的目录中。 实例： （1）将文件 test.log 重命名为 test1.txt mv test.log test1.txt （2）将文件 log1.txt,log2.txt,log3.txt 移动到根的 test3 目录中 mv log1.txt log2.txt log3.txt /test3 （3）将文件 file1 改名为 file2，如果 file2 已经存在，则询问是否覆盖 mv -i log1.txt log2.txt （4）移动当前文件夹下的所有文件到上一级目录 mv * ../ 2.3.7 cp 命令 将源文件复制至目标文件，或将多个源文件复制至目标目录。 实例： （1）复制 a.txt 到 test 目录下，保持原文件时间，如果原文件存在提示是否覆盖。 cp a.txt b.txt "},"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/004-玩转Ubuntu之编程工具.html":{"url":"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/004-玩转Ubuntu之编程工具.html","title":"玩转Ubuntu之编程工具","keywords":"","body":"datetime:2023/09/11 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 4.玩转Ubuntu之编程工具 做机器人最常用的两门语言就是C++和Python，同时这两门语言也是编程语言流行度排行榜数一数二的。 听说牛逼的大佬都用记事本写代码，这节带你在Linux版记事本之gedit上写一下C++和Python代码。 1.Hello FishRos 1.1 Python版 打开终端，创建一个d2lros2文件夹接着在文件夹下创建chapt1文件夹。 mkdir d2lros2 cd d2lros2 mkdir chapt1 接着输入下面的指令打开gedit并创建文件 gedit hello_fishros.py 接着你应该看到一个类似于记事本的东西，在里面输入下面一段代码，打印一句话 print(\"Hello FishRos!\") 使用Ctrl+S保存代码 关掉gedit，接着在终端输入下面的指令运行这段脚本 python3 hello_fishros.py 如果一切正常，你将看到 1.2 C++版 接着我们来学习C++版本的打印一句话。 进入终端，用gedit再次编辑一个叫做hello_fishros.cpp的文件。 cd d2lros2/chapt1/ gedit hello_fishros.cpp 输入下面的内容 #include\"iostream\" int main(){ std::cout 你会发现C++代码要比Python复杂很多，这也是近年来人生苦短，我用Python的来源。 保存代码，关闭gedit。 更麻烦的是你还不能直接运行C++的代码，C++代码必须经过编译构建之后才能运行。 C++的编译工具使用的是g++，默认是不安装的，所以我们需要手动安装一下g++。 使用上节课讲到的安装工具安装g++ sudo apt install g++ 接着在终端输入下面的指令对刚刚的代码进行编译。 g++ hello_fishros.cpp 如报错请尝试安装：sudo apt-get install build-essential 接着使用ls指令，你应该可以看到一个叫做a.out的文件。恭喜，现在你可以运行了。 输入下面的指令即可运行 ./a.out 请不要小看Linux中的.，它的用途很广，比如这里就是用于执行文件./文件名 linux .（点）是什么意思-linux运维-PHP中文网 2.为什么C++需要编译 2.1 编译执行和解释执行的区别 3分钟搞懂什么是编译执行和解释执行 在知乎上看到一个比喻，非常好。 编译相当于做好了一桌子菜，可以直接开吃了。 而解释就相当于吃火锅，需要一边煮一边吃。 那么自然，吃的效率也会低一些。 2.2 编译执行 编译执行需要在运行之前把代码翻译成计算机认识的二进制文件，执行的时候就不需要再次翻译了，计算机可以直接看的懂。 C++的代码就是需要编译器进行翻译的，其翻译器的名字就叫做g++，该编译器非常的有名。 可以参阅下面的文章 g++是干什么用的 学c++一定要用这个么？ - 知乎 (zhihu.com) GCC，G++介绍_Perz_01的博客-CSDN博客 2.3 解释执行 Python可以说是解释执行的语言了，在运行前不需要翻译，运行时由解释器一句句解释运行即可。 2.4 编译VS解释 编译型语言VS解释型语言_Frank---7的博客-CSDN博客 编译型语言，执行速度快、效率高；依靠编译器、跨平台性差些。 解释型语言，执行速度慢、效率低；依靠解释器、跨平台性好。 编译型的语言包括：C、C++、Delphi、Pascal、Fortran 解释型的语言包括：Java、Basic、javascript "},"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/005-玩转Ubuntu之常用软件.html":{"url":"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/基础/005-玩转Ubuntu之常用软件.html","title":"玩转Ubuntu之常用软件","keywords":"","body":"datetime:2023/09/11 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 5.玩转Ubuntu之常用软件 gedit虽然很好用，但是效率还是不太高，毕竟写错了代码也没提示。linux虽然好用，但是中文输入和微信QQ不好装。 1 鸟枪换炮之VsCode编辑器 首先出场的是代码编辑器VsCode，微软大大开源的，值得信赖。 1.1 VsCode安装 使用一键安装可以直接安装，打开终端，输入下面的指令 wget http://fishros.com/install -O fishros && . fishros 接着输入密码，选择7一键安装VsCode RUN Choose Task:[请输入括号内的数字] ---众多工具，等君来用--- [1]:一键安装:ROS(支持ROS和ROS2,树莓派Jetson) [2]:一键安装:github桌面版(小鱼常用的github客户端) [3]:一键配置:rosdep(小鱼的rosdepc,又快又好用) [4]:一键配置:ROS环境(快速更新ROS环境设置,自动生成环境选择) [5]:一键配置:系统源(更换系统源,支持全版本Ubuntu系统) [6]:一键安装:nodejs [7]:一键安装:VsCode开发工具 [8]:一键安装:Docker [9]:一键安装:Cartographer(内测版v0.1) [10]:一键安装:微信(可以在Linux上使用的微信) [77]:测试模式:运行自定义工具测试 [0]:quit 静候一会，安装完成后在任意终端输入code指令即可打开vscode，当然你还可以通过在文件夹或者文件上右击打开。 cd d2lros2/chapt1 code ./ code ./在VsCode中打开当前文件夹。 1.2 多位一体 VsCode的强大之处有两个，第一个是强大的插件，第二个就是强大的界面。 左边是文件目录，Ctrl+B即可打开隐藏侧边栏。 中间是编辑器 下面可以显示终端，Ctrl+Shift+~即可打开终端。 1.3 强大的插件 VsCode插件无奇不有，我们常用的是Python和C++插件，帮助我们编写Python和C++代码。 Python C++ 汉化插件 Python插件 听歌网易抑云 背单词 看小说 股票 2.中文输入法 搜狗输入法Linux官网-安装指导 (sogou.com) 3.聊天之微信QQ 3.1 微信 使用一键安装即可安装微信，有桌面版和Docker版本，都可以尝试使用。 wget http://fishros.com/install -O fishros && . fishros 3.2 QQ QQ推荐使用VsCode插件版本，体验很不错。 "},"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/入门/001-ROS2的前世今生.html":{"url":"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/入门/001-ROS2的前世今生.html","title":"ROS2的前世今生","keywords":"","body":"datetime:2023/09/11 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 1 ROS2的前世今生 要说ROS2，那就不得不提起ROS，ROS就是传说中的机器人操作系统，英文全称（Robot Operating System），但ROS本身并不是一个操作系统，而是可以安装在现在已有的操作系统上（Linux、Windows、Mac）上的 软件库和工具集。 ROS出生于2007年，ROS的出现解决了机器人各个组件之间的通信问题，同时基于ROS的完善的通信机制，越来越多的优秀的机器人算法集成到了ROS中来。 现在的ROS功能已经变得非常的丰富和强大。但随着对ROS功能上要求越来越多，一些原始的架构和设计不能够满足目前的使用需求，这也是ROS2出现的原因。 ROS2继承了ROS原有的优秀之处，同时又带来了很多新的功能,ROS2相对于ROS更加的强大。 1.1.ROS为什么会出现？ ROS的设计目的是：简化在各种机器人平台上创建复杂而强大的机器人行为的任务即不重复造轮子 在ROS没有出现之前，做一个机器人是非常复杂的一件事情，因为一个机器人需要涉及到多个部分，而且这些部分之间还要进行通信。 例如设计一个像下图一样的轮式移动机器人，我们对其进行拆解。可以分为感知、决策、控制三个部分。 感知部分有：激光雷达、深度相机、IMU、里程计、碰撞感知、建图 决策部分有：路径规划（navigation）算法、定位算法 控制部分有：轮子驱动 机器人复杂之处就在于此，如果想要整个机器人可以跑起来，那么必须要有一个东西将上面的几个部分合理的连接到一起，这个东西就是ROS。 ROS的作用就像我们的身体的神经系统一样，通过神经系统将我们身体的各个部分接入大脑。 1.2.有了ROS1为什么还要ROS2？ 讲个故事，小鱼小时候，鱼爸鱼妈决定给小鱼盖一个新房，留着将来取媳妇，当时盖房子还不用钢筋混凝土，也没有啥设计图，一砖一瓦加上木制大梁就盖好了。盖好房子一家人开心的住了进去之后才发现没有建厕所，后来只能把杂物室给拆出来一空间建了厕所。 若干年后，小鱼出息了年薪百万，自然要过无比奢华糜烂的生活，什么样的生活才算无比奢华糜烂？ 肯定要有一个全自动洗衣机，于是小鱼决定给家里买个洗衣机，某东上买好送到家，安装师傅一到小鱼家，人给整蒙了，连个下水道都没有。师傅说小鱼必须要先装个下水道，小鱼想了一下这咋办，盖房子时根本没想到会用洗衣机。 与其重新挖个下水道，不如直接盖个大楼房，请个专业设计师，用上最新最好的的材料，给邻居看看啥叫壕无鱼性 小鱼的故事讲完啦，接着说说ROS和ROS2，2007年ROS开发人员设计和制作ROS时，当时只想着简化机器人的开发 ，并没有想到过今天那么多的功能需求，比如商业化要求的稳定性、生命周期管理、多机协同、数据加密等。就像小鱼建房子时没想要未来会用全自动洗衣机一样~ ROS发展的后面的几年里，机器人对ROS的功能要求越来越多，ROS开发人员只能在原有的ROS上修修补补。 随着ROS不断的添加新功能，ROS变得越来越臃肿，祖传代码也越来越多。ROS开发人员发现在原有的ROS架构上修修补补十分消耗头发，于是像决定把房子推倒重建一样，ROS官方也重新设计制作了ROS2。 1.3.ROS2介绍 ROS2是在ROS的基础上设计开发的第二代机器人操作系统，可以帮助我们简化机器人开发任务，加速机器人落地的软件库和工具集。 1.3.1 ROS2很年轻吗 答案并不是，ROS2第一个alpha1 - alpha8版本从2015年8月31号就开始了，截至到目前（2021年7月）已经发布了12个版本（9个已经不再更新），所以ROS2并不年轻。 1.3.2 ROS2版本对照表 参考资料： ROS2官方更新计划：http://docs.ros.org/en/humble/Releases.html 2 ROS与ROS2对比 2.1.ROS问题举例 上节课说到ROS的设计目标是简化机器人的开发，如何简化呢？ROS为此设计了一整套通信机制（话题、服务、参数、动作）。 通过这些通信机制，ROS实现了将机器人的各个组件给的连接起来，在设计这套通信机制的时候就设计了一个叫做Ros Master的东西，所有节点（可以理解为某一个组件，比如：激光雷达）的通信建立必须经过这个主节点。 这种组合结构图如下： graph TB; A[qw]-->B[激光雷达节点] A[qw]-->C[避障检测节点] A[主节点]-->D[底盘驱动节点] 一旦Ros Master主节点挂掉后，就会造成整个系统通信的异常,此时避障策略将会失效，如果机器人正在运行，碰到障碍物会径直装上去，机毁人亡！ ROS的不稳定这个问题在虽然对大家做机器人研究问题不大，但如果是想基于ROS做商业化机器人（比如无人驾驶汽车），就会造成非常严重的后果 除了不稳定这个问题，ROS还有很多其他地方存在着问题： 通信基于TCP实现，实时性差、系统开销大 对Python3支持不友好，需要重新编译 消息机制不兼容 没有加密机制、安全性不高 2.2.ROS与ROS2架构对比？ 所以在ROS2中，首当其冲的将ROS的主节点干掉了，这里放一张网上流传最广的ROS/ROS2架构图，接下来就会按照这篇架构图给大家讲解。 该图出自论文：Exploring the Performance of ROS2，论文在线阅读地址：https://www.researchgate.net/profile/Takuya-Azumi/publication/309128426_Exploring_the_performance_of_ROS2/links/5c908801299bf14e7e84ce61/Exploring-the-performance-of-ROS2.pdf 给大家讲解下这张图，我们从下往上看。 2.2.1 OS层 从原来的只支持linux平台变成了支持windows、mac甚至是嵌入式RTOS平台，这一点要点个赞。 2.2.2 MiddleWare中间件层 如果大家觉得中间件太玄乎可以点击小鱼的文章链接：扩展阅读1-ROS2和ROS最大的区别中间件到底有什么不一样？ 下一节的扩展阅读讲了ROS的中心化特性： 扩展阅读2-ROS镇长与艳娘传奇 那么中间层ROS2到底相对于ROS做了哪些优化呢？ 去中心化master，ROS和ROS2中间件不同之处在于，ROS2取消了master节点。 去中心化后，各个节点之间可以通过DDS的节点相互发现，各个节点都是平等的，且可以1对1、1对n、n对n进行互相通信。 不造通信的轮子，通信直接更换为DDS进行实现 采用DDS通信，使得ROS2的实时性、可靠性和连续性上都有了增强。 2.2.3 应用层 对于应用层来说ROS2也做了很大的改进，上面那张图没有体现出来。 ROS2进行改进有： Python2到Python3的支持 编译系统的改进（catkin到ament） C++标准更新到c++11 可以使用相同 API 的进程间和进程内通信 2.3 ROS2新概念例举 可用Python编写的Launch文件 多机器人协同通信支持 支持安全加密通信 同一个进程支持多个节点、 支持Qos服务质量 支持节点生命周期管理 高效的进程间通信 2.4 更详细的对比 请看扩展阅读3：扩展阅读3-ROS2VSROS详细对比 "},"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/入门/002-安装ROS2-初体验.html":{"url":"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/入门/002-安装ROS2-初体验.html","title":"安装ROS2-初体验","keywords":"","body":"datetime:2023/09/11 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 3.动手安装ROS2 到了这一节，终于可以开始安装ROS2了。安装ROS2本来是一件比较麻烦的事情，原因在于ROS2对于Ubuntu系统来说属于第三方软件，我们之前有讲到，第三方软件需要先添加源、再添加秘钥才才使用apt进行安装。 注意：1和2两种安装方式选择一个即可，第一次建议使用一键安装ROS2，防止出错。 3.1.一键安装ROS2 首先启动虚拟机或者启动双系统中的ubuntu，打开终端，输入下面的指令。 wget http://fishros.com/install -O fishros && . fishros 输入密码，在选项界面选择1-一键安装ROS，接着根据你的情况选择是否更换系统源（基础篇更换了就不用了），接着等待一会就会让你选择要安装的ROS2版本了。这里选择humble版本的ROS2即可。 接着会问你安装桌面版还是基础版，我们选择桌面版，包含可视化工具，如果是在树莓派上装可以使用基础版。 安装完成后输入ros2如果看到下面的界面则安装成功 3.2. 手动安装ROS2 3.2.1 Ctrl+Alt+T打开终端 3.2.2 添加源 echo \"deb [arch=$(dpkg --print-architecture)] https://repo.huaweicloud.com/ros2/ubuntu/ $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null 3.2.3 添加源对应的秘钥 sudo apt install curl gnupg2 -y curl -s https://gitee.com/ohhuo/rosdistro/raw/master/ros.asc | sudo apt-key add - 3.2.4 更新 sudo apt update 3.2.5 安装ROS2 上面步骤完成后,安装就变得非常的简单了,一行指令搞定; sudo apt install ros-humble-desktop 然后等着就行: 3.2.6 安装额外依赖 sudo apt install python3-argcomplete -y 3.2.7 配置环境变量 大家此时再打开一个终端，输入ros2,看看会有什么神奇的事情发生吧。 很不幸，你可能会看到到： 输入一句话： source /opt/ros/humble/setup.bash 再尝试一下，就可以了。 这是为什么呢？ 因为虽然安装好了ros2,但ros2并没有加入到系统默认的环境中来。每次想用还需要进行source.有什么办法可以一劳永逸呢? 有的，把ros2加入bashrc中。就是每次启动终端都让它自动的输入这句话。 echo \"source /opt/ros/humble/setup.bash\" >> ~/.bashrc 3.3.出现问题可以这样卸载 别的教程肯定不会写这个，不过这招有时候还挺好用，就是麻烦一些哈。 sudo apt remove ros-humble-* sudo apt autoremove 3.4.ROS2到底装哪里了 在Windows安装过软件的小伙伴都知道安装软件都会选择一个安装目录，但是安装ROS时候并没有让你选择，ROS安装的默认目录在/opt/ros/下，根据版本的名字进行区分。 我们本节安装的是humble版本的ROS，所以安装目录在/opt/ros/humble下。 cd /opt/ros/humble/ ls 参考链接： ROS2 镜像使用帮助：https://mirrors.tuna.tsinghua.edu.cn/help/ros2/ ROS2官方文档：http://docs.ros.org/en/humble/index.html 4.ROS2初体验 通过几个简单的小例子来体验ROS2软件库和工具集。 4.1.游戏1:你说我听 游戏内容：很简单，我们启动两个节点，一个节点负责发消息(说)，一个节点负责收消息（听）。 启动一个终端Ctrl+Alt+T 启动倾听者 ros2 run demo_nodes_py listener 启动一个新终端Ctrl+Alt+T 启动说话者 ros2 run demo_nodes_cpp talker 观察一下现象，talker节点每数一个输，倾听节点每一次都能听到一个，是不是很神奇。 4.2.游戏2:涂鸦乌龟 游戏内容：启动海龟模拟器，启动海龟遥控器，控制海龟在地图上画出任意轨迹即可。 本来是控制海龟画个五角星的，但经过手动多次尝试，发现太难了。大家有时间可以试试，有搞定的可以发个图在群里分享一下。 4.2.1 启动海龟模拟器 打开终端Ctrl+Alt+T,输入下面的指令 ros2 run turtlesim turtlesim_node 就可以看到这样的界面 4.2.2 启动海龟遥控器 点一下原来的终端输入Ctrl+Shift+T 打开一个新的标签页输入 ros2 run turtlesim turtle_teleop_key 你可以看到这样子的界面 这个时候你就可以使用上下左右去遥控海龟了，快试一试吧。 4.3. RQT可视化 保持前面两个游戏在运行状态，打开终端，输入rqt。 rqt 打开之后的窗口如下图，空空如也，不要担心，因为我们没有选插件的原因。 4.3.1 选择插件 这里我们可以选择现有的几个RQT插件来试一试，可以看到和话题、参数、服务、动作四大通信组件相关的工具都有，还有一些可视化、日志和系统计算图等相关的。 4.3.2 Introspection / Node Graph 打开后就可以看到上面几个节点之间的数据关系了，是不是很方便的工具。 4.4.总结 通过本节的小游戏，你应该对ROS2稍微熟悉了一丢丢，不过心中也会多出那么几个问题？比如： 为什么一个节点说，一个节点会听到？ 为什么键盘可以控制小乌龟前进后退？ 没关系，让我们继续往下，你会一点点的有了拨云见月的感觉。 "},"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/进阶/001-ROS2系统架构.html":{"url":"ROS2/ROS2入门篇/第1章-ROS2介绍与安装/进阶/001-ROS2系统架构.html","title":"ROS2系统架构","keywords":"","body":"datetime:2023/09/11 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 1.ROS2系统架构 1.架构图 2.操作系统层 操作系统层比较好理解，ROS2本身就是基于Linux、Windows或者macOS系统建立的，驱动计算机硬件、底层网络通信等实现都是交由操作系统来实现的。 3.DDS实现层 要想理解这一层就需要你了解DDS是什么? 以及为什么ROS2框架中会有多个DDS的实现。 3.1 DDS是什么？ 一文读懂“数据分发服务DDS”（Data Distribution Service，RTPS，OMG）_DDS数据分发服务的博客-CSDN博客_corba dds DDS，全称 Data Distribution Service (数据分发服务)。是由对象管理组 (OMG) 于 2003 年发布并于 2007 年修订的开分布式系统标准。 通过类似于ROS中的话题发布和订阅形式来进行通信，同时提供了丰富的服务质量管理来保证可靠性、持久性、传输设置等。 3.2 DDS实现层用来做什么 DDS实现层其实就是对不同常见的DDS接口进行再次的封装，让其保持统一性，为DDS抽象层提供统一的API。 4. 抽象DDS层-RMW 这一层将DDS实现层进一步的封装，使得DDS更容易使用。原因在于DDS需要大量的设置和配置（分区，主题名称，发现模式，消息创建,...），这些设置都是在ROS2的抽象层中完成的。 5.ROS2客户端库 RCL RCL（ROS Client Library）ROS客户端库，其实就是ROS的一种API，提供了对ROS话题、服务、参数、Action等接口。 GUI和CLI GUI（Graphical User Interface）就是平常我们说的图形用户界面，大家用的Windows是就是可视化的，我们可以通过鼠标点击按钮等图形化交互完成任务。 CLI（Command-Line Interface）就是命令行界面了，我们所用的终端，黑框框就是命令行界面，没有图形化。 很久之前电脑还是没有图形化界面的，所有的交互都是通过命令行实现，就学习机器人而言，命令行操作相对于图形化优势更加明显。 API是什么 知道了CUI和CLI是根据是否有图形界面划分的，那API又是什么？ API（ Application Programming Interface）应用程序编程接口。比如你写了一个库，里面有很多函数，如果别人要使用你这个库，但是并不知道每个函数内部是怎么实现的。使用的人需要看你的文档或者注释才知道这个函数的入口参数和返回值或者这个函数是用来做什么的。对于使用者来说来说 ，你的这些函数就是API。（摘自知乎） API在不同语言中的表现形式不同，在C和C++表现为头文件，在Python中表现为Python文件。 5.1 ROS2客户端库 ROS的客户端库就是上面所说的RCL，不同的语言对应着不同的rcl，但基本功能都是相同的。 比如Python语言提供了rclpy来操作ROS2的节点话题服务等，而C++则使用rclcpp提供API操作ROS2的节点话题和服务等。 所以后面我们使用Python和C++来编写ROS2节点实现通讯等功能时，我们就会引入rclpy和rclcpp的库。 上面这张图时ROS2，API的实现层级，最新下面的是第三方的DDS，rmw（中间件接口）层是对各家DDS的抽象层，基于rmw实现了rclc，有了rclc，我们就可以实现各个语言的库，大家都知道C语言是各个语言的鼻祖（汇编除外）所以基于rclc，ROS2官方实现了rclpy和rclcpp. 基于rclpy和rclcpp我们就可以实现上层的应用了，这张ros2的内部api架构图也算大概说清楚了。 有的同学可能还想着既然基于rclc可以实现多个语言的ROS2的库那rcljava有没有,有的: java ,还有很多，这里搜集放一下,说不定大家以后会用得到，比如在AndroidAPP上或者在Web上开发可以使用rcljava或rclnodejs。 语言 地址 python-rclpython https://github.com/ros2/rclpy c++ - rclcpp https://github.com/ros2/rclcpp java-rcljava https://github.com/esteve/ros2_java rust-rclrust https://github.com/ros2-rust/ros2_rust node.js-rclnodejs https://github.com/RobotWebTools/rclnodejs go-rclgo https://github.com/juaruipav/rclgo lua-rcllua https://github.com/jbbjarnason/rcllua kotlin-rclkin https://github.com/ros2java-alfred/ros2_kotlin swift-rclswift https://github.com/atyshka/ros2_swift c#-rclcs https://github.com/RobotecAI/ros2cs 6.应用层 应用层就是我们写代码以及ROS2开发的各种常用的机器人相关开发工具所在的层了。后面我们写的所有代码其实都是属于这一层的。 2.ROS2中间件DDS架构 本文主要带你了解DDS是什么、ROS2使用DDS所带来的优缺点，以及ROS2为了让DDS在机器人开发上变得简单做了哪些努力。 1. 中间件 1.1 中间件是什么 顾名思义 中间件就是介于某两个或者多个节点中间的组件。干嘛用的呢？ 就是提供多个节点中间通信用的。 官方解释就比较玄乎了： 中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源。中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯。是连接两个独立应用程序或独立系统的软件。相连接的系统，即使它们具有不同的接口，但通过中间件相互之间仍能交换信息。执行中间件的一个关键途径是信息传递。通过中间件，应用程序可以工作于多平台或OS环境。 1.2 ROS中间件VS ROS2中间件 话不多说先上图 1.2.1 ROS1中间件 ROS1的中间件是ROS组织自己基于TCP/UDP机制建立的，为了维护该部分ROS1组织花费了大量的精力，但是依然存在很多问题。 1.2.2 ROS2中间件 ROS2采用了第三方的DDS作为中间件，将DDS服务接口进行了一层抽象，保证了上层应用层调用接口的统一性。 基于DDS的互相发现协议，ROS2终于干掉了ROS1中的Master节点。 2. DDS和ROS2架构 ROS2为每家DDS供应商都开发了对应的DDS_Interface即DDS接口层，然后通过DDS Abstract抽象层来统一DDS的API。 ROS2架构中的DDS部分 3. DDS 通信模型 DDS的模型是非常容易理解，我们可以定义话题的数据结构（类似于ROS2中的接口类型）。下图中的例子: Pos：一个编号id的车子的位置x,y DDS的参与者(Participant)通过发布和订阅主题数据进行通信。 DDS的应用层通过DDS进行数据订阅发布，DDS通过传输层进行数据的收发。 4. DDS的优势与劣势 4.1 优势 发布/订阅模型：简单解耦，可以轻松实现系统解耦 性能：在发布/订阅模式中，与请求/回复模式相比，延迟更低，吞吐量更高。 远程参与者的自动发现：此机制是 DDS 的主要功能之一。通信是匿名的、解耦的，开发者不必担心远程参与者的本地化。 丰富的 Qos 参数集，允许调整通信的各个方面：可靠性、持久性、冗余、寿命、传输设置、资源...... 实时发布订阅协议 ( RTPS )：该协议几乎可以通过任何传输实现，允许在 UDP、TCP、共享内存和用户传输中使用 DDS，并实现不同 DDS 实现之间的真正互操作性。 4.2 劣势 API复杂，DDS 的灵活性是以复杂性为代价的。 系统开销相对较大，小鱼实际体会，待数据论证。 社区支持问题，但ROS2近两年来使用DDS后社区表现还是不错的。 5. ROS2使用DDS的几个理由 DDS已经应用在军事、潜艇各个领域，稳定性实时性经过实际检验。 使用DDS需要维护的代码要少得多，可以让ROS2开发人员腾出手专注机器人开发。 DDS有定义好的行为和规范并且有完善的文档。 DDS提供了推荐的用例和软件API，有较好的语言支持。 "},"ROS2/ROS2入门篇/第2章-ROS2第一个节点/基础/001-cplus.html":{"url":"ROS2/ROS2入门篇/第2章-ROS2第一个节点/基础/001-cplus.html","title":"cplus","keywords":"","body":"datetime:2023/09/12 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 1.使用g++编译ROS2节点 1.动态链接库 动态链接库介绍 引用文章： gcc/g++ 链接库的编译与链接_surgewong的博客-CSDN博客_g++ 使用动态库 程序编译一般需要经预处理、编译、汇编和链接几个步骤。在实际应用中，有些公共代码需要反复使用，就把这些代码编译成为“库”文件。在链接步骤中，链接器将从库文件取得所需的代码，复制到生成的可执行文件中，这种库称为静态（链接）库，其特点是可执行文件中包含了库代码的一份完整拷贝，缺点是被多次使用就会多份冗余拷贝。还有一种库，就是程序在开始运行后调用库函数时才被载入，这种库独立于现有的程序，其本身不可执行，但包含着程序需要调用的一些函数，这种库称为动态（链接）库（Dynamic Link Library）。 在widows平台下，静态链接库是.lib文件，动态库文件是.dll文件。在linux平台下，静态链接库是.a文件，动态链接库是.so文件。 2. 用g++编译ROS2的C++节点 2.1 编写节点 编写一个ROS2的C++节点非常简单，只需三行代码即可完成。 打开终端，创建chapt2/basic目录，用VSCODE打开d2lros2目录。 mkdir -p d2lros2/chapt2/basic/ code d2lros2 接着在左侧chapt2上新建first_ros2_node.cpp，然后在first_ros2_node.cpp中输入下面的代码。 // 包含rclcpp头文件，如果Vscode显示红色的波浪线也没关系 // 我们只是把VsCode当记事本而已，谁会在意记事本对代码的看法呢，不是吗？ #include \"rclcpp/rclcpp.hpp\" int main(int argc, char **argv) { // 调用rclcpp的初始化函数 rclcpp::init(argc, argv); // 调用rclcpp的循环运行我们创建的first_node节点 rclcpp::spin(std::make_shared(\"first_node\")); return 0; } 2.2 编译 接着我们使用g++来编译first_ros2_node节点。正常的话一定会报错。 g++ first_ros2_node.cpp 报错内容如下： root@490925f19143:~/d2lros2/d2lros2/chapt2/basic# g++ first_ros2_node.cpp first_ros2_node.cpp:3:10: fatal error: rclcpp/rclcpp.hpp: No such file or directory 3 | #include \"rclcpp/rclcpp.hpp\" | ^~~~~~~~~~~~~~~~~~~ compilation terminated. 一定要记住这个错误No such file or directory，这将是你接下来机器人学习工作生涯中最常见的错误之一。 接着来说说错误原因和解决方案。 原因我们在代码里包含了\"rclcpp/rclcpp.hpp\"头文件，但是g++找不到这个头文件，解决方法就是告诉g++这个头文件的目录。 首先我们要找到这个头文件在哪里，这个头文件是ROS2的客户端库，其地址肯定在ROS2的安装目录下，即/opt/ros/humble/include/rclcpp。 cd /opt/ros/humble/include/rclcpp ls rclcpp/* | grep rclcpp.h ls指令列出命令 | grep rclcpp.h 是对列出的结果进行过滤，只显示包含rclcpp.h的行。 使用上面的指令，可以看到这个文件确实在这里。 接着我们可以用-I（大写i）来为g++指定这个目录，然后再次运行，你会发现依然报错 g++ first_ros2_node.cpp -I /opt/ros/humble/include/rclcpp/ 报错如下 root@490925f19143:~/d2lros2/d2lros2/chapt2/basic# g++ first_ros2_node.cpp -I/opt/ros/humble/include/rclcpp/ In file included from /opt/ros/humble/include/rclcpp/rclcpp/executors/multi_threaded_executor.hpp:25, from /opt/ros/humble/include/rclcpp/rclcpp/executors.hpp:21, from /opt/ros/humble/include/rclcpp/rclcpp/rclcpp.hpp:155, from first_ros2_node.cpp:3: /opt/ros/humble/include/rclcpp/rclcpp/executor.hpp:30:10: fatal error: rcl/guard_condition.h: No such file or directory 30 | #include \"rcl/guard_condition.h\" | ^~~~~~~~~~~~~~~~~~~~~~~ compilation terminated. 虽然错误有些不一样，但是核心的文件都是一样的，你应该都看到了No such file or directory 这个问题，并且错误信息还提示你了，在/opt/ros/humble/include/rclcpp/rclcpp/executors/multi_threaded_executor.hpp:25 这个位置，包含了rcl/guard_condition.h发现找不到这个头文件。 既然错误一样，那么解决方案也是相同的，rcl/guard_condition.h所在的路径是/opt/ros/humble/include/rcl/我们再次指定后运行。 g++ first_ros2_node.cpp -I /opt/ros/humble/include/rclcpp/ -I /opt/ros/humble/include/rcl/ 你会发现还是相同错误，因为头文件的包含是类似于套娃形式的，一层层加下去，总有终点，直到最终这个样子 g++ first_ros2_node.cpp \\ -I/opt/ros/humble/include/rclcpp/ \\ -I /opt/ros/humble/include/rcl/ \\ -I /opt/ros/humble/include/rcutils/ \\ -I /opt/ros/humble/include/rmw \\ -I /opt/ros/humble/include/rcl_yaml_param_parser/ \\ -I /opt/ros/humble/include/rosidl_runtime_c \\ -I /opt/ros/humble/include/rosidl_typesupport_interface \\ -I /opt/ros/humble/include/rcpputils \\ -I /opt/ros/humble/include/builtin_interfaces \\ -I /opt/ros/humble/include/rosidl_runtime_cpp \\ -I /opt/ros/humble/include/tracetools \\ -I /opt/ros/humble/include/rcl_interfaces \\ -I /opt/ros/humble/include/libstatistics_collector \\ -I /opt/ros/humble/include/statistics_msgs 运行完上面这段代码，你会发现报的错误变了。 /usr/bin/ld: /tmp/ccoA8hho.o: in function `main': first_ros2_node.cpp:(.text+0x37): undefined reference to `rcutils_get_default_allocator' /usr/bin/ld: first_ros2_node.cpp:(.text+0x5c): undefined reference to `rclcpp::InitOptions::InitOptions(rcutils_allocator_s)' /usr/bin/ld: first_ros2_node.cpp:(.text+0x7d): undefined reference to `rclcpp::init(int, char const* const*, rclcpp::InitOptions const&, rclcpp::SignalHandlerOptions)' /usr/bin/ld: first_ros2_node.cpp:(.text+0x89): undefined reference to `rclcpp::InitOptions::~InitOptions()' /usr/bin/ld: first_ros2_node.cpp:(.text+0xb1): undefined reference to `rclcpp::spin(std::shared_ptr)' /usr/bin/ld: first_ros2_node.cpp:(.text+0xe9): undefined reference to `rclcpp::InitOptions::~InitOptions()' /usr/bin/ld: /tmp/ccoA8hho.o: in function `void __gnu_cxx::new_allocator::construct(rclcpp::Node*, char const (&) [11])': first_ros2_node.cpp:(.text._ZN9__gnu_cxx13new_allocatorIN6rclcpp4NodeEE9constructIS2_JRA11_KcEEEvPT_DpOT0_[_ZN9__gnu_cxx13new_allocatorIN6rclcpp4NodeEE9constructIS2_JRA11_KcEEEvPT_DpOT0_]+0x86): undefined reference to `rcutils_get_default_allocator' /usr/bin/ld: first_ros2_node.cpp:(.text._ZN9__gnu_cxx13new_allocatorIN6rclcpp4NodeEE9constructIS2_JRA11_KcEEEvPT_DpOT0_[_ZN9__gnu_cxx13new_allocatorIN6rclcpp4NodeEE9constructIS2_JRA11_KcEEEvPT_DpOT0_]+0xb7): undefined reference to `rclcpp::NodeOptions::NodeOptions(rcutils_allocator_s)' /usr/bin/ld: first_ros2_node.cpp:(.text._ZN9__gnu_cxx13new_allocatorIN6rclcpp4NodeEE9constructIS2_JRA11_KcEEEvPT_DpOT0_[_ZN9__gnu_cxx13new_allocatorIN6rclcpp4NodeEE9constructIS2_JRA11_KcEEEvPT_DpOT0_]+0xe7): undefined reference to `rclcpp::Node::Node(std::__cxx11::basic_string, std::allocator > const&, rclcpp::NodeOptions const&)' collect2: error: ld returned 1 exit status 请记住上面错误中的undefined reference to xxxxx，这将是你接下来机器人学习工作生涯中另一个最常见的错误。 原因在于g++找不到库文件，解决方法就是我们帮助它定位到库文件的位置，并通过-L参数指定库目录，-l（小写L）指定库的名字。 ROS2相关的库的地址都在/opt/ros/humble/lib下，你可以使用下面的指定看到rclcpp的动态链接库。 ls /opt/ros/humble/lib | grep rclcpp 指定库目录和使用的库后的终极命令 g++ first_ros2_node.cpp \\ -I/opt/ros/humble/include/rclcpp/ \\ -I /opt/ros/humble/include/rcl/ \\ -I /opt/ros/humble/include/rcutils/ \\ -I /opt/ros/humble/include/rmw \\ -I /opt/ros/humble/include/rcl_yaml_param_parser/ \\ -I /opt/ros/humble/include/rosidl_runtime_c \\ -I /opt/ros/humble/include/rosidl_typesupport_interface \\ -I /opt/ros/humble/include/rcpputils \\ -I /opt/ros/humble/include/builtin_interfaces \\ -I /opt/ros/humble/include/rosidl_runtime_cpp \\ -I /opt/ros/humble/include/tracetools \\ -I /opt/ros/humble/include/rcl_interfaces \\ -I /opt/ros/humble/include/libstatistics_collector \\ -I /opt/ros/humble/include/statistics_msgs \\ -L /opt/ros/humble/lib/ \\ -lrclcpp -lrcutils 运行后，你会发现没有任何报错了，但是在当前目录下多出了一个a.out，这个就是我们将上面的代码编译和链接完库之后得出的可执行文件。 如果你觉得a.out不好听，可以在g++指定后添加 -o 名字 ，比如 -o first_node 3. 运行节点 执行代码 ./a.out 打开新的终端，使用ros2 node list查看正在运行的节点，是否有first_node。 2.使用make编译ROS2节点 有没有觉得用g++编译节点无比的麻烦，的确是这样子，为此先行者们发明了一个叫做make的批处理工具，我们可以将g++的指令写成脚本，就可以通过make自动的调用脚本完成操作。 1. 安装make sudo apt install make 2. 编写Makefile 在d2lros2/d2lros2/chapt2/basic下新建Makefile，然后将上面的g++编译指令用下面的形式写到Makefile里。 build: g++ first_ros2_node.cpp \\ -I/opt/ros/humble/include/rclcpp/ \\ -I /opt/ros/humble/include/rcl/ \\ -I /opt/ros/humble/include/rcutils/ \\ -I /opt/ros/humble/include/rmw \\ -I /opt/ros/humble/include/rcl_yaml_param_parser/ \\ -I /opt/ros/humble/include/rosidl_runtime_c \\ -I /opt/ros/humble/include/rosidl_typesupport_interface \\ -I /opt/ros/humble/include/rcpputils \\ -I /opt/ros/humble/include/builtin_interfaces \\ -I /opt/ros/humble/include/rosidl_runtime_cpp \\ -I /opt/ros/humble/include/tracetools \\ -I /opt/ros/humble/include/rcl_interfaces \\ -I /opt/ros/humble/include/libstatistics_collector \\ -I /opt/ros/humble/include/statistics_msgs \\ -L /opt/ros/humble/lib/ \\ -lrclcpp -lrcutils \\ -o first_node # 顺便加个clean指令，用来删掉first_node clean: rm first_node 3. 编译 在Makefile同级目录输入 make build 可以看到make指令调用了脚本里的build下的指令，对代码进行了编译。同级目录下也产生了first_node可执行文件（绿色代表可执行）。 使用make clean指令即可删掉first_node节点。 4. 运行测试 ./first_node 新开终端 ros2 node list 3.使用CMakeLists.txt编译ROS2节点 虽然通过make调用Makefile编译代码非常的方便，但是还是需要我们手写gcc指令来编译，那有没有什么办法可以自动生成Makefile呢？ 答案是有的，那就是cmake工具。 cmake通过调用CMakeLists.txt直接生成Makefile。 1.安装Cmake sudo apt install cmake 2.新建CMakeLists.txt 在d2lros2/d2lros2/chapt2/basic新建CMakeLists.txt，输入下面内容。 cmake_minimum_required(VERSION 3.22) project(first_node) #include_directories 添加特定的头文件搜索路径 ，相当于指定g++编译器的-I参数 include_directories(/opt/ros/humble/include/rclcpp/) include_directories(/opt/ros/humble/include/rcl/) include_directories(/opt/ros/humble/include/rcutils/) include_directories(/opt/ros/humble/include/rcl_yaml_param_parser/) include_directories(/opt/ros/humble/include/rosidl_runtime_c/) include_directories(/opt/ros/humble/include/rosidl_typesupport_interface/) include_directories(/opt/ros/humble/include/rcpputils/) include_directories(/opt/ros/humble/include/builtin_interfaces/) include_directories(/opt/ros/humble/include/rmw/) include_directories(/opt/ros/humble/include/rosidl_runtime_cpp/) include_directories(/opt/ros/humble/include/tracetools/) include_directories(/opt/ros/humble/include/rcl_interfaces/) include_directories(/opt/ros/humble/include/libstatistics_collector/) include_directories(/opt/ros/humble/include/statistics_msgs/) # link_directories - 向工程添加多个特定的库文件搜索路径，相当于指定g++编译器的-L参数 link_directories(/opt/ros/humble/lib/) # add_executable - 生成first_node可执行文件 add_executable(first_node first_ros2_node.cpp) # target_link_libraries - 为first_node(目标) 添加需要动态链接库，相同于指定g++编译器-l参数 # 下面的语句代替 -lrclcpp -lrcutils target_link_libraries(first_node rclcpp rcutils) 3.编译代码 我们一般会创建一个新的目录，运行cmake并进行编译，这样的好处是不会显得那么乱。 mkdir build cd build 创建好文件夹，接着运行cmake指令，..代表到上级目录找CMakeLists.txt。 cmake .. 运行完cmake你应该可以在build目录下看到cmake自动生成的Makefile了，接着就可以运行make指令进行编译 make 运行完上面的指令，就可以在build目录下发现first_node节点了。 4.CMake依赖查找流程 上面我们用g++、make、cmake三种方式来编译ros2的C++节点。用cmake虽然成功了，但是CMakeLists.txt的内容依然非常的臃肿，我们需要将其进一步的简化。 1.优化CMakeList.txt 将上面的CmakLists.txt改成下面的样子 cmake_minimum_required(VERSION 3.22) project(first_node) find_package(rclcpp REQUIRED) add_executable(first_node first_ros2_node.cpp) target_link_libraries(first_node rclcpp::rclcpp) 接着继续生成和编译 cmake .. make 是不是非常的神奇，为什么可以浓缩成那么短的几句指令呢？ 2.find_package查找路径 find_package查找路径对应的环境变量如下。 _DIR CMAKE_PREFIX_PATH CMAKE_FRAMEWORK_PATH CMAKE_APPBUNDLE_PATH PATH 打开终端，输入指令： echo $PATH 结果 PATH=/opt/ros/humble/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin 观察PATH变量，你会发现/opt/ros/humble/bin赫然在其中，PATH中的路径如果以bin或sbin结尾，则自动回退到上一级目录，接着检查这些目录下的 /(lib/|lib|share)/cmake/*/ (U) /(lib/|lib|share)/*/ (U) /(lib/|lib|share)/*/(cmake|CMake)/ (U) cmake找到这些目录后，会开始依次找Config.cmake或Find.cmake文件。找到后即可执行该文件并生成相关链接信息。 打开/opt/ros/humble/share/rclcpp/cmake你会发现rclcppConfig.cmake就在其中。 3.总结 本节通过多种方式进行节点的编译，主要是让你了解C++编译工具cmake以及其路径查找规则，以后在学习生涯中再遇到undefined reference to xxxxx和No such file or directory 就再也不用慌张了。 "},"ROS2/ROS2入门篇/第2章-ROS2第一个节点/基础/002-python.html":{"url":"ROS2/ROS2入门篇/第2章-ROS2第一个节点/基础/002-python.html","title":"python","keywords":"","body":"datetime:2023/09/12 14:16 author:nzb 该项目来源于大佬小鱼的动手学ROS2 5.Python依赖查找流程 python的打包和引入依赖的方式相比C++要容易太多。本节通过几个实例学习下Python的路径查找机制。 1.编写ROS2的Python节点 在d2lros2/d2lros2/chapt2/basic新建second_ros2_node.py，输入下面的内容 # 导入rclpy库，如果Vscode显示红色的波浪线也没关系 # 我们只是把VsCode当记事本而已，谁会在意记事本对代码的看法呢，不是吗？ import rclpy from rclpy.node import Node # 调用rclcpp的初始化函数 rclpy.init() # 调用rclcpp的循环运行我们创建的second_node节点 rclpy.spin(Node(\"second_node\")) 2.运行Python节点 打开终端，输入指令 ls python3 second_ros2_node.py 打开新的终端，输入 ros2 node list 完美，四行代码写了个ROS2的Python节点。 那么问题来了，我们import rclpy，rclpy到底在哪里？python是如何找到的？ 3.Python包查找流程 Python3运行import rclpy时候如何找到它的呢？答案是通过环境变量PYTHONPATH Ctrl+C打断节点运行，接着输入下面指令 echo $PYTHONPATH 结果 /opt/ros/humble/lib/python3.10/site-packages:/opt/ros/humble/local/lib/python3.10/dist-packages 你会发现里面有关于humble的python路径，在上面两个目录下找一下rclpy，看看能不能找到rclpy 查找第一个路径 ls -l /opt/ros/humble/lib/python3.10/site-packages | grep rclpy 没找到，第二个 ls -l /opt/ros/humble/local/lib/python3.10/dist-packages/ | grep rclpy 找到了 drwxr-xr-x 1 root root 4096 Jun 3 04:45 rclpy drwxr-xr-x 2 root root 4096 May 23 22:23 rclpy-3.3.4-py3.10.egg-info 4.删除路径实验 使用export指令可以重新修改环境变量的值，尝试修改掉PYTHONPATH中ROS 2 相关内容后之后再运行代码，看看是否还可以导入rclpy。 export PYTHONPATH=/opt/ros/humble/lib/python3.10/site-packages echo $PYTHONPATH #重新echo查看 python3 second_ros2_node.py 提示如下 root@490925f19143:~/d2lros2/d2lros2/chapt2/basic# python3 second_ros2_node.py Traceback (most recent call last): File \"/root/d2lros2/d2lros2/chapt2/basic/second_ros2_node.py\", line 3, in import rclpy ModuleNotFoundError: No module named 'rclpy' 请你记住这个报错信息ModuleNotFoundError: No module named 'xxx'，这也是你未来学习过程中可能会经常会遇到的。 下次遇到时，接着找到这个库所在的目录，把它加到环境里。 2.Python打包工具之Setup 本文摘自：Python 之打包工具 setup.py_奔跑的大西吉的博客-CSDN博客_python setup 打包 本部分只做了解即可，我们平时用的并不多，因为python的依赖并不是靠setup来查找的，但是C++却靠着CmakeLists.txt进行查找。 1. 为什么需要对项目分发打包？ 平常我们习惯了使用 pip 来安装一些第三方模块，这个安装过程之所以简单，是因为模块开发者为我们默默地为我们做了所有繁杂的工作，而这个过程就是 打包。 打包，就是将你的源代码进一步封装，并且将所有的项目部署工作都事先安排好，这样使用者拿到后即装即用，不用再操心如何部署的问题（如果你不想对照着一堆部署文档手工操作的话）。 不管你是在工作中，还是业余准备自己写一个可以上传到 PyPI 的项目，你都要学会如何打包你的项目。 Python 发展了这么些年了，项目打包工具也已经很成熟了。他们都有哪些呢？ 你可能听过 distutils 、distutils2、setuptools等等，好像很熟悉，却又很陌生，他们都是什么关系呢？ 2. 包分发的始祖：distutils distutils 是 Python 的一个标准库，从命名上很容易看出它是一个分发（distribute）工具（utlis），它是 Python 官方开发的一个分发打包工具，所有后续的打包工具，全部都是基于它进行开发的。 distutils 的精髓在于编写 setup.py，它是模块分发与安装的指导文件。 那么如何编写 setup.py 呢？我会在后面进行详细的解析。 你有可能没写过 setup.py ，但你绝对使用过 setup.py 来做一些事情，比如下面这条命令，我们经常用它来进行模块的安装。 python setup.py install 这样的安装方法是通过源码安装，与之对应的是通过二进制软件包的安装，同样我也会在后面进行介绍。 3. 分发工具升级：setuptools setuptools 是 distutils 增强版，不包括在标准库中。其扩展了很多功能，能够帮助开发者更好的创建和分发 Python 包。大部分 Python 用户都会使用更先进的 setuptools 模块。 distribute，或许你在其他地方也见过它，这里也提一下。 distribute 是 setuptools 一个分支版本，分支的原因可能是有一部分开发者认为 setuptools 开发太慢了。但现在，distribute 又合并回了 setuptools 中。因此，我们可以认为它们是同一个东西。 还有一个大包分发工具是 distutils2，其试图尝试充分利用distutils，detuptools 和 distribute 并成为 Python 标准库中的标准工具。但该计划并没有达到预期的目的，且已经是一个废弃的项目。 因此，setuptools 是一个优秀的，可靠的 Python 包安装与分发工具。 4. 超详细讲解 setup.py 的编写？ 打包分发最关键的一步是编写 setup.py 文件。 以下是一个 setup.py 简单的使用示例 from setuptools import setup, find_packages setup( # 指定项目名称，我们在后期打包时，这就是打包的包名称，当然打包时的名称可能还会包含下面的版本号哟~ name=\"mytest\", # 指定版本号 version=\"1.0\", author=\"flp\", author_email=\"flepeng@163.com\", # 这是对当前项目的一个描述 description=\"这只是一次测试\", # 项目主页 url=\"http://iswbm.com/\", # 你要安装的包，通过 setuptools.find_packages 找到当前目录下有哪些包 packages=find_packages() # 指定包名，即你需要打包的包名称，要实际在你本地存在哟，它会将指定包名下的所有\"*.py\"文件进行打包哟，但不会递归去拷贝所有的子包内容。 # 综上所述，我们如果想要把一个包的所有\"*.py\"文件进行打包，应该在packages列表写下所有包的层级关系哟~这样就开源将指定包路径的所有\".py\"文件进行打包! packages=['devops', \"devops.dev\", \"devops.ops\"], ) setup 函数常用的参数如下： 参数 说明 name 包名称 version 包版本 author 程序的作者 author_email 程序的作者的邮箱地址 maintainer 维护者 maintainer_email 维护者的邮箱地址 url 程序的官网地址 license 程序的授权信息 description 程序的简单描述 long_description 程序的详细描述 platforms 程序适用的软件平台列表 classifiers 程序的所属分类列表 keywords 程序的关键字列表 packages 需要处理的包目录(通常为包含 init.py 的文件夹) py_modules 需要打包的 Python 单文件列表 download_url 程序的下载地址 cmdclass 添加自定义命令 package_data 指定包内需要包含的数据文件 include_package_data 自动包含包内所有受版本控制(cvs/svn/git)的数据文件 exclude_package_data 当 include_package_data 为 True 时该选项用于排除部分文件 data_files 打包时需要打包的数据文件，如图片，配置文件等 ext_modules 指定扩展模块 scripts 指定可执行脚本,安装时脚本会被安装到系统 PATH 路径下 package_dir 指定哪些目录下的文件被映射到哪个源码包 entry_points 动态发现服务和插件，下面详细讲 python_requires 指定运行时需要的Python版本 requires 指定依赖的其他包 provides 指定可以为哪些模块提供依赖 install_requires 应用于指定项目正确运行所需的最低要求 extras_require 当前包的高级/额外特性需要依赖的分发包 tests_require 在测试时需要使用的依赖包 setup_requires 指定运行 setup.py 文件本身所依赖的包 dependency_links 指定依赖包的下载地址 zip_safe 不压缩包，而是以目录的形式安装 推荐资料： Python 打包用户指南 — Python 打包用户指南 "},"ROS2/ROS2入门篇/第2章-ROS2第一个节点/入门/001-节点介绍-工作空间-构建工具Colcon.html":{"url":"ROS2/ROS2入门篇/第2章-ROS2第一个节点/入门/001-节点介绍-工作空间-构建工具Colcon.html","title":"节点介绍-工作空间-构建工具Colcon","keywords":"","body":"datetime:2023/09/12 14:16 author:nzb 该项目来源于大佬的动手学ROS2 1.ROS2节点介绍 1. ROS2节点是什么 ROS2中每一个节点也是只负责一个单独的模块化的功能（比如一个节点负责控制车轮转动，一个节点负责从激光雷达获取数据、一个节点负责处理激光雷达的数据、一个节点负责定位等等） 2.节点之间如何交互？ 上面举了一个激光雷达的例子，一个节点负责获取激光雷达的扫描数据，一个节点负责处理激光雷达数据，比如去除噪点。 那节点与节点之间就必须要通信了，那他们之间该如何通信呢？ROS2早已为你准备好了一共四种通信方式: 话题-topics 服务-services 动作-Action 参数-parameters 这四种种通信方式的用途和使用方法，放到了第四和第五章来介绍，到时候同时会带大家手撸代码。 官方给了一张图，大家先大概看一下，帮助理解 3. 如何启动一个节点？ 知道了节点的概念之后，我们该如何启动一个节点呢？ 因为工作空间和包的概念，放到了下一讲，这里跟着一起运行一个节点，感受一下。 使用指令： ros2 run 指令意义：启动 包下的 中的节点。 使用样例： ros2 run turtlesim turtlesim_node 大家可以尝试一下上面的指令，就是我们在第一章中启动小乌龟模拟器的那条指令。 运行之后可以看到一只小乌龟，接下来就可以试试下一节中提到的几个指令来查看节点信息和列表。 4. 通过命令行界面查看节点信息 4.1 ROS2命令行 ROS2的CLI，就是和ROS2相关的命令行操作。什么是命令行界面呢？这里再讲解一个概念，CLI（Command-Line Interface）和GUI（Graphical User Interface） GUI（Graphical User Interface）就是平常我们说的图形用户界面，大家用的Windows是就是可视化的，我们可以通过鼠标点击按钮等图形化交互完成任务。 CLI（Command-Line Interface）就是命令行界面了，我们所用的终端，黑框框就是命令行界面，没有图形化。 很久之前电脑还是没有图形化界面的，所有的交互都是通过命令行实现，就学习机器人而言，命令行操作相对于图形化优势更加明显。 ROS2为我们提供了一系列指令，通过这些指令，可以实现对ROS2相关模块信息的获取设置等操作。 4.2 节点相关的CLI 运行节点(常用) ros2 run 查看节点列表(常用)： ros2 node list 查看节点信息(常用)： ros2 node info 重映射节点名称 ros2 run turtlesim turtlesim_node --ros-args --remap __node:=my_turtle 运行节点时设置参数 ros2 run example_parameters_rclcpp parameters_basic --ros-args -p rcl_log_level:=10 5.总结 ROS2命令行工具源码;ros2/ros2cli: ROS 2 command line interface tools (github.com) 2.ROS2工作空间 运行一个节点的时候使用的是 ros2 run 包名字 可执行文件名字 那你有没有想过，我们想找到一个节点（可执行文件），就必须要先知道它在哪个包，那问题就来了，想要找到某个包，该去哪里找？ 答案就是：工作空间 注意：一个工作空间下可以有多个功能包，一个功能包可以有多个节点存在 1. 工作空间 定义：工作空间是包含若干个功能包的目录，一开始大家把工作空间理解成一个文件夹就行了。这个文件夹包含下有src。所以一般新建一个工作空间的操作就像下面一样 cd d2lros2/chapt2/ mkdir -p chapt2_ws/src 是不是觉得就像创建一个目录（其实就是创建一个目录） 2.功能包是什么 功能包可以理解为存放节点的地方，ROS2中功能包根据编译方式的不同分为三种类型。 ament_python，适用于python程序 cmake，适用于C++ ament_cmake，适用于C++程序,是cmake的增强版 3.功能包获取的两种方式 3.1 安装获取 安装一般使用 sudo apt install ros--package_name 安装获取会自动放置到系统目录，不用再次手动source。 3.2 手动编译获取 手动编译相对麻烦一些，需要下载源码然后进行编译生成相关文件。 什么时候需要手动编译呢?一般我们能安装的功能包都是作者编译好程序将可执行文件上传到仓库中，然后我们才能够通过apt进行安装，如果作者还没来得及测试上传，或者忘记了测试上传，就会找不到对应的包，这时候就需要手动编译安装了。 另外一种就是我们需要对包的源码进行修改，这个时候也需要自己编译修改。 手动编译之后，需要手动source工作空间的install目录。 下一节学习完编译器colcon会通过实例带大家一起下载编译安装功能包~ 4.与功能包相关的指令 ros2 pkg create Create a new ROS2 package executables Output a list of package specific executables list Output a list of available packages prefix Output the prefix path of a package xml Output the XML of the package manifest or a specific tag 1.创建功能包 ros2 pkg create --build-type {cmake,ament_cmake,ament_python} --dependencies 2.列出可执行文件 列出所有 ros2 pkg executables 列出turtlesim功能包的所有可执行文件 ros2 pkg executables turtlesim 3.列出所有的包 ros2 pkg list 4.输出某个包所在路径的前缀 ros2 pkg prefix 比如小乌龟 ros2 pkg prefix turtlesim 5.列出包的清单描述文件 每一个功能包都有一个标配的manifest.xml文件，用于记录这个包的名字，构建工具，编译信息，拥有者，干啥用的等信息。 通过这个信息，就可以自动为该功能包安装依赖，构建时确定编译顺序等 查看小乌龟模拟器功能包的信息。 ros2 pkg xml turtlesim 5.总结 介绍完工作空间和功能包，接下来就可以讲讲ROS2的编译工具colcon，下一讲我们就开始对代码动手了~ 3. ROS2构建工具—Colcon 本节会从下面几个方面来介绍： Colcon是个啥 安装colcon 编个东西测试一下 运行一个自己编的节点 colcon学习总结指令 1.Colcon是个啥 colcon其实是一个功能包构建工具，这个工具用来做什么的呢？ 简单点说就是用来编译代码的，上几节跟大家讲了如何进行ROS2工作空间的创建，但没有说如何进行编译，其实就是用colcon。 ROS2默认是没有安装colcon的，所以就从如何安装colcon开始跟大家讲解colcon的使用方法。 colcon想当于ros1中的catkin工具，学过ros1的同学可以辅助理解。没学过也没关系，用多了自然也就懂了。 2.安装colcon 如果使用一键安装ROS2，会帮你安装好这个工具，以防万一我们再装一次，打开终端复制粘贴进去即可。 sudo apt-get install python3-colcon-common-extensions 安装完成后，打开终端输入colcon即可看到其使用方法。 3. 编个东西测试一下 创建一个工作区文件夹colcon_test_ws cd d2lros2/chapt2/ mkdir colcon_test_ws && cd colcon_test_ws 下载个ROS2示例源码测试一下 git clone https://github.com/ros2/examples src/examples -b humble 编译工程 colcon build 如果在编译中遇到Setuptools DeprecationWarning: setup.py install is deprecated.这个警告，可以通过更新setuptools解决。 详细操作见社区帖子：https://fishros.org.cn/forum/topic/254/ 编完之后的目录结构 构建完成后，在src同级目录我们应该会看到 build 、 install 和 log 目录: . ├── build ├── install ├── log └── src 4 directories, 0 files build 目录存储的是中间文件。对于每个包，将创建一个子文件夹，在其中调用例如CMake install 目录是每个软件包将安装到的位置。默认情况下，每个包都将安装到单独的子目录中。 log 目录包含有关每个colcon调用的各种日志信息。 4.运行一个自己编的节点 打开一个终端使用 cd colcon_test_ws进入我们刚刚创建的工作空间，先source 一下资源 source install/setup.bash 运行一个订者节点，你将看不到任何打印，因为没有发布者 ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function 打开一个新的终端，先source，再运行一个发行者节点 source install/setup.bash ros2 run examples_rclcpp_minimal_publisher publisher_member_function 5.本节学习指令 这个要特别说一下，因为ros2的build没有ros中的devel概念了，如果想达到devel目录那样的效果，就需要加这个参数。没有学过ros的请主动忽略这句话。 5.1 只编译一个包 colcon build --packages-select YOUR_PKG_NAME 5.2 不编译测试单元 colcon build --packages-select YOUR_PKG_NAME --cmake-args -DBUILD_TESTING=0 5.3 运行编译的包的测试 colcon test 5.4 允许通过更改src下的部分文件来改变install（重要） 每次调整 python 脚本时都不必重新build了 colcon build --symlink-install 参考资料: colcon官方文档 ROS2官网文档 "},"ROS2/ROS2入门篇/第2章-ROS2第一个节点/入门/002-使用RCLCPP和RCLPY编写节点.html":{"url":"ROS2/ROS2入门篇/第2章-ROS2第一个节点/入门/002-使用RCLCPP和RCLPY编写节点.html","title":"使用RCLCPP和RCLPY编写节点","keywords":"","body":"datetime:2023/09/13 09:36 author:nzb 该项目来源于大佬的动手学ROS2 4.使用RCLCPP编写节点 节点需要存在于功能包当中、功能包需要存在于工作空间当中。所以我们要想创建节点，就要先创建一个工作空间，再创建功能包。 1.创建工作空间和功能包 1.1 工作空间 工作空间就是文件夹，所以很简单。 cd d2lros2/chapt2/ mkdir -p chapt2_ws/src/ 1.2 创建example_cpp功能包 创建example_cpp功能包，使用ament-cmake作为编译类型，并为其添加rclcpp依赖。 cd chapt2_ws/src ros2 pkg create example_cpp --build-type ament_cmake --dependencies rclcpp 大家可以手写一下这个代码，感受一下。现在来讲一讲这条命令的含义和参数。 pkg create 是创建包的意思 --build-type 用来指定该包的编译类型，一共有三个可选项ament_python、ament_cmake、cmake --dependencies 指的是这个功能包的依赖，这里给了一个ros2的C++客户端接口rclcpp 打开终端，进入chapt2_ws/src运行上面的指令，创建完成后的目录结构如下： . └── src └── example_cpp ├── CMakeLists.txt ├── include │ └── example_cpp ├── package.xml └── src 5 directories, 2 files 2.创建节点 接着我们在example_cpp/src下创建一个node_01.cpp文件，创建完成后的目录结构如下： 3.编写代码 3.1 编写代码 继续跟着一起输入代码，输入的时候可以边输边理解。 #include \"rclcpp/rclcpp.hpp\" int main(int argc, char **argv) { /* 初始化rclcpp */ rclcpp::init(argc, argv); /*产生一个node_01的节点*/ auto node = std::make_shared(\"node_01\"); // 打印一句自我介绍 RCLCPP_INFO(node->get_logger(), \"node_01节点已经启动.\"); /* 运行节点，并检测退出信号 Ctrl+C*/ rclcpp::spin(node); /* 停止运行 */ rclcpp::shutdown(); return 0; } 3.2 修改CmakeLists 在node_01.cpp中输入上面的内容后，还需要修改一下CMakeLists.txt。将其添加为可执行文件，并使用install指令将其安装到install目录。 在CmakeLists.txt最后一行加入下面两行代码。 add_executable(node_01 src/node_01.cpp) ament_target_dependencies(node_01 rclcpp) 添加这两行代码的目的是让编译器编译node_01这个文件，接着在上面两行代码下面添加下面的代码。 install(TARGETS node_01 DESTINATION lib/${PROJECT_NAME} ) 2.编译运行节点 在chapt2_ws下依次输入下面的命令 2.1 编译节点 colcon build 2.2 source环境 source install/setup.bash 2.3 运行节点 ros2 run example_cpp node_01 不出意外，你可以看到 3.测试 当节点运行起来后，可以再尝试使用ros2 node list指令来查看现有的节点。这个时候你应该能看到： 4.总结 至此，相信你已经掌握了如何编写一个C++版本的ros2节点了，但是这仅仅是编写ROS2节点方式之一，相比之下，更推荐你使用面向对象的方式编写节点，在进阶篇将会向你展示其写法。 5.使用RCLPY编写节点 1.创建Python功能包 创建一个名字叫做example_py python版本的功能包。 cd chapt2/chapt2_ws/src/ ros2 pkg create example_py --build-type ament_python --dependencies rclpy 创建完成后的目录结构 . ├── example_py │ └── __init__.py ├── package.xml ├── resource │ └── example_py ├── setup.cfg ├── setup.py └── test ├── test_copyright.py ├── test_flake8.py └── test_pep257.py 3 directories, 8 files 2.编写程序 编写ROS2节点的一般步骤 1. 导入库文件 2. 初始化客户端库 3. 新建节点 4. spin循环节点 5. 关闭客户端库 在example_py/example_py下创建node_02.py接着我们开始编写代码。跟着一起边理解输入下面的代码，注释不用输。 import rclpy from rclpy.node import Node def main(args=None): \"\"\" ros2运行该节点的入口函数 编写ROS2节点的一般步骤 1. 导入库文件 2. 初始化客户端库 3. 新建节点对象 4. spin循环节点 5. 关闭客户端库 \"\"\" rclpy.init(args=args) # 初始化rclpy node = Node(\"node_02\") # 新建一个节点 node.get_logger().info(\"大家好，我是node_02.\") rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 代码编写完成用Crtl+S进行保存。接着修改setup.py。 entry_points={ 'console_scripts': [ \"node_02 = example_py.node_02:main\" ], }, ) setup.py这段配置是声明一个ROS2的节点，声明后使用colcon build才能检测到，从而将其添加到install目录下。 完成上面的工作后，就可以编译运行了。 3.编译运行节点 打开vscode终端，进入chapt2/chapt2_ws/ 3.1 编译节点 cd chapt2/chapt2_ws/ colcon build --- stderr: example_py /usr/lib/python3/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn( --- 如果在编译中看到上述错误没关系，不影响使用，ros2官方正在修复。 错误原因是setuptools版本太高造成，使用下面的指令可以进行版本的回退。 sudo pip install setuptools==58.2.0 --upgrade 3.2 source环境 source install/setup.bash 3.3 运行节点 ros2 run example_py node_02 运行结果 4.测试 当节点运行起来后，可以再尝试使用ros2 node list指令来查看现有的节点。这个时候你应该能看到： 这说明你的节点已经运行起来了。 5.总结 本节我们学习了使用Python在工作空间的功能包里编写一个节点，代码是相同的，但是多了一些配置。 当然除了使用这种方法编写一个节点，还有其他方式，将其放到了进阶篇来讲。 "},"ROS2/ROS2入门篇/第2章-ROS2第一个节点/进阶/001-面向对象编程思想.html":{"url":"ROS2/ROS2入门篇/第2章-ROS2第一个节点/进阶/001-面向对象编程思想.html","title":"面向对象编程思想","keywords":"","body":"datetime:2023/09/13 09:36 author:nzb 该项目来源于大佬的动手学ROS2 1. OOP介绍 除了使用上节中的只定义一个main函数就完成编写一个Python节点外，还有另外两种方式。 本节就来讲一讲出现么多种编写节点的原因，并对其中较为重要的OOP方法进行介绍。 要做机器人离不开计算机编程，而计算机编程经过多年的发展，演变出了三种不同且常用的编程思想，分别是： 面向过程编程思想。缩写：POP 面向对象编程思想。缩写：OOP 函数式思想。缩写：FP 1.Why 为什么了解这些编程思想呢？尤其是OOP。 遇到过很多同学，在阅读机器人相关开源程序代码时，比如导航框架Nav2、机械臂运动控制框架Moveit时发现，别人的代码，每一行好像都看得懂，但放一起就看不懂了，看别人函数调来调去，很快人就给整蒙了。不知道如何下手。 这其实就是对别人的编程思想不了解造成的，所以本节课就给提一提常见的三种编程思想，让大家脑子里有个概念，以后遇到了看不明白的程序，知道该往哪个方向去学习。 编程思想博大精深，这里只是对三种思想的基本介绍。 2.思想辨析 首先明确一件事情，编程是为了什么？ 是为了赚钱吗？ 不，我们写程序肯定是为了解决实际的问题的，那编程思想编程思想就是解决问题的思路（赚钱工具） 那这三种思想有什么区别呢？ 2.1 用三种思想把大象装进冰箱 比如我们想把一只大象装进冰箱，分别用三种思想，我们看看有什么不一样。 2.1.1 面向过程思想 如果我们采用面向过程的思想，可以分为三步： 打开冰箱门 把大象塞进去 关上冰箱门 面向过程编程就是分析出解决问题所需要步骤，然后分别实现每一步，再一步步执行即可。 2.1.2 面向对象思想 面向对象编程思想（OOP）怎么做呢？ 那就要先知道面向对象是什么？搞清楚啥是对象？ 对象是女朋友吗？答案肯定不是。 任何我们想要探究的事物都可以当作一个对象，比如我们可以把你家的冰箱理解为一个对象，我们就可以研究你家冰箱由哪些部分（指令装置等）组成，你家冰箱能干什么（制冷、调温等）？ 接着我们开始下定义，就是取个高大上的名字 冰箱 定义 举例 冰箱的组成部分 冰箱的属性 制冷器，调温旋钮、灯带等 冰箱能干什么 冰箱的行为 制冷，调温、照明等 对象的行为其实是对其属性的操作，比如对制冷器操作就可以制冷，给灯带通电就可以照明。 对象 = 属性+行为 接着我们开始采用OOP的方法把大象装进冰箱 调用：冰箱->打开门(行为) 调用：冰箱->装东西(行为) 调用：冰箱->关闭门(行为) 看起来和面向过程没啥区别，但我们的思想发生了重大的转变，我们把冰箱当作了一个独立的对象，我们是通过和冰箱这个对象交互完成了整个过程。 接着来看函数式编程 定义关进（冰箱，大象）函数 实现函数：关门(放入(开门(冰箱)，大象)) 可以看到多层的函数嵌套调用，这就是函数编程的魅力，因为FP不是我们的机器人学习中的重点，这里就不过多讲解啦！ 3.面向对象编程 简单介绍完，我们来说说今天的主角，面向对象编程OOP。 面向对象中有五个重要的概念，理解这五个概念相当于对OOP编程有了了解，下面一个个来介绍。 3.1 类与对象（抽象与具体） 我们通过调用你家美的冰箱的开门、装东西和关门三个行为来把大象装进冰箱。这时我们可以把你家的美的冰箱（具体的）称之为一个对象，而冰箱（抽象的）就称为一个类。 比如说鱼类和，鱼类就是一个类，而就是鱼类（抽象的）中的一个对象（具体的）。 在ROS2设计时这种抽象和具体的思想发挥着非常重要的作用，比如说DDS是有很多厂家的，ROS2为了匹配不同厂家的DDS，就设计除了DDS抽象层，而每一个具体的DDS厂家，我们可以称之为一个DDS的对象，是具体的。 3.2 封装、继承与多态 所谓封装就是将属性和行为封装在一起。上面已经介绍了对象 = 属性+行为，比如冰箱将冰箱的温度值（属性）和对温度值的操作（行为）等封装在一起。 继承，继承可以帮我们减少很多的工作量（比如王撕聪从他爹那里继承了很多钱，这样他就少奋斗了很多年），比如ROS2中的执行器类，通过继承执行器类实现了单线程执行器和多线程执行器，更多具体的例子我们在后续的学习中遇到再说。 多态，其实很简单，我们可以说鲤鱼是鱼类，草鱼是鱼类，鲤鱼是鱼类。同一个鱼类可以有多种不同的类型，即多态。更多的用法，等到写代码的时候再和一起解锁 4.如何选择code思想 三种编程思想，我们写程序的时候该如何选择呢? 个人的拙见是根据你的功能需求来，如果只需要实现一个很简单的功能，比如只是做一个键盘控制器，实现控制小车前进后退，直接采用面向过程的设计思想即可。 但如果是做一个稍大的工程，且后续要考虑功能的拓展性，这个时候就需要采用面向对象的思路来了。 参考链接： -浅谈面向对象的编程思想：如何优雅地把大象装进冰箱？_SYSU_101的博客-CSDN博客 2.使用面向对象方式编写ROS2节点 1.C++版本 在d2lros2/chapt2/chapt2_ws/src/example_cpp/src下新建node_03.cpp，接着输入下面的代码。 #include \"rclcpp/rclcpp.hpp\" /* 创建一个类节点，名字叫做Node03,继承自Node. */ class Node03 : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 Node03(std::string name) : Node(name) { // 打印一句 RCLCPP_INFO(this->get_logger(), \"大家好，我是%s.\",name.c_str()); } private: }; int main(int argc, char **argv) { rclcpp::init(argc, argv); /*产生一个node_03的节点*/ auto node = std::make_shared(\"node_03\"); /* 运行节点，并检测退出信号*/ rclcpp::spin(node); rclcpp::shutdown(); return 0; } 接着修改CMakeLists.txt，添加下方代码。 add_executable(node_03 src/node_03.cpp) ament_target_dependencies(node_03 rclcpp) install(TARGETS node_03 DESTINATION lib/${PROJECT_NAME} ) 接着即可自行编译测试 colcon build --packages-select example_cpp source install/setup.bash ros2 run example_cpp node_03 2.Python版本 在d2lros2/d2lros2/chapt2/chapt2_ws/src/example_py/example_py下新建node_04.py，输入下面的代码 #!/usr/bin/env python3 import rclpy from rclpy.node import Node class Node04(Node): \"\"\" 创建一个Node04节点，并在初始化时输出一个话 \"\"\" def __init__(self, name): super().__init__(name) self.get_logger().info(\"大家好，我是%s!\" % name) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = Node04(\"node_04\") # 新建一个节点 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 接着修改setup.py entry_points = { 'console_scripts': [ \"node_02 = example_py.node_02:main\", \"node_04 = example_py.node_04:main\" ], }, 注意格式和结尾的,符号，console_scripts是个数组。 编译测试 colcon build --packages-select example_py source install/setup.bash ros2 run example_py node_04 3.总结 把节点写成一个类的形式对我们组织代码和使用ROS2的新特性有很多的好处，后面我们将以此种方式（用类建立节点）来学习后续内容。 "},"ROS2/ROS2入门篇/第2章-ROS2第一个节点/进阶/002-Colcon使用进阶.html":{"url":"ROS2/ROS2入门篇/第2章-ROS2第一个节点/进阶/002-Colcon使用进阶.html","title":"Colcon使用进阶","keywords":"","body":"datetime:2023/09/13 09:36 author:nzb 该项目来源于大佬的动手学ROS2 3.Colcon使用进阶 基础篇中带你用gcc编译了ROS2节点。对你来说，使用CMake（GCC或Makefile）和 Python Setup打包工具依然可以完成ROS2代码的编译，那为什么还需要Colcon呢？ 带着这个问题，我们来进一步的学习Colcon。 1.ROS生态中的构建系统和构建工具 1.1 构建系统与构建工具 两者的区分点在于针对的对象不同，构建系统之针对一个单独的包进行构建，而构建工具重点在于按照依赖关系依次调用构建系统完成一系列功能包的构建。 ROS中用到的构建系统：CMake、ament_cmake、catkin、Python setuptools。 ROS中用到的构建工具：colcon、catkin_make、catkin_make_isolated、catkin_tools。 很明显colcon作为构建工具，通过调用CMake、Python setuptools完成构建。 1.2 常见构建系统 1.2.1 CMake CMake 是一个跨平台构建系统生成器。项目使用独立于平台的文件指定其生成过程。用户通过使用CMake为其平台上的本机工具生成构建系统来构建项目。 通常用法有：cmake、make、make intsall 1.2.2 Python setuptools setuptools是Python包的打包常用工具。Python 包使用文件来描述依赖项，以及如何构建和安装内容。在ROS2中，功能包可以是“普通”Python包，而在ROS1中，任何Python功能都是从CMake文件触发setup.py进行打包。 通常的用法有：python setup.py 1.2.3 catkin catkin基于CMake，并提供了一组方便的函数，使编写CMake包更容易。它自动生成 CMake 配置文件以及 pkg 配置文件。它还提供了注册不同类型测试的函数。 1.3 常见构建工具 1.3.1 catkin_make 该工具仅调用 CMake 一次，并使用 CMake 的函数在单个上下文中处理所有包。虽然这是一种有效的方法，因为所有包中的所有目标都可以并行化，但它具有明显的缺点。由于所有函数名称、目标和测试都共享一个命名空间，并且规模更大，这很容易导致冲突。 1.3.2 colcon colcon是一个命令行工具，用于改进构建，测试和使用多个软件包的工作流程。它自动化了流程，处理了订购并设置了使用软件包的环境。 colcon 文档 1.3.3 ament_tools ament_tools由用于构建 ROS 2 包的独立 Python 3 包提供。它是为引导ROS 2项目而开发的，因此仅针对Python 3，并且可以在Linux，MacOS和Windows上运行。 ament_tools支持构建以下软件包： 带有package.xml文件的 ROS 2 包。 带有package.xml普通的 CMake 包。 没有清单文件的普通 CMake 包（从 CMake 文件中提取包名称和依赖项）。 带有package.xml文件的 Python 包。 没有清单文件的 Python 包（从setup.py文件中提取包名称和依赖项）。 2.Colcon构建进阶 我们平时用的最多的场景是编译功能包，所以这里重点介绍build时候的一些参数。 2.1 build参数 2.1.0 构建指令 --packages-select ，仅生成单个包（或选定的包）。 --packages-up-to，构建选定的包，包括其依赖项。 --packages-above，整个工作区，然后对其中一个包进行了更改。此指令将重构此包以及（递归地）依赖于此包的所有包。 2.1.1.指定构建后安装的目录 可以通过 --build-base参数和--install-base，指定构建目录和安装目录。 2.1.2.合并构建目录 --merge-install: 使用 作为所有软件包的安装前缀，而不是安装基中的软件包特定子目录。--install-base: 如果没有此选项，每个包都将提供自己的环境变量路径，从而导致非常长的环境变量值。 使用此选项时，添加到环境变量的大多数路径将相同，从而导致环境变量值更短。 2.1.3.符号链接安装 启用--symlink-install后将不会把文拷贝到install目录，而是通过创建符号链接的方式。 2.1.4.错误时继续安装 启用--continue-on-error，当发生错误的时候继续进行编译。 2.1.5 CMake参数 --cmake-args，将任意参数传递给CMake。与其他选项匹配的参数必须以空格为前缀。 2.1.6 控制构建线程 --executor EXECUTOR ，用于处理所有作业的执行程序。默认值是根据所有可用执行程序扩展的优先级选择的。要查看完整列表，请调用 colcon extensions colcon_core.executor --verbose。 sequential [colcon-core] 一次处理一个包。 parallel [colcon-parallel-executor] 处理多个作业平行. --parallel-workers NUMBER 要并行处理的最大作业数。默认值为 os.cpu_count() 给出的逻辑 CPU 内核数。 2.1.7 开启构建日志 使用--log-level可以设置日志级别，比如--log-level info。 3.总结 有关测试相关的暂时不讲了，毕竟国内的程序员写测试的还是很少的（😉）。 "},"ROS2/ROS2入门篇/第2章-ROS2第一个节点/进阶/003-ROS2节点发现与多机通信.html":{"url":"ROS2/ROS2入门篇/第2章-ROS2第一个节点/进阶/003-ROS2节点发现与多机通信.html","title":"ROS2节点发现与多机通信","keywords":"","body":"datetime:2023/09/13 09:36 author:nzb 该项目来源于大佬的动手学ROS2 4.ROS2节点发现与多机通信 本文主要讲解ROS2的DOMAIN_ID概念，并介绍在没有ROSMASTER的情况下，ROS2如何实现互相发现。 1.概述 如其他地方所解释的，ROS 2用于通讯的默认中间件是DDS。在DDS中，不同逻辑网络共享物理网络的主要机制称为域(Domain) ID。同一域上的ROS 2节点可以自由地相互发现并发送消息，而不同域上的ROS 2节点则不能。所有ROS 2节点默认使用域ID为0。为了避免在同一网络上运行ROS 2的不同计算机组之间互相干扰，应为每组设置不同的域ID。 2.选择域ID (短版本) 下面的文本解释了应该在ROS 2中使用的域ID范围的推导。要跳过该背景知识并且只是选择一个安全的数字，只需选择一个介于0和101之间的安全的域ID (包括0和101)。 3.选择域ID (长版本) DDS使用域ID计算将用于发现和通讯的UDP端口。有关如何计算端口的详细信息，请参见 这篇文章 。我们知道在网络中，UDP端口是 无符号16位整型 。因此可以分配的最大端口号是65535。用链接 中的公式计算一下，这意味着可以分配的最高域账号是232，而可以分配的最低域账号是0。 特定平台的约束 为了实现最大的兼容性，在选择域账号时应遵循一些特定于平台的附加约束。特别是，最好避免在操作系统的 临时端口范围 中分配域ID。这避免了ROS 2节点使用的端口与计算机上的其他网络服务之间可能的冲突。 以下是一些关于特定平台临时端口的提示。 Linux 默认情况下，linux内核使用端口32768-60999作为临时端口。这意味着域ID 0-101 和 215-232 可以安全使用，而不会与临时端口发生冲突。临时端口范围可在Linux中通过在 /proc/sys/net/ipv4/ip_local_port_range 中设置自定义值进行配置。如果使用自定义临时端口范围，则可能需要相应地调整上述数字。 macOS 默认情况下，macOS上的临时端口范围为49152-65535。这意味着域ID 0-166可以安全使用，而不会与临时端口发生冲突。通过为 net.inet.ip.portrange.first 和 net.inet.ip.portrange.last 设置自定义sysctl值，临时端口范围可在macOS中配置。如果使用自定义临时端口范围，则可能需要相应地调整上述数字。 Windows 默认情况下，Windows上的临时端口范围为49152-65535。这意味着域ID 0-166可以安全使用，不会与临时端口发生冲突。临时的端口范围可通过 使用netsh 在窗口中配置。如果使用自定义临时端口范围，则可能需要相应地调整上述数字。 参与者约束 对于计算机上运行的每个ROS 2进程，将创建一个DDS \"participant\" 。由于每个DDS参与者占用计算机上的两个端口，因此在一台计算机上运行120个以上的ROS 2进程可能会溢出到其他域ID或临时端口。 为了解释原因，我们考虑域ID编号1和2。 域ID 1使用端口7650和7651进行多播。 域ID 2使用端口7900和7901进行多播。 在域ID 1中创建第一个进程 (第0个参与者) 时，端口7660和7661用于单播。 在域ID 1中创建第120个进程 (第119个参与者) 时，端口7898和7899用于单播。 在域ID 1中创建第121个进程 (第120个参与者) 时，端口7900和7901用于单播，并与域ID 2重叠。 如果已知计算机一次只能在一个域ID上，并且域ID足够低，那么创建比这更多的ROS 2进程是安全的。 在选择特定平台域 ID 范围顶部的域 ID 时，还有一个限制因素需要考虑。 例如，假设一台ID为101的Linux计算机: 计算机上的第0个ROS 2进程将连接到端口32650、32651、32660和32661。 计算机上的第1个ROS 2进程将连接到端口32650、32651、32662和32663。 计算机上的第53个ROS 2进程将连接到端口32650、32651、32766和32767。 计算机上的第54个ROS 2进程将连接到端口32650、32651、32768和32769，运行在临时端口范围内。 因此，在Linux上使用域ID为101时应创建的最大进程数为54。同样，在Linux上使用域ID为232时应创建的最大进程数为63，因为最大端口号为65535。 macOS和Windows的情况相似，尽管数字不同。在macOS和Windows上，当选择166 (范围顶部) 的域账号时，运行到临时端口范围之前，可以在计算机上创建的ROS 2进程的最大数量为120。 4.域ID到UDP端口号计算器 到这里试用： http://dev.ros2.fishros.com/doc/Concepts/About-Domain-ID.html#domain-id-to-udp-port-calculator "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/基础/001-从底层理解通信及通信中间件ZMQ.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/基础/001-从底层理解通信及通信中间件ZMQ.html","title":"从底层理解通信及通信中间件ZMQ","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 从底层理解通信 当涉及到底层通信时，通过在Linux命令行中执行一些相关操作可以更好地理解通信的工作方式。下面是一些通过Linux命令行来说明通信方式的示例： 通信的目的 通信的目的是在计算机系统中实现不同组件、进程或设备之间的信息和数据传递。通过通信，各个实体可以共享信息、协调行动并实现协同工作。在计算机领域，通信是构建分布式系统、网络和协议的基础。 通信原理 通信的原理涉及两个主要方面：通信协议和通信方式。通信协议定义了数据的格式、传输方式、错误检测和纠正等规则，以确保可靠的数据传输。通信方式涉及了不同的通信介质和技术，包括网络通信和进程间通信（IPC）。 通信方式 1. 基于TCP/UDP的网络通信方式 基于TCP/UDP的网络通信方式通过计算机网络进行信息交换。其中，TCP（传输控制协议）提供可靠的、面向连接的通信，而UDP（用户数据报协议）则是无连接的通信方式。在Linux命令行中，可以使用诸如ping和nc命令来演示网络通信。 例如，使用ping命令进行基于UDP的网络通信： ping 192.168.0.1 该命令将向IP地址为192.168.0.1的主机发送ICMP Echo请求，并等待接收相应的回复。 使用nc命令进行基于TCP的网络通信： nc -l 1234 该命令将在本地监听端口1234，并等待与之建立TCP连接的客户端。通过在另一个终端窗口中执行以下命令，可以建立与本地1234端口的TCP连接并在连接上发送消息： echo \"Hello, TCP!\" | nc 127.0.0.1 1234 2. 基于共享内存的进程间通信（IPC）方式 基于共享内存的IPC方式通过共享内存区域在同一计算机系统内的不同进程之间进行通信。在Linux命令行中，可以使用ipcs和ipcrm命令来管理共享内存段。 通过ipcs命令查看当前系统中的共享内存段： ipcs -m 使用ipcrm命令删除不再需要的共享内存段： ipcrm -m 通过以上示例，我们可以更好地理解通信的目的和原理，并使用Linux命令行演示了基于TCP/UDP的网络通信和基于共享内存的IPC通信的示例。这有助于进一步理解通信的实际应用和操作。 2.通信中间件之ZMQ 零MQ (zeromq.org) 1.什么是ZeroMQ 在说pyzmq之前，肯定要了解一下ZeroMQ，了解ZeroMQ还是从FastDDS那里，因为FastDDS官网老是在哪里强调自己比ZeroMQ性能要好。 大家知道FastDDS是ROS2的通信中间件，那既然FastDDS比ZeroMQ性能好，那为啥还要介绍ZeroMQ呢？ 原因是ZeroMQ非常的轻量，也就是小巧，占用资源少，看名字，Zero Message Queue，零消息队列。 ZeroMQ提供了各种（如进程内、进程间、TCP 和多播）消息传输的套接字，是不是听起来很强大的样子。 2.PyZmq 了解完ZMQ是啥后，我们再来看看PyZMQ。 因为文档过于完善，不打算跟大家费解释了，给一个官方网址，大家自行阅读 https://pyzmq.readthedocs.io/en/latest/ pyzmq也提供了类似于订阅发布的方式来传递消息，还有更多的使用方法，比如客户端服务端这种，网上有大佬已经探索了，贴个链接在这里，大家有需要使用的可以去瞅一瞅。 https://www.php.cn/python-tutorials-459626.html 3.总结 如果你在做机器人，需要去ROS，需要找一个高效的消息中间件，我想ZMQ应该比较适合你，当然也可以根据机器人的处理器和性能试试ROS2的FastDDS。 "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/001-topic.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/001-topic.html","title":"topic","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 1.ROS2话题入门 话题是ROS2中最常用的通信方式之一，话题通信采取的是订阅发布模型。 1.订阅发布模型 一个节点发布数据到某个话题上，另外一个节点就可以通过订阅话题拿到数据。 graph LR A[节点1] --发布-->B[topic_name] B -- 订阅 --> C[节点2] 除了上述这种一个节点发布，一个节点接受的形式外，ROS2话题通信其实还可以是1对n,n对1,n对n的。 1对n graph LR A[节点1] --发布-->B[topic_name] B -- 订阅 --> C[节点2] B -- 订阅 --> D[节点3] B -- 订阅 --> E[节点4] n对1（同一个话题可以有多个发布者） graph LR A[节点1] --发布-->B[topic_name] D[节点2] --发布-->B[topic_name] B -- 订阅 --> C[节点2] n对n graph LR A[节点1] --发布-->B[topic_name] F[节点2] --发布-->B[topic_name] G[节点3] --发布-->B[topic_name] B -- 订阅 --> C[节点4] B -- 订阅 --> D[节点5] B -- 订阅 --> E[节点6] 还有一种就是ROS2节点可以订阅本身发布的话题 graph LR A[节点] --发布-->B[topic_name] B -- 订阅 --> A[节点] 2. 消息接口 为了方便发送者和接收者进行数据的交换，ROS2帮我们在数据传递时做好了消息的序列化和反序列化（有关消息序列化相关内容请参考本章基础篇），而且ROS2的消息序列化与反序列化通信是可以做到跨编程语言、跨平台和跨设备之间的。 ROS2如何做到跨编程语言、跨平台和跨设备之间的数据收发呢？这就得益于通过定义消息接口文件了。 因为跨平台和设备实现较为复杂，这里简单说一下如何实现跨语言的。当我们定义好消息接口后，ROS2会根据消息接口内容生成不同语言的接口类，在不同编程语言中调用相同的类即可实现无感的消息序列化和反序列化。 通过对消息接口介绍，相信你肯定能猜到这样一条规则：同一个话题，所有的发布者和接收者必须使用相同消息接口。 3. ROS2话题工具 3.1 GUI工具 3.1.1 RQT工具之rqt_graph ROS2作为一个强大的工具，在运行过程中，我们是可以通过命令来看到节点和节点之间的数据关系的。 运行我们第二章中的你说我听小demo。依次打开三个终端，分别输入下面三个命令。 ros2 run demo_nodes_py listener ros2 run demo_nodes_cpp talker rqt_graph 你将看到下面这张图 你可以尝试改变菜单栏的Hide或者Group选项，看一看下面图的变化，感受一下rqt_graph工具的强大。 这是一个很重要的工具，在学习和使用ROS2的过程中经常会用到它，来看一看数据到底是怎么走的，它可以帮我们搞清楚一个节点的输入和输出是什么。 3.2 CLI工具 还记得上一章的ros2 node指令吗？ros2也支持很多强大的topic指令。可以使用下面的指令查看。 ros2 topic -h 本着学以致用的目的，先对比较常用的几个命令进行介绍，其他的我们用到的时候再介绍（现在介绍反而不好理解）。 3.2.1 ros2 topic list 返回系统中当前活动的所有主题的列表 命令 ros2 topic list 结果 3.2.2 ros2 topic list -t 增加消息类型 命令 ros2 topic list -t 结果 3.2.3 ros2 topic echo 打印实时话题内容 命令 ros2 topic echo /chatter 结果 3.2.4 ros2 topic info 查看主题信息 命令 ros2 topic info /chatter 结果 3.2.5 ros2 interface show 查看消息类型 上面一个指令告诉大家这个消息是std_msgs/msg/String，那String里面有什么呢？不妨来试一试。 命令 ros2 interface show std_msgs/msg/String 结果 3.2.6 ros2 topic pub arg 手动发布命令 关闭发布者，我们受到来发布 命令 ros2 topic pub /chatter std_msgs/msg/String 'data: \"123\"' 结果 4.最后 了解完话题，下一节就会带大家来动手写一写话题通信代码。 参考链接：Understanding ROS 2 topics — ROS 2 Documentation: Humble documentation "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/002-topic-rclcpp.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/002-topic-rclcpp.html","title":"topic-rclcpp","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 2.话题之RCLCPP实现 本节我们学习使用ROS2的RCLCPP客户端库来实现话题通信。 RCLCPP为Node类提供了丰富的API接口，其中就包括创建话题发布者和创建话题订阅者。 1.创建节点 本节我们将创建一个控制节点和一个被控节点。 控制节点创建一个话题发布者，发布控制命令（command）话题，接口类型为字符串（string），控制接点通过发布者发布控制命令（前进、后退、左转、右转、停止）。 被控节点创建一个订阅者，订阅控制命令，收到控制命令后根据命令内容打印对应速度出来。 graph LR; A[控制节点]--command-->B[被控节点] 依次输入下面的命令，创建chapt3_ws工作空间、example_topic_rclcpp功能包和topic_publisher_01.cpp。 cd d2lros2/ mkdir -p chapt3/chapt3_ws/src cd chapt3/chapt3_ws/src ros2 pkg create example_topic_rclcpp --build-type ament_cmake --dependencies rclcpp touch example_topic_rclcpp/src/topic_publisher_01.cpp 完成后目录结构 . └── src └── example_topic_rclcpp ├── CMakeLists.txt ├── include │ └── example_topic_rclcpp ├── package.xml └── src └── topic_publisher_01.cpp 5 directories, 3 files 接着采用面向对象方式写一个最简单的节点。 #include \"rclcpp/rclcpp.hpp\" class TopicPublisher01 : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 TopicPublisher01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"%s节点已经启动.\", name.c_str()); } private: // 声明节点 }; int main(int argc, char **argv) { rclcpp::init(argc, argv); /*创建对应节点的共享指针对象*/ auto node = std::make_shared(\"topic_publisher_01\"); /* 运行节点，并检测退出信号*/ rclcpp::spin(node); rclcpp::shutdown(); return 0; } 修改CMakeLists.txt add_executable(topic_publisher_01 src/topic_publisher_01.cpp) ament_target_dependencies(topic_publisher_01 rclcpp) install(TARGETS topic_publisher_01 DESTINATION lib/${PROJECT_NAME} ) 接着可以编译测试下，注意运行colcon的目录。 cd chapt3/chapt3_ws/ colcon build --packages-select example_topic_rclcpp source install/setup.bash ros2 run example_topic_rclcpp topic_publisher_01 2.编写发布者 2.1 学习使用API文档 想要创建发布者，只需要调用node的成员函数create_publisher并传入对应的参数即可。 有关API文档详细内容可以访问：rclcpp: rclcpp: ROS Client Library for C++ (ros2.org) 打开主页，可以看到创建发布者的函数，进去即可看到参数和详细解释。 通过文档可以看出，我们至少需要传入消息类型（msgT）、话题名称（topic_name）和 服务指令（qos）。 2.2 导入消息接口 消息接口是ROS2通信时必须的一部分，通过消息接口ROS2才能完成消息的序列化和反序列化。ROS2为我们定义好了常用的消息接口，并生成了C++和Python的依赖文件，我们可以直接在程序中进行导入。 ament_cmake类型功能包导入消息接口分为三步： 在CMakeLists.txt中导入，具体是先find_packages再ament_target_dependencies。 在packages.xml中导入，具体是添加depend标签并将消息接口写入。 在代码中导入，C++中是#include\"消息功能包/xxx/xxx.hpp\"。 我们依次做完这三步后文件内容如下： CMakeLists.txt find_package(rclcpp REQUIRED) find_package(std_msgs REQUIRED) add_executable(topic_publisher_01 src/topic_publisher_01.cpp) ament_target_dependencies(topic_publisher_01 rclcpp std_msgs) packages.xml ament_cmake rclcpp std_msgs ament_lint_auto ament_lint_common 代码文件topic_publisher_01.cpp #include \"rclcpp/rclcpp.hpp\" #include \"std_msgs/msg/string.hpp\" class TopicPublisher01 : public rclcpp::Node 2.3 创建发布者 根据ROS2的RCLCPPAPI文档可以看出，我们需要提供消息接口、话题名称和服务质量Qos。 消息接口上面我们已经导入了，是std_msgs/msg/string.h。 话题名称（topic_name），我们就用control_command。 Qos，Qos支持直接指定一个数字，这个数字对应的是KeepLast队列长度。一般设置成10，即如果一次性有100条消息，默认保留最新的10个，其余的都扔掉。 接着我们可以编写发布者的代码了。 #include \"rclcpp/rclcpp.hpp\" #include \"std_msgs/msg/string.hpp\" class TopicPublisher01 : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 TopicPublisher01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"大家好，我是%s.\", name.c_str()); // 创建发布者 command_publisher_ = this->create_publisher(\"command\", 10); } private: // 声明话题发布者 rclcpp::Publisher::SharedPtr command_publisher_; }; 2.4 使用定时器定时发布数据 2.4.1 查看定时器API 虽然编写好了发布者，但是我们还没有发布数据，我们需要通过ROS2中的定时器来设置指定的周期调用回调函数，在回调函数里实现发布数据功能。 有关回调函数和定时器相关内容请参考基础篇多线程与回调函数相关内容。 再次找到RCLCPP文档，找到创建定时器函数，观察参数 period，回调函数调用周期。 callback，回调函数。 group，调用回调函数所在的回调组，默认为nullptr。 2.4.2 编写代码 #include \"rclcpp/rclcpp.hpp\" #include \"std_msgs/msg/string.hpp\" class TopicPublisher01 : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 TopicPublisher01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"大家好，我是%s.\", name.c_str()); // 创建发布者 command_publisher_ = this->create_publisher(\"command\", 10); // 创建定时器，500ms为周期，定时发布 timer_ = this->create_wall_timer(std::chrono::milliseconds(500), std::bind(&TopicPublisher01::timer_callback, this)); } private: void timer_callback() { // 创建消息 std_msgs::msg::String message; message.data = \"forward\"; // 日志打印 RCLCPP_INFO(this->get_logger(), \"Publishing: '%s'\", message.data.c_str()); // 发布消息 command_publisher_->publish(message); } // 声名定时器指针 rclcpp::TimerBase::SharedPtr timer_; // 声明话题发布者指针 rclcpp::Publisher::SharedPtr command_publisher_; }; 2.4.3 代码讲解 定时器 定时器是ROS2中的另外一个常用功能，通过定时器可以实现按照一定周期调用某个函数以实现定时发布等逻辑。 定时器对应的类是rclcpp::TimerBase，调用create_wall_timer将返回其共享指针。 创建定时器时传入了两个参数，这两个参数都利用了C++11的新特性。 std::chrono::milliseconds(500)，代表500ms，chrono是c++ 11中的时间库，提供计时，时钟等功能。 std::bind(&TopicPublisher01::timer_callback, this)，bind() 函数的意义就像它的函数名一样，是用来绑定函数调用的某些参数的。 创建发布消息 std_msgs::msg::String是通过ROS2的消息文件自动生成的类，其原始消息文件内容可以通过命令行查询 ros2 interface show std_msgs/msg/String 结果 # This was originally provided as an example message. # It is deprecated as of Foxy # It is recommended to create your own semantically meaningful message. # However if you would like to continue using this please use the equivalent in example_msgs. string data 可以看到其内部包含了一个string data，ROS2会将消息文件转换成一个类，并把其中的定义转换成类的成员函数。 2.5 运行测试 编译，source，运行 cd chapt3/chapt3_ws/ colcon build --packages-select example_topic_rclcpp source install/setup.bash ros2 run example_topic_rclcpp topic_publisher_01 测试 # 查看列表 ros2 topic list # 输出内容 ros2 topic echo /command 3.编写订阅者 之所以我们可以用命令行看到数据，原因在于CLI创建了一个订阅者来订阅/command指令。接下来我们将要手动创建一个节点订阅并处理数据。 3.1 创建订阅节点 cd chapt3_ws/src/example_topic_rclcpp touch src/topic_subscribe_01.cpp 编写代码 #include \"rclcpp/rclcpp.hpp\" class TopicSubscribe01 : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 TopicSubscribe01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"大家好，我是%s.\", name.c_str()); } private: // 声明节点 }; int main(int argc, char **argv) { rclcpp::init(argc, argv); /*创建对应节点的共享指针对象*/ auto node = std::make_shared(\"topic_subscribe_01\"); /* 运行节点，并检测退出信号*/ rclcpp::spin(node); rclcpp::shutdown(); return 0; } CMakeLists.txt add_executable(topic_subscribe_01 src/topic_subscribe_01.cpp) ament_target_dependencies(topic_subscribe_01 rclcpp) install(TARGETS topic_subscribe_01 DESTINATION lib/${PROJECT_NAME} ) 编译测试 cd chapt3/chapt3_ws/ colcon build --packages-select example_topic_rclcpp source install/setup.bash ros2 run example_topic_rclcpp topic_subscribe_01 3.2 查看订阅者API文档 看API文档或者看头文件中关于函数的定义这是一个好习惯。 五个参数，但后面两个都是默认的参数，我们只需要有话题名称、Qos和回调函数即可。 3.3 编写代码 #include \"rclcpp/rclcpp.hpp\" #include \"std_msgs/msg/string.hpp\" class TopicSubscribe01 : public rclcpp::Node { public: TopicSubscribe01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"大家好，我是%s.\", name.c_str()); // 创建一个订阅者订阅话题 command_subscribe_ = this->create_subscription(\"command\", 10, std::bind(&TopicSubscribe01::command_callback, this, std::placeholders::_1)); } private: // 声明一个订阅者 rclcpp::Subscription::SharedPtr command_subscribe_; // 收到话题数据的回调函数 void command_callback(const std_msgs::msg::String::SharedPtr msg) { double speed = 0.0f; if(msg->data == \"forward\") { speed = 0.2f; } RCLCPP_INFO(this->get_logger(), \"收到[%s]指令，发送速度 %f\", msg->data.c_str(),speed); } }; 依然的需要在CMakeLists.txt添加下std_msgs依赖 ament_target_dependencies(topic_subscribe_01 rclcpp std_msgs) packages.xml就不需要了，同一个功能包，已经添加了。 3.4 运行测试 编译运行订阅节点 cd chapt3/chapt3_ws/ colcon build --packages-select example_topic_rclcpp source install/setup.bash ros2 run example_topic_rclcpp topic_subscribe_01 手动发布数据测试订阅者 ros2 topic pub /command std_msgs/msg/String \"{data: forward}\" 4.订阅发布测试 关闭上面启动的终端，重新运行指令 cd chapt3/chapt3_ws/ source install/setup.bash ros2 run example_topic_rclcpp topic_subscribe_01 运行发布节点 cd chapt3/chapt3_ws/ source install/setup.bash ros2 run example_topic_rclcpp topic_publisher_01 运行结果 查看计算图rqt 打开RQT、选择Node Graph、点击刷新下 "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/003-topic-rclpy.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/003-topic-rclpy.html","title":"topic-rclpy","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 3.话题之RCLPY实现 有了前面的经验，实现Python版本的发布订阅也非常的轻松了，因为ROS2的API一致性保持的很好，这点值得点赞。 Node — rclpy 0.6.1 documentation (ros2.org) 1.创建功能包和节点 创建功能包 cd chapt3/chapt3_ws/src/ ros2 pkg create example_topic_rclpy --build-type ament_python --dependencies rclpy 创建节点文件 cd example_topic_rclpy/example_topic_rclpy touch topic_subscribe_02.py touch topic_publisher_02.py 简单编写下代码，依然采用类的形式 发布者 #!/usr/bin/env python3 import rclpy from rclpy.node import Node class NodePublisher02(Node): def __init__(self,name): super().__init__(name) self.get_logger().info(\"大家好，我是%s!\" % name) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = NodePublisher02(\"topic_publisher_02\") # 新建一个节点 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 订阅节点 #!/usr/bin/env python3 import rclpy from rclpy.node import Node class NodeSubscribe02(Node): def __init__(self,name): super().__init__(name) self.get_logger().info(\"大家好，我是%s!\" % name) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = NodeSubscribe02(\"topic_subscribe_02\") # 新建一个节点 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy setup.py entry_points={ 'console_scripts': [ \"topic_publisher_02 = example_topic_rclpy.topic_publisher_02:main\", \"topic_subscribe_02 = example_topic_rclpy.topic_subscribe_02:main\" ], }, 2.编写订阅者 from std_msgs.msg import String class NodeSubscribe02(Node): def __init__(self,name): super().__init__(name) self.get_logger().info(\"大家好，我是%s!\" % name) # 创建订阅者 self.command_subscribe_ = self.create_subscription(String,\"command\",self.command_callback,10) def command_callback(self,msg): speed = 0.0 if msg.data==\"backup\": speed = -0.2 self.get_logger().info(f'收到[{msg.data}]命令，发送速度{speed}') 3.编写发布者 from std_msgs.msg import String class NodePublisher02(Node): def __init__(self,name): super().__init__(name) self.get_logger().info(\"大家好，我是%s!\" % name) self.command_publisher_ = self.create_publisher(String,\"command\", 10) self.timer = self.create_timer(0.5, self.timer_callback) def timer_callback(self): \"\"\" 定时器回调函数 \"\"\" msg = String() msg.data = 'backup' self.command_publisher_.publish(msg) self.get_logger().info(f'发布了指令：{msg.data}') #打印一下发布的数据 4.运行测试 4.1 发布节点 cd chapt3/chapt3_ws/ source install/setup.bash ros2 run example_topic_rclpy topic_publisher_02 4.1 订阅节点 cd chapt3/chapt3_ws/ source install/setup.bash ros2 run example_topic_rclpy topic_subscribe_02 4.2 RQT "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/004-service.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/004-service.html","title":"service","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 4.ROS2服务入门 1.服务通信介绍 服务分为客户端和服务端，平时我们用的手机APP都可以成为客户端，而APP服务器对于软件来说就是服务端。 客户端发送请求给服务端，服务端可以根据客户端的请求做一些处理，然后返回结果给客户端。 graph TB A[服务端-李四] --发送响应-->B[客户端-李三] B[客户端] --发送请求--> A[服务端] 所以服务-客户端模型，也可以成为请求-响应模型。 不知道你有没有感觉到服务和话题的不同之处，话题是没有返回的，适用于单向或大量的数据传递。而服务是双向的，客户端发送请求，服务端响应请求。 同时服务还是有一些注意事项： 同一个服务（名称相同）有且只能有一个节点来提供 同一个服务可以被多个客户端调用 放两张官方形象的动图： 2.体验服务 在我们安装ROS2的时候其实系统为我们安装了一些样例程序，其中就有服务使用样例，我们可以先来体验一下。 2.1 启动服务端 打开终端，运行下面的命令，这个命令用于运行一个服务节点，这个服务的功能是将两个数字相加，给定a，b两个数，返回sum也就是ab之和。 ros2 run examples_rclpy_minimal_service service 2.2 使用命令查看服务列表 ros2 service list 2.3手动调用服务 再启动一个终端，输入下面的命令（注意a：、b：后的空格）。 ros2 service call /add_two_ints example_interfaces/srv/AddTwoInts \"{a: 5,b: 10}\" 我们可以看到客户端请求两个数字5+10，服务端返回15。 3.ROS2服务常用命令 ROS2的命令行工具，觉得还是非常值得一学的，毕竟确实很实用（装X），之前已经给大家讲过了关于节点、话题、接口相关的命令了，现在说一下关于服务的那些命令行。 3.1查看服务列表 ros2 service list 3.2手动调用服务 ros2 service call /add_two_ints example_interfaces/srv/AddTwoInts \"{a: 5,b: 10}\" 如果不写参数值调用会怎么样？比如下面这种，大家可以尝试下。 ros2 service call /add_two_ints example_interfaces/srv/AddTwoInts 3.3 查看服务接口类型 ros2 service type /add_two_ints 3.4查找使用某一接口的服务 这个命令看起来和4.3刚好相反。 ros2 service find example_interfaces/srv/AddTwoInts 4.总结 本节大家和一起又多认识了一个小伙伴，ROS2的服务。 下一节我们将学习使用RCL在节点里创建服务端和客户端。 "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/005-service-rclcpp.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/005-service-rclcpp.html","title":"service-rclcpp","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 5.服务之RCLCPP实现 因为还没有学习如何自定义接口，所以我们先借着上一节的两数相加的示例接口，利用rclcpp提供的接口实现两数相加的服务端和客户端。 1.创建功能包和节点 cd chapt3/chapt3_ws/src ros2 pkg create example_service_rclcpp --build-type ament_cmake --dependencies rclcpp touch example_service_rclcpp/src/service_server_01.cpp touch example_service_rclcpp/src/service_client_01.cpp 面向对象方式写两个最简单的节点 service_server_01.cpp #include \"rclcpp/rclcpp.hpp\" class ServiceServer01 : public rclcpp::Node { public: ServiceServer01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); } private: }; int main(int argc, char** argv) { rclcpp::init(argc, argv); auto node = std::make_shared(\"service_server_01\"); rclcpp::spin(node); rclcpp::shutdown(); return 0; } service_client_01.cpp #include \"rclcpp/rclcpp.hpp\" class ServiceClient01 : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 ServiceClient01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); } private: }; int main(int argc, char** argv) { rclcpp::init(argc, argv); /*创建对应节点的共享指针对象*/ auto node = std::make_shared(\"service_client_01\"); /* 运行节点，并检测退出信号*/ rclcpp::spin(node); rclcpp::shutdown(); return 0; } CMakeLists.txt add_executable(service_client_01 src/service_client_01.cpp) ament_target_dependencies(service_client_01 rclcpp) add_executable(service_server_01 src/service_server_01.cpp) ament_target_dependencies(service_server_01 rclcpp) install(TARGETS service_server_01 DESTINATION lib/${PROJECT_NAME} ) install(TARGETS service_client_01 DESTINATION lib/${PROJECT_NAME} ) 完成上面的步骤，即可编译测试了，相信你已经对这些步骤非常熟悉了。 cd chapt3/chapt3_ws/ colcon build --packages-select example_service_rclcpp # 运行 service_server_01 source install/setup.bash ros2 run example_service_rclcpp service_server_01 # 打开新终端运行 service_client_01 source install/setup.bash ros2 run example_service_rclcpp service_client_01 2.服务端实现 2.1 导入接口 两数相加我们需要利用ROS2自带的example_interfaces接口，使用命令行可以查看这个接口的定义。 ros2 interface show example_interfaces/srv/AddTwoInts 结果 int64 a int64 b --- int64 sum 导入接口的三个步骤不知道你是否还记得。 ament_cmake类型功能包导入消息接口分为三步： 在CMakeLists.txt中导入，具体是先find_packages再ament_target_dependencies。 在packages.xml中导入，具体是添加depend标签并将消息接口写入。 在代码中导入，C++中是#include\"消息功能包/xxx/xxx.hpp\"。 根据步骤改一下： CMakeLists.txt # 这里我们一次性把服务端和客户端对example_interfaces的依赖都加上 find_package(example_interfaces REQUIRED) add_executable(service_client_01 src/service_client_01.cpp) ament_target_dependencies(service_client_01 rclcpp example_interfaces) add_executable(service_server_01 src/service_server_01.cpp) ament_target_dependencies(service_server_01 rclcpp example_interfaces) packages.xml example_interfaces 代码 #include \"example_interfaces/srv/add_two_ints.hpp\" 2.2 编写代码 先看代码再解释 #include \"example_interfaces/srv/add_two_ints.hpp\" #include \"rclcpp/rclcpp.hpp\" class ServiceServer01 : public rclcpp::Node { public: ServiceServer01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); // 创建服务 add_ints_server_ = this->create_service( \"add_two_ints_srv\", std::bind(&ServiceServer01::handle_add_two_ints, this, std::placeholders::_1, std::placeholders::_2)); } private: // 声明一个服务 rclcpp::Service::SharedPtr add_ints_server_; // 收到请求的处理函数 void handle_add_two_ints( const std::shared_ptr request, std::shared_ptr response) { RCLCPP_INFO(this->get_logger(), \"收到a: %ld b: %ld\", request->a, request->b); response->sum = request->a + request->b; }; }; create_service，参考rclcpp API文档即可 ServiceT，消息接口example_interfaces::srv::AddTwoInts service_name，服务名称 callback，回调函数，使用成员函数作为回调函数，std::bind进行转换 qos_profile，服务质量配置文件，默认rmw_qos_profile_services_default group，调用服务的回调组，默认nullptr 2.3 测试 cd chapt3_ws/ colcon build --packages-select example_service_rclcpp source install/setup.bash ros2 run example_service_rclcpp service_server_01 接着打开一个新的终端 # 你应该可以看到我们声明的服务 ros2 service list # 使用命令行进行调用 ros2 service call /add_two_ints_srv example_interfaces/srv/AddTwoInts \"{a: 5,b: 10}\" 3.客户端实现 3.1 API接口 写代码时看API文档是个好习惯，先看看创建客户端的：地址 3.1.1 create_client 参数加上ServiceT（接口类型），一共有四个，都是老熟人了，就不介绍了。 3.1.2 async_send_request 接着我们来看看发送请求的API，地址 我们这里要用的是这个函数async_send_request()同时传入两个参数 request，请求的消息，这里用于放a，b两个数。 CallBack，回调函数，异步接收服务器的返回的函数。 至于为什么ROS2中那么多回调函数，以及用回调函数的好处，这里就不解释了，不清楚的小伙伴可以看看基础篇的内容。 3.1.3 wait_for_service 这个函数是用于等待服务上线的，这个函数并不在rclcpp:: Client中定义，而是在其父类中定义的。 上面是继承图，在其父类中有这个函数的解释。 参数就一个，等待的时间，返回值是bool类型的，上线了就是true，不上线就是false。 之所以会用的这个函数的原因是，再发送请求之前保证服务端启动了，避免发送一个请求出去而无人响应的尴尬局面。 最后还有一些小细节，先看代码再进一步的解释。 3.2 代码 #include \"example_interfaces/srv/add_two_ints.hpp\" class ServiceClient01 : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 ServiceClient01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); // 创建客户端 client_ = this->create_client(\"add_two_ints_srv\"); } void send_request(int a, int b) { RCLCPP_INFO(this->get_logger(), \"计算%d+%d\", a, b); // 1.等待服务端上线 while (!client_->wait_for_service(std::chrono::seconds(1))) { //等待时检测rclcpp的状态 if (!rclcpp::ok()) { RCLCPP_ERROR(this->get_logger(), \"等待服务的过程中被打断...\"); return; } RCLCPP_INFO(this->get_logger(), \"等待服务端上线中\"); } // 2.构造请求的 auto request = std::make_shared(); request->a = a; request->b = b; // 3.发送异步请求，然后等待返回，返回时调用回调函数 client_->async_send_request( request, std::bind(&ServiceClient01::result_callback_, this, std::placeholders::_1)); }; private: // 声明客户端 rclcpp::Client::SharedPtr client_; void result_callback_( rclcpp::Client::SharedFuture result_future) { auto response = result_future.get(); RCLCPP_INFO(this->get_logger(), \"计算结果：%ld\", response->sum); } }; 这里需要额外讲解的是回调函数void result_callback_(rclcpp::Client::SharedFuture result_future) 这个又臭又长的参数确实让人惊了下，函数的参数是客户端AddTwoInts类型的SharedFuture对象，这个对象的定义如下 可以看到其又是利用C++11的新特性std::shared_future创建的SharedResponse类模板。 类模板 std::shared_future 提供访问异步操作结果的机制，类似 std::future ，除了允许多个线程等候同一共享状态。 我们具体看看std::shared_future的API 可以看到使用get函数即可获取结果。所以下面这段代码的意思相信你已经大概理解了。 auto response = result_future.get(); RCLCPP_INFO(this->get_logger(), \"计算结果：%ld\", response->sum); 3.3 测试 最后还要修改下主函数，用于调用服务端发送请求。 int main(int argc, char** argv) { rclcpp::init(argc, argv); /*创建对应节点的共享指针对象*/ auto node = std::make_shared(\"service_client_01\"); /* 运行节点，并检测退出信号*/ //增加这一行，node->send_request(5, 6);，计算5+6结果 node->send_request(5, 6); rclcpp::spin(node); rclcpp::shutdown(); return 0; } 接着编译运行客户端 cd chapt3_ws/ colcon build --packages-select example_service_rclcpp source install/setup.bash ros2 run example_service_rclcpp service_client_01 打开服务端，让服务上线 source install/setup.bash ros2 run example_service_rclcpp service_server_01 4.总结 本节我们通过RCLCPP完成了服务服务端和客户端的编写，并学了一些C++语言的新特性。下一节我们学习使用rclpy实现相同的功能。 "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/006-service-rclpy.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/006-service-rclpy.html","title":"service-rclpy","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 6.服务之RCLPY实现 1.创建功能包和节点 事到如今，也不藏着掖着了，创建功能包其实还可以加上一些参数，让这个过程变得更简单。 先上指令再说 cd chapt3/chapt3_ws/src ros2 pkg create example_service_rclpy --build-type ament_python --dependencies rclpy example_interfaces --node-name service_server_02 接着你会惊奇的发现，依赖，setup.py中的安装配置，ROS2都帮你加好了。 这是因为 --node-name service_server_02会帮你创建好节点文件和添加执行文件。 但是也有一些限制，比如只支持一个节点文件，所以我们还需要手动创建一个。 cd example_service_rclpy/example_service_rclpy/ touch service_client_02.py 修改下setup.py entry_points={ 'console_scripts': [ \"service_client_02 = example_service_rclpy.service_client_02:main\", \"service_server_02 = example_service_rclpy.service_server_02:main\" ], }, 接着面向对象来一筐，将两个节点的内容补充一下 service_server_02 #!/usr/bin/env python3 import rclpy from rclpy.node import Node class ServiceServer02(Node): def __init__(self,name): super().__init__(name) self.get_logger().info(\"节点已启动：%s!\" % name) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = ServiceServer02(\"service_server_02\") # 新建一个节点 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy service_client_02 #!/usr/bin/env python3 import rclpy from rclpy.node import Node from example_interfaces.srv import AddTwoInts class ServiceClient02(Node): def __init__(self,name): super().__init__(name) self.get_logger().info(\"节点已启动：%s!\" % name) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = ServiceClient02(\"service_client_02\") # 新建一个节点 node.send_request(3,4) rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 2.服务端实现 2.1 看 API 地址放这里，大家自行看下即可 Node — rclpy 0.6.1 documentation (ros2.org) 2.2 写代码 # 导入接口 from example_interfaces.srv import AddTwoInts class ServiceServer02(Node): def __init__(self,name): super().__init__(name) self.get_logger().info(\"节点已启动：%s!\" % name) self.add_ints_server_ = self.create_service(AddTwoInts,\"add_two_ints_srv\", self.handle_add_two_ints) def handle_add_two_ints(self,request, response): self.get_logger().info(f\"收到请求，计算{request.a} + {request.b}\") response.sum = request.a + request.b return response 2.3 测试 colcon build --packages-select example_service_rclpy source install/setup.bash ros2 run example_service_rclpy service_server_02 打开新终端 ros2 service call /add_two_ints_srv example_interfaces/srv/AddTwoInts \"{a: 5,b: 10}\" 3.客户端实现 2.1 API Node — rclpy 0.6.1 documentation (ros2.org) 2.2 写代码 from example_interfaces.srv import AddTwoInts class ServiceClient02(Node): def __init__(self,name): super().__init__(name) self.get_logger().info(\"节点已启动：%s!\" % name) self.client_ = self.create_client(AddTwoInts,\"add_two_ints_srv\") def result_callback_(self, result_future): response = result_future.result() self.get_logger().info(f\"收到返回结果：{response.sum}\") def send_request(self, a, b): while rclpy.ok() and self.client_.wait_for_service(1)==False: self.get_logger().info(f\"等待服务端上线....\") request = AddTwoInts.Request() request.a = a request.b = b self.client_.call_async(request).add_done_callback(self.result_callback_) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = ServiceClient02(\"service_client_02\") # 新建一个节点 # 调用函数发送请求 node.send_request(3,4) rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 同样是异步请求，rclpy客户端库定义的是call_async并且使用add_done_callback添加回调函数。 2.3 测试 编译启动客户端 colcon build --packages-select example_service_rclpy source install/setup.bash ros2 run example_service_rclpy service_client_02 启动服务端 source install/setup.bash ros2 run example_service_rclpy service_server_02 4.总结 本节我们通过rclpy库实现了节点之间的服务通信。但是我们都是用别人的接口，下一节我们学习自定义接口并在代码中使用。 下面两节含实战内容，一定要跟着动手写哦。 "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/007-interface.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/007-interface.html","title":"interface","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 7.ROS2接口介绍 本节将会带你学习认识一个新的概念，叫做interface，即接口。 1.ROS2接口介绍 1.1 什么是接口 接口其实是一种规范 你还记得前面几节的示例中，我们在代码中使用过这两种接口，这两种数据类型分别代表字符串和32位二进制的整型数据，是ROS 2提前定义的一种规范。 std_msgs/msg/String std_msgs/msg/UInt32 1.2 为什么使用接口 举一个雷达的例子，不同的厂家生产出不同的类型的激光雷达，每种雷达驱动方式、扫描速率等等都不相同。 当机器人进行导航时，需要激光雷达的扫描数据，假如没有统一接口，每次更换一个种类的雷达，都需要重新做程序适配。 于是ROS2中定义了一个统一的接口叫做sensor_msgs/msg/LaserScan,现在几乎每个雷达的厂家都会编写程序将自己雷达的数据变成sensor_msgs/msg/LaserScan格式，提供给用户使用。 如果雷达的例子不好理解，大家可以把雷达换成手机充电器，USB接口是不是也是一种规范，所有的厂家都按照这种接口进行充电器和连接线的生产。 1.3. ROS2自带的接口 前面话题通信时std_msgs功能包是我们安装ROS2的时候ROS2为我们自动安装的，除了std_msgs之外，ROS2还定义了很多做机器人常用的接口。 使用ros2 interface package sensor_msgs命令可以查看某一个接口包下所有的接口 比如：传感器类的消息包sensor_msgs 打开终端输入：ros2 interface package sensor_msgs sensor_msgs/msg/JointState #机器人关节数据 sensor_msgs/msg/Temperature #温度数据 sensor_msgs/msg/Imu #加速度传感器 sensor_msgs/msg/Image #图像 sensor_msgs/msg/LaserScan #雷达数据 ...... 虽然ROS2为我们定义了大量有手就行，拿来就用的接口，但有时候还是不能满足我们的变态想法，所以我们需要掌握自定义接口的方法。 2. 接口文件内容 2.1 可以定义的接口三种类型 提到过，ROS2提供了四种通信方式： 话题-Topics 服务-Services 动作-Action 参数-Parameters 除了参数之外，话题、服务和动作(Action)都支持自定义接口，每一种通信方式所适用的场景各不相同，所定义的接口也被分为话题接口、服务接口、动作接口三种。 2.2 接口形式 这三种接口定义起来有什么不一样的地方呢？先带大家直观感受一下： 话题接口格式：xxx.msg int64 num 服务接口格式：xxx.srv int64 a int64 b --- int64 sum 动作接口格式：xxx.action int32 order --- int32[] sequence --- int32[] partial_sequence 2.3 接口数据类型 根据引用方式不同可以分为基础类型和包装类型两类。 基础类型有（同时后面加上[]可形成数组） bool byte char float32,float64 int8,uint8 int16,uint16 int32,uint32 int64,uint64 string 包装类型 即在已有的接口类型上进行包含，比如 uint32 id string image_name sensor_msgs/Image 2.4 接口如何生成代码 有的同学可能会问这样一个问题，我们只是简单的写了一下变量类型和名称，我们在程序里面怎么调用呢？ 其实这里有一个转换的过程：将msg、srv、action文件转换为Python和C++的头文件。 graph LR A[msg,srv,action] -->B[ROS2-IDL转换器] B --> C[Python的py,C++的.h头文件] 通过ROS2的IDL模块 产生了头文件，有了头文件，我们就可以在程序里导入并使用这个消息模块。 3.自定义接口实践 3.1 场景定义 给定一个机器人开发中的常见控制场景，我们设计满足要求的服务接口和话题接口。 设计两个节点 一个机器人节点，对外提供移动指定距离服务，移动完成后返回当前位置，同时对外发布机器人的位置和状态（是否在移动）。 机器人控制节点，通过服务控制机器人移动指定距离，并实时获取机器人的当前位置和状态。 假设机器人在坐标轴上，只能前后移动。 3.2 定义接口 服务接口MoveRobot.srv # 前进后退的距离 float32 distance --- # 当前的位置 float32 pose 话题接口，采用基础类型 RobotStatus.msg uint32 STATUS_MOVEING = 1 uint32 STATUS_STOP = 1 uint32 status float32 pose 话题接口，混合包装类型 RobotPose.msg uint32 STATUS_MOVEING = 1 uint32 STATUS_STOP = 2 uint32 status geometry_msgs/Pose pose 3.3 创建接口功能包编接口 创建功能包 ros2 pkg create example_ros2_interfaces --build-type ament_cmake --dependencies rosidl_default_generators geometry_msgs 注意功能包类型必须为：ament_cmake 依赖rosidl_default_generators必须添加，geometry_msgs视内容情况添加（我们这里有geometry_msgs/Pose pose所以要添加）。 接着创建文件夹和文件将3.2中文件写入，注意话题接口放到msg文件夹下，以.msg结尾。服务接口放到srv文件夹下，以srv结尾。 . ├── CMakeLists.txt ├── msg │ ├── RobotPose.msg │ └── RobotStatus.msg ├── package.xml └── srv └── MoveRobot.srv 2 directories, 5 files 接着修改CMakeLists.txt find_package(rosidl_default_generators REQUIRED) find_package(geometry_msgs REQUIRED) # 添加下面的内容 rosidl_generate_interfaces(${PROJECT_NAME} \"msg/RobotPose.msg\" \"msg/RobotStatus.msg\" \"srv/MoveRobot.srv\" DEPENDENCIES geometry_msgs ) 接着修改package.xml ament_cmake rosidl_default_generators geometry_msgs rosidl_interface_packages #添加这一行 ament_lint_auto ament_lint_common 保存即可编译 colcon build --packages-select example_ros2_interfaces 编译完成后在chapt3_ws/install/example_ros2_interfaces/include 下你应该可以看到C++的头文件。在chapt3_ws/install/example_ros2_interfaces/local/lib/python3.10/dist-packages下应该可以看到Python版本的头文件。 接下来的代码里我们就可以通过头文件导入和使用我们定义的接口了。 @TODO 讲一下为什么要source 4.ROS2接口常用CLI命令 最后给大家讲一下ROS2接口相关的常用命令有哪些。 4.1查看接口列表 ros2 interface list 4.2 查看某一个接口详细的内容 ros2 interface show std_msgs/msg/String "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/008-interface-rclcpp.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/008-interface-rclcpp.html","title":"interface-rclcpp","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 8.自定义接口RCLCPP实战 本节我们就利用上一节创建好的消息接口进行代码编写代码，学习在实际的项目中使用自定义接口，同时也作为一个小练习，我们将在同一个节点里融合话题和服务两种通信方式。 1.创建功能包和节点 这里我们设计两个节点 example_interfaces_robot_01，机器人节点，对外提供控制机器人移动服务并发布机器人的状态。 example_interfaces_control_01，控制节点，发送机器人移动请求，订阅机器人状态话题。 在工作空间下的src文件夹中创建功能包example_ros2_interfaces添加example_ros2_interfaces和rclcpp依赖，并自动生成example_interfaces_robot_01节点。 因为--node-name只支持创建一个节点，我们再添加一下另外一个节点。 cd chapt3_ws/ ros2 pkg create example_interfaces_rclcpp --build-type ament_cmake --dependencies rclcpp example_ros2_interfaces --destination-directory src --node-name example_interfaces_robot_01 touch src/example_interfaces_rclcpp/src/example_interfaces_control_01. CMakeLists.txt find_package(ament_cmake REQUIRED) find_package(rclcpp REQUIRED) find_package(example_ros2_interfaces REQUIRED) add_executable(example_interfaces_robot_01 src/example_interfaces_robot_01.cpp) target_include_directories(example_interfaces_robot_01 PUBLIC $ $) target_compile_features(example_interfaces_robot_01 PUBLIC c_std_99 cxx_std_17) # Require C99 and C++17 ament_target_dependencies( example_interfaces_robot_01 \"rclcpp\" \"example_ros2_interfaces\" ) install(TARGETS example_interfaces_robot_01 DESTINATION lib/${PROJECT_NAME}) add_executable(example_interfaces_control_01 src/example_interfaces_control_01.cpp) target_include_directories(example_interfaces_control_01 PUBLIC $ $) target_compile_features(example_interfaces_control_01 PUBLIC c_std_99 cxx_std_17) # Require C99 and C++17 ament_target_dependencies( example_interfaces_control_01 \"rclcpp\" \"example_ros2_interfaces\" ) install(TARGETS example_interfaces_control_01 DESTINATION lib/${PROJECT_NAME}) 面向对象写一下两个节点的内容 example_interfaces_control_01.cpp #include \"rclcpp/rclcpp.hpp\" class ExampleInterfacesControl : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 ExampleInterfacesControl(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); } private: }; int main(int argc, char** argv) { rclcpp::init(argc, argv); auto node = std::make_shared(\"example_interfaces_control_01\"); rclcpp::spin(node); rclcpp::shutdown(); return 0; } example_interfaces_robot_01.cpp #include \"rclcpp/rclcpp.hpp\" /*创建一个机器人类，模拟真实机器人*/ class Robot { public: Robot() = default; ~Robot() = default; private: }; class ExampleInterfacesRobot : public rclcpp::Node { public: ExampleInterfacesRobot(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); } private: Robot robot; }; int main(int argc, char** argv) { rclcpp::init(argc, argv); auto node = std::make_shared(\"example_interfaces_robot_01\"); rclcpp::spin(node); rclcpp::shutdown(); return 0; } 保存编译即可测试 cd chapt3_ws/ colcon build source install/setup.bash 2.编写机器人类 // 导入上一节定义的消息接口 #include \"example_ros2_interfaces/msg/robot_status.hpp\" #include \"example_ros2_interfaces/srv/move_robot.hpp\" #include \"rclcpp/rclcpp.hpp\" /* * 测试指令：ros2 service call /move_robot example_ros2_interfaces/srv/MoveRobot \"{distance: 5}\" */ class Robot { public: Robot() = default; ~Robot() = default; /** * @brief 移动指定的距离 * * @param distance * @return float */ float move_distance(float distance) { status_ = example_ros2_interfaces::msg::RobotStatus::STATUS_MOVEING; target_pose_ += distance; // 当目标距离和当前距离大于0.01则持续向目标移动 while (fabs(target_pose_ - current_pose_) > 0.01) { // 每一步移动当前到目标距离的1/10 float step = distance / fabs(distance) * fabs(target_pose_ - current_pose_) * 0.1; current_pose_ += step; std::cout 该类的实现比较简单，对外提供获取当前状态、获取当前位置和移动一定的距离三个接口，其中移动指定距离这个函数每移动一步会休眠500ms。 3.编写机器人节点逻辑 接着我们就可以利用接口编写机器人节点了 class ExampleInterfacesRobot : public rclcpp::Node { public: ExampleInterfacesRobot(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); /*创建move_robot服务*/ move_robot_server_ = this->create_service( \"move_robot\", std::bind(&ExampleInterfacesRobot::handle_move_robot, this, std::placeholders::_1, std::placeholders::_2)); /*创建发布者*/ robot_status_publisher_ = this->create_publisher(\"robot_status\", 10); /*创建一个周期为500ms的定时器*/ timer_ = this->create_wall_timer(std::chrono::milliseconds(500), std::bind(&ExampleInterfacesRobot::timer_callback, this)); } private: Robot robot; /*实例化机器人*/ rclcpp::TimerBase::SharedPtr timer_; /*定时器，用于定时发布机器人位置*/ rclcpp::Service::SharedPtr move_robot_server_; /*移动机器人服务*/ rclcpp::Publisher::SharedPtr robot_status_publisher_; /*发布机器人位姿发布者*/ /** * @brief 500ms 定时回调函数， * */ void timer_callback() { // 创建消息 example_ros2_interfaces::msg::RobotStatus message; message.status = robot.get_status(); message.pose = robot.get_current_pose(); RCLCPP_INFO(this->get_logger(), \"Publishing: %f\", robot.get_current_pose()); // 发布消息 robot_status_publisher_->publish(message); }; /** * @brief 收到话题数据的回调函数 * * @param request 请求共享指针，包含移动距离 * @param response 响应的共享指针，包含当前位置信息 */ void handle_move_robot(const std::shared_ptr request, std::shared_ptr response) { RCLCPP_INFO(this->get_logger(), \"收到请求移动距离：%f，当前位置：%f\", request->distance, robot.get_current_pose()); robot.move_distance(request->distance); response->pose = robot.get_current_pose(); }; }; 逻辑也比较简单，利用定时器不断发送数据，收到请求后调用机器人类的move_distance接口来移动机器人。 4.编写控制节点 控制节点类代码 头文件部分 #include \"rclcpp/rclcpp.hpp\" #include \"example_ros2_interfaces/srv/move_robot.hpp\" #include \"example_ros2_interfaces/msg/robot_status.hpp\" ExampleInterfacesControl类 class ExampleInterfacesControl : public rclcpp::Node { public: ExampleInterfacesControl(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); /*创建move_robot客户端*/ client_ = this->create_client( \"move_robot\"); /*订阅机器人状态话题*/ robot_status_subscribe_ = this->create_subscription(\"robot_status\", 10, std::bind(&ExampleInterfacesControl::robot_status_callback_, this, std::placeholders::_1)); } /** * @brief 发送移动机器人请求函数 * 步骤：1.等待服务上线 * 2.构造发送请求 * * @param distance */ void move_robot(float distance) { RCLCPP_INFO(this->get_logger(), \"请求让机器人移动%f\", distance); /*等待服务端上线*/ while (!client_->wait_for_service(std::chrono::seconds(1))) { //等待时检测rclcpp的状态 if (!rclcpp::ok()) { RCLCPP_ERROR(this->get_logger(), \"等待服务的过程中被打断...\"); return; } RCLCPP_INFO(this->get_logger(), \"等待服务端上线中\"); } // 构造请求 auto request = std::make_shared(); request->distance = distance; // 发送异步请求，然后等待返回，返回时调用回调函数 client_->async_send_request( request, std::bind(&ExampleInterfacesControl::result_callback_, this, std::placeholders::_1)); }; private: // 声明客户端 rclcpp::Client::SharedPtr client_; rclcpp::Subscription::SharedPtr robot_status_subscribe_; /* 机器人移动结果回调函数 */ void result_callback_( rclcpp::Client::SharedFuture result_future) { auto response = result_future.get(); RCLCPP_INFO(this->get_logger(), \"收到移动结果：%f\", response->pose); } /** * @brief 机器人状态话题接收回调函数 * * @param msg */ void robot_status_callback_(const example_ros2_interfaces::msg::RobotStatus::SharedPtr msg) { RCLCPP_INFO(this->get_logger(), \"收到状态数据位置：%f 状态：%d\", msg->pose ,msg->status); } }; main函数 int main(int argc, char** argv) { rclcpp::init(argc, argv); auto node = std::make_shared(\"example_interfaces_control_01\"); /*这里调用了服务，让机器人向前移动5m*/ node->move_robot(5.0); rclcpp::spin(node); rclcpp::shutdown(); return 0; } 5.测试运行 5.1 编译 colcon build --packages-up-to example_interfaces_rclcpp 又遇到了个新的指令--packages-up-to，在colcon使用进阶篇有讲到，编译一个节点及其依赖，使用这个指令你会发现，以先后顺序编译了example_ros2_interfaces 再编译example_interfaces_rclcpp。 5.2 测试 控制端 source install/setup.bash ros2 run example_interfaces_rclcpp example_interfaces_control_01 服务端 source install/setup.bash ros2 run example_interfaces_rclcpp example_interfaces_robot_01 服务端启动后机器人开始移动，时间为：1654693733.053691559 移动结束，收到移动结果：4.990017，时间为：1654693763.501926752 5.3 思考 虽然机器人可以移动了，客户端也可以收到机器人的位置了，但是聪明的你应该发现了，在机器人移动期间，控制端就收不到了来自机器人端的实时位置信息的话题发布了。 原因是服务端调用机器人移动的时候造成了主线程的阻塞和休眠，只有机器人完成移动后才会退出，造成了发布数据的定时器回调无法正常进行。 解决这个问题的方法有很多，比如开个单独给服务开个线程，比如换一种通信方式，带着问题和好奇心，我们继续学习，将带你解决掉它。 "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/009-interface-rclpy.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/入门/009-interface-rclpy.html","title":"interface-rclpy","keywords":"","body":"datetime:2023/09/13 16:38 author:nzb 该项目来源于大佬的动手学ROS2 9.自定义接口RCLPY实战 上一节我们使用RCLCPP的API通过自定义接口实现控制节点和机器人节点之间的话题与服务通信。本节我们以RCLPY客户端库为例，给大家讲解实现方法。 1.创建功能包 这里我们依然设计两个节点 example_interfaces_robot_02，机器人节点，对外提供控制机器人移动服务并发布机器人的状态。 example_interfaces_control_02，控制节点，发送机器人移动请求，订阅机器人状态话题。 cd chapt3_ws/ ros2 pkg create example_interfaces_rclpy --build-type ament_python --dependencies rclpy example_ros2_interfaces --destination-directory src --node-name example_interfaces_robot_02 --maintainer-name \"fishros\" --maintainer-email \"fishros@foxmail.com\" touch src/example_interfaces_rclpy/example_interfaces_rclpy/example_interfaces_control_02.py setup.py maintainer='fishros', maintainer_email='fishros@foxmail.com', entry_points={ 'console_scripts': [ 'example_interfaces_control_02 = example_interfaces_rclpy.example_interfaces_control_02:main', 'example_interfaces_robot_02 = example_interfaces_rclpy.example_interfaces_robot_02:main' ], }, 这里又加了两个选项 --maintainer-name \"fishros\"，指定拥有者的名字 --maintainer-email \"fishros@foxmail.com\"，指定拥有者邮箱 example_interfaces_robot_02.py #!/usr/bin/env python3 import rclpy from rclpy.node import Node class Robot(): def __init__(self) -> None: pass class ExampleInterfacesRobot02(Node): def __init__(self, name): super().__init__(name) self.get_logger().info(\"节点已启动：%s!\" % name) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = ExampleInterfacesRobot02(\"example_interfaces_robot_02\") # 新建一个节点 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy example_interfaces_control_02.py #!/usr/bin/env python3 import rclpy from rclpy.node import Node class ExampleInterfacesControl02(Node): def __init__(self, name): super().__init__(name) self.get_logger().info(\"节点已启动：%s!\" % name) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = ExampleInterfacesControl02(\"example_interfaces_control_02\") # 新建一个节点 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 编译测试 # 新终端 colcon build --packages-up-to example_interfaces_rclpy source install/setup.bash ros2 run example_interfaces_rclpy example_interfaces_robot_02 # 新终端 source install/setup.bash ros2 run example_interfaces_rclpy example_interfaces_control_02 2.编写机器人类 源码与解析 from example_ros2_interfaces.msg import RobotStatus import math from time import sleep class Robot(): def __init__(self) -> None: self.current_pose_ = 0.0 self.target_pose_ = 0.0 self.status_ = RobotStatus.STATUS_STOP def get_status(self): return self.status_ def get_current_pose(self): return self.current_pose_ def move_distance(self, distance): self.status_ = RobotStatus.STATUS_MOVEING # 更新状态为移动、 self.target_pose_ += distance # 更新目标位置 while math.fabs(self.target_pose_ - self.current_pose_) > 0.01: step = distance / math.fabs(distance) * math.fabs(self.target_pose_ - self.current_pose_) * 0.1 # 计算一步移动距离 self.current_pose_ += step # 移动一步 print(f\"移动了：{step}当前位置：{self.current_pose_}\") sleep(0.5) # 休息0.5s self.status_ = RobotStatus.STATUS_STOP # 更新状态为停止 return self.current_pose_ 3.编写机器人节点 from example_ros2_interfaces.srv import MoveRobot class ExampleInterfacesRobot02(Node): def __init__(self, name): super().__init__(name) self.get_logger().info(\"节点已启动：%s!\" % name) self.robot = Robot() self.move_robot_server_ = self.create_service(MoveRobot, \"move_robot\", self.handle_move_robot) self.robot_status_publisher_ = self.create_publisher(RobotStatus, \"robot_status\", 10) self.publisher_timer_ = self.create_timer(0.5, self.publisher_timer_callback) def publisher_timer_callback(self): \"\"\" 定时器回调发布数据函数 \"\"\" msg = RobotStatus() # 构造消息 msg.status = self.robot.get_status() msg.pose = self.robot.get_current_pose() self.robot_status_publisher_.publish(msg) # 发布消息 self.get_logger().info(f'发布了当前的状态：{msg.status} 位置：{msg.pose}') def handle_move_robot(self, request, response): self.robot.move_distance(request.distance) response.pose = self.robot.get_current_pose() return response 逻辑与RCLCPP版本一致，创建服务和发布者，并创建定时器定时调用发布者完成发布。 4.编写控制节点 #!/usr/bin/env python3 import rclpy from rclpy.node import Node from example_ros2_interfaces.msg import RobotStatus from example_ros2_interfaces.srv import MoveRobot class ExampleInterfacesControl02(Node): def __init__(self, name): super().__init__(name) self.get_logger().info(\"节点已启动：%s!\" % name) self.client_ = self.create_client(MoveRobot, \"move_robot\") self.robot_status_subscribe_ = self.create_subscription(RobotStatus, \"robot_status\", self.robot_status_callback, 10) def robot_status_callback(self, msg): self.get_logger().info(f\"收到状态数据位置：{msg.pose} 状态：{msg.status}\") def move_result_callback_(self, result_future): response = result_future.result() self.get_logger().info(f\"收到返回结果：{response.pose}\") def move_robot(self, distance): while rclpy.ok() and self.client_.wait_for_service(1) == False: self.get_logger().info(f\"等待服务端上线....\") request = MoveRobot.Request() request.distance = distance self.get_logger().info(f\"请求服务让机器人移动{distance}\") self.client_.call_async(request).add_done_callback(self.move_result_callback_) def main(args=None): rclpy.init(args=args) # 初始化rclpy node = ExampleInterfacesControl02(\"example_interfaces_control_02\") # 新建一个节点 node.move_robot(5.0) # 移动5米 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 控制节点逻辑也与RCLCPP版本一致，创建一个订阅者和客户端，在主函数中请求服务端进行移动。 5.运行测试 # 新终端 colcon build --packages-up-to example_interfaces_rclpy source install/setup.bash ros2 run example_interfaces_rclpy example_interfaces_robot_02 # 新终端 source install/setup.bash ros2 run example_interfaces_rclpy example_interfaces_control_02 同样的，你会发现在机器人移动期间是机器人节点并没有发布机器人位姿出来，在进阶篇中我们可以使用ROS2的多线程执行器和回调组来解决这个问题。 "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/进阶/001-原始数据类型与包装类型.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/进阶/001-原始数据类型与包装类型.html","title":"原始数据类型与包装类型","keywords":"","body":"datetime:2023/09/15 16:38 author:nzb 该项目来源于大佬的动手学ROS2 1. 原始数据类型与包装类型 在ROS2中定义接口，需要编写一个接口文件，该文件后缀为msg、srv、action。 在接口文件中定义通信过程中所使用的数据类型和数据名称，那可用的数据类型和数据名称有哪些呢？今天就带你详细了解一下ROS2接口文件中的数据类型和数据名称。 1.数据名称 数据名称就是一个字符串，没啥好说的，符合编程语言变量的命名规则就行（比如不能是数字开头） 2.数据类型 2.1 数据类型有哪些呢？ 这里可以告诉你，原始的数据类型只有九类。其中每一个都可以在后面加上[]将其变成数组形式（从一个变成多个） bool byte char float32, float64 int8, uint8 int16, uint16 int32, uint32 int64, uint64 string 上面这九类中，官方也在考虑新增一些和删除一些，目前还是支持的，后续会根据资料再更新一下本文。 2.2 类型扩展（套娃） 2.2.1 第一层套娃 ROS2基于上面的九类基础数据类型，为我们定义出了很多拿来就用的数据类型，比如我们在前面章节中用到的图像数据类型sensor_msgs/Image,我们可以使用下面的命令来看一下其组成： ros2 interface show sensor_msgs/msg/Image 去掉单行的注释后的样子如下： std_msgs/Header header # Header timestamp should be acquisition time of image uint32 height # image height, that is, number of rows uint32 width # image width, that is, number of columns string encoding # Encoding of pixels -- channel meaning, ordering, size uint8 is_bigendian # is this data bigendian? uint32 step # Full row length in bytes uint8[] data # actual matrix data, size is (step * rows) 我们可以看到，除了第一行std_msgs/Header header之外的其他部分都是由基础类型组成。 2.2.2 第二层套娃 那std_msgs/Header由什么组成呢？我们再次使用下面的指令查看一下： ros2 interface show std_msgs/msg/Header 结果如下： builtin_interfaces/Time stamp # Two-integer timestamp that is expressed as seconds and nanoseconds. string frame_id # Transform frame with which this data is associated. 2.2.3 第三层套娃 看完上面的结果，除了基本类型string和我们发现还有一层builtin_interfaces/Time，我们再查看一下这个接口类型。 ros2 interface show builtin_interfaces/msg/Time 结果如下： # Time indicates a specific point in time, relative to a clock's 0 point. # The seconds component, valid over all int32 values. int32 sec # The nanoseconds component, valid in the range [0, 10e9). uint32 nanosec 我们发现结果全都是基本类型了，终于我们把套娃给解开了。 3.接口类型总结 通过基本类型的组合，可以构成一个新的数据类型，而新的数据类型又可以和基本类型或者另外一个数据类型互相组成另一个数据类型。所以我们可以说ROS2中的数据类型有无数种。 "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/进阶/002-通信质量Qos配置指南.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/进阶/002-通信质量Qos配置指南.html","title":"通信质量Qos配置指南","keywords":"","body":"datetime:2023/09/15 16:38 author:nzb 该项目来源于大佬的动手学ROS2 Rviz显示不出数据了！一文搞懂Qos ROS2的通信中间件换成了DDS。这让我们可以精准地控制节点间的通信质量。通信效率也迎来了一次大的提升。 但是... 但是... 一个不小心，看到了类似这样的报错信息： [WARN] [1644578813.965216245] [subscriber_qos_obj]: New publisher discovered on topic '/qos_test', offering incompatible QoS. No messages will be received from it. Last incompatible policy: RELIABILITY 本来好好的Rviz也显示不了雷达数据了。 这就是incompatible QoS搞的鬼！ 两个节点的Qos设置不兼容将没法通信 那什么是Qos（Quality of Service） 在ROS1中，节点间的通信是基于TCP的。因为TCP的失败重传机制，在一些网络不稳定的场景，通信会出现延时严重的问题。这大大限制了ROS1的使用场景。 在ROS2中，采用DDS作为通信中间件。ROS2的DDS中间件是可以配置成不同厂家提供的。这些不同的DDS各自有不同的侧重点，可根据项目的不同需求来选择。ROS2 Galactic和Rolling 默认采用rmw_cyclonedds_cpp。rmw_cyclonedds_cpp在进程间和多主机间通信的场景下，主要是使用UDP做为通信媒介。 通过正确的服务质量策略配置，ROS2可以像TCP一样可靠，也可以像UDP那样尽力而为。在不稳定的网络环境下，“尽力而为”策略将更合适。在实时性要求高的场景下，设定数据的有效性将是必须的。 针对节点特定的工作负载和使用场景，有倾向地配置Qos将可以使通信质量达到最佳。 我们可以为发布器、订阅器、提供服务的服务器和客户端配置QoS。 因为每个节点的Qos是可以单独配置的，所以如果配置的Qos互相不兼容，节点间的通信将无法建立。 Qos（Quality of Service）有哪些配置项 配置项目 History Keep last: 只缓存最新的N个数据，N可通过Depth的Queue size配置。 Keep all: 缓存所有的数据，但是受限于DDS底层的资源限制。 Depth Queue size: 当History设置为Keep last时有效。 QoS & QoS::keep_last(size_t depth) { rmw_qos_profile_.history = RMW_QOS_POLICY_HISTORY_KEEP_LAST; rmw_qos_profile_.depth = depth; return *this; } Reliability Best effort: 尽力传送数据，但是网络不稳定可能会丢弃一些数据。 Reliable: 确保数据被传送到，可能会重传多次，导致数据延时严重。 Durability Transient local: 为后订阅话题的订阅者保留数据，比如map_server发布map的Qos策略。 Volatile: 不为后订阅话题的订阅者保留数据，比如订阅传感器数据的节点。 // Create a publisher using the QoS settings to emulate a ROS1 latched topic occ_pub_ = create_publisher( topic_name, rclcpp::QoS(rclcpp::KeepLast(1)).transient_local().reliable()); Deadline Duration: 设置数据被发布的间隔时间。比如：像cmd_vel等控制命令就希望是固定间隔时间下发的。 Lifespan Duration: 设置数据从发布到被接收的最大间隔时间。超过该时间将被认为是过时的数据，直接丢弃了。这对于传感器数据来说是很重要的。因为过时的传感器数据毫无用处。 Liveliness Automatic: 一个节点可能有多个发布器。只要有一个发布器发布了数据，系统将认为该节点的所有发布器在接下来的lease duration时间段内是活跃的。 Manual by topic: 如果手动确认发布器仍然是活跃的，系统将认为该发布器在接下来的lease duration时间段内是活跃的。 Lease Duration Duration: 在这个时间段内，发布器需发布数据，不然会被系统认为是停止工作了。该参数与Liveliness配合使用。 不兼容的Qos策略 知道了所有的Qos的配置项目后，哪些跟哪些配置是不兼容的呢？ 这里有一张对比表帮助我们避免不兼容的Qos策略设置。 表中的x表示人为设定了某个值，Default值根据不同的DDS有不同的设定。通常是下面两种： /// Constant representing an infinite duration. Use rmw_time_equal for comparisons. /** * Different RMW implementations have different representations for infinite durations. * This value is reported for QoS policy durations that are left unspecified. * Do not directly compare `sec == sec && nsec == nsec`, because we don't want to be sensitive * to non-normalized values (nsec > 1 second) - use rmw_time_equal instead. * This value is INT64_MAX nanoseconds = 0x7FFF FFFF FFFF FFFF = d 9 223 372 036 854 775 807 * * Note: these constants cannot be `static const rmw_time_t` because in C that can't be used * as a compile-time initializer */ #define RMW_DURATION_INFINITE {9223372036LL, 854775807LL} #define RMW_DURATION_UNSPECIFIED {0LL, 0LL} 查询话题的Qos策略 用下面的命令查询 ros2 topic info /scan --verbose 输出示例 Type: sensor_msgs/msg/LaserScan Publisher count: 1 Node name: laserscan Node namespace: / Topic type: sensor_msgs/msg/LaserScan Endpoint type: PUBLISHER GID: 71.03.10.01.8b.5b.f9.27.8e.9d.a4.4e.00.00.6c.03.00.00.00.00.00.00.00.00 QoS profile: Reliability: BEST_EFFORT Durability: VOLATILE Lifespan: 9223372036854775807 nanoseconds Deadline: 9223372036854775807 nanoseconds Liveliness: AUTOMATIC Liveliness lease duration: 9223372036854775807 nanoseconds Subscription count: 0 分析一下: Reliability = BEST_EFFORT. 这是在传感器节点中的标准设置方式。因为我们感兴趣的是获得大量的数据，如果丢失一两个信息，其实并不重要。 Durability = Volatile. 这也是传感器节点的标准方式，特别是具有高数据量的传感器。我们并不需要为晚加入的节点保存旧的信息。因为旧信息对它根本没有意义了。 Liveliness = Automatic. 这是默认的设置，特别是对于传感器。我们认为在lease duration时间段内，节点发布了任何话题，代表节点是活跃的。 Deadline = \"9223372036.854775807\" seconds ( INFINITE VALUE ). 这意味着 没有Deadline限制. Lifespan = \"9223372036.854775807\" seconds( INFINITE VALUE ). 这意味着 没有数据有效性限制. 不管数据延时多久被接受到都认为其是有效。这是从gazebo中发出的数据。仿真环境下这么设置应该没啥关系。但在实际场景下则需要根据需求设置一下。 系统层预设的Qos 这里以rclcpp为例。 Qos配置的相关接口维护在rclcpp模块中的qos.cpp和qos.hpp文件中。/opt/ros/galactic/include/rmw/qos_profiles.h中维护了预设的Qos结构数据。 这里放置两个瞧瞧。 /** * Sensor Data QoS class * - History: Keep last, * - Depth: 5, * - Reliability: Best effort, * - Durability: Volatile, * - Deadline: Default, * - Lifespan: Default, * - Liveliness: System default, * - Liveliness lease duration: default, * - avoid ros namespace conventions: false */ static const rmw_qos_profile_t rmw_qos_profile_sensor_data = { RMW_QOS_POLICY_HISTORY_KEEP_LAST, 5, RMW_QOS_POLICY_RELIABILITY_BEST_EFFORT, RMW_QOS_POLICY_DURABILITY_VOLATILE, RMW_QOS_DEADLINE_DEFAULT, RMW_QOS_LIFESPAN_DEFAULT, RMW_QOS_POLICY_LIVELINESS_SYSTEM_DEFAULT, RMW_QOS_LIVELINESS_LEASE_DURATION_DEFAULT, false }; /** * Parameters QoS class * - History: Keep last, * - Depth: 1000, * - Reliability: Reliable, * - Durability: Volatile, * - Deadline: Default, * - Lifespan: Default, * - Liveliness: System default, * - Liveliness lease duration: default, * - Avoid ros namespace conventions: false */ static const rmw_qos_profile_t rmw_qos_profile_parameters = { RMW_QOS_POLICY_HISTORY_KEEP_LAST, 1000, RMW_QOS_POLICY_RELIABILITY_RELIABLE, RMW_QOS_POLICY_DURABILITY_VOLATILE, RMW_QOS_DEADLINE_DEFAULT, RMW_QOS_LIFESPAN_DEFAULT, RMW_QOS_POLICY_LIVELINESS_SYSTEM_DEFAULT, RMW_QOS_LIVELINESS_LEASE_DURATION_DEFAULT, false }; 测试Qos的示例代码 这里简单说明一种Qos不兼容的情况。 先看订阅器的示例代码 import rclpy from rclpy.node import Node from std_msgs.msg import String # import Quality of Service library, to set the correct profile and reliability. from rclpy.qos import ReliabilityPolicy, QoSProfile class SubscriberQoS(Node): def __init__(self): super().__init__('subscriber_qos_obj') # create the subscriber object self.subscriber = self.create_subscription( String, '/qos_test', self.listener_callback, QoSProfile(depth=10, reliability=ReliabilityPolicy.RELIABLE)) def listener_callback(self, msg): self.get_logger().info(\"Data Received =\" + str(msg.data)) def main(args=None): rclpy.init(args=args) sub_qos_obj = SubscriberQoS() rclpy.spin(sub_qos_obj) sub_qos_obj.destroy_node() rclpy.shutdown() if __name__ == '__main__': main() 再看看发布器的代码 import argparse import rclpy from rclpy.node import Node from std_msgs.msg import String from rclpy.qos_event import PublisherEventCallbacks from rclpy.duration import Duration from rclpy.qos import QoSProfile from rclpy.qos import QoSDurabilityPolicy from rclpy.qos import QoSLivelinessPolicy from rclpy.qos import QoSReliabilityPolicy class PublisherQoS(Node): def __init__(self, qos_profile, node_name=\"publisher_qos_obj\"): super().__init__(node_name) # create the publisher object # create_publisher(msg_type, topic, qos_profile, *, callback_group=None, event_callbacks=None) # INFO: https://docs.ros2.org/foxy/api/rclpy/api/node.html rclpy.logging.set_logger_level( node_name, rclpy.logging.LoggingSeverity.INFO) event_callbacks = PublisherEventCallbacks( incompatible_qos=self.incompatible_qos_clb) self.publisher_ = self.create_publisher(msg_type=String, topic='/qos_test', qos_profile=qos_profile, event_callbacks=event_callbacks) # This is the Unique id for each of the messages that will be sent self.msgs_id = 0 # self.current_time = self.get_clock().now() self.current_time_s = 0 self.current_time_ns = 0 # define the timer period for 0.5 seconds timer_period = 0.5 # create a timer sending two parameters: # - the duration between 2 callbacks (0.5 seeconds) # - the timer function (timer_callback) self.timer = self.create_timer(timer_period, self.timer_callback) def incompatible_qos_clb(self, event): \"\"\" This is the callback that will be executed when the Event of **Incompatible QoS** is triggered. \"\"\" self.get_logger().error(\"A subscriber is asking for an INCOMPATIBLE QoS Triggered!!\") self.get_logger().error(str(event.last_policy_kind)) self.get_logger().error(\"############################\") def timer_callback(self): # Here we have the callback method msg = String() test_time = self.get_clock().now() self.current_time_s, self.current_time_ns = test_time.seconds_nanoseconds() time_str = str(self.current_time_s) + \",\" + str(self.current_time_ns) dds_msg_str = str(self.msgs_id) + \":\" + time_str msg.data = dds_msg_str # Publish the message to the topic self.publisher_.publish(msg) # Display the message on the console self.get_logger().info('Publishing: \"%s\"' % msg) self.msgs_id += 1 def get_parser(): parser = argparse.ArgumentParser() parser.add_argument( '-reliability', type=str, choices=['best_effort', 'reliable'], help='Select Policy for reliability, use ros2 run dds_tests_pkg publisher_dds_custom_qos_exe -reliability best_effort|reliable') return parser def main(args=None): # Lets parse the arguments parser = get_parser() parsed_args = parser.parse_args() # Configuration variables reliability = parsed_args.reliability print(reliability) qos_profile_publisher = QoSProfile(depth=10) # Options QoSDurabilityPolicy.VOLATILE, QoSDurabilityPolicy.TRANSIENT_LOCAL, qos_profile_publisher.durability = QoSDurabilityPolicy.VOLATILE qos_profile_publisher.deadline = Duration(seconds=2) # Options QoSLivelinessPolicy.MANUAL_BY_TOPIC, QoSLivelinessPolicy.AUTOMATIC qos_profile_publisher.liveliness = QoSLivelinessPolicy.AUTOMATIC qos_profile_publisher.liveliness_lease_duration = Duration(seconds=2) # Options: QoSReliabilityPolicy.RELIABLE, QoSReliabilityPolicy.BEST_EFFORT if reliability == \"reliable\": qos_profile_publisher.reliability = QoSReliabilityPolicy.RELIABLE else: qos_profile_publisher.reliability = QoSReliabilityPolicy.BEST_EFFORT # initialize the ROS communication rclpy.init(args=args) # declare the node constructor pub_qos_obj = PublisherQoS(qos_profile_publisher) # pause the program execution, waits for a request to kill the node (ctrl+c) rclpy.spin(pub_qos_obj) # Explicity destroy the node pub_qos_obj.destroy_node() # shutdown the ROS communication rclpy.shutdown() if __name__ == '__main__': main() 按照下面的方式启动能正常收发 export RMW_IMPLEMENTATION=rmw_cyclonedds_cpp #指定中间通信件 ros2 run qos_tests_pkg publisher_custom_minimal_qos_exe -reliability reliable export RMW_IMPLEMENTATION=rmw_cyclonedds_cpp #指定中间通信件 ros2 run qos_tests_pkg subscriber_custom_minimal_qos_exe 两边命令窗口的打印均正常 发布命令窗口 reliable [INFO] [1644578723.014033825] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='0:1644578722,985456932')\" [INFO] [1644578723.486186513] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='1:1644578723,485332074')\" [INFO] [1644578723.986142873] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='2:1644578723,985345254')\" [INFO] [1644578724.486645546] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='3:1644578724,485467771')\" [INFO] [1644578724.986427990] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='4:1644578724,985333069')\" [INFO] [1644578725.486563859] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='5:1644578725,485435341')\" [INFO] [1644578725.986608071] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='6:1644578725,985460097')\" [INFO] [1644578726.486474454] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='7:1644578726,485332301')\" [INFO] [1644578726.986147983] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='8:1644578726,985357784')\" 接收命令窗口 [INFO] [1644578723.015739998] [subscriber_qos_obj]: Data Received =0:1644578722,985456932 [INFO] [1644578723.486751033] [subscriber_qos_obj]: Data Received =1:1644578723,485332074 [INFO] [1644578723.986497548] [subscriber_qos_obj]: Data Received =2:1644578723,985345254 [INFO] [1644578724.486954816] [subscriber_qos_obj]: Data Received =3:1644578724,485467771 [INFO] [1644578724.986790852] [subscriber_qos_obj]: Data Received =4:1644578724,985333069 [INFO] [1644578725.486864984] [subscriber_qos_obj]: Data Received =5:1644578725,485435341 [INFO] [1644578725.986921274] [subscriber_qos_obj]: Data Received =6:1644578725,985460097 [INFO] [1644578726.486804679] [subscriber_qos_obj]: Data Received =7:1644578726,485332301 [INFO] [1644578726.986422874] [subscriber_qos_obj]: Data Received =8:1644578726,985357784 按Qos不兼容的方式启动 export RMW_IMPLEMENTATION=rmw_cyclonedds_cpp #指定中间通信件 ros2 run qos_tests_pkg publisher_custom_minimal_qos_exe -reliability best_effort export RMW_IMPLEMENTATION=rmw_cyclonedds_cpp #指定中间通信件 ros2 run qos_tests_pkg subscriber_custom_minimal_qos_exe 这时两边的命令窗口都将出现incompatible QoS等字符。 发布命令窗口 best_effort [ERROR] [1644578813.964901713] [publisher_qos_obj]: A subscriber is asking for an INCOMPATIBLE QoS Triggered!! [ERROR] [1644578813.965861273] [publisher_qos_obj]: rmw_qos_policy_kind_t.RMW_QOS_POLICY_RELIABILITY [ERROR] [1644578813.966438368] [publisher_qos_obj]: ############################ [INFO] [1644578814.439657635] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='0:1644578814,438408983')\" [INFO] [1644578814.939157191] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='1:1644578814,938248853')\" [INFO] [1644578815.439442102] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='2:1644578815,438273310')\" [INFO] [1644578815.939210872] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='3:1644578815,938319227')\" [INFO] [1644578816.439078646] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='4:1644578816,438258510')\" [INFO] [1644578816.939358849] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='5:1644578816,938258582')\" [INFO] [1644578817.439420153] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='6:1644578817,438366411')\" [INFO] [1644578817.939196207] [publisher_qos_obj]: Publishing: \"std_msgs.msg.String(data='7:1644578817,938358924')\" 接收命令窗口 [WARN] [1644578813.965216245] [subscriber_qos_obj]: New publisher discovered on topic '/qos_test', offering incompatible QoS. No messages will be received from it. Last incompatible policy: RELIABILITY 原因是发布器和订阅器的Qos配置不兼容。 发布器：QoS Reliability=Best_Effort 订阅器：QoS Reliability=Reliable "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/进阶/003-DDS进阶之Fast-DDS环境搭建.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/进阶/003-DDS进阶之Fast-DDS环境搭建.html","title":"DDS进阶之Fast-DDS环境搭建","keywords":"","body":"datetime:2023/09/15 16:38 author:nzb 该项目来源于大佬的动手学ROS2 DDS进阶之Fast-DDS环境搭建 1.论FastDDS的三种打开方式 FastDDS和普通ROS包一样，有二进制安装、源码编译、Docker三种安装方式。 因为官方把二进制和Docker放到了官网。。 而且要填写个人信息才能下载。。 而且下载速度超级超级慢。。 而且不方便观摩源码。。 所以带你一起从源码进行安装。 因为DDS和ROS2相关，我们也可以使用colcon来编译，就不用cmake了(有需要cmake的自行到官网找) 2.源码编译安装FastDDS 下载编译DDS分为三步，第一步如果你已经安装了ROS2可以跳过。。 1.安装工具和依赖库 安装工具 sudo apt install python3-colcon-common-extensions python3-vcstool zip openjdk-8-jdk -y 安装依赖库 sudo apt-get install libasio-dev -y 2.创建目录，下载仓库 mkdir -p fastdds_ws/src cd fastdds_ws && wget https://downloads.gradle-dn.com/distributions/gradle-6.4-bin.zip && unzip gradle-6.4-bin.zip wget http://fishros.com/tools/files/fastrtps.repos && vcs import src 安装Fast DDS依赖项的 repos 文件时出现404：Not Found 3.编译 colcon build cd src/fastddsgen/ && gradle assemble 最后一步:配置环境变量 xxx是你的目录前缀 echo 'source xxx/fastdds_ws/install/setup.bash' >> ~/.bashrc echo 'export PATH=$PATH:xxx/fastdds_ws/gradle-6.4/bin/' >> ~/.bashrc echo 'export DDSGEN=xxx/fastdds_ws/src/fastddsgen/scripts' >> ~/.bashrc "},"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/进阶/004-使用DDS进行订阅发布.html":{"url":"ROS2/ROS2入门篇/第3章-ROS2节点通信之话题与服务/进阶/004-使用DDS进行订阅发布.html","title":"使用DDS进行订阅发布","keywords":"","body":"datetime:2023/09/15 16:38 author:nzb 该项目来源于大佬的动手学ROS2 使用DDS进行订阅发布 3.HelloFish例程 DDS使用的RTPS，就是Real-Time Publish Subscribe协议，其实和ROS与ROS2中的发布订阅的感觉时一样的，所以我们就跑一个例程来收发消息，消息内容就叫HelloFish 下载代码 git clone https://github.com/fishros/dds_tutorial.git 编译例程 cd dds_tutorial/examples/01-hellofishros mkdir build && cd build cmake .. make 执行例程 开一个终端 ./DDSHelloFishRosPublisher 再开一个终端 ./DDSHelloFishRosSubscribe 查看结果 正确结果像下面这样子，已经证明一切OK了~ 4.总结 看到熟悉的发布订阅是不是很神奇，FASTDDS底层采用了多种协议进行数据的传输，包括不靠谱但真的很快的UDP，靠谱但是不怎么快的TCP，还有感觉不传输的内存交换（SHM)。 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/基础/001-开环控制与闭环控制.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/基础/001-开环控制与闭环控制.html","title":"开环控制与闭环控制","keywords":"","body":"datetime:2023/09/18 10:18 author:nzb 该项目来源于大佬的动手学ROS2 1.开关控制与闭环控制 机器人的控制可以分为两种类型：开环控制和闭环控制。 一、闭环控制介绍 开环控制是指机器人按照预先设定的命令执行任务，但并不会对执行过程中的状态进行反馈和调整。简单来说，开环控制就是机器人盲目地按照指令执行任务，不考虑实际执行情况是否符合预期。开环控制的优点是简单易用，适用于一些简单的任务，如基本的运动控制或简单的搬运。但是，它的缺点也很明显，因为机器人无法感知执行任务的实际情况，因此无法自动调整行动，导致执行任务的成功率低，可靠性差。 二、闭环控制介绍 闭环控制是指机器人通过传感器或其他检测设备获取执行任务过程中的状态信息，将这些信息反馈给控制系统，从而实现对机器人执行任务过程中的实时控制和调整。在闭环控制中，机器人执行任务的过程中会根据反馈信息调整执行动作，确保机器人按照预期的方式完成任务。闭环控制的优点是能够根据实际情况进行实时调整，提高了机器人执行任务的成功率和可靠性。 三、哪个更常用？ 在机器人应用中，闭环控制更加普遍，因为它能够根据反馈信息实时调整机器人的动作，确保机器人按照预期的方式执行任务。同时，闭环控制还可以帮助机器人适应不同的工作环境，增强机器人的鲁棒性和自适应能力，实现更高效、更精准的控制。在一些高精度和复杂的应用场景中，闭环控制已经成为机器人控制的标准，比如精密加工、医疗手术、自动驾驶等。 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/001-param.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/001-param.html","title":"param","keywords":"","body":"datetime:2023/09/18 10:18 author:nzb 该项目来源于大佬的动手学ROS2 1.ROS2参数通信介绍 在前面的机器人控制示例中我们，机器人每移动一步休息500ms，加入我们想让机器人休息时间少一些，就需要手动的修改源码减少其值，这非常的不方便。 在机器人开发中，会有很多参数和设置可以后期需要调整的，如果都放到源码里很难实现动态修改和管理，ROS2为了解决这一问题，提出了参数这一通信机制。 1.参数通信是什么？ 1.1 参数定义 ROS2官方对参数的定义是： A parameter is a configuration value of a node. You can think of parameters as node settings. 参数是节点的一个配置值，你可以任务参数是一个节点的设置 ROS2的参数就是节点的设置，和我们上面提出的需求不谋而合，有了参数我们就可以实现动态的改变李四写小说的速度了 1.2 参数组成成分 ROS2参数是由键值对组成的，此话怎讲？键值对指的是就是名字和数值，比方说 名字：李四写小说周期，值：5s 名字：显示器亮度,值：60% 名字的数据类型不多说肯定是字符串了，值的数据类型呢？我们这里用到的是5是整型数据，显然只有一个整型是不够用的，ROS2支持的参数值的类型如下： bool 和bool[]，布尔类型用来表示开关，比如我们可以控制雷达控制节点，开始扫描和停止扫描。 int64 和int64[]，整形表示一个数字，含义可以自己来定义，这里我们可以用来表示李四节点写小说的周期值 float64 和float64[]，浮点型，可以表示小数类型的参数值 string 和string[]，字符串，可以用来表示雷达控制节点中真实雷达的ip地址 byte[]，字节数组，这个可以用来表示图片，点云数据等信息 2.体验参数 我们使用乌龟模拟器来体验一下参数，同时讲解一下常用的参数的命令行工具。 2.1 运行小乌龟模拟器节点和小乌龟控制节点 打开终端 ros2 run turtlesim turtlesim_node 再打开一个终端 ros2 run turtlesim turtle_teleop_key 可以看到下面的蓝蓝的模拟器 2.2 查看节点有哪些参数（设置） 我们可以使用下面的指令来查看所有节点的参数列表，打开一个终端，运行下面的指令 ros2 param list 写代码为什么要做到见名知意?我们看到乌龟模拟器的四个参数，background背景bgr指的是blue、green、red。简而言之就是背景颜色。那这几个参数应该可以控制乌龟模拟器的背景颜色。 最后一个use_sim_time是每个节点都带的，后面写篇文章稍微讲讲。 如果看不懂，还可以有一个方法详细查看一个参数的信息。 ros2 param describe 比如： ros2 param describe /turtlesim background_b 这里就可以详细的看到参数的名字，参数的描述，参数的类型，还有对参数的约束，最大值最小值等。 2.3 查看参数值 参数的组成由名字和值（键值组成），名字可以通过param list获取，值该使用指令获取呢？ 下面这个命令行工具可以帮助我们获取参数的值 ros2 param get /turtlesim background_b 运行一下，你会发现结果是255，蓝色进度条打满，再看看r红色和g绿色。 分别是255,86,69 2.4 设置参数 找到了参数和值，接着我们来改变一下乌龟模拟器的颜色。 打开精心准备的在线工具：https://fishros.com/tools/pickr 选取一个自己喜欢的颜色，这里就选绿色，因为乌龟模拟器换成绿色的应该很奇怪。 可以看到当前的这个颜色,r为44，g为156，b为10，接着我们可以使用下面的指令来设置参数的值。 ros2 param set 我们依次修改参数值： ros2 param set /turtlesim background_r 44 ros2 param set /turtlesim background_g 156 ros2 param set /turtlesim background_b 10 接着你可以看到这样的颜色的乌龟模拟器（绿的令人发慌） 需要留意的是，我们修改的背景数据并没有被存储，只是临时修改。重新启动节点乌龟模拟器依然还是原来的蓝色，不是我们想要的绿色的。 2.5 把参数存起来 把参数存起来其实就相当去把当前的参数值拍一张快照，然后保存下来，后面可以用于恢复参数到当前的数值。 可以使用下面的命令进行操作： ros2 param dump 2.5.1 给乌龟模拟器参数拍照 比如我们要保存乌龟模拟器的节点数据，可以采用下面的指令; ros2 param dump /turtlesim 文件被保存成了yaml格式，用cat指令看一看 cat ./turtlesim.yaml 2.5.2 恢复参数值 我们Ctrl+C关闭乌龟模拟器，然后再重新运行。 ros2 run turtlesim turtlesim_node 可以看到模拟器又变成了蓝色了，接着通过param的load的方法把参数值恢复成我们之前存储的。 ros2 param load /turtlesim ./turtlesim.yaml 几乎是瞬间，乌龟模拟器又被我们搞绿了 2.5.3 启动节点时加载参数快照 有什么办法一开始就让乌龟模拟器变成绿色？答案有的。 ros2 的run 指令支持下面这种骚操作。 ros2 run --ros-args --params-file 关闭我们的乌龟模拟器，使用下面的指令重新运行 ros2 run turtlesim turtlesim_node --ros-args --params-file ./turtlesim.yaml 可以看到一上来就时绿了的模拟器。 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/002-param-rclcpp.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/002-param-rclcpp.html","title":"param-rclcpp","keywords":"","body":"datetime:2023/09/18 10:18 author:nzb 该项目来源于大佬的动手学ROS2 2.参数之RCLCPP实现 上节我们通过参数控制了小乌龟模拟器的背景色，但是我们并不知道小乌龟模拟器是如何接收到参数并将其应用的，本节我们就学习使用ROS2的RCLCPP中参数相关的API实现对ROS2打印的日志级别控制。 ROS2将日志分为五个级别，在RCLCPP中通过不同的宏可以实现不同日志级别日志的打印，例程如下： RCLCPP_DEBUG(this->get_logger(), \"我是DEBUG级别的日志，我被打印出来了!\"); RCLCPP_INFO(this->get_logger(), \"我是INFO级别的日志，我被打印出来了!\"); RCLCPP_WARN(this->get_logger(), \"我是WARN级别的日志，我被打印出来了!\"); RCLCPP_ERROR(this->get_logger(), \"我是ERROR级别的日志，我被打印出来了!\"); RCLCPP_FATAL(this->get_logger(), \"我是FATAL级别的日志，我被打印出来了!\"); 有时候日志太多，会让人眼花缭乱找不到重要信息，所以我们需要对日志的级别进行过滤，比如只看INFO以上级别的，ROS2中可以通过已有的API设置日志的级别，RCLCPP中API如下： this->get_logger().set_level(log_level); 1.创建功能包和节点 我们创建一个功能包和测试节点，声明参数并实现动态修改打印的日志级别功能。 mkdir -p chapt4/chapt4_ws/ ros2 pkg create example_parameters_rclcpp --build-type ament_cmake --dependencies rclcpp --destination-directory src --node-name parameters_basic --maintainer-name \"fishros\" --maintainer-email \"fishros@foxmail.com\" parameters_basic.cpp #include #include \"rclcpp/rclcpp.hpp\" class ParametersBasicNode : public rclcpp::Node { public: explicit ParametersBasicNode(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); } private: }; int main(int argc, char** argv) { rclcpp::init(argc, argv); /*创建对应节点的共享指针对象*/ auto node = std::make_shared(\"parameters_basic\"); /* 运行节点，并检测退出信号*/ rclcpp::spin(node); rclcpp::shutdown(); return 0; } 构建测试 colcon build --packages-select example_parameters_rclcpp source install/setup.bash ros2 run example_parameters_rclcpp parameters_basic 2.RCLCPP参数API 在RCLCPP的API中，关于参数相关的函数比较多些，但都是围绕 参数获取 、 参数设置 、 参数描述 、 列出参数 、 添加 和 移除 参数回调事件。 rclcpp: rclcpp: ROS Client Library for C++ 3.使用参数控制节点日志级别 #include #include \"rclcpp/rclcpp.hpp\" /* # declare_parameter 声明和初始化一个参数 # describe_parameter(name) 通过参数名字获取参数的描述 # get_parameter 通过参数名字获取一个参数 # set_parameter 设置参数的值 */ class ParametersBasicNode : public rclcpp::Node { public: // 构造函数,有一个参数为节点名称 explicit ParametersBasicNode(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); this->declare_parameter(\"rcl_log_level\", 0); /*声明参数*/ this->get_parameter(\"rcl_log_level\", log_level); /*获取参数*/ /*设置日志级别*/ this->get_logger().set_level((rclcpp::Logger::Level)log_level); using namespace std::literals::chrono_literals; timer_ = this->create_wall_timer( 500ms, std::bind(&ParametersBasicNode::timer_callback, this)); } private: int log_level; rclcpp::TimerBase::SharedPtr timer_; void timer_callback() { this->get_parameter(\"rcl_log_level\", log_level); /*获取参数*/ /*设置日志级别*/ this->get_logger().set_level((rclcpp::Logger::Level)log_level); std::coutget_logger(), \"我是DEBUG级别的日志，我被打印出来了!\"); RCLCPP_INFO(this->get_logger(), \"我是INFO级别的日志，我被打印出来了!\"); RCLCPP_WARN(this->get_logger(), \"我是WARN级别的日志，我被打印出来了!\"); RCLCPP_ERROR(this->get_logger(), \"我是ERROR级别的日志，我被打印出来了!\"); RCLCPP_FATAL(this->get_logger(), \"我是FATAL级别的日志，我被打印出来了!\"); } }; int main(int argc, char** argv) { rclcpp::init(argc, argv); /*创建对应节点的共享指针对象*/ auto node = std::make_shared(\"parameters_basic\"); /* 运行节点，并检测退出信号*/ rclcpp::spin(node); rclcpp::shutdown(); return 0; } 代码解析 这里我们使用了三个参数相关的函数和一个设置节点日志级别的函数 declare_parameter，参数有两个参数名和参数值。 get_parameter，参数有两个，参数名和放入结果的变量。 设置日志级别 set_level，设置日志级别，ROS2的日志级别定义在文件/opt/ros/humble/include/rcutils/rcutils/logging.h的167-175行。 /// The severity levels of log messages / loggers. enum RCUTILS_LOG_SEVERITY { RCUTILS_LOG_SEVERITY_UNSET = 0, /// 4.编译测试 colcon build --packages-select example_parameters_rclcpp source install/setup.bash ros2 run example_parameters_rclcpp parameters_basic 运行后你会发现DEBUG级别的日志并没有被打印出来，原因在于我们将节点的日志级别设置为了0，0对应的日志级别为RCUTILS_LOG_SEVERITY_UNSET即未设置使用默认级别，节点默认的日志级别就是INFO级别 的，所以只能打印INFO以上的日志信息。 运行节点的时候可以指定参数的值，我们尝试将log_level的值改成10即DEBUG级别。 ros2 run example_parameters_rclcpp parameters_basic --ros-args -p rcl_log_level:=10 再试试其他级别-FATAL 除了在节点运行前通过CLI传递参数，在运动的过程中也可以动态的修改参数 #查看参数列表 ros2 param list #设置参数级别 ros2 param set /parameters_basic rcl_log_level 10 5.总结 上面我们通过参数实现了动态控制节点日志级别的功能，其实像这样的功能ROS2早已为我们准备好了，在运行任意节点时候可以通过CLI传递日志级别配置。 ros2 run package-name node-name --ros-args --log-level debug 除了命令行设置参数和查看日志，通过rqt也可以可视化设置和查看 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/003-param-rclpy.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/003-param-rclpy.html","title":"param-rclpy","keywords":"","body":"datetime:2023/09/18 10:18 author:nzb 该项目来源于大佬的动手学ROS2 3.参数之RCLPY实现 上节利用RCLCPP的API实现了参数相关的基础操作（声明、获取），本节我们采用RCLPY的API来尝试实现相同的功能。 1.创建功能包和节点 cd chapt4/chapt4_ws/ ros2 pkg create example_parameters_rclpy --build-type ament_python --dependencies rclpy --destination-directory src --node-name parameters_basic --maintainer-name \"fishros\" --maintainer-email \"fishros@foxmail.com\" parameters_basic.py #!/usr/bin/env python3 import rclpy from rclpy.node import Node class ParametersBasicNode(Node): \"\"\" 创建一个ParametersBasicNode节点，并在初始化时输出一个话 \"\"\" def __init__(self,name): super().__init__(name) self.get_logger().info(f\"节点已启动：{name}!\") def main(args=None): rclpy.init(args=args) # 初始化rclpy node = ParametersBasicNode(\"parameters_basic\") # 新建一个节点 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 2.RCLPY参数API https://docs.ros2.org/latest/api/rclpy/api/node.html 3.使用参数控制节点日志级别 class ParametersBasicNode(Node): \"\"\" 创建一个ParametersBasicNode节点，并在初始化时输出一个话 \"\"\" def __init__(self, name): super().__init__(name) self.get_logger().info(f\"节点已启动：{name}!\") # 声明参数 self.declare_parameter('rcl_log_level', 0) # 获取参数 log_level = self.get_parameter(\"rcl_log_level\").value # 设置参数 self.get_logger().set_level(log_level) # 定时修改 self.timer = self.create_timer(0.5, self.timer_callback) def timer_callback(self): \"\"\"定时器回调函数\"\"\" # 获取参数 log_level = self.get_parameter(\"rcl_log_level\").value # 设置参数 self.get_logger().set_level(log_level) print( f\"========================{log_level}=============================\") self.get_logger().debug(\"我是DEBUG级别的日志，我被打印出来了!\") self.get_logger().info(\"我是INFO级别的日志，我被打印出来了!\") self.get_logger().warn(\"我是WARN级别的日志，我被打印出来了!\") self.get_logger().error(\"我是ERROR级别的日志，我被打印出来了!\") self.get_logger().fatal(\"我是FATAL级别的日志，我被打印出来了!\") 4.编译测试 colcon build --packages-select example_parameters_rclpy source install/setup.bash ros2 run example_parameters_rclpy parameters_basic 指定参数值测试 ros2 run example_parameters_rclpy parameters_basic --ros-args -p rcl_log_level:=10 动态设置参数测试 ros2 param list ros2 param set /parameters_basic rcl_log_level 40 5.总结 虽然实现了动态的设置参数，但还有些不够完美，参数的值被外界改变，我们的节点并没有收到任何通知，本节实现的动态改变是通过一个定时器不断的轮询获取参数值实现的，那有没有什么办法可以接收到参数改变的通知呢？答案在进阶篇。 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/004-action.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/004-action.html","title":"action","keywords":"","body":"datetime:2023/09/18 10:18 author:nzb 该项目来源于大佬的动手学ROS2 4.动作（Action）通信与自定义接口 通过前面章节的学习，你已经掌握了ROS2中四大通信利器中话题、服务、参数这三个，还差最后一个就能将ROS2的通信机制全部打包带回家了，这节课就带你一起认识一下Action，并带你动手体验一下Action通信。 1.Action背景 前面章节学习了话题、服务、参数。 话题适用于节点间单向的频繁的数据传输，服务则适用于节点间双向的数据传递，而参数则用于动态调整节点的设置，动作Action和他们三个有什么不同之处呢？ 如果这些问题体现在机器人上，可能是这样子的。我们通过服务服务发送一个目标点给机器人，让机器人移动到该点： 你不知道机器人有没有处理移动到目标点的请求（不能确认服务端接收并处理目标） 假设机器人收到了请求，你不知道机器人此时的位置和距离目标点的距离（没有反馈） 假设机器人移动一半，你想让机器人停下来，也没有办法通知机器人 上面的场景在机器人控制当中经常出现，比如控制导航程序，控制机械臂运动，控制小乌龟旋转等，很显然单个话题和服务不能满足我们的使用，因此ROS2针对控制这一场景，基于原有的话题和服务，设计了动作（Action）这一通信方式来解决这一问题。 2.Action的组成部分 知道了Action的出现原因，接着说说Action的三大组成部分目标、反馈和结果。 目标：即Action客户端告诉服务端要做什么，服务端针对该目标要有响应。解决了不能确认服务端接收并处理目标问题 反馈：即Action服务端告诉客户端此时做的进度如何（类似与工作汇报）。解决执行过程中没有反馈问题 结果：即Action服务端最终告诉客户端其执行结果，结果最后返回，用于表示任务最终执行情况。 参数是由服务构建出来了，而Action是由话题和服务共同构建出来的（一个Action = 三个服务+两个话题） 三个服务分别是： 1.目标传递服务 2.结果传递服务 3.取消执行服务 两个话题： 1.反馈话题（服务端发布，客户端订阅） 2.状态话题（服务端发布，客户端订阅） 3.感受Action 带着前面对Action的了解，接着我们一起来了直观的通过小乌龟的案例来感受一下Action的魅力。 3.1 启动乌龟模拟器和键盘控制节点 乌龟模拟器 ros2 run turtlesim turtlesim_node 键盘控制节点 ros2 run turtlesim turtle_teleop_key 打开键盘控制节点后，你应该窗口中可以看到下面的提示 Use arrow keys to move the turtle. Use G|B|V|C|D|E|R|T keys to rotate to absolute orientations. 'F' to cancel a rotation. 有请翻译官（其实用Deppl翻译的） 使用方向键移动乌龟。 用G、B、V、C、D、E、R、T键旋转到绝对方向。'F'可以取消旋转。 这段提示什么意思呢？其实就是字面的意思， 小乌龟键盘控制节点，提供两种可选的控制方式。 方向键，通过话题(Topic)控制小乌龟的（直接发送移动话题） 绝对旋转，则是采用动作(Action）来控制的小乌龟 3.2 使用绝对旋转(Action)控制小乌龟 使用绝对旋转控制小乌龟即使用Action来控制小乌龟。 在小乌龟的遥控窗口我们使用键盘上的F按键周围的按键来尝试运行控制下小乌龟的方向，你会看到小乌龟根据我们所按下按键所在的方向来在原地进行旋转。 同时在旋转的过程中，我们可以使用F按键，来取消小乌龟的运动。 4. Action的CLI工具 Action的命令行工具一共有三个,下面我们一一介绍。 4.1 action list 该命令用于获取目前系统中的action列表。 ros2 action list 你将看到 /turtle1/rotate_absolute 如果在list后加入-t参数，即可看到action的类型 /turtle1/rotate_absolute [turtlesim/action/RotateAbsolute] 知道了接口类型之后，可以使用接口相关CLI指令获取接口的信息 ros2 interface show turtlesim/action/RotateAbsolute 结果 # The desired heading in radians float32 theta --- # The angular displacement in radians to the starting position float32 delta --- # The remaining rotation in radians float32 remaining 4.2 action info 查看action信息，在终端中输入下面的指令。 ros2 action info /turtle1/rotate_absolute 你将看到,action客户端和服务段的数量以及名字。 Action: /turtle1/rotate_absolute Action clients: 1 /teleop_turtle Action servers: 1 /turtlesim 4.3 action send_goal 该指令用于发送actin请求到服务端，我们可以模拟下，让小乌龟转到我们定义的角度。 我们只需要把goal发给服务端即可，根据goal的定义，我们可以看到goal是由一个浮点类型的theta组成的，我们把theta发给服务端。 发送弧度制1.6给小乌龟 ros2 action send_goal /turtle1/rotate_absolute turtlesim/action/RotateAbsolute \"{theta: 1.6}\" 结果 Waiting for an action server to become available... Sending goal: theta: 1.6 Goal accepted with ID: b215ad060899444793229171e76481c7 Result: delta: -1.5840003490447998 Goal finished with status: SUCCEEDED 我们可以看到goal和result，但是没有看到feedback，这里我们需要加一个参数 --feedback 加上这个参数我们再发送一次。 ros2 action send_goal /turtle1/rotate_absolute turtlesim/action/RotateAbsolute \"{theta: 1.5}\" --feedback 可以看到了，这次的日志中多出了很多实时的反馈，反馈的数值是小乌龟当前的角度与我们给定的目标角度之间的差值，可以看到一直在变小。 Waiting for an action server to become available... Sending goal: theta: 1.5 Feedback: remaining: -0.0840003490447998 Goal accepted with ID: b368de0ed1a54e00890f1b078f4671c8 Feedback: remaining: -0.06800031661987305 Feedback: remaining: -0.05200028419494629 Feedback: remaining: -0.03600025177001953 Feedback: remaining: -0.020000219345092773 Feedback: remaining: -0.004000186920166016 Result: delta: 0.08000016212463379 Goal finished with status: SUCCEEDED 5.自定义通信接口 我们接下来以控制机器人移动到点为例子，来学习Action通信。因为这个场景是我们自己定义的，ROS2并没有拿来就用的接口，所以我们需要自定义Action通信接口。 5.1 创建接口功能包 创建功能包 cd chapt4_ws/ ros2 pkg create robot_control_interfaces --build-type ament_cmake --destination-directory src --maintainer-name \"fishros\" --maintainer-email \"fishros@foxmail.com\" 创建接口文件 mkdir -p src/robot_control_interfaces/action touch src/robot_control_interfaces/action/MoveRobot.action packages.xml rosidl_default_generators rosidl_interface_packages CMakeLists.txt find_package(ament_cmake REQUIRED) find_package(rosidl_default_generators REQUIRED) rosidl_generate_interfaces(${PROJECT_NAME} \"action/MoveRobot.action\" ) 5.2 编写接口 # Goal: 要移动的距离 float32 distance --- # Result: 最终的位置 float32 pose --- # Feedback: 中间反馈的位置和状态 float32 pose uint32 status uint32 STATUS_MOVEING = 3 uint32 STATUS_STOP = 4 5.3 编译生成接口 colcon build --packages-select robot_control_interfaces 编译成功后，即可看到C++头文件和Python相关文件 C++ Action消息头文件目录install/robot_control_interfaces/include Python Action消息文件目录install/robot_control_interfaces/local/lib/python3.10 6.总结 本节我们学习了Action并手动创建了Action的接口，下一节将带你一起使用接口完成任务。 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/005-action-rclcpp.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/005-action-rclcpp.html","title":"action-rclcpp","keywords":"","body":"datetime:2023/09/18 10:18 author:nzb 该项目来源于大佬的动手学ROS2 5.动作之CPP实现 上一节介绍了Action通信并一起自定义了一个接口，本节我们尝试使用接口来利用动作通信控制机器人。 1.创建功能包和节点 1.1 创建功能包 创建example_action_rclcpp功能包，添加robot_control_interfaces、rclcpp_action、rclcpp三个依赖，自动创建action_robot_01 节点，并手动创建action_control_01.cpp节点。 cd chapt4_ws/ ros2 pkg create example_action_rclcpp --build-type ament_cmake --dependencies rclcpp rclcpp_action robot_control_interfaces --destination-directory src --node-name action_robot_01 --maintainer-name \"fishros\" --maintainer-email \"fishros@foxmail.com\" touch src/example_action_rclcpp/src/action_control_01.cpp 接着我们创建Robot类的头文件和CPP文件。 touch src/example_action_rclcpp/include/example_action_rclcpp/robot.h touch src/example_action_rclcpp/src/robot.cpp 创建完成后目录结构 . ├── CMakeLists.txt ├── include │ └── example_action_rclcpp │ └── robot.h ├── package.xml └── src ├── action_control_01.cpp ├── action_robot_01.cpp └── robot.cpp 3 directories, 6 files 1.2 robot.h /* copyright */ #ifndef EXAMPLE_ACTIONI_RCLCPP_ROBOT_H_ #define EXAMPLE_ACTIONI_RCLCPP_ROBOT_H_ #include \"rclcpp/rclcpp.hpp\" #include \"robot_control_interfaces/action/move_robot.hpp\" class Robot { public: Robot() = default; ~Robot() = default; private: }; #endif // EXAMPLE_ACTIONI_RCLCPP_ROBOT_H_ 1.3 robot.cpp 暂时为空，第二部分编写 #include \"example_action_rclcpp/robot.h\" 1.4 action_robot_01.cpp #include \"example_action_rclcpp/robot.h\" #include \"rclcpp/rclcpp.hpp\" #include \"rclcpp_action/rclcpp_action.hpp\" #include \"robot_control_interfaces/action/move_robot.hpp\" // 创建一个ActionServer类 class ActionRobot01 : public rclcpp::Node { public: explicit ActionRobot01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); } }; int main(int argc, char** argv) { rclcpp::init(argc, argv); auto action_server = std::make_shared(\"action_robot_01\"); rclcpp::spin(action_server); rclcpp::shutdown(); return 0; } 1.5 action_control_01.cpp #include \"rclcpp/rclcpp.hpp\" #include \"rclcpp_action/rclcpp_action.hpp\" #include \"robot_control_interfaces/action/move_robot.hpp\" class ActionControl01 : public rclcpp::Node { public: explicit ActionControl01(std::string name): Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); } }; // class ActionControl01 int main(int argc, char** argv) { rclcpp::init(argc, argv); auto action_client = std::make_shared(\"action_robot_cpp\"); rclcpp::spin(action_client); rclcpp::shutdown(); return 0; } 1.6 CMakeList.txt find_package(ament_cmake REQUIRED) find_package(rclcpp REQUIRED) find_package(robot_control_interfaces REQUIRED) find_package(example_interfaces REQUIRED) find_package(rclcpp_action REQUIRED) # action_robot节点 add_executable(action_robot_01 src/robot.cpp src/action_robot_01.cpp ) target_include_directories(action_robot_01 PUBLIC $ $) target_compile_features(action_robot_01 PUBLIC c_std_99 cxx_std_17) # Require C99 and C++17 ament_target_dependencies( action_robot_01 \"rclcpp\" \"rclcpp_action\" \"robot_control_interfaces\" \"example_interfaces\" ) install(TARGETS action_robot_01 DESTINATION lib/${PROJECT_NAME}) # action_control节点 add_executable(action_control_01 src/action_control_01.cpp ) target_include_directories(action_control_01 PUBLIC $ $) target_compile_features(action_control_01 PUBLIC c_std_99 cxx_std_17) # Require C99 and C++17 ament_target_dependencies( action_control_01 \"rclcpp\" \"rclcpp_action\" \"robot_control_interfaces\" \"example_interfaces\" ) install(TARGETS action_control_01 DESTINATION lib/${PROJECT_NAME}) 2.编写机器人类 机器人类主要负责移动机器人和提供当前机器人的状态，我们设计几个函数来实现该功能。 2.1 robot.h #ifndef EXAMPLE_ACTIONI_RCLCPP_ROBOT_H_ #define EXAMPLE_ACTIONI_RCLCPP_ROBOT_H_ #include \"rclcpp/rclcpp.hpp\" #include \"robot_control_interfaces/action/move_robot.hpp\" class Robot { public: using MoveRobot = robot_control_interfaces::action::MoveRobot; Robot() = default; ~Robot() = default; float move_step(); /*移动一小步，请间隔500ms调用一次*/ bool set_goal(float distance); /*移动一段距离*/ float get_current_pose(); int get_status(); bool close_goal(); /*是否接近目标*/ void stop_move(); /*停止移动*/ private: float current_pose_ = 0.0; /*声明当前位置*/ float target_pose_ = 0.0; /*目标距离*/ float move_distance_ = 0.0; /*目标距离*/ std::atomic cancel_flag_{false}; /*取消标志*/ int status_ = MoveRobot::Feedback::STATUS_STOP; }; #endif // EXAMPLE_ACTIONI_RCLCPP_ROBOT_H_ 2.2 robot.cpp #include \"example_action_rclcpp/robot.h\" /*移动一小步，请间隔500ms调用一次*/ float Robot::move_step() { int direct = move_distance_ / fabs(move_distance_); float step = direct * fabs(target_pose_ - current_pose_) * 0.1; /* 每一步移动当前到目标距离的1/10*/ current_pose_ += step; std::cout 3.编写机器人节点 class ActionRobot01 : public rclcpp::Node { public: using MoveRobot = robot_control_interfaces::action::MoveRobot; using GoalHandleMoveRobot = rclcpp_action::ServerGoalHandle; explicit ActionRobot01(std::string name) : Node(name) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); using namespace std::placeholders; // NOLINT this->action_server_ = rclcpp_action::create_server( this, \"move_robot\", std::bind(&ActionRobot01::handle_goal, this, _1, _2), std::bind(&ActionRobot01::handle_cancel, this, _1), std::bind(&ActionRobot01::handle_accepted, this, _1)); } private: Robot robot; rclcpp_action::Server::SharedPtr action_server_; rclcpp_action::GoalResponse handle_goal( const rclcpp_action::GoalUUID& uuid, std::shared_ptr goal) { RCLCPP_INFO(this->get_logger(), \"Received goal request with distance %f\", goal->distance); (void)uuid; if (fabs(goal->distance > 100)) { RCLCPP_WARN(this->get_logger(), \"目标距离太远了，本机器人表示拒绝！\"); return rclcpp_action::GoalResponse::REJECT; } RCLCPP_INFO(this->get_logger(), \"目标距离%f我可以走到，本机器人接受，准备出发！\", goal->distance); return rclcpp_action::GoalResponse::ACCEPT_AND_EXECUTE; } rclcpp_action::CancelResponse handle_cancel( const std::shared_ptr goal_handle) { RCLCPP_INFO(this->get_logger(), \"Received request to cancel goal\"); (void)goal_handle; robot.stop_move(); /*认可取消执行，让机器人停下来*/ return rclcpp_action::CancelResponse::ACCEPT; } void execute_move(const std::shared_ptr goal_handle) { const auto goal = goal_handle->get_goal(); RCLCPP_INFO(this->get_logger(), \"开始执行移动 %f 。。。\", goal->distance); auto result = std::make_shared(); rclcpp::Rate rate = rclcpp::Rate(2); robot.set_goal(goal->distance); while (rclcpp::ok() && !robot.close_goal()) { robot.move_step(); auto feedback = std::make_shared(); feedback->pose = robot.get_current_pose(); feedback->status = robot.get_status(); goal_handle->publish_feedback(feedback); /*检测任务是否被取消*/ if (goal_handle->is_canceling()) { result->pose = robot.get_current_pose(); goal_handle->canceled(result); RCLCPP_INFO(this->get_logger(), \"Goal Canceled\"); return; } RCLCPP_INFO(this->get_logger(), \"Publish Feedback\"); /*Publish feedback*/ rate.sleep(); } result->pose = robot.get_current_pose(); goal_handle->succeed(result); RCLCPP_INFO(this->get_logger(), \"Goal Succeeded\"); } void handle_accepted(const std::shared_ptr goal_handle) { using std::placeholders::_1; std::thread{std::bind(&ActionRobot01::execute_move, this, _1), goal_handle} .detach(); } }; 代码解析 上面的代码信息量有些大，但都是围绕着Action展开的，带你一步步分解。 首先找到创建Action的API：https://docs.ros2.org/latest/api/rclcpp_action/ Action使用了三个回调函数，分别用于处理收到目标、收到停止、确认接受执行。 handle_goal，收到目标，反馈是否可以执行该目标，可以则返回ACCEPT_AND_EXECUTE,不可以则返回REJECT handle_cancel，收到取消运行请求，可以则返回ACCEPT，不可以返回REJECT。 handle_accepted，处理接受请求，当handle_goal中对移动请求ACCEPT后则进入到这里进行执行，这里我们是单独开了个线程进行执行execute_move函数，目的是避免阻塞主线程。 执行函数execute_move，调用机器人，进行一步步的移动，这里我们采用了while循环的形式，不断调用机器人移动并获取机器人的位置，通过feedback进行反馈。同时检测任务是否被取消，如顺利执行完成则反馈最终结果。 代码中我们还用到了Rate函数来精准控制循环的周期，让其保持为2HZ，关于Rate等流程控制的工具，放到进阶篇来讲解。 4.编写控制节点 先看API：rclcpp_action: rclcpp_action Namespace Reference (ros2.org) 接着看代码 class ActionControl01 : public rclcpp::Node { public: using MoveRobot = robot_control_interfaces::action::MoveRobot; using GoalHandleMoveRobot = rclcpp_action::ClientGoalHandle; explicit ActionControl01( std::string name, const rclcpp::NodeOptions& node_options = rclcpp::NodeOptions()) : Node(name, node_options) { RCLCPP_INFO(this->get_logger(), \"节点已启动：%s.\", name.c_str()); this->client_ptr_ = rclcpp_action::create_client(this, \"move_robot\"); this->timer_ = this->create_wall_timer(std::chrono::milliseconds(500), std::bind(&ActionControl01::send_goal, this)); } void send_goal() { using namespace std::placeholders; this->timer_->cancel(); if (!this->client_ptr_->wait_for_action_server(std::chrono::seconds(10))) { RCLCPP_ERROR(this->get_logger(), \"Action server not available after waiting\"); rclcpp::shutdown(); return; } auto goal_msg = MoveRobot::Goal(); goal_msg.distance = 10; RCLCPP_INFO(this->get_logger(), \"Sending goal\"); auto send_goal_options = rclcpp_action::Client::SendGoalOptions(); send_goal_options.goal_response_callback = std::bind(&ActionControl01::goal_response_callback, this, _1); send_goal_options.feedback_callback = std::bind(&ActionControl01::feedback_callback, this, _1, _2); send_goal_options.result_callback = std::bind(&ActionControl01::result_callback, this, _1); this->client_ptr_->async_send_goal(goal_msg, send_goal_options); } private: rclcpp_action::Client::SharedPtr client_ptr_; rclcpp::TimerBase::SharedPtr timer_; void goal_response_callback(GoalHandleMoveRobot::SharedPtr goal_handle) { if (!goal_handle) { RCLCPP_ERROR(this->get_logger(), \"Goal was rejected by server\"); } else { RCLCPP_INFO(this->get_logger(), \"Goal accepted by server, waiting for result\"); } } void feedback_callback( GoalHandleMoveRobot::SharedPtr, const std::shared_ptr feedback) { RCLCPP_INFO(this->get_logger(), \"Feedback current pose:%f\", feedback->pose); } void result_callback(const GoalHandleMoveRobot::WrappedResult& result) { switch (result.code) { case rclcpp_action::ResultCode::SUCCEEDED: break; case rclcpp_action::ResultCode::ABORTED: RCLCPP_ERROR(this->get_logger(), \"Goal was aborted\"); return; case rclcpp_action::ResultCode::CANCELED: RCLCPP_ERROR(this->get_logger(), \"Goal was canceled\"); return; default: RCLCPP_ERROR(this->get_logger(), \"Unknown result code\"); return; } RCLCPP_INFO(this->get_logger(), \"Result received: %f\", result.result->pose); // rclcpp::shutdown(); } }; // class ActionControl01 代码解析 创建客户端简单，发送请求的时候可以指定三个回调函数： goal_response_callback，目标的响应回调函数。 feedback_callback，执行过程中进度反馈接收回调函数。 result_callback，最终结果接收的回调函数。 这里利用了定时器完成了定时请求的功能，请求一次后就立马使用timer_->cancel();取消掉了这个定时器，如此就实现了节点启动后定时发一次请求的功能。 5.编译测试 一个终端，运行机器人节点 cd chapt4_ws/ colcon build --packages-up-to example_action_rclcpp source install/setup.bash ros2 run example_action_rclcpp action_robot_01 新终端，运行控制节点 source install/setup.bash ros2 run example_action_rclcpp action_control_01 执行完成 6.总结与测试 上面只做了简单的测试，你可以尝试再编写一个定时器，在节点启动的第5s时发送取消执行请求，看看是否可以让机器人停下来。 本节我们利用rclcpp_action的API实现了Action通信的测试，Action在后续的机器人开发中并没那么常用，但是其思想比较重要，应该掌握。 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/006-action-rclpy.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/006-action-rclpy.html","title":"action-rclpy","keywords":"","body":"datetime:2023/09/18 10:18 author:nzb 该项目来源于大佬的动手学ROS2 6.动作之RCLPY实现 上节我们再C++中结合RCLCPP和RCLCPPACTION库实现了Action通信，本节我们利用RCLPY在Python中实现相同的功能。 1.创建功能包和节点 1.1 创建功能包 cd chapt4_ws/ ros2 pkg create example_action_rclpy --build-type ament_python --dependencies rclpy robot_control_interfaces --destination-directory src --node-name action_robot_02 --maintainer-name \"fishros\" --maintainer-email \"fishros@foxmail.com\" # 手动再创建action_control_02节点文件 touch src/example_action_rclpy/example_action_rclpy/action_control_02.py #手动创建机器人类robot.py touch src/example_action_rclpy/example_action_rclpy/robot.py 1.2 robot.py from robot_control_interfaces.action import MoveRobot import math class Robot(): \"\"\"机器人类，模拟一个机器人\"\"\" def __init__(self) -> None: pass def get_status(self): \"\"\"获取状态\"\"\" pass def get_current_pose(self): \"\"\"获取当前位置\"\"\" pass def close_goal(self): \"\"\"接近目标\"\"\" pass def stop_move(self): \"\"\"停止移动\"\"\" pass def move_step(self): \"\"\"移动一小步\"\"\" pass def set_goal(self, distance): \"\"\"设置目标\"\"\" pass 1.3 action_robot_02.py #!/usr/bin/env python3 import time # 导入rclpy相关库 import rclpy from rclpy.node import Node from rclpy.action import ActionServer from rclpy.action.server import ServerGoalHandle # 导入接口 from robot_control_interfaces.action import MoveRobot # 导入机器人类 from example_action_rclpy.robot import Robot #from rclpy.executors import MultiThreadedExecutor #from rclpy.callback_groups import MutuallyExclusiveCallbackGroup class ActionRobot02(Node): \"\"\"机器人端Action服务\"\"\" def __init__(self,name): super().__init__(name) self.get_logger().info(f\"节点已启动：{name}!\") def main(args=None): \"\"\"主函数\"\"\" rclpy.init(args=args) action_robot_02 = ActionRobot02(\"action_robot_02\") # 采用多线程执行器解决rate死锁问题 # executor = MultiThreadedExecutor() # executor.add_node(action_robot_02) # executor.spin() rclpy.spin(action_robot_02) rclpy.shutdown() 1.4 action_control_02.py import rclpy from rclpy.action import ActionClient from rclpy.node import Node # 导入Action接口 from robot_control_interfaces.action import MoveRobot class ActionControl02(Node): \"\"\"Action客户端\"\"\" def __init__(self,name): super().__init__(name) self.get_logger().info(f\"节点已启动：{name}!\") def main(args=None): \"\"\"主函数\"\"\" rclpy.init(args=args) action_robot_02 = ActionControl02(\"action_control_02\") rclpy.spin(action_robot_02) rclpy.shutdown() 1.5 setup.py entry_points={ 'console_scripts': [ 'action_robot_02 = example_action_rclpy.action_robot_02:main', 'action_control_02 = example_action_rclpy.action_control_02:main' ], }, 接着就可以自行编译测试是否可以将节点运行起来了 2.编写机器人类 class Robot(): \"\"\"机器人类，模拟一个机器人\"\"\" def __init__(self) -> None: self.current_pose_ = 0.0 self.target_pose_ = 0.0 self.move_distance_ = 0.0 self.status_ = MoveRobot.Feedback def get_status(self): \"\"\"获取状态\"\"\" return self.status_ def get_current_pose(self): \"\"\"获取当前位置\"\"\" return self.current_pose_ def close_goal(self): \"\"\"接近目标\"\"\" return math.fabs(self.target_pose_ - self.current_pose_) 代码不复杂，就不进行解析了 3.编写机器人节点 class ActionRobot02(Node): \"\"\"机器人端Action服务\"\"\" def __init__(self,name): super().__init__(name) self.get_logger().info(f\"节点已启动：{name}!\") self.robot_ = Robot() self.action_server_ = ActionServer( self, MoveRobot, 'move_robot', self.execute_callback # ,callback_group=MutuallyExclusiveCallbackGroup() ) def execute_callback(self, goal_handle: ServerGoalHandle): \"\"\"执行回调函数,若采用默认handle_goal函数则会自动调用\"\"\" self.get_logger().info('执行移动机器人') feedback_msg = MoveRobot.Feedback() self.robot_.set_goal(goal_handle.request.distance) # rate = self.create_rate(2) while rclpy.ok() and not self.robot_.close_goal(): # move self.robot_.move_step() # feedback feedback_msg.pose = self.robot_.get_current_pose() feedback_msg.status = self.robot_.get_status() goal_handle.publish_feedback(feedback_msg) # cancel check if goal_handle.is_cancel_requested: result = MoveRobot.Result() result.pose = self.robot_.get_current_pose() return result # rate.sleep() # Rate会造成死锁，单线程执行器时不能使用 time.sleep(0.5) goal_handle.succeed() result = MoveRobot.Result() result.pose = self.robot_.get_current_pose() return result 真是人生苦短，我用Python，这里代码就变得简单了 只指定了一个回调函数self.execute_callback，原因在于Python这为我们封装好了几个默认的函数。 打开文件/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/action/server.py，查看源码如下 class ActionServer(Waitable): \"\"\"ROS Action server.\"\"\" def __init__( self, node, action_type, action_name, execute_callback, *, callback_group=None, goal_callback=default_goal_callback, handle_accepted_callback=default_handle_accepted_callback, cancel_callback=default_cancel_callback, goal_service_qos_profile=qos_profile_services_default, result_service_qos_profile=qos_profile_services_default, cancel_service_qos_profile=qos_profile_services_default, feedback_pub_qos_profile=QoSProfile(depth=10), status_pub_qos_profile=qos_profile_action_status_default, result_timeout=900 ): \"\"\" Create an ActionServer. :param node: The ROS node to add the action server to. :param action_type: Type of the action. :param action_name: Name of the action. Used as part of the underlying topic and service names. :param execute_callback: Callback function for processing accepted goals. This is called if when :class:`ServerGoalHandle.execute()` is called for a goal handle that is being tracked by this action server. :param callback_group: Callback group to add the action server to. If None, then the node's default callback group is used. :param goal_callback: Callback function for handling new goal requests. :param handle_accepted_callback: Callback function for handling newly accepted goals. Passes an instance of `ServerGoalHandle` as an argument. :param cancel_callback: Callback function for handling cancel requests. :param goal_service_qos_profile: QoS profile for the goal service. :param result_service_qos_profile: QoS profile for the result service. :param cancel_service_qos_profile: QoS profile for the cancel service. :param feedback_pub_qos_profile: QoS profile for the feedback publisher. :param status_pub_qos_profile: QoS profile for the status publisher. :param result_timeout: How long in seconds a result is kept by the server after a goal reaches a terminal state. \"\"\" 刚刚说的的几个默认函数 def default_handle_accepted_callback(goal_handle): \"\"\"Execute the goal.\"\"\" goal_handle.execute() def default_goal_callback(goal_request): \"\"\"Accept all goals.\"\"\" return GoalResponse.ACCEPT def default_cancel_callback(cancel_request): \"\"\"No cancellations.\"\"\" return CancelResponse.REJECT 4.编写控制节点 class ActionControl02(Node): \"\"\"Action客户端\"\"\" def __init__(self, name): super().__init__(name) self.get_logger().info(f\"节点已启动：{name}!\") self.action_client_ = ActionClient(self, MoveRobot, 'move_robot') self.send_goal_timer_ = self.create_timer(1, self.send_goal) def send_goal(self): \"\"\"发送目标\"\"\" self.send_goal_timer_.cancel() goal_msg = MoveRobot.Goal() goal_msg.distance = 5.0 self.action_client_.wait_for_server() self._send_goal_future = self.action_client_.send_goal_async(goal_msg, feedback_callback=self.feedback_callback) self._send_goal_future.add_done_callback(self.goal_response_callback) def goal_response_callback(self, future): \"\"\"收到目标处理结果\"\"\" goal_handle = future.result() if not goal_handle.accepted: self.get_logger().info('Goal rejected :(') return self.get_logger().info('Goal accepted :)') self._get_result_future = goal_handle.get_result_async() self._get_result_future.add_done_callback(self.get_result_callback) def get_result_callback(self, future): \"\"\"获取结果反馈\"\"\" result = future.result().result self.get_logger().info(f'Result: {result.pose}') def feedback_callback(self, feedback_msg): \"\"\"获取回调反馈\"\"\" feedback = feedback_msg.feedback self.get_logger().info(f'Received feedback: {feedback.pose}') 控制节点依然采用三个回调函数实现数据的接收 goal_response_callback，收到目标处理结果。 get_result_callback，获取结果反馈。 feedback_callback，接收过程信息。 5.构建测试 接着我们可以编译进行测试。 cd chapt4_ws/ colcon build --packages-up-to example_action_rclpy # 运行机器人节点 source install/setup.bash ros2 run example_action_rclpy action_robot_02 # 新终端 source install/setup.bash ros2 run example_action_rclpy action_control_02 6.总结 本节我们学习了使用Python编写Action，在设计上Python显得比C++更好用些，但背后的逻辑都是一样的，下一节我们将对ROS2节点通信进行总结。 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/007-通信机制对比总结.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/入门/007-通信机制对比总结.html","title":"通信机制对比总结","keywords":"","body":"datetime:2023/09/18 10:18 author:nzb 该项目来源于大佬的动手学ROS2 7.通信机制对比总结 1.话题 话题（Topic）是一种轻量级的通信方式，用于实现发布-订阅模式，即一个节点发布数据，另一个节点订阅数据。话题是一种单向的通信方式，发布者发布数据后，无法获知数据是否被订阅者成功接收。话题的数据类型可以是ROS中定义的任意消息类型。常见的使用话题实现的场景包括传感器数据的传递、节点间的状态信息交换等。 2.服务 服务是双向的，提供了一种客户端-服务器模式，即客户端向服务器发送请求，服务器响应请求并返回结果。服务可以实现双向通信，并且支持传递任意的ROS消息类型。服务的实现需要定义两个消息类型，一个用于请求，一个用于响应。常见的使用服务实现的场景包括节点之间的命令调用、请求数据等。 3.参数 参数（Parameter）是ROS 2中节点的一种配置机制，它可以用于对节点进行设置。参数可以存储整数、浮点数、布尔值、字符串等基本类型数据，也可以存储ROS消息类型。参数的读写操作可以通过服务实现。在节点启动时，可以通过ROS参数服务器将参数传递给节点，也可以在运行时动态修改参数。常见的使用参数的场景包括节点的配置、调试等。，原理基于服务。 4.动作 动作（Action）是ROS 2中的高级通信机制，它可以实现异步的双向通信，并且支持取消、暂停、恢复等操作。动作通常用于需要执行较长时间的任务，如机器人的导航、物体识别等。与服务不同，动作可以通过话题实时发布执行状态、进度等信息，以便客户端监控执行情况。动作的实现需要定义三个消息类型，一个用于请求，一个用于响应，一个用于反馈。常见的使用动作的场景包括机器人的自主导航、物体抓取等。 5.总结 本节课我们稍微总结了下ROS2的通信机制，下一节课我们将对ROS2的中常用的工具进行介绍，让我们保持好奇心，继续往下学习吧～ "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/进阶/001-ROS参数通信原理介绍.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/进阶/001-ROS参数通信原理介绍.html","title":"ROS参数通信原理介绍","keywords":"","body":"datetime:2023/09/19 14:02 author:nzb 该项目来源于大佬的动手学ROS2 1.ROS参数通信原理介绍 ROS2的参数其实是用服务实现的，是怎么知道的呢？ 随意运行一个节点，你使用下面的指令，就可以看到多出来很多的参数相关的服务。 ros2 service list 比如启动乌龟模拟器 ros2 run turtlesim turtlesim_node 多出来的这些服务就是用于操作这个节点的参数的 /turtlesim/describe_parameters /turtlesim/get_parameter_types /turtlesim/get_parameters /turtlesim/list_parameters /turtlesim/set_parameters /turtlesim/set_parameters_atomically 我们如何使用服务查看参数呢？ 手动调一下服务就行了~ ros2 service call /turtlesim/list_parameters rcl_interfaces/srv/ListParameters \"{prefixes: [],depth: 0}\" 这里可以看到结果里的四个参数 names=['background_b', 'background_g', 'background_r','use_sim_time'] 采用ros2 param list再看看对不对 ros2 param list 是不是长的一样 总结 通过上面的实验告诉我们ROS2的参数操作其实就是通过服务通信方式实现的，获取参数列表，set和get操作就是操作相应的服务 "},"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/进阶/002-生命周期节点.html":{"url":"ROS2/ROS2入门篇/第4章-ROS2通信之参数与动作/进阶/002-生命周期节点.html","title":"生命周期节点","keywords":"","body":"datetime:2023/09/19 14:02 author:nzb 该项目来源于大佬的动手学ROS2 3. 生命周期节点 以前在ROS1中，节点的启动顺序无法被控制，这对整个机器人系统来说是一件非常危险和不可控的事，比如说机器人传感器还未启动就开始进行数据的读取了。 在ROS2中提出了生命周期节点的概念，通过生命周期来控制和检测节点状态。 1.生命周期节点介绍 ROS2生命周期节点是利用状态机构成的，状态直接的转换依靠ROS2的通信机制完成。 生命周期节点主要有以下几个状态 未配置状态（Unconfigured） ，节点开始时的第一个状态，并在出现错误后结束。没有执行，其主要目的是错误恢复。 非活跃状态（Inactivate），节点持有资源（发布者、监听者等）和配置（参数、内部变量），但什么也不做。 没有执行，没有传输，传入的数据可以保存在缓冲区中，但不能读取， 主要目的是允许重新配置。 活跃状态（Activate）， 正常执行。 已完成状态（Finalized），节点已被销毁。 具体的状态之间转换关系请参考下图。 参考文章 "},"ROS2/ROS2入门篇/第5章-ROS2常用工具/001-启动管理工具-Launch.html":{"url":"ROS2/ROS2入门篇/第5章-ROS2常用工具/001-启动管理工具-Launch.html","title":"启动管理工具-Launch","keywords":"","body":"datetime:2023/09/19 14:11 author:nzb 该项目来源于大佬的动手学ROS2 1.启动管理工具-Launch 1.Launch启动工具介绍 1.1 问题描述 对于一个机器人系统来说，往往由很多个不同功能的节点组成，启动一个机器人系统时往往需要启动多个节点，同时根据应用场景和机器人的不同，每个节点还会有不同的配置项。 如果每个节点我们都开一个新终端，敲ros2 run指令并写一堆参数，这是多么浪费生命且令人绝望的事情。 除了启动，你会发现，一个个关闭也是很难受的。 1.2 解决方案 可不可以编写一个类似于脚本的文件来管理节点的启动呢？ ROS2设计时就为我们想好了，为我们设计了一套完整的语法和规则的文件来帮助我们组织节点的启动，这个武器就叫launch文件。 launch文件允许我们同时启动和配置多个包含 ROS 2 节点的可执行文件 在ROS1中launch文件只有一种格式以.launch结尾的xml文档，不熟悉的同学写起来被xml语法折磨的死去活来。不过在ROS2中不要担心，因为在ROS2你可以使用Python代码来编写launch文件 2.编写第一个ROS2的launch文件 2.1 三种编写launch文件的方法 ROS2的launch文件有三种格式，python、xml、yaml。其中ROS2官方推荐的时python方式编写launch文件。 原因在于，相较于XML和YAML， Python是一个编程语言，更加的灵活，我们可以利用Python的很多库来做一些其他工作（比如创建一些初始化的目录等）。 除了灵活还有另外一个原因是ros2/launch（一般launch共功能）和ros2/launch_ros（ROS 2 launch的特性）是用 Python 编写的，我们使用python编写launch文件可以使用 XML 和 YAML 中不能用的launch功能。 要说使用python版本的launch有什么坏处，那就是写起来比yaml要冗余 2.2 使用Python编写Launch 我们的目标是编写一个launch文件，最后使用launch指令，同时启动服务端和客户端节点。 2.2.1 创建功能包和launch文件 创建文件夹和功能包，接着touch一个launch文件，后缀为.py。 mkdir -p chapt5/chapt5_ws/src cd chapt5/chapt5_ws/src ros2 pkg create robot_startup --build-type ament_cmake --destination-directory src mkdir -p src/robot_startup/launch touch src/robot_startup/launch/example_action.launch.py 2.2.2 启动多个节点的示例 我们需要导入两个库，一个叫做LaunchDescription，用于对launch文件内容进行描述，一个是Node，用于声明节点所在的位置。 注意这里要定一个名字叫做generate_launch_description的函数，ROS2会对该函数名字做识别。 # 导入库 from launch import LaunchDescription from launch_ros.actions import Node def generate_launch_description(): \"\"\"launch内容描述函数，由ros2 launch 扫描调用\"\"\" action_robot_01 = Node( package=\"example_action_rclcpp\", executable=\"action_robot_01\" ) action_control_01 = Node( package=\"example_action_rclcpp\", executable=\"action_control_01\" ) # 创建LaunchDescription对象launch_description,用于描述launch文件 launch_description = LaunchDescription( [action_robot_01, action_control_01]) # 返回让ROS2根据launch描述执行节点 return launch_description 2.2.3 将launch文件拷贝到安装目录 如果你编写完成后直接编译你会发现install目录下根本没有你编写的launch文件，后续launch自然也找不到这个launch文件。 因为我们用的是ament_cmake类型功能包，所以这里要使用cmake命令进行文件的拷贝 install(DIRECTORY launch DESTINATION share/${PROJECT_NAME}) 如果是ament_python功能包版 from setuptools import setup from glob import glob import os setup( name=package_name, version='0.0.0', packages=[package_name], data_files=[ ('share/ament_index/resource_index/packages', ['resource/' + package_name]), ('share/' + package_name, ['package.xml']), (os.path.join('share', package_name, 'launch'), glob('launch/*.launch.py')), ], }, ) 2.2.4 编译测试 使用colcon指令编译我们的程序 colcon build 编译完成后，在chapt5/chapt5_ws/install/robot_startup/share/robot_startup/launch目录下你应该就可以看到被cmake拷贝过去的launch文件了。 接着运行 # source 第五章的工作目录，这样才能找到对应的节点，不信你可以不source试试 source ../../chapt5/chapt5_ws/install/setup.bash source install/setup.bash ros2 launch robot_startup example_action.launch.py # 新终端 ros2 node list #即可看到两个节点 3 添加参数&修改命名空间 接着我们尝试使用launch运行参数节点，并通过launch传递参数，和给节点以不同的命名空间。 新建chapt5/chapt5_ws/src/robot_startup/launch/example_param_rclcpp.launch.py。 编写内容如下 # 导入库 from launch import LaunchDescription from launch_ros.actions import Node def generate_launch_description(): \"\"\"launch内容描述函数，由ros2 launch 扫描调用\"\"\" parameters_basic1 = Node( package=\"example_parameters_rclcpp\", namespace=\"rclcpp\", executable=\"parameters_basic\", parameters=[{'rcl_log_level': 40}] ) parameters_basic2 = Node( package=\"example_parameters_rclpy\", namespace=\"rclpy\", executable=\"parameters_basic\", parameters=[{'rcl_log_level': 50}] ) # 创建LaunchDescription对象launch_description,用于描述launch文件 launch_description = LaunchDescription( [parameters_basic1, parameters_basic2]) # 返回让ROS2根据launch描述执行节点 return launch_description 编译运行测试 # source 第五章的工作目录，这样才能找到对应的节点，不信你可以不source试试 source ../../chapt5/chapt5_ws/install/setup.bash source install/setup.bash ros2 launch robot_startup example_param_rclcpp.launch.py # 新终端 ros2 node list #即可看到两个节点 4. 深入了解 如何编写launch文件 在ROS1中launch文件是一种格式以.launch结尾的xml文档；而在ROS2中推荐使用Python方式编写launch文件，此时的launch文件是一种格式以.launch.py结尾的Python脚本。 启动节点 对于一个基础的启动节点的launch文件，需要引用以下库，然后创建一个名为做generate_launch_description的函数 from launch import LaunchDescription from launch_ros.actions import Node def generate_launch_description(): ...... 下文中未注明的均在generate_launch_description()函数中进行操作。 创建LaunchDescription的对象ld（名字任意） ld = LaunchDescription() 然后创建一个Actions.Node对象 example - node = Node( package='package-name', # 节点所在的功能包 namespace='package-namespace', # 命名空间。如果存在同名节点，这一选项会有用 executable='execute-name/script-name.py', # 表示要运行的可执行文件名或脚本名字.py parameters=[{'parameter-name': parameter - value}], # 参数 arguments=['-xxx', xxx, '-xxx', xxx], # 启动参数 output='screen', # 用于将话题信息打印到屏幕 name='node-name' # 表示启动后的节点名，可以没有 remappings = [ # 重映射 ('/xxx/xxx-new', '/xxx/xxx-old'), ] ) example - node2 = Node( ...... ) 将上面所有的Node对象加入ld，然后返回 ld.add_action(example - node) ld.add_action(example - node2) return launch_description 调用shell命令 需要添加头文件 from launch.actions import ExecuteProcess 使用ExecuteProcess调用shell命令 example_cmd = ExecuteProcess( cmd=['some-cmd', 'some-cmd'], # 命令，用逗号隔开 additional_env={'EXAMPLE_PATH': path}, # 可以添加临时的环境变量 output='screen' ) ld.add_action(example_cmd) 获取路径 使用FindPackageShare获取package路径 from launch_ros.substitutions import FindPackageShare # ...... package_name = \"example-package\" package_name_path = FindPackageShare(package=package_name).find(package_name) 或者使用get_package_share_directory from ament_index_python.packages import get_package_share_directory # ...... package_name = \"example-package\" package_name_path = get_package_share_directory(package_name) 连接路径 使用join import os ... # 文件 file - name = 'example-file.xxx' # 字符串前加`f`表示可以在字符串里面使用用花括号括起来的变量和表达式，如定义好的`file-name` file - path = os.path.join(package - path, f'example-folder/{file - name}') # 或者使用逗号隔开 file - path = os.path.join(package - path, 'example-folder', file - name) # 路径 dir - path = os.path.join(package - path, 'example-folder/') 使用替换 from launch.substitutions import PathJoinSubstitution ... PathJoinSubstitution([ FindPackageShare('example-package'), 'example-folder', 'example-file.xxx' ]) 改变参数 一般需要用到以下两个模块 from launch.substitutions import LaunchConfiguration from launch.actions import DeclareLaunchArgument LaunchConfiguration用于在变量中存储启动参数的值并将它们传递给所需的操作，允许我们在launch文件的任何部分获取启动参数的值。 example - cfg = LaunchConfiguration('arg-name', default='true') DeclareLaunchArgument用于定义可以从上述启动文件或控制台传递的启动参数 example - arg = DeclareLaunchArgument( 'arg-name', default_value='xxx', description='some description' ) ld.add_action(example - arg) 启动另一个launch文件 假设已经存在很多的单独的launch文件用于启动不同的功能，如果需要同时启动这些launch文件，可以使用IncludeLaunchDescription在launch文件中嵌套启动launch文件，这样可以提高复用率。 需要以下两个头文件 from launch.actions import IncludeLaunchDescription from launch.launch_description_sources import PythonLaunchDescriptionSource 使用IncludeLaunchDescription嵌套launch文件，其中同样可以使用上文所述的传递参数 another - launch = IncludeLaunchDescription( PythonLaunchDescriptionSource( os.path.join(launch_file_dir, 'launch-file-name.launch.py') ), launch_arguments={'arg-name': example - arg}.items() ) ld.add_action(another - launch) 在另一个launch文件中使用参数 我们来看一个实例：这个launch文件有一个字符串格式的路径作为参数，其中的robot_state_publisher需要传入robot_description作为参数，而这个参数需要使用open()， 也就是需要那个路径参数。我们自然而然会想到使用LaunchConfiguration，但是当你试图获取urdf_path_cfg的时候会发现这根本不是一个字符串。具体解决方案如下： import os from launch import LaunchDescription from launch.actions import DeclareLaunchArgument from launch.substitutions import LaunchConfiguration from launch_ros.actions import Node from launch.actions import OpaqueFunction def launch_setup(context, *args, **kwargs): use_sim_time_cfg = LaunchConfiguration('use_sim_time') urdf_path_cfg = LaunchConfiguration('urdf_path') urdf_path = urdf_path_cfg.perform(context) print('\\033[92m' + \"robot_state_publisher: Use urdf dir: \" + urdf_path + '\\033[0m') with open(urdf_path, 'r') as infp: robot_desc = infp.read() robot_state_publisher_node = Node( package='robot_state_publisher', executable='robot_state_publisher', name='robot_state_publisher', output='screen', parameters=[{ 'use_sim_time': use_sim_time_cfg, 'robot_description': robot_desc }] ) return [ robot_state_publisher_node, ] def generate_launch_description(): ld = LaunchDescription() use_sim_time_arg = DeclareLaunchArgument( 'use_sim_time', default_value='true', description='Use simulation (Gazebo) clock if true' ) urdf_path_arg = DeclareLaunchArgument( 'urdf_path', default_value='robot.urdf', description='urdf_path' ) ld.add_action(urdf_path_arg) ld.add_action(use_sim_time_arg) ld.add_action(OpaqueFunction(function=launch_setup)) return ld 这种写法我个人认为极其不优雅，但是确实能解决实际问题。 强烈建议ROS加入获取参数内容的方法！！！！！ "},"ROS2/ROS2入门篇/第5章-ROS2常用工具/002-ROS2命令行工具.html":{"url":"ROS2/ROS2入门篇/第5章-ROS2常用工具/002-ROS2命令行工具.html","title":"ROS2命令行工具","keywords":"","body":"datetime:2023/09/21 10:19 author:nzb 该项目来源于大佬的动手学ROS2 2.ROS2命令行工具 1.命令小结 打开终端，输入ros2，你将看到下面的内容： usage: ros2 [-h] Call `ros2 -h` for more detailed usage. ... ros2 is an extensible command-line tool for ROS 2. optional arguments: -h, --help show this help message and exit Commands: action Various action related sub-commands bag Various rosbag related sub-commands component Various component related sub-commands daemon Various daemon related sub-commands doctor Check ROS setup and other potential issues interface Show information about ROS interfaces launch Run a launch file lifecycle Various lifecycle related sub-commands multicast Various multicast related sub-commands node Various node related sub-commands param Various param related sub-commands pkg Various package related sub-commands run Run a package specific executable security Various security related sub-commands service Various service related sub-commands topic Various topic related sub-commands wtf Use `wtf` as alias to `doctor` Call `ros2 -h` for more detailed usage. 每一个Command都是对应着ROS2目前所拥有的工具，其实每一个我们在前面的章节中几乎都使用过，而那些没有使用的到的，几乎都是不常用的，所以大家只需要将前面章节中的CLI掌握即可 这里只是提示下，当我们忘记了某个命令行工具的时候该怎么办，可以使用对应的指令加上-h，即可获取其使用方法。 "},"ROS2/ROS2入门篇/第5章-ROS2常用工具/003-RVIZ2.html":{"url":"ROS2/ROS2入门篇/第5章-ROS2常用工具/003-RVIZ2.html","title":"RVIZ2","keywords":"","body":"datetime:2023/09/21 10:19 author:nzb 该项目来源于大佬的动手学ROS2 3. RVIZ2 1.RVIZ2是什么 RVIZ2是ROS2中的一个非常重要且常用的数据可视化工具。 那数据指的是什么数据？可视化又是怎么可视化的？RVIZ2又是如何实现不同数据的可视化的呢？ 答案如下： 数据：各种调试机器人时常用的数据，比如：图像数据、三维点云数据、地图数据、TF数据，机器人模型数据等等 可视化：可视化就是让你直观的看到数据，比如说一个三维的点(100,100,100),通过RVIZ可以将其显示在空间中 如何做到不同数据的可视化：强大的插件，如果没有你的数据，你可以自己再写一个插件，即插即用，方便快捷 注意：RVIZ强调将数据可视化出来，是已有数据的情况下，把数据显示出来而以，而我们后面要讲的gazebo仿真软件是通过模拟真实环境产生数据，两者用途并不一样。 2.RVIZ2 基础配置 2.1 全局配置 Fixed Frame：所有帧参考的帧的名称，坐标都是相对的，这个就是告诉RVIZ你是相对谁的，一般是设置成map或者odom Frame Rate：用于设置更新 3D 视图的最大频率。 2.2 网格 用于可视化通常与地板平面相关联的网格 Reference frame：帧用作网格坐标参考（通常：） Plane cell count: 单元格中网格的大小 Normal cell count：在沿垂直于叶栅平面的网格数（正常：0） Cell size：每个网格单元的尺寸（以米为单位） Plane：标识网格平面的两个轴 2.3 机器人模型 根据 URDF 模型的描述来可视化机器人的模型。 Visual enabled: 启用/禁用模型的 3D 可视化 Description Source：机器人模型文件的来源，可以在File和Topic之间进行选择 Description Topic: 机器人模型文件所在的话题 2.4 TF 可视化构成 TF 广播的所有帧的位置和方向 Marker Scale: 将字和坐标系标识调整的小一些，使其更加可见且不那么混乱 Update interval：以秒为单位的TF广播更新时间 最佳实践，勾选你想看的Frames，直观的看到两个坐标之间的关系 3.总结 看完之后是不是还挺不明所以的，因为大多插件都是和坐标相关的，这个要大家学习了下一章节机器人学和URDF建模之后就非常的清晰了 "},"ROS2/ROS2入门篇/第5章-ROS2常用工具/004-RQT工具.html":{"url":"ROS2/ROS2入门篇/第5章-ROS2常用工具/004-RQT工具.html","title":"RQT工具","keywords":"","body":"datetime:2023/09/21 10:19 author:nzb 该项目来源于大佬的动手学ROS2 4. RQT工具 前面介绍过rqt_graph这个工具，我们在平时编写ROS2程序中经常使用，除了rqt_graph,ROS2中还有很多非常易用的RQT工具，一起来体验下 1. RQT是什么 RQT是一个GUI框架，通过插件的方式实现了各种各样的界面工具。 强行解读下：RQT就像插座，任何电器只要符合插座的型号就可以插上去工作。 说到这里你应该对ROS2的插件化设计感到无比震撼，上节的bag话题录制的存储格式也是插件式的。 2. 体验RQT 没有复杂的指令，一句命令行就可以调出rqt界面。 rqt 打开之后的窗口如下图，空空如也，不要担心，因为我们没有选插件的原因。 2.1 选择插件 这里我们可以选择现有的几个RQT插件来试一试，可以看到和话题、参数、服务、动作四大通信组件相关的工具都有，还有一些可视化、日志和系统计算图等相关的。 我们按照比较常用的几个来看一下，其他的大家有个印象，后续用到再用。 2.2 插件大观 Introspection / Node Graph 第一个是肯定是rqt_graph,插件名字叫做Node Graph,这个名字觉得更加的贴切，用rqt_graph更多的是为了延续ROS1中的用法，这个插件用于查看节点和节点之间的关系的。 Introspection / Process Monitor 这个插件可以看到所有与ROS2相关的进程 Topic/ Message Publisher 可以图形化发布话题数据 Service /Service Caller 图形化调用服务工具 Visualization / Image View 看图像话题数据的Image View Visualization / MatPlot 话题数据图形化工具MqtPlot，就是用这个工具来调PID的 Configuration / Parameter Reconfigure 3. 总结 准备有时间开发一些RQT工具来满足平时的一些特殊场景的使用，到时写一个教程出来，下一节我们一起学习ROS2中的RVIZ2工具。 "},"ROS2/ROS2入门篇/第5章-ROS2常用工具/005-时光记录仪之rosbag2.html":{"url":"ROS2/ROS2入门篇/第5章-ROS2常用工具/005-时光记录仪之rosbag2.html","title":"时光记录仪之rosbag2","keywords":"","body":"datetime:2023/09/21 10:19 author:nzb 该项目来源于大佬的动手学ROS2 5.时光记录仪之rosbag2 本节我们来介绍ROS2中常用的一个CLI工具——rosbag2，这个工具用于记录话题的数据（就像录视频一样）。 我们就可以使用这个指令将话题数据存储为文件 ，后续我们无需启动节点，直接可以将bag文件里的话题数据发布出来。 这个工具在我们做一个真实机器人的时候非常有用，比如我们可以录制一段机器人发生问题的话题数据，录制完成后可以多次发布出来进行测试和实验，也可以将话题数据分享给别人用于验证算法等。 我们尝试使用bag工具来记录话题数据，并二次重放。 一、安装 当我们安装ROS2的时候，这个命令行工具已经为我们自动安装了，这里我们就不需要再次安装。 二、记录 2.1 常用指令 启动talker ros2 run demo_nodes_cpp talker 2.1.1 记录 /topic-name 为话题名字 ros2 bag record /topic-name 2.1.2 记录多个话题的数据 ros2 bag record topic-name1 topic-name2 2.1.3 记录所有话题 ros2 bag record -a 2.1.4其他选项 -o name 自定义输出文件的名字 ros2 bag record -o file-name topic-name -s 存储格式 目前仅支持sqllite3,其他还带拓展，后续更新再更新。 2.2 录制chatter 2.2.1 启动talker 运行talker节点 ros2 run demo_nodes_cpp talker 2.2.2 录制 接着使用像下面的指令就可以进行话题数据的录制了 ros2 bag record /chatter 如何停止录制呢？我们直接在终端中使用Ctrl+C指令打断录制即可 接着你会在终端中发现多处一个文件夹，名字叫做rosbag2_xxxxxx.db3 打开文件夹，可以看到内容 这样我们就完成了录制。 三、查看录制出话题的信息 我们在播放一个视频前，可以通过文件信息查看视频的相关信息，比如话题记录的时间，大小，类型，数量 ros2 bag info bag-file 四、播放 4.1 播放话题数据 接着我们就可以重新的播放数据,使用下面的指令可以播放数据 ros2 bag play xxx.db3 使用ros2的topic的指令来查看数据 ros2 topic echo /chatter 4.2 播放选项 4.2.1 倍速播放 -r -r选项可以修改播放速率，比如 -r 值，比如 -r 10,就是10倍速，十倍速播放话题 ros2 bag play rosbag2_2021_10_03-15_31_41_0.db3 -r 10 4.2.2 -l 循环播放 单曲循环就是它了 ros2 bag play rosbag2_2021_10_03-15_31_41_0.db3 -l 4.2.3 播放单个话题 ros2 bag play rosbag2_2021_10_03-15_31_41_0.db3 --topics /chatter 五、总结 相信你已经掌握了ROS2的bag工具~ "},"ROS2/ROS2入门篇/第5章-ROS2常用工具/006-兼容仿真工具-Gazebo.html":{"url":"ROS2/ROS2入门篇/第5章-ROS2常用工具/006-兼容仿真工具-Gazebo.html","title":"兼容仿真工具-Gazebo","keywords":"","body":"datetime:2023/09/21 10:19 author:nzb 该项目来源于大佬的动手学ROS2 6.兼容仿真工具-Gazebo 今天说说Gazebo，有些同学没有学习RVIZ和Gazebo之前，分不清Gazebo和Rviz之间的区别，只道是Gazebo和RVIZ都能显示机器人模型。 1.Gazebo VS Rviz2 昨天有说RVIZ2是什么： 文章中讲道RVIZ2是用来可视化数据的软件，核心要义是将数据展示出来（我们不生产数据只做数据的搬运工）。 而Gazebo是用于模拟真实环境生产数据的（我们不搬运数据只做数据的生产者） 所以Gazebo可以根据我们所提供的机器人模型文件，传感器配置参数，给机器人创造一个虚拟的环境，虚拟的电机和虚拟的传感器，并通过ROS/ROS2的相关功能包把传感器数据电机数据等发送出来（生产数据）。 这样我们就不用花一分钱，就拥有了各式各样的机器人和传感器（一万八的雷达，也只不过是用鼠标拖拽一下）。 2.Gazebo集成ROS2 Gazebo 是一个独立的应用程序，可以独立于 ROS 或 ROS 2 使用。 Gazebo与ROS 版本的集成是通过一组叫做gazebo_ros_pkgs的包 完成的，gazebo_ros_pkgs将Gazebo和ROS2连接起来。 2.1 gazebo_ros_pkgs gazebo_ros_pkgs不是一个包，是一堆包如下： gazebo_dev：开发Gazebo插件可以用的API gazebo_msgs：定义的ROS2和Gazebo之间的接口（Topic/Service/Action） gazebo_ros：提供方便的 C++ 类和函数，可供其他插件使用，例如转换和测试实用程序。它还提供了一些通常有用的插件。gazebo_ros::Node gazebo_plugins：一系列 Gazebo 插件，将传感器和其他功能暴露给 ROS2 例如: gazebo_ros_camera 发布ROS2图像 gazebo_ros_diff_drive 通过ROS2控制和获取两轮驱动机器人的接口 ROS1的插件迁移到ROS2进度：https://github.com/ros-simulation/gazebo_ros_pkgs/wiki 3. 两轮差速小demo 3.1安装gazebo 因为安装ROS2不会默认安装gazebo，所以我们要手动安装,一行命令很简单，如果提示找不到先去更新下ROS2的源。 sudo apt install gazebo 3.2 安装ROS2的两轮差速功能包 一行代码全给装了，不差这点空间 sudo apt install ros-humble-gazebo-* 3.3 运行两轮差速demo 一行代码搞定 gazebo /opt/ros/humble/share/gazebo_plugins/worlds/gazebo_ros_diff_drive_demo.world 然后你就可以看到一个死丑死丑的小车 3.4 查看话题 通过下面的指令可看到话题和话题的类型，把目光放到这个话题/demo/cmd_demo,下面我们就通过这个话题来控制小车动起来。 ros2@ros2-TM1613R:~$ ros2 topic list -t /clock [rosgraph_msgs/msg/Clock] /demo/cmd_demo [geometry_msgs/msg/Twist] /demo/odom_demo [nav_msgs/msg/Odometry] /parameter_events [rcl_interfaces/msg/ParameterEvent] /rosout [rcl_interfaces/msg/Log] /tf [tf2_msgs/msg/TFMessage] 3.5 让小车前进 ros2 topic pub /demo/cmd_demo geometry_msgs/msg/Twist \"{linear: {x: 0.2,y: 0,z: 0},angular: {x: 0,y: 0,z: 0}}\" 然后就可以看到小车动了起来。 4.总结 RVIZ2是用来可视化数据的软件，核心要义是将数据展示出来（我们不生产数据只做数据的搬运工） Gazebo是用于模拟真实环境生产数据的（我们不搬运数据只做数据的生产者) Gazebo是独立于ROS/ROS2的软件（还有很多仿真软件可以用ROS/ROS2） ROS2和Gazebo之间的桥梁是：gazebo_ros_pkgs "},"ROS2/机器人学篇/第6章-运动学基础/基础-数学基础/001-矩阵与矩阵运算.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/基础-数学基础/001-矩阵与矩阵运算.html","title":"矩阵与矩阵运算","keywords":"","body":"datetime:2023/09/19 14:11 author:nzb 该项目来源于大佬的动手学ROS2 1.矩阵与矩阵运算 本节我们来学习一下线性代数的基础中的矩阵部分，矩阵作为我们学习机器人学中最常用的基础知识，后面学习过程中我们会经常遇到，比如：表示旋转的旋转矩阵、坐标变换中的齐次矩阵、关节速度映射雅可比矩阵、仿真中的惯性矩阵等等。所以很有必要在正式学习之前，了解一下矩阵的概念及常用的矩阵定义。 1.矩阵介绍 1.1 矩阵定义 由 m*n 个数 a_{ij}(i=1,2,..,m;j=1,2...,n) 排成的m行n列的矩阵表格 \\begin{bmatrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1n}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2n}}\\\\\r {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {a_{m1}}&{a_{m2}}&{\\cdots}&{a_{mn}}\\\\ \\end{bmatrix} 称为一个 m*n 的矩阵,记为为 A 或 (a_{ij})_{m*n}(i=1,2,..,m;j=1,2...,n) ，当 m=n 时称 A 为 n 阶方阵. 矩阵就是一堆可能存在着某种联系数的组合，编号规则也很简单，第一行第一列的数编号为 a_{11} ,第二行第一列叫做 a_{21} ，以此类推 如果两个矩阵都是m*n个数组成，则称两个矩阵为同型矩阵。 1.2 零矩阵 所谓零矩阵，就是矩阵中每个数都是 0 ,比如一个 3*3 的 0 矩阵（零矩阵常用 O 来表示） O_{3*3}=\\begin{bmatrix}{0}&{0}&{0}\\\\{0}&{0}&{0}\\\\{0}&{0}&{0}\\\\\\end{bmatrix} 零矩阵是不是和自然数零一样神奇呢？ 根据矩阵的运算法则，零矩阵有以下性质，下一节我们会来动手验证。 任何矩阵（前提符合运算法则）与零矩阵相加、减结果都是其本身 A-O=A \\\\ \\\\ A+O=A 零矩阵与任何矩阵的相乘结果都是零矩阵（注意，矩阵型号可能会变） 1.3 单位矩阵 主对角线上的元素都为 1 ，其余元素全为 0 的 n 阶矩阵称为 n 阶单位矩阵,常用符号 I 表示，如 I3 I_{3}\r =\\begin{bmatrix}{1}&{0}&{0}\\\\{0}&{1}&{0}\\\\{0}&{0}&{1}\\\\\\end{bmatrix} 单位矩阵的性质与自然数1相似 根据矩阵的运算法则，单位矩阵有以下性质： 任何矩阵与单位矩阵的乘积结果为其本身 AI_n = A\\\\\\\\ I_nB = B 2.矩阵的运算 2.1加减法运算 两个矩阵相加减，即其对应元素相加减。 设矩阵 A=\\begin{bmatrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1n}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2n}}\\\\\r {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {a_{m1}}&{a_{m2}}&{\\cdots}&{a_{mn}}\\\\ \\end{bmatrix},B=\\begin{bmatrix} {b_{11}}&{b_\r {12}}&{\\cdots}&{b_{1n}}\\\\ {b_{21}}&{b_{22}}&{\\cdots}&{b_{2n}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {b_{m1}}&{b_\r {m2}}&{\\cdots}&{b_{mn}}\\\\ \\end{bmatrix} 有 A\\pm\\;B=\\begin{bmatrix} {a_{11}\\pm\\;b_{11}}&{a_{12}\\pm\\;b_{12}}&{\\cdots}&{a_{1n}\\pm\\;b_{1n}}\\\\ {a_{21}\\pm\\;b_\r {21}}&{a_{22}\\pm\\;b_{22}}&{\\cdots}&{a_{2n}\\pm\\;b_{2n}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {a_{m1}\\pm\\;b_{m1}}&{a_\r {m2}\\pm\\;b_{m2}}&{\\cdots}&{a_{mn}\\pm\\;b_{mn}}\\\\ \\end{bmatrix} 只有两个矩阵为同型矩阵时才能进行加减运算。 运算性质 交换律： A+B=B+A 结合律： (A+B)+C=A+(B+C) 乘法结合律： (AB)C=A(BC) 栗子： \r A=\\begin{bmatrix}{1}&{0}&{1}\\\\{1}&{0}&{0}\\\\{0}&{0}&{1}\\\\\\end{bmatrix},B=\\begin{bmatrix}{0}&{0}&{1}\\\\{1}&{0}&{0}\\\\{0}&{0}&{1}\\\\\\end{bmatrix}\r A+B= B+A =\\begin{bmatrix}{1}&{0}&{2}\\\\{2}&{0}&{0}\\\\{0}&{0}&{2}\\\\\\end{bmatrix} 2.2乘法运算 乘法运算分为两种，一种是标量乘法，一种是矩阵乘法。 2.2.1 标量乘法 标量乘法即一个矩阵和一个数相乘。运算法则：将矩阵的每一个元素都乘上这个数即可 栗子： A = \\begin{bmatrix}{1}&{2}\\\\{3}&{4}\\\\\\end{bmatrix}\\\\ 2\\times A= 2\\times\r \\begin{bmatrix}{1}&{2}\\\\{3}&{4}\\\\\\end{bmatrix} = \\begin{bmatrix}{2 \\times 1}&{2 \\times 2}\\\\{2 \\times 3}&{2 \\times\r 4}\\\\\\end{bmatrix} =\\begin{bmatrix}{2}&{4}\\\\{6}&{8}\\\\\\end{bmatrix} 2.2.2 矩阵运算 运算法则 设矩阵 A\\times B = C = (c_{ij})_{m*n} ，则 C 的第 i 行第 j 列的元素 c_{ij} 的值等于矩阵A的第 i 行元素和矩阵B的第 j 列元素两两乘积之和。 栗子： 设： A = \\begin{bmatrix}{1}&{2}\\\\{3}&{4}\\\\\\end{bmatrix}, B = \\begin{bmatrix}{1}&{0}\\\\{0}&{3}\\\\\\end{bmatrix} \\\\ 则 A \\times B = C = \\begin{bmatrix}{c_{11}}&{c_{12}}\\\\{c_{21}}&{c_{22}}\\\\\\end{bmatrix} c_{11} =1*1+2*0 = 1 c_{12} =1*0+2*3 = 6 c_{21} = 3*1+4*0 = 3 c_{22} = 3+0 + 4*3 = 12 C = \\begin{bmatrix}{1}&{6}\\\\{3}&{12}\\\\\\end{bmatrix} 乘积之和其实就是点乘运算，比如栗子： a = [1,2,3],b = [0,1,2]\\\\ a\\cdot b =1*0+2*1+3*2 = 8 矩阵的乘法的意义是非常有意思的，这里放一个链接，欢迎大家阅读： 矩阵乘法的本质是什么？ 运算性质 尝试计算下上面栗子中的 B\\times A 的值，得到的结果依然是上面栗子中的 C 吗? 答案：并不是，一般情况下，矩阵的乘法并不满足交换律 矩阵的运算规律： 结合律 (A\\times B)\\times C = A \\times(B\\times C) 分配律 A\\times(B+C) = A\\times B + A\\times C 2.3转置运算 转置运算定义非常简单，将矩阵的对应行列元素互换(右上角加 {T} 表示） C = \\begin{bmatrix}{c_{11}}&{c_{12}}\\\\{c_{21}}&{c_{22}}\\\\\\end{bmatrix} ,C^{T} = \\begin{bmatrix}{c_{11}}&{c_{21}}\\\\{c_\r {12}}&{c_{22}}\\\\\\end{bmatrix} \\\\ 栗子： A = \\begin{bmatrix}{1}&{2}\\\\{3}&{4}\\\\\\end{bmatrix},A^T = \\begin{bmatrix}{1}&{3}\\\\{2}&{4}\\\\\\end{bmatrix} 运算规律 (A^T)^T = A (A+B)^T = A^T + B^T (AB)^T = B^TA^T 3.重要定义 3.1 矩阵的逆 3.1.1 定义 A,B 是n阶方阵，E是n阶单位矩阵，若 AB=BA=E ,则称 A 是可逆矩阵，并称B是A的逆，且逆矩阵是唯一的，记作 A^{-1} 这个我们本节课就不举栗子了，下节课我们使用代码来直接求。 注意：不一定所有的矩阵都是可逆的 3.1.2 运算规律 (A^{-1})^{-1} = A AB 可逆， (AB)^{-1}=B^{-1}A^{-1} "},"ROS2/机器人学篇/第6章-运动学基础/基础-数学基础/002-MiniConda与Jupyter介绍安装.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/基础-数学基础/002-MiniConda与Jupyter介绍安装.html","title":"MiniConda与Jupyter介绍安装","keywords":"","body":"datetime:2023/09/19 14:11 author:nzb 该项目来源于大佬的动手学ROS2 2.MiniConda与Jupyter介绍安装 上一节我们介绍了机器人学的基础——矩阵相关知识，秉持着学以至用的原则，准备带大家先用代码来实现下矩阵的创建以及矩阵的运算。 工欲善其事，必先利其器，如果是编写机器人相关算法，最为推荐的就是使用jupyter来和ros进行通信了。 所以本节课就带你一起安装好MiniConda，并在MiniConda中安装好jupyter并配置好ros2环境。 1.MiniConda与Jupyter介绍 1.1 MiniConda 介绍 Miniconda 是 Conda 的免费最小安装程序。 Conda是什么呢？ Conda是在Windows、macOS和Linux上运行的开源软件包管理系统和环境管理系统。Conda可以快速安装、运行和更新软件包及其依赖项。 所以相比于conda的大体积miniconda更加的小和易用。 1.2 Jupyter介绍 可以把jupyter理解为一个可以在网页运行python语言的工具。 jupyter提出了文学化编程的概念，让我们可以在单元格(cell)中，像在笔记本上写文章一样，随时写，随时运行，随时根据运行的结果来修改我们的代码，这样的交互式编程模式可以极大的提升我们编写代码的效率。 2.安装miniconda与jupyer 2.1 miniconda下载 minconda下载地址：https://docs.conda.io/en/latest/miniconda.html 这里推荐选择Python3.10 Miniconda3 Linux 64-bit 地址：https://repo.anaconda.com/miniconda/Miniconda3-py310_23.5.2-0-Linux-x86_64.sh 下载完成后你可以得到一个.sh的安装文件 2.2 miniconda安装 在安装目录文件夹空白处右击，在终端中打开,输入下面指令即可安装 bash Miniconda3-xxxx-Linux-x86_64.sh 一路点enter，然后输入yes，回车即可完成安装，最后一步会提醒你是否要自动初始化环境，这里我们先选择yes。 没有选没事，跟着来一起初始化一次conda，打开终端输入下面的命令即可 cd ~/miniconda3/bin ./conda init 重启终端，你会发现你的终端前多了一个base,这代表你已经装好了conda。 如果想退出conda环境可以输入 conda deactivate 为了能够使用系统的 ROS2 的库，我们要创建和系统Python版本一样的环境，使用下面的命令可以查看系统当前的Python版本，接着创建相应的的环境。 conda deactivate #先退出虚拟环境，不然下一句命令就会返回虚拟环境的Python版本号 python --version # 这句命令会返回当前的Python版本号 替换下面的 为上一个命令返回的版本号 conda create -n ros2 python= 接着激活这个环境即可 conda activate ros2 2.3 jupyter安装 方便起见，我们就在ros2环境下安装jupyter，使用的是清华大学源。 pip3 install jupyter -i https://pypi.tuna.tsinghua.edu.cn/simple 安装完成后，我们就可以使用下面的指令启动jupyter了，不出意外你的浏览器将要跳出来，然后自动打开conda页面。 jupyter-notebook 3.使用jupyter编写节点李四 接着带你一起使用jupyter来写ros2的代码。 3.1 新建Python3并编写第一行代码 点击新建Python3 然后你可以看到一行行的单元格。 接着我们就可以在单元格里输入python代码，然后使用Shift+Enter来运行这行代码，比如我们可以试一试打印一句话 print(\"hello jupyter\") 接着我们使用Shift+Enter来运行这行代码，可以看到这行代码的结果，随之展示在了该句打印的下方，我们可以修改打印的内容，然后重新使用Shift+Enter来运行，下面的数值也会随之改变。 3.2 编写ROS2代码 使用ros2无非是使用其rclpy客户端库，jupyter完美的支持了该库，一起和用import来导入吧。 第一行输入下面的指令，点击Shift+Enter可以看到没有任何报错，即导入成功了。 import rclpy from rclpy.node import Node 接着在和一起初始化客户端库，新建节点李四和spin节点吧，完整的代码如下： import rclpy from rclpy.node import Node rclpy.init() # 初始化rclpy node = Node(\"li4\") # 新建一个节点 node.get_logger().info(\"大家好，我是作家li4.\") rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） 分步输入运行 注意这里我们没有调用shutdown,因为我们还不希望rclpy关掉。 3.3 测试 我们接下来用，ros2的命令行工具查看一下li4节点是否在线。 在jupyter中运行命令行和打开终端也是非常方便的，为了学习jupyter，我们使用jupyter自带的终端来运行ros2的指令。 我们新建一个终端，回到文件夹目录视图，点击新建终端 打开后的样子如下 在终端中输入 ros2 node list 可以看到李四已经出现了 4.总结 不能说吹爆jupyter，但用python和ros写算法调试程序，jupyter真的是非常的好用，还有更强大的画图功能等等，后面在机器人学学习课程中都会一一讲到，并且带着大家一起来熟悉jupyter与ros2的更多知识。 "},"ROS2/机器人学篇/第6章-运动学基础/基础-数学基础/003-矩阵运算实战.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/基础-数学基础/003-矩阵运算实战.html","title":"矩阵运算实战","keywords":"","body":"datetime:2023/09/19 14:11 author:nzb 该项目来源于大佬的动手学ROS2 3.矩阵运算实战 上一节我们安装好了MiniConda和Jupyter，本节课我们继续回到学习机器人学的路上来。首先我们来学习使用一个矩阵库Numpy，并且通过Numpy将我们第一节学习到的矩阵相关计算一一实现。 1.NumPy是什么 NumPy是一个功能强大的Python库，主要用于对多维数组执行计算。NumPy这个词来源于两个单词-- Numerical和Python。NumPy提供了大量的库函数和操作，可以帮助程序员轻松地进行数值计算。 通过这个库我们可以非常简单的完成矩阵的创建、矩阵的计算，不管是二维还是多维都非常的easy. NumPy可以使用在以下场景： 机器学习模型： 在编写机器学习算法时，需要对矩阵进行各种数值计算。例如矩阵乘法、换位、加法等。NumPy提供了一个非常好的库，用于简单(在编写代码方面)和快速(在速度方面)计算。NumPy数组可用于存储训练数据和机器学习模型的参数。 图像处理和计算机图形学： 计算机中的图像表示为多维数字数组。NumPy成为同样情况下最自然的选择。实际上，NumPy提供了一些优秀的库函数来快速处理图像。例如，镜像图像、按特定角度旋转图像等。 数学任务： NumPy对于执行各种数学任务非常有用，如数值积分、微分、内插、外推等。因此，当涉及到数学任务时，它形成了一种基于Python的对MATLAB的快速替代。 2.Numpy安装 我们尝试在单元格内导入numpy，如果报错说明你没有安装 import numpy as np 在conda环境中安装非常的简单，也是一句话的事，在单元格内输入下面的代码，然后Shift+Enter执行即可。 注意指令前面有一个!，感叹号代表我们输入的是一句命令行 !pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple 安装完成后，再次导入就不会报错了。 3.创建矩阵 导入完成之后我们就可以通过numpy来创建矩阵。 numpy中有矩阵和数组两个概念，数组相比矩阵更加灵活 3.1 创建单位矩阵 创建一个3*3的零矩阵。 np.identity(3) 3.2 创建零矩阵 创建一个3*3的零矩阵。 np.zeros([3,3]) 3.3 创建随机矩阵 创建一个3*3的随机矩阵。 np.random.rand(3,3) 3.4 从已有数组创建矩阵 假设我们已经有了数据，我们想创建一个矩阵怎么办呢？ 比如我们创建一个2*2的矩阵，矩阵的数据分别是[1,2,3,4]。 我们可以通过reshape改变矩阵的形状，这里我们把矩阵变成了2*2的样子。 np.asarray([1,2,3,4]).reshape(2,2) 3.5 判断两个矩阵是否相等 numpy的allclose方法，比较两个array是不是每一元素都相等，默认在1e-05的误差范围内。 我们做一个测试： print(\"零矩阵和单位矩阵\",np.allclose(np.zeros([3,3]),np.identity(3))) print(\"单位矩阵和单位矩阵\",np.allclose(np.identity(3),np.identity(3))) 4.计算矩阵 计算矩阵我们主要对第一节中的矩阵算法进行验证。 4.1 矩阵加法/减法 加法使用np.add,减法np.subtract A = np.asarray([1,2,3,4]).reshape(2,2) B = np.zeros(2) print(np.add(A,B)) 4.2 矩阵乘法 乘法使用np.dot （前提同形）任何矩阵乘上零矩阵等于零矩阵，任何矩阵乘上单位矩阵等于其本身 A = np.asarray([1,2,3,4]).reshape(2,2) B = np.zeros([2,2]) C = np.identity(2) print(np.dot(A,B)) print(np.dot(A,C)) 4.3 矩阵求逆 矩阵求逆使用np.linalg.inv 矩阵的逆与矩阵的乘积为单位矩阵 A = np.asarray([1,2,3,4]).reshape(2,2) A_INV = np.linalg.inv(A) print(A_INV) print(np.dot(A,A_INV)) 需要注意的是，并不是所有的矩阵都有逆，比如零矩阵就没有逆，如果尝试用numpy来求逆则会出现错误 O = np.zeros(2) O_INV = np.linalg.inv(O) 另外如果使用的是conda提供的numpy包，对于某些不存在逆的矩阵，并不会抛出错误。 但是对于通过pip安装的相同版本甚至更高版本的numpy，则不会出现类似问题。 \"\"\" numpy packages isntalled from conda: numpy 1.21.2 py38h20f2e39_0 numpy-base 1.21.2 py38h79a1101_0 \"\"\" c=np.asarray([ 1,2,3, 4,5,6, 7,8,9, ]).reshape((3,3)) print(\"矩阵的行列式：\",np.linalg.det(c)) print(\"矩阵的秩：\",np.linalg.matrix_rank(c)) c_inv=np.linalg.inv(c) print(\"矩阵c和c_inv点乘的结果：\",\"\\n\",np.dot(c,c_inv)) 4.4 矩阵转置 矩阵转置在矩阵后使用.T即可 A = np.asarray([1,2,3,4]).reshape(2,2) A.T 5.总结 今天一起学习了使用numpy操作矩阵，还有更多的资料可以在公众号后台回复numpy获取，我们下节见～ "},"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/001-空间坐标描述.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/001-空间坐标描述.html","title":"空间坐标描述","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 1.空间坐标描述 1.何为位姿 1.1 引言 在书籍《天才在左，疯子在右》中有这样一个故事，有一位十七岁的少年，他对量子力学有着独特的见解和远超同龄人的知识储备，他说四维生物突破了时空的界限，在它的观察中，将人类一生的活动看成一条连续的线，就像一条长长的虫子，它可以看到人的过去，也可以看到人的未来。 我们对四维空间不了解，但对三维立体和二维的平面每天都有接触。一张铺平的中国地图是二维平面的，拔地而起的高楼大厦是三维立体的。 那我们如何用数字表示高楼在地图中的位姿呢？又如何用数字表示某个高楼中你的位姿呢？ 1.2 我们先来看地图中高楼的位姿 在地图上，我们可以利用经纬度坐标系来描述位姿，在经纬度坐标系中，我们可以使用经度值和纬度值表示地图上的某一个大楼的坐标，比如天安门的经纬度经度：116.38 ，纬度：39.90 经纬度坐标系是以经纬度原点（几内亚湾）建立的二维平面直角坐标系，因此我们可以使用x,y来描述该坐标系中的任意一个点的位置。 经度的起点就是指0度经线，位于英国格林尼治天文台旧址。 纬度的起点就是指0度纬线，就是指赤道。而经度0和纬度0的交点，大致位于非洲西部的几内亚湾，位于海上。 通过经纬度可以定位到地图中的建筑物的位置，但我们依然无法得知这个建筑物的朝向（东南西北），所以除了描述位置的经纬度外，我们还需要增加一个theta( \\theta ) ,表示朝向。这样我们就得到了一个物体在二维平面中用数学描述的三个值，经度（x）、维度（y） 和 朝向（theta）。 1.3 高楼中你的位姿 现实世界是三维的，除了经纬度还有海拔高度。所以采用经度（x）、维度（y）并不能完整的描述出空间中物体的位置，例如只有经纬度无法表示你所处的楼层的海拔高度，这样就没办法确定你的位置。 我们同样可以在经纬度原点建立一个三维空间直角坐标系，采用经度（x）、维度（y）和海拔高度（z）三个值来描述三维空间中任意一点的位置。 和二维空间中类似，知道了你在某一个大楼中的位置还不够，并不能判断出你的姿态（躺平的、站着的还是侧卧的），那我们该如何描述三维空间中的姿态呢? 答案是旋转矩阵，旋转矩阵是什么？我们接着往下看。 1.4 参考坐标系 无论是在二维空间还是在三维空间，我们想要描述一个物体的位置和姿态第一步就是确定一个参考坐标系，物体的位置和姿态描述我们都是以这个坐标系作为参考的。 参考坐标系，这一点很重要，因为没有绝对的坐标，只有相对的坐标。 2.位置的表示 从第一节背景中可以得知，二维平面中的位置可以用 x,y 表示，三维空间中的位置可以用 x,y,z 来表示。 无论是在三维空间还是在二维平面，我们都可以使用 x,y,z 来表示位置，只不过对于二维空间来说，z的值是默认的一个固定不变的值，比如 0 假如我们确定了一个空间直角坐标系A,我们就可以使用 x,y,z 来确定A坐标系中任意一点P的位置，可以记作 {^A}P {^A}P= \\begin{bmatrix} x \\\\ y \\\\ z \\\\ \\end{bmatrix} 2.1 位置矢量 直角坐标系{A}其实可以看作是由三个互相正交（两两垂直）的单位矢量组成的。 那么在坐标系{A}中的一点P也可以写作矢量形式，其矢量形式由其在三个单位矢量上的分量组成。 所以参考坐标系{A}中一点P也可以写作 {^A}P= \\begin{bmatrix} {^x}p \\\\ {^y}p \\\\ {^z}p \\\\ \\end{bmatrix} = [{^x}p，{^y}p , {^z}p ]^T \\tag{位置矢量} 如果说位置矢量不太好理解，可以简单的认为就是坐标轴的 x,y,z \\begin{bmatrix}{x}\\\\{y}\\\\{z}\\\\\\end{bmatrix} 3.姿态的表示 在背景中提到除了位置，坐标描述还有另外一个非常重要的组成部分——姿态。 接着上面的说，我们已经知道坐标系A中的一个点P的位置，我们如何描述P点在{A}坐标系下的姿态呢？ 我们可以以P点为原点再建立一个坐标系(也可以认为该坐标系固定在物体P点上)，这样我们就可以通过描述新坐标系{P} 和 参考坐标系{A} 之间的姿态关系来表示 {^A}P 点的姿态。 上图是使用RVIZ2绘制的，红色代表x轴，绿色代表y轴，蓝色代表z轴。 从图中可以看出，坐标系{P}的每一个轴和参考坐标系的每一个轴之间都有一个角度，比如Px轴和Ax,Ay,Az三个轴之间存在三个角度，通过这三个角度我们就可以确定Px轴和参考坐标系{A}之间的关系，以此类推，我们也可以确定Py轴和Pz轴分别与{A}之间的关系。 每个轴的相对姿态关系确定了，坐标系之间的姿态也就确定了， {^A}P 点的姿态也就确定了。 3.1 旋转矩阵 我们将上述坐标系{P}的三个轴相对于参考坐标系{A}三个轴的共九个角度的余弦值，组成一个3*3的矩阵，该矩阵就是旋转矩阵，因该矩阵是{P}相对于{A}的姿态关系的表示，故记作 {^A_P}R {^A_P}R=[{^A}x_{P} \\ {^A}y_{P} \\ {^A}z_{P}] = \\begin{bmatrix}{r_{11}}&{r_{12}}&{r_{13}}\\\\{r_{21}}&{r_{22}}&{r_\r {23}}\\\\{r_{31}}&{r_{32}}&{r_{33}}\\\\\\end{bmatrix} \\tag{旋转矩阵} 两个向量的点乘为两个向量的长度与它们夹角余弦的积,所以 r11 可以表示为单位向量 P_{x} 与 A_{x} 的点积，旋转矩阵就可以写为下面的形式 {^A_P}R = \\begin{bmatrix} {P_{x}\\cdot A_x} & {P_{y}\\cdot A_x} & {P_{z}\\cdot A_x}\\\\ {P_{x}\\cdot A_y} & {P_{y}\\cdot\r A_y} & {P_{z}\\cdot A_y}\\\\ {P_{x}\\cdot A_z} & {P_{y}\\cdot A_z} & {P_{z}\\cdot A_z}\\\\ \\end{bmatrix} 将 {^A_P}R 进行转置可得 {^A_P}R^T {^A_P}R^T = \\begin{bmatrix} {P_{x}\\cdot A_x} & {P_{x}\\cdot A_y} & {P_{x}\\cdot A_z}\\\\ {P_{y}\\cdot A_x} & {P_{y}\\cdot\r A_y} & {P_{y}\\cdot A_z}\\\\ {P_{z}\\cdot A_x} & {P_{z}\\cdot A_y} & {P_{z}\\cdot A_z}\\\\ \\end{bmatrix} 可以看出 {^A_P}R^T 其实表示坐标系{P}作为参考坐标系下坐标系{A}的姿态，即 {^A_P}R^T = {^P_A}R = {^A_P}R^{-1} 需要注意的是： 当两个坐标系之间姿态没有变化，即坐标系间 x,y,z 轴方向对应重合，则旋转矩阵为单位矩阵，这个很好求得，有兴趣的同学可以算一下 从矩阵的角度看，矩阵的逆等于矩阵的转置，则该矩阵为正交矩阵，显而易见，旋转矩阵是正交矩阵 4.位置+姿态 通过位置矢量我们可以描述一个点在特定参考坐标系下的位置，通过旋转矩阵可以描述一个点在特定参考坐标系下的姿态。 在机器人当中位置和姿态一般会一起出现，所以我们将其组合就叫做位姿 4.1 位姿描述的多个含义 含义1：表示特定参考坐标系下某个物体（点）的位置和姿态，比如我们描述参考坐标系{A}中物体（点）P的位置和姿态 含义2：表示两个坐标系之间的位姿关系，比如位置可以表示坐标系{A}和坐标系{B}原点位置关系，姿态可以表示两个坐标系坐标轴的朝向关系 坐标系之间关系， ^AP_{Bo} 表示两坐标系原点之间位置矢量 {B} = \\{ ^A_BR, {^A}P_{Bo} \\} 含义3：两个物体之间的关系，我们通常把坐标系固定在物体上，这样就可以表示两个物体之间的位姿关系，比如自行车前轮和后轮的关系 说：学会了位置和姿态描述，三维空间坐标关系描述相信已经难不倒你了 5.坐标变换 位姿是相对的，同一个物体在不同的参考坐标系下的位姿数据肯定是不同的。在后续的学习和使用当中，我们会经常需要求同一个点在不同坐标系的位姿表示，这就要求我们掌握坐标变换的方法了。 比如在手眼系统中，我们可以通过视觉算法获取到工件坐标系P鱼相机坐标系C之间的关系，我们想要控制机械臂的末端运动到工件坐标系P进行夹取，那么我们就要知道工件坐标系P在机器人基坐标系B 下的位姿，如何获取呢？这就需要进行坐标变换了。 5.1 平移坐标变换 如图，坐标系{A}、{B}、{C}的姿态是相同的，其之间的姿态对应的旋转矩阵都是单位矩阵。在我们已知： {A}为参考坐标系，{B}的位置矢量 {^A_B}P=[1,1,1]^T {B}为参考坐标系，{C}的位置矢量 {^B_C}P=[3,0,1]^T 求： {A}为参考坐标系，{C}的位置矢量 {^A_C}P 大家可以利用简单的几何知识手算一下，再继续往下看 正确的答案应该是： {^A_C}P=[4,1,2]^T 算法也很简单，直接将 {^A_B}P 与 {^B_C}P 相加即可 {^A_C}P ={^A_B}P+{^B_C}P=[1,1,1]^T+[3,0,1] ^T=[4,1,2]^T 由此可知，我们通过平移坐标变换可以求出同一个点（{P}）在相同姿态不同位置坐标系({A}鱼{B})下的不同表示，也可以得到坐标的平移方程 {^A_C}P ={^A_B}P+{^B_C}P \\tag{坐标平移方程} 要提醒大家注意：在上述例子中，{A},{B},{C}三个坐标系的姿态都是相同的，所以 {^A_C}R={^A_B}R={^B_C}R ，即都是单位旋转矩阵 5.2 旋转坐标变换 如果坐标系之间姿态不同，同一个点的位姿在不同参考姿态下的位置和姿态也会不一样。 上图中，坐标系{A}鱼坐标系{B}原点重合（连名字都连一块了），我们已知： {B}坐标系绕{A}的z轴即 A_z 旋转了 45^\\circ {B}鱼{C}姿态相同，{B}为参考坐标系，{C}的位置矢量为 {^B_C}P=[3,0,1]^T 求 {A}为参考坐标系，{C}的位置矢量 {^A_C}P {A}为参考坐标系，{C}的旋转矩阵 {^A_C}R 这次相对来说困难一些，不过我们依然可以手推出来,跟着的思路一起往下走 5.2.1 求 {^A_C}R 因为{B}鱼{C}姿态相同，所以{A}参考坐标系下{C}的姿态和{A}参考坐标系下{B}的姿态是相同的，即： {^A_B}R={^A_C}R 接着只需要求 {^A_B}R 即可，因为{B}坐标系绕{A}的z轴即 A_z 旋转了 45^\\circ ,我们可以一一计算旋转矩阵各个元素的值 {^A_B}R ={^A_C}R = \\begin{bmatrix} {B_{x}\\cdot A_x} & {B_{y}\\cdot A_x} & {B_{z}\\cdot A_x}\\\\ {B_{x}\\cdot A_y} & {B_\r {y}\\cdot A_y} & {B_{z}\\cdot A_y}\\\\ {B_{x}\\cdot A_z} & {B_{y}\\cdot A_z} & {B_{z}\\cdot A_z}\\\\ \\end{bmatrix} =\r \\begin{bmatrix} {cos(45)} & cos(90+45) & cos(90)\\\\ {cos(90-45)} & cos(45) & cos(90)\\\\ {cos(90)} & cos(90) & cos(0)\\\\\r \\end{bmatrix} = \\begin{bmatrix} {cos(45)} & cos(90+45) & 0\\\\ {cos(90-45)} & cos(45) & 0\\\\ {0} &0 &1\\\\ \\end{bmatrix} 将结果算出来，再利用 工具 来验证一下，看看最终结果对不对 到此我们求出了 {^A_C}P 与 {^A_C}R ，但聪明的鱼粉肯定不会就此罢休，我们接着来举一反三 {B}绕着{A}的z轴旋转了45度我们计算出来了，那如果{B}绕着{A}旋转 \\theta 角度该如何呢?相信心中已经有了答案 R(z,\\theta)= \\begin{bmatrix} {cos\\theta} & -sin\\theta & 0\\\\ {sin\\theta} & cos\\theta & 0\\\\ {0} &0 &1\\\\ \\end{bmatrix}\r \\tag{提示：重要方程1} 那如果不是绕着z轴旋转，而是绕着x轴呢？ R(x,\\theta)= \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & {cos\\theta} & -sin\\theta \\\\ 0&{sin\\theta} & cos\\theta \\\\ \\end{bmatrix}\r \\tag{提示：重要方程2} 绕着y轴呢？ R(y,\\theta)= \\begin{bmatrix} {cos\\theta} & 0 & {sin\\theta}\\\\ 0 &1 &0\\\\ {-sin\\theta} & 0 &cos\\theta \\\\ \\end{bmatrix}\r \\tag{提示：重要方程3} 5.2.2 求 ^A_CP 现在我们已知 ^B_CP 和 ^A_BR ,那如何求 ^A_CP 呢，我们可以使用下面这个方程 ^A_CP = {^A_BR}{^B_CP}\\tag{坐标旋转方程} 关于这个方程，其实是将 ^B_CP 在{B}上各轴的分量变换到了{A}的各轴上 {^A_BR} 是一个 3*3 的矩阵， {^B_CP} 是 3*1 的矩阵，其相乘结果还是一个 3*1 的矩阵，利用前几节学习的矩阵乘法手算或者使用numpy进行计算，得到最终结果为： ^A_CP = {^A_BR}{^B_CP}\\ = [2.12,2.12,1]^T 小思考:{C}的参考坐标系从{B}变成了{A},{C}在空间中的位置发生了变化了吗？ 5.3平移旋转复合变换 在我们平时搞机（器人）时，一般情况下两个坐标系原点不重合姿态也不相同。我们将坐标变换拆分成先绕参考坐标系旋转，再绕参考坐标系平移两步，这样我们就得到了坐标的复合变换方程 ^A_CP = {^A_BR}{^B_CP}+^A_BP 这个公式其实也很好理解， {^A_BR}{^B_CP} 就是将{C}在{B}上的各轴分量转换到{A}上，再和原来在{A}上各轴的分量再相加。不理解的同学也没事，后面我们使用最多的还是齐次变换矩阵，根据方程直接撸代码就行了。 6.左手还是右手 最后要说的是左手坐标系和右手坐标系，一般情况下我们都是使用右手坐标系搞机。 用右手确定的坐标系就是右手坐标系了，跟着一起做： 拿起你的右手，先给自己竖个大拇指，然后打开手掌，将大拇指的方向朝向下图中的蓝色z轴，让剩下的四根手指朝向红色的x轴，此时朝向手心外的就是绿绿的y轴的方向了。 如果你换左手，做上述动作，你会发现y轴是朝手心里的。 再放张图给肢体不协调的同学： 7.练习 光说不练假把式，我们来做个手眼转换题 如图🔓示，已知： 1.相机坐标系{C}为参考坐标系，工具坐标系{P}的位置矢量在相机坐标系{C}的x,y,z各轴投影为 2,1,2 ，并且工具坐标系和相机坐标系姿态相同。 2.机器人基坐标系{B}为参考坐标系，相机坐标系{C}的位置矢量在{B}各轴的投影为 0,0,3 ，坐标系{C}绕着坐标系{B}的x轴转了180度 可以参考下图看题目 求： {B}为参考坐标系，坐标系{P}的位置矢量和旋转矩阵 答案： 位置矢量： [2,-1,1]^T 旋转矩阵： \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & -1 & 0\\\\ 0 &0 & -1\\\\ \\end{bmatrix} 参考文档 机器人学导论 机器人学基础 "},"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/002-空间坐标描述实战.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/002-空间坐标描述实战.html","title":"空间坐标描述实战","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 2.空间坐标描述实战 上一节我们学习了坐标描述和坐标变换的理论知识，本节课我们把重点放到动手实现上，通过numpy实现坐标的描述和变换，同时结合ROS2鱼RVIZ进行坐标关系可视化与求解。 通过本节你将掌握： 使用numpy表示位置矢量和旋转矩阵 使用numpy进行平移与旋转坐标变换 了解ROS2中TF2的概念 使用tf2相关CLI工具进行坐标变换 使用python操作TF进行坐标变换 1.numpy表示位姿 在前几节中，带你安装使用了ROS2和MiniConda，并学习使用Numpy进行矩阵相关运算的验证。 那我们如何使用numpy中的矩阵表示位置矢量和旋转矩阵呢？ 1.1 位置表示 上一节中我们使用一个3行1列的矩阵表示了位置，那么我们在numpy中自然也可以使用这样一个矩阵表示。 打开终端，输入下面指令打开jupyter jupyter-notebook 新建一个python3的代码并重命名，接着在单元格中导入numpy import numpy as np 1.1.1 位置矩阵 使用3*1的矩阵表示位置，我们新建一个沿着x、y、z各平移1个单位的位置矢量。 np.asarray([1.0,1.0,1.0]).reshape(3,1) 1.2 姿态表示 姿态可以使用3*3的旋转矩阵表示,3*3的单位矩阵代表没有姿态变换，注意没有姿态变换不是零矩阵，而是单位矩阵。 我们新建一个旋转矩阵，用该旋转矩阵表示绕着z轴旋转45度，可以这样写： import math import numpy as np theta = math.radians(45) R_AB = np.asarray([math.cos(theta),-math.sin(theta),0, math.sin(theta),math.cos(theta),0, 0,0,1 ]).reshape(3,3) print(R_AB) 运行后得到的旋转矩阵是不是和上节的一样 2.numpy坐标变换 掌握了使用numpy表示位置和姿态后，接着我们使用numpy来完成上一节的小练习 2.1 题目 如图🔓示，已知： 1.相机坐标系{C}为参考坐标系，工具坐标系{P}的位置矢量在相机坐标系{C}的x,y,z各轴投影为 2,1,2 ，并且工具坐标系和相机坐标系姿态相同。 2.机器人基坐标系{B}为参考坐标系，相机坐标系{C}的位置矢量在{B}各轴的投影为 0,0,3 ，坐标系{C}绕着坐标系{B}的x轴转了180度 可以参考下图看题目 求： {B}为参考坐标系，坐标系{P}的位置矢量和旋转矩阵 2.2 使用numpy求解 2.2.1 旋转矩阵求解 这里我们就需要使用复合坐标变换了，根据坐标变换规则有： ^B_PR=^B_CR^C_PR {C}和{P}姿态相同，所以 ^C_PR 是一个单位矩阵。又因为{C}绕着{B}的x旋转了180度，根据上节的重要公式2可知 R(x,\\theta)= \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & {cos\\theta} & -sin\\theta \\\\ 0&{sin\\theta} & cos\\theta \\\\ \\end{bmatrix} \\tag{提示：重要方程2} 所以 ^B_CR 对应的程序可以这样写 import math import numpy as np theta = math.radians(180) R_BC = np.asarray([1, 0, 0, 0, math.cos(theta), -math.sin(theta), 0, math.sin(theta), math.cos(theta)]).reshape(3, 3) 所以 ^B_PR 可以用程序求得： R_BP = R_BC*np.identity(3) print(\"旋转矩阵R_BP：\\n\",R_BP) 2.2.2 平移矩阵求解 根据复合变换规则可知： ^B_PP=^B_CR^C_PP+^B_CP 根据描述有： ^B_CP=[0,0,3]^T 、 ^C_PP=[2,1,2]^T 所以可以写这样写程序： P_BC = np.asarray([0, 0, 3]).reshape(3, 1) P_CP = np.asarray([2, 1, 2]).reshape(3, 1) P_BP = np.add(np.dot(R_BC, P_CP), P_BC) print(\"位置矢量P_BP:\\n\", P_BP.T) 运行下，可以得到结果 2.3 结果对比 与上节课答案一致 位置矢量： [2,-1,1]^T 旋转矩阵： \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & -1 & 0\\\\ 0 &0 & -1\\\\ \\end{bmatrix} \\tag{提示：重要方程1} "},"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/003-姿态的不同表示.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/003-姿态的不同表示.html","title":"姿态的不同表示","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 3.姿态的不同表示 本节课，我们来学习姿态的多种表示方式。在前面的课程中，我们一共接触了三种姿态的表示方式： 旋转矩阵-在位姿描述一节中 坐标轴旋转-绕xyz轴旋转不同的角度(欧拉角) 四元数-ROS2的TF2中的姿态描述 本节将对以上的三种姿态描述进行归类与介绍，并对他们之间的转换方法进行讲解，下一节带你一起通过代码直观的观察和操作姿态变换。 将常用的坐标描述分为三类，共五种。这五种也是在平时工作中所接触到的几乎所有姿态描述方法，三类共五种方法如下： 旋转矩阵-旋转矩阵 坐标轴旋转-固定轴欧拉角,非固定轴欧拉角 任意轴旋转-等效轴角,四元数 常用的坐标转换包括： 固定角与四元数互转 固定角与旋转矩阵互转 四元数与旋转矩阵互转 1.旋转矩阵 关于旋转矩阵我们在前几节教程中已经介绍了，旋转矩阵采用的是旋转后的坐标系三个轴分别与原坐标系三个轴的夹角余弦值共九个数字组成的3*3矩阵。 旋转矩阵一般记作 R 若两个坐标系姿态相同，其旋转矩阵为单位矩阵。 1.1 旋转矩阵的描述 如图，描述坐标系{P}和参考坐标系{A}之间的姿态关系的旋转矩阵用符号 {^A_P}R 来表示。 {^A_P}R=[{^A}x_{P} \\ {^A}y_{P} \\ {^A}z_{P}] = \\begin{bmatrix}{r_{11}}&{r_{12}}&{r_{13}}\\\\{r_{21}}&{r_{22}}&{r_\r {23}}\\\\{r_{31}}&{r_{32}}&{r_{33}}\\\\\\end{bmatrix} \\tag{旋转矩阵} 两个向量的点乘=两个向量的长度(1)与它们夹角余弦的积，所以 r11 可以表示为向量 P_{x} 与 A_{x} 的点积，旋转矩阵就可以写为下面的形式 {^A_P}R = \\begin{bmatrix} {P_{x}\\cdot A_x} & {P_{y}\\cdot A_x} & {P_{z}\\cdot A_x}\\\\ {P_{x}\\cdot A_y} & {P_{y}\\cdot\r A_y} & {P_{z}\\cdot A_y}\\\\ {P_{x}\\cdot A_z} & {P_{y}\\cdot A_z} & {P_{z}\\cdot A_z}\\\\ \\end{bmatrix} 1.2 绕某一轴旋转 \\theta 角的旋转矩阵 新的坐标系绕原坐标系某一坐标轴旋转任意角度得到的旋转矩阵有如下等式。 绕x轴旋转 \\theta 后姿态矩阵 R(x,\\theta)= \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & {cos\\theta} & -sin\\theta \\\\ 0&{sin\\theta} & cos\\theta \\\\ \\end{bmatrix}\r 绕y轴旋转 \\theta 后姿态矩阵 R(y,\\theta)= \\begin{bmatrix} {cos\\theta} & 0 & {sin\\theta}\\\\ 0 &1 &0\\\\ {-sin\\theta} & 0 &cos\\theta \\\\ \\end{bmatrix}\r 绕z轴旋转 \\theta 后姿态矩阵 R(z,\\theta)= \\begin{bmatrix} {cos\\theta} & -sin\\theta & 0\\\\ {sin\\theta} & cos\\theta & 0\\\\ {0} &0 &1\\\\ \\end{bmatrix}\r 2.欧拉角-绕坐标轴的旋转 2.1 12种旋转顺序 旋转矩阵是一个冗余的（九个值之间存在约束关系），可以只需要三个参数来表示的矩阵。假如知道坐标系绕分别绕X、Y、Z轴的旋转角度，不就同样可以表示旋转了吗？ 这个猜想是对的，结合1.2中绕三个轴旋转的三个 \\theta ，按照特定的顺序将对应的旋转矩阵乘起来就可以确定一个旋转矩阵。 但需要注意的是，矩阵的乘法不具备交换性，所以旋转顺序不同会造成不同的结果。 比方说若是先绕自身 x 轴旋转 \\alpha ，再绕自身 y 轴旋转 \\beta ： R(x,\\alpha)R(y,\\beta)= \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & {cos\\alpha} & -sin\\alpha \\\\ 0&{sin\\alpha} & cos\\alpha \\\\\r \\end{bmatrix} \\begin{bmatrix} {cos\\beta} & 0 & {sin\\beta}\\\\ 0 &1 &0\\\\ {-sin\\beta} & 0 &cos\\beta \\end{bmatrix} = \\begin{bmatrix} {cos\\beta} & 0 & {sin\\beta}\\\\ sin\\alpha sin\\beta &cos\\alpha & -sin\\alpha cos\\beta\\\\ {-cos\\alpha\r sin\\beta} & sin\\alpha &cos\\alpha cos\\beta \\\\ \\end{bmatrix} 比方说若是，先绕自身 y 轴旋转 \\beta ，绕自身 x 轴旋转 \\alpha ： R(y,\\beta)R(x,\\alpha)= \\begin{bmatrix} {cos\\beta} & 0 & {sin\\beta}\\\\ 0 &1 &0\\\\ {-sin\\beta} & 0 &cos\\beta \\\\\r \\end{bmatrix} \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & {cos\\alpha} & -sin\\alpha \\\\ 0&{sin\\alpha} & cos\\alpha \\\\ \\end{bmatrix} = \\begin{bmatrix} cos\\beta & sin\\alpha sin\\beta & {sin\\beta}\\\\ 0 & {cos\\alpha} & -sin\\alpha \\\\ {-sin\\beta} & sin\\alpha\r &cos\\alpha sin\\beta \\\\ \\end{bmatrix} 所以我们对旋转顺序做排列组合，可以得到12种旋转顺序: xyz,xyx, xzy xzx,yzx, yzy yxz, yxy , zxy zxz, zyx, zyz 2.2 两种参考坐标系 除了要考虑旋转时所绕轴的顺序，还要考虑参考坐标系（坐标轴）的不同。 2.2.1 参考固定的坐标系 假设坐标系B与坐标系A初始姿态相同 坐标系{B}绕坐标系A的x轴Ax旋转 \\alpha 接着坐标系{B}绕着A的y轴Ay旋转 \\beta 接着绕Az旋转 \\gamma 上述三次旋转，都是以A坐标系的xyz轴为参考坐标系进行旋转，该旋转方式为固定旋转轴的旋转，通常称之为固定角欧拉角或固定轴旋转。 2.2.2 参考自身坐标系 我们也可以不沿着坐标系A的各轴旋转，而是绕旋转之后B的某一轴再次旋转，我们称之为非固定旋转轴的欧拉角。 说：无论是参考自身坐标系还是参考固定的坐标系，都有12种旋转方式，所以欧拉角有12*2=24种旋转方式，后面的计算中我们也将直观的感受到24种旋转方式的不同。 2.3 固定转轴欧拉角 转 旋转矩阵 首先我们来考虑绕固定的坐标系旋转如何转换成旋转矩阵 我们以XYZ的旋转顺序来举例说明，其他旋转顺序类似 现在假设A、B两个坐标系重合，B坐标系绕A坐标系的X轴旋转45度，绕A的Z轴旋转90度. 求旋转之后A为参考坐标系，B坐标系的姿态 ^A_BR_{XYZ(45,0,90)} 先告诉你最终的结果： ^A_BR_{XYZ(45,0,90)}=R_{Z(90)}R_{Y(0)}R_{X(45)}=R_{Z(90)}R_{X(45)}=\\begin{bmatrix} 0.&-0.70710678 & 0.70710678\\\\\r -1&0&0\\\\ 0&0.70710678&0.70710678\\\\ \\end{bmatrix} 为什么结果是将绕Z轴的旋转矩阵乘绕X轴的旋转矩阵呢？ 这里引用林沛群老师的解释： 我们可以假设一个向量v固定在B坐标系上，那我们让B坐标系绕着A坐标系的三个轴做旋转，就可以认为是让向量v绕着坐标系A的三个轴做旋转，那先转的肯定先乘，所以我们先让向量v乘上Rx(45)，再让其乘上Rz(90)，即： v' = R_{Z(90)}(R_{X(45)}v) 根据矩阵乘法的结合律，括号可以去掉： v' = R_{Z(90)}R_{X(45)}v 所以我们可以得到，绕固定轴XYZ旋转的欧拉角转旋转矩阵方法: R_{XYZ(\\gamma,\\beta,\\alpha)}=R_{Z(\\alpha)}R_{Y(\\beta)}R_{X(\\gamma)} 最终结果： 根据旋转顺序不同，固定角有12种旋转方式，这里我们给出了绕固定轴以XYZ顺序旋转欧拉角的转旋转矩阵的等式，其他旋转顺序对应的旋转矩阵可以尝试自行推导。 2.2 非固定旋转轴的欧拉角 非固定旋转轴，即每次旋转是绕着自身的坐标轴进行旋转，其旋转动图如2.2.2节所示。 非固定旋转的欧拉角转旋转矩阵推导也很简单，我们以旋转顺序ZYX为例子分析 2.2.1 ZYX 因为每次旋转都是绕着自身进行的，我们可以将每次的旋转进行拆解 ^A_BR={^A_{B'}R}{^{B'}_{B''}R}{^{B''}_{B}R} 等式右边的三次旋转按照顺序Z-Y-X进行的，所以最终B坐标系在A坐标系下的姿态为： ^A_BR_{Z'Y'X'}=R_{Z(\\alpha)}R_{Y(\\beta)}R_{X(\\gamma)} 最终结果太难敲，直接截图啦 旋转矩阵转欧拉角的方法需要使用双参变量的反正切函数，我们后面在程序当中直接调用对应函数即可实现，这里对原理就不再进行推导了 3.轴角 在介绍四元数之前，我们先来说说等效角度轴线，这种表示姿态的方式。 上一节欧拉角中无论是绕着自身的某个轴旋转，还是绕着固定的坐标系的某个轴进行旋转，旋转时参考的轴都是坐标系的主轴 假如我们参考的轴不是主轴，那么任何姿态都可以通过选择适当的轴和角度得到，换句话说，两个坐标系之间的任何姿态都可以通过绕某一个特定的轴(矢量)旋转特定的角度得到。 说到这里相信你已经理解了轴角的意义，接着我们给出轴角和旋转矩阵之间的转换关系 轴角转旋转矩阵 假设坐标系B和参考坐标系A重合，将B绕着A坐标系下的矢量 ^AK 按右手定则旋转 \\theta 角度，旋转之后B坐标系在A坐标系下的姿态可以用 ^A_BR(K,\\theta) 表示，注意矢量K为单位矢量(模长为1)，K为一个3*1的矢量 ^AK=[k_x,k_y,k_z]^T 在已知矢量K和 \\theta 的情况下，我们如何得到旋转矩阵呢? 有等式： 其中 c\\theta=cos\\theta \\\\ s\\theta=sin\\theta \\\\ v\\theta=1-cos\\theta \\theta 的符号由右手定则确定，右手大拇指指向矢量K的方向. 旋转矩阵转轴角需要根据情况讨论，该部分转换我们直接调用相应函数实现，这里对其原理不再叙述，感兴趣的同学可以参考：https://en.wikipedia.org/wiki/Rotation_matrix#Axis_of_a_rotation 4.四元数 除了轴角可以使用一个数字表示角度，三个数字表示旋转轴，一共四个数字表示旋转外。还有另外一种四个数字表示表示旋转的方式——四元数。 四元数的四个数字由一个实部和三个虚部组成，是一个超复数形式 q = w + x*i+ y*j + z*k 关于四元数的由来有个小故事，分享一下： 1843年10月16日的傍晚，英国数学家哈密顿和他的妻子一起步行去都柏林，途中经过布鲁哈姆桥时，他的脚步突然放慢了。妻子以为他要尽情欣赏周围的景色，于是也放慢了脚步。其实哈密顿此时正在思考他久久不能解决的问题。早在1828年，他就想发明一种新的代数，用来描述绕空间一定轴转动并同时进行伸缩的向量的运动。他设想这种新代数应包含四个分量：两个来固定转动轴，一个来规定转动角度，第四个来规定向量的伸缩。但是在构造新代数的过程中，由于他受传统观念的影响，不肯放弃乘法交换律，故屡受挫折。哈密顿盲目地相信，普通代数最重要的规律必定继续存在于他寻找的代数中。然而此刻，他的脑际突然产生了一个闪念：在所寻找的代数中，能否让交换律不成立呢？比方说，A×B不等于B×A而是等于负的B×A。这个想法太大胆了，他感到非常激动。哈密顿马上掏出笔记本，把他的思想火花记录下来。这一火花就是I，J，K之间的基本方程，即四元数乘法基本公式。哈密顿因此把1843年10月16日称为四元数的生日。此后，哈密顿一生的最后22年几乎完全致力于四元数的研究，成果发表在他去世后出版的《四元数基础》一书中。四元数的出现，推倒了传统代数的关卡，故有数学史上里程碑的美誉。后人为了纪念这一发明，特意在当年哈密顿刻划过的石头上镶嵌了一块水泥板，上面清楚地记载着1843年曾经发生的故事。 四元数在机器人中使用的非常多，甚至在量子力学中都有使用，关于四元数旋转的本质，也学习了很久才搞清楚，B站上3B1B的视频非常经典，大家自行食用。 在机器人学当中用到的四元数都是单位四元数（四维单位超球体在三维空间的投影）,下文中提到的四元数默认指单位四元数 接着我们来说说四元数常用的转换 四元数转旋转矩阵 旋转矩阵转四元数 四元数转欧拉角 欧拉角转四元数 轴角转四元数 轴: ^AK=[k_x,k_y,k_z]^T 角: \\theta x= k_x\\sin(\\theta/2)\\\\ y= k_y\\sin(\\theta/2) \\\\ z= k_z\\sin(\\theta/2)\\\\ w = \\cos(\\theta/2) [w, x, y, z]中， [1, 0, 0, 0] 表示不做任何操作，没有旋转； 小计算: w^2+x^2+y^2+z^2=1 "},"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/004-姿态转换实战.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/004-姿态转换实战.html","title":"姿态转换实战","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 4.姿态转换实战 这节课我们就利用相关的开源库，来完成姿态的不同表示方式之间的转换。 包含12中转换形式，其中一些转换的计算方式，前面几节课中有给出相应的公式。 四元数模块:quaternions 四元数 转 旋转矩阵 旋转矩阵 转 四元数 四元数 转 轴角 轴角 转 四元数 欧拉模块:euler 欧拉角 转 四元数 四元数 转 欧拉角 欧拉角 转 旋转矩阵 旋转矩阵 转 欧拉角 欧拉角 转 轴角 轴角 转欧拉角 轴角模块:axangles 轴角 转 旋转矩阵 旋转矩阵 转 轴角 本节主要推荐的是Python的相关实现，用的是常用的transforms3d库,该库的api设计非常的巴适，是非常的爱~ 1.安装 安装使用pip即可 pip install transforms3d -i https://pypi.tuna.tsinghua.edu.cn/simple 2.四元数相关转换 四元数模块在transforms3d.quaternions里，直接导入即可使用 2.1 四元数与旋转矩阵互转 import transforms3d as tfs import numpy as np # 四元数转旋转矩阵 tfs.quaternions.quat2mat([1,0,0,0]) # 旋转矩阵转四元数 tfs.quaternions.mat2quat(np.asarray([[1., 0., 0.],[0., 1., 0.],[0., 0., 1.]])) 2.2 四元数与轴角互转 import transforms3d as tfs import numpy as np # 四元数转旋轴角 tfs.quaternions.quat2axangle([1,0,0,0]) # 轴角转四元数 tfs.quaternions.axangle2quat([1,0,0],0.5) 3.欧拉角相关转换 四元数模块在transforms3d.euler里，直接导入即可使用 3.1 欧拉角与四元数互转 import transforms3d as tfs import numpy as np # 固定轴欧拉角转四元数 tfs.euler.euler2quat(0,0,0,\"sxyz\") # 四元数转固定轴欧拉角 tfs.euler.quat2euler([1,0,0,0],\"sxyz\") 3.2 欧拉角与旋转矩阵互转 import transforms3d as tfs import numpy as np # 固定轴欧拉角转旋转矩阵 tfs.euler.euler2mat(0,0,0,\"sxyz\") # 旋转矩阵转固定轴欧拉角 tfs.euler.mat2euler(np.asarray([[1., 0., 0.],[0., 1., 0.],[0., 0., 1.]]),\"sxyz\") 3.3 欧拉角与轴角互转 import transforms3d as tfs import numpy as np # 固定轴欧拉角轴角 tfs.euler.euler2axangle(0,0,0,\"sxyz\") # 轴角转固定轴欧拉角 tfs.euler.axangle2euler([1,0,0],0.5,\"sxyz\") 4.轴角相关转换 四元数模块在transforms3d.axangle里，直接导入即可使用 4.1 轴角与旋转矩阵互转 import transforms3d as tfs import numpy as np # 轴角转旋转矩阵 tfs.axangles.axangle2mat([1,0,0],0.5) # 旋转矩阵转轴角 tfs.axangles.mat2axangle(np.asarray([[1., 0., 0.],[0., 1., 0.],[0., 0., 1.]])) 5.C++实现Eigen 开源地址,欢迎一起加入完善: https://gitee.com/ohhuo/transforms3d_cpp 参考文档： http://matthew-brett.github.io/transforms3d/ "},"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/005-齐次坐标变换.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/005-齐次坐标变换.html","title":"齐次坐标变换","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 5.齐次坐标变换 前面几节中，学习了使用TF进行坐标的变换，也带你通过旋转和平移求解了坐标的变换关系，但计算的过程中旋转和平移是分开计算的，那有没有一种方法，可以让旋转矩阵和平移向量合并到同一个矩阵里呢？ 答案是有的，我们可以将 3*3 的旋转矩阵和 3*1 的平移矩阵进行组合，并添加一行(0,0,0,1)使其变成一个 4*4 的方阵，其组合方式如下： 有旋转矩阵 R = \\begin{bmatrix}{r_{11}}&{r_{12}}&{r_{13}}\\\\{r_{21}}&{r_{22}}&{r_{23}}\\\\{r_{31}}&{r_{32}}&{r_{33}}\\\\\\end{bmatrix}\r \\tag{旋转矩阵} 平移矩阵 P= \\begin{bmatrix}{x}\\\\{y}\\\\{z}\\\\\\end{bmatrix} \\tag{平移矩阵} 合并成齐次变换矩阵 T = \\begin{bmatrix}{r_{11}}&{r_{12}}&{r_{13}}&{x} \\\\{r_{21}}&{r_{22}}&{r_{23}}&{y} \\\\{r_{31}}&{r_{32}}&{r_{33}}&{z}\r \\\\0&0&0&1 \\\\\\end{bmatrix} \\tag{齐次矩阵} 为什么要这样写，我们可以简单的推导一下，矩阵是支持分块运算的，我们将上面的矩阵进行分块 T = \\begin{bmatrix}{R}&{P} \\\\0&1\\\\\\end{bmatrix} \\tag{齐次矩阵} 假设 ^A_BT 表示B坐标系到A坐标系的齐次变换，B坐标系下的点C坐标为 ^B_CP ，求C在A坐标系下的坐标 ^A_CP 我们将 ^A_BT 乘 ^B_CP 上，可得 ^A_CP= \\begin{bmatrix}{^A_BR}&{^A_BP}\\\\0&1\\\\\\end{bmatrix} \\begin{bmatrix}{^B_CP}\\\\1\\\\\\end{bmatrix} =\r {^A_BR}{^B_CP}+^A_BP 根据前面学习的平移+旋转复合坐标变换公式，正确的结果如下 ^A_CP = {^A_BR}{^B_CP}+^A_BP 你会发现，两者最终结果完全相同，也就是说，我们的平移加旋转复合变换，可以直接用齐次变换矩阵代替。 1.齐次变换矩阵特性 接着我们来探索一下齐次变换矩阵的一些特性 2.1.齐次变换矩阵的符号表示 一般使用H或者T来表示齐次变换矩阵，矩阵的左上角标明参考坐标系，矩阵左下角标明目标坐标系，比如 ^A_BT 表示B坐标系到A坐标系的变换关系(平移+旋转) 2.2.齐次变换矩阵的逆的几何含义 就像矩阵的逆一样，齐次变换矩阵也有逆，其逆也有对应的几何含义，比如 比如 ^A_BT 表示B坐标系到A坐标系的变换关系 那么 ^A_BT 的逆 ^A_BT^{-1}=^B_AT 表示A坐标系到B坐标系的变换关系 2.3.齐次变换矩阵的乘法的几何含义 3.3.1齐次矩阵与平移向量相乘 齐次矩阵与平移向量相乘，即可求出某个向量在另一坐标系下的表示，上面例子中即是如此。 3.3.2齐次矩阵与齐次矩阵相乘 齐次矩阵与齐次矩阵相乘，可以转换不同坐标系之间的关系，比如： ^A_BT^B_CT=^A_CT 比如当我们有一个六自由度的机械臂，知道两两相邻关节之间的关系，那么就可以通过其次矩阵相乘的方法求出，关节6在关节0下的位置和姿态： ^0_1T^1_2T^2_3T^3_4T^4_5T^5_6T=^0_6T "},"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/006-齐次坐标变换实战.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/006-齐次坐标变换实战.html","title":"齐次坐标变换实战","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 6.齐次坐标变换实战 上一节我们对齐次矩阵的组成和齐次矩阵的求逆和乘法两个运算的几何意义进行了介绍。 本节课我们就通过对应的函数和库实现齐次矩阵的生成，齐次矩阵的乘法和求逆。 1.齐次矩阵的合成与分解 齐次矩阵的的生成可以一个姿态和一个平移向量组成，因为姿态可以用四元数、欧拉角、轴角、旋转矩阵四种方式来表示 所以我们考虑先将对应的姿态转成旋转矩阵，然后使用numpy讲旋转矩阵和平移向量填写到齐次矩阵对应的位置即可 1.1旋转矩阵+平移向量 #导入库 import numpy as np import transforms3d as tfs # 定义旋转矩阵R和平移向量T R = np.asarray([[1., 0., 0.],[0., 1., 0.],[0., 0., 1.]]) T = np.asarray([1,0,1]) R,T 1.1.1 使用numpy方法合成齐次变换矩阵 temp = np.hstack((R,T.reshape(3,1))) np.vstack((temp,[0,0,0,1])) 1.1.2 使用tfs中的函数合成齐次变换矩阵 tfs.affines.compose(T,R,[1,1,1]) 1.2四元数+平移向量 思路:先将四元数转换成旋转矩阵，然后再利用1.1合成齐次矩阵 R = tfs.quaternions.quat2mat([1,0,0,0]) tfs.affines.compose(T,R,[1,1,1]) 1.3 练习 1.3.1 练习1 已知相机坐标系{C}为参考坐标系，工具坐标系{P}的位置矢量在相机坐标系{C}x,y,z各轴投影为 2,1,2 ，并且工具坐标系和相机坐标系姿态相同，求 ^C_PT 1.3.2 练习2 已知机器人基坐标系{B}为参考坐标系，相机坐标系{C}在的位置矢量在{B}各轴的投影为 0,0,3 ,坐标系{C}和绕着坐标系{B}的x轴转了180度，求 ^B_CT 2.齐次矩阵的分解 齐次矩阵的分解指的是已有齐次矩阵的情况下，将其分解为姿态和平移两部分 2.1 将qcjz分解为固定轴欧拉角和平移向量 tfs.euler.mat2euler(T[0:3,0:3]),T[:3,3:4] 2.3 将qcjz分解为四元数和平移向量 tfs.quaternions.mat2quat(T[0:3,0:3]),T[:3,3:4] 3.齐次矩阵的乘法 对应numpy中矩阵的乘法np.dot讲两个矩阵相乘即可，我们以一道例题来讲解这个问题。 3.1 练习-眼在手外 如图🔓示，已知： 1.相机坐标系{C}为参考坐标系，工具坐标系{P}的位置矢量在相机坐标系{C}x,y,z各轴投影为 2,1,2 ，并且工具坐标系和相机坐标系姿态相同。 2.机器人基坐标系{B}为参考坐标系，相机坐标系{C}在的位置矢量在{B}各轴的投影为 0,0,3 ,坐标系{C}和绕着坐标系{B}的x轴转了180度 可以参考下图看题目 求： {B}为参考坐标系，坐标系{P}的位置矢量和旋转矩阵 解体思路也很简单，我们只要得出 B到C的齐次变换矩阵 ^B_CT C到P的齐次变换矩阵 ^C_PT 得到之后将两者相乘即可得出： ^B_PT=^B_CT^C_PT 求出 ^B_PT 我们再将其分解成位置矢量和旋转矩阵即可 动手写代码： 先求T_BC import math T_BC = tfs.affines.compose([0,0,3],tfs.euler.euler2mat(math.pi,0,0),[1,1,1]) T_BC 再求T_CP T_CP = T = tfs.affines.compose([2,1,2],np.identity(3),[1,1,1]) T_CP 求T_BP T_BP = np.dot(T_BC,T_CP) T_BP 分解成欧拉角对比结果 tfs.euler.mat2euler(T_BP[0:3,0:3]),T_BP[:3,3:4] 到这里我们就利用做了齐次矩阵的乘法完成了坐标的变换 3.齐次矩阵求逆 3.1练习-眼在手上 如图机器人基座坐标系为B、末端坐标系为E、相机坐标系为C、物品坐标系为O、其中相机固定在机械臂的末端。 已知 ^B_ET={ xyz:[0.5,0.6,0.8] ,qwqxqyqz:[1,0,0,0]} \\\\ ^C_ET={ xyz:[0.00,0.05,0.05] ,qwqxqyqz:[0.707, 0.706, 0,0]} \\\\ ^C_OT={ xyz:[0.00,0.02,0.85] ,qwqxqyqz:[0.877,0.479,0,0]} \\\\ 求： ^B_OT ^B_OT=^B_ET^E_CT^C_OT^E_CT=^C_ET^{-1} 写代码： T_BE = tfs.affines.compose([0.5,0.6,0.8],tfs.quaternions.quat2mat([1,0,0,0]),[1,1,1]) T_CE = tfs.affines.compose([0.00,0.05,0.05],tfs.quaternions.quat2mat([0.707,0.706,0,0]),[1,1,1]) T_CO = tfs.affines.compose([0.00,0.02,0.85],tfs.quaternions.quat2mat([0.877,0.479,0,0]),[1,1,1]) T_EC = np.linalg.inv(T_CE) np.dot(np.dot(T_BE,T_EC),T_CO) 4.练习 4.1 map坐标系转换 在移动机器人导航中，存在这样一个坐标系关系. 地图坐标系(Map)->里程计坐标系(Odom)->机器人坐标系(BaseLink) 其中里程计到机器人坐标系关系一般是由底盘轮子编码器给出，而地图坐标系和里程计坐标系之间的关系是通过定位模块估算出来的。 所以请听题目： 现在通过地图匹配获取到机器人在地图中的位置为[1.5,2.3,0],姿态(固定轴欧拉角)为[0,0,3.14] 查看里程计上报的机器人坐标为：位置[1.0,3.2,0] 姿态(固定轴欧拉角)[0,0,1.0] 求地图坐标系和里程计坐标系之间的关系 4.2 机械臂运动学正解 已知一个3自由的机械臂，已知: 关节1和关节2坐标关系为:[0,0,0.2] 固定轴欧拉角:[0,0,1.57] 关节2和关节3坐标关系为:[0.5,0,0.0] 固定轴欧拉角:[0,0,1.0] 求关节1和关节3之间的关系？ "},"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/007-机器人运动学介绍.html":{"url":"ROS2/机器人学篇/第6章-运动学基础/入门-机器人运动学/007-机器人运动学介绍.html","title":"机器人运动学介绍","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 7. 机器人运动学介绍 机器人学是一个非常庞大的学科，凡是和机器人设计应用相关的都可以划分到机器人学中，主要有运动学和动力学、系统结构、感知传感技术、运动规划技术、决策技术等。 为了方便后面的机器人建模和仿真，本节我们对机器人的运动学进行简单的介绍和学习。 1.机器人运动学 机器人运动学研究机器人的位姿关系，主要包含正向运动学和逆向运动学两类。 正向运动学即给定机器人各关节变量，计算机器人末端的位置姿态；比如上节课我们已知机器人关节和关节之间的关系，求关节1和关节3之间的关系 逆向运动学即已知机器人末端的位置姿态，反求机器人的关节变量；比如当我们已知机器人关节1和关节3之间的关系，求关节关节1和关节2，关节2和关节3之间关系。 2.机械臂运动学介绍 正运动学：已知每个关节的角度，求末端的位姿 逆运动学：已知末端姿态，求每一个关节的角度 3.两轮差速底盘运动学介绍 两轮差速模型指机器人底盘由两个驱动轮和若干支撑轮构成的底盘模型，像turtlebot和开源机器人fishbot都是两轮差速模型。 两轮差速模型通过两个驱动轮可以通过不同转速和转向，使得机器人的达到某个特定的角速度和线速度。 两轮的平衡车大家都见过吧，靠着两个轮子即可实现前后移动（线速度），左转右转（角速度）。 3.1 正逆解 了解了两轮差速模型，那正逆解又是怎么回事？ 正运动学：已知两个轮子的速度，求整车的角速度（弧度/秒）和线速度（米/秒） graph LR; A[左轮当前速度]-->B[正运动学] D[右轮当前速度]-->B B-->C[机器人当前角速度] B-->E[机器人当前线速度] 逆运动学：已知目标角速度和线速度，求两个轮子的转速 graph LR; A[机器人目标线速度]-->C[运动学逆解] B[机器人目标角速度]-->C C-->D[左轮目标速度] C-->E[右轮目标速度] 3.2轮式里程计 graph LR; A[左右轮当前速度/位置]-->B[里程计推算] B-->C[里程计-odom] 当我们知道了两个轮子之间的相对位置，同时知道了每一时刻机器人的角速度和线速度，那我们如何获取机器人的当前角度和位置呢？ 3.2.1 角度 影响机器人当前角度的因素只有一个，就是角速度。 某一时刻机器人转动的角度 = 这一时刻机器人的角速度*这一时刻时长 假如我们认定初始时刻机器人的角度为0,通过对机器人转动角度角度进行累加，即可获得机器人的当前角度。 上述过程其实就是对角速度进行积分得到角度。 3.2.2 位置 通过对角速度积分，我们得到了角度。 机器人某一时刻自身方向上的前进速度可以分解为里程计坐标系中x轴和y轴方向上的速度。 从图中可以看出： v_y = v*cos(\\theta) \\\\ v_y = v*sin(\\theta) 得到了x和y方向上的速度，乘上该速度对应的某一时刻经过的时间，即可得到这一时刻在x轴和y轴方向上的位移，对位移进行累加即可得到里程计中的x和y。 "},"ROS2/机器人学篇/第7章-ROS2运动学/001-TF2介绍及RVIZ-TF组件.html":{"url":"ROS2/机器人学篇/第7章-ROS2运动学/001-TF2介绍及RVIZ-TF组件.html","title":"TF2介绍及RVIZ-TF组件","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 1.tf2介绍 TF即变换的英文单词TransForm的缩写。所以ROS和ROS2中的TF就是指和坐标变换相关的工具。 在搞机器人当中，坐标变换经常用到，所以ROS2帮我们做了一个强大易用的TF工具 1.发布坐标关系 我们先使用TF2的相关工具，解决上一节的手眼坐标转换问题，直观的感受一下TF2的强大。 要想让TF帮我们完成坐标变换，我们就需要告诉它坐标和坐标之间的关系。 拿上面的手眼系统来说，我们要想获取到相机的基坐标系{B}和工具{P}之间的关系，只需要将机械臂和相机、相机和工具之间的关系告诉TF即可。 2.我们如何告诉TF？ 可以使用tf的坐标广播工具进行广播坐标关系，广播时需要三个数据： 父坐标系名称（字符串） 子坐标系名称（字符串） 父子之间的变换关系（平移关系和旋转关系） 在终端中输入： ros2 run tf2_ros static_transform_publisher 按enter键，可以看到 A command line utility for manually sending a transform. Usage: static_transform_publisher x y z qx qy qz qw frame_id child_frame_id OR Usage: static_transform_publisher x y z yaw pitch roll frame_id child_frame_id 这是该CLI所提供的使用提示，可以看出 使用TF发布位置和姿态时，位置的描述使用的是xyz三个参数，而姿态的描述则分两种 第一种是四元数形式（qx qy qz qw） 第二种是欧拉角形式（yaw偏航角-rz pitch俯仰角-ry roll滚转角-rx），我们这里采用的是欧拉形式，绕x轴旋转采用欧拉角中的滚转角roll来描述，注意角度单位采用弧度制。 关于欧拉角和四元数的区别我们放到了姿态的多种表示章节来讲。 2.1 发布B到C的位姿 比如针对上面的手眼转换，广播机械臂坐标系{B}和相机坐标系{C}之间的关系。 父坐标系的名字就是B，子坐标系的名字是C，父子之间的平移关系是0 0 3,旋转关系是绕x轴旋转180度。 在ROS2中可以使用下面的指令发布变换，打开终端，输入下面的指令： ros2 run tf2_ros static_transform_publisher 0 0 3 0 0 3.14 B C 如果在终端中看到下面的提示则代表发布成功 2.2 发布C到P的位姿 接着我们发布坐标系{C}到坐标系{T}的位姿 再打开一个新的终端，输入下面的命令： ros2 run tf2_ros static_transform_publisher 2 1 2 0 0 0 C P 3. 监听/获取TF关系 发布也发布了，接着我们就把坐标系之间的关系打印出来，只要坐标系之间是有连接的，我们就可以使用TF求出来，使用下面的指令就可以得到机械臂基坐标系{B}和工具坐标系{P}之间的关系。 打开终端,输入命令： ros2 run tf2_ros tf2_echo B P 可以看到终端中不断输出B和C之间的平移和旋转，平移采用的是xyz，基本正确，y和z的微小差异是因为我们发布变换时旋转输入的是3.14并不精确。 至于旋转部分采用的是四元数表示，关于这部分姿态的表示，之前的章节讲过。 除了使用TF获取关系外，ros2还提供很多工具来查看坐标之间的关系，大家可以在终端中输入下面的命令自行尝试。 4.TF常用工具 4.1 rqt_tf_tree 2022-04-26更新的，这个工具的二进制安装版本作者3月底才发布，之前没提的原因是需要源码装太麻烦了 这个工具需要我们手动安装下 sudo apt install ros-humble-rqt-tf-tree 安装完成后，再次打开rqt工具，Plugins->Visualization->TF Tree 接着你就可以看到这个强大的，几乎可以实时看到系统tf更新信息的工具，这个工具对于后面我们进行导航和机械臂的调试非常有帮助。 长的不一样没关系，这是后面补充的图。 如果打开后没有该选项：rm ~/.config/ros.org/rqt_gui.ini 4.2 tf2_monitor 查看所有的发布者和频率。 ros2 run tf2_ros tf2_monitor Gathering data on all frames for 10 seconds... RESULTS: for all Frames Frames: Frame: C, published by , Average Delay: 3001.98, Max Delay: 3001.98 Frame: P, published by , Average Delay: 741.497, Max Delay: 741.497 All Broadcasters: Node: 5029.14 Hz, Average Delay: 1871.74 Max Delay: 3001.98 RESULTS: for all Frames Frames: Frame: C, published by , Average Delay: 3001.98, Max Delay: 3001.98 Frame: P, published by , Average Delay: 741.497, Max Delay: 741.497 All Broadcasters: Node: 5029.14 Hz, Average Delay: 1871.74 Max Delay: 3001.98 view_frames.py 可以生成TF的pdf，目前也有在线的实时查看工具。 ros2 run tf2_tools view_frames.py [INFO] [1636558316.667894410] [view_frames]: Listening to tf data during 5 seconds... [INFO] [1636558321.702280144] [view_frames]: Generating graph in frames.pdf file... [INFO] [1636558321.709904442] [view_frames]: Result:tf2_msgs.srv.FrameGraph_Response(frame_yaml=\"C: \\n parent: 'B'\\n broadcaster: 'default_authority'\\n rate: 10000.000\\n most_recent_transform: 0.000000\\n oldest_transform: 0.000000\\n buffer_length: 0.000\\nP: \\n parent: 'C'\\n broadcaster: 'default_authority'\\n rate: 10000.000\\n most_recent_transform: 0.000000\\n oldest_transform: 0.000000\\n buffer_length: 0.000\\n\") /opt/ros/humble/lib/tf2_tools/view_frames.py:75: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(result.frame_yaml) 除了使用命令行进行坐标关系的广播和监听，我们还可以使用代码来广播和监听，接下来就带你一起用程序来发布TF广播和获取坐标关系。 2.可视化坐标变换 运行上节课的示例，打开终端输入rviz2，打开rviz2，我们尝试在rviz2中直观的看到坐标之间的关系 1.设置默认坐标系 刚打开RVIZ2，你看到的应该是这样一个界面 我们可以看到窗口左边的配置选项，全局选项默认选择的FixedFrame为map，这个map就是rviz2默认的坐标系的名字，动动脚趾头想一下我们并没有发布map这个坐标系，所以下面Global Status也是红色的错误。 此时我们可以手动的修改以下固定的Frame为B，让默认的坐标系设置成机械臂的基坐标系{B}。 设置完成后，错误也没有了，因为此时的ROS2的TF中确确实实找到了一个叫做B的坐标系。 2.添加TF插件 即使没有错误，现在我们还是看不到坐标系，这是为什么呢？RVIZ2是一个插件化的软件，所以我们要添加TF相关的插件才能看到TF数据。 点击左下角的Add，在弹出的窗口中选择TF点击OK 之后你在RVIZ2中就可以看到下图的坐标关系 终于显示出来了，但是没有名字又太小了，修改下左边的选项，勾选Show Names，修改Marker Scale 为5 如果觉得视角不好，可以使用鼠标左键右键以及按下滚轮拖动修改。 "},"ROS2/机器人学篇/第7章-ROS2运动学/002-坐标变换发布监听Python和Cpp实现.html":{"url":"ROS2/机器人学篇/第7章-ROS2运动学/002-坐标变换发布监听Python和Cpp实现.html","title":"坐标变换发布监听Python和Cpp实现","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 3.坐标变换发布监听Python实现 运行前面安装的jupyter，我们尝试使用代码来操作tf 在开始之前，我们总结下TF相关的操作有哪些？ 广播（TransformBroadcaster）：将坐标系鱼坐标系之间的位姿态关系发布出去 监听（TransformListener）：获取坐标系和坐标系之间的位姿关系 TF(坐标变换TransformStamped)帧：广播出去的一组数据可以称作一个TF帧，包含父坐标系名称、子坐标系名称，父坐标系和子坐标系之间的关系 接着我们就可以编写代码来实现上面对TF帧的发布和监听。 1.坐标变换广播 在进行坐标变换广播前，我们根据两个坐标系之间的关系是否会随着时间变化分成以下两种情况： 坐标系之间的关系不随时间推移而改变，称为静态坐标变换，需要使用静态广播发布器（StaticTransformBroadcaster）发布。比如：机器人的两个轮子之间关系，可以认为随时间的变换其相对位置不变。 坐标系之间的关系随时间的推移而改变，称为（动态）坐标变换，使用广播发布器（TransformBroadcaster）发布坐标关系。比如机器人在世界坐标系中的位置，因为机器人会动。 我们依然使用手眼系统为例，尝试使用广播发布器来发布坐标系之间的关系。 在手眼系统中，机械臂基座和相机坐标系之间的位置是固定不变的，我们可以通过静态广播发布器来发布，而相机坐标系下工件的位置是实时识别得到的，其值会随时间变化，故我们用广播发布器来发布。 2.静态广播发布器 在jupyter中输入并运行以下程序，使用方式就像ros2的话题发布，只不过不需要指名发布的话题（发布到系统的TF树上）。 原程序地址：[tf2_static_tf_publish.ipynb](https://fishros.com/d2lros2foxy/chapt7/7.2.2%E5%8A%A8%E6%89%8B%E5%AD%A6%E7%A9%BA%E9%97%B4%E5%A7%BF%E6%80%81%E6%8F%8F%E8%BF%B0/code/tf2_static_tf_publish.ipynb) --> 这里四元数的值需要通过在线的坐标转换获取，选择角度，绕x轴旋转180，上面就是对应的四元数，x,y,z,w为1,0,0,0 最后通过坐标监听工具可以查找出B和C之间的关系： 注意这里输出的At time 0.0 代表任意时刻 3.广播发布器 接着我们来使用广播发布器发布C和工具P之间的关系平移：x:2 y:1 z:2 旋转:qx:0 qy:0 qz:0 qw:1 只需要将上面的静态广播发布器改为广播发布器，但需要注意的是，发布坐标变换时要以一定的频率实时发布，这样当我们获取坐标时才能获取到当前时刻的坐标（有点不好理解，就是坐标关系和时间有关系）。 原程序地址：[tf2_tf_publish.ipynb](https://fishros.com/d2lros2foxy/chapt7/7.2.2%E5%8A%A8%E6%89%8B%E5%AD%A6%E7%A9%BA%E9%97%B4%E5%A7%BF%E6%80%81%E6%8F%8F%E8%BF%B0/code/tf2_tf_publish.ipynb) --> 同样也可以使用命令行获取到C和P之间关系。 也可以通过命令行获取到B和P之间关系，完成手眼转换 注意这里的结果中的时间：At time 1637494822.281105208.代表具体的某一个时刻，不同时刻坐标之间的平移和旋转可以不同 4.坐标变换监听 所谓坐标变换监听就是监听整个系统的坐标变换关系。 通过TransformListener即可获取到整个tf系统中窗口大小为10s的坐标关系，并且我们创建了一个buffer，TransformListener会把收到的坐标关系放入buffer 中，我们后面就可以通过buffer的lookup_transform()函数获取到坐标之间的关系。 原程序地址：[tf2_tf_listener.ipynb](https://fishros.com/d2lros2foxy/chapt7/7.2.2%E5%8A%A8%E6%89%8B%E5%AD%A6%E7%A9%BA%E9%97%B4%E5%A7%BF%E6%80%81%E6%8F%8F%E8%BF%B0/code/tf2_tf_listener.ipynb) --> 可以看到最终打印的结果和我们上面用命令行和numpy计算结果一致。 4.坐标变换发布监听C++实现 因为C++无法在jupyter中直接运行，所以小鱼将C++TF相关的代码放到这里，有需要的同学自取。 #include #include //声明&初始化发布者 std::unique_ptr tf_broadcaster_; tf_broadcaster_ = std::make_unique(this); //发布 geometry_msgs::msg::TransformStamped transform; transform.header.stamp = this->now(); transform.header.frame_id = \"odom\"; transform.child_frame_id = \"base_link\"; // Fill in transform.transform.translation transform.transform.translation.x = 0.0; transform.transform.translation.y = 0.0; transform.transform.translation.z =0.0; // Fill in transform.transform.rotation auto quat = tf2::Quaternion(); quat.setRPY(0.0;, 0.0, 0.0); transform.transform.rotation.x = 0.0; transform.transform.rotation.y = 0.0; transform.transform.rotation.z = 0.0; transform.transform.rotation.w = 0.0; tf_broadcaster_->sendTransform(transform); "},"ROS2/建模仿真篇/第8章-机器人建模/001-URDF统一机器人建模语言.html":{"url":"ROS2/建模仿真篇/第8章-机器人建模/001-URDF统一机器人建模语言.html","title":"URDF统一机器人建模语言","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 1. URDF统一机器人建模语言 本节课我们来介绍机器人的URDF建模。 URDF（Unified Robot Description Format）统一机器人描述格式，URDF使用XML格式描述机器人文件。 XML是 被设计用来传输和存储数据的可扩展标记语言，注意语言本身是没有含义的，只是规定了其数据格式 比如说下面这段信息： 具体的描述 具体的描述 具体的描述 XML格式在线校验工具:在线代码格式化 (oschina.net) XML格式注释： 标签: robot link robot标签的属性name: robot标签的子标签link: link> 使用XML定义的一个最简单的URDF模型可以像下面这样 接着我们从下面四个方面介绍URDF： URDF的组成介绍 URDF-Link介绍 URDF-Joint介绍 创建一个简单的URDF并在RVIZ2中可视化 1.URDF的组成介绍 一般情况下，URDF由声明信息和两种关键组件共同组成 1.1 声明信息 声明信息包含两部分，第一部分是xml的声明信息，放在第一行 第二部分是机器人的声明，通过robot标签就可以声明一个机器人模型 ...... 1.2 两种关键组件(Joint&Link) 以FishBot机器人为例分析。观察下图机器人的结构。 可以简化为如下五个部件组成： 躯体 左右轮子 支撑轮 雷达激光 IMU模块 这五个部件之间的固定方式为： graph TB A[左轮] -->C[躯体] B[右轮] -->C[躯体] D[IMU] -->C[躯体] E[雷达] -->C[躯体] F[支撑轮子] -->C[躯体] 我们把左轮，右轮、支撑轮子，IMU和雷达部件称为机器人的Link 而Link和Link之间的连接部分称之为Joint关节 接着我们给每个link和joint取个名字。 graph TB A[左轮:left_wheel_link] --left_wheel_joint-->C[躯体] B[右轮:right_wheel_link] --right_wheel_joint-->C[躯体] D[IMU:imu_link] --imu_joint-->C[躯体] E[雷达:laser_link] --laser_joint-->C[躯体] F[支撑轮子:caster_link] --caster_joint-->C[躯体:base_link] 所以我们就可以使用6个link和5个joint来描述这个机器人，接着我们分别对link和joint进行详细的介绍。 2.Link介绍 上面我们介绍完了link，那一个link该怎么写呢？ 我们来看一个base_link的写法，通过link标签即可声明一个link,属性name指定部件名字 通过两行代码就可以定义好base_link，但现在的base_link是空的，我们还要声明我们的base_link长什么样，通过visual子标签就可以声明出来机器人的visual形状。 2.1 link标签定义 link的子标签列表 visual 显示形状 (几何形状) 长方体 标签属性: size-长宽高 举例： 圆柱体 标签属性:radius -半径 length-高度 举例： sphere 球体 属性：radius -半径 举例： mesh 第三方导出的模型文件 属性：filename 举例: origin (可选：默认在物体几何中心) 属性 xyz默认为零矢量 rpy弧度表示的翻滚、俯仰、偏航 举例： material 材质 属性 name 名字 color 属性 rgba a代表透明度 举例： collision 碰撞属性，仿真章节中讲解 inertial 惯性参数 质量等，仿真章节中讲解 3.Joint介绍 joint为机器人关节，机器人关节用于连接两个机器人部件，主要写明父子关系 父子之间的连接类型，包括是否固定的，可以旋转的等 父部件名字 子部件名字 父子之间相对位置 父子之间的旋转轴，绕哪个轴转 比如我们再建立一个雷达部件laser_link，然后将laser_link固定到base_link 3.1 joint标签详解 joint属性 name 关节的名称 type 关节的类型 revolute: 旋转关节，绕单轴旋转,角度有上下限,比如舵机0-180 continuous: 旋转关节，可以绕单轴无限旋转,比如自行车的前后轮 fixed: 固定关节，不允许运动的特殊关节 prismatic: 滑动关节，沿某一轴线移动的关节，有位置极限 planer: 平面关节，允许在xyz，rxryrz六个方向运动 floating: 浮动关节，允许进行平移、旋转运动 joint的子标签 parent 父link名称 child子link名称 origin 父子之间的关系xyz rpy axis 围绕旋转的关节轴 下一节我们尝试将我们的机器人模型在RVIZ2中显示出来 参考文档 urdf/XML/link - ROS Wiki http://docs.ros.org/en/humble/Tutorials/URDF/URDF-Main.html "},"ROS2/建模仿真篇/第8章-机器人建模/002-RVIZ2可视化移动机器人模型.html":{"url":"ROS2/建模仿真篇/第8章-机器人建模/002-RVIZ2可视化移动机器人模型.html","title":"RVIZ2可视化移动机器人模型","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 8.2 RVIZ2可视化移动机器人模型 上一节讲完joint和link，我们来把我们上面定义的简单的URDF(包含身体和雷达)用RVIZ2显示出来，直观的感受下，我们的机器人模型。 URDF可视化的步骤如下： 建立机器人描述功能包 建立urdf文件夹编写urdf文件 建立launch文件夹，编写launch文件 修改setup.py配置，编译测试 1.建立功能包 轻车熟路，先创建一个chapt8_ws工作空间，然后建立功能包，包的类型选ament_python ros2 pkg create fishbot_description --build-type ament_python 2.建立URDF文件 建立URDF文件夹，创建urdf文件 cd fishbot_description && mkdir urdf touch fishbot_base.urdf 完成后src下的目录结构： ├── fishbot_description │ ├── __init__.py ├── package.xml ├── setup.cfg ├── setup.py └── urdf └── fishbot_base.urdf 编辑fishbot_base.urdf 3.建立launch文件 在目录src/fishbot_description下创建launch文件夹并在其下新建display_rviz2.launch.py文件。 mkdir launch touch display_rviz2.launch.py 完成后的目录结构： ├── fishbot_description │ ├── __init__.py ├── launch │ └── display_rviz2.launch.py ├── package.xml ├── setup.cfg ├── setup.py └── urdf └── fishbot_base.urdf import os from launch import LaunchDescription from launch.substitutions import LaunchConfiguration from launch_ros.actions import Node from launch_ros.substitutions import FindPackageShare def generate_launch_description(): package_name = 'fishbot_description' urdf_name = \"fishbot_base.urdf\" ld = LaunchDescription() pkg_share = FindPackageShare(package=package_name).find(package_name) urdf_model_path = os.path.join(pkg_share, f'urdf/{urdf_name}') robot_state_publisher_node = Node( package='robot_state_publisher', executable='robot_state_publisher', arguments=[urdf_model_path] ) joint_state_publisher_node = Node( package='joint_state_publisher_gui', executable='joint_state_publisher_gui', name='joint_state_publisher_gui', arguments=[urdf_model_path] ) rviz2_node = Node( package='rviz2', executable='rviz2', name='rviz2', output='screen', ) ld.add_action(robot_state_publisher_node) ld.add_action(joint_state_publisher_node) ld.add_action(rviz2_node) return ld 想要可视化模型需要三个节点参与 joint_state_publisher_gui 负责发布机器人关节数据信息，通过joint_states话题发布 robot_state_publisher_node负责发布机器人模型信息robot_description，并将joint_states数据转换tf信息发布 rviz2_node负责显示机器人的信息 graph TB A[joint_state_publisher]--joint_states-->B B[robot_state_publisher]--robot_description-->C C[rviz2] 这里我们用到了joint_state_publisher_gui和robot_state_publisher两个包，如果你的系统没有安装这两个包，可以手动安装: sudo apt install ros-$ROS_DISTRO-joint-state-publisher-gui ros-$ROS_DISTRO-robot-state-publisher joint_state_publisher_gui，还有一个兄弟叫做joint_state_publisher两者区别在于joint_state_publisher_gui运行起来会跳出一个界面，通过界面可以操作URDF中能动的关节 4.修改setup.py 导入包 from glob import glob import os 加入目录安装 ('share/ament_index/resource_index/packages', ['resource/' + package_name]), ('share/' + package_name, ['package.xml']), 完整 from setuptools import setup from glob import glob import os package_name = 'fishbot_description' setup( name=package_name, version='0.0.0', packages=[package_name], data_files=[ ('share/ament_index/resource_index/packages', ['resource/' + package_name]), ('share/' + package_name, ['package.xml']), (os.path.join('share', package_name, 'launch'), glob('launch/*.launch.py')), (os.path.join('share', package_name, 'urdf'), glob('urdf/**')), ], install_requires=['setuptools'], zip_safe=True, maintainer='root', maintainer_email='root@todo.todo', description='TODO: Package description', license='TODO: License declaration', tests_require=['pytest'], entry_points={ 'console_scripts': [ ], }, ) 5.编译测试 编译 colcon build 运行测试 source install/setup.bash ros2 launch fishbot_description display_rviz2.launch.py 添加robotmodel模块，分别选择link名称如下，即可看到机器人的模型显示 此时看看节点关系图 这里大家可以参考图理一理launch文件中启动的三个节点的关系。 然后打开TF模块，看一下机器人的坐标系关系 6.本节练习 练习1：尝试将修改机器人身体颜色为蓝色，透明度为50%(0.1 0.1 1.0 0.5) 练习2：尝试在URDF中添加imu_link并使用imu_joint将其固定在车体的中心上方2cm，imu采用的几何形状为box。长宽高均为2cm 结果展示： "},"ROS2/建模仿真篇/第8章-机器人建模/003-创建一个两轮差速模型.html":{"url":"ROS2/建模仿真篇/第8章-机器人建模/003-创建一个两轮差速模型.html","title":"创建一个两轮差速模型","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 8.3 动手创建一个移动机器人 本节课我们来一起动手创建一个两轮差速的移动机器人fishbot,在上一节的时候我们已经给我们的机器人安装上了雷达，本节课我们接着上节课的来继续完善我们的机器人模型。 机器人除了雷达之外，还需要IMU加速度传感器以及可以驱动的轮子，在第七章中我们曾介绍过机器人学部分，曾对两差速模型进行过介绍，所以我们还需要再创建两个差速驱动轮和一个支撑轮。 所以本节带你一起给机器人添加如下部件和关节： IMU传感器部件与关节 左轮子部件与关节 右轮子部件与关节 支撑轮子部件与关节 1.添加IMU传感器(上节作业) IMU传感器和透明度与颜色修改是上节课，作业，先带你一起完成一下 练习1：尝试将修改机器人身体颜色为蓝色，透明度为50%(0.1 0.1 1.0 0.5) 练习2：尝试在URDF中添加imu_link并使用imu_joint将其固定在车体的中心上方2cm，imu采用的几何形状为box,长宽高各是2cm 1.1 修改颜色 透明度修改只需要在base_link中添加material 1.2 添加imu 2.添加右轮 2.1 添加关节 关节名称为right_wheel_link,在做ros2小车的时候采用的轮子如下图： 轮子的宽为4cm,直径为6.4cm,几何形状是个圆柱体，所以geometry配置如下： 需要注意的是,圆柱默认的朝向是向上的 我们可通过origin的rpy改变轮子的旋转角度，让其绕x轴旋转pi/2,所以origin的配置为 颜色换黑色，可以得到下面的配置： 2.2 添加joint 我们把左轮子的中心固定在机器人左后方 需要注意的是origin和axis值的设置 先看origin 因为base_link的高度是0.12,我们 z表示child相对parent的z轴上的关系，想将轮子固定在机器人的下表面,所以origin的z向下偏移0.12/2=0.06m(向下符号为负) y表示child相对parent的y轴上的关系，base_link的半径是0.10,所以我们让轮子的y轴向负方向偏移0.10m(向左符号为负) x表示child相对parent的x轴上的关系，向后偏移则是x轴向后进行偏移，我们用个差不多的值0.02m(向后符号为负) 再看axis 轮子是会转动的，那应该按照哪个轴转动呢？从上图可以看出是绕着y轴的逆时针方向，所以axis的设置为： 3.添加左轮 左轮就是右轮的映射，不再赘述 4.添加支撑轮 支撑轮子固定在机器人的前方，用个球体，半径用0.016m，小球的直径为0.032m与左右轮子半径相同，然后向下偏移0.016+0.06=0.076m,向下值为负，同时把支撑论向前移动一些，选个0.06m 最终结果如下： 最终URDF文件 5.测试运行 5.1 编译测试 colcon build source install/setup.bash ros2 launch fishbot_description display_rviz2.launch.py 5.2 最终结果 rviz的配置 最终结果 jointstate多出两个滑动条 节点关系 打印joint_states话题 ros2 topic echo /joint_states 5.3 通过joint_state_gui改变关节tf中关节角度 在JointStatePublisher中,拖动滑动条,观察 rviz2中tf的变换 joint_states中的值的变换 可以看到随着进度条拖动,话题中的值和rviz2中机器人关节在同步的旋转,joint_states话题也可以手动发送,下一节课带你一起通过手动发送joint_states来控制机器人轮子转动 5.4 论如何让车轮着地 虽然显示出了机器人模型，但有一个问题不知道你发现没有，那就是在RVIZ中的机器人轮子是在地面之下的。 原因在于我们fixed-frame选择的是base_link,base_link的位置本来就在left_wheel_link和right_wheel_link只上，那该怎么办呢？ 其实很简单，我们增加一个虚拟link和关节，这个关节与base_link相连，位置位于base_link向下刚好到车轮下表面的位置。 来，让我们给base_link添加一个父link-base_footprint，新增的URDF代码如下： 因为是虚拟关节，我们不用对这个link的形状进行描述，joint的origin设置为xyz=\"0.0 0.0 0.076\"表示关节base_footprint向上0.076就是base_link（觉得不好理解可以看下图）。 保存编译再次运行测试，此时车轮就在地面只上啦~ gazebo仿真模型沉到地下， 可能原因一： 碰撞属性设置的rpy要和在link的rpy设置的应保持一样 可能原因二： mass(质量)的值太大了，无法承受机器之重，受力面积又小，物体刚性系数估计也不够，被强制压入地面了 解决：质量小对应惯性矩阵也要调整哦 "},"ROS2/建模仿真篇/第8章-机器人建模/004-通过JointStates控制RVIZ2关节.html":{"url":"ROS2/建模仿真篇/第8章-机器人建模/004-通过JointStates控制RVIZ2关节.html","title":"通过JointStates控制RVIZ2关节","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 8.4 控制移动机器人轮子运动 本节我们来看看如何手动的发送joint_states来控制机器人轮子连续转动 要实现上图效果，我们需要自己编写节点,取代joint_state_publisher发送关节位姿给robot_state_pubsher，robot_state_publisher发送tf控制机器人的关节转动。 1.新建节点 2.创建发布者 3.编写发布逻辑 4.编译测试 1.新建节点 方便起见，我们就在fishbot_describle包中新建节点（参考李四节点代码） cd fishbot_ws touch fishbot_description/fishbot_description/rotate_wheel.py #!/usr/bin/env python3 import rclpy from rclpy.node import Node class RotateWheelNode(Node): def __init__(self, name): super().__init__(name) self.get_logger().info(f\"node {name} init..\") def main(args=None): \"\"\" ros2运行该节点的入口函数 1. 导入库文件 2. 初始化客户端库 3. 新建节点 4. spin循环节点 5. 关闭客户端库 \"\"\" rclpy.init(args=args) # 初始化rclpy node = RotateWheelNode(\"rotate_fishbot_wheel\") # 新建一个节点 rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 配置下setup.py entry_points={ 'console_scripts': [ \"rotate_wheel= fishbot_description.rotate_wheel:main\" ], }, 编译运行 colcon build source install/setup.bash ros2 run fishbot_description rotate_wheel 2.创建发布者 创建发布者之前，要知道robot_state_pubsher所订阅的话题类型是什么？ 回忆前面章节中学习的内容，我们可以采用如下指令查看 ros2 topic info /joint_states Type: sensor_msgs/msg/JointState Publisher count: 1 Subscription count: 1 接着 ros2 interfaces show sensor_msgs/msg/JointState # This is a message that holds data to describe the state of a set of torque controlled joints. # # The state of each joint (revolute or prismatic) is defined by: # * the position of the joint (rad or m), # * the velocity of the joint (rad/s or m/s) and # * the effort that is applied in the joint (Nm or N). # # Each joint is uniquely identified by its name # The header specifies the time at which the joint states were recorded. All the joint states # in one message have to be recorded at the same time. # # This message consists of a multiple arrays, one for each part of the joint state. # The goal is to make each of the fields optional. When e.g. your joints have no # effort associated with them, you can leave the effort array empty. # # All arrays in this message should have the same size, or be empty. # This is the only way to uniquely associate the joint name with the correct # states. std_msgs/Header header string[] name float64[] position float64[] velocity float64[] effort 知道了话题类型，我们就可以来创建发布者了. #!/usr/bin/env python3 import rclpy from rclpy.node import Node # 1.导入消息类型JointState from sensor_msgs.msg import JointState class RotateWheelNode(Node): def __init__(self, name): super().__init__(name) self.get_logger().info(f\"node {name} init..\") # 2.创建并初始化发布者成员属性pub_joint_states_ self.pub_joint_states_ = self.create_publisher(JointState, \"joint_states\", 10) 3.编写发布逻辑 3.1 多线程定频发布Rate 创建好发布者，我们想让话题按照某个固定的速度进行发布，可以采用ROS2中的定时神器Rate,不清楚Rate的小伙伴可以看看的这篇文章：ROS中的定频神器你会用吗 为了能够一直循环使用rate，我们单独开一个线程用于发布joint_states话题数据，在ROS2程序中单独开线程进行话题发布的方法为： import threading from rclpy.node import Node class RotateWheelNode(Node): def __init__(self): # 创建一个Rate和线程 self.pub_rate = self.create_rate(5) # 5Hz # 创建线程 self.thread_ = threading.Thread(target=self._thread_pub) self.thread_.start() def _thread_pub(self): while rclpy.ok(): # 做一些操作，使用rate保证循环频率 self.pub_rate.sleep() 3.2 构造发布数据 接着我们来构造发布的数据： joint_states有一个头和四个数组需要赋值（可通过ros2 interface指令查询） std_msgs/Header header #时间戳信息 和 frame_id string[] name float64[] position float64[] velocity float64[] effort 对应的含义为： # 这是一个持有数据的信息，用于描述一组扭矩控制的关节的状态。 # # 每个关节（渐进式或棱柱式）的状态由以下因素定义。 # #关节的位置（rad或m）。 # #关节的速度（弧度/秒或米/秒）和 # #在关节上施加的力（Nm或N）。 # # 每个关节都由其名称来唯一标识 # 头部规定了记录关节状态的时间。所有的联合状态 # 必须是在同一时间记录的。 # # 这个消息由多个数组组成，每个部分的联合状态都有一个数组。 # 目标是让每个字段都是可选的。例如，当你的关节没有 # 扭矩与它们相关，你可以让扭矩数组为空。 # # 这个信息中的所有数组都应该有相同的大小，或者为空。 # 这是唯一能将关节名称与正确的 # 状态。 string[] name #关节名称数组 float64[] position #关节位置数组 float64[] velocity #关节速度数组 float64[] effort #扭矩数据 3.2.1 name name是关节的名称，要与urdf中的定义的关节名称相同，根据我们的URDF定义有 self.joint_states.name = ['left_wheel_joint', 'right_wheel_joint'] 3.2.2 position 表示关节转动的角度值，因为关节类型为continuous,所以其值无上下限制，初始值赋值为0.0 # 关节的位置 self.joint_states.position = [0.0, 0.0] 我们采用速度控制机器人轮子转动，所以机器人的位置更新则可以通过下面式子计算得出 某一段时间内轮子转动的角度 = （当前时刻-上一时刻）*两个时刻之间的轮子转速 delta_time = time.time() - last_update_time # 更新位置 self.joint_states.position[0] += delta_time * self.joint_states.velocity[0] self.joint_states.position[1] += delta_time * self.joint_states.velocity[1] 3.2.3 velocity 因为我们采用速度进行控制，所以对外提供一个速度更改接口。 def update_speed(self, speeds): self.joint_speeds = speeds 3.3 完成后代码 #!/usr/bin/env python3 import rclpy from rclpy.node import Node # 1.导入消息类型JointState from sensor_msgs.msg import JointState import threading import time class RotateWheelNode(Node): def __init__(self, name): super().__init__(name) self.get_logger().info(f\"node {name} init..\") # 创建并初始化发布者成员属性pub_joint_states_ self.joint_states_publisher_ = self.create_publisher(JointState, \"joint_states\", 10) # 初始化数据 self._init_joint_states() self.pub_rate = self.create_rate(30) self.thread_ = threading.Thread(target=self._thread_pub) self.thread_.start() def _init_joint_states(self): # 初始左右轮子的速度 self.joint_speeds = [0.0, 0.0] self.joint_states = JointState() self.joint_states.header.stamp = self.get_clock().now().to_msg() self.joint_states.header.frame_id = \"\" # 关节名称 self.joint_states.name = ['left_wheel_joint', 'right_wheel_joint'] # 关节的位置 self.joint_states.position = [0.0, 0.0] # 关节速度 self.joint_states.velocity = self.joint_speeds # 力 self.joint_states.effort = [] def update_speed(self, speeds): self.joint_speeds = speeds def _thread_pub(self): last_update_time = time.time() while rclpy.ok(): delta_time = time.time() - last_update_time last_update_time = time.time() # 更新位置 self.joint_states.position[0] += delta_time * self.joint_states.velocity[0] self.joint_states.position[1] += delta_time * self.joint_states.velocity[1] # 更新速度 self.joint_states.velocity = self.joint_speeds # 更新 header self.joint_states.header.stamp = self.get_clock().now().to_msg() # 发布关节数据 self.joint_states_publisher_.publish(self.joint_states) self.pub_rate.sleep() def main(args=None): rclpy.init(args=args) # 初始化rclpy node = RotateWheelNode(\"rotate_fishbot_wheel\") # 新建一个节点 node.update_speed([15.0, -15.0]) rclpy.spin(node) # 保持节点运行，检测是否收到退出指令（Ctrl+C） rclpy.shutdown() # 关闭rclpy 4.编译测试 编译程序 colcon build --packages-select fishbot_description 此时运行关节数据发布节点 ros2 run fishbot_description rotate_wheel 测试之前还需要修改下display_rviz2.launch.py文件，注释其joint_state_publisher节点 # ld.add_action(joint_state_publisher_node) ld.add_action(robot_state_publisher_node) ld.add_action(rviz2_node) 先运行rviz和robot_state_publisher source install/setup.bash ros2 launch fishbot_description display_rviz2.launch.py 观察此时rviz界面，可以看到轮子疯狂转动 5.课后练习 尝试将左右轮速度参数化，然后尝试采用rqt动态参数配置工具，实时控制轮子的转速。 "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/001-机器人仿真介绍.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/001-机器人仿真介绍.html","title":"机器人仿真介绍","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 9.1 机器人仿真介绍 本节课我们主要对机器人仿真进行介绍，同时对ROS2支持的常用仿真平台进行介绍。 1.为什么需要机器人仿真 所谓机器人仿真其实就是通过软件来模仿硬件的特性，用于验证机器人算法、架构等。 肯定有同学会问为什么要做机器人仿真，有这个用软件来模拟硬件的空挡，直接搞真实的机器人不行吗? 答案肯定是可以的，对于个人极客来说，直接动手比仿真要来的快和直接的多。单对于公司和非常复杂的项目来说，仿真就变得很重要了。 原因在于： 仿真可以解决真机资源不足，真实的机器人一般价格都很贵，搭建起来也很耗费资源。 仿真可以保证环境的一致和稳定，举个例子，之前在部署导航系统时发现在A机器人上没问题，但在B机器人上老是丢位置，明明算法是一致的，后来发现是B机器人的IMU模块出现了松动。 仿真场景可以更加灵活，在测试机器人算法时可以通过仿真软件快速更改仿真环境，验证算法（甚至还可以让机器人原地起飞） 2.仿有哪些缺点 上面说完仿真的各种好，那仿真有哪些缺陷呢？ 之前听一位做机械臂动力学的朋友说，他们做研发时候从来没做过仿真，原因在于仿真环境中的机器人和真实环境机器人差别过大。 所以机器人仿真的主要缺陷就是仿不全，现实世界中的环境非常复杂，光线、材质、电磁干扰等等，仿真平台无法做到100%的仿真。 3.常用仿真平台 相较于ROS，ROS2支持更多更专业的仿真平台，常用的有： 3.1 Gazebo 官网链接：https://www.cyberbotics.com/ Gazebo是ROS中常用的机器人仿真平台，也是OSRF（开源机器人基金会）的作品之一，关于Gazebo的介绍，已经在第六章进行介绍了，忘记的同学可以翻看下。 3.2 WeBots 官网链接：https://www.cyberbotics.com/ Webots由Cyberbotics公司开发，是一个用于模拟机器人的开源和多平台桌面应用程序。它提供了一个完整的开发环境来对机器人进行建模、编程和仿真。Webots内核基于开源动力学引擎ODE和OpenGL，可以在Windows，Linux和macOS上运行，并且支持多种编程语言( C/C++，Python，Java，MATLAB)。 3.3 Ignition 官网链接：https://gazebosim.org/ 官方文档:https://ignitionrobotics.org/docs Ignition是继承于Gazebo的下一代仿真平台，Ignition Robotics基于开发库和云服务等丰富全面的工具箱，提供了一种全新的仿真方式，进一步简化仿真。高度逼真的传感器可在接近真实的环境中快速迭代更新机器人物理设计。在安全上可测试控制策略，并在持续的集成化侧重中利用仿真的诸多优势。 3.4 Unity 官网链接：hhttps://unity.com/ UnityForROS2:https://github.com/RobotecAI/ros2-for-unity Unity Robotics软件包带有许多现成的接口，能让你轻松与ROS或ROS 2的交换信息。你也能用URDF Importer直接从URDF文件中导入机器人配置，在Unity高质量的渲染管线与高精度的物理模拟加持下开始训练机器人。Unity的Asset Store还售有大量现成的环境和道具，可用于补充机器人的训练环境、完善训练任务。只需几键，你搭建的模拟就可以构建并部署到Windows 10、Mac OS或Linux等任意主流操作系统。你甚至可以使用C#、Bolt可视化编程及Asset Store上的众多脚本和实用程序来根据自己的需求进一步定制模拟环境。 4.我们用哪个仿真平台？ 鉴于从ROS和Gazebo中得到的大量经验，我们依然选择Gazebo作为本次进行仿真的主要平台。但在本章节的后面，会带你一起探索下其他的仿真平台。 让我们保持好奇心，下一节在上一章节机器人建模的基础上，为我们的机器人模型注入仿真需要的物理属性参数。 "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/002-为机器人URDF模型注入物理属性.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/002-为机器人URDF模型注入物理属性.html","title":"为机器人URDF模型注入物理属性","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 9.2.为机器人URDF模型注入物理属性 上节我们知道，机器人仿真就是用软件来模拟硬件的特性，那么我们必须要告诉仿真平台机器人各个关节的物理属性，比如： 有多重， 有多大的惯性 重心在哪 碰撞边界在哪 关节的上下界限 其他的一些必要信息等等 所以这节课就带你将物理信息写入到urdf中，让机器人在gazebo中显示出来。 1.需要哪些物理信息？ 一般来说有碰撞和内参两个就够了，但是因为之前的偷懒，还要加一个摩擦力配置。 碰撞描述是物体的用于碰撞检测的包围形状。内参用于描述物体的质量，惯性矩阵。link的摩擦力。 1.1 碰撞检测 在机器人仿真中，我们要对物体之前是否接触，是否发生碰撞做检测，常用的检测方法比如包围盒，判断两个物体的包围盒是否相交来快速判断物体是否发生碰撞。 在URDF中，我们可以可以在link标签下添加collison子标签来对物体的形状进行描述。 collision可以包含的子标签如下： origin，表示碰撞体的中心位姿 geometry，用于表示用于碰撞检测的几何形状 material，可选的，描述碰撞几何体的材料(这个设置可以在gazebo仿真时通过view选项看到碰撞包围体的形状) 一个完整的collision标签实例如下： 1.2 旋转惯量 旋转惯量矩阵是用于描述物体的惯性的，在做动力学仿真的时候，这些参数尤为重要。 在URDF中我们可以通过在link下添加inertial子标签，为link添加惯性参数的描述。 intertial标签包含的子标签如下： mass，描述link的质量 inertia，描述link的旋转惯量（该标签有六个属性值ixx\\ixy\\ixz\\iyy\\iyz\\izz） 一个完整的inertial标签示例如下： 关于intertial的属性设置，不是随意设置的，常见的几何体我们可以通过公式进行计算。计算方法可以看的这篇文章-URDF仿真惯性参数不知道怎么配？快收藏，常见几何物体URDF分享。 比如我们上一章节的fishbot的轮子和车体，都是实心圆柱，可以采用下面的公式进行计算： 注意：这个矩阵是一个对称矩阵，所以只需要通过其上三角即可描述完整描述这个矩阵，所以在URDF中只需要填写六个数字即可。 实心圆柱体的惯性矩阵:半径为r，高度为h，质量为m 的实心圆柱体 形状： 矩阵： 1.3 摩擦力和刚性系数 在Fishbot的URDF中，前面的支撑轮主要起支撑作用，因为我们将其使用fixed标签固定到了base_link上，所以它无法转动。 哪该怎么办呢？教你一个取巧的办法，我们可以要把这个轮子的摩擦力设置为0，让它直接在地上滑动即可， 如何设置呢？6行代码放到URDF中： 其中mu1,mu2代表摩擦力，kp,kd代表刚性系数。 2.为FishBot添加物理惯性 利用上面的方法公式，为我们的fishbot个个link添加好物理属性，完成后的base_link如下： 完全添加好的机器人URDF模型 Gazebo/Black --> / cmd_vel:=cmd_vel odom:=odom 30 left_wheel_joint --> right_wheel_joint --> left_wheel_joint right_wheel_joint 0.2 0.065 20 1.0 true true false odom base_footprint ~/out:=joint_states 30 right_wheel_joint left_wheel_joint Gazebo/Black / ~/out:=imu false true 100 true 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 true true 5 0 0 0.075 0 0 0 360 1.000000 0.000000 6.280000 0.120000 3.5 0.015000 gaussian 0.0 0.01 /tb3 --> ~/out:=scan sensor_msgs/LaserScan laser_link 可以将配置好的模型下载到src/c/urdf文件夹下，等下我们要用gazebo将该模型显示出来。 "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/003-常见几何物体URDF仿真惯性参数怎么配.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/003-常见几何物体URDF仿真惯性参数怎么配.html","title":"常见几何物体URDF仿真惯性参数怎么配","keywords":"","body":"datetime:2023/09/26 18:28 author:nzb 该项目来源于大佬的动手学ROS2 一.惯性矩阵是什么 惯性矩阵描述的是物体的惯性张量在x,y,z三个坐标轴上的投影的矩阵形式（若不对还请指出哈） 二.为什么需要自定义 从solidworks中导出的urdf模型，惯量矩阵一般都是不对的，我们拿到的模型基本都是只有机械臂的外壳，减速机等都没有包含在内，质量和材料设置也都不对，生成关节的内参也是不对的。 如果内参已经有问题到影响我们仿真了，这个时候就需要我们来手动修改内参，如何手动修改呢？ 三.如何自定义 根据我们机械臂关节的近似形状和常见几何形状的内参公式进行计算设置，比如说机械臂关节一般都是圆柱体，所以我们可以根据圆柱体的惯性张量公式进行设置。 四.常见三维几何物体张量矩阵 常见几何物体的内参惯性张量矩阵，也就是张量公式。 1.实心球体 半径为r，质量为m的是实心球体 形状 矩阵 2.空心球体 半径为r，质量为m的是空心球体 形状 矩阵 3.实心椭球 半轴长度为a , b , c，质量m的实心椭球 形状 矩阵 4.实心长方体 宽度为w，高度为h，深度为d，质量为m 的实心长方体 形状 矩阵 5.绕细长杆末端 沿y轴长度为l，质量为m 的绕末端旋转的细长杆 形状 矩阵 6.绕细长杆中心 沿y轴长度为l，质量为m 的绕中心旋转的细长杆 形状 矩阵 7.实心圆柱体 半径为r，高度为h，质量为m 的实心圆柱体 形状 矩阵 8.圆柱管 内径为r1，外径为r2，长度为h，质量为m 的带有开口端的厚壁圆柱管 形状 矩阵 9.正圆锥 半径为r，高度为h，质量为m 的正圆锥 形状 矩阵 五、如何使用矩阵 惯性矩阵是一个3*3的对称矩阵，所以在urdf中只使用六个值描述该矩阵，对应着上面的公式赋值即可。 示例： "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/004-在Gazebo加载机器人模型.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/004-在Gazebo加载机器人模型.html","title":"在Gazebo加载机器人模型","keywords":"","body":"datetime:2023/10/07 10:21 author:nzb 该项目来源于大佬的动手学ROS2 9.3.使用gazebo加载URDF 1.Gazebo-ROS2插件介绍 gazebo是独立于ROS/ROS2之外的仿真软件，我们可以独立使用Gazebo。如果我们想要通过ROS2和Gazebo进行交互，需要通过gazebo_ros插件来进行。 接下来先带你通过命令行的形式来启动gazebo-ros2插件以及使用插件提供的服务来将fishbot的urdf模型在gazebo中显示出来。 1.1 安装Gazebo插件 sudo apt install ros-humble-gazebo-ros 1.2 启动Gazebo并启动插件 安装完成后，我们就可以通过下面的命令行来启动gazebo并加载ros2插件。 gazebo --verbose -s libgazebo_ros_init.so -s libgazebo_ros_factory.so 看到下面的日志和Gazebo界面代表启动成功 Gazebo multi-robot simulator, version 11.9.0 Copyright (C) 2012 Open Source Robotics Foundation. Released under the Apache 2 License. http://gazebosim.org [Msg] Waiting for master. Gazebo multi-robot simulator, version 11.9.0 Copyright (C) 2012 Open Source Robotics Foundation. Released under the Apache 2 License. http://gazebosim.org [Msg] Waiting for master. [Msg] Connected to gazebo master @ http://127.0.0.1:11345 [Msg] Publicized address: 192.168.2.103 [Msg] Loading world file [/usr/share/gazebo-11/worlds/empty.world] [INFO] [1649151283.208884022] [gazebo_ros_node]: ROS was initialized without arguments. [Msg] Connected to gazebo master @ http://127.0.0.1:11345 [Msg] Publicized address: 192.168.2.103 2.插件节点及其服务介绍 使用3.1中的指令启动Gazebo并加载gazebo_ros插件，我们使用下面的指令来看插件的节点，以及改节点为我们提供的服务有哪些？ 节点列表 ros2 node list 正确返回 /gazebo 然后我们看看这个节点对外提供的服务有哪些？ ros2 service list /delete_entity /get_model_list /spawn_entity /gazebo/describe_parameters /gazebo/get_parameter_types /gazebo/get_parameters /gazebo/list_parameters /gazebo/set_parameters /gazebo/set_parameters_atomically 除去和参数相关的几个服务，我们可以看到另外三个特殊服务： /spawn_entity，用于加载模型到gazebo中 /get_model_list，用于获取模型列表 /delete_entity，用于删除gazbeo中已经加载的模型 我们想要让gazebo显示出我们配置好的fishbot使用/spawn_entity来加载即可。 接着我们可以来请求服务来加载模型，先带你看一下服务的接口类型。 ros2 service type /spawn_entity 返回 gazebo_msgs/srv/SpawnEntity 指令 ros2 interface show gazebo_msgs/srv/SpawnEntity 返回 string name # Name of the entity to be spawned (optional). string xml # Entity XML description as a string, either URDF or SDF. string robot_namespace # Spawn robot and all ROS interfaces under this namespace geometry_msgs/Pose initial_pose # Initial entity pose. string reference_frame # initial_pose is defined relative to the frame of this entity. # If left empty or \"world\" or \"map\", then gazebo world frame is # used. # If non-existent entity is specified, an error is returned # and the entity is not spawned. --- bool success # Return true if spawned successfully. string status_message # Comments if available. 可以看到服务的请求内容包括： string name ，需要加载的实体的名称 (可选的)。 string xml ，实体的XML描述字符串, URDF或者SDF。 string robot_namespace ，产生的机器人和所有的ROS接口的命名空间，多机器人仿真的时候很有用。 geometry_msgs/Pose initial_pose ，机器人的初始化位置 string reference_frame ，初始姿态是相对于该实体的frame定义的。如果保持\"empty\"或\"world\"或“map”，则使用 gazebo的world作为frame。如果指定了不存在的实体，则会返回错误 3.调用服务加载fishbot 看到这里你是不是迫不及待敲起来命令行来加载我们的机器人到gazebo了，别着急，再推荐一个可视化服务请求工具，其实在第六章中介绍过，在rqt工具集里有一个叫服务请求工具。 命令行输入rqt，在插件选项中选择Services->Service Caller,然后再下拉框选择/spawn_entity服务，即可看到下面的界面。 接着我们把我们的FishBot的URDF模型复制粘贴，放到xml中（注意要把原来的''删掉哦！），然后拿起我们的小电话Call。 接着就可以看到工厂返回说成功把机器人制作出来送入gazebo了。 此时再看我们的Gazebo,一个小小的，白白的机器人出现了。 按住Shift加鼠标左键，拖动一下，来好好的欣赏欣赏我们的机器人。 3.4 在不同位置加载多个机器人 欣赏完毕后，再带你生产一个fishbot（为了后面需要多机器人仿真的小伙伴）。 修改rqt中的参数，增加一个命名空间，然后修改一个位置，让第二个机器人和第一个相距1m的地方生产，然后点击Call。 返回成功，此时拖送Gazebo观察一下，发现多出了一个机器人，距离刚好是在X轴（红色）1米（一个小格子一米）处。 3.5 查询和删除机器人 利用rqt工具，我们再对另外两个服务接口进行请求。 查到了三个模型，一个大地，一个fishbot，一个fishbot_0。 我们接着尝试把fishbot_0删掉，选择删除实体，输入fishbot_0的名字，拿起小电话通知工厂回收我们的0号fishbot。 调用成功，观察gazebo发现机器人没了 4. 将启动gazebo和生产fishbot写成launch文件 打开fishbot工作空间，在src/fishbot_description/launch中添加一个gazebo.launch.py文件，我们开始编写launch文件来在gazebo中加载机器人模型。 启动gazebo，我们可以将命令行写成一个launch节点 ExecuteProcess( cmd=['gazebo', '--verbose','-s', 'libgazebo_ros_init.so', '-s', 'libgazebo_ros_factory.so', gazebo_world_path], output='screen') 上面我们加载机器人是直接将XML格式的URDF复制过去进行加载的，这样很不方便，我们可以使用gazebo_ros为我们提供好的一个叫做spawn_entity.py节点，该节点支持从文件地址直接生产机器人到Gazebo。 其实该节点的原理也很简单，从URDF中读取机器人模型，然后再调用服务，和我们手动操作一个样子，只道没差别。 该节点需要两个参数，一个机器人的模型名字和urdf的文件地址，这个简单，前面我们曾经使用package_share来拼接过urdf路径。 spawn_entity_cmd = Node( package='gazebo_ros', executable='spawn_entity.py', arguments=['-entity', robot_name_in_model, '-file', urdf_model_path], output='screen') 最终写好的launch文件如下： import os from launch import LaunchDescription from launch.actions import ExecuteProcess from launch_ros.actions import Node from launch_ros.substitutions import FindPackageShare def generate_launch_description(): robot_name_in_model = 'fishbot' package_name = 'fishbot_description' urdf_name = \"fishbot_gazebo.urdf\" ld = LaunchDescription() pkg_share = FindPackageShare(package=package_name).find(package_name) urdf_model_path = os.path.join(pkg_share, f'urdf/{urdf_name}') # Start Gazebo server start_gazebo_cmd = ExecuteProcess( cmd=['gazebo', '--verbose', '-s', 'libgazebo_ros_init.so', '-s', 'libgazebo_ros_factory.so'], output='screen') # Launch the robot spawn_entity_cmd = Node( package='gazebo_ros', executable='spawn_entity.py', arguments=['-entity', robot_name_in_model, '-file', urdf_model_path], output='screen') ld.add_action(start_gazebo_cmd) ld.add_action(spawn_entity_cmd) return ld 编译运行 colcon build --packages-select fishbot_description source install/setup.bash ros2 launch fishbot_description gazebo.launch.py 完美显示 5.总结 这节课我们为Fishbot注入了仿真必须的物理属性，但是机器人还是不会动，下一节课我们就利用Gazebo的其他插件，让我们的机器人动起来。 最后再留一个课后作业： 尝试将fishbot的物理属性去掉，再加载机器人看看会发生什么？ 尝试将fishbot的碰撞改成很小，再看看会发生什么？ gazebo还支持link的材料修改，在URDF中添加下面的代码，给支撑轮一个不一样的材质吧，你也可以将reference改成其他link，装点一下你的机器人。 Gazebo/Black "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/005-Gazebo仿真插件之两轮差速.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/005-Gazebo仿真插件之两轮差速.html","title":"Gazebo仿真插件之两轮差速","keywords":"","body":"datetime:2023/10/07 10:21 author:nzb 该项目来源于大佬的动手学ROS2 9.4.Gazebo仿真插件之两轮差速 完成了上节课的Gazebo加载FishBot，但是机器人还是不会动，你一定很不开心吧，本节课就带你一起通过配置两轮差速控制插件，让我们的机器人动起来~ 最终效果： 1.Gazebo插件介绍 之前说过Gazebo是一个独立于ROS的软件，对外提供了丰富的API可以使用，gazebo的插件按照用途大致可以分为两种： 用于控制的插件，通过插件可以控制机器人关节运动，可以进行位置、速度、力的控制，比如我们这节课的两轮差速控制器。 用于数据采集的插件，比如IMU传感器用于采集机器人的惯性，激光雷达用于采集机器人周围的点云信息。 当然上面两类插件功能也可以写到一个插件里，两轮差速插件就是一个二合一加强版。 2.两轮差速插件介绍 两轮差速插件用于控制机器人轮子关节的位置变化，同时该插件还会获取轮子的位置以及速度的信息的反馈，根据反馈的位置信息结合运动学模型即可计算出当前机器人的位姿（里程计）。 该插件的名称为：gazebo_ros_diff_drive 两轮差速控制器和Gazebo的关系 两轮差速控制器可以将轮子的目标转速发送给Gazebo，并从Gazebo获取到实际的速度和位置。 注意：发送给Gazebo是目标速度，反馈回来的是实际速度。目标!=实际，比如轮子卡住了，无论你发什么目标速度，实际速度都是0。 要想快速了解一个系统的功能，最直接的就是看系统的对外的输入和输出是什么？什么都不要说，看下图： graph LR; D[配置参数-轮距直径等]-->B A[控制指令-cmdvel]-->B[gazebo_ros_diff_drive] B-->C[里程计-odom] B-->E[里程计tf-可选] B-->F[轮子tf-可选] 上图就是对gazebo_ros_diff_drive的输入和输出信息的总结，可以很直观的看到该插件主要输入控制指令，主要输出里程计信息。接着带你分别认识一下输入和输出两个部分。 2.2 输入参数 2.2.1 配置参数 不知道你是否还记得在第七章中，对两轮差速底盘的运动学正的介绍。如果要完成底盘的正逆解和里程计的推算就必须要知道轮子的直径和间距。 同时该插件还提供了一些可以控制输出的选项，因为是仿真，所以还要告诉插件轮子对应的joint名称等信息，这样就有了下面这个参数表格： 配置项 含义 ros ros相关配置，包含命名空间和话题重映射等 update_rate 数据更新速率 left_joint 左轮关节名称 right_joint 右轮关节名称 wheel_separation 左右轮子的间距 wheel_diameter 轮子的直径 max_wheel_torque 轮子最大的力矩 max_wheel_acceleration 轮子最大的加速度 publish_odom 是否发布里程计 publish_odom_tf 是否发布里程计的tf开关 publish_wheel_tf 是否发布轮子的tf数据开关 odometry_frame 里程计的framed ID，最终体现在话题和TF上 robot_base_frame 机器人的基础frame的ID 2.2.2 控制指令 两轮差速控制器默认通过订阅话题cmd_vel来获取目标线速度和角速度。该话题的类型为：geometry_msgs/msg/Twist 我们通过ros2的CLI来看一下这个消息包含的内容有哪些？ ros2 interface show geometry_msgs/msg/Twist # This expresses velocity in free space broken into its linear and angular parts. Vector3 linear Vector3 angular 可以看到包含线速度和角速度，我们用proto在看一下包含的基本数据类型有哪些？ ros2 interface proto geometry_msgs/msg/Twist \"linear: x: 0.0 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0 \" 线速度和角速度都包含在x、y、z，代表坐标系的三个方向上的对应速度。 两轮差速控制器收到这个话题数据后将其中的角速度和线速度转换上两个轮子的转动速度发送给Gazebo。 2.3 输出参数 2.3.1 里程计 里程计信息默认的输出话题为odom，其消息类型为：nav_msgs/msg/Odometry 同样的使用CLI看一下其消息的组成结构： ros2 interface show nav_msgs/msg/Odometry # This represents an estimate of a position and velocity in free space. # The pose in this message should be specified in the coordinate frame given by header.frame_id # The twist in this message should be specified in the coordinate frame given by the child_frame_id # Includes the frame id of the pose parent. std_msgs/Header header # Frame id the pose points to. The twist is in this coordinate frame. string child_frame_id # Estimated pose that is typically relative to a fixed world frame. geometry_msgs/PoseWithCovariance pose # Estimated linear and angular velocity relative to child_frame_id. geometry_msgs/TwistWithCovariance twist ros2 interface proto nav_msgs/msg/Odometry \"header: stamp: sec: 0 nanosec: 0 frame_id: '' child_frame_id: '' pose: pose: position: x: 0.0 y: 0.0 z: 0.0 orientation: x: 0.0 y: 0.0 z: 0.0 w: 1.0 covariance: - 0.0 - 0.0 ... twist: twist: linear: x: 0.0 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0 covariance: - 0.0 - 0.0 ... \" 可以看到其数据主要包含三个部分： header，表示该消息发布的时间 pose，表示当前机器人位置和朝向 twist，表示当前机器人的线速度和角速度 数据中还包含一个covariance，其代表协方差矩阵，后面写篇文章来介绍下，这里只需了解其含义即可。 2.3.2 里程计TF信息 设为true，订阅tf话题里你就可以看到像下面的msg，建议后面配置好后，手动修改下，对比区别 - header: stamp: sec: 6157 nanosec: 907000000 frame_id: odom child_frame_id: base_footprint transform: translation: x: 0.0005557960241049835 y: -0.0007350446303238693 z: 0.01599968753145574 rotation: x: 4.691143395208505e-07 y: 7.115496626557812e-06 z: -0.018531475772549166 w: 0.9998282774331005 2.3.3 左右轮子TF信息 设为true，订阅tf话题里你就可以看到像下面的msg，建议后面配置好后，手动修改下，对比区别 - header: stamp: sec: 6157 nanosec: 941000000 frame_id: base_link child_frame_id: left_wheel_link transform: translation: x: -0.02 y: 0.1 z: -0.06 rotation: x: 0.0 y: 0.049519025127821005 z: 0.0 w: 0.9987731805321918 - header: stamp: sec: 6157 nanosec: 941000000 frame_id: base_link child_frame_id: right_wheel_link transform: translation: x: -0.02 y: -0.1 z: -0.06 rotation: x: 0.0 y: -0.0663387077034509 z: 0.0 w: 0.9977971616817898 3.在URDF中配置两轮差速模型 上面该介绍的我们都给介绍了，接着我们直接来配置。 因为是给Gazebo的插件，所以在URDF中，我们需要使用进行配置，因为是要给gazebo配置插件，所有要在gazebo标签下添加plugin子插件。 话不多说，上代码 / cmd_vel:=cmd_vel odom:=odom 30 left_wheel_joint right_wheel_joint 0.2 0.065 20 1.0 true true true odom base_footprint 将这段代码加到我们的URDF中，然后对着上面介绍的配置项，一一看下，接着我们就可以来测试运行了。 完整的URDF可以参考： 4.两轮差速插件测试 修改完了URDF模型我们将代码编译一下，让更新后的URDF文件安装到install目录，接着就可以运行9.2中的launch文件，将模型加载到Gazebo中。 4.1 编译-启动 colcon build ros2 launch fishbot_description gazebo.launch.py 接着你可以使用CLI工具看一下系统有哪些节点在运行 ros2 node list ros2 topic list ros2 node list --------------- /diff_drive /gazebo ros2 topic list --------------- /clock /cmd_vel /odom /parameter_events /performance_metrics /rosout /tf 相信此时你已经看到了我们插件订阅的的/cmd_vel和发布的/odom了。 4.3 使用键盘控制fishbot 你还记得第二章中带你玩的小乌龟吗？当时我们用键盘来控制小乌龟运动，现在我们可以用键盘来控制fishbot动起来了。 你需要一个键盘控制工具，可以用下面的指令安装 sudo apt install ros-humble-teleop-twist-keyboard 这个功能包下有一个节点，这个节点会监听键盘的按键事件，然后发布cmd_vel话题，该话题被gazebo的两轮差速插件所订阅。所以我们就可以通过这个节点来控制fishbot。 ros2 run teleop_twist_keyboard teleop_twist_keyboard 如果你想让这个节点不是发布cmd_vel话题，而是别的，可以采用ROS2的话题重映射功能。 eg: ros2 run teleop_twist_keyboard teleop_twist_keyboard --ros-args --remap cmd_vel:=cmd_vel1 接着尝试使用来控制机器人运动 U I O J K L M 点一下I，你就能看到fishbot在Gazebo中飞速的移动。接着打开终端，打印一下odom话题和tf话题，移动机器人观察数据变化。 此时你应该玩一会，体验一下各种花式走法。 4.4 使用rqt显示速度数据 接着我们尝试使用rqt将数据在rqt中可视化出来，打开终端输入rqt。 rqt 选择Plugin->Visualization->Plot 在上方Topic输入/cmd_vel/linear/x，再输入/cmd_vel/angular/z，然后用键盘控制机器人移动。 cmd_vel中的速度代表目标速度，接着我们显示一下当前速度（在odom.twist中） 4.5 在RVIZ2中显示Fishbot及其轨迹 打开rviz2 rviz2 修改FixedFrame为odom 添加插件，Add->Odometry->OK 选择话题，Odometry->Topic->选/odom 去除协方差显示，Odometry->Covariance>取消勾选 键盘控制节点，点个U，原地转圈圈 最终结果： 4.6 在RVIZ2中显示机器人模型 虽然机器人的轨迹已经在RVIZ中显示出来了，但是并没有机器人的模型，也看不到轮子的转动，来带你一起解决这个问题。 前面介绍过，要发布机器人模型我们所使用的节点是robot_state_publisher,所以我们在gazebo.launch.py中加入这个节点，同时再加上rviz2的启动节点，最终的gazebo.launch.py 内容如下： import os from launch import LaunchDescription from launch.actions import ExecuteProcess from launch_ros.actions import Node from launch_ros.substitutions import FindPackageShare def generate_launch_description(): robot_name_in_model = 'fishbot' package_name = 'fishbot_description' urdf_name = \"fishbot_gazebo.urdf\" ld = LaunchDescription() pkg_share = FindPackageShare(package=package_name).find(package_name) urdf_model_path = os.path.join(pkg_share, f'urdf/{urdf_name}') # Start Gazebo server start_gazebo_cmd = ExecuteProcess( cmd=['gazebo', '--verbose', '-s', 'libgazebo_ros_init.so', '-s', 'libgazebo_ros_factory.so', gazebo_world_path], output='screen') # Launch the robot spawn_entity_cmd = Node( package='gazebo_ros', executable='spawn_entity.py', arguments=['-entity', robot_name_in_model, '-file', urdf_model_path], output='screen') # Start Robot State publisher start_robot_state_publisher_cmd = Node( package='robot_state_publisher', executable='robot_state_publisher', arguments=[urdf_model_path] ) # Launch RViz start_rviz_cmd = Node( package='rviz2', executable='rviz2', name='rviz2', output='screen', # arguments=['-d', default_rviz_config_path] ) ld.add_action(start_gazebo_cmd) ld.add_action(spawn_entity_cmd) ld.add_action(start_robot_state_publisher_cmd) ld.add_action(start_rviz_cmd) return ld 保存编译启动 colcon build ros2 launch fishbot_description gazebo.launch.py 然后继续启动键盘控制，Enjoy It! "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/006-Gazebo仿真插件之IMU.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/006-Gazebo仿真插件之IMU.html","title":"Gazebo仿真插件之IMU","keywords":"","body":"datetime:2023/10/07 10:21 author:nzb 该项目来源于大佬的动手学ROS2 9.5.Gazebo仿真插件之IMU 上节课通过配置两轮差速控制器我们已经成功的让fishbot在gazebo中动了起来，本节课我们通过给fishbot的URDF配置IMU传感器插件，让IMU模块工作起来。 1.惯性测量单元IMU介绍 惯性测量单元是测量物体三轴姿态角(或角速率)以及加速度的装置。一般的，一个IMU包含了三个单轴的加速度计和三个单轴的陀螺， 加速度计检测物体在载体坐标系统独立三轴的加速度信号，而陀螺检测载体相对于导航坐标系的角速度信号， 测量物体在三维空间中的角速度和加速度，并以此解算出物体的姿态。在导航中有着很重要的应用价值。 上面这段话是从百科中摘抄出来的，你需要知道的一个关键点是IMU可以测量以下三组数据： 三维角度 三维加速度 三维角速度 1.1 IMU长啥样？ 便宜的长这样： 贵的长这样： 不要钱的长什么样？ 仿真的不要钱哈哈，接着我们来配置一下仿真的IMU。 2.Gazebo-IMU插件介绍 仿真的IMU也是对应一个后缀为.so的动态链接库，使用下面的指令可以查看所有的动态链接库： ls /opt/ros/humble/lib/libgazebo_ros* /opt/ros/humble/lib/libgazebo_ros2_control.so /opt/ros/humble/lib/libgazebo_ros_ackermann_drive.so /opt/ros/humble/lib/libgazebo_ros_bumper.so /opt/ros/humble/lib/libgazebo_ros_camera.so /opt/ros/humble/lib/libgazebo_ros_diff_drive.so /opt/ros/humble/lib/libgazebo_ros_elevator.so /opt/ros/humble/lib/libgazebo_ros_factory.so /opt/ros/humble/lib/libgazebo_ros_force.so /opt/ros/humble/lib/libgazebo_ros_force_system.so /opt/ros/humble/lib/libgazebo_ros_ft_sensor.so /opt/ros/humble/lib/libgazebo_ros_gps_sensor.so /opt/ros/humble/lib/libgazebo_ros_hand_of_god.so /opt/ros/humble/lib/libgazebo_ros_harness.so /opt/ros/humble/lib/libgazebo_ros_imu_sensor.so /opt/ros/humble/lib/libgazebo_ros_init.so /opt/ros/humble/lib/libgazebo_ros_joint_pose_trajectory.so /opt/ros/humble/lib/libgazebo_ros_joint_state_publisher.so /opt/ros/humble/lib/libgazebo_ros_node.so /opt/ros/humble/lib/libgazebo_ros_p3d.so /opt/ros/humble/lib/libgazebo_ros_planar_move.so /opt/ros/humble/lib/libgazebo_ros_projector.so /opt/ros/humble/lib/libgazebo_ros_properties.so /opt/ros/humble/lib/libgazebo_ros_ray_sensor.so /opt/ros/humble/lib/libgazebo_ros_state.so /opt/ros/humble/lib/libgazebo_ros_template.so /opt/ros/humble/lib/libgazebo_ros_tricycle_drive.so /opt/ros/humble/lib/libgazebo_ros_utils.so /opt/ros/humble/lib/libgazebo_ros_vacuum_gripper.so /opt/ros/humble/lib/libgazebo_ros_video.so /opt/ros/humble/lib/libgazebo_ros_wheel_slip.so IMU对应的消息类型为sensor_msgs/msg/Imu ros2 interface show sensor_msgs/msg/Imu # This is a message to hold data from an IMU (Inertial Measurement Unit) # # Accelerations should be in m/s^2 (not in g's), and rotational velocity should be in rad/sec # # If the covariance of the measurement is known, it should be filled in (if all you know is the # variance of each measurement, e.g. from the datasheet, just put those along the diagonal) # A covariance matrix of all zeros will be interpreted as \"covariance unknown\", and to use the # data a covariance will have to be assumed or gotten from some other source # # If you have no estimate for one of the data elements (e.g. your IMU doesn't produce an # orientation estimate), please set element 0 of the associated covariance matrix to -1 # If you are interpreting this message, please check for a value of -1 in the first element of each # covariance matrix, and disregard the associated estimate. std_msgs/Header header geometry_msgs/Quaternion orientation float64[9] orientation_covariance # Row major about x, y, z axes geometry_msgs/Vector3 angular_velocity float64[9] angular_velocity_covariance # Row major about x, y, z axes geometry_msgs/Vector3 linear_acceleration float64[9] linear_acceleration_covariance # Row major x, y z 可以看到除了每个数据对应的三个协方差之外，每一个还都对应一个3*3的协方差矩阵。 3.给FIshbot配置IMU传感器 有了上节课的经验，我们可以很轻松的添加IMU传感器，但是还有一个需要注意的地方，为了更真实的模拟IMU传感器，我们需要给我们的仿真IMU传感器加点料。 加什么？加点高斯噪声，高斯噪声只需要指定平均值和标准差两个参数即可，不过因为IMU传感器的特殊性，我们还需要给模型添加两个偏差参数，分别是 平均值偏差和标准差偏差。 有关Gazebo仿真和噪声模型更深入的介绍可以参考发的两篇推文： Gazebo仿真进阶教程之传感器高斯噪声（一） Gazebo仿真进阶教程之传感器高斯噪声（二） 下面是IMU传感器的URDF配置代码，大家结合文章对应可以理解一下，IMU对应的插件库libgazebo_ros_imu_sensor.so / ~/out:=imu false true 100 true 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 将上面的代码加到fishbot_gazebo.urdf中，接着我们就可以进行测试了。 4.编译测试 编译 colcon build 运行 ros2 launch fishbot_description gazebo.launch.py CLI看话题 ros2 topic list ros2 topic info /imu ros2 topic echo /imu 输出： header: stamp: sec: 150 nanosec: 599000000 frame_id: base_footprint orientation: x: 3.434713830866392e-07 y: 7.119913105768616e-06 z: -0.00028312437320413914 w: 0.9999999598948884 orientation_covariance: - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 angular_velocity: x: -0.00013597855247901325 y: 0.0006306135617081868 z: -0.00015794894627685146 angular_velocity_covariance: - 4.0e-08 - 0.0 - 0.0 - 0.0 - 4.0e-08 - 0.0 - 0.0 - 0.0 - 4.0e-08 linear_acceleration: x: 0.08679200038530369 y: 0.07753419258567491 z: 9.687910969061628 linear_acceleration_covariance: - 0.00028900000000000003 - 0.0 - 0.0 - 0.0 - 0.00028900000000000003 - 0.0 - 0.0 - 0.0 - 0.00028900000000000003 用rqt可视化： 5.总结 本节我们对IMU传感器进行介绍，并通过gazbeo的imu插件完成了fishbot的IMU数据的输出。 最后还有小练习等着你： 再次启动遥控节点，控制fishbot，观察IMU传感器的数据变化 "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/007-Gazebo仿真插件之激光雷达.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/007-Gazebo仿真插件之激光雷达.html","title":"Gazebo仿真插件之超声波","keywords":"","body":"datetime:2023/10/07 10:21 author:nzb 该项目来源于大佬的动手学ROS2 9.6.为FishBot添加添加激光雷达传感器 本节我们来认识一个新的传感器，该传感器在自动驾驶、室内导航等应用非常多，比如扫地机器人上就是用的它作为感知环境的重要工具，该传感器是激光雷达。 1.激光雷达介绍 激光雷达（Light Detection And Ranging）,缩写LiDAR，翻译一下叫——激光探测与测距。 1.1 激光雷达原理介绍 激光雷达的原理也很简单，就像蝙蝠的定位方法一样，蝙蝠定位大家都知道吧，像下面这样子的回声定位。 普通的单线激光雷达一般有一个发射器，一个接收器，发射器发出激光射线到前方的目标上，物品会将激光反射回来，然后激光雷达的接受器可以检测到反射的激光。 通过计算发送和反馈之间的时间间隔，乘上激光的速度，就可以计算出激光飞行的距离，该计算方法成为TOF（飞行时间法Time of flight，也称时差法）。 除了TOF之外还有其他方法进行测距，比如三角法，这里就不拓展了放一篇文章，大家自行阅读。 激光三角测距原理详述 目前市面上的激光雷达，几乎都是采用三角测距，比如思岚的： 需要注意的是虽然只有一个发射器和一个接受器，激光雷达通过电机可以进行旋转，这样就可以达到对周围环境360度测距的目的。 1.2 激光雷达大赏 五位数的长这样 四位数的长这样 三位数的长这样 两位数的长这样 不要钱的长这样 仿真的，不要钱 2.Gazebo激光雷达插件 因为激光雷达是属于射线类传感器，该类传感在在Gazebo插件中都被封装成了一个动态库libgazebo_ros_ray_sensor.so。 接着我们来看看LiDAR的话题消息接口sensor_msgs/msg/LaserScan。 ros2 interface show sensor_msgs/msg/LaserScan # Single scan from a planar laser range-finder # # If you have another ranging device with different behavior (e.g. a sonar # array), please find or create a different message, since applications # will make fairly laser-specific assumptions about this data std_msgs/Header header # timestamp in the header is the acquisition time of # the first ray in the scan. # # in frame frame_id, angles are measured around # the positive Z axis (counterclockwise, if Z is up) # with zero angle being forward along the x axis float32 angle_min # start angle of the scan [rad] float32 angle_max # end angle of the scan [rad] float32 angle_increment # angular distance between measurements [rad] float32 time_increment # time between measurements [seconds] - if your scanner # is moving, this will be used in interpolating position # of 3d points float32 scan_time # time between scans [seconds] float32 range_min # minimum range value [m] float32 range_max # maximum range value [m] float32[] ranges # range data [m] # (Note: values range_max should be discarded) float32[] intensities # intensity data [device-specific units]. If your # device does not provide intensities, please leave # the array empty. 雷达的数据结构有些复杂，但通过注释和名字相信你可以看的七七八八，看不懂也没关系，一般情况下我们不会直接的对雷达的数据做操作。这里也就先skip。 3.为FishBot添加雷达插件 有了前面的经验，我们需要在URDF添加以下内容即可 true true 5 0 0 0.075 0 0 0 360 1.000000 0.000000 6.280000 0.120000 3.5 0.015000 gaussian 0.0 0.01 ~/out:=scan sensor_msgs/LaserScan laser_link 可以看到: 雷达也可以设置更新频率update_rate，这里设置为5 雷达可以设置分辨率，设置为1，采样数量360个，最终生成的点云数量就是360 雷达也有噪声，模型为gaussian 雷达有扫描范围range，这里配置成0.12-3.5，0.015分辨率 雷达的pose就是雷达的joint中位置的设置值 4.编译测试 编译 colcon build 运行 ros2 launch fishbot_description gazebo.launch.py CLI看话题 ros2 topic list ros2 topic info /scan ros2 topic echo /scan 接着我们尝试使用rviz2进行可视化激光雷达数据 添加和修改RVIZ2的如下：（通过LaserScan插件可以看到激光数据） 相信你改完之后依然是看不到任何激光雷达的数据的，反看topic的echo出来的数据，不是0就是inf(无限大)，再看看gazebo你会发现，激光雷达并没有达到任何一个物体上。 所以我们可以手动的给激光雷达周围添加一下东西，点击Gazebo工具栏的正方体，圆球或者圆柱，随意放置几个到我们激光雷达的最大扫描半径内。 接着我们再看一下RVIZ2，这里把size改大了10倍0.01->0.1。 5.总结 到这里我们就把fishbot的各个传感器都仿真出来了，第九章的内容也暂且告一段落，迎接我们的是第十章，也就是fishbot的导航仿真，nav2了。 如果你想先本教程一步学习Nav2，可以到nav2中文网 哦～ "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/008-Gazebo仿真插件之超声波.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/008-Gazebo仿真插件之超声波.html","title":"Gazebo仿真插件之超声波","keywords":"","body":"datetime:2023/10/07 10:21 author:nzb 该项目来源于大佬的动手学ROS2 9.7.Gazebo仿真插件之超声波 本节是拓展章节，主要讲解一下如何给FishBot添加一个超声波传感器。 在实际的机器人开发过程中，我们可能会利用超声波传感器实现实时避障的功能，毕竟超声波的价格相较于激光雷达要便宜很多（便宜的几块钱）。 所以本节我们来说一下如何使用ROS2+Gazebo来仿真超声波传感器。 1.超声波传感器介绍 百科来一段： 超声波传感器是将超声波信号转换成其它能量信号（通常是电信号）的传感器。超声波是振动频率 高于20kHz的机械波。它具有频率高、波长短、绕射现象小，特别是方向性好、能够成为射线 而定向传播等特点。超声波对液体、固体的穿透本领很大，尤其是在阳光不透明的固体中。超声波碰到杂质或分界面会产生显著反射形成反射回波，碰到活动物体能产生多普勒效应 。超声波传感器广泛应用在工业、国防、生物医学等方面。 接着看看长什么样子： 便宜的就长这样子，一共两个头，一个头用于发送波，一个头接收波。这个还稍微高级一点，带一个光敏电阻，可以为超声波数据做一些补偿。 超声波传感器原理是什么呢？ 距离=(发送时间-接收时间)*速度/2 看了超声波的原理，你有没有发现和前面的激光雷达传感器是一样的，是的，所以超声波传感器插件和激光雷达传感器插件在Gazebo插件中是同一个： libgazebo_ros_ray_sensor.so 2.超声波插件配置 直接上配置，接着再解释 2.1 添加超声波关节 超声波总要装在机器人身上某个位置，所以我们先添加一个关节和Joint，为了省事，link我们就只写个名字，你如果有需要可以按照前面的章节那样添加一下。 2.2 添加Gazebo插件 添加完了关节，我们就可以配置gazebo的插件了，gazebo插件配置如下 0 0 0 0 0 0 true 5 5 1 -0.12 0.12 5 1 -0.01 0.01 0.02 4 0.01 gaussian 0.0 0.01 ~/out:=ultrasonic_sensor_1 sensor_msgs/Range ultrasound ultrasonic_sensor_link 3.编译运行测试 3.1Gazebo可视化 添加完成后就可以编译测试下代码 colcon build --packages-select fishbot_description source install/setup.bash ros2 launch fishbot_description gazebo.launch.py 没有物体的前面可以放个东西，因为本节是后面补充的，所有这里有个墙。 3.2话题数据 打开终端，输入下面指令 ros2 topic list ros2 topic info /ultrasonic_sensor_1 ros2 topic echo /ultrasonic_sensor_1 不出意外可以看到下面的数据 header: stamp: sec: 4458 nanosec: 1000000 frame_id: ultrasonic_sensor_link radiation_type: 0 field_of_view: 0.23999999463558197 min_range: 0.019999999552965164 max_range: 4.0 range: 2.6798219680786133 这里的range就是fishbot到墙之间的距离：2.67982 我们来讲一讲超声波传感器的数据类型sensor_msgs/msg/Range # ros2 topic info /ultrasonic_sensor_1 Type: sensor_msgs/msg/Range Publisher count: 1 Subscription count: 0 你可以使用ros2 interface show sensor_msgs/msg/Range看到详细的解释，我们翻译一下 # Single range reading from an active ranger that emits energy and reports # one range reading that is valid along an arc at the distance measured. # This message is not appropriate for laser scanners. See the LaserScan # message if you are working with a laser scanner. # # This message also can represent a fixed-distance (binary) ranger. This # sensor will have min_range===max_range===distance of detection. # These sensors follow REP 117 and will output -Inf if the object is detected # and +Inf if the object is outside of the detection range. std_msgs/Header header # timestamp in the header is the time the ranger # returned the distance reading # Radiation type enums # If you want a value added to this list, send an email to the ros-users list uint8 ULTRASOUND=0 uint8 INFRARED=1 uint8 radiation_type # 传感器射线类型 # (sound, IR, etc) [enum] float32 field_of_view # 距离数据对应的弧[rad]的大小，测量物体的范围介于 # -field_of_view/2 到 field_of_view/2 之间。 # 0 角度对应于传感器的 x 轴。 float32 min_range # 最小范围值 [m] float32 max_range # 最大范围值 [m] # 固定距离需要 min_range==max_range float32 range # 范围数据 [m] # (Note: values range_max should be discarded) # Fixed distance rangers only output -Inf or +Inf. # -Inf represents a detection within fixed distance. # (Detection too close to the sensor to quantify) # +Inf represents no detection within the fixed distance. # (Object out of range) 结论，主要关注range就可以了。 3.3 在RVIZ2中可视化超声波数据 Add ->By topic->Range 4.总结 本节主要介绍了如何对超声波传感器进行仿真，在导航的过程中我们通常把超声波放到一个代价地图中进行停障等行为。所以学习其仿真还是很有用的。 "},"ROS2/建模仿真篇/第9章-机器人仿真/入门/009-Gazebo仿真环境搭建.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/入门/009-Gazebo仿真环境搭建.html","title":"Gazebo仿真环境搭建","keywords":"","body":"datetime:2023/10/07 10:21 author:nzb 该项目来源于大佬的动手学ROS2 9.8.Gazebo仿真环境搭建 本节我们要在Gazebo中建立一个测试的环境，其实也很简单，利用Gazebo的画墙工具即可完成。 1. Gazebo的world介绍 world即世界，gazebo的world文件就是用于描述世界模型的，也就是环境模型。 Gazebo已经为我们准备了很多常用的物体模型，除了基础的圆球，圆柱，立方体外的，其实还有飞机、汽车、房子等你现实中无法拥有的。 但是一开始安装Gazebo的时候并不会帮你下载好这些模型，需要我们手动下载，一行代码下载指令，打开终端，复制粘贴下面这句 cd ~/.gazebo && wget https://gitee.com/ohhuo/scripts/raw/master/gazebo_model.py && python3 gazebo_model.py 然后等待脚本运行完成，当然也不用等它完成，因为一共有281个模型，是逐一下载并解压到~/.gazebo/models/目录的。 此时再次打开终端，输入gazebo，把选项卡切换到Insert 在Insert选项卡下可以看到一个目录，以及目录下的模型名称，随着下载脚本的不断下载，这里的模型会越来越多。 随手拖几个，搭建一个漂亮的环境出来~ 每个成功的男人都有一辆车 上面是Gazebo为我们准备好的开源模型，我们也可以通过Gazebo的工具来自己画一个环境。 2. 通过建墙工具建立world Gazebo左上角->Edit->Building Editor 接着可以看到这样一个编辑界面 2.1 随手画墙 点击左边的Wall,你就可以在上方的白色区域进行建墙了。 建完后还可以用选Add Color或者Add Texture，然后点击下方墙，给墙添加颜色或者纹理。 2.2 从已有地图画墙 首先你要有一个地图，为你准备了两个，两个图片都是800*600像素的。 打开Gazebo->Gazebo左上角->Edit->Building Editor->左下方选Import 将上面两个图片存到本地，在这个界面选图片，记着选Next 左边选尺寸对应关系 我们选择默认的，100像素/米。点击OK（需要手动将100改变一下才能点击OK哦），之后就可以用图片画墙了。 注意：导入完图片不会直接出来墙，图片只是提供了墙的大概位置，需要你手动用墙再将边描一遍。 建完后点击File->Exit,在退出的弹框中选Exit。 接着在Gazebo界面中就可以看到墙了，我们再手动添加几个物体，就可以用于下面的导航使用了。 添加完，接着点击File->SaveWorld，将文件保存到我们的fishbot_descrption的world下。 没有world目录的小伙伴可以先手动创建下 点击右上角Sace，在文件夹就可以看到这个world文件 3.启动时加载world 3.1 命令行加载World 加载world其实也很简单，可以先启动Gazebo，再手动的加载文件，也可以在Gazebo启动时加载： 比如在前面加载ROS2插件基础上再加载fishbot.world。 gazebo --verbose -s libgazebo_ros_init.so -s libgazebo_ros_factory.so 你的world文件目录/fishbot.world 3.2 在launch中加载World 修改launch文件，将上面的命令行写到gazebo.launch.py中即可。 gazebo_world_path = os.path.join(pkg_share, 'world/fishbot.world') # Start Gazebo server start_gazebo_cmd = ExecuteProcess( cmd=['gazebo', '--verbose', '-s', 'libgazebo_ros_init.so', '-s', 'libgazebo_ros_factory.so', gazebo_world_path], output='screen') 最后记得修改setup.py文件，让编译后将world文件拷贝到install目录下 添加一行 (os.path.join('share', package_name, 'world'), glob('world/**')), 添加完后 data_files=[ ('share/ament_index/resource_index/packages', ['resource/' + package_name]), ('share/' + package_name, ['package.xml']), (os.path.join('share', package_name, 'launch'), glob('launch/*.launch.py')), (os.path.join('share', package_name, 'urdf'), glob('urdf/**')), (os.path.join('share', package_name, 'world'), glob('world/**')), ], 3.3 编译测试 colcon build source install/setup.bash ros2 launch fishbot_description gazebo.launch.py 打开RVIZ2看看雷达 4.总结 本节我们实现了在Gazebo中简单的搭建了一个环境，下节我们就开始对SLAM建图进行介绍。 课后作业： 将雷达的Decay Time修改成1000,然后遥控Fishbot在环境中走一圈，然后观察雷达留下的点云形状。 正确答案如下（的环境）： "},"ROS2/建模仿真篇/第9章-机器人仿真/进阶/001-Gazebo仿真进阶教程之传感器高斯噪声.html":{"url":"ROS2/建模仿真篇/第9章-机器人仿真/进阶/001-Gazebo仿真进阶教程之传感器高斯噪声.html","title":"Gazebo仿真进阶教程之传感器高斯噪声","keywords":"","body":"datetime:2023/10/07 10:21 author:nzb 该项目来源于大佬的动手学ROS2 Gazebo仿真进阶教程之传感器高斯噪声 传感器噪声 每一个或几乎每个传感器的输出中都有噪声。相机可能有色差、声纳有多路径效应和激光会有不正确的距离读数。我们必须在仿真的传感器中添加噪声，以使得仿真的传感器和真实传感器产生的数据更加接近。 Gazebo 有一个内置的噪声模型，可以应用高斯噪声到各种传感器。虽然高斯噪声可能不是非常现实，它总比没有好，并作为一个很好的第一阶近似噪声。高斯噪声也比较容易应用于数据流。 第 1 步：可视化传感器数据 让我们从查看当前的 Velodyne 输出开始，然后我们可以添加噪声。 打开 Gazebo，插入 Velodyne 传感器。 gazebo 选择左上角附近的插入选项卡。 向下滚动并选择 Velodyne HDL-32 型号。 单击渲染窗口中的某个位置。 在激光束前面添加一个 Box，这样我们就可以得到有用的数据。 选择渲染窗口上方工具栏中的 Box 图标。 在激光束前左键单击以放置盒子。 我们可以通过 Gazebo 的主题可视化器仔细查看传感器数据。 按 Ctrl-t，打开主题选择器。找话题。/gazebo/default/velodyne/top/sensor/scan 选择主题，然后按确定打开激光可视化器。/gazebo/default/velodyne/top/sensor/scan 请注意输出的流畅线条。 第 2 步：向传感器添加噪声 可以使用标签访问 Gazebo 的噪声模型。有关更多信息，请参见 sdformat.org/spec。 打开 Velodyne 模型。 gedit ~/.gazebo/models/velodyne_hdl32/model.sdf 添加一个元素作为元素的子元素。我们将首先应用大量的噪点，这样效果就很容易看到了。 0 0 -0.004645 1.5707 0 0 true gaussian 0.0 0.1 再次将 Velodyne 传感器添加到 Gazebo，并在横梁前插入一个盒子。 打开主题可视化工具 (Ctrl-t)，然后选择 Velodyne 激光扫描主题。输出应该看起来很嘈杂。 现在让我们将噪音降低到合理的程度。 0 0 -0.004645 1.5707 0 0 true gaussian 0.0 0.02 常见传感器的噪声 介绍 Gazebo提供了很多常见传感器的模型，在真实的世界，传感器都会产生噪声，因为现实中的传感器并不能完美的观察这个世界。但是在默认的情况下，Gazebo的传感器可以完美的观察仿真世界，为了让仿真更加的真实，我们会在Gazebo的传感器中添加一些噪声到Gazebo传感器生成的数据中。 Gazebo目前可以给下面几个类型的传感器添加噪声: 射线类（Ray） (例如, 雷达) 相机（Camera） 惯性测量单元（IMU） 接下来带你一一介绍。 射线类-Ray（雷达）噪声 对于射线传感器，我们将高斯噪声加入到每个波束的范围中。你可以设置平均值和标准差正态分布，从中噪声值将被采样。噪声值为每个波束独立采样。在添加噪声后，产生的范围被限制在传感器的最小和最大范围(包括在内)之间。 测试传感器噪声模型： 创建模型目录 mkdir -p ~/.gazebo/models/noisy_laser 创建模型配置文件 gedit ~/.gazebo/models/noisy_laser/model.config 复制粘贴下面的代码到配置文件 Noisy laser 1.0 model.sdf My Name me@my.email My noisy laser. 创建一个文件 ~/.gazebo/models/noisy_laser/model.sdf gedit ~/.gazebo/models/noisy_laser/model.sdf 粘贴以下内容，这是添加了噪声的标准 Hokuyo 模型的代码： false 0.1 model://hokuyo/meshes/hokuyo.dae 0.01 0 0.03 0 -0 0 640 1 -2.26889 2.268899 0.08 10 0.01 gaussian 0.0 0.01 1 30 true 启动Gazebo： gazebo 插入嘈杂的激光：在左侧窗格中，选择Insert选项卡，然后单击。将您的激光器放在世界某处，并在其前面放置一个盒子。Noisy laser 可视化嘈杂的激光：单击窗口->主题可视化（或按 Ctrl-T）以调出主题选择器。 找到名称为 like 的主题并单击它，然后单击。您将获得一个显示激光数据的激光视图窗口。/gazebo/default/hokuyo/link/laser/scan Okay 如您所见，扫描噪声很大。要调整噪声，只需调整其中的平均值和标准偏差值，其中单位是米： model.sdf gaussian 0.0 0.01 这些是Hokuyo激光的合理值。 相机噪音 对于相机传感器，我们对输出放大器噪声进行建模，它为每个像素独立添加高斯采样干扰。您可以设置从中采样噪声值的高斯分布的均值和标准差。为每个像素独立采样一个噪声值，然后将该噪声值独立添加到该像素的每个颜色通道。添加噪声后，生成的颜色通道值被限制在 0.0 和 1.0 之间；这个浮点颜色值最终会在图像中作为一个无符号整数，通常在 0 到 255 之间（每个通道使用 8 位）。 此噪声模型在GLSL着色器中实现，需要 GPU 才能运行。 测试相机噪声模型： 创建模型目录： mkdir -p ~/.gazebo/models/noisy_camera 创建模型配置文件： gedit ~/.gazebo/models/noisy_camera/model.config 粘贴以下内容： Noisy camera 1.0 model.sdf My Name me@my.email My noisy camera. 创建一个文件。~/.gazebo/models/noisy_camera/model.sdf gedit ~/.gazebo/models/noisy_camera/model.sdf 粘贴以下内容，这是添加了噪点的标准相机模型的副本： false 0.05 0.05 0.05 0 0 0 0.1 0.1 0.1 0.1 1.047 1024 1024 0.1 100 gaussian 0.0 0.07 1 30 true 启动Gazebo： gazebo 插入嘈杂的摄像头：在左侧窗格中，选择Insert选项卡，然后单击。把你的相机放在世界的某个地方。Noisy camera 可视化嘈杂的摄像机：单击 Window->Topic Visualization（或按 Ctrl-T）以调出 Topic Selector。 找到名称为 like 的主题并单击它，然后单击。您将获得一个显示图像数据的图像视图窗口。/gazebo/default/camera/link/camera/image Okay 如果您仔细观察，您会发现图像有噪点。要调整噪声，只需调整这些是无单位的值；噪声将被添加到 [0.0,1.0] 范围内的每个颜色通道。 model.sdf 上面的例子很高，我们尝试减少这个值： gaussian 0.0 0.007 这些对于像样的数码相机来说是合理的值。 IMU 噪声 对于 IMU 传感器，我们对角速率和线性加速度的两种干扰进行建模：噪声和偏差。分别考虑角速率和线性加速度，导致该模型有 4 组参数：速率噪声、速率偏差、加速度噪声和加速度偏差。没有对 IMU 的方向数据应用噪声，该数据被提取为世界框架中的完美值（这在未来应该会改变）。 噪音是可加性的，从正态分布中取样。你可以设置高斯分布的平均值和标准差(一个用于比率，一个用于加速度) ，从中将采样噪声值。噪声值为每个样本的每个组件(x，y，z)独立采样，并添加到该组件中。 偏差也是附加的，但是只在模拟开始的时候会被取样一次。你可以设置高斯分布的平均值和标准差(一个用于比率，一个用于加速度) ，从中可以采样到偏差值。偏差将根据提供的参数进行取样，然后以等概率否定; 假设所提供的平均值表示偏差的大小，并且在两个方向上都可能存在偏差。此后，偏差是一个固定值，添加到每个样品的每个组分(x，y，z)。 注意： 根据被模拟的系统和物理引擎的配置，模拟的 IMU 数据可能已经很嘈杂，因为系统没有一直被求解到收敛。因此，根据您的应用程序，可能不需要添加噪声。 测试 IMU 噪声模型： 创建模型目录： mkdir -p ~/.gazebo/models/noisy_imu 创建模型配置文件： gedit ~/.gazebo/models/noisy_imu/model.config 粘贴以下内容： Noisy IMU 1.0 model.sdf My Name me@my.email My noisy IMU. 创建~/.gazebo/models/noisy_imu/model.sdf文件 gedit ~/.gazebo/models/noisy_imu/model.sdf 粘贴以下内容： 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 1 1000 启动Gazebo： gazebo 插入嘈杂的 IMU：在左侧窗格中，选择Insert选项卡，然后单击。将您的 IMU 放在世界的某个地方。Noisy IMU 可视化嘈杂的 IMU：单击 Window->Topic Visualization（或按Ctrl-T）调出 Topic Selector。 找到名称为 like 的主题并单击它，然后单击。您将获得一个显示 IMU 数据的文本视图窗口。/gazebo/default/imu/link/imu/imu Okay 在 IMU 等高速传感器上识别噪声可能很困难，尤其是在复杂系统中。您应该能够看到大的非零均值对噪声或偏差参数的影响。 要调整噪声，只需使用. 速率噪声和速率偏差的单位是 rad/s，加速度噪声和加速度偏差的单位是 m/s^2。 model.sdf 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 上面是一个高质量IMU的合理噪声配置值。 "},"ROS2/Nav2导航篇/第10章-SLAM建图/基础/001-图像常见格式及存储.html":{"url":"ROS2/Nav2导航篇/第10章-SLAM建图/基础/001-图像常见格式及存储.html","title":"图像常见格式及存储","keywords":"","body":"datetime:2023/10/09 11:03 author:nzb 该项目来源于大佬的动手学ROS2 1.图像常见格式及存储 在日常生活中，我们会用到各种各样的地图，比如交通轨道图、城市地图、世界地图。 1.地图分类 我们根据地图所表达信息的不同可以将地图分为三类： 1.1 尺度地图（Metric Map） 尺度地图用于表示尺寸距离，可以理解为把真实世界按比例缩小，尺度地图中每个点都可以使用一个经纬值进行表示。 因为尺度地图是按照真实世界按比例缩小，所以要有比例尺来表示缩小比例。 1.2 拓扑地图（Topological Map） 拓扑地图用于表示点与点之间的连接信息，比如地铁轨道交通图。 1.3 语义地图（Semantic Map） 语义地图可以理解为在上面两个地图上增加了语义，比如尺度地图中某处是红绿灯、斑马线。拓扑地图中某个点是深圳北站。 在机器人领域 尺度地图常用于定位于地图构建（Mapping）、定位（Localization）和同时定位与地图构建（Simultaneous Localization And Mapping，SLAM） 拓扑地图常用于路径规划（Path Planning） 语义地图常用于人机交互（Human Robot Interaction）。 2.地图的存储 地图也是图，所以地图一般以图片的形式存储下来，常见的格式比如png就是可以存储ROS2中的二维地图的。 但是对于一些三维的点云图，二维的方式就不怎么好存储，就需要一些特殊格式了，因为我们后面不涉及三维空间建图，这里就不在展开了。 2.占据栅格地图 我们先了解下什么是栅格地图（Grid Map）。 如上图将地图数据分割为一块块的栅格来表达地图信息，就是栅格地图。 那什么是占据（Occupancy）呢？ 机器人通过激光雷达等传感器来感知深度信息，但我们知道，传感器都是有噪声的（在前面的机器人仿真建模过程中，我们为了更加真实给激光雷达还添加了高斯噪声），所以机器人前方的某个位置到底有没有物体（障碍物）是不确定的。 我们可以采用概率来解决这一问题，认为确实有物体的栅格的占据率为100%，确定没有物体的栅格占据率为0%，不确定的栅格就用（确认占据概率/确认非占据概率）值表示占据率。 由此我们知道占据栅格地图就是一张写满占据率的格子组成的地图。 我们在做机器人的路径规划的时候，需要确定一个格子是有障碍物？没障碍物？还是未知呢？所以我们一般会设定两个阈值： 占据阈值（occupied_thresh），比如0.65，则表示栅格占据率大于0.65的认为是有障碍物。 空闲阈值（free_thresh），比如0.25，则表示栅格占据率小于0.25的认为没有障碍物。 那在free_thresh和occupied_thresh之间的则认为是未知区域（未探索）。 "},"ROS2/Nav2导航篇/第10章-SLAM建图/入门/001-SLAM前世今生.html":{"url":"ROS2/Nav2导航篇/第10章-SLAM建图/入门/001-SLAM前世今生.html","title":"SLAM前世今生","keywords":"","body":"datetime:2023/10/09 11:03 author:nzb 该项目来源于大佬的动手学ROS2 SLAM技术概述 第一节中我们知道，要解决机器人自主导航问题就需要有感知（建图和定位）参与，通过感知输出机器人当前环境的地图信息和位置。而本节要讲的SLAM就是解决地图和定位问题的。 1. SLAM是什么 SLAM是同步定位与地图构建(Simultaneous Localization And Mapping)的缩写。 先通过一个视频直观了解一下 视频中随着机器人的移动，机器人的传感器获取到了环境信息，然后完成对博物馆地图的构建。 有小伙伴可能会问，只看到建图没看到定位呀。细心观察可以发现建图的过程中，其实一直都在计算机器人的位置。 2. SLAM如何解决建图定位问题 机器人通过自身传感器数据处理进行位置估计，同时通过不断移动完成对整个未知环境的地图构建。这就是SLAM解决的问题。 那又是如何解决的呢？SLAM实现的方案很多，但是几个比较关键的技术如下： 传感器感知 通过各类传感器实现对环境的感知，比如通过激光雷达获取环境的深度信息。同时可以通过传感器融合来提高位置估计的精度，比如融合轮式里程计、IMU、雷达、深度相机数据等。 视觉/激光里程计 基本原理是通过前后数据之间对比得出机器人位置的变化。 回环检测 判断机器人是否到达之前到过的位置，可以解决位置估计误差问题，建图时可以纠正地图误差。 经典视觉SLAM结构 视觉SLAM主要是以视觉为传感器，解决定位与建图的问题，其主要可以分为前端、后端、回环检测和建图等四个部分，其中各个部分的作用分别为： （1）前端：前端也称为视觉里程计，其作用是接受传感器(相机)的数据，通过计算得到两帧图像之间传感器(相机)的位姿变化，并将此变化传递给后端进行优化。 （2）后端：后端的作用是接受前端传过来的位姿数据，从一系列带噪声的位姿数据中估计最优的轨迹与地图。 （3）回环检测：由于后端的估计总避免不了误差，经过较长一段的时间还是会有漂移，为了保证相机在经过同一点的时候，预测的轨迹点与之前是重合的，所以需要通过回环检测检测图像的相似性，将相同的位姿点约束到同一点，减少漂移的误差。 （4）建图：建图部分是为了构建周围环境的地图，表达“我周围的环境如何”。 经过上述的四个部分，机器人就能在一个陌生的环境中知道“我在哪”以及“我周围的环境如何”，这样机器人就能完成一些高层次的任务，如导航、规划等。 3.SLAM算法分类 从算法的对数据的处理方式上看，目前常用的SLAM开源算法可以分为两类 1.基于滤波，比如扩展卡尔曼滤波（EKF: Extended Kalman Filter）、粒子滤波(PF: Particle Filter)等。 ROS中的gmapping、hector_slam算法都是基于滤波实现的。 2.基于图优化，先通过传感器进行构图，然后对图进行优化。 目前比较主流的是图优化的方法，Cartographer就是基于图优化实现的。图优化相对于滤波，不用实时的进行计算，效率更高，消耗的资源更少，所以在实际场景中使用的更多。 4.SLAM开源库 4.1. Cartographer github地址：https://github.com/cartographer-project/cartographer Cartographer是一个可跨多个平台和传感器配置以2D和3D形式提供实时同时定位和建图（SLAM）的系统。 4.2. ORB_SLAM2(纯视觉) github地址：https://github.com/raulmur/ORB_SLAM2 ORB-SLAM2适用于单目，双目和RGB-D相机的实时SLAM库，用于计算相机轨迹和稀疏3D重建 4.3 VINS github地址：https://github.com/HKUST-Aerial-Robotics/VINS-Mono VINS-Mono是单目视觉惯性系统的实时SLAM框架。它使用基于优化的滑动窗口配方来提供高精度的视觉惯性测距。 5.总结 本节课我们简单介绍了下感知部分的技术担当SLAM，并对常用的开源库进行介绍，下一节我们就对其中的Cartograpger开源库进行介绍和安装。 参考文章： https://blog.csdn.net/heyijia0327/article/details/47686523 "},"ROS2/Nav2导航篇/第10章-SLAM建图/入门/002-Carto介绍及安装.html":{"url":"ROS2/Nav2导航篇/第10章-SLAM建图/入门/002-Carto介绍及安装.html","title":"Carto介绍及安装","keywords":"","body":"datetime:2023/10/09 11:03 author:nzb 该项目来源于大佬的动手学ROS2 2. Cartographer介绍与安装 1.Cartographer介绍 Cartographer是Google开源的一个可跨多个平台和传感器配置以2D和3D形式提供实时同时定位和建图（SLAM）的系统。 github地址：https://github.com/cartographer-project/cartographer 文档地址：https://google-cartographer.readthedocs.io/en/latest 机器人里，建图最终方案都是采用了Cartographer，甚至花费大量人力物力对Cartographer算法进行裁剪，这足以表明Cartographer算法的优越性。 Cartographer系统架构概述（简单看看即可，如果大家后面确定研究方向是SLAM可以深入学习）： 简单的可以看到左边的可选的输入有深度信息、里程计信息、IMU数据、固定Frame姿态。 2.Carttographer安装 2.1 apt安装 安装carotgrapher sudo apt install ros-humble-cartographer 需要注意我们不是直接使用cartographer，而是通过cartographer-ros功能包进行相关操作，所以我们还需要安装下cartographer-ros sudo apt install ros-humble-cartographer-ros 2.2 源码安装 比较推荐源码安装的方式，毕竟是以学习为目的，我们后面要稍微看一下源码。 将下面的源码克隆到fishbot_ws的src目录下： git clone https://ghproxy.com/https://github.com/ros2/cartographer.git -b ros2 git clone https://ghproxy.com/https://github.com/ros2/cartographer_ros.git -b ros2 安装依赖 这里我们使用rosdepc进行依赖的安装，rosdepc指令找不到可以先运行下面的一键安装命令，选择一键配置rosdep即可。 wget http://fishros.com/install -O fishros && . fishros 接着在fishbot_ws下运行下面这个命令进行依赖的安装。 rosdepc 是制作的国内版 rosdep，是一个用于安装依赖的工具。该工具的安装可以采用一键安装 进行，选项编号为3。安装完成后运行一次rodepc update即可使用。 rosdepc install -r --from-paths src --ignore-src --rosdistro $ROS_DISTRO -y 编译 这里有一个新的命令--packages-up-to，意思是其所有依赖后再编译该包 colcon build --packages-up-to cartographer_ros 2.3 测试是否安装成功 如果是源码编译请先source下工作空间后再使用下面指令查看是否安装成功； ros2 pkg list | grep cartographer 能看到下面的结果即可 cartographer_ros cartographer_ros_msgs 可能你会好奇为什么没有cartographer，因为cartographer包的编译类型原因造成的，不过没关系，cartographer_ros依赖于cartographer，所以有cartographer_ros一定有cartographer。 3.Cartographer参数配置 作为一个优秀的开源库，Cartographer提供了很多可以配置的参数，虽然灵活性提高了，但同时也提高了使用难度（需要对参数进行调节配置），所以有必要在正式使用前对参数进行基本的介绍。 因为我们主要使用其进行2D的建图定位，所以我们只需要关注2D相关的参数。 Cartographer参数是使用lua文件来描述的，不会lua也没关系，我们只是改改参数而已。 提示：lua中的注释采用 -- 开头 3.1 前端参数 文件：trajectory_builder_2d src/cartographer/configuration_files/trajectory_builder_2d.lua 请你打开这个文件自行浏览，对其中我们可能会在初次建图配置的参数进行介绍。 -- 是否使用IMU数据 use_imu_data = true, -- 深度数据最小范围 min_range = 0., -- 深度数据最大范围 max_range = 30., -- 传感器数据超出有效范围最大值时，按此值来处理 missing_data_ray_length = 5., -- 是否使用实时回环检测来进行前端的扫描匹配 use_online_correlative_scan_matching = true -- 运动过滤，检测运动变化，避免机器人静止时插入数据 motion_filter.max_angle_radians 3.2 后端参数 文件：pose_graph.lua-后端参数配置项 路径src/cartographer/configuration_files/pose_graph.lua 该文件主要和地图构建 --Fast csm的最低分数，高于此分数才进行优化。 constraint_builder.min_score = 0.65 --全局定位最小分数，低于此分数则认为目前全局定位不准确 constraint_builder.global_localization_min_score = 0.7 3.3 Carotgrapher_ROS参数配置 该部分参数主要是用于和ROS2进行通信和数据收发的配置，比如配置从哪个话题读取里程记数据，从哪个话题来获取深度信息（雷达）。 文件：backpack_2d.lua 路径：src/cartographer_ros/cartographer_ros/configuration_files/backpack_2d.lua include \"map_builder.lua\" include \"trajectory_builder.lua\" options = { map_builder = MAP_BUILDER, trajectory_builder = TRAJECTORY_BUILDER, -- 用来发布子地图的ROS坐标系ID，位姿的父坐标系，通常是map。 map_frame = \"map\", -- SLAM算法跟随的坐标系ID tracking_frame = \"base_link\", -- 将发布map到published_frame之间的tf published_frame = \"base_link\", -- 位于“published_frame ”和“map_frame”之间，用来发布本地SLAM结果（非闭环），通常是“odom” odom_frame = \"odom\", -- 是否提供里程计 provide_odom_frame = true, -- 只发布二维位姿态（不包含俯仰角） publish_frame_projected_to_2d = false, -- 是否使用里程计数据 use_odometry = false, -- 是否使用GPS定位 use_nav_sat = false, -- 是否使用路标 use_landmarks = false, -- 订阅的laser scan topics的个数 num_laser_scans = 0, -- 订阅多回波技术laser scan topics的个数 num_multi_echo_laser_scans = 1, -- 分割雷达数据的个数 num_subdivisions_per_laser_scan = 10, -- 订阅的点云topics的个数 num_point_clouds = 0, -- 使用tf2查找变换的超时秒数 lookup_transform_timeout_sec = 0.2, -- 发布submap的周期间隔 submap_publish_period_sec = 0.3, -- 发布姿态的周期间隔 pose_publish_period_sec = 5e-3, -- 轨迹发布周期间隔 trajectory_publish_period_sec = 30e-3, -- 测距仪的采样率 rangefinder_sampling_ratio = 1., --里程记数据采样率 odometry_sampling_ratio = 1., -- 固定的frame位姿采样率 fixed_frame_pose_sampling_ratio = 1., -- IMU数据采样率 imu_sampling_ratio = 1., -- 路标采样率 landmarks_sampling_ratio = 1., } 4.总结 本节我们简单的介绍了Cartographer以及二进制和源码安装的方法，并对参数进行介绍。 下一节我们就开始为fishbot配置cartographer，接着就可以使用fishbot进行建图了。 参考文章： https://google-cartographer.readthedocs.io/en/latest/configuration.html "},"ROS2/Nav2导航篇/第10章-SLAM建图/入门/003-配置FishBot进行建图.html":{"url":"ROS2/Nav2导航篇/第10章-SLAM建图/入门/003-配置FishBot进行建图.html","title":"配置FishBot进行建图","keywords":"","body":"datetime:2023/10/10 11:03 author:nzb 该项目来源于大佬的动手学ROS2 3. 配置Fishbot进行建图 上一节我们安装好了cartographer，这节课我们就开始配置cartographer进行建图。 我们需要创建一个功能包，将参数文件和Cartographer启动文件放到一起然后启动。 1.创建fishbot_cartographer 在src目录下，使用创建功能包指令，创建功能包 cd src ros2 pkg create fishbot_cartographer 接着创建配置文件夹、launch文件夹和rviz配置文件夹。 cd fishbot_cartographer mkdir config mkdir launch mkdir rviz 创建完成的功能包结构 . ├── CMakeLists.txt ├── config ├── launch ├── src ├── package.xml └── rviz 2.添加cartographer配置文件 在fishbot/config目录下创建fishbot_2d.lua文件。 接着我们来写一下配置文件，相较于默认的配置文件，主要修改以下内容（见注释） include \"map_builder.lua\" include \"trajectory_builder.lua\" options = { map_builder = MAP_BUILDER, trajectory_builder = TRAJECTORY_BUILDER, map_frame = \"map\", tracking_frame = \"base_link\", -- base_link改为odom,发布map到odom之间的位姿态 published_frame = \"odom\", odom_frame = \"odom\", -- true改为false，不用提供里程计数据 provide_odom_frame = false, -- false改为true，仅发布2D位资 publish_frame_projected_to_2d = true, -- false改为true，使用里程计数据 use_odometry = true, use_nav_sat = false, use_landmarks = false, -- 0改为1,使用一个雷达 num_laser_scans = 1, -- 1改为0，不使用多波雷达 num_multi_echo_laser_scans = 0, -- 10改为1，1/1=1等于不分割 num_subdivisions_per_laser_scan = 1, num_point_clouds = 0, lookup_transform_timeout_sec = 0.2, submap_publish_period_sec = 0.3, pose_publish_period_sec = 5e-3, trajectory_publish_period_sec = 30e-3, rangefinder_sampling_ratio = 1., odometry_sampling_ratio = 1., fixed_frame_pose_sampling_ratio = 1., imu_sampling_ratio = 1., landmarks_sampling_ratio = 1., } -- false改为true，启动2D SLAM MAP_BUILDER.use_trajectory_builder_2d = true -- 0改成0.10,比机器人半径小的都忽略 TRAJECTORY_BUILDER_2D.min_range = 0.10 -- 30改成3.5,限制在雷达最大扫描范围内，越小一般越精确些 TRAJECTORY_BUILDER_2D.max_range = 3.5 -- 5改成3,传感器数据超出有效范围最大值 TRAJECTORY_BUILDER_2D.missing_data_ray_length = 3. -- true改成false,不使用IMU数据，大家可以开启，然后对比下效果 TRAJECTORY_BUILDER_2D.use_imu_data = false -- false改成true,使用实时回环检测来进行前端的扫描匹配 TRAJECTORY_BUILDER_2D.use_online_correlative_scan_matching = true -- 1.0改成0.1,提高对运动的敏感度 TRAJECTORY_BUILDER_2D.motion_filter.max_angle_radians = math.rad(0.1) -- 0.55改成0.65,Fast csm的最低分数，高于此分数才进行优化。 POSE_GRAPH.constraint_builder.min_score = 0.65 --0.6改成0.7,全局定位最小分数，低于此分数则认为目前全局定位不准确 POSE_GRAPH.constraint_builder.global_localization_min_score = 0.7 -- 设置0可关闭全局SLAM -- POSE_GRAPH.optimize_every_n_nodes = 0 return options 3.添加launch文件 3.1 launch需要包含的节点 要完成使用Cartographer进行建图，需要两个节点的参与，整个过程的计算流图如下： /cartographer_node节点: 该节点从/scan和/odom话题接收数据进行计算，输出/submap_list数据. 该节点需要接收一个参数配置文件（第二部分写的那个）参数。 /occupancy_grid_node节点： 该节点接收/submap_list子图列表，然后将其拼接成map并发布 该节点需要配置地图分辨率和更新周期两个参数。 3.2 编写launch文件 在路径src/fishbot_cartographer/launch/下新建cartographer.launch.py文件，接着我们将上面两个节点加入到这个launch文件中。 我们在第二部分写的配置文件就是给cartographer_node节点的，可以通过这个节点启动参数configuration_directory和configuration_basename进行传递。 import os from launch import LaunchDescription from launch.substitutions import LaunchConfiguration from launch_ros.actions import Node from launch_ros.substitutions import FindPackageShare def generate_launch_description(): # 定位到功能包的地址 pkg_share = FindPackageShare(package='fishbot_cartographer').find('fishbot_cartographer') #=====================运行节点需要的配置======================================================================= # 是否使用仿真时间，我们用gazebo，这里设置成true use_sim_time = LaunchConfiguration('use_sim_time', default='true') # 地图的分辨率 resolution = LaunchConfiguration('resolution', default='0.05') # 地图的发布周期 publish_period_sec = LaunchConfiguration('publish_period_sec', default='1.0') # 配置文件夹路径 configuration_directory = LaunchConfiguration('configuration_directory',default= os.path.join(pkg_share, 'config') ) # 配置文件 configuration_basename = LaunchConfiguration('configuration_basename', default='fishbot_2d.lua') rviz_config_dir = os.path.join(pkg_share, 'config')+\"/cartographer.rviz\" print(f\"rviz config in {rviz_config_dir}\") #=====================声明三个节点，cartographer/occupancy_grid_node/rviz_node================================= cartographer_node = Node( package='cartographer_ros', executable='cartographer_node', name='cartographer_node', output='screen', parameters=[{'use_sim_time': use_sim_time}], arguments=['-configuration_directory', configuration_directory, '-configuration_basename', configuration_basename]) cartographer_occupancy_grid_node = Node( package='cartographer_ros', executable='cartographer_occupancy_grid_node', name='cartographer_occupancy_grid_node', output='screen', parameters=[{'use_sim_time': use_sim_time}], arguments=['-resolution', resolution, '-publish_period_sec', publish_period_sec]) rviz_node = Node( package='rviz2', executable='rviz2', name='rviz2', arguments=['-d', rviz_config_dir], parameters=[{'use_sim_time': use_sim_time}], output='screen') #===============================================定义启动文件======================================================== ld = LaunchDescription() ld.add_action(cartographer_node) ld.add_action(cartographer_occupancy_grid_node) ld.add_action(rviz_node) return ld 4.添加安装指令 做完上面的操作，我们还需要添加安装指令。 打开CmakeLists.txt，添加下面一条指令，将三个目录安装到install目录。 install( DIRECTORY config launch rviz DESTINATION share/${PROJECT_NAME} ) 5.开始建图 5.1编译启动 colcon build --packages-select fishbot_cartographer 启动建图前，需要先启动gazebo仿真环境，因为我们的建图程序依赖于Gazebo提供雷达和里程计等数据。 source install/setup.bash ros2 launch fishbot_description gazebo.launch.py source,启动建图 source install/setup.bash ros2 launch fishbot_cartographer cartographer.launch.py 5.2修改配置 如果一切正常，你应该看到的是一个空空如也的RVIZ界面 不用担心，此时地图其实已经有了，我们需要添加一下地图相关的插件即可。 通过Add->By Topic添加组件。 最后通过左边的插件你应该可以看到图和机器人了。 5.3开始建图 打开我们机器人遥控节点，降低速度，控制机器人走一圈，看看地图的变化。 ros2 run teleop_twist_keyboard teleop_twist_keyboard 6.保存地图 走完一圈，没有黑影部分，我们就可以保存地图为一个本地文件了。我们需要使用一个叫做nav2_map_server的工具。 6.1 安装nav2_map_server sudo apt install ros-humble-nav2-map-server 6.2 保存地图 ros2 run nav2_map_server map_saver_cli --help 可以看到有下面的用法 Usage: map_saver_cli [arguments] [--ros-args ROS remapping args] Arguments: -h/--help -t -f --occ --free --fmt --mode trinary(default)/scale/raw NOTE: --ros-args should be passed at the end of command line 我们的地图话题为map，文件名字我们用fishbot_map,所以有下面这个这样写的命令行。 # 先将地图保存到src/fishbot_cartographer/map目录下 cd src/fishbot_cartographer/ && mkdir map && cd map ros2 run nav2_map_server map_saver_cli -t map -f fishbot_map 接着我们就可以得到下面的两个文件 . ├── fishbot_map.pgm └── fishbot_map.yaml 0 directories, 2 files 这两个文件就是对当前地图保存下来的文件，其中.pgm是地图的数据文件，.yaml后缀的是地图的描述文件。 下面的导航过程中我们将要使用到地图文件进行路径的搜索和规划。 7.总结 本节带你一起完成了Fishbot的Cartographer配置和建图，下一节会对地图是什么以及如何使用进行介绍，接着我们就可以配置Nav2进行Fishbot的导航了。 "},"ROS2/Nav2导航篇/第10章-SLAM建图/进阶/001-ROS2地图加载与编辑.html":{"url":"ROS2/Nav2导航篇/第10章-SLAM建图/进阶/001-ROS2地图加载与编辑.html","title":"ROS2地图加载与编辑","keywords":"","body":"datetime:2023/10/10 11:03 author:nzb 该项目来源于大佬的动手学ROS2 1.地图文件介绍 1.地图数据文件.pgm介绍 OccupancyGrid由一个.yaml格式的元数据文件，和.pgm图片格式的地图数据文件组成。从上节课建图后保存的文件也可以看出。 . ├── fishbot_map.pgm └── fishbot_map.yaml 0 directories, 2 files 打开上节课建好的地图，观察下，你应该会有几点疑问： 不是说占据栅格地图每个栅格都有一个概率吗？为什么看不出来？ 立方体内和圆柱体内和墙之外的区域为什么是灰色的？ 原因如下： 一个栅格对应到图片上其实是一个像素，每一个像素的值在0-255之间，所以将像素值和占据率之间的映射即可，而像素值反应到图像上就是颜色的深浅，1.2图对应的像素颜色如下： 建图的时候物体内和墙之外的区域机器人并没有探索到，没有数据参考就认为其值是未知的。 2.地图描述文件.yaml介绍 除了fishbot_map.pgm文件外，还有另外一个fishbot_map.yaml的文件，fishbot_map.yaml文件是地图的配置文件，该文件内容如下： image: fishbot_map.pgm mode: trinary resolution: 0.05 origin: [ -3.37, -2.88, 0 ] negate: 0 occupied_thresh: 0.65 free_thresh: 0.25 image：图像名称 mode：图像模式，默认为trinary(三进制)，还有另外两个可选项scale(缩放的)和raw(原本的值)。 resolution：分辨率，一个栅格对应的物理尺寸，单位为m。0.05则表示一个栅格为0.05m origin：地图原点位置，单位是m。 negate：是否反转图像 cooupied_thresh：占据阈值 free_thresh：空闲阈值 如何在地图上找出机器人原点的像素位置？ 1、图像的像素原点在左下角 2、借张图左边的0,0是地图原点，右边的图0,0是图像的像素原点 3、假如机器人地图原点是[-3.37m, -2.88m]，除上分辨率则可得到像素原点[-67.4px,-57.6px]。地图原点在x和y轴分别偏移[-67.4px,-57.6px] 就到了像素原点，反过来说，地图原点就在像素原点的[67.4px,57.6px]处。 4、转换公式 像素点转地图点：地图点 = 地图原点 + (像素点 * 分辨率) 地图点转像素点：像素点= (地图点 - 地图原点) / 分辨率 拓展 Trinary（三进制）模式： 这种模式通常用于表示地图中的障碍物信息。可能有三种值，比如0表示自由空间，1表示障碍物，2表示未知区域。这样的表示方式对于一些算法（如路径规划）可能更易于处理。 Scale（缩放的）模式： 这种模式可能涉及到对地图数据进行缩放，以适应不同的需求或分辨率。缩放可以是线性的，也可以是非线性的，具体取决于实现。缩放的模式可能用于调整地图的精度或分辨率，以便在不同的应用场景中使用。 Raw（原本的值）模式： 这种模式可能表示地图数据的原始值，没有经过额外的处理或缩放。在这种模式下，地图数据通常以原始的形式进行存储和表示。 这些模式的选择可能取决于具体的应用场景和算法需求。例如，在进行路径规划时，使用trinary模式可能更方便，而在进行地图可视化时，可能会选择使用缩放或原始值模式。 3.地图加载 3.1 启动地图 了解完地图的格式和描述文件，接着我们看看如何将地图加载到rviz2中进行显示。我们使用nav2_map_server进行地图的保存，也可以使用它来加载地图。 打开终端，进入src/map/运行下面指令： #启动cartographer ros2 launch fishbot_cartographer cartographer.launch.py # 启动地图 ros2 run nav2_map_server map_server --ros-args --param yaml_filename:=fishbot_map.yaml 其中--ros-args --param yaml_filename:=fishbot_map.yaml指定地图描述文件名称.fishbot_map.yaml。 3.2 打开rviz2 打开终端 rviz2 通过add->bytopic->选择map组件。此时你应该什么都看不到，没关系，这是正常的。 3.3 配置并激活map_server map_server节点采用的是ROS2的生命周期进行编写的，除了启动节点，我们还需要手动的配置和激活节点才能使用。 打开新的终端，使用下面指令进行配置： ros2 lifecycle set /map_server configure 使用下面的指令进行激活： ros2 lifecycle set /map_server activate 完成这一步，你应该就可以在rviz2中看到地图了。 将栅格数量改大，然后将Grid的cellsize改成0.05,你就可以看到我们之间建立的地图每一个栅格的占据情况了。 生命周期节点转换图如下： 4.地图编辑 最后我们来说一下如何对地图进行编辑，地图编辑的方法有很多，你可以手动改图片，也可以通过opencv等图像处理库进行图像的去除噪点等操作。 这里介绍的是手动添加一个地图用PS进行编辑 。 打开网址：https://www.gaituya.com/ps/ 接着点击文件打开选择我们的.pgm文件，即可看到下图。 接着将下面的正方形给补上。 保存后在文件选择导出为png格式即可，因为PS并不支持pgm格式的导出，所以我们选择png格式，幸运的是png格式的地图也是被map_server所支持的。 把导出的图片放到map文件夹下，接着我们需要修改下yaml配置文件中图片的后缀。 image: fishbot_map.png mode: trinary resolution: 0.05 origin: [-3.37, -2.88, 0] negate: 0 occupied_thresh: 0.65 free_thresh: 0.25 接着你可以重新运行下map_server（记得先关闭rviz2），然后看一下map是否发生了改变。 5. 总结 本节我们主要学习了地图的相关概念以及加载和编辑的方式，下一节我们就开始正式学习Nav2导航框架。 参考文章： https://zhuanlan.zhihu.com/p/21738718 "},"ROS2/Nav2导航篇/第10章-SLAM建图/进阶/002-使用纯雷达定位建图.html":{"url":"ROS2/Nav2导航篇/第10章-SLAM建图/进阶/002-使用纯雷达定位建图.html","title":"使用纯雷达定位建图","keywords":"","body":"datetime:2023/10/10 11:03 author:nzb 该项目来源于大佬的动手学ROS2 Cartographer纯雷达定位建图 所谓纯雷达建图指不依靠IMU或者里程计信息，只使用雷达的深度点云进行建图，但我们的机器人在摩擦力较小容易打滑的地面或者没有里程计信息的机器人上，只使用激光雷达进行定位和建图往往可以取得较好的效果。 从里程计+雷达SLAM，切换成纯雷达SLAM只需要修改Cartographer的参数即可。 本代码基于Ubuntu22.04+ROS 2.0 humble版本进行测试。 机器人使用fishbot代码： 在fishbot的工作空间下新建cartographer配置文件 src/fishbot_cartographer/config/fishbot_laser_2d.lua ，新建launch文件：src/fishbot_cartographer/launch/cartographer_pure_laser.launch.py 配置文件 include \"map_builder.lua\" include \"trajectory_builder.lua\" options = { map_builder = MAP_BUILDER, trajectory_builder = TRAJECTORY_BUILDER, map_frame = \"map\", -- 跟踪和发布的frame都改成雷达的frameID tracking_frame = \"laser_frame\", published_frame = \"laser_frame\", odom_frame = \"odom\", -- true改为false，不用提供里程计数据 provide_odom_frame = true, -- false改为true，仅发布2D位资 publish_frame_projected_to_2d = false, use_pose_extrapolator = true, -- true改为false，不使用里程计数据 use_odometry = false, use_nav_sat = false, use_landmarks = false, -- 0改为1,使用一个雷达 num_laser_scans = 1, -- 1改为0，不使用多波雷达 num_multi_echo_laser_scans = 0, -- 10改为1，1/1=1等于不分割 num_subdivisions_per_laser_scan = 1, num_point_clouds = 0, lookup_transform_timeout_sec = 0.2, submap_publish_period_sec = 0.3, pose_publish_period_sec = 5e-3, trajectory_publish_period_sec = 30e-3, rangefinder_sampling_ratio = 1., odometry_sampling_ratio = 1., fixed_frame_pose_sampling_ratio = 1., imu_sampling_ratio = 1., landmarks_sampling_ratio = 1., } -- false改为true，启动2D SLAM MAP_BUILDER.use_trajectory_builder_2d = true -- 0改成0.10,比机器人半径小的都忽略 TRAJECTORY_BUILDER_2D.min_range = 0.10 -- 30改成3.5,限制在雷达最大扫描范围内，越小一般越精确些 TRAJECTORY_BUILDER_2D.max_range = 5.5 -- 5改成3,传感器数据超出有效范围最大值 TRAJECTORY_BUILDER_2D.missing_data_ray_length = 3. -- true改成false,不使用IMU数据，大家可以开启，然后对比下效果 TRAJECTORY_BUILDER_2D.use_imu_data = false -- false改成true,使用实时回环检测来进行前端的扫描匹配 TRAJECTORY_BUILDER_2D.use_online_correlative_scan_matching = true -- 1.0改成0.1,提高对运动的敏感度 -- TRAJECTORY_BUILDER_2D.motion_filter.max_angle_radians = math.rad(0.1) -- 0.55改成0.65,Fast csm的最低分数，高于此分数才进行优化。 POSE_GRAPH.constraint_builder.min_score = 0.65 --0.6改成0.7,全局定位最小分数，低于此分数则认为目前全局定位不准确 POSE_GRAPH.constraint_builder.global_localization_min_score = 0.7 TRAJECTORY_BUILDER_2D.real_time_correlative_scan_matcher.linear_search_window = 0.1 TRAJECTORY_BUILDER_2D.real_time_correlative_scan_matcher.translation_delta_cost_weight = 10. TRAJECTORY_BUILDER_2D.real_time_correlative_scan_matcher.rotation_delta_cost_weight = 1e-1 POSE_GRAPH.optimization_problem.huber_scale = 1e2 POSE_GRAPH.optimize_every_n_nodes = 35 -- 设置0可关闭全局SLAM -- POSE_GRAPH.optimize_every_n_nodes = 0 return options launch文件 接着我们新加一个launch文件，修改参数文件的名称，保存编译即可进行测试。 import os from launch import LaunchDescription from launch.substitutions import LaunchConfiguration from launch_ros.actions import Node from launch_ros.substitutions import FindPackageShare def generate_launch_description(): # 定位到功能包的地址 pkg_share = FindPackageShare(package='fishbot_cartographer').find('fishbot_cartographer') # =====================运行节点需要的配置======================================================================= # 是否使用仿真时间，我们用gazebo，这里设置成true use_sim_time = LaunchConfiguration('use_sim_time', default='false') # 地图的分辨率 resolution = LaunchConfiguration('resolution', default='0.05') # 地图的发布周期 publish_period_sec = LaunchConfiguration('publish_period_sec', default='1.0') # 配置文件夹路径 configuration_directory = LaunchConfiguration('configuration_directory', default=os.path.join(pkg_share, 'config')) # 配置文件 configuration_basename = LaunchConfiguration('configuration_basename', default='fishbot_laser_2d.lua') # =====================声明三个节点，cartographer/occupancy_grid_node/rviz_node================================= cartographer_node = Node( package='cartographer_ros', executable='cartographer_node', name='cartographer_node', output='screen', parameters=[{'use_sim_time': use_sim_time}], arguments=['-configuration_directory', configuration_directory, '-configuration_basename', configuration_basename]) cartographer_occupancy_grid_node = Node( package='cartographer_ros', executable='cartographer_occupancy_grid_node', name='cartographer_occupancy_grid_node', output='screen', parameters=[{'use_sim_time': use_sim_time}], arguments=['-resolution', resolution, '-publish_period_sec', publish_period_sec]) rviz_node = Node( package='rviz2', executable='rviz2', name='rviz2', # arguments=['-d', rviz_config_dir], parameters=[{'use_sim_time': use_sim_time}], output='screen') # ===============================================定义启动文件======================================================== ld = LaunchDescription() ld.add_action(cartographer_node) ld.add_action(cartographer_occupancy_grid_node) ld.add_action(rviz_node) return ld "},"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/入门/001-Nav2导航框架介绍.html":{"url":"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/入门/001-Nav2导航框架介绍.html","title":"Nav2导航框架介绍","keywords":"","body":"datetime:2023/10/11 11:03 author:nzb 该项目来源于大佬的动手学ROS2 1.Nav2导航框架介绍与安装 上一节我们对机器人导航过程中所用到的2D地图进行了介绍，本节我们就来正式的学习下Nav2导航框架，关于Nav2相关的更多资料，请访问Nav2中文网。 1.Nav2是什么 Nav2项目继承并发扬ROS导航栈的精神。该项目力求以安全的方式让移动机器人从A点移动到B点。Nav2也可以应用于其他应用，包括机器人导航，如下动态点跟踪，在这个过程中需要完成动态路径规划、计算电机的速度、避免障碍、恢复行为。 2.Nav2如何做到的 Nav2使用行为树调用模块化服务器来完成一个动作。动作可以是计算路径、控制力、恢复或任何其他与导航相关的操作。这些都是通过ROS Action服务器与行为树 (BT) 通信的独立节点。下图可以让你对Nav2的架构有一个很好的初步了解。 2.2 四个服务 再对上面的架构图进一步的进行解释，可以简单分为一大三小四个服务。 一大： BT Navigator Server 导航行为树服务，通过这个大的服务来进行下面三个小服务组织和调用。 三小： Planner Server，规划服务器，其任务是计算完成一些目标函数的路径。根据所选的命名法和算法，该路径也可以称为路线。说白了就是在地图上找路。 Controller Server，控制服务器，在ROS 1中也被称为局部规划器，是我们跟随全局计算路径或完成局部任务的方法。说白了就是根据找的路控制机器人走路。 Recovery Server，恢复服务器，恢复器是容错系统的支柱。恢复器的目标是处理系统的未知状况或故障状况并自主处理这些状况。说白了就是机器人可能出现意外的时候想办法让其正常，比如走着走着掉坑如何爬出来。 通过规划路径、控制机器人沿着路径运动、遇到问题自主恢复三者进行不断切换完成机器人的自主导航（在这个过程还需要很多节点和数据的辅助，详见下面的组建部分）。 2.3 两大代价（成本）地图 在机器人导航的时候，仅仅靠一张SLAM建立的原始地图是不够的，机器人在运动过程中可能会出现新的障碍物，也有可能发现原始地图中某一块的障碍物消失了，所以在机器人导航过程中维护的地图是一个动态的地图，根据更新频率方式和用途不同，可以分为下面两种。 注意：不论是全局代价地图还是局部代价地图都是有很多个图层共同叠加而成的，你也可以自己定义图层。 2.3.1 全局代价地图 （Global Costmap） 全局代价地图主要用于全局的路径规划器。从上面结构图中其在可以看到在Planner Server中。 通常包含的图层有： Static Map Layer：静态地图层，通常都是SLAM建立完成的静态地图。 Obstacle Map Layer：障碍地图层，用于动态的记录传感器感知到的障碍物信息。 Inflation Layer：膨胀层，在以上两层地图上进行膨胀（向外扩张），以避免机器人的外壳会撞上障碍物。 2.3.2 局部代价地图（Local Costmap） 局部代价地图主要用于局部的路径规划器。从上面结构图中其在可以看到在Controller Server中。 通常包含的图层有： Obstacle Map Layer：障碍地图层，用于动态的记录传感器感知到的障碍物信息。 Inflation Layer：膨胀层，在障碍地图层上进行膨胀（向外扩张），以避免机器人的外壳会撞上障碍物。 3.Nav2导航相关概念 该部分摘抄自Nav2中文网，中间删除了一些信息，全部文章请访问原文页面 。 3.1 动作服务器（Action Server） 动作服务器在第五章中 我们有简单介绍过，Nav2框架中大量的才用了这种通信方式，并将起分装成了行为树（关于行为树下面会介绍）的基础节点进行调用。 通过动作服务器通信，来计算路径规划、控制机器人运动和恢复。每个动作服务器都有自己独特的 nav2_msgs 格式的 .action 类型，用于与服务器进行交互。 3.2 生命周期节点和绑定 生命周期 (或被管理的，更正确的) 节点是ROS 2独有的。更多信息可以是 在这里 。它们是包含状态机转换的用于加载和卸载ROS 2服务器的节点。这有助于确定ROS系统启动和关闭的状态是否正常。 生命周期节点框架在整个项目中被广泛使用，所有服务器都使用它。如果可能的话，所有ROS系统最好使用生命周期节点。 上一节我们通过命令行来配置和激活map_server节点就是因为map_server节点采用了生命周期节点进行管理。 3.3 行为树 行为树 (BT) 在复杂的机器人任务中变得越来越普遍。它们是待完成任务的树形结构。行为树为定义多步或多状态应用程序创建了一个更具可扩展性和人类可理解性的框架。这与有限状态机 (FSM) 相反，后者可能有几十个状态和数百个状态过渡。 一个例子就是踢足球机器人。将足球比赛的逻辑嵌入FSM将具有挑战性，且容易出错因为有许多可能的状态和规则。此外，像从左侧、右侧或中间射门这样的建模选择尤其不清楚。使用行为树则可以为许多行为创建和重用基本原语，像 \"kick\" \"walk\" \"go to ball\" 。更多信息可以在 这本书 找到。强烈建议阅读第1-3章，以更好地理解术语和工作流程。大约需要30分钟。 Nav2项目使用 BehaviorTree CPP V3 作为行为树库。在 BT Navigator 中，创建了可以构建为行为树的节点插件。将节点插件加载到BT中，并且在解析该行为树的XML文件时，将关联注册的名称。此时，我们可以通过该行为树进行导航。 使用此库的一个原因是它能够加载子树。这意味着可以将Nav2行为树可以进行套娃操作。举个例子是在足球比赛中，使用Nav2行为树作为 \"go to ball\" 节点，将足球检测作为更大任务的一部分。此外，为BT提供了一个 NavigateToPoseAction 插件，因此可以从客户端应用程序通过通常的动作接口调用Nav2软件导航栈。 3.4 导航服务器 规划器和控制器是导航任务的核心。恢复器用于使机器人摆脱不良状态或尝试处理各种形式的问题，以使系统具有容错能力。在本节中，将分析有关它们的一般概念及其在Nav2项目中的用途。 3.4.1 规划器，控制器和恢复服务器 该项目中的三个Action Server是规划器、恢复器和控制器服务器。这些Action Server用于托管一个地图算法插件，以完成各种任务。它们还托管由该算法插件使用的环境表达，以计算其输出。 规划器（Planners） 规划器的任务是计算完成一些目标函数的路径。根据所选的命名法和算法，该路径也可以称为路线。两个典型示例是计算一个到达目标位姿的规划（例如从当前位置到达一个目标位姿）或者完全覆盖（例如覆盖所有空闲空间的规划）。规划器可以访问全局环境表达和缓存在其中的传感器数据。规划器可以被编写为具有以下功能的工具： 计算最短路径 计算完整覆盖路径 沿稀疏或预定义路线计算路径 Nav2中规划器的一般任务是计算从当前位置到达目标位姿的一个有效且可能是最佳的路径。 控制器 （Controllers） 控制器，在ROS 1中也被称为局部规划器，是我们跟随全局计算路径或完成局部任务的方法。控制器有权访问局部环境表达，以尝试计算要跟随的基准路径的可行控制工作。许多控制器会将机器人向前投射到空间中，并在每次更新迭代时计算局部可行路径。控制器可以被编写为具有以下功能的工具： 跟随路径 使用里程计坐标系中的检测器与充电站（桩）对接 登上电梯 与某个工具的接口 在Nav2中，控制器的一般任务是计算一个有效的控制工作以跟随全局规划路径。然而，有多个控制器类和局部规划器类。Nav2项目的目标就是所有控制器算法都可以作为此服务器中的插件，以用于一般研究和产业任务中。 恢复器 （Recovery） 恢复器是容错系统的支柱。恢复器的目标是处理系统的未知状况或故障状况并自主处理这些状况。例子包括感知系统中会导致环境表达充满假障碍物的故障。这样就会触发清除成本地图恢复以允许机器人移动。 另一个例子就是机器人由于动态障碍物或控制不佳而卡住。在允许的情况下，倒退或原地旋转会允许机器人从卡住的位置移动到可以成功进行导航的自由空间中。 最后，在完全故障的情况下，可以实施恢复以引起操作员的注意以寻求帮助。这可以通过电子邮件、短信、Slack、Matrix等来完成。 3.4.2 航点跟随 航点跟随是导航系统的基本功能之一。它会告知系统如何使用导航程序到达多个目的地。 nav2_waypoint_follower 软件包含一个航路点跟踪程序，该程序具有特定任务执行程序的插件接口。如果需要让机器人前往给定位姿并完成像拍照、捡起盒子或等待用户输入之类的特定任务，这会非常有用。 关于机器人队管理器/调度器有两种思想流派：哑机器人+智能集中式调度器；智能机器人+哑集中式调度器。 在第一种思想中， nav2_waypoint_follower 软件包足以创造一个产品级的机器人解决方案。由于自主系统/调度器在分配任务时会考虑机器人的姿势、电池电量、当前任务等因素，机器人上的应用程序只需要关心手头的任务，而不用关心完成系统要求任务的其他复杂因素。在这种情况下，应该将发送至航点跟随者的请求视为1个工作单元（例如，仓库中的1次拣货、1个安全巡逻循环、1个过道等）来执行任务，然后返回给调度器以进行下一个任务或者要求充电。在这种思想流派中，航点跟随应用程序只是导航软件堆栈之上和系统自主应用程序之下的一个步骤。 在第二种思想中， nav2_waypoint_follower 软件包是一个不错的示例应用程序/概念证明，但确实需要机器人上的航点跟踪/自主系统来承担更多任务以制定健壮的解决方案。在这种情况下，应该使用 nav2_behavior_tree 软件包创建自定义应用程序级别的行为树，以使用导航来完成任务。这可以包含子树，例如在任务中检查充电状态以返回停泊坞，或者在更复杂的任务中处理1个以上的工作单元。很快，将会有一个 nav2_bt_waypoint_follower (名称有待调整)，它将允许用户更容易地创建此应用程序。在这个思想流派中，航点跟随应用程序与自主系统的联系更加紧密，或者在很多情况下，航点跟随应用程序就是自主系统本身。 这两种思想流派并不能简单地说谁比谁更好，谁更好很大程度上取决于机器人正在完成何种任务、处于何种类型的环境中以及有何种可用的云资源。通常，对于既定的业务案例，这种区别非常明显。 3.5 状态估计（重要组件） Nav2中，默认进行状态估计的组件是AMCL (Adaptive Monte Carlo Localization)自适应蒙特卡洛定位。nav2中对应的功能包是nav2_amcl。 根据ROS社区标准，在导航项目中，需要提供两个主要的坐标转换。 map 到 odom 的坐标变换由定位系统 (定位，建图，SLAM)提供， odom 到 base_link 的坐标转换由里程计系统提供。 注解：无需在机器人上使用LIDAR即可使用导航系统。不需要使用基于激光雷达的防撞、定位或SLAM系统。但是，Nav2确实可以提供说明和支持使用激光雷达对这些系统进行尝试和真实实现。使用基于视觉或深度传感器的定位系统和使用其他传感器来避免碰撞可以同样成功。唯一的要求就是在选择具体实现方式时遵循REP-105标准。 REP-105标准 REP 105 定义了导航和更大的ROS生态系统所需的框架和约定。应始终遵循这些约定，以利用社区中丰富的定位、里程计和SLAM项目。 简而言之，REP-105至少必须为机器人构造一个包含map -> odom -> base_link -> [sensorframes] 的完整 的TF树。TF2是 ROS 2中的时变坐标变换库，Nav2使用TF2来表达和获取时间同步的坐标变换。全球定位系统 (GPS、SLAM、动作捕捉Motion Capture) 的工作是至少要提供 map-> odom 的坐标转换。然后，里程计系统的作用是提供 odom -> base_link 的坐标转化。关于 base_link 的其余坐标转换应该是静态的，并应在 URDF 中定义。 3.6 全局定位: 定位与SLAM 全局定位系统 (GPS、SLAM、运动捕捉) 的工作是至少提供 map -> odom 的坐标转换。Nav2项目提供的 amcl 是一种基于粒子过滤器的自适应蒙特卡罗定位技术，用于静态地图的定位。Nav2还提供用于定位和生成静态映射的SLAM工具箱作为默认的SLAM算法。 这些方法还可能产生其他输出，包括位置话题、地图或其他元数据，但它们必须提供该转换才能有效。使用机器人定位可以将多种定位方法融合在一起，下面将详细讨论。 3.7 里程计（Odometry） 里程计系统的作用是提供 odom -> base_link 的坐标转换。里程计可以来自许多数据源，包括激光雷达、车轮编码器、VIO和IMU。里程计的目标是提供基于机器人运动的平滑和连续的局部坐标系。全局定位系统会相对全局坐标的坐标变换进行更新，以解决里程计的漂移问题。 这个 Robot Localization 通常用于这种融合。它将采用各种类型的 N 个传感器，并为TF和话题提供连续平滑的里程计。一个典型的移动机器人装置可能有来自车轮编码器或IMU的里程计以及融合在这个工作区内的视觉。 这样平滑输出就可用于精确运动的航行位置推算和在全局位置更新之间准确地更新机器人的位置。 3.8 环境表达（建模） 环境表征是机器人感知环境的方式。它还充当各种算法和数据源的中心定位工具，以将它们的信息组合到一个空间中。这样，控制器、规划器和恢复器就可以使用该空间来安全有效地计算它们的任务。 成本地图和图层 当前的环境表达是一个成本地图。成本地图是包含来自未知、空闲、占用或膨胀成本的单元格的规则2D单元格网格。然后搜索该成本地图以计算全局计划或采样以计算局部控制工作。 各种成本地图图层被实现为pluginlib插件，以将信息缓冲到成本地图中。这包括来自LIDAR、RADAR、声纳、深度传感器、图像传感器等的信息。最好在传感器数据输入到成本地图之前进行处理，但这取决于开发人员。 可以使用相机或深度传感器创建代价地图层来检测和跟踪场景中的障碍物，以避免碰撞。此外，可以创建层来基于一些规则或启发式算法来改变基础成本图。最后，它们可用于将实时数据缓冲到2D或3D世界中，以进行障碍物的二值化标记。 成本地图过滤器 想象一下，您正在注释地图文件 (或任何图像文件)，以便根据注释地图中的位置执行特定操作。 通过使用成本地图过滤器可以实现以下功能： 机器人永远不会进入的禁区/安全区。 限速区，机器人进入这些区域的最大速度将受到限制。 机器人在工业环境和仓库中移动的首选通道。 其他形式的环境表示 存在各种其他形式的环境表征。包括: 梯度图，类似于成本地图，但梯度图会表达表面梯度以检查可穿越性 3D成本图，以3D形式表示空间，但这样就也需要3D规划和碰撞检测 网格图，类似于梯度图，但具有多个角度的表面网格 Vector space ，接收传感器信息并使用机器学习算法来检测要跟踪的单个物品和位置，而不是对离散点进行缓冲区计算 4.Nav2下载安装 看完了第三节的是不是似懂非懂，接下来我们将通过实验进一步来对照着学习。 Nav2的安装有两种方式，一种是通过二进制直接安装，另外一种是通过源码的方式进行安装，这里依然推荐源码的方式，毕竟我们还是要看一看Nav2的源码的。 4.1 apt安装 安装nav2 sudo apt install ros-humble-nav2-* 4.2 源码安装 将下面的源码克隆到fishbot_ws的src目录下： git clone https://ghproxy.com/https://github.com/ros-planning/navigation2.git -b humble 安装依赖 这里我们使用rosdepc进行依赖的安装，rosdepc指令找不到可以先运行下面的一键安装命令，选择一键配置rosdep即可。 wget http://fishros.com/install -O fishros && . fishros 接着在fishbot_ws下运行下面这个命令进行依赖的安装。 rosdepc install -r --from-paths src --ignore-src --rosdistro $ROS_DISTRO -y 编译 这里有一个新的命令--packages-up-to，意思是其所有依赖后再编译该包 colcon build --packages-up-to navigation2 4.3 测试是否安装成功 如果是源码编译请先source下工作空间后再使用下面指令查看是否安装成功； ros2 pkg list | grep navigation2 能看到下面的结果即可 navigation2 5.源码功能包拆解 包含代码的功能包及其功能见下面列表 #==============控制器及其实现相关功能包======================# nav2_controller　｜　控制器 nav2_dwb_controller | DWB控制器，Nav2控制器的一个实现 nav2_regulated_pure_pursuit_controller | 纯追踪控制器，Nav2控制器的一个实现 nav2_constrained_smoother #==============规划器及其实现相关功能包======================# nav2_planner | Nav2规划器 nav2_navfn_planner　｜　navfn规划器，Nav2规划器的一个实现 nav2_smac_planner | smac规划器，Nav2规划器的一个实现 #=====================恢复器==============================# nav2_recoveries | Nav2恢复器 #=====================行为树节点及其定义====================# nav2_bt_navigator |　导航行为树 nav2_behavior_tree | 行为树节点插件定义 #=====================地图和定位===========================# nav2_map_server　｜　地图服务器 nav2_costmap_2d　｜　2D代价地图 nav2_voxel_grid | 体素栅格 nav2_amcl | 自适应蒙特卡洛定位。　　状态估计，输入地图、激光、里程计数据，输出机器人map和odom之间的位姿关系。 #=====================通用插件系统管理等====================# nav2_bringup | 启动入口 nav2_common　｜　公共功能包 nav2_msgs　｜　通信相关消息定义 nav2_util | 常用工具 nav2_lifecycle_manager |节点生命周期管理器　 nav2_rviz_plugins | RVIZ插件 #=====================核心定义============================# nav2_core　｜　Nav2核心包 navigation2 | nav2导航汇总配置 #=====================应用================================# nav2_waypoint_follower | 路点跟踪 #=====================测试=================================# nav2_system_tests | 系统测试 上面的每个节点都有自己的参数可以配置，下一节我们就对个个节点的配置进行介绍并进行适配 6.总结 本节我们对Nav2进行了详细的介绍和安装，下一节我们就开始为FishBot配置Nav2，然后开始尝试让Nav2控制Fishbot自主的移动起来。 "},"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/入门/002-为FishBot配置Nav2.html":{"url":"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/入门/002-为FishBot配置Nav2.html","title":"为FishBot配置Nav2","keywords":"","body":"datetime:2023/10/12 11:03 author:nzb 该项目来源于大佬的动手学ROS2 2.为FishBot配置Nav2 安装好了Nav2，我们开始针对我们的fishbot改变一些参数进行导航相关的参数配置。Nav2可配置的参数比起Cartographer更多，但是不要害怕，因为大多数参数我们可能不会改变。 有关Nav2的更多参数介绍和详细的配置意义，可以参考Nav2中文网配置指南一节。 本节主要准备两个文件给launch节点使用，第一个是地图文件，第二个是nav2参数文件。 1.创建fishbot_navigation2 1.1创建功能包 和前面在Cartographer中一样，我们需要创建一个文件夹放置配置文件、launch文件、rviz配置和地图等。 进入到src目录下，使用下面指令创建功能包： ros2 pkg create fishbot_navigation2 --dependencies nav2_bringup 这里我们添加了一个依赖nav2_bringup，后面写launch文件要用到，这里提前添加一下依赖。 创建完成后的目录结构： . ├── CMakeLists.txt ├── include │ └── fishbot_navigation2 ├── package.xml └── src 3 directories, 2 files 1.2 添加maps文件夹 cd src/fishbot_navigation2 mkdir launch config maps param rviz 1.3 复制地图文件 将上一节的地图文件复制到map文件夹下。 复制完成后fishbot_navigation2的文件结构如下 . ├── CMakeLists.txt ├── config ├── launch ├── maps │ ├── fishbot_map.png │ ├── fishbot_map.pgm │ ├── fishbot_map.yaml ├── package.xml ├── param └── rviz 5 directories, 5 files 2.添加Nav2配置文件 2.1 创建参数文件 我们需要配置的文件是Nav2的参数文件，同样的，贴心的Nav2已经为我们准备好了参数模板 src/navigation2/nav2_bringup/bringup/params/nav2_params.yaml 在src/fishbot_navigation2/param/目录下创建fishbot_nav2.yaml cd src/fishbot_navigation2/param/ touch fishbot_nav2.yaml 2.2 复制参数 然后将src/navigation2/nav2_bringup/bringup/params/nav2_params.yaml的内容复制粘贴到fishbot_nav2.yaml文件中。 参数文件中的参数是谁的？ 在之前的章节保存参数中，我们曾用ros2 param dump 指令将某个节点的参数保存为一个.yaml格式的文件。fishbot_nav2.yaml文件就是保存Nav2相关节点参数的文件。 3. 配置参数 其实参数不配置也是可以将Nav2跑起来的，但是后期想要更改运行的效果就需要对参数进行修改，所以有必要大概了解下参数的配置项和含义查询方法和修改方法。 3.1 参数列表 编号 配置项 用途 对应模块与参数详解 1 amcl 机器人定位 nav2_amcl 2 bt_navigator 导航行为树（用于加载行为树节点并根据xml配置进行调度） nav2_bt_navigator , nav2_behavior_tree 3 controller_server 控制器服务器 nav2_controller , nav2_dwb_controller, nav2_regulated_pure_pursuit_controller 4 planner_server 规划服务器 nav2_planner , nav2_navfn_planner, smac_planner 5 recoveries_server 恢复服务器 nav2_recoveries 6 local_costmap 局部代价地图 nav2_costmap_2d , static_layer, inflation_layer 7 global_costmap 全局代价地图 nav2_costmap_2d , nav2_map_server 有关更多的Nav2所有参数的详细介绍，可以访问Nav2中文网中的配置指南章节，非常的详细，无比的具体。 3.2 配置机器人半径和碰撞半径 在全局代价地图和局部代价地图配置用，默认的机器人半径是0.22，而我们fishbot的半径是0.12，所以需要修改机器人的半径为0.12。 local_costmap: local_costmap: ros__parameters: robot_radius: 0.12 global_costmap: global_costmap: ros__parameters: robot_radius: 0.12 为了防止机器人发生碰撞，一般我们会给代价地图添加一个碰撞层（inflation_layer），在local_costmap和global_costmap配置中，你可以看到下面关于代价地图相关的配置： global_costmap: global_costmap: ros__parameters: plugins: [ \"static_layer\", \"obstacle_layer\", \"inflation_layer\" ] inflation_layer: plugin: \"nav2_costmap_2d::InflationLayer\" cost_scaling_factor: 3.0 inflation_radius: 0.55 打开参数配置中的inflation_layer ，我们来看看其配置项和含义。 可以看到inflation_radius默认0.55对fishbot来说可能有些大了，我们改小些。 global_costmap: global_costmap: ros__parameters: plugins: [\"static_layer\", \"obstacle_layer\", \"inflation_layer\"] inflation_layer: plugin: \"nav2_costmap_2d::InflationLayer\" cost_scaling_factor: 3.0 inflation_radius: 0.35 以上就是以代价地图碰撞半径为例的配置方法，nav2可以配置的参数非常多，假如你在导航过程中遇到问题，根据问题的表现推断下是哪个模块中造成的，接着修改其对应参数，大概率就可以解决问题，解决不了的可以看源码详细分析。 3.3 配置frame_id和话题 这里也不用配置，因为我们的fishbot话题名称和tf名称都是遵循着默认的话题的。 如果你的机器人不是，或者你改变了话题，这里就需要重新配置。 默认全局的坐标系：map 默认里程计坐标系：odom 默认雷达话题：scan 默认机器人基坐标系：base_link 默认地图话题：map 4. 总结 本节我们简单的了解了Nav2各个模块参数的配置方法和参数的介绍，下一节就开始编写文件正式建图。 完整的配置文件如下 amcl: ros__parameters: use_sim_time: True alpha1: 0.2 alpha2: 0.2 alpha3: 0.2 alpha4: 0.2 alpha5: 0.2 base_frame_id: \"base_link\" beam_skip_distance: 0.5 beam_skip_error_threshold: 0.9 beam_skip_threshold: 0.3 do_beamskip: false global_frame_id: \"map\" lambda_short: 0.1 laser_likelihood_max_dist: 2.0 laser_max_range: 100.0 laser_min_range: -1.0 laser_model_type: \"likelihood_field\" max_beams: 60 max_particles: 2000 min_particles: 500 odom_frame_id: \"odom\" pf_err: 0.05 pf_z: 0.99 recovery_alpha_fast: 0.0 recovery_alpha_slow: 0.0 resample_interval: 1 robot_model_type: \"nav2_amcl::DifferentialMotionModel\" save_pose_rate: 0.5 sigma_hit: 0.2 tf_broadcast: true transform_tolerance: 10.0 update_min_a: 0.2 update_min_d: 0.25 z_hit: 0.5 z_max: 0.05 z_rand: 0.5 z_short: 0.05 scan_topic: scan amcl_map_client: ros__parameters: use_sim_time: True amcl_rclcpp_node: ros__parameters: use_sim_time: True bt_navigator: ros__parameters: use_sim_time: True global_frame: map robot_base_frame: base_link odom_topic: /odom bt_loop_duration: 10 default_server_timeout: 20 # 'default_nav_through_poses_bt_xml' and 'default_nav_to_pose_bt_xml' are use defaults: # nav2_bt_navigator/navigate_to_pose_w_replanning_and_recovery.xml # nav2_bt_navigator/navigate_through_poses_w_replanning_and_recovery.xml # They can be set here or via a RewrittenYaml remap from a parent launch file to Nav2. plugin_lib_names: - nav2_compute_path_to_pose_action_bt_node - nav2_compute_path_through_poses_action_bt_node - nav2_smooth_path_action_bt_node - nav2_follow_path_action_bt_node - nav2_spin_action_bt_node - nav2_wait_action_bt_node - nav2_back_up_action_bt_node - nav2_drive_on_heading_bt_node - nav2_clear_costmap_service_bt_node - nav2_is_stuck_condition_bt_node - nav2_goal_reached_condition_bt_node - nav2_goal_updated_condition_bt_node - nav2_globally_updated_goal_condition_bt_node - nav2_is_path_valid_condition_bt_node - nav2_initial_pose_received_condition_bt_node - nav2_reinitialize_global_localization_service_bt_node - nav2_rate_controller_bt_node - nav2_distance_controller_bt_node - nav2_speed_controller_bt_node - nav2_truncate_path_action_bt_node - nav2_truncate_path_local_action_bt_node - nav2_goal_updater_node_bt_node - nav2_recovery_node_bt_node - nav2_pipeline_sequence_bt_node - nav2_round_robin_node_bt_node - nav2_transform_available_condition_bt_node - nav2_time_expired_condition_bt_node - nav2_path_expiring_timer_condition - nav2_distance_traveled_condition_bt_node - nav2_single_trigger_bt_node - nav2_is_battery_low_condition_bt_node - nav2_navigate_through_poses_action_bt_node - nav2_navigate_to_pose_action_bt_node - nav2_remove_passed_goals_action_bt_node - nav2_planner_selector_bt_node - nav2_controller_selector_bt_node - nav2_goal_checker_selector_bt_node - nav2_controller_cancel_bt_node - nav2_path_longer_on_approach_bt_node - nav2_wait_cancel_bt_node - nav2_spin_cancel_bt_node - nav2_back_up_cancel_bt_node - nav2_drive_on_heading_cancel_bt_node bt_navigator_rclcpp_node: ros__parameters: use_sim_time: True controller_server: ros__parameters: use_sim_time: True controller_frequency: 20.0 min_x_velocity_threshold: 0.001 min_y_velocity_threshold: 0.5 min_theta_velocity_threshold: 0.001 failure_tolerance: 0.3 progress_checker_plugin: \"progress_checker\" goal_checker_plugins: [\"general_goal_checker\"] # \"precise_goal_checker\" controller_plugins: [\"FollowPath\"] # Progress checker parameters progress_checker: plugin: \"nav2_controller::SimpleProgressChecker\" required_movement_radius: 0.5 movement_time_allowance: 10.0 # Goal checker parameters #precise_goal_checker: # plugin: \"nav2_controller::SimpleGoalChecker\" # xy_goal_tolerance: 0.25 # yaw_goal_tolerance: 0.25 # stateful: True general_goal_checker: stateful: True plugin: \"nav2_controller::SimpleGoalChecker\" xy_goal_tolerance: 0.25 yaw_goal_tolerance: 0.25 # DWB parameters FollowPath: plugin: \"dwb_core::DWBLocalPlanner\" debug_trajectory_details: True min_vel_x: 0.0 min_vel_y: 0.0 max_vel_x: 0.26 max_vel_y: 0.0 max_vel_theta: 1.0 min_speed_xy: 0.0 max_speed_xy: 0.26 min_speed_theta: 0.0 # Add high threshold velocity for turtlebot 3 issue. # https://github.com/ROBOTIS-GIT/turtlebot3_simulations/issues/75 acc_lim_x: 2.5 acc_lim_y: 0.0 acc_lim_theta: 3.2 decel_lim_x: -2.5 decel_lim_y: 0.0 decel_lim_theta: -3.2 vx_samples: 20 vy_samples: 5 vtheta_samples: 20 sim_time: 1.7 linear_granularity: 0.05 angular_granularity: 0.025 transform_tolerance: 0.2 xy_goal_tolerance: 0.25 trans_stopped_velocity: 0.25 short_circuit_trajectory_evaluation: True stateful: True critics: [\"RotateToGoal\", \"Oscillation\", \"BaseObstacle\", \"GoalAlign\", \"PathAlign\", \"PathDist\", \"GoalDist\"] BaseObstacle.scale: 0.02 PathAlign.scale: 32.0 PathAlign.forward_point_distance: 0.1 GoalAlign.scale: 24.0 GoalAlign.forward_point_distance: 0.1 PathDist.scale: 32.0 GoalDist.scale: 24.0 RotateToGoal.scale: 32.0 RotateToGoal.slowing_factor: 5.0 RotateToGoal.lookahead_time: -1.0 controller_server_rclcpp_node: ros__parameters: use_sim_time: True local_costmap: local_costmap: ros__parameters: update_frequency: 5.0 publish_frequency: 2.0 global_frame: odom robot_base_frame: base_link use_sim_time: True rolling_window: true width: 3 height: 3 resolution: 0.05 robot_radius: 0.22 plugins: [\"voxel_layer\", \"inflation_layer\"] inflation_layer: plugin: \"nav2_costmap_2d::InflationLayer\" cost_scaling_factor: 3.0 inflation_radius: 0.55 voxel_layer: plugin: \"nav2_costmap_2d::VoxelLayer\" enabled: True publish_voxel_map: True origin_z: 0.0 z_resolution: 0.05 z_voxels: 16 max_obstacle_height: 2.0 mark_threshold: 0 observation_sources: scan scan: topic: /scan max_obstacle_height: 2.0 clearing: True marking: True data_type: \"LaserScan\" raytrace_max_range: 3.0 raytrace_min_range: 0.0 obstacle_max_range: 2.5 obstacle_min_range: 0.0 static_layer: map_subscribe_transient_local: True always_send_full_costmap: True local_costmap_client: ros__parameters: use_sim_time: True local_costmap_rclcpp_node: ros__parameters: use_sim_time: True global_costmap: global_costmap: ros__parameters: update_frequency: 1.0 publish_frequency: 1.0 global_frame: map robot_base_frame: base_link use_sim_time: True robot_radius: 0.22 resolution: 0.05 track_unknown_space: true plugins: [\"static_layer\", \"obstacle_layer\", \"inflation_layer\"] obstacle_layer: plugin: \"nav2_costmap_2d::ObstacleLayer\" enabled: True observation_sources: scan scan: topic: /scan max_obstacle_height: 2.0 clearing: True marking: True data_type: \"LaserScan\" raytrace_max_range: 3.0 raytrace_min_range: 0.0 obstacle_max_range: 2.5 obstacle_min_range: 0.0 static_layer: plugin: \"nav2_costmap_2d::StaticLayer\" map_subscribe_transient_local: True inflation_layer: plugin: \"nav2_costmap_2d::InflationLayer\" cost_scaling_factor: 3.0 inflation_radius: 0.55 always_send_full_costmap: True global_costmap_client: ros__parameters: use_sim_time: True global_costmap_rclcpp_node: ros__parameters: use_sim_time: True map_server: ros__parameters: use_sim_time: True yaml_filename: \"turtlebot3_world.yaml\" map_saver: ros__parameters: use_sim_time: True save_map_timeout: 5.0 free_thresh_default: 0.25 occupied_thresh_default: 0.65 map_subscribe_transient_local: True planner_server: ros__parameters: expected_planner_frequency: 20.0 use_sim_time: True planner_plugins: [\"GridBased\"] GridBased: plugin: \"nav2_navfn_planner/NavfnPlanner\" tolerance: 0.5 use_astar: false allow_unknown: true planner_server_rclcpp_node: ros__parameters: use_sim_time: True smoother_server: ros__parameters: use_sim_time: True smoother_plugins: [\"simple_smoother\"] simple_smoother: plugin: \"nav2_smoother::SimpleSmoother\" tolerance: 1.0e-10 max_its: 1000 do_refinement: True behavior_server: ros__parameters: costmap_topic: local_costmap/costmap_raw footprint_topic: local_costmap/published_footprint cycle_frequency: 10.0 behavior_plugins: [\"spin\", \"backup\", \"drive_on_heading\", \"wait\"] spin: plugin: \"nav2_behaviors/Spin\" backup: plugin: \"nav2_behaviors/BackUp\" drive_on_heading: plugin: \"nav2_behaviors/DriveOnHeading\" wait: plugin: \"nav2_behaviors/Wait\" global_frame: odom robot_base_frame: base_link transform_tolerance: 0.1 use_sim_time: true simulate_ahead_time: 2.0 max_rotational_vel: 1.0 min_rotational_vel: 0.4 rotational_acc_lim: 3.2 robot_state_publisher: ros__parameters: use_sim_time: True waypoint_follower: ros__parameters: loop_rate: 20 stop_on_failure: false waypoint_task_executor_plugin: \"wait_at_waypoint\" wait_at_waypoint: plugin: \"nav2_waypoint_follower::WaitAtWaypoint\" enabled: True waypoint_pause_duration: 200 "},"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/入门/003-使用FishBot进行自主导航.html":{"url":"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/入门/003-使用FishBot进行自主导航.html","title":"使用FishBot进行自主导航","keywords":"","body":"datetime:2023/10/12 11:03 author:nzb 该项目来源于大佬的动手学ROS2 3.使用FishBot进行自主导航 经过前面三节的铺垫，我们只需要再编写一个launch文件启动nav2就可以让fishbot自己动起来了。 1.编写launch文件 我们将地图、配置文件传递给nav2为我们提供好的launch文件中即可。 再一个launch文件中包裹另一个功能包中的luanch文件采用的是IncludeLaunchDescription和PythonLaunchDescriptionSource import os from ament_index_python.packages import get_package_share_directory from launch import LaunchDescription from launch.actions import IncludeLaunchDescription from launch.launch_description_sources import PythonLaunchDescriptionSource from launch.substitutions import LaunchConfiguration from launch_ros.actions import Node def generate_launch_description(): # =============================1.定位到包的地址============================================================= fishbot_navigation2_dir = get_package_share_directory('fishbot_navigation2') nav2_bringup_dir = get_package_share_directory('nav2_bringup') # =============================2.声明参数，获取配置文件路径=================================================== # use_sim_time 这里要设置成true,因为gazebo是仿真环境，其时间是通过/clock话题获取，而不是系统时间 use_sim_time = LaunchConfiguration('use_sim_time', default='true') map_yaml_path = LaunchConfiguration('map', default=os.path.join(fishbot_navigation2_dir, 'maps', 'fishbot_map.yaml')) nav2_param_path = LaunchConfiguration('params_file', default=os.path.join(fishbot_navigation2_dir, 'param', 'fishbot_nav2.yaml')) rviz_config_dir = os.path.join(nav2_bringup_dir, 'rviz', 'nav2_default_view.rviz') # =============================3.声明启动launch文件，传入：地图路径、是否使用仿真时间以及nav2参数文件============== nav2_bringup_launch = IncludeLaunchDescription( PythonLaunchDescriptionSource([nav2_bringup_dir, '/launch', '/bringup_launch.py']), launch_arguments={ 'map': map_yaml_path, 'use_sim_time': use_sim_time, 'params_file': nav2_param_path}.items(), ) rviz_node = Node( package='rviz2', executable='rviz2', name='rviz2', arguments=['-d', rviz_config_dir], parameters=[{'use_sim_time': use_sim_time}], output='screen') return LaunchDescription([nav2_bringup_launch, rviz_node]) 2.安装并添加依赖 2.1 修改CMakeLists.txt 添加install指令，将文件拷贝到install目录 cmake_minimum_required(VERSION 3.5) project(fishbot_navigation2) # find dependencies find_package(ament_cmake REQUIRED) install( DIRECTORY launch param maps DESTINATION share/${PROJECT_NAME} ) ament_package() 2.2 添加依赖 主要是添加这行nav2_bringup fishbot_navigation2 0.0.0 TODO: Package description root TODO: License declaration ament_cmake ament_lint_auto ament_lint_common nav2_bringup ament_cmake 3.构建运行 3.1 构建 colcon build --packages-up-to fishbot_navigation2 3.2 运行 3.2.1 运行仿真 source install/setup.bash ros2 launch fishbot_description gazebo.launch.py 3.2.2 运行Nav2 source install/setup.bash ros2 launch fishbot_navigation2 navigation2.launch.py 4.初始化位置 启动后正常你应该在RVIZ2和终端看到一个错误，这是因为没有给定初始化位置（告诉机器人它在地图的大概位置）导致的。 [planner_server-5] [INFO] [1652973621.731976741] [global_costmap.global_costmap]: Timed out waiting for transform from base_link to map to become available, tf error: Invalid frame ID \"map\" passed to canTransform argument target_frame - frame does not exist [rviz2-10] [INFO] [1652973621.760971376] [rviz2]: Message Filter dropping message: frame 'odom' at time 0.000 for reason 'Unknown' [rviz2-10] [INFO] [1652973621.856298950] [rviz2]: Message Filter dropping message: frame 'laser_link' at time 4392.881 for reason 'Unknown' [rviz2-10] [INFO] [1652973621.951345246] [rviz2]: Message Filter dropping message: frame 'laser_link' at time 4392.981 for reason 'Unknown' [rviz2-10] [INFO] [1652973621.951468235] [rviz2]: Message Filter dropping message: frame 'odom' at time 0.000 for reason 'Unknown' [rviz2-10] [INFO] [1652973622.047860791] [rviz2]: Message Filter dropping message: frame 'laser_link' at time 4393.081 for reason 'Unknown' 通过RVIZ2的工具栏上的 2D Pose Estimate 可以给迷茫的fishbot指明“机生方向”。 点击 2D Pose Estimate ，进行姿态初始化（选中机器人在Gazebo位置差不多的点，左键点击不要松开，移动鼠标给定方向），初始化完后，左边的Global Status 就正常了。 5.单点导航 点击RVIZ2工具栏上的 就可以给fishbot安排一个目标点了，点击按钮，到地图上任意一点击鼠标左键，注意不要松开，移动鼠标给定一个方向。 6.多点（路点）导航 观察左下角，有一个Nav2的Rviz2小插件，可以进行启动停止和导航模式的切换，点击 切换到路点模式。 接着你可以使用工具栏的 按钮，给FishBot指定多个要移动的点，接着点击左下角的启动，就可以看到FishBot依次到达这些目标点。 7.查看机器人当前在地图中的位置 在机器人导航过程中我们如何实时查看机器人在地图中的位置呢？我们可以通过tf进行查看。 打开终端，输入指令： ros2 run tf2_ros tf2_echo map base_link 接着就可以看到下面的信息，旋转和变换位姿数据了 [INFO] [1653215686.225862749] [tf2_echo]: Waiting for transform map -> base_link: Invalid frame ID \"map\" passed to canTransform argument target_frame - frame does not exist At time 4873.528000000 - Translation: [-0.009, -0.016, 0.076] - Rotation: in Quaternion [0.000, -0.000, -0.000, 1.000] At time 4874.514000000 - Translation: [-0.009, -0.016, 0.076] - Rotation: in Quaternion [0.000, -0.000, -0.000, 1.000] 8.总结 本节我们终于将FishBot的自主导航给跑了起来，不过我们都是通过RVIZ2的工具给机器人指定的目标点，除了工具栏的工具，我们还可以使用代码的方式发送目标点给FishBot，下一节就会带你一起学习Nav2的API（应用程序接口）。 课后作业： 使用rqt_tf_tree观察tf树的结构 阅读下Nav2中文网配置指南章节内容（顺便挑几个代校准的段落进行校准） "},"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/入门/004-使用Nav2导航API进行导航.html":{"url":"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/入门/004-使用Nav2导航API进行导航.html","title":"使用Nav2导航API进行导航","keywords":"","body":"datetime:2023/10/12 11:03 author:nzb 该项目来源于大佬的动手学ROS2 TODO 4.使用Nav2导航API进行导航 Nav2的API其实是Nav2提供的一个Python库，通过该库你可以事先调用你的机器人进行简单的控制（比如导航到点）。 很遗憾的是，该功能包官方并没有发布foxy版本的，再下一个galactic版本才开始正式发布。 从2022年5月23号开始，教程将开始向humble版本迁移，该部分内容将在humble版本发布。 1.导入nav2_simple_commander from nav2_simple_commander.robot_navigator import BasicNavigator import rclpy from copy import deepcopy 初始化BasicNavigator rclpy.init() nav = BasicNavigator() navigator.waitUntilNav2Active() 2.初始化位置 # ======================初始化位置，代替rviz2的2D Pose Estimate=============================== initial_pose = PoseStamped() initial_pose.header.frame_id = 'map' initial_pose.header.stamp = navigator.get_clock().now().to_msg() initial_pose.pose.position.x = 0.0 initial_pose.pose.position.y = 0.0 initial_pose.pose.orientation.w = 1.0 navigator.setInitialPose(initial_pose) 3.导航到点 #========================导航到目标点1=========================================== goal_pose1 = deepcopy(initial_pose) goal_pose1.pose.position.x = 1.5 nav.goToPose(goal_pose1) while not nav.isNavComplete(): feedback = nav.getFeedback() #检查是否超时，超时则停止导航到点 if feedback.navigation_duration > 600: nav.cancelNav() #================================导航到目标点2================================== goal_pose2 = deepcopy(initial_pose) goal_pose2.pose.position.x = -1.5 nav.goToPose(goal_pose2) while not nav.isNavComplete(): feedback = nav.getFeedback() #检查是否超时，超时则停止导航到点 if feedback.navigation_duration > 600: nav.cancelNav() #===============================查看返回结果===================================== result = nav.getResult() if result == NavigationResult.SUCCEEDED: print('Goal succeeded!') elif result == NavigationResult.CANCELED: print('Goal was canceled!') elif result == NavigationResult.FAILED: print('Goal failed!') 4.总结 上面是对nav2_simple_commander的简单介绍，介于本教程目前主要维护foxy版本问题，暂时该部分无法使用，不过你可以使用galactic版本进行实践。 "},"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/进阶/001-使用EKF融合里程计和IMU.html":{"url":"ROS2/Nav2导航篇/第11章-Nav2导航仿真实战/进阶/001-使用EKF融合里程计和IMU.html","title":"使用EKF融合里程计和IMU","keywords":"","body":"datetime:2023/10/12 11:03 author:nzb 该项目来源于大佬的动手学ROS2 "},"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/基础/001-嵌入式开发介绍与环境搭建.html":{"url":"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/基础/001-嵌入式开发介绍与环境搭建.html","title":"嵌入式开发介绍与环境搭建","keywords":"","body":"datetime:2023/10/16 11:03 author:nzb 该项目来源于大佬的动手学ROS2 1.什么是单片机MCU 一、什么是MCU？和CPU什么区别？ 你知道我们电脑用的处理器叫做CPU（Central Processing Unit 中央处理器），那你知道现在的智能家电里的处理器是什么吗？比如可以连WIFI和蓝牙的空调，比如在寒冷的冬天里常用的小米电暖器是什么处理器吗？ 答案就是微型控制单元-MCU（Micro Control Unit），我们常说单片微型计算机，简称就是单片机，上面两张图就是两种不同类型的单片机。 如果你有组装过电脑，你应该知道，电脑想要运行起来除了CPU还要内存条、硬盘等设备才能正常运行，而单片机则将CPU、内存、蓝牙等外设集成到了一起，这一点也是CPU和MCU之间的主要区别。 二、单片机为什么有那么多种类？ 在上面的单片机介绍中，放了两种单片机图片，事实上单片机的种类是非常之多的，用在洗衣机上的单片机、用在3D打印机的单片机和用在电暖气上的单片机都是不同的类型，那为什么有那么多分类呢？ 答案是不同单片机具有不同的配置，比如不同的主频，慢的有几兆赫兹，快的有几百兆赫兹，不同的外设，比如有的支持USB、有的支持WIFI、有的支持蓝牙、还有的甚至多加了个处理器（比如卖的MicroROS学习板主控就是双核的）。 2.微处理器开发平台 上一节我们对单片机硬件进行了简单介绍，但单片机运行不仅仅需要硬件，类似于电脑需要配套的操作系统一样，单片机还需要与之配套的软件，本节我们学习下常见的开发平台。 我们的MicroROS板采用的单片机是ESP32芯片，该芯片支持蓝牙和WIFI并且是双核的国产芯片，用途很广，所以就介绍下该芯片的常用的几个开发平台。 一、官方平台-ESPIDF(ESP IoT Development FrameWork) 官网地址：https://www.espressif.com/zh-hans/products/sdks/esp-idf 所谓官方平台就是单片机的厂商，针对单片机提供的开发框架，该框架为我们提供了一个C/C++ SDK，我们通过include相应的头文件就可以实现对硬件的控制。 下面这一段是官方介绍 ESP-IDF 是乐鑫官方的物联网开发框架，适用于 ESP32、ESP32-S、ESP32-C 和 ESP32-H 系列 SoC。它基于 C/C++ 语言提供了一个自给自足的 SDK，方便用户在这些平台上开发通用应用程序。ESP-IDF 目前已服务支持数以亿计的物联网设备，并已开发构建了多种物联网产品，例如照明、消费电子大小家电、支付终端、工控等各类物联网设备。 ESP-IDF的核心其实是基于开源的FreeRTOS优化而来的，而FreeRTOS是一个迷你（几k大小）的实时操作系统内核，所以别看它小，照样跑了个操作系统。 展示一段ESP_IDF版本的HelloWorld，感受一下 /* * SPDX-FileCopyrightText: 2010-2022 Espressif Systems (Shanghai) CO LTD * * SPDX-License-Identifier: CC0-1.0 */ #include #include #include \"sdkconfig.h\" #include \"freertos/FreeRTOS.h\" #include \"freertos/task.h\" void app_main(void) { printf(\"Hello world!\\n\"); vTaskDelay(1000 / portTICK_PERIOD_MS); fflush(stdout); esp_restart(); } 二、Arduino平台 官网地址：https://www.arduino.cc/en/about Arduino是一款便捷灵活、方便上手的开源电子原型平台，本次MicroROS学习就是基于该平台进行开发。 展示一段Arduino版本的HelloWorld代码，感受一下 #include void setup() { // put your setup code here, to run once: Serial.begin(9600); Serial.println(\"Hello World!\"); } void loop() { // put your main code here, to run repeatedly: } 三、MicroPython平台 官网地址：https://micropython.org/ 大家都知道，人生苦短，我用Python，针对单片机平台，有没有可能使用Python开发呢？——MicroPython来了。 MicroPython是 Python 3 语言的精简实现 ，包括Python标准库的一小部分，经过优化可在微控制器和受限环境中运行。 同样的我们的MicroROS板同时也是支持使用MicroPython进行开发，只需要刷入相应的固件即可。 展示一段MicroPython的HelloWorld代码，感受下它的简单 print('Hello, World!') 四、对比与总结 上面介绍了三种常见的平台，做个表格对比下三种平台的优缺点。 平台名称 优点 缺点 ESP_IDF 官方出品、测试完成度高、安全稳定、有官方支持、适合产品化、支持microROS 三方教程少、工程复杂、新手不友好 Arduino 社区庞大，教程丰富、新手友好，简单易用、支持microROS 封装较多 MicroPython Python语言、简单易用 解释执行，效率低下，封装较多，不支持microROS 看完上面的对比，对于新手来说选择Ardunio平台容易入门且教程丰富，并且ESP32单片机是官方出品了Arduino支持（开源地址：https://github.com/espressif/arduino-esp32）。 了解完单片机开发平台，下一节我们正式搭建开发环境，然后开始编写我们的第一个HelloWorld工程！ 3.搭建PlateFormIO开发环境 我们开始介绍并搭建PlatformIO（以下简称PIO）的开发环境。因为网络原因，PIO搭建起来是一个挺困难的事情，但是在一键安装里添加了一键安装PIO，为你解决这一难题。 开始之前，想和你约定好本次学习之旅的开发环境和平台，这里采用的开发环境信息如下： 系统版本：Ubuntu 22.04（虚拟机实体机都可） ROS版本：ROS2-Humble 开发板：MicroROS学习板V1.0.0 一、PIO介绍 官网地址：https://platformio.org/ PIO是一个面向嵌入式开发的专业协作平台，它提供了一个适配VsCode的插件，它具有一个用户友好且可扩展的集成开发环境，具有一组专业开发工具，提供现代而强大的功能，以加快并简化嵌入式产品的创建和交付。 二、安装PIO PIO的开发我们采用VsCode，所以在这之前你需要安装VsCode，VsCode安装可以使用一键安装，快速且稳定。 2.1 安装VsCode 运行一键安装指令，之后选择7即可 wget http://fishros.com/install -O fishros && . fishros 安装完成VsCode后，推荐你继续使用一键安装来安装PIO。 2.2 安装PIO（可跳过） 注意这一步仅适用Ubuntu22.04系统，非该系统请直接跳过 继续使用一键安装，选项12 wget http://fishros.com/install -O fishros && . fishros 2.3 安装VsCode插件 打开VsCode，我们还需安装一个PlatformIO插件就能正常Work了。 任意终端输入code，或者在菜单中找到vscode都可以打开vscode，接着在扩展中搜索PlatformIO，选择后点击安装即可。 安装完成后在侧方栏应该可以看到一个蚂蚁头的图标，这个就是PIO，点击图标，点击上访的Open就可以打开PIO HOME。 三、新建工程测试 接着我们就可以利用PIO建立第一个Arduino工程进行测试，首先点击New Project。 四步新建工程 输入工程名 example01_helloworld 选择开发板，这里选择Adafruit ESP32 Feather 选择开发框架，这里我们用Arduino，PIO还支持IDF（IoT Development FrameWork） 开发位置可以选择默认的位置，也可以自定义位置 最后点击Finish即可，这样我们就得到了一个支持ESP32的Arduino工程。 4.PIO工程结构&构建方式 上一节我们搭建好了PIO的开发环境，并新建了第一个工程。本节我们详细了解下该工程，了解我们需要在哪里写代码，在哪里改配置。 一、工程目录概述 首先展开工程，可以看到工程一共有8个部分如上图所示。 PIO配置文件 VsCode配置文件 头文件放置目录 库文件放置目录 代码资源放置目录，主函数就在这里 测试文件放置目录 git忽略文件 platformio配置文件 二、在哪里写代码？ 打开src/main.cpp就是我们工程的程序入口文件，打开该文件，已经默认给我们生成了9行代码，后续的主要开发就在这里进行。 #include void setup() { // put your setup code here, to run once: } void loop() { // put your main code here, to run repeatedly: } 三、工程配置文件-platformio.ini 打开工程主目录下的platformio.ini文件，预生成的配置文件如下 ; PlatformIO Project Configuration File ; ; Build options: build flags, source filter ; Upload options: custom upload port, speed and extra flags ; Library options: dependencies, extra library storages ; Advanced options: extra scripting ; ; Please visit documentation for the other options and examples ; https://docs.platformio.org/page/projectconf.html [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino 这里用到的主要配置有四个 [env:featheresp32]编译环境 platform = espressif32，单片机平台 board = featheresp32，开发板 framework = arduino，开发框架-arduino 后续还有很多关于工程的配置都放在这里，同时我们可以添加一条配置board_build.f_cpu = 240000000L，将单片机的主频提高到240MHZ的主频。 [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino board_build.f_cpu = 240000000L 四、编译工程 在VsCode中编译PIO，编译工程和将编译结果下载到开发板上都非常的方便。 编译工程可以手动点击左下角的对号进行，其他操作也可以通过按钮进行。 点击编译按钮，看到如下界面则代表编译成功 其中打印信息有很多有用的提示，比如工程占用的RAM和Flash大小（可以理解为系统程序大小） RAM: [ ] 4.9% (used 16144 bytes from 327680 bytes) Flash: [== ] 16.2% (used 212961 bytes from 1310720 bytes) 编译完成工程，在.pio/build/featheresp32目录下可以看到firmware.bin，这个就是我们工程编译之后生成的二进制文件，将该文件下载到开发板上就可以运行了。 五、PIO快捷键 这里再介绍几个PIO的快捷键，在接下来的学习中你肯定能用到 快捷键 内容 Ctrl+Alt+B 编译工程 Ctrl+Alt+U 将程序上传烧录到开发板 Ctrl+Alt+S 打开串口Monitor "},"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/基础/002-第一个HelloWord工程-串口通信-接收实验.html":{"url":"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/基础/002-第一个HelloWord工程-串口通信-接收实验.html","title":"HelloWord-串口通信-接收实验","keywords":"","body":"datetime:2023/10/17 11:03 author:nzb 该项目来源于大佬的动手学ROS2 5.第一个HelloWord工程 这一节我们正式编写代码，输出HelloWorld到电脑上。在正是开始编写代码前，我们先了解下开发流程。 一、Arduino开发流程 Arduino和其他单片机开发，一共分为四步。 编写代码，根据相关的API和SDK进行代码的编写。 编译工程，将工程的代码文件编译成二进制文件。 烧录二进制文件，将上一步生成的二进制文件通过工具烧录到开发板中。 运行测试，重启开发板，观察硬件执行情况（数据打印一般通过串口查看） 接下来就按照上面总结的几个步骤来尝试编写HelloWorld! 二、编写代码 2.1 Arduino函数介绍 前面有介绍，Ardunio平台的一大特点就是简单易用，而Ardunio使用的开发语言是C/C++，从工程生成的默认代码就可以看出来。 #include void setup() { // put your setup code here, to run once: } void loop() { // put your main code here, to run repeatedly: } 整个代码可以分为三个部分 头文件#include setup()函数，该函数只会在启动时被系统调用一次 loop()函数，该函数会被系统循环调用，直到重启或者断电 2.2 为什么没有入口函数main函数？ 在学习C语言和C++时你应该学过，程序的入口文件是main函数，但在这个Arduino中却没有main函数的存在，这是为什么？ Arduino其实是有main函数的，Arduino的main函数长这样ESP32-Arduino库有所不同，但原理一样： #include // Declared weak in Arduino.h to allow user redefinitions. int atexit(void (* /*func*/ )()) { return 0; } // Weak empty variant initialization function. // May be redefined by variant files. void initVariant() __attribute__((weak)); void initVariant() { } void setupUSB() __attribute__((weak)); void setupUSB() { } int main(void) { init(); initVariant(); #if defined(USBCON) USBDevice.attach(); #endif setup(); for (;;) { loop(); if (serialEventRun) serialEventRun(); } return 0; } 核心的代码就这一段 setup(); for (;;) { loop(); if (serialEventRun) serialEventRun(); } 从这里就可以看出来，setup和loop函数之间的关系，在main函数中先调用一次setup函数，再使用for死循环调用loop函数。 2.3 串口输出HelloWorld 要实现将HelloWorld!从开发板输出到电脑上，我们需要了解一个常用的通信协议Serial，常称串口通信。 关于串口通信的原理可以到B站搜索相关视频，但在这里使用时你只需要了解如何使用即可。 这里我们了解三个函数，串口初始化、串口打印、串口读取。 函数原型 参数 返回值 描述 void begin(unsigned long baud) baud：串口波特率 void 该函数用于初始化串口，主要配置串口波特率，波特率类似于频道号，串口收发双方保持相同的波特率才能进行正常通信。常见的波特率有9600，115200等，波特率其实代表每秒数据收发的频率，波特率越高，速度越快。 size_t printf(const char *format, ...) format：格式化字符串 size_t 打印的字符数量 该函数和我们常见的printf函数一致，eg：Serial.printf(\"Hello World!\"); int read(void) void int 读取的字符值，ASSIC表示 该函数用于读取一个字节的数据，返回值就是这个字节的值，如果没有数据则返回-1 基于上面的函数，我们可以这样输出HelloWorld! #include void setup() { Serial.begin(115200); } void loop() { Serial.printf(\"Hello World!\\n\"); } 在setup()函数里进行串口的初始化，波特率设置成了115200，在loop函数中不断的输出Hello World!。 三、编译代码 点击对号，或者使用快捷键Ctrl+Alt+B，即可编译。 看到Building .pio/build/featheresp32/firmware.bin和Successfully created esp32 image.就代表已经成功生成了二进制文件，下一步我们就开始烧录二进制文件。 四、烧录二进制文件 4.1 连接开发板到电脑 MicroROS学习板采用TypeC接口，你需要一个USB数据线将开发板连接到你的电脑。连接电脑后，Linux系统驱动会被自动搜索和加载，查看是否有正确驱动，可以使用lsusb进行测试。 lsusb 输入后，如果可以看到CP210x这个设备，就代表驱动加载成功了 驱动加载成功后在/dev目录下会多出一个ttyUSBx的设备，比如这里就是/dev/ttyUSB0 使用ls /dev/ttyUSB*指令可以将其列出 4.2 设置设备权限 我们想让开发板和电脑通过串口进行通信，电脑端只需对这个串口进行读写就行了。因为设备默认的生成目录是在/dev目录下，普通用户是没有读写权限的，所以在使用之前我们可以修改下该设备的权限。 临时修改 sudo chmod 666 /dev/ttyUSBx 也可以永久修改，将用户添加到dialout和plugdev组（重启后方生效） sudo usermod -a -G dialout $USER sudo usermod -a -G plugdev $USER 4.3 烧录二进制文件 点击左下角的上传烧录按钮，或者使用快捷键Ctrl+Alt+U进行烧录。 看到上面四部分打印代表烧录成功，可以看到PIO可以自动检测串口并进行连接，接着上传文件到开发板，最后自动重启。 五、运行测试 因为在下载完成后，下载程序帮我们自动重启了，所以这里我们不需要进行重启。接着我们使用串口Monitor打开串口看看有没有数据。 点击Serial Monitor按钮，或者使用快捷键Ctrl+Alt+S，如果没有出错，你将看到下面的乱码。 原因是终端的波特率不对，开发板发送给电脑数据的波特率是115200，而电脑接手的波特率是9600，不匹配就会造成乱码。 通过修改配置文件，可以修改Serial Monitor的默认波特率。 在platformio.ini中添加一行代码 monitor_speed = 115200 接着关闭刚刚的终端，再重新打开，接着我们就可以看到嗖嗖嗖的Hello World! 六、总结 本节我们成功将自己的代码上传到开发板上了，然后通过串口成功的和单片机建立了单向连接（开发板向电脑发送数据），下一节我们学习下电脑向单片机发送消息。 最后还有一个几个小作业 1.上面我们输出Hello World!在不断的输出，如果想要改成只输出一次，代码该怎么写？ 答案： #include void setup() { Serial.begin(115200); Serial.printf(\"Hello World!\\n\"); } void loop() { } 2.上面我们输出Hello World!在快速的输出，如果想要改成每秒输出一次，代码该怎么写？ 提示函数：void delay(uint32_t ms)延时指定ms。 答案： #include void setup() { Serial.begin(115200); } void loop() { delay(1000); Serial.printf(\"Hello World!\\n\"); } 6.串口通信-接收实验 上一节我们完成了第一个Hello World工程，学习使用了串口模块的初始化和发送，本节我们再来一个串口接收小实验，把串口收发数据补齐。 一、检测并接收单个字符 1.1 代码编写 /** * @file demo01_read_byte.cpp * @author fishros@foxmail.com * @brief 初始化串口，当有数据过来的时候读取并将数据打印出来 * @version 0.1 * @date 2022-12-18 * * @copyright Copyright (c) 2022 * */ #include void setup() { // 初始化串口 Serial.begin(115200); } void loop() { // 判断是否有有效数据，返回值是有效数据的长度 if (Serial.available()) { // 读取一个数据 int c = Serial.read(); // -1 代表接收失败 if (c != -1) { // 以%c字符的格式输出接收的数据 Serial.printf(\"I receve %c\\n\", c); } } } 这里多用了一个函数Serial.available()，该函数代表当前串口中缓存有效数据的长度。 1.2 使用串口监视器发送消息 使用快捷键，编译 Ctrl+Alt+B、上传 Ctrl+Alt+U，接着准备发送数据 因为要发送消息，这里我们换一个收发分离的串口监视器来进行数据发送,在VSCODE的侧边栏中，点击“Extensions”图标，然后在搜索框中搜索“SerialMonitor”，找到并安装SerialMonitor插件。 使用Ctrl+Alt+~打开终端，接着在终端中你可以看到串口监视器一栏 接着打开我们板子对应的串口设备 选择串口编号 设置波特率 点击开始监视 发送测试 输入数据 点击发送 查看返回 尝试发送12 可以看到受到了两条返回，这是因为我们每次只接收一个数据，所以即使发送12，接收数据也是一个一个接收和打印的。 那有没有办法一次性接收多个数据呢？我们换个函数即可。 二、一次性接收一串数据 2.1 代码编写 /** * @file demo01_read_byte.cpp * @author fishros@foxmail.com * @brief 初始化串口，当有数据过来的时候读取并将数据打印出来 * @version 0.1 * @date 2022-12-18 * * @copyright Copyright (c) 2022 * */ #include void setup() { // 初始化串口 Serial.begin(115200); } void loop() { // 判断是否有有效数据 if (Serial.available()) { // 读取一个String字符串数据 String str = Serial.readString(); // 以%s的格式输出接收的数据 Serial.printf(\"I receve %s\\n\", str.c_str()); } } 2.2 编译下载 点击按钮或者使用快捷键编译下载代码。 如果你在下载代码时遇到下面的错误，是因为刚刚的串口监视器没有关闭， Auto-detected: /dev/ttyUSB0 Uploading .pio/build/featheresp32/firmware.bin esptool.py v4.2.1 Serial port /dev/ttyUSB0 Connecting........... serial.serialutil.SerialException: device reports readiness to read but returned no data (device disconnected or multiple access on port?) *** [upload] Error 1 点击停止监视后，继续下载即可 2.3 测试 下载完成后，重新打开串口，接着发送一串消息 三、总结 本节我们通过两个串口接收数据小实验，学习了串口数据的接收和发送。 "},"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/入门/001-看懂LED驱动电路-GPIO控制-学会使用ADC.html":{"url":"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/入门/001-看懂LED驱动电路-GPIO控制-学会使用ADC.html","title":"看懂LED驱动电路-GPIO-ADC","keywords":"","body":"datetime:2023/10/18 09:55 author:nzb 该项目来源于大佬的动手学ROS2 1.点灯基础-看懂LED驱动电路 上一节我们学习了单片机的开发流程，接下来我们就尝试通过代码来控制LED灯的开关，但是在正式写代码前，你需要先学会如何看电路图。 提示： 在学习下面的内容前，需要你了解基础的电路基础知识（电流、电压和电阻，比如串联分压，并联分流），简单复习下初中物理知识即可。 一、LED介绍 LED（Light Emitting Diode），发光二极管，是一种能够将电能转化为可见光的固态的半导体器件，它可以直接把电转化为光。LED的心脏是一个半导体的晶片，晶片的一端附在一个支架上，一端是负极，另一端连接电源的正极，使整个晶片被环氧树脂封装起来。 既然是二极管，就一个非常重要的特性，就是单向导电性。所以它的一端要接正极，一端是负极。并且不能反接。 二、点灯电路原理 上面这张图是MicroROS学习板的蓝色LED电路图和实际电路，R2是一个1K欧姆的电阻，LED1是一个蓝色的LED灯，右侧是3.3V的电压源，左侧ESP_IO2是单片机的引脚。 电流是从电压高的地方流向电压低的地方，如果我们将ESP_IO2的电压设成3.3V时，此时电路两端电压相同，没有电流经过，此时LED1不工作。 如果我们将ESP_IO2设置成0V时，此时右侧电压高，左侧电压低，电流从右侧流过LED1到ESP_IO2，此时LED1开始工作。 所以我们可以通过ESP_IO2的电压高低来控制LED1灯的亮灭，这个就是点灯电路的原理。 2.完成点灯-GPIO控制 上一节了解了MicroROS学习板的LED电路原理，最后得到结论是通过控制ESP_IO2的电平就可以控制电压，接下来我们就尝试利用Arduino的ESP_IO2对IO进行控制。 一、GPIO控制介绍 1.1 什么是GPIO 首先我们了解下GPIO（General-purpose input/output），中文名通用型之输入输出的简称。 输出模式，指GPIO是可以通过程序控制其电压高低，普通的GPIO只能输出低电平（0V）和高电平（3.3V，有的单片机是5V）。 输入模式，指GPIO可以读取其上的电压，普通的GPIO只能读取低电平和高电平两种。比如当我们想测试一个按键是否被按下，就可以GPIO的输入功能。 1.2 GPIO控制API Arduino提供了简单易用的API来控制IO的输入和输出。 1.2.1 引脚模式设置-pinMode 该函数用于定义特定引脚的 GPIO 操作模式。 void pinMode(uint8_t pin, uint8_t mode); pin定义 GPIO 引脚编号。 mode设置操作模式。 基本输入和输出支持以下模式： INPUT将 GPIO 设置为不带上拉或下拉（高阻抗）的输入。 OUTPUT将 GPIO 设置为输出/读取模式。 INPUT_PULLDOWN 将 GPIO 设置为具有内部下拉列表的输入。 INPUT_PULLUP 将 GPIO 设置为带有内部上拉的输入。 1.2.2 数字输出-digitalWrite digitalWrite用于设置被配置为OUTPUT模式的引脚电平为HIGH 或 LOW。 void digitalWrite(uint8_t pin, uint8_t val); pin所设置的GPIO编号。 val将输出数字状态设置为HIGH 或LOW 。 1.2.3 数字输入-digitalRead digitalRead用于读取配置为INPUT模式的给定引脚的状态。 int digitalRead(uint8_t pin); pin 所设置的GPIO编号。 此函数将返回所选引脚的逻辑状态为 HIGH或LOW。 有了上面三个函数，我们就可以编写代码了。 二、编写LED闪烁代码 新建example02_led工程，接着输入下面的代码。 /** * @file main.cpp * @author fishros@foxmail.com * @brief 使LED灯亮1s关闭1s,持续闪烁 * @version 0.1 * @date 2022-12-19 * * @copyright Copyright (c) 2022 * */ #include void setup() { // put your setup code here, to run once: pinMode(2, OUTPUT); // 设置2号引脚模式为OUTPUT模式 } void loop() { // put your main code here, to run repeatedly: digitalWrite(2, LOW); // 低电平，打开LED灯 delay(1000); // 休眠1000ms digitalWrite(2, HIGH); // 高电平，关闭LED灯 delay(1000); // 休眠1000ms } 这里我们让LED亮1s关闭1s，持续闪烁，代码很简单，不再讲解。 编译下载代码到开发板，接着观察现象，你会发现蓝色LED灯在不断闪烁。 三、通过串口控制LED 我们继续更新下工程代码，实现通过串口指令来控制LED的亮灭。 #include void setup() { Serial.begin(115200); pinMode(2, OUTPUT); // 设置2号引脚模式为OUTPUT模式 } void loop() { // LED串口控制代码 if (Serial.available()) { String command = Serial.readString(); if (command == \"on\") { digitalWrite(2, LOW); // 低电平，打开LED灯 } else if (command == \"off\") { digitalWrite(2, HIGH); // 高电平，关闭LED灯 } } /* // LED闪烁代码 digitalWrite(2, LOW); // 低电平，打开LED灯 delay(1000); // 休眠1000ms digitalWrite(2, HIGH); // 高电平，关闭LED灯 delay(1000); // 休眠1000ms */ } 通过串口读取指令，收到on则打开LED，收到off关闭LED。 将代码下载到开发板，接着打开串口监视器，输入指令进行测试。 3.学会使用按键-GPIO输入 一、 按键检测原理 上面的原理图就是我们MicroROS开发板的BOOT按键的原理图，该按键的位置在板子的左下角。 简单的看下原理图可知 当BOOT按下时，1,2就被联通了，此时ESP_IO2就连接到了GND上，也就是连接到GND，ESP_IO2的电平被拉低了。 当BOOT没有按下时，ESP_IO0通过R10连接到了3.3V，ESP_IO2引脚上的电压就被拉高了。 二、 使用按键控制LED灯（按着开松开关） 新建example03_key工程，在main.cpp输入代码。 /** * @file main.cpp * @author fishros@foxmail.com * @brief 使用按键控制LED灯,按着开，松开关 * @version 0.1 * @date 2022-12-19 * * @copyright Copyright (c) 2022 * */ #include void setup() { Serial.begin(115200); pinMode(0, INPUT); // 设置0号引脚模式为INPUT模式 pinMode(2, OUTPUT); // 设置2号引脚模式为OUTPUT模式 } void loop() { if (digitalRead(0) == LOW) { Serial.println(\"LED ON\"); digitalWrite(2, LOW); // 低电平，打开LED灯 } else { Serial.println(\"LED OFF\"); digitalWrite(2, HIGH); // 高电平，关闭LED灯 } } 接着将代码编译烧录到开发板上，按下按键，查看LED灯。 三、使用按键控制LED（自锁开关） 所谓自锁，就是按下开，再按一下关，看一下代码实现 /** * @file main.cpp * @author fishros@foxmail.com * @brief 使用按键控制LED灯,按着开，松开关，自锁开关 * @version 0.1 * @date 2022-12-19 * * @copyright Copyright (c) 2022 * */ #include bool status = false; void setup() { Serial.begin(115200); pinMode(0, INPUT); // 设置0号引脚模式为INPUT模式 pinMode(2, OUTPUT); // 设置2号引脚模式为OUTPUT模式 } void loop() { // 自锁开关 if (digitalRead(0) == LOW) { delay(50); // 休眠50ms再次判断，防止误触 if (digitalRead(0) == LOW) { status = !status; while (digitalRead(0) == LOW) // 死循环等待放开按键 ; } } if (status == true) { digitalWrite(2, LOW); // 低电平，打开LED灯 } else { digitalWrite(2, HIGH); // 低电平，打开LED灯 } /* // 按着开，松开关 if (digitalRead(0) == LOW) { Serial.println(\"LED ON\"); digitalWrite(2, LOW); // 低电平，打开LED灯 } else { Serial.println(\"LED OFF\"); digitalWrite(2, HIGH); // 高电平，关闭LED灯 } */ } 这里稍微复杂一些，当按键按下时我们需要休眠50ms，防止误触，接着反置状态，等待按键松开。 将代码下载到开发板，按下按键，测试一下。 4.电池电压测量-学会使用ADC 上面两节通过LED和按键学习了GPIO的输出和输入。 但这种输入和输出只有两种状态HIGH或者LOW，我们称这种为数字逻辑，这也是输入输出函数称为数字输入和数字输出的原因。 但是电池的电压是一个在一个范围内不断变化的值，明显无法通过HIGH和LOW来表示，所以本节我们学习使用ADC，将电压值这个模拟信号转换成数字信号。 一、ADC介绍 ADC（analog to digital converter）模数转换器是一种非常常见的外设，用于将电压等模拟信号转换为数字形式，以便微控制器可以读取和处理。 ADC在控制和监控应用中非常有用，因为大多数传感器（例如温度、压力、力）都是输出的模拟电压，所以我们需要掌握ADC。 与ADC相对应的DAC——用于将数字信号转换成模拟信号，比如将一段二进制的音乐文件转换成一段连续的电压信号播放出来就需要DAC。 ADC（模数转换器）： 模拟信号：ADC用于将模拟信号转换为数字信号。模拟信号是连续变化的电压或电流信号，可以来自传感器、电压源、电流源等。 采样：ADC对模拟信号进行采样，即按照一定的时间间隔获取信号的离散样本值。 分辨率：ADC的分辨率指的是它可以将模拟信号分成多少个离散的量化级别。通常以位数表示，例如8位、10位、12位等，分辨率越高，表示精度越高。 采样率：ADC的采样率是指每秒钟进行模拟信号采样的次数，以赫兹（Hz）为单位。采样率越高，可以更准确地还原原始模拟信号。 参考电压：ADC需要一个参考电压作为基准来将模拟信号转换为数字值。参考电压通常由外部提供，可以根据应用的需求选择适当的参考电压值。 DAC（数模转换器）： 数字信号：DAC用于将数字信号转换为模拟信号。数字信号是离散的、以数字形式表示的信号，可以来自于计算机、微控制器等。 数字量化：DAC对数字信号进行量化，将离散的数字值转换为连续的模拟信号。量化过程中使用的分辨率决定了模拟输出的精度。 输出范围：DAC的输出范围指的是它可以生成的模拟输出信号的电压或电流范围。输出范围可以根据具体的应用需求进行调整。 更新速率：DAC的更新速率是指它能够按照新的数字输入值更新模拟输出的速率。更新速率越高，可以更快地响应输入信号的变化。 ADC的例子： 温度测量：使用温度传感器（例如热敏电阻或热电偶）将模拟温度信号转换为数字值，以便嵌入式系统可以读取和处理温度数据。 光照检测：使用光敏电阻或光传感器将光照强度转换为数字信号，以便系统可以根据环境的亮度调整相应的控制或显示。 声音录制：使用麦克风将声音信号转换为数字信号，以便进行声音的录制、处理和分析。 电压监测：使用电压传感器将电压信号转换为数字值，以便监测和保护电路中的电压情况。 DAC的例子： 音频输出：将数字音频信号转换为模拟信号，以驱动扬声器或耳机，实现声音的播放和放大。 电机控制：将数字控制信号转换为模拟电压或电流信号，以控制步进电机或直流电机的转速和方向。 波形生成：根据数字信号生成模拟信号，用于生成各种波形（例如正弦波、方波、三角波）以及合成音频信号。 电源输出调节：通过将数字控制信号转换为模拟电压信号，实现对电源输出的调节和稳定，例如用于电源管理和调整。 二、电池电压测量原理 在我们的开发板所使用的ESP32单片机上，自带了ADC模块，我们只需要将需要测量的模拟电压接入相应引脚，接着调用ADC相关API即可读取。 因为ADC原理是采用电压比较方式进行测量，而我们的单片机的供电电压为3.3V，所以测量的电压范围最大不能超过3.3V，但我们采用的电池电压和板子的供电电压分别是12V和5V的。 所以想要使用单片机测量电池电压，那么就要想办法将板子测量的电压按照比例缩小即可，根据初中物理知识，串联分压原理，就设计了这样的电路。 串联分压，左边接电机电压输入引脚，右侧接地，R18是40.2千欧阻值的电阻，R19是10千欧的，假如此时VMOTOR的输入电压为5V，那么ESP_IO34的电压就是 V_{ESPIO34}=V_{VMOTOR}*(10/(40.2+10))=V_{VMOTOR}/5.02 那么如果此时通过ADC测量出 V_{ESPIO34} 上的电压，通过下面的等式就可以算出 V_{VMOTOR} 的电压值。 V_{VMOTOR} =V_{ESPIO34}*5.02 三、Arduino ADC API 了解了原理，我们来看看Arduino为我们提供了哪些API可以直接获取到引脚上的电压。 3.1 设置ADC衰减系数（analogReadResolution） 这个函数用来设置ADC读取时的衰减系数。 输入到引脚的电压在输入到ADC之前可能会衰减。有 4 种可用的衰减选项，衰减越高，可测量的输入电压就越高，为了能够测量到12V以上的电压，我们采用最高的衰减比-ADC_11db。 typedef enum { ADC_0db, ADC_2_5db, ADC_6db, ADC_11db, } adc_attenuation_t; 3.2 读取ADC值（analogRead） 此函数用于获取给定引脚或ADC通道的ADC原始值，默认是12位分辨率，所以这个读出来的值的范围就是0-2^12，也就是最大4096。 uint16_t analogRead(uint8_t pin); pin 要读取ADC值的GPIO 引脚 返回值：ADC原始值 3.3 读取电压值（analogReadMillivolts） 此函数用于获取给定引脚或ADC 通道的 ADC 值（以毫伏为单位）。 uint32_t analogReadMilliVolts(uint8_t pin); pin 要读取ADC值的GPIO 引脚 返回值：此函数将以毫伏为单位返回模拟值。 四、编写程序 利用上面的三个API和计算公式就可以实现电压的测量，新建example04_adc工程，在main.cpp输入代码。 /** * @file main.cpp * @author fishros@foxmail.com * @brief 4.电池电压测量-学会使用ADC * @version 0.1 * @date 2023-01-04 * * @copyright Copyright(c) fishros.com 2023 * */ #include void setup() { Serial.begin(115200); pinMode(34, INPUT); analogSetAttenuation(ADC_11db); } void loop() { int analogValue = analogRead(34); // 读取原始值0-4096 int analogVolts = analogReadMilliVolts(34); // 读取模拟电压，单位毫伏 float realVolts = 5.02 * ((float)analogVolts * 1e-3); // 计算实际电压值 Serial.printf(\"ADC analog value = %d\\n\", analogValue); Serial.printf(\"ADC millivolts value = %d\\n\", analogVolts); Serial.printf(\"realVolts value = %f\\n\", realVolts); delay(100); } 五、测试 根据第三节中的原理图，我们测量的是VMOTOR的电压，VMOTOR是通过一个跳线帽选择连接到5V还是12V上的，详情可以看下面的原理图。 对应板子上的位置 这里我们把跳线帽调整到左侧，让VMOTOR和5V连接，接着打开串口观察测量到的电压值。 可以看到我们成功的测量到了实际的电压值为5.045V，符合正常电压值。 如果你有整台FishBot小车，可以将跳线帽调整到12V的位置，打开电池电源开关，看看是否可以正常测量到12V的电压。 六、总结 本节我们通过电池电压测量的例程，学习了ADC的使用，电池电压测量对我们机器人来说是非常重要的，当电压低的时候可以进行自动返回充电，然后等充电完成后再继续工作。 "},"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/001-学会安装第三方开源库.html":{"url":"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/001-学会安装第三方开源库.html","title":"学会安装第三方开源库","keywords":"","body":"datetime:2023/10/18 17:03 author:nzb 该项目来源于大佬的动手学ROS2 1.学会安装第三方开源库 秉承着拒绝重复造轮子的ROS精神，本节我们学习如何在我们的工程里安装第三方开源库。 在我们的PIO工程中有多种方式可以添加第三方库，常用的有以下三种： 通过PIO搜索安装 通过GIT地址安装 手动下载安装 接下来我们以安装OLED库和IMU的驱动库为例，学习安装第三方库的方法。 开始之前先新建一个工程example05_depends 一、通过PIO搜索安装 我们以安装OLED常用的三方库Adafruit SSD1306安装为例。 点击PIO图标 点击Libraries 输入Adafruit SSD1306 点击下载按钮 5.点击Add to Project 6.选择要添加到的工程 7.点击Add 看到界面表示成功 此时打开platformio.ini你将看到 [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = adafruit/Adafruit SSD1306@^2.5.7 lib_deps = adafruit/Adafruit SSD1306@^2.5.7就是我们安装的库的名字。 既然安装好了那安装的文件位置在哪里呢？打开.pio/libdeps/featheresp32，这里就是我们安装的第三方库的代码位置。 二、通过GIT地址安装 我们的开发板，装载了一块MPU6050模块，通过该模块可以实现对温度、加速度、加速度、重力测量。 这里推荐一个简单易用MPU6050的三方驱动库MPU6050_light: https://github.com/rfetick/MPU6050_light 接着我们来看如何将该库添加到我们的工程中 1.复制仓库地址 2.打开platformio.ini，将地址复制进去即可 [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = adafruit/Adafruit SSD1306@^2.5.7 https://github.com/rfetick/MPU6050_light.git 稍等片刻，等待PIO下载完成，接着打开.pio/libdeps/featheresp32可以看到MPU6050_light库被下载到该目录。 三、手动下载安装 该方式更简单，我们直接将工程克隆到工程的lib目录下即可。 cd lib git clone https://github.com/rfetick/MPU6050_light.git 四、总结 本节我们学习了三种安装三方库的方式，下一节我们开始尝试使用三方库来驱动MPU6050和OLED。 "},"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/002-使用开源库驱动IMU.html":{"url":"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/002-使用开源库驱动IMU.html","title":"使用开源库驱动IMU","keywords":"","body":"datetime:2023/10/18 17:03 author:nzb 该项目来源于大佬的动手学ROS2 2.使用开源库驱动IMU 上一节我们安装好了MPU6050的三方库，这一节我们尝试使用该库将我们板子上的IMU模块驱动起来。 一、MPU6050介绍 首先我们了解下MPU6050模块，从外观看，长这个样子 MPU6050 为全球首例集成六轴传感器的运动处理组件，内置了运动融合引擎，用于手持和桌面的应用程序、游戏控制器、体感遥控以及其他消费电子设备。它内置一个三轴 MEMS 陀螺仪、一个三轴 MEMS 加速度计、一个数字运动处理引擎（DMP）以及用于第三方的数字传感器接口的辅助 I2C 端口（常用于扩展磁力计）。当辅助 I2C 端口连接到一个三轴磁力计，MPU6050 能提供一个完整的九轴融合输出到其主 I2C 端口。 在我们板子上的位置是这里 二、调用开源库驱动 新建工程example06_mpu6050 2.1 添加依赖 修改platformio.ini [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://ghproxy.com/https://github.com/rfetick/MPU6050_light.git 2.2 复制样例程序 该开源库作者提供了开源库的使用方式，将.pio/libdeps/featheresp32/MPU6050_light/examples/GetAllData/GetAllData.ino复制到main.cpp中。 /* Get all possible data from MPU6050 * Accelerometer values are given as multiple of the gravity [1g = 9.81 m/s²] * Gyro values are given in deg/s * Angles are given in degrees * Note that X and Y are tilt angles and not pitch/roll. * * License: MIT */ #include \"Wire.h\" #include MPU6050 mpu(Wire); unsigned long timer = 0; void setup() { Serial.begin(9600); Wire.begin(); byte status = mpu.begin(); Serial.print(F(\"MPU6050 status: \")); Serial.println(status); while(status!=0){ } // stop everything if could not connect to MPU6050 Serial.println(F(\"Calculating offsets, do not move MPU6050\")); delay(1000); mpu.calcOffsets(true,true); // gyro and accelero Serial.println(\"Done!\\n\"); } void loop() { mpu.update(); if(millis() - timer > 1000){ // print data every second Serial.print(F(\"TEMPERATURE: \"));Serial.println(mpu.getTemp()); Serial.print(F(\"ACCELERO X: \"));Serial.print(mpu.getAccX()); Serial.print(\"\\tY: \");Serial.print(mpu.getAccY()); Serial.print(\"\\tZ: \");Serial.println(mpu.getAccZ()); Serial.print(F(\"GYRO X: \"));Serial.print(mpu.getGyroX()); Serial.print(\"\\tY: \");Serial.print(mpu.getGyroY()); Serial.print(\"\\tZ: \");Serial.println(mpu.getGyroZ()); Serial.print(F(\"ACC ANGLE X: \"));Serial.print(mpu.getAccAngleX()); Serial.print(\"\\tY: \");Serial.println(mpu.getAccAngleY()); Serial.print(F(\"ANGLE X: \"));Serial.print(mpu.getAngleX()); Serial.print(\"\\tY: \");Serial.print(mpu.getAngleY()); Serial.print(\"\\tZ: \");Serial.println(mpu.getAngleZ()); Serial.println(F(\"=====================================================\\n\")); timer = millis(); } } 2.3 修改代码 1.修改波特率 9600->115200 2.修改IO地址 Wire.begin();->Wire.begin(18, 19); 修改完后代码，并附上对代码的注释讲解 #include \"Wire.h\" // 导入I2C相关头文件 #include // 导入MPU6050库 MPU6050 mpu(Wire); // 新建MPU6050对象mpu unsigned long timer = 0; void setup() { Serial.begin(115200); Wire.begin(18, 19); // 初始化I2C，设置sda引脚为GPIO18,SCL引脚为GPIO19 byte status = mpu.begin(); // 检测IMU模块状态 Serial.print(F(\"MPU6050 status: \")); Serial.println(status); while (status != 0) { } // stop everything if could not connect to MPU6050 Serial.println(F(\"Calculating offsets, do not move MPU6050\")); delay(1000); mpu.calcOffsets(true, true); // gyro and accelero 校准 Serial.println(\"Done!\\n\"); } void loop() { mpu.update(); if (millis() - timer > 1000) { // print data every second Serial.print(F(\"TEMPERATURE: \")); Serial.println(mpu.getTemp()); // 温度 Serial.print(F(\"ACCELERO X: \")); Serial.print(mpu.getAccX()); // X轴加速度 Serial.print(\"\\tY: \"); Serial.print(mpu.getAccY()); // Y轴加速度 Serial.print(\"\\tZ: \"); Serial.println(mpu.getAccZ()); // Z轴加速度 Serial.print(F(\"GYRO X: \")); Serial.print(mpu.getGyroX()); // X轴 角速度 Serial.print(\"\\tY: \"); Serial.print(mpu.getGyroY()); // Y轴 角速度 Serial.print(\"\\tZ: \"); Serial.println(mpu.getGyroZ()); // Z轴 角速度 Serial.print(F(\"ACC ANGLE X: \")); Serial.print(mpu.getAccAngleX()); // X轴角加速度 Serial.print(\"\\tY: \"); Serial.println(mpu.getAccAngleY()); // Y轴角加速度 Serial.print(F(\"ANGLE X: \")); Serial.print(mpu.getAngleX()); // X角度 Serial.print(\"\\tY: \"); Serial.print(mpu.getAngleY()); // Y角度 Serial.print(\"\\tZ: \"); Serial.println(mpu.getAngleZ()); // Z角度 Serial.println(F(\"=====================================================\\n\")); timer = millis(); } } 三、编译测试 保存代码，编译下载到开发板。打开串口监视器，查看结果。 结果 四、总结 本节我们通过调用开源库实现了对IMU传感器的的调用，如果你对该库感兴趣，可以随时到.pio/libdeps/featheresp32/MPU6050_light/src/MPU6050_light.h查看源码 class MPU6050{ public: // INIT and BASIC FUNCTIONS MPU6050(TwoWire &w); byte begin(int gyro_config_num=1, int acc_config_num=0); ... private: ... }; 可以看到，这里是通过面向对象的方式将MPU6050封装成了一个类，我们使用的时候也是通过实例化后使用的，所以下一节我们将学习如何在我们的工程里使用面向对象的方式进行封装。 "},"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/003-学会面向对象编程-封装IMU驱动.html":{"url":"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/003-学会面向对象编程-封装IMU驱动.html","title":"面向对象封装IMU驱动","keywords":"","body":"datetime:2023/10/20 10:03 author:nzb 该项目来源于大佬的动手学ROS2 3.学会面向对象编程-封装IMU驱动 上一节我们成功读取到了IMU的数据，其中角度用欧拉角的方式表示的，在我们机器人世界里姿态的表示往往使用四元数表示（如果不清楚他们之间的关系可以回看第六章机器人学篇），所以我们需要将欧拉角转换成四元数。除此之外我们还需要将其坐标系矫正到右手坐标系。 所以本节我们将通过面向对象的方式将IMU驱动进行封装，并为其添加坐标系转换以及四元数转换函数。 一、理论介绍 1.1.欧拉角转四元数 欧拉角转四元数的公式我们在第六章入门篇第三节有介绍，这里回顾一下 根据公式我们可以写出代码 typedef struct { float w; float x; float y; float z; } quaternion_t; Euler2Quaternion(float roll, float pitch, float yaw, quaternion_t &q) { double cr = cos(roll * 0.5); double sr = sin(roll * 0.5); double cy = cos(yaw * 0.5); double sy = sin(yaw * 0.5); double cp = cos(pitch * 0.5); double sp = sin(pitch * 0.5); q.w = cy * cp * cr + sy * sp * sr; q.x = cy * cp * sr - sy * sp * cr; q.y = sy * cp * sr + cy * sp * cr; q.z = sy * cp * cr - cy * sp * sr; } 1.2 坐标系校准 我们采用右手坐标系，接着我们依次来校准角度数据的方向。 打开终端，点击RST,查看IMU数据。 首先是X轴，我们让开发板上爱神丘比特的剑头指向自己，然后从右侧往左侧倾斜。 可以看到此时X轴为正值，符合右手坐标系法则。 接着是Y轴，平放，将箭头朝向自己的胸口，接着抬高板子，让箭头指向自己的头部，观察Y轴的变化。 Y轴为负值，不符合右手坐标系法则，所以Y的值应该取一次负，使其为正。 接着是Z轴，平放，将箭头朝向自己的胸口，然后逆时针旋转板子，观察数值变化。 值为正，表示符合右手坐标系法则。 你可能会问怎么确认怎样旋转是正，怎样旋转是负，首先要确认轴向，我们开发板的Z轴朝上，X轴朝前，此时Y轴应该朝左。接着摊开右手手掌，用大拇指朝向轴的方向，比如朝向X轴，然后握起手掌，那么你握的方向就是正方向。 二、开始写代码 新建工程example07_mpu6050_oop 接着为其添加依赖 修改platformio.ini [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://ghproxy.com/https://github.com/rfetick/MPU6050_light.git 接着在lib下新建IMU文件夹，并在文件夹下新建IMU.h和IMU.cpp IMU.h #ifndef __IMU_H__ #define __IMU_H__ #include \"Wire.h\" #include \"MPU6050_light.h\" typedef struct { float w; float x; float y; float z; } quaternion_t; // 四元数结构体 typedef struct { float x; float y; float z; } vector_3d_t; // 通用3D点结构体 typedef struct { quaternion_t orientation; vector_3d_t angle_euler; vector_3d_t angular_velocity; vector_3d_t linear_acceleration; } imu_t; // IMU数据结构体 class IMU { private: MPU6050 *mpu_; // mpu6050指针 public: /** * @brief MPU6050构造一个新的IMU对象 * * @param mpu */ IMU(MPU6050 &mpu); ~IMU() = default; /** * @brief 初始化函数 * * @param sda 引脚编号 * @param scl 引脚编号 * @return true * @return false */ bool begin(int sda, int scl); /** * @brief 欧拉角转四元数 * * @param roll 输入X * @param pitch 输入y * @param yaw 输入Z * @param q 返回的四元数引用 */ static void Euler2Quaternion(float roll, float pitch, float yaw, quaternion_t &q); /** * @brief 获取IMU数据函数 * * @param imu */ void getImuData(imu_t &imu); /** * @brief 更新IMU数据，同上一节中的mou.update * */ void update(); }; #endif // __IMU_H__ IMU.cpp #include \"IMU.h\" IMU::IMU(MPU6050 &mpu) { mpu_ = &mpu; }; bool IMU::begin(int sda, int scl) { Wire.begin(sda, scl); byte status = mpu_->begin(); Serial.print(F(\"MPU6050 status: \")); Serial.println(status); if (status != 0) { return false; } // stop everything if could not connect to MPU6050 Serial.println(F(\"Calculating offsets, do not move MPU6050\")); delay(1000); // mpu.upsideDownMounting = true; // uncomment this line if the MPU6050 is mounted upside-down mpu_->calcOffsets(); // gyro and accelero Serial.println(\"Done!\\n\"); return true; } void IMU::Euler2Quaternion(float roll, float pitch, float yaw, quaternion_t &q) { double cr = cos(roll * 0.5); double sr = sin(roll * 0.5); double cy = cos(yaw * 0.5); double sy = sin(yaw * 0.5); double cp = cos(pitch * 0.5); double sp = sin(pitch * 0.5); q.w = cy * cp * cr + sy * sp * sr; q.x = cy * cp * sr - sy * sp * cr; q.y = sy * cp * sr + cy * sp * cr; q.z = sy * cp * cr - cy * sp * sr; } void IMU::getImuData(imu_t &imu) { imu.angle_euler.x = mpu_->getAngleX(); imu.angle_euler.y = -mpu_->getAngleY(); imu.angle_euler.z = mpu_->getAngleZ(); imu.angular_velocity.x = mpu_->getAccAngleX(); imu.angular_velocity.y = -mpu_->getAccAngleY(); imu.angular_velocity.z = mpu_->getGyroZ(); imu.linear_acceleration.x = mpu_->getAccX(); imu.linear_acceleration.y = mpu_->getAccY(); imu.linear_acceleration.z = mpu_->getAccZ(); IMU::Euler2Quaternion(imu.angle_euler.x, imu.angle_euler.y, imu.angle_euler.z, imu.orientation); } void IMU::update() { mpu_->update(); } main.cpp #include #include \"IMU.h\" MPU6050 mpu(Wire); // 初始化MPU6050对象 IMU imu(mpu); // 初始化IMU对象 imu_t imu_data; unsigned long timer = 0; void setup() { Serial.begin(115200); imu.begin(18, 19); // 初始化IMU,使用18，19引脚 } void loop() { imu.update(); if ((millis() - timer) > 100) { imu.getImuData(imu_data); // 获取IMU数据结构体 Serial.printf(\"imu:\\teuler(%f,%f,%f)\\n\", imu_data.angle_euler.x, imu_data.angle_euler.y, imu_data.angle_euler.z); Serial.printf(\"imu:\\torientation(%f,%f,%f,%f)\\n\", imu_data.orientation.w, imu_data.orientation.x, imu_data.orientation.y, imu_data.orientation.z); timer = millis(); } } 对于代码的解释已经放到了注释之中。 编译下载后，你将看到 三、总结 本节我们通过对MPU6050驱动的封装，学习了如何在嵌入式上使用面向对象编程的方法，下一节我们继续尝试使用开源库来驱动OLED模块，让我们的显示器亮起来。. "},"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/004-使用开源库驱动OLED.html":{"url":"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/004-使用开源库驱动OLED.html","title":"使用开源库驱动OLED","keywords":"","body":"datetime:2023/10/24 10:23 author:nzb 该项目来源于大佬的动手学ROS2 4.使用开源库驱动OLED 本节我们继续尝试使用开源库，驱动OLED模块，最后的效果实现在OLED上显示当前的角度信息。 我们MicroROS开发板上的OLED位置如图所示。 一、OLED模块介绍 我们的OLDE模块样子如上图所示，整个屏幕有128*64个像素点，我们可以实现对每一个像素点的亮灭控制，以此实现对屏幕显示内容的控制。注意我们并不能控制屏幕上像素的颜色，所以我们OLED一般是单色的。 那我们如何控制它的亮灭呢，可以看到在OLED的上方一共有四个引脚，从左到右依次是GND、VCC、SCL、SDA，其中GND、VCC是用于OLED的供电使用，SCL和SDA是I2C通信使用。 听到I2C通信是不是觉得很熟悉，毕竟上一节驱动MPU6050时我们就是使用的I2C协议（Wrie），别着急，我们先用着，下一节我们再详细介绍I2C通信。 二、新建工程并安装依赖 安装依赖，可以直接修改platformio.ini [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://ghproxy.com/https://github.com/rfetick/MPU6050_light.git adafruit/Adafruit SSD1306@^2.5.7 接着打开IMU的源码目录，将.pio/libdeps/featheresp32/MPU6050_light/examples/GetAngle/GetAngle.ino文件内容复制到main.cpp中，接着修改波特率和I2C地址。 #include \"Wire.h\" #include MPU6050 mpu(Wire); unsigned long timer = 0; void setup() { Serial.begin(115200); Wire.begin(18, 19); byte status = mpu.begin(); Serial.print(F(\"MPU6050 status: \")); Serial.println(status); while (status != 0) { } // stop everything if could not connect to MPU6050 Serial.println(F(\"Calculating offsets, do not move MPU6050\")); delay(1000); // mpu.upsideDownMounting = true; // uncomment this line if the MPU6050 is mounted upside-down mpu.calcOffsets(); // gyro and accelero Serial.println(\"Done!\\n\"); } void loop() { mpu.update(); if ((millis() - timer) > 10) { // print data every 10ms Serial.print(\"X : \"); Serial.print(mpu.getAngleX()); Serial.print(\"\\tY : \"); Serial.print(mpu.getAngleY()); Serial.print(\"\\tZ : \"); Serial.println(mpu.getAngleZ()); timer = millis(); } } 三、使用Adafruit库驱动OLED 该库提供的驱动例程较为复杂，这里提供一个简易版本。 #include \"Wire.h\" #include // 加载Adafruit_GFX库 #include // 加载Adafruit_SSD1306库 Adafruit_SSD1306 display; // 声明对象 void setup() { Wire.begin(18, 19); display = Adafruit_SSD1306(128, 64, &Wire); display.begin(SSD1306_SWITCHCAPVCC, 0x3C); // 设置OLED的I2C地址，默认0x3C display.clearDisplay(); // 清空屏幕 display.setTextSize(2); // 设置字体大小，最小为1 display.setCursor(0, 0); // 设置开始显示文字的坐标 display.setTextColor(SSD1306_WHITE); // 设置字体颜色 display.println(\"hello oled!\"); // 输出的字符 } void loop() { } 根据上面的简易版本，修改原有的IMU代码，最后得到如下代码 /* Get tilt angles on X and Y, and rotation angle on Z * Angles are given in degrees * * License: MIT */ #include \"Wire.h\" #include #include // 加载Adafruit_GFX库 #include // 加载Adafruit_SSD1306库 Adafruit_SSD1306 display; MPU6050 mpu(Wire); unsigned long timer = 0; void setup() { Serial.begin(115200); Wire.begin(18, 19); /*========================OLED初始化====================================*/ display = Adafruit_SSD1306(128, 64, &Wire); display.begin(SSD1306_SWITCHCAPVCC, 0x3C); // 设置OLED的I2C地址 display.clearDisplay(); // 清空屏幕 display.setTextSize(2); // 设置字体大小 display.setCursor(0, 0); // 设置开始显示文字的坐标 display.setTextColor(SSD1306_WHITE); // 设置字体颜色 display.println(\"hello oled!\"); // 输出的字符 display.display(); /*========================IMU初始化====================================*/ byte status = mpu.begin(); Serial.print(F(\"MPU6050 status: \")); Serial.println(status); while (status != 0) { } // stop everything if could not connect to MPU6050 Serial.println(F(\"Calculating offsets, do not move MPU6050\")); delay(1000); // mpu.upsideDownMounting = true; // uncomment this line if the MPU6050 is mounted upside-down mpu.calcOffsets(); // gyro and accelero Serial.println(\"Done!\\n\"); } void loop() { mpu.update(); if ((millis() - timer) > 100) { // print data every 100ms Serial.print(\"X : \"); Serial.print(mpu.getAngleX()); Serial.print(\"\\tY : \"); Serial.print(mpu.getAngleY()); Serial.print(\"\\tZ : \"); Serial.println(mpu.getAngleZ()); timer = millis(); /*==========================OLED显示===========================*/ display.clearDisplay(); // 清空屏幕 display.setCursor(0, 0); // 设置开始显示文字的坐标 display.print(\"X=\"); // 输出X display.println(mpu.getAngleX()); display.print(\"Y=\"); // 输出Y display.println(mpu.getAngleY()); display.print(\"Z=\"); // 输出Z display.println(mpu.getAngleZ()); display.display(); } } 四、下载测试 接上OLED，将代码编译下载到开发板上，观察OLED的显示。 五、总结 本节依然是很轻松的完成了OLED驱动，但你应该有个疑问，为什么OLED和MPU6050代码里都有这么一句Wire.begin(18, 19);，为什么都是18和19，不能是其他的数值吗？带着疑惑，下一节带你一起探秘I2C通信以及原理图。 "},"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/005-I2C通信-点亮OLED.html":{"url":"ROS2/ROS2硬件控制篇/第13章-嵌入式开发之从点灯开始/进阶/005-I2C通信-点亮OLED.html","title":"I2C通信-点亮OLED","keywords":"","body":"datetime:2023/10/24 10:23 author:nzb 该项目来源于大佬的动手学ROS2 5.通讯协议小课堂-I2C通信 本节主要介绍I2C协议，并将其主要特点拎出来和大家说说。 网上关于I2C协议介绍的有很多，但大都非常细致，将高低电平数据协议等等都介绍了，但新手学习时不用关注那么多底层的东西，比起了解通信原理，了解它是什么，怎么用对我们更加重要。 一、I2C是一种总线通讯协议 和之前我们介绍的串口通信类似，I2C也是一种通信协议。但它是一种总线通讯协议，也就是说，一个I2C可以连接多个设备，物理连接上像这样。 那它串的设备数量有没有上限呢？有的，上限是127个。 那为什么我们都是用18和19来驱动OLED和MPU6050呢？原因很简单，他们都是连在同一跟线上。 上原理图 像ESP32这种引脚资源匮乏的单片机，引脚的复用就显得很重要了，这里我们就将OLED和MPU6050都接在同一个I2C上，减少引脚占用。 二、I2C是一种两线协议 在上几节我们驱动OLED和IMU的时候，都导入了\"Wire.h\"，这个就是Arudino提供的好的头文件。我们使用的Wire的定义如下 TwoWire Wire = TwoWire(0); TwoWire也就是两线的意思，两线也就是一个是SCL，一个是SDA SCL即时钟线，以一个固定的周期进行电平变换，SDA即数据线，用于数据的传输，这样说有些抽象，用逻辑分析仪截取了一段OLED初始化时的SCl（GPIO18）和SDA（GPIO19）上的电平变化，并分析出其对应的数据。 再放大一些看 可以直观的看到SCL在数据传输开始前一直保持高电平，SDA变成了低电平，这意为着数据传输的开始，也就是那个绿点的地方。 根据I2C协议规定：SCL处于高电平时，SDA由高到低变化，这种信号是起始信号。 继续观察，你会发现，在传输过程中SCL引脚电平在以一个固定的周期来回跳变，从机这边 当检测到SCL电平跳变后就开始读取SDA上的的电平，高记为1,低记为0。 所以你可以看到逻辑分析仪检测到 八个上升箭头，一共传输了八位数据，这八位数据用16进制表示就是0X3C。 0X3C是什么，就是我们OLED的设备地址，所以这段信号的意思就是，我接下来要给0X3C的设备发数据了，请编号为0X3C的设备准备接收。 这个信号会被0X3C的设备接收和处理，而同一总线上ID非0X3C的接收到数据后就会将其扔掉，这就是I2C支持多个设备的核心原因。 在我们的开发板上，OLED的默认地址为：0X3C，IMU的默认地址为：0x68 附件:OLED初始化时I2C引脚数据图 从该表可以看出，数据从905ms开始，到907ms完成了初始化数据的传输，下一节我们将按照这个数据传输内容编写代码，初始化OLED。 三、I2C是一种半双工协议 上面我们仔细分析了I2C协议，SCL用于周期的变换，SDA用于传输数据，所以同一时间，SDA要么用于接收，要么用于发送。所以我们可以得到I2C是一种半双工协议，同一时间只能进行接收或发送。 四、总结 本节带你从I2C协议信号入手，详细介绍了I2C数据的特点，如果你手头也有逻辑分析工具，也可以尝试进行分析，开发板设计的时也非常人性化，你可以这样随手拿几个杜邦线就可以接入进行测量。 6.I2C通信实验-点亮OLED 本节我们就尝试直接使用I2C协议来点亮OLED，因为主要测试I2C协议，所以对于复杂的显示处理部分就掠过了，毕竟有方便的开源库使用，我们也不用那么纠结，如果实在想使用I2C直接驱动OLED，可以去看在雷达驱动板上手撸的代码 。 一、新建工程 还是老样子，不过这次不需要添加任何依赖。 二、I2CAPI介绍 这里我们需要了解几个Wire常用的API。 1.Wire.begin 初始化可以设置引脚，如Wire.begin(18, 19); 2.Wire.beginTransmission，开始传输，传入目标地址，如OLED-0x3C Wire.beginTransmission(0x3c); 3.Wire.write 开始写数据， 直接传如要写的数据即可 4.Wire.endTransmission 结束传输，写入完成后调用 三、编写代码 #include #include \"Wire.h\" uint8_t cmd_ssd1315[] = {0xae, 0x00, 0x10, 0x40, 0x81, 0xcf, 0xa1, 0xc8, 0xa6, 0xa8, 0x3f, 0xd3, 0x00, 0xd5, 0x80, 0xd9, 0xf1, 0xda, 0x12, 0xdb, 0x40, 0x20, 0x00, 0x8d, 0x14, 0xa4, 0xa6, 0xaf}; void setup() { Wire.begin(18, 19); Wire.beginTransmission(0x3c); for (int i = 0; i 这里的代码，我们将cmd_ssd1315中的数据依次通过I2C写入地址为0x3C的设备中，这些数据分别代表这初始化OLED所需要的参数，如亮度、方向等信息，具体请参考SSD1315的手册，或自行百度。 四、测试 将代码下载到开发板，查看OLED,可以看到OLED此时成功亮起，有很多半点，属于正常现象。 五、总结 本节我们主要尝试通过I2C尝试发送一段指令给OLED，并将其成功点亮。至此我们嵌入式开发基础篇的内容就全部完成了，下一章开始我们将正是进入MicroROS的开发中来，到时更有我们熟悉的WIFI、蓝牙等模块的使用。 "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/基础/001-MicroROS介绍与服务安装.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/基础/001-MicroROS介绍与服务安装.html","title":"MicroROS介绍与服务安装","keywords":"","body":"datetime:2023/10/24 10:23 author:nzb 该项目来源于大佬的动手学ROS2 1.Micro-ROS介绍与服务安装 本节我们主要介绍下Micro-ROS几大主要特点。 先上系统框架图，下面再一一介绍。 一、特点1：运行在微控制器上的ROS2 首先从名称看，Micro-ROS，Micro指的就是microcontrollers即微控制器。 核心作用就是上面这句话micro-ROS puts ROS 2 onto microcontrollers。既然是在微控制器上，因硬件资源受限，其功能肯定会有所裁剪，但核心的ROS2通信功能依然保有。 二、特点2：MicroROS支持多种通信协议并依赖Agent 所谓Agen其实就是一个代理，微控制器可以通过串口，蓝牙、以太网、Wifi等多种协议将数据传递给Agent，Agent再将其转换成ROS2的话题等数据，以此完成通信。 三、特点3：通过RCLC-API调用MicroROS 因为MicroROS遵循RCLCAPI，所以和在上位机中使用Python或者C++调用MicroROS有所不同，最终代码风格如下面这段所示 #include #include #include rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; rcl_timer_t timer; void setup() { // Configure serial transport Serial.begin(115200); set_microros_serial_transports(Serial); delay(2000); allocator = rcl_get_default_allocator(); //create init_options RCCHECK(rclc_support_init(&support, 0, NULL, &allocator)); // create node RCCHECK(rclc_node_init_default(&node, \"micro_ros_platformio_node\", \"\", &support)); // create publisher RCCHECK(rclc_publisher_init_default( &publisher, &node, ROSIDL_GET_MSG_TYPE_SUPPORT(std_msgs, msg, Int32), \"micro_ros_platformio_node_publisher\")); // create executor RCCHECK(rclc_executor_init(&executor, &support.context, 1, &allocator)); RCCHECK(rclc_executor_add_timer(&executor, &timer)); msg.data = 0; } 四、在上位机上安装Agent 我们使用Docker来进行Agent的安装。 4.1 安装Docker 打开终端，复制粘贴输入下面代码 wget http://fishros.com/install -O fishros && . fishros 接着输入密码，在下面的界面输入8,一键安装Docker,完成后等待即可。 4.2 运行Agent 安装完成Docker后打开终端，输入下面的指令 sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO serial --dev /dev/ttyUSB0 -v6 稍微等待下载完成，看到如下界面表示成功启动。 上面的指令是使用串口通讯协议运行microros-agent，还可以通过UDP、TCP、CAN等协议运行，具体指令如下 # UDPv4 micro-ROS Agent docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 # Serial micro-ROS Agent docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO serial --dev [YOUR BOARD PORT] -v6 # TCPv4 micro-ROS Agent docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO tcp4 --port 8888 -v6 # CAN-FD micro-ROS Agent docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO canfd --dev [YOUR CAN INTERFACE] -v6 五、总结 本节我们主要介绍了MicroROS的主要特点，接着介绍使用Docker下载和运行Agent，既然搞定了上位机，下一节我们正是开始在开发板上编写MicroROS节点，然后测试与上位机的连接是否正常。 "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/基础/002-第一个MicroROS节点.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/基础/002-第一个MicroROS节点.html","title":"第一个MicroROS节点","keywords":"","body":"datetime:2023/10/24 10:23 author:nzb 该项目来源于大佬的动手学ROS2 2.你的第一个MicroROS节点 上一节我们介绍了MicroROS和Agent的安装，本节我们开始正是编写代码，接入ROS2。 一、新建工程添加依赖 1.1 新建工程 新建example10_hello_microros工程，这里需要更改下工程的位置，默认目录是在文档目录下，在测试时发现目录定位上有bug，所以建议建议直接放到主目录或其下目录，这里直接放到主目录。 1.2 添加依赖 打开platform.ini,接着我们添加MicroROS的依赖。 [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git 这里使用的地址并不是MicroROS官方仓库，而是经过修改后的国内仓库地址，里面放置了编译好后可以直接使用的microros静态库，并对仓库中需要梯子的地址进行了替换。 二、编写代码-第一个节点 开始编写代码，因为Micro-ROS遵循RCLC-API，所以这里通过一个最简单的例程介绍如何新建一个节点。 #include #include #include #include #include rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; void setup() { Serial.begin(115200); // 设置通过串口进行MicroROS通信 set_microros_serial_transports(Serial); // 延时时一段时间，等待设置完成 delay(2000); // 初始化内存分配器 allocator = rcl_get_default_allocator(); // 创建初始化选项 rclc_support_init(&support, 0, NULL, &allocator); // 创建节点 hello_microros rclc_node_init_default(&node, \"hello_microros\", \"\", &support); // 创建执行器 rclc_executor_init(&executor, &support.context, 1, &allocator); } void loop() { delay(100); // 循环处理数据 rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } 上面代码并不复杂，已经将注释写上，强烈建议你跟着代码敲一遍，不要直接复制粘贴。 相比在上位机中开发ROS，这里多了几步 设置通信协议，因为可以通过多种方式连接，所以需要进行提前设置 初始化内存分配器，在微控制器上资源受限，内存的管理要很细致 创建初始化选项，用于初始化rcl并创建一些需要用到的数据结构体 关于rclc的api并没有找到文档，不过源码的头文件依然非常清晰，直接安装Ctrl点击某个函数即可跳转（不行的，重启下Vscode）。 比如关于rclc_support_init 的源码及参数介绍。 /** * Initializes rcl and creates some support data structures. * Initializes clock as RCL_STEADY_TIME. * * * Attribute | Adherence * ------------------ | ------------- * Allocates Memory | Yes (in RCL) * Thread-Safe | No * Uses Atomics | No * Lock-Free | Yes * * \\param[inout] support a zero-initialized rclc_support_t * \\param[in] argc number of args of main * \\param[in] argv array of arguments of main * \\param[in] allocator allocator for allocating memory * \\return `RCL_RET_OK` if RCL was initialized successfully * \\return `RCL_RET_INVALID_ARGUMENT` if any null pointer as argument * \\return `RCL_RET_ERROR` in case of failure */ RCLC_PUBLIC rcl_ret_t rclc_support_init( rclc_support_t * support, int argc, char const * const * argv, rcl_allocator_t * allocator); 三、运行测试 连接开发板，编译下载，如果遇到端口被占用，多半是你的microros_agent没有关闭，Ctrl+C打断运行再次尝试。 接着打开Agent 然而并没有什么反应，重新点击一次RST即可看到有数据发送和接收过来了。 接着打开新的终端，输入指令 ros2 node list ros2 node info /hello_microros 可以看到，我们的第一个节点成功运行起来了。 四、总结 本节我们成功的在微控制器平台上将MicroROS节点运行起来了，下一节我们开始正式进行ROS2通信的学习。 "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/入门/001-话题订阅-控制LED.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/入门/001-话题订阅-控制LED.html","title":"话题订阅-控制LED","keywords":"","body":"datetime:2023/10/24 10:23 author:nzb 该项目来源于大佬的动手学ROS2 1.话题订阅-控制LED 你好，我是爱吃鱼香ROS的小鱼。本节我们正式进入到MicroROS的核心通信部分的学习中来，本节我们将通过话题订阅实现，通过话题控制LED的亮灭。 一、新建工程添加依赖 新建example11_microros_topic_sub工程 修改platformio.ini添加依赖 ; PlatformIO Project Configuration File ; ; Build options: build flags, source filter ; Upload options: custom upload port, speed and extra flags ; Library options: dependencies, extra library storages ; Advanced options: extra scripting ; ; Please visit documentation for the other options and examples ; https://docs.platformio.org/page/projectconf.html [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git 二、编写代码-实现订阅 编辑main.cpp，代码如下，注释小鱼已经添加到代码中来了 #include #include #include #include #include #include rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; // 声明话题订阅者 rcl_subscription_t subscriber; // 声明消息文件 std_msgs__msg__Int32 sub_msg; // 定义话题接收回调函数 void callback_subscription_(const void *msgin) { const std_msgs__msg__Int32 *msg = (const std_msgs__msg__Int32 *)msgin; if (msg->data == 0) { digitalWrite(2, HIGH); } else { digitalWrite(2, LOW); } } void setup() { Serial.begin(115200); // 设置通过串口进行MicroROS通信 set_microros_serial_transports(Serial); // 延时时一段时间，等待设置完成 delay(2000); // 初始化内存分配器 allocator = rcl_get_default_allocator(); // 创建初始化选项 rclc_support_init(&support, 0, NULL, &allocator); // 创建节点 topic_sub_test rclc_node_init_default(&node, \"topic_sub_test\", \"\", &support); // 订阅者初始化 rclc_subscription_init_default( &subscriber, &node, ROSIDL_GET_MSG_TYPE_SUPPORT(std_msgs, msg, Int32), \"led_control\"); // 创建执行器 rclc_executor_init(&executor, &support.context, 1, &allocator); // 为执行器添加一个订阅者 rclc_executor_add_subscription(&executor, &subscriber, &sub_msg, &callback_subscription_, ON_NEW_DATA); // 初始化LED pinMode(2, OUTPUT); } void loop() { delay(100); // 循环处理数据 rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } 三、代码注解 相比之前的节点代码这里主要多了这几行 #include 添加消息类型头文件 rcl_subscription_t subscriber; 声明话题订阅者 std_msgs__msg__Int32 sub_msg; 声明消息文件，这一点和上位机不同，因为内存紧缺，所以提前定义 void callback_subscription_(const void *msgin) 接收到数据的回调函数 rclc_subscription_init_default 初始化话题订阅者 rclc_executor_add_subscription(&executor, &subscriber, &sub_msg, &callback_subscription_, ON_NEW_DATA); ,为执行器添加一个订阅者 四、下载测试 4.1 编译下载 连接开发板，编译下载。 4.2 启动Agent 接着打开终端启动agent sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO serial --dev /dev/ttyUSB0 -v 点击下RST按钮，重启开发板，正常可以看到下图内容 4.3 查看是否连通 接着打开终端查看节点和话题 ros2 node list ros2 topic list 4.4 测试控制 关闭LED ros2 topic pub /led_control std_msgs/msg/Int32 \"{data: 0}\" --once 打开LED ros2 topic pub /led_control std_msgs/msg/Int32 \"{data: 1}\" --once 五、总结 本节我们通过话题订阅，实现对开发板上LED的控制，下一节我们将尝试读取开发板上的VM引脚电压，并将其通过话题发布到上位机中。 "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/入门/002-MicroROS话题发布实现.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/入门/002-MicroROS话题发布实现.html","title":"MicroROS话题发布实现","keywords":"","body":"datetime:2023/10/24 10:23 author:nzb 该项目来源于大佬的动手学ROS2 2.MicroROS-话题发布实现 本节将学习在开发板上实现话题的发布，最终实现通过话题发布当前开发板的电池电量信息，关于电量信息的测量，请参考：电池电压测量-学会使用ADC 一、新建工程添加依赖 新建example12_microros_topic_pub工程 修改platformio.ini添加依赖 ; PlatformIO Project Configuration File ; ; Build options: build flags, source filter ; Upload options: custom upload port, speed and extra flags ; Library options: dependencies, extra library storages ; Advanced options: extra scripting ; ; Please visit documentation for the other options and examples ; https://docs.platformio.org/page/projectconf.html [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git 二、编写代码-实现订阅 编辑main.cpp，代码如下，注释已经添加到代码中来了 #include #include #include #include #include // 添加头文件 #include rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; rcl_timer_t timer; // 声明话题发布者 rcl_publisher_t publisher; // 声明消息文件 std_msgs__msg__Float32 pub_msg; // 定义定时器接收回调函数 void timer_callback(rcl_timer_t *timer, int64_t last_call_time) { RCLC_UNUSED(last_call_time); if (timer != NULL) { rcl_publish(&publisher, &pub_msg, NULL); } } void setup() { Serial.begin(115200); // 设置通过串口进行MicroROS通信 set_microros_serial_transports(Serial); // 延时时一段时间，等待设置完成 delay(2000); // 初始化内存分配器 allocator = rcl_get_default_allocator(); // 创建初始化选项 rclc_support_init(&support, 0, NULL, &allocator); // 创建节点 topic_sub_test rclc_node_init_default(&node, \"topic_pub_test\", \"\", &support); // 订阅者初始化 rclc_publisher_init_default( &publisher, &node, ROSIDL_GET_MSG_TYPE_SUPPORT(std_msgs, msg, Float32), \"battery_voltage\"); // 创建定时器，200ms发一次 const unsigned int timer_timeout = 200; rclc_timer_init_default( &timer, &support, RCL_MS_TO_NS(timer_timeout), timer_callback); // 创建执行器 rclc_executor_init(&executor, &support.context, 1, &allocator); // 给执行器添加定时器 rclc_executor_add_timer(&executor, &timer); // 初始化ADC pinMode(34, INPUT); analogSetAttenuation(ADC_11db); } void loop() { delay(100); // 循环处理数据 rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); // 通过ADC获取电压值 int analogValue = analogRead(34); // 读取原始值0-4096 int analogVolts = analogReadMilliVolts(34); // 读取模拟电压，单位毫伏 float realVolts = 5.02 * ((float)analogVolts * 1e-3); // 计算实际电压值 pub_msg.data = realVolts; } 三、代码注解 相比之前的节点代码这里主要多了这几行 #include 包含flaot32类型头文件 rcl_publisher_t publisher; 定义发布者 std_msgs__msg__Float32 pub_msg; 定义发布消息，也需要提前定义 void timer_callback(rcl_timer_t *timer, int64_t last_call_time) 定义定时器回调函数，当我们需要以某个频率做什么的时候定时器可以派上用场 rclc_publisher_init_default 初始化发布者 rclc_timer_init_default 初始化定时器 rclc_executor_add_timer 给执行器添加一个定时器回调 四、下载测试 4.1 编译下载 连接开发板，编译下载。 4.2 启动Agent服务 接着打开终端启动agent sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO serial --dev /dev/ttyUSB0 -v 点击下RST按钮，重启开发板，正常可以看到下图内容 4.3 测试是否连通 ros2 node list ros2 topic list 4.4 查看话题数据 ros2 topic echo /battery_voltage 这里连接了小车的电池，VM电压代表电池电压，符合正常电压值范围。 同时可以使用下面指令测量话题频率 fishros@fishros-MS-7D42:~/example12_microros_topic_pub$ ros2 topic hz /battery_voltage average rate: 4.828 min: 0.207s max: 0.208s std dev: 0.00021s window: 6 average rate: 5.034 min: 0.106s max: 0.208s std dev: 0.02793s window: 12 average rate: 4.973 min: 0.106s max: 0.208s std dev: 0.02378s window: 17 average rate: 4.941 min: 0.106s max: 0.208s std dev: 0.02104s window: 22 average rate: 5.005 min: 0.106s max: 0.208s std dev: 0.02594s window: 28 average rate: 4.977 min: 0.106s max: 0.208s std dev: 0.02404s window: 33 average rate: 4.958 min: 0.106s max: 0.208s std dev: 0.02249s window: 38 average rate: 4.997 min: 0.106s max: 0.208s std dev: 0.02541s window: 44 五、总结 本节我们通过电量信息发布例程，学习了如何在开发板上实现话题发布流程。下一节我们开始尝试在开发板上建立服务端，尝试服务通信。 "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/入门/003-MicroROS服务通信服务端实现.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/入门/003-MicroROS服务通信服务端实现.html","title":"MicroROS服务通信服务端实现","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 3.MicroROS-服务通信服务端实现 一、新建工程添加依赖 新建example13_microros_service_server工程 修改platformio.ini添加依赖 ; PlatformIO Project Configuration File ; ; Build options: build flags, source filter ; Upload options: custom upload port, speed and extra flags ; Library options: dependencies, extra library storages ; Advanced options: extra scripting ; ; Please visit documentation for the other options and examples ; https://docs.platformio.org/page/projectconf.html [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git 二、编写代码-实现服务代码 编辑main.cpp，代码如下，注释已经添加到代码中来了 #include #include #include #include #include // 添加接口 #include rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; // 定义服务 rcl_service_t service; // 服务请求和返回消息定义 example_interfaces__srv__AddTwoInts_Request req; example_interfaces__srv__AddTwoInts_Response res; // 服务回调函数 void service_callback(const void *req, void *res) { example_interfaces__srv__AddTwoInts_Request *req_in = (example_interfaces__srv__AddTwoInts_Request *)req; example_interfaces__srv__AddTwoInts_Response *res_in = (example_interfaces__srv__AddTwoInts_Response *)res; // 计算sum res_in->sum = req_in->a + req_in->b; } void setup() { Serial.begin(115200); // 设置通过串口进行MicroROS通信 set_microros_serial_transports(Serial); // 延时时一段时间，等待设置完成 delay(2000); // 初始化内存分配器 allocator = rcl_get_default_allocator(); // 创建初始化选项 rclc_support_init(&support, 0, NULL, &allocator); // 创建节点 hello_microros rclc_node_init_default(&node, \"service_test\", \"\", &support); // 使用默认配置创建服务 rclc_service_init_default(&service, &node, ROSIDL_GET_SRV_TYPE_SUPPORT(example_interfaces, srv, AddTwoInts), \"/addtwoints\"); // 创建执行器 rclc_executor_init(&executor, &support.context, 1, &allocator); // 执行器添加服务 rclc_executor_add_service(&executor, &service, &req, &res, service_callback); } void loop() { delay(100); // 循环处理数据 rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } 三、代码注解 相比之前的节点代码这里主要多了这几行 #include 添加接口头文件 rcl_service_t service; 定义服务 example_interfaces__srv__AddTwoInts_Request res; 定义请求数据存储位置 example_interfaces__srv__AddTwoInts_Response req;定义响应数据存储位置 void service_callback(const void *req, void *res) 服务回调函数 rclc_service_init_default(&service, &node, ROSIDL_GET_SRV_TYPE_SUPPORT(example_interfaces, srv, AddTwoInts), \"/addtwoints\"); 使用默认配置初始化服务 rclc_executor_add_service(&executor, &service, &req, &res, service_callback); 为执行器添加服务定义 四、下载测试 4.1 编译下载 连接开发板，编译下载。 4.2 启动Agent服务 接着打开终端启动agent sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO serial --dev /dev/ttyUSB0 -v 点击下RST按钮，重启开发板，正常可以看到下图内容 4.3 测试是否连通 ros2 node list ros2 service list 4.4 测试服务 测试个1+2吧，使用ROS2CLI ros2 service call /addtwoints example_interfaces/srv/AddTwoInts \"{a: 1, b: 2}\" 成功的返回了3 五、总结 本节我们通过两数相加的Demo实现了服务通信，但是我们使用的是样例服务接口，在嵌入式平台上如何才能自定义接口呢？我们进阶篇见！ "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/进阶/001-控制OLED自定义消息接口.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/进阶/001-控制OLED自定义消息接口.html","title":"控制OLED自定义消息接口","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 1.控制OLED-自定义消息接口 前面章节中我们使用ROS2提供的两数相加服务接口实现了服务通信，但是很多场景需要我们自定定义接口，所以本节我们就学习如何自定义MicroROS的接口，以及如何将自己的功能包添加到MicroROS中来。 本节课最终效果是：通过自定义的服务接口控制开发板上的OLED显示器的内容。 ros2 service call /oled_control fishbot_interfaces/srv/OledControl \"{px: 0, py: 0 ,data: 'oled control by service~'}\" 一、新建工程添加依赖 新建example14_custom_interface ,注意请不要将工程放置于文档目录下，因为自定义接口编译时目录拼接存在Bug 修改platformio.ini [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git adafruit/Adafruit SSD1306@^2.5.7 这里除了添加micro_ros库之外再添加oled驱动库。 二、添加自定义接口 添加自定义接口一共需要三步。 1.创建extra_packages文件夹并创建接口功能包 2.编译功能包（主要为了测试功能包是否正常） 3.删除.pio/libdeps/featheresp32/micro_ros_platformio/libmicroros文件夹，重新编译 2.1 创建功能包 在工程的主目录下创建extra_packages文件夹，接着在文件夹下创建fishbot_interfaces功能包 cd example14_custom_interface mkdir extra_packages cd extra_packages ros2 pkg create fishbot_interfaces 接着添加服务接口文件并修改CMakeLists.txt和package.xml 文件extra_packages/fishbot_interfaces/srv/OledControl.srv int32 px int32 py string data --- int32 result 文件extra_packages/fishbot_interfaces/CMakeLists.txt cmake_minimum_required(VERSION 3.5) project(fishbot_interfaces) if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\") add_compile_options(-Wall -Wextra -Wpedantic) endif() # find dependencies find_package(ament_cmake REQUIRED) # uncomment the following section in order to fill in # further dependencies manually. # find_package( REQUIRED) if(BUILD_TESTING) find_package(ament_lint_auto REQUIRED) # the following line skips the linter which checks for copyrights # uncomment the line when a copyright and license is not present in all source files #set(ament_cmake_copyright_FOUND TRUE) # the following line skips cpplint (only works in a git repo) # uncomment the line when this package is not in a git repo #set(ament_cmake_cpplint_FOUND TRUE) ament_lint_auto_find_test_dependencies() endif() find_package(rosidl_default_generators REQUIRED) rosidl_generate_interfaces(${PROJECT_NAME} \"srv/OledControl.srv\" ) ament_package() 文件package.xml fishbot_interfaces 0.0.0 TODO: Package description root TODO: License declaration ament_cmake rosidl_default_generators rosidl_default_runtime rosidl_interface_packages ament_lint_auto ament_lint_common ament_cmake 2.2 编译功能包 cd extra_packages/ colcon build 2.3 重新编译工程 编译前需要删除.pio/libdeps/featheresp32/micro_ros_platformio/libmicroros文件夹，使用Ctrl+Alt+B重新重新编译工程。 三、编写代码 和两数相加服务相似的代码，只不过更换了接口并添加了OLED的驱动。 #include #include #include #include #include #include #include \"Wire.h\" #include // 加载Adafruit_GFX库 #include // 加载Adafruit_SSD1306库 #include // 添加接口 rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; // 定义服务 rcl_service_t service; // 服务请求和返回消息定义 fishbot_interfaces__srv__OledControl_Request req; fishbot_interfaces__srv__OledControl_Response res; Adafruit_SSD1306 display; // 服务回调函数 void service_callback(const void *req, void *res) { fishbot_interfaces__srv__OledControl_Request *req_in = (fishbot_interfaces__srv__OledControl_Request *)req; fishbot_interfaces__srv__OledControl_Response *res_in = (fishbot_interfaces__srv__OledControl_Response *)res; // 计算sum display.clearDisplay(); // 清空屏幕 display.setCursor(req_in->px, req_in->py); // 设置开始显示文字的坐标 display.println(req_in->data.data); // 输出的字符 display.display(); res_in->result = 0; } void setup() { Serial.begin(115200); // 设置通过串口进行MicroROS通信 set_microros_serial_transports(Serial); // 延时时一段时间，等待设置完成 delay(2000); // 初始化内存分配器 allocator = rcl_get_default_allocator(); // 创建初始化选项 rclc_support_init(&support, 0, NULL, &allocator); // 创建节点 hello_microros rclc_node_init_default(&node, \"example14_interface\", \"\", &support); // 使用默认配置创建服务 rclc_service_init_default(&service, &node, ROSIDL_GET_SRV_TYPE_SUPPORT(fishbot_interfaces, srv, OledControl), \"/oled_control\"); // 创建执行器 rclc_executor_init(&executor, &support.context, 1, &allocator); // 执行器添加服务 rclc_executor_add_service(&executor, &service, &req, &res, service_callback); // 重要，为string类型消息分配空间 req.data = micro_ros_string_utilities_init_with_size(100); /*========================OLED初始化====================================*/ Wire.begin(18, 19); display = Adafruit_SSD1306(128, 64, &Wire); display.begin(SSD1306_SWITCHCAPVCC, 0x3C); // 设置OLED的I2C地址 display.clearDisplay(); // 清空屏幕 display.setTextSize(1); // 设置字体大小 display.setCursor(0, 0); // 设置开始显示文字的坐标 display.setTextColor(SSD1306_WHITE); // 设置字体颜色 display.println(\"hello fishros!\"); // 输出的字符 display.display(); } void loop() { delay(100); // 循环处理数据 rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } 四、代码讲解 这里对新增的几行主要代码进行讲解 #include 添加string工具类 req.data = micro_ros_string_utilities_init_with_size(100); 使用string类型内存分配工具为data分配100字节e的空间 主要就是这两部分，值得注意的是，如果不提前为string类型的数据分配内容空间，最终会导致无法正常接收数据。 五、下载测试 5.1 编译下载 连接开发板，编译下载。 5.2 启动Agent 接着打开终端启动agent sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO serial --dev /dev/ttyUSB0 -v 点击下RST按钮，重启开发板，正常可以看到下图内容 5.3 查看是否连通 接着打开终端查看节点和话题 ros2 node list ros2 service list 4.4 测试控制 进入extra_packages，source环境 source install/setup.bash 显示nihao ros2 service call /oled_control fishbot_interfaces/srv/OledControl \"{px: 0, py: 0 , data: 'nihao'}\" 显示oled control by service~ ros2 service call /oled_control fishbot_interfaces/srv/OledControl \"{px: 0, py: 0 ,data: 'oled control by service~'}\" 六、总结 本节通过使用自定义服务接口控制oled显示的例程，学习了如何在工程中添加自己的功能包和接口文件。下一节我们将学习如何让开发板的时间和上位机的时间进行同步。 编译后不能运行，缺少对应的功能包，可能是因为不同Python解释器导致，humble使用的是Python3.10，尽可能卸载其他版本的Python "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/进阶/002-做个时钟-系统时间同步.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/进阶/002-做个时钟-系统时间同步.html","title":"做个时钟-系统时间同步","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 2.做个时钟-系统时间同步 在机器人系统中，时间同步非常重要。 原因在于，硬件系统采集的数据都是随时间变换而变化的，如果当前的控制使用上一时刻的传感器数据判断，就会造成各种问题，比如机器人上一时刻检测到前方有障碍，下一时刻障碍消失了，但此时如果采用过期的数据，就会造成误判。 MicroROS在设计时为我们提供了一系列的API用于时间同步和时间获取，本节我们就通过MicroROS进行时间同步，并最终在OLED上实现一个时钟功能。 最终效果如下: 一、新建工程并添加依赖 1.1 新建工程 新建example15_time_sync工程 1.2 添加依赖 这里需要使用三个库，microros、oled驱动以及时间库Time [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git adafruit/Adafruit SSD1306@^2.5.7 paulstoffregen/Time@^1.6.1 二、编写代码 代码并不多，单个文件，将相应注释已经加上。 #include #include #include #include #include #include // 加载时间库，提供setTime\\year\\month...函数 #include // 加载Adafruit_GFX库 #include // 加载Adafruit_SSD1306库 Adafruit_SSD1306 display; // 声明对象 rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; const int timeout_ms = 1000; static int64_t time_ms; static time_t time_seconds; char time_str[25]; void setup() { Serial.begin(115200); // 设置通过串口进行MicroROS通信 set_microros_serial_transports(Serial); // 延时时一段时间，等待设置完成 delay(2000); // 初始化内存分配器 allocator = rcl_get_default_allocator(); // 创建初始化选项 rclc_support_init(&support, 0, NULL, &allocator); // 创建节点 example15_time_sync rclc_node_init_default(&node, \"example15_time_sync\", \"\", &support); // 创建执行器 rclc_executor_init(&executor, &support.context, 1, &allocator); Wire.begin(18, 19); display = Adafruit_SSD1306(128, 64, &Wire); display.begin(SSD1306_SWITCHCAPVCC, 0x3C); // 设置OLED的I2C地址，默认0x3C display.setTextSize(2); // 设置字体大小，最小为1 display.clearDisplay(); // 清空屏幕 display.setCursor(0, 0); // 设置开始显示文字的坐标 display.setTextColor(SSD1306_WHITE); // 设置字体颜色 display.println(\"hello oled!\"); // 输出的字符 } void loop() { /*=========================同步时间=====================================*/ while (!rmw_uros_epoch_synchronized()) // 判断时间是否同步 { rmw_uros_sync_session(timeout_ms); // 同步时间 if (rmw_uros_epoch_synchronized()) { time_ms = rmw_uros_epoch_millis(); // 获取当前时间 time_seconds = time_ms / 1000; setTime(time_seconds + 8 * 3600); // 将当前时间+8H到北京时间然后设置到系统 } delay(10); return; } /*========================获取时间与显示==================================*/ sprintf(time_str, \"%04d-%02d-%02d %02d:%02d:%02d \", year(), month(), day(), hour(), minute(), second()); display.clearDisplay(); // 清空屏幕 display.setCursor(00, 0); // 设置开始显示文字的坐标 display.println(time_str); // 输出的字符 display.display(); delay(100); } 三、代码注解&API介绍 核心的时间同步代码就三行 rmw_uros_epoch_synchronized 判断microros是否已经同步时间 rmw_uros_sync_session 同步时间 rmw_uros_epoch_millis 获取当前时间 四、下载测试 4.1 编译下载 4.2 启动Agent 接着打开终端启动agent sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO serial --dev /dev/ttyUSB0 -v 点击下RST按钮，重启开发板，正常可以看到下图内容 4.3 查看是否连通 ros2 node list 4.4 查看时间 五、总结 本节我们通过三个API完成了MicroROS时间同步功能的开发，最终并将当前时间在OLED上显示出来，但使用有线的方式过于麻烦，下一节我们尝试通过无线WIFI完成时间的同步与MicroROS的通信开发。 "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/进阶/003-无线通讯-了解传输原理.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/进阶/003-无线通讯-了解传输原理.html","title":"无线通讯-了解传输原理","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 3.无线通讯-了解传输原理 在前面的学习中，我们一直通过串口通信来连接MicroROS，但一直扯着跟线是不是觉得很麻烦，本节我们利用开发板上的WIFI功能尝试使用无线的方式连接Agent。 一、新建工程并添加依赖 1.1 新建工程 1.2 添加依赖&修改配置 修改platformio.ini [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino board_microros_transport = wifi lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git 注意这里的配置，我们多添加了一个board_microros_transport，这个配置值我们给的是wifi，表示无线传输。 除了WIFI还支持其他方式，比如蓝牙，但是需要们自定义协议，后续FishBot开发教程中，将带你一起实现自定义协议。 二、编写代码 代码相对于串口通信只改变了三行，主要是设置wifi传输函数——set_microros_wifi_transports，需要传入wifi名称，密码，电脑IP,端口号四个参数。电脑IP获取方式请参考第三部分。 #include #include #include #include #include #include rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; void setup() { Serial.begin(115200); // 设置通过WIFI进行MicroROS通信 IPAddress agent_ip; agent_ip.fromString(\"192.168.2.105\"); // 设置wifi名称，密码，电脑IP,端口号 set_microros_wifi_transports(\"fishbot\", \"12345678\", agent_ip, 8888); // 延时时一段时间，等待设置完成 delay(2000); // 初始化内存分配器 allocator = rcl_get_default_allocator(); // 创建初始化选项 rclc_support_init(&support, 0, NULL, &allocator); // 创建节点 microros_wifi rclc_node_init_default(&node, \"microros_wifi\", \"\", &support); // 创建执行器 rclc_executor_init(&executor, &support.context, 1, &allocator); } void loop() { delay(100); // 循环处理数据 rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } 三、电脑IP获取 打开一个新的终端，输入ip -4 a | grep inet看看电脑的ip地址，一般可以看到多个网卡的，此时可以忽略172(docker)和127(本地) 开头的ip地址，剩下的一般就是我们要的ip地址，比如这里的就是192.168.0.105 四、下载测试 4.1 编译下载 4.2 启动Agent 打开终端输入指令，注意WIFI方式和之前的指令不太一样 docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 点击RST，正确连接上可以看到 4.3 测试是否连通 ros2 node list 看到节点表示连接成功～ 五、总结 本节开始，我们成功通过无线的方式将MicroROS连接到WIFI上来了，那问题来了，什么时候用串口模式，什么时候用WIFI模式呢？ 串口模式，适合当我们用树莓派等主控板在机器人上时，直接串口连接树莓派即可 WIFI模式，像FishBot一样，直接无线驱动机器人，WIFI此时就很合适了 "},"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/进阶/004-榨干性能-使用双核运行MicroROS.html":{"url":"ROS2/ROS2硬件控制篇/第14章-接入ROS2-MicroROS/进阶/004-榨干性能-使用双核运行MicroROS.html","title":"使用双核运行MicroROS","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 4.榨干性能-使用双核运行MicroROS 在硬件篇开始的第一节时，曾提到，我们所使用的开发板单片机是双核240M主频的，但是在后面的开发中我们并没有真正的使用了双核，主频也是使用的默认160MHZ。 所以本节带你一起带你一起提升主频并启动双核进行MicoROS的双核。 一、双核与RTOS介绍 所谓双核指的是ESP32单片机有两个内核，所有的外设都通过一个总线连接到两个内核上，也就是说，程序无论在哪个核上运行都可以操作硬件。 在前面的单片机开发平台介绍中，曾介绍ESP32的官方开发平台ESP-IDF的核心其实是基于开源的FreeRTOS优化而来的，而ESP32-Arduino则是对ESP-IDF的进一步封装，所以毋庸置疑，ESP32-Ardunio也是支持FreeRTOS的。 二、双核打印实验 接下来我们通过一个双核打印小实验来测试是否可以使用双核。 开始之前你需要了解两个函数 xPortGetCoreI() 获取当前程序所运行的内核ID，ID有0和1 xTaskCreatePinnedToCore 启动一个TASK并将其绑定到指定ID的内核，ID有0和1 新建example17_micoros2core，修改platformio.ini，提高主频 ; PlatformIO Project Configuration File ; ; Build options: build flags, source filter ; Upload options: custom upload port, speed and extra flags ; Library options: dependencies, extra library storages ; Advanced options: extra scripting ; ; Please visit documentation for the other options and examples ; https://docs.platformio.org/page/projectconf.html [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino board_build.f_cpu = 240000000L board_microros_transport = wifi lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git 测试代码如下 #include /** * @brief MicroROSTASK,打印ID * * @param param */ void microros_task(void *param) { while (true) { delay(1000); Serial.printf(\"microros_task on core:%d\\n\", xPortGetCoreID()); } } void setup() { Serial.begin(115200); /** * @brief 创建一个人物在Core 0 上 * microros_task 任务函数 * \"microros_task\" 任务名称 * 10240 任务占用内存大小 * NULL 任务参数，为空 * 1 任务优先级 * NULL 任务Handle可以为空 * 0 内核编号 */ xTaskCreatePinnedToCore(microros_task, \"microros_task\", 10240, NULL, 1, NULL, 0); } void loop() { delay(1000); Serial.printf(\"loop on core:%d\\n\", xPortGetCoreID()); } 测试结果 三、MicroROS双核实验 编写代码，在上节的代码稍微做些修改即可。 #include #include #include #include #include #include rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; /** * @brief MicroROSTASK,打印ID * * @param param */ void microros_task(void *param) { // 设置通过WIFI进行MicroROS通信 IPAddress agent_ip; agent_ip.fromString(\"192.168.2.105\"); // 设置wifi名称，密码，电脑IP,端口号 set_microros_wifi_transports(\"fishbot\", \"12345678\", agent_ip, 8888); // 延时时一段时间，等待设置完成 delay(2000); // 初始化内存分配器 allocator = rcl_get_default_allocator(); // 创建初始化选项 rclc_support_init(&support, 0, NULL, &allocator); // 创建节点 microros_wifi rclc_node_init_default(&node, \"microros_wifi\", \"\", &support); // 创建执行器 rclc_executor_init(&executor, &support.context, 1, &allocator); while (true) { delay(100); Serial.printf(\"microros_task on core:%d\\n\", xPortGetCoreID()); // 循环处理数据 rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } } void setup() { Serial.begin(115200); /** * @brief 创建一个人物在Core 0 上 * microros_task 任务函数 * \"microros_task\" 任务名称 * 10240 任务占用内存大小 * NULL 任务参数，为空 * 1 任务优先级 * NULL 任务Handle可以为空 * 0 内核编号 */ xTaskCreatePinnedToCore(microros_task, \"microros_task\", 10240, NULL, 1, NULL, 0); } void loop() { delay(1000); Serial.printf(\"do some control on core:%d\\n\", xPortGetCoreID()); } 下载后，运行Agent即可测试 docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 四、总结 本节通过配置和启动新任务成功开启了另一内核并完成MicroROS相关的传输。你可能会问使用双核240M有什么坏处，坏处就是耗电，不过相比我们的电池来说是不值一提的。 "},"ROS2/ROS2硬件控制篇/第15章-ROS2硬件实战-自制简易雷达/001-测量距离学会超声波传感器.html":{"url":"ROS2/ROS2硬件控制篇/第15章-ROS2硬件实战-自制简易雷达/001-测量距离学会超声波传感器.html","title":"测量距离学会超声波传感器","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 1.简易雷达原理介绍 在正式开始制作我们的简易雷达前，我们先了解下原理。 我们所说的雷达是一种测距设备，比如FishBot上搭载的雷达就可以实现360度的旋转测距——测量指定角度前方障碍物的距离。 所以要实现一个简易雷达，我们必须要有一个可以测量距离的传感器，一个可以指定角度的电机。 一、测距传感器超声波 百度百科介绍 超声波传感器是将超声波信号转换成其它能量信号（通常是电信号）的传感器。超声波是振动频率 高于20kHz的机械波。它具有频率高、波长短、绕射现象小，特别是方向性好、能够成为射线 而定向传播等特点。超声波对液体、固体的穿透本领很大，尤其是在阳光不透明的固体中。超声波碰到杂质或分界面会产生显著反射形成反射回波，碰到活动物体能产生多普勒效应 。超声波传感器广泛应用在工业、国防、生物医学等方面。 接着看看长什么样子： 便宜的就长这样子，一共两个头，一个头用于发送波，一个头接收波。 那么超声波传感器原理是什么呢？ 距离=(发送时间-接收时间)*速度/2 下一节我们将通过代码根据这一原理进行距离测量测试。 二、常用执行器舵机 舵机是可以根据指定角度进行旋转的特殊电机。 其硬件结构如上图所示，当我们把角度信息发送到控制板时，控制板通过电位器测量出当前的角度，然后根据当前角度和目标角度的角度差控制电机旋转，直到角度差变的几乎为零。 三、结构设计 主控板依然使用MicroROS学习板，购买雷达套餐购买链接 的小伙伴可以通过赠送的支架将超声波固定到舵机上，也可以自行用胶枪之类的固定。最终的结构示意图如下 2.测量距离学会超声波传感器 上一节简单的介绍了超声波传感器，但是没有介绍如何通过代码使用，本节我们尝试使用并封装超声波模块。 我们使用的超声波模块一共有四个引脚，分别是 TRIG 即发送引脚，用于发送超声波 ECHO 即接收引脚，用于接收反射回来的超声波 VCC 电源接5V GND 电源地 一、新建工程 新建example18_sr04 二、编写代码 带注释的代码如下 #include #define Trig 27 // 设定SR04连接的Arduino引脚 #define Echo 21 void setup() { Serial.begin(115200); pinMode(Trig, OUTPUT); // 初始化舵机和超声波 pinMode(Echo, INPUT); // 要检测引脚上输入的脉冲宽度，需要先设置为输入状态 } void loop() { static double mtime; digitalWrite(Trig, LOW); // 测量距离 delayMicroseconds(2); // 延时2us digitalWrite(Trig, HIGH); delayMicroseconds(10); // 产生一个10us的高脉冲去触发SR04 digitalWrite(Trig, LOW); mtime = pulseIn(Echo, HIGH); // 检测脉冲宽度，注意返回值是微秒us float detect_distance = mtime / 58.0 / 100.0; // 计算出距离,输出的距离的单位是厘米cm Serial.printf(\"distance=%f\\n\", detect_distance); delay(500); } 三、代码注解 核心代码分为两部分 3.1发送超声 方波产生，低-高-低 digitalWrite(Trig, LOW); // 测量距离 delayMicroseconds(2); // 延时2us digitalWrite(Trig, HIGH); delayMicroseconds(10); // 产生一个10us的高脉冲去触发SR04 digitalWrite(Trig, LOW); 3.2 检测回响计算距离 mtime = pulseIn(Echo, HIGH); // 检测脉冲宽度，注意返回值是微秒us float detect_distance = mtime / 58.0 / 100.0; // 计算出距离,输出的距离的单位是米m 58是一个时间系数，根据声音在空气中传播速度计算而来。pulseIn函数用于检测某个引脚从当前时间跳变到高电平之间持续的时间。 四、下载测试 将超声波模块连接到开发板上的超声波接口上 下载代码，打开串口，查看距离不断变化 五、总结 本节我们成功实现使用超声波实现距离测量功能，下一节我们尝试使用第三方库驱动舵机。 "},"ROS2/ROS2硬件控制篇/第15章-ROS2硬件实战-自制简易雷达/002-控制舵机学会使用执行器.html":{"url":"ROS2/ROS2硬件控制篇/第15章-ROS2硬件实战-自制简易雷达/002-控制舵机学会使用执行器.html","title":"控制舵机学会使用执行器","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 3.控制舵机学会使用执行器 本节我们尝试使用第三方库来驱动舵机，实现让舵机指针指向任意角度。 一、新建工程 新建example19_servo 在platformio.ini中添加舵机库 ; PlatformIO Project Configuration File ; ; Build options: build flags, source filter ; Upload options: custom upload port, speed and extra flags ; Library options: dependencies, extra library storages ; Advanced options: extra scripting ; ; Please visit documentation for the other options and examples ; https://docs.platformio.org/page/projectconf.html [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = madhephaestus/ESP32Servo@^0.12.0 二、编写代码 带注释代码如下。 #include #include Servo servo1; // 创建对象 void setup() { servo1.setPeriodHertz(50); // 舵机控制周期为50hz，即一个周期1000/50=20ms servo1.attach(4, 500, 2500); // 使用GPIO4作为舵机1信号引脚，占空比为500-2500us即 0.5-2.5ms servo1.write(90.0); // 设置90度 } void loop() { for (int i = 0; i 三、代码注解 这里主要需要介绍的是关于舵机的控制周期及占空比是如何设置的，这里设计到了PWM相关的知识。 PWM即脉宽调制（Pulse-width Modulation, PWM），之前在I2C介绍章节中，曾介绍过通信时SCL上就是一个固定周期的脉冲 PWM有两个重要的参数，第一个是周期，就像是正弦波，其周期就是2pi，指的是多久循环一次，我们这里设置的是50HZ，也就是说20ms。 在一个周期里，引脚高电平的时间就称为占空比，这里我们设置的是0.5ms-2.5ms之间作为舵机控制的占空比范围。 换句话说，假设我们设置当前舵机角度为90度，此时占空比 占空比 = 500+90*(2500-500)/180 四、下载测试 将舵机插在S1接口，注意黄色线接蓝色信号。 接着下载代码，观察舵机。 五、总结 本节我们通过三方库完成了对舵机的控制，下一节我们正式将舵机和超声波结合起来，测量指定角度下的距离。 "},"ROS2/ROS2硬件控制篇/第15章-ROS2硬件实战-自制简易雷达/003-舵机和超声波循环扫描.html":{"url":"ROS2/ROS2硬件控制篇/第15章-ROS2硬件实战-自制简易雷达/003-舵机和超声波循环扫描.html","title":"舵机和超声波循环扫描","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 4.舵机+超声波循环扫描 本节我们尝试将超声波的舵机结合起来实现循环扫描功能。 一、新建工程 新建example20_simple_laser 添加依赖，这里顺便吧microros的添加上，下一节直接使用 ; PlatformIO Project Configuration File ; ; Build options: build flags, source filter ; Upload options: custom upload port, speed and extra flags ; Library options: dependencies, extra library storages ; Advanced options: extra scripting ; ; Please visit documentation for the other options and examples ; https://docs.platformio.org/page/projectconf.html [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino board_microros_transport = wifi lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git madhephaestus/ESP32Servo@^0.12.0 二、编写代码 原理是先控制舵机走到某个角度，接着调用超声波测量距离，这里将超声波测距离封装了一个函数，并用一个数组存储10个历史数据。 #include #include #include #include #define Trig 27 // 设定SR04连接的Arduino引脚 #define Echo 21 Servo servo1; float get_distance(int angle) { static double mtime; servo1.write(angle); // 移动到指定角度 delay(25); // 稳定身形 digitalWrite(Trig, LOW); // 测量距离 delayMicroseconds(2); digitalWrite(Trig, HIGH); delayMicroseconds(10); // 产生一个10us的高脉冲去触发SR04 digitalWrite(Trig, LOW); mtime = pulseIn(Echo, HIGH); // 检测脉冲宽度，注意返回值是微秒us float detect_distance = mtime / 58.0 / 100.0; // 计算出距离,输出的距离的单位是厘米cm Serial.printf(\"point(%d,%f)\\n\", angle, detect_distance); return detect_distance; } void setup() { Serial.begin(115200); pinMode(Trig, OUTPUT); // 初始化舵机和超声波 pinMode(Echo, INPUT); // 要检测引脚上输入的脉冲宽度，需要先设置为输入状态 servo1.setPeriodHertz(50); // Standard 50hz servo servo1.attach(4, 500, 2500); servo1.write(90.0); } void loop() { for (int i = 0; i 三、下载测试 连接好超声波和舵机。 下载代码，观察串口输出 这里显示的就是角度以及距离信息。 "},"ROS2/ROS2硬件控制篇/第15章-ROS2硬件实战-自制简易雷达/004-可视化点云雷达消息合成.html":{"url":"ROS2/ROS2硬件控制篇/第15章-ROS2硬件实战-自制简易雷达/004-可视化点云雷达消息合成.html","title":"可视化点云雷达消息合成","keywords":"","body":"datetime:2023/10/26 10:23 author:nzb 该项目来源于大佬的动手学ROS2 5.可视化点云-雷达消息合成 上一节完成了指定角度距离的测量这一节我们将其合成ROS的laserscan消息，并将其通过microros发布到上位机，最终实现rviz2的可视化。 一、雷达消息介绍 使用指令ros2 interface show sensor_msgs/msg/LaserScan，可以看到ROS2对雷达数据接口的定义。 # Single scan from a planar laser range-finder # # If you have another ranging device with different behavior (e.g. a sonar # array), please find or create a different message, since applications # will make fairly laser-specific assumptions about this data std_msgs/Header header # timestamp in the header is the acquisition time of builtin_interfaces/Time stamp int32 sec uint32 nanosec string frame_id # the first ray in the scan. # # in frame frame_id, angles are measured around # the positive Z axis (counterclockwise, if Z is up) # with zero angle being forward along the x axis float32 angle_min # start angle of the scan [rad] float32 angle_max # end angle of the scan [rad] float32 angle_increment # angular distance between measurements [rad] float32 time_increment # time between measurements [seconds] - if your scanner # is moving, this will be used in interpolating position # of 3d points float32 scan_time # time between scans [seconds] float32 range_min # minimum range value [m] float32 range_max # maximum range value [m] float32[] ranges # range data [m] # (Note: values range_max should be discarded) float32[] intensities # intensity data [device-specific units]. If your # device does not provide intensities, please leave # the array empty. 1.1 header部分 头部分，主要是设置雷达的frame_id和时间戳，在microros中可以这样赋值 pub_msg.header.frame_id = micro_ros_string_utilities_set(pub_msg.header.frame_id, \"laser\"); // 初始化消息内容 int64_t current_time = rmw_uros_epoch_millis(); pub_msg.header.stamp.sec = current_time * 1e-3; pub_msg.header.stamp.nanosec = current_time - pub_msg.header.stamp.sec * 1000; 1.2 数据部分 angle_min 当前数据中最小的测量角度 angle_max 当前数据中最大的测量角度 angle_increment 我们默认就是一次1度，所以可以直接写 pub_msg.angle_increment = 1.0 / 180 * PI; time_increment 每个数据之间递增的时间，可以直接使用扫描的总之间除点数 scan_time 扫描时间，开始扫描到结束扫描的时间 range_min 最小范围可以直接赋值 我们设置成0.05即5cm range_max 最大范围，我们直接设置成5.0m ranges 测量的距离值数组 intensities 测量的强度，这里我们直接忽略即可 二、代码编写 直接在上一节工程上修改，全部代码如下，一次我们发布10个点，并且启动了ESP32的双核，同时采取了时间同步，保证雷达数据的时间戳正常。 #include #include #include #include #include #include #include #include #include #define PCOUNT 10 #define Trig 27 // 设定SR04连接的Arduino引脚 #define Echo 21 rclc_executor_t executor; rclc_support_t support; rcl_allocator_t allocator; rcl_node_t node; rcl_publisher_t publisher; // 声明话题发布者 sensor_msgs__msg__LaserScan pub_msg; // 声明消息文件 Servo servo1; bool connected_agent = false; void microros_task(void *param) { IPAddress agent_ip; // 设置通过WIFI进行MicroROS通信 agent_ip.fromString(\"192.168.2.105\"); // 从字符串获取IP地址 set_microros_wifi_transports(\"fishbot\", \"12345678\", agent_ip, 8888); // 设置wifi名称，密码，电脑IP,端口号 delay(2000); // 延时时一段时间，等待设置完成 allocator = rcl_get_default_allocator(); // 初始化内存分配器 rclc_support_init(&support, 0, NULL, &allocator); // 创建初始化选项 rclc_node_init_default(&node, \"example20_simple_laser\", \"\", &support); // 创建节点 rclc_publisher_init_default( // 发布初始化 &publisher, &node, ROSIDL_GET_MSG_TYPE_SUPPORT(sensor_msgs, msg, LaserScan), \"/scan\"); rclc_executor_init(&executor, &support.context, 1, &allocator); // 创建执行器 pub_msg.header.frame_id = micro_ros_string_utilities_set(pub_msg.header.frame_id, \"laser\"); // 初始化消息内容 pub_msg.angle_increment = 1.0 / 180 * PI; pub_msg.range_min = 0.05; pub_msg.range_max = 5.0; while (true) { delay(10); if (!rmw_uros_epoch_synchronized()) // 判断时间是否同步 { rmw_uros_sync_session(1000); // 同步时间 continue; } connected_agent = true; rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); // 循环处理数据 } } float get_distance(int angle) { static double mtime; servo1.write(angle); // 移动到指定角度 delay(25); // 稳定身形 digitalWrite(Trig, LOW); // 测量距离 delayMicroseconds(2); digitalWrite(Trig, HIGH); delayMicroseconds(10); // 产生一个10us的高脉冲去触发SR04 digitalWrite(Trig, LOW); mtime = pulseIn(Echo, HIGH); // 检测脉冲宽度，注意返回值是微秒us float detect_distance = mtime / 58.0 / 100.0; // 计算出距离,输出的距离的单位是厘米cm Serial.printf(\"point(%d,%f)\\n\", angle, detect_distance); return detect_distance; } void setup() { Serial.begin(115200); pinMode(Trig, OUTPUT); // 初始化舵机和超声波 pinMode(Echo, INPUT); // 要检测引脚上输入的脉冲宽度，需要先设置为输入状态 servo1.setPeriodHertz(50); // Standard 50hz servo servo1.attach(4, 500, 2500); servo1.write(90.0); xTaskCreatePinnedToCore(microros_task, \"microros_task\", 10240, NULL, 1, NULL, 0); } void loop() { if (!connected_agent) return; static float ranges[PCOUNT + 1]; for (int i = 0; i 三、下载测试 下载代码 启动agent。 docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 测试 ros2 node list ros2 topic list ros2 topic echo /scan 接着打开终端，输入rviz2打开rviz 修改配置，显示过去5s数据 四、总结 本节我们成功实现了使用超声波和舵机模拟雷达数据，并将其合成scan发布到电脑上使用rviz2进行可视化。至此我们完成了ROS2硬件控制的所有课程。下面迎接你的将是移动机器人和机械臂开发课程，请做好准备，继续出发。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/001-移动机器人底盘结构介绍.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/001-移动机器人底盘结构介绍.html","title":"移动机器人底盘结构介绍","keywords":"","body":"datetime:2023/10/31 14:20 author:nzb 该项目来源于大佬的动手学ROS2 1.移动机器人底盘结构介绍 本节我们对移动机器人底盘结构进行简单的介绍，并着重介绍FishBot基础版的组成结构。 对于一个移动底盘来说，所要提供的核心功能有两个-感知和执行能力，我们分别进行介绍。 一、感知-传感器 所谓感知即通过给类传感器获取环境信息的能力。在移动机器人中，我们常用的传感器有 距离传感器——雷达、超声波 轮子速度传感器——编码器 惯性测量单元——IMU传感器 图像传感器——单目、双目、深度摄像头 除了上面几类之外，你也可以根据需求挂载其他你需要的传感器，比如温湿度测量传感器等。 对于FishBot基础版来说，搭载的传感器有雷达、超声波、编码器和IMU四种。 在上一篇中我们已经使用了超声波和IMU，所以本节我们对雷达和编码器这两种传感器进行简单介绍。 1.1 雷达 我们采用的激光雷达是单线旋转式三角测距激光雷达。 1.1.1 雷达测距原理介绍 在雷达的头部分别有一个激光发射头和线性的CCD接收头。 特意拆了个雷达，放张图给大家看看 右边黑色的是发射头，左边是CCD接收头，发射头发射出的光属于波长大约在1000nm左右的红外光，肉眼是不可见的。 FishBot所采用的这种激光雷达的测距原理是三角测距法 从上图可以看出，当我们已知L（机械安装值）和d1（CCS测量值）和f（机械安装值）的情况下，我们可以得到D1的值，即激光雷达到被测物体的距离 D_1/(L+d_2)=f/d_2 \\\\ D_1 = (f*(L+d_2))/d_2 = fL/d_2+f 激光头通过不断旋转，这样就可以测量出360度的深度信息。 1.2 编码器 在移动机器人中我们需要实时的获取到机器人各个轮子的转速，通过转速根据机器人的运动学模型将轮子的速度转换成机器人的速度，通过对速度进行积分（速度*距离）得到机器人行走的距离。 我们如何对轮子速度的测量所使用的传感器就是编码器，在FishBot上，我们采用的是AB电磁编码器。 电磁编码器是由1和2两个霍尔传感器和圆形磁铁3共同组成的，该磁铁的磁性是间隔分布的，磁铁固定在电机的转子上，当电机转动时，带动磁铁转动，此时用于检测磁性的霍尔传感器就会检测到磁性的变化，从而就可以测量出电机在某段时间内转了多少圈即电机的转速。 二、执行器 所谓执行器就是负责动的部件，在移动机器人上，最重要的一个执行器就是电机了，除此之外我们也可以把OLED这种显示设备看作一个可以操作的执行器。 电机有很多分类，大类可以按照有刷无刷、直流交流来分类，具体就不展开了，我们下面主要介绍FishBot所采用的电机。 2.1 电机 我们FishBot上采用的是一个额定电压12V的370减速电机，额定转速为130转/分、额定电流0.5A，转矩600克力厘米。 电机相信你很熟悉，那什么是减速电机呢？减速电机指的是带减速器的电机。 电机一般由定子和转子组成的，一般转速都比较快，但输出的力矩比较小，所以我们会给电机配备减速器，让转速降低，提高力矩。 三、其他配件 除了执行器和传感器外，还有一些必要配件 电池，提供电力支持 稳压模块，提供电压转换，FishBot以将其集成到主控板上 万向轮等必要支撑结构 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/002-从H桥说起-电机驱动原理介绍.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/002-从H桥说起-电机驱动原理介绍.html","title":"从H桥说起-电机驱动原理","keywords":"","body":"datetime:2023/10/31 14:20 author:nzb 该项目来源于大佬的动手学ROS2 2.从H桥说起-电机驱动原理介绍 一、电机驱动原理介绍 正式编写代码前，我们先了解下电机驱动的原理，以便于我们了解我们如何才能通过代码控制电机的转速和正反转。 1.1 H桥电路 让电机动起来只需要通电就行，比如我们用的额定电压为12V 130RPM的电机，当给到12V的电压时可以达到额定转速130转/分，但如果我们给8V的电压，此时电机依然可以转动，但转速就相对较低。 只是转起来还不行，要想控制机器人前进后退，左转右转，我们还需要控制轮子的转的方向，想要控制转速我们则需要控制给到电机的电压。 H桥（H-Bridge）电路可以帮我们实现上面两个功能，之所以叫H桥，因为这个电路长的像H。通过该电路可以将电源电压正向或反向地施加到电动机上，从而实现正向、反向转动和制动等功能。 该电路由四个独立开关管（MOSFET）组成，在H桥电路中，两个开关管组成一对，如上图所示。当我们接通Q1和Q4，关闭Q3和Q2时，电源电压正向施加到电动机上，使其正向转动。 我们关闭Q1和Q4，接通Q2和Q3时，电源电压反向施加到电动机上，使其反向转动。 在制动时，同时关闭四个开关管，这样电动机会在短时间内停止转动。另外，通过之前介绍的在PWM（脉宽调制）控制下，可以通过改变开关管的开关时间比例，就可以实现电动机的速度控制。 1.2 原理图 看完H桥电路原理，我们来讲讲在FishBot主控板上如何搭载的该电路的。在开发板上我们采用了一款H桥电路芯片DRV8833来实现电机的驱动。 该电路原理图如上图所示，我们通过AIN1（IO23）的高低电平控制H桥中Q1和Q4的开关，通过AIN2（IO22）控制Q2和Q3的开关，所以我们在程序中通过控制AIN1和AIN2的高低电平变化就可以完成对电机正反转的控制。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/003-电机控制之正反转实验.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/003-电机控制之正反转实验.html","title":"电机控制之正反转实验","keywords":"","body":"datetime:2023/11/01 10:06 author:nzb 该项目来源于大佬的动手学ROS2 3.电机控制之正反转实验 前面说到通过控制对应的IO电平变换即可完成对电机正反转的控制，本节我们尝试编写代码，进行实验。 一、新建工程 新建example21_motor_direction_control 二、编写代码 根据第前面硬件控制章节学到的内容可知，控制IO电平只需要使用pinMode和digitalWrite相关函数即可。 /** * @file main.cpp * @author fishros@foxmail.com * @brief 电机正反转控制 * @version 0.1 * @date 2022-12-19 * * @copyright Copyright (c) 2022 * */ #include #define AIN1 23 // 电机驱动模块AIN1引脚 #define AIN2 22 // 电机驱动模块AIN2引脚 #define KEY 0 // 按键引脚 int motorStatus = 0; // 电机状态变量，0-3循环变化 void setup() { Serial.begin(115200); // 初始化串口通信 pinMode(KEY, INPUT); // 设置按键引脚为输入模式 pinMode(AIN1, OUTPUT); // 设置AIN1引脚为输出模式 pinMode(AIN2, OUTPUT); // 设置AIN2引脚为输出模式 } void loop() { if (digitalRead(KEY) == LOW) // 检测按键是否按下 { delay(50); // 延迟50ms，以防止误触 if (digitalRead(KEY) == LOW) { while (digitalRead(0) == LOW) // 等待按键松开，避免连续按下 ; motorStatus++; // 切换电机状态 motorStatus = motorStatus % 4; // 保持该变量值在0-4之间 } } // 根据电机状态切换IO电平 switch (motorStatus) { case 0: Serial.println(\"AIN1: HIGH, AIN2: LOW\"); // 调试信息：AIN1为高电平，AIN2为低电平 digitalWrite(AIN1, HIGH); digitalWrite(AIN2, LOW); break; case 1: Serial.println(\"AIN1: LOW, AIN2: HIGH\"); // 调试信息：AIN1为低电平，AIN2为高电平 digitalWrite(AIN1, LOW); digitalWrite(AIN2, HIGH); break; case 2: Serial.println(\"AIN1: HIGH, AIN2: HIGH\"); // 调试信息：AIN1和AIN2均为高电平 digitalWrite(AIN1, HIGH); digitalWrite(AIN2, HIGH); break; case 3: Serial.println(\"AIN1: LOW, AIN2: LOW\"); // 调试信息：AIN1和AIN2均为低电平 digitalWrite(AIN1, LOW); digitalWrite(AIN2, LOW); break; default: break; } } 代码解释 在setup函数中，通过pinMode函数将KEY、AIN1和AIN2引脚设置为对应的输入输出模式。 在loop函数中，首先通过digitalRead函数检测按键是否按下，如果检测到按键按下，则会将电机状态变量motorStatus加1，然后通过switch语句根据电机状态改变AIN1和AIN2引脚的电平状态。同时，还会通过Serial.println函数将AIN1和AIN2引脚的电平状态输出到串口，方便调试。 三、测试 将代码下载到FishBot主控板上，点击按键，查看轮子转动效果。 你可以发现，当AIN1和AIN2同时为高电平或者同时为低时，电机并不会转动，符合上一节中对H桥的介绍。 四、总结 本节我们成功通过代码验证了上一节电机控制理论，下一节我们尝试通过PWM的占空比控制电机的转速。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/004-电机控制之速度控制实验.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/004-电机控制之速度控制实验.html","title":"电机控制之速度控制实验","keywords":"","body":"datetime:2023/11/01 10:06 author:nzb 该项目来源于大佬的动手学ROS2 4.电机控制之速度控制实验 前面说到通过控制对应的IO上的PWM占空比即可完成对电机速度的控制。 关于PWM的介绍在ROS2硬件控制篇的舵机控制中已经介绍过了，所以我们知道通过改变PWM的占空比可以实现对输出电压的大小调节。占空比越大，输出电压越高；占空比越小，输出电压越低。 接着我们通过一个实验来验证下 一、新建工程 新建example22_motor_speed_control 二、编写代码 程序的基本思路是，通过检测按键输入来改变占空比的大小，从而控制电机的转速。按下按键后，每次增加0.1的占空比，当占空比达到1.0时，重新从0开始计数。在loop函数中，通过控制AIN1引脚的高低电平来实现PWM信号的输出，从而控制电机的速度。 /** * @file main.cpp * @author fishros@foxmail.com * @brief 电机速度控制 * @version 0.1 * @date 2022-12-19 * * @copyright Copyright (c) 2022 * */ #include #define AIN1 23 // 电机驱动模块AIN1引脚 #define AIN2 22 // 电机驱动模块AIN2引脚 #define KEY 0 // 按键引脚 #define CYCLE 10 // 定义PWM信号的周期长度，单位为ms float duty = 0.0; // 定义占空比变量，并初始化为0.0 void setup() { Serial.begin(115200); // 初始化串口通信 pinMode(KEY, INPUT); // 设置按键引脚为输入模式 pinMode(AIN1, OUTPUT); // 设置AIN1引脚为输出模式 pinMode(AIN2, OUTPUT); // 设置AIN2引脚为输出模式 digitalWrite(AIN2, LOW);// 设置AIN2引脚为低电平，控制电机转向 } void loop() { // 检测按键是否按下 if (digitalRead(KEY) == LOW) { delay(50); // 延迟50ms，以防止误触 // 确认按键已经按下 if (digitalRead(KEY) == LOW) { // 等待按键松开，避免连续按下 while (digitalRead(0) == LOW) ; // 每次增加0.1的占空比，当占空比达到1.0时，重新从0开始计数 duty = duty + 0.1; if (duty > 1.0) duty = 0; } } // 输出PWM信号控制电机转速 digitalWrite(AIN1, HIGH); // 将AIN1引脚设置为高电平 delay(CYCLE * duty); // 延迟一段时间，时间长度由占空比决定 digitalWrite(AIN1, LOW); // 将AIN1引脚设置为低电平 delay(CYCLE * (1 - duty)); // 延迟一段时间，时间长度由占空比决定 } 三、测试 将代码下载到主控板上，点击BOOT按键，观察电机转速。 四、总结 本节我们通过简单的一个实验学习了如何通过PWM调节电机的PWM，但有一点需要注意，程序中使用了delay函数来控制PWM信号的占空比，这种方法在简单的应用场景下是可行的，但是在需要更高精度的控制场景下可能会产生问题。为了实现更高精度的PWM控制，我们可以采用ESP32的电机PWM控制单元，下一节我们就尝试使用这一开源库实现更精细化的控制。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/005-电机控制之使用开源库驱动多路电机.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/005-电机控制之使用开源库驱动多路电机.html","title":"电机控制之使用开源库驱动多路电机","keywords":"","body":"datetime:2023/11/01 10:06 author:nzb 该项目来源于大佬的动手学ROS2 5.电机控制之使用开源库驱动多路电机 前面了解了电机控制的原理并通过实验测试了对电机正反转以及转速的控制。本节我们采用开源库调用ESP32的外设MCPWM进行精细化的电机PWM控制。 一、MCPWM简介 MCPWM中文名是电机控制脉宽调制器 （Motor Control Pulse Width Modulator ），是一款多功能 PWM 发生器，包含各种子模块，使其成为电机控制、数字电源等电力电子应用的关键元件。MCPWM 外设可用于以下场景： 数字电机控制，例如有刷/无刷直流电机、RC 伺服电机 基于开关模式的数字电源转换 功率DAC，其中占空比相当于DAC模拟值 计算外部脉冲宽度，并将其转换为其他模拟值，如速度、距离 为磁场定向控制 （FOC） 生成空间矢量 PWM （SVPWM） 信号 这里只需要了解MCPWM可以用来做什么就足够了 二、新建工程并添加依赖 新建example23_mcpwm_control 在platformio.ini添加依赖 [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino lib_deps = https://github.com/fishros/Esp32McpwmMotor.git 这里我们使用的驱动库是开源的Esp32McpwmMotor，支持12路PWM输出，可以同时控制6个直流电机，所以对于只有两个驱动轮的FishBot来说绰绰有余。 关于该库的详细介绍和使用可以查看Github 中的说明，另外欢迎顺手给个star~ 三、编写代码 直接参考开源库中的代码 #include #include Esp32McpwmMotor motor; // 创建一个名为motor的对象，用于控制电机 void setup() { Serial.begin(115200); // 初始化串口通信，波特率为115200 motor.attachMotor(0, 23, 22); // 将电机0连接到引脚23和引脚22 motor.attachMotor(1, 12, 13); // 将电机1连接到引脚12和引脚13 } void loop() { motor.updateMotorSpeed(0, -70); // 设置电机0的速度(占空比)为负70% motor.updateMotorSpeed(1, 70); // 设置电机1的速度(占空比)为正70% delay(2000); // 延迟两秒 motor.updateMotorSpeed(0, 70); // 设置电机0的速度(占空比)为正70% motor.updateMotorSpeed(1, -70); // 设置电机1的速度(占空比)为负70% delay(2000); // 延迟两秒 } 上面这段代码是用于控制两个电机进行正反转的程序。其中使用了Esp32McpwmMotor库来控制电机，该库提供了一些常用的控制函数，比如attachMotor()用于连接电机，updateMotorSpeed()用于更新电机速度。 在setup()函数中，首先通过Serial.begin()函数初始化串口通信，然后通过motor.attachMotor()函数将两个电机连接到指定的引脚，引脚的确定可以从原理图得出。 在loop()函数中，通过motor.updateMotorSpeed()函数分别控制电机0和电机1的速度。每次调用该函数时，第一个参数是电机的编号，第二个参数是电机的速度，正数表示正转，负数表示反转。然后通过delay() 函数延迟两秒，实现电机正反转的循环控制。 四、测试 下载到开发板，测试下能不能动起来。 五、总结 本节我们通过开源库实现对两个电机正反转和速度的同时控制，下一节我们结合ROS 2的话题通信机制，尝试通过键盘来控制小车的前进后退与转弯。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/006-做个遥控车订阅ROS2Twist.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/006-做个遥控车订阅ROS2Twist.html","title":"做个遥控车订阅ROS2Twist","keywords":"","body":"datetime:2023/11/01 10:06 author:nzb 该项目来源于大佬的动手学ROS2 6.做个遥控车-订阅ROS2 Twist 本节我们结合上一节电机控制以及前面章节的MicroROS话题订阅部分知识点，来实现一个可以用键盘遥控的小车。 一、新建工程 新建工程example24_ros2_car 修改配置 [env:featheresp32] ; 这是一个环境配置标签，指定了代码将运行的硬件平台和框架 platform = espressif32 ; 指定了使用的平台为Espressif 32 board = featheresp32 ; 指定使用的硬件板为Feather ESP32 framework = arduino ; 指定使用的框架为Arduino board_microros_transport = wifi ; 指定使用的Micro-ROS传输方式为Wi-Fi lib_deps = ; 列出所有依赖库的URL，这些库将被下载和安装 https://github.com/fishros/Esp32McpwmMotor.git ; ESP32-MCPWM-Motor库，用于驱动电机 https://gitee.com/ohhuo/micro_ros_platformio.git ; Micro-ROS平台库，用于在ESP32上运行ROS 2 二、编写代码 #include #include #include #include #include #include #include #include #include // 定义 ROS2 执行器和支持结构 rclc_executor_t executor; rclc_support_t support; // 定义 ROS2 内存分配器 rcl_allocator_t allocator; // 定义 ROS2 节点和订阅者 rcl_node_t node; rcl_subscription_t subscriber; // 定义接收到的消息结构体 geometry_msgs__msg__Twist sub_msg; // 定义控制两个电机的对象 Esp32McpwmMotor motor; // 回调函数，当接收到新的 Twist 消息时会被调用 void twist_callback(const void *msg_in) { // 将接收到的消息指针转化为 geometry_msgs__msg__Twist 类型 const geometry_msgs__msg__Twist *twist_msg = (const geometry_msgs__msg__Twist *)msg_in; // 从 Twist 消息中获取线速度和角速度 float linear_x = twist_msg->linear.x; float angular_z = twist_msg->angular.z; // 打印接收到的速度信息 Serial.printf(\"recv spped(%f,%f)\\n\", linear_x, angular_z); // 如果速度为零，则停止两个电机 if (linear_x == 0 && angular_z == 0) { motor.updateMotorSpeed(0, 0); motor.updateMotorSpeed(1, 0); return; } // 根据线速度和角速度控制两个电机的转速 if (linear_x > 0) { motor.updateMotorSpeed(0, 70); motor.updateMotorSpeed(1, 70); } if (linear_x 0) { motor.updateMotorSpeed(0, -70); motor.updateMotorSpeed(1, 70); } if (angular_z 代码使用 Esp32McpwmMotor 库初始化电机，设置 micro-ROS 通信参数以连接到 ROS2 代理，并初始化一个 ROS2 节点和一个订阅者，以订阅 /cmd_vel 主题上的 Twist 消息。 当接收到新的 Twist 消息时，调用 twist_callback() 函数提取线性和角速度，并相应地控制电机。如果两个速度都为零，则电机停止。否则，根据方向设置电机速度。在正向方向上，速度设置为 70，在反向方向上为 -70。 loop() 函数重复调用 rclc_executor_spin_some() 来处理来自 ROS2 网络的传入数据。 需要注意的是，你要根据自己的网络情况修改下面的代码以实现无线通信，如果不知道怎么设置，请回看前面章节。 agent_ip.fromString(\"192.168.2.105\"); set_microros_wifi_transports(\"fishbot\", \"12345678\", agent_ip, 8888); 三、下载测试 将代码下载到小车，运行agent，点击RST等待接入。 sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 接着我们使用ROS 2的键盘控制节点来进行控制测试 ros2 run teleop_twist_keyboard teleop_twist_keyboard 接着按下入JKL，几个按键，看一下小车是否动了起来。 四、总结 本节我们通过将小车接入MicroROS完成了一个遥控小车的开发。下一节我们开始使用编码器来测量轮子的转速。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/007-速度测量-编码器-脉冲测量与校准.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/007-速度测量-编码器-脉冲测量与校准.html","title":"速度测量-编码器-脉冲测量与校准","keywords":"","body":"datetime:2023/11/01 10:06 author:nzb 该项目来源于大佬的动手学ROS2 7.从编码器说起-速度测量原理介绍 上节做完小车，遥控时小车前进时你应该会发现，小车很难走一条直线，但明明我们给到两个电机的PWM占空比都是相同的，原因在于每一个电机的硬件参数并不能完全的保证一致，所以当我们采用开环控制时，即使我们给到每个电机相同的电压，也不能让两个电机保持相同的转速。 要解决这个问题我们就要把开环控制改成闭环控制，我们要实现的是速度闭环，所以第一步我们要实现的是对电机速度的测量。 一、轮速测量原理 第一节中介绍过，我们采用的是AB磁编码器，编码器直接连接到了我们的单片机IO上，当电机转动时，IO上的电平高低就会产生变化，我们称这种电平从低到高再到低的过程称作一个脉冲。 因为有减速机的存在，当减速器的输出轴（轮胎）转动了一圈，我们会检测到多个脉冲。所以要想通过编码器得出轮子的速度，我们需要知道检测到一个脉冲时，轮子行走多远距离。 我们FishBot上的电机轮子直径为65mm，当轮子转一圈时产生N个脉冲，那么一个脉冲轮子前进的距离D可以这样计算，单位是mm。 D = 65*PI/N 下面我们将通过实际的测试确定D的值，已知D的情况下，我们测得，某一段时间 \\Delta T (ms)内测得脉冲数为 P_T ，则此时电机的转速为 V_T (m/s) V_T = ((P_T*D)/1000)/(\\Delta T/1000) \\\\ =(P_T*D)/\\Delta T 二、轮速测量原理 你可能会好奇，为什么我们的电机后面有两个霍尔传感器，用一个不就可以对电机进行测速了吗？原因是使用两个会更精准，同时可以测量方向。 我们把磁铁看作小汽车，AB两个传感器是一条路上前后两个摄像头，如果汽车是正着行驶的，你会发现总是A摄像头先看到汽车，然后再是B，但如果反过来行驶，则是B摄像头先看到设备。 [A] [B] ------------------------------------------------------------- [汽车-->] [为了更加直观也分别用逻辑分析仪测量了两段轮子正转和反转时，AB编码器上电平的变化。 放大正转时，当A（通道0）电平为高电平后（A摄像头先看到了汽车），过了一段时间B（通道1）才变为高电平（B摄像头看到了汽车）。 放大反转部分，当A（通道0）电平为高电平后（A摄像头看到了汽车），在A之前B（通道1）已经为高电平了（B摄像头先看到了汽车）。 所以在代码中我们可以检测到当A通道从低电平变成高电平时，B通道的电平值，如果为低则表示正转，为高则表示反转。 8.脉冲测量与校准实验 有了上面的理论，这一节我们编写代码来尝试下是否能够读取到电机上编码器的脉冲数，并通过实验测试出小车的输出轴转速和编码器脉冲的比值。 一、新建工程并导入开源库 新建example25_encoder 添加依赖 [env:featheresp32] ; 这是一个环境配置标签，指定了代码将运行的硬件平台和框架 platform = espressif32 ; 指定了使用的平台为Espressif 32 board = featheresp32 ; 指定使用的硬件板为Feather ESP32 framework = arduino ; 指定使用的框架为Arduino lib_deps = ; 列出所有依赖库的URL，这些库将被下载和安装 https://github.com/fishros/Esp32PcntEncoder.git ; ESP32 编码器驱动库 这里我们使用的是Esp32PcntEncoder开源库，这个库调用了ESP32的脉冲计算外设进行编码器脉冲的计算，使用非常简单。 二、代码实现 编写代码 #include #include Esp32PcntEncoder encoders[2]; // 创建一个数组用于存储两个编码器 void setup() { // 1.初始化串口 Serial.begin(115200); // 初始化串口通信，设置通信速率为115200 // 2.设置编码器 encoders[0].init(0, 32, 33); // 初始化第一个编码器，使用GPIO 32和33连接 encoders[1].init(1, 26, 25); // 初始化第二个编码器，使用GPIO 26和25连接 } void loop() { delay(10); // 等待10毫秒 // 读取并打印两个编码器的计数器数值 Serial.printf(\"tick1=%d,tick2=%d\\n\", encoders[0].getTicks(), encoders[1].getTicks()); } 上面这段代码使用了ESP32PcntEncoder库来读取两个旋转编码器的计数器数值。其中，函数setup()用于初始化串口和编码器；函数loop()用于读取并打印两个编码器的计数器数值。以下是代码的详细解释： 首先包含了两个头文件Arduino.h和Esp32PcntEncoder.h，用于编写Arduino程序和使用ESP32PcntEncoder库。 在全局变量中创建了一个长度为2的Esp32PcntEncoder数组，用于存储两个编码器。 函数setup()用于初始化串口和编码器。在本代码中，首先通过Serial.begin()函数初始化串口，设置通信速率为115200。然后通过encoders[0].init()和encoders[1].init() 函数分别初始化了两个编码器。其中，函数init()需要传入三个参数，分别是编码器的ID、引脚A的GPIO编号和引脚B的GPIO编号。在本代码中，第一个编码器的ID为0，引脚A连接的GPIO为32 ，引脚B连接的GPIO为33；第二个编码器的ID为1，引脚A连接的GPIO为26，引脚B连接的GPIO为25。 函数loop()用于读取并打印两个编码器的计数器数值。在本代码中，首先通过delay()函数等待10毫秒。然后通过encoders[0].getTicks()和encoders[1].getTicks() 函数分别读取了两个编码器的计数器数值。最后通过Serial.printf()函数将这两个数值打印。 三、下载测试 将代码下载进入开发板，打开串口监视器，查看输出。 四、脉冲/圈计算 为了计算一个脉冲轮子前进的距离，我们可以通过手动将轮子旋转10圈，然后利用前面的公式进行计算。 这里将轮子转动10圈后得到脉冲数为19419，也就是说当前电机1941.8个脉冲/圈 根据公式可以算出，一个脉冲轮子前进的距离为 D = 65*PI/(19419/10)\\\\ =0.1051566 接着我们可以利用公式计算速度。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/008-速度转换-机器人最大速度测量.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/008-速度转换-机器人最大速度测量.html","title":"速度转换-机器人最大速度测量","keywords":"","body":"datetime:2023/11/01 10:06 author:nzb 该项目来源于大佬的动手学ROS2 9.速度转换-机器人最大速度测量 有了上一节的测量值，这一节我们尝试对电机最大速度进行测量。 一、新建工程并导入开源库 新建example26_max_speed_measurement 添加依赖 [env:featheresp32] ; 这是一个环境配置标签，指定了代码将运行的硬件平台和框架 platform = espressif32 ; 指定了使用的平台为Espressif 32 board = featheresp32 ; 指定使用的硬件板为Feather ESP32 framework = arduino ; 指定使用的框架为Arduino lib_deps = ; 列出所有依赖库的URL，这些库将被下载和安装 https://github.com/fishros/Esp32PcntEncoder.git ; ESP32 编码器驱动库 二、编写代码 编写代码 #include #include Esp32PcntEncoder encoders[2]; // 创建一个数组用于存储两个编码器 int64_t last_ticks[2]; // 记录上一次读取的计数器数值 int32_t pt[2]; // 记录两次读取之间的计数器差值 int64_t last_update_time; // 记录上一次更新时间 float speeds[2]; // 记录两个电机的速度 void setup() { // 1.初始化串口 Serial.begin(115200); // 初始化串口通信，设置通信速率为115200 // 2.设置编码器 encoders[0].init(0, 32, 33); // 初始化第一个编码器，使用GPIO 32和33连接 encoders[1].init(1, 26, 25); // 初始化第二个编码器，使用GPIO 26和25连接 // 3.让电机1以最大速度转起来 pinMode(23, OUTPUT); digitalWrite(23, HIGH); } void loop() { delay(10); // 等待10毫秒 // 4.计算两个电机的速度 uint64_t dt = millis() - last_update_time; // 计算两次读取之间的时间差 pt[0] = encoders[0].getTicks() - last_ticks[0]; // 计算第一个编码器两次读取之间的计数器差值 pt[1] = encoders[1].getTicks() - last_ticks[1]; // 计算第二个编码器两次读取之间的计数器差值 speeds[0] = float(pt[0] * 0.1051566) / dt; // 计算第一个电机的速度 speeds[1] = float(pt[1] * 0.1051566) / dt; // 计算第二个电机的速度 // 5.更新记录 last_update_time = millis(); // 更新上一次更新时间 last_ticks[0] = encoders[0].getTicks(); // 更新第一个编码器的计数器数值 last_ticks[1] = encoders[1].getTicks(); // 更新第二个编码器的计数器数值 // 6.打印信息 Serial.printf(\"tick1=%d,tick2=%d\\n\", encoders[0].getTicks(), encoders[1].getTicks()); // 打印两个编码器的计数器数值 Serial.printf(\"spped1=%f,spped2=%f\\n\", speeds[0], speeds[1]); // 打印两个电机的速度 } 在loop()函数中，首先等待10毫秒，然后读取两个编码器的计数器数值，并且计算出它们的旋转速度。 其中，last_ticks数组用于存储上一次读取的计数器数值，pt数组存储两次读取之间的计数器增量，last_update_time变量存储上一次读取的时间，speeds数组存储两个编码器的旋转速度。 最后，通过串口打印出两个编码器的计数器数值和旋转速度。此外，还让GPIO 23输出高电平，使电机1以最大速度转动。 三、下载测试 下载代码，观察串口打印 最大速度为-0.389079m/s。 四、总结 本节我们完成了对电机速度的测量，下一节我们尝试利用PID动态的控制电机保持在某个转速。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/009-控制速度-PID控制器实现.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/009-控制速度-PID控制器实现.html","title":"控制速度-PID控制器实现","keywords":"","body":"datetime:2023/11/01 10:06 author:nzb 该项目来源于大佬的动手学ROS2 10.控制速度-PID控制器实现 上一节我们通过编码器完成了对机器人单个轮子的速度测量，完成了电机速度闭环控制的重要一步-反馈。 有了反馈，接着我们需要设计一个控制器来帮助我们实现这个需求，这个控制器的输入是当前的速度和目标速度，输出是应该给到电机的PWM占空比。 一、PID控制器介绍 PID控制器是一种广泛应用于工业控制、自动化控制等领域的控制算法，其名称来源于“比例-积分-微分”三个控制器参数，即Proportional（比例）、Integral（积分）、Derivative（微分）。 PID控制器的基本原理是通过测量目标系统的反馈信号和期望输出信号之间的误差，根据一定的数学模型计算出控制信号，使目标系统能够稳定地达到期望输出。具体来说，PID控制器的计算公式为： \\text{Output} = K_p \\cdot \\text{Error} + K_i \\cdot \\int\\text{Error dt} + K_d \\cdot \\frac{\\text{d(Error)}}{\\text{dt}} 其中，Kp、Ki和Kd分别表示比例系数、积分系数和微分系数，Error表示目标系统的误差，Integral(Error)表示误差的积分，Derivative(Error)表示误差的微分。 在PID控制器中，比例系数、积分系数和微分系数的选取是关键，需要根据具体的控制需求进行调整。比例系数主要影响系统的响应速度和稳定性，积分系数主要影响系统的稳态误差，而微分系数主要影响系统的抗干扰性能。 说了理论你可能不是很理解，没关系，写完代码和调参后你感受就会变的深刻起来。 二、新建工程搭建框架 2.1 新建工程 example27_pid_controller 修改platformio.ini配置，添加开源库和microros配置 [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino board_microros_transport = wifi board_microros_distro = humble lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git https://github.com/fishros/Esp32McpwmMotor.git https://github.com/fishros/Esp32PcntEncoder.git 2.2 添加PidController 在lib下新建PidController文件夹，并在PidController下新建PidController.h和PidController.cpp 最终目录结构 . ├── include │ └── README ├── lib │ ├── PidController │ │ ├── PidController.cpp │ │ └── PidController.h │ └── README ├── platformio.ini ├── src │ └── main.cpp └── test └── README 5 directories, 7 files 2.3 复制并修改代码 将之前遥控车的代码复制粘贴到当前的main函数中，同时 添加PidController.h的头文件 删除原有的控制逻辑 添加电机速度测量函数 修改为双核通信 添加了一些注释 最终代码如下 #include #include // 包含用于 ESP32 的 micro-ROS PlatformIO 库 #include // 包含 ESP32 的 WiFi 库 #include // 包含 ROS 客户端库 (RCL) #include // 包含用于 C 的 ROS 客户端库 (RCLC) #include // 包含 RCLC 执行程序库，用于执行订阅和发布 #include // 包含 ROS2 geometry_msgs/Twist 消息类型 #include // 包含用于计数电机编码器脉冲的 ESP32 PCNT 编码器库 #include // 包含使用 ESP32 的 MCPWM 硬件模块控制 DC 电机的 ESP32 MCPWM 电机库 #include // 包含 PID 控制器库，用于实现 PID 控制 Esp32PcntEncoder encoders[2]; // 创建一个长度为 2 的 ESP32 PCNT 编码器数组 rclc_executor_t executor; // 创建一个 RCLC 执行程序对象，用于处理订阅和发布 rclc_support_t support; // 创建一个 RCLC 支持对象，用于管理 ROS2 上下文和节点 rcl_allocator_t allocator; // 创建一个 RCL 分配器对象，用于分配内存 rcl_node_t node; // 创建一个 RCL 节点对象，用于此基于 ESP32 的机器人小车 rcl_subscription_t subscriber; // 创建一个 RCL 订阅对象，用于订阅 ROS2 消息 geometry_msgs__msg__Twist sub_msg; // 创建一个 ROS2 geometry_msgs/Twist 消息对象 Esp32McpwmMotor motor; // 创建一个 ESP32 MCPWM 电机对象，用于控制 DC 电机 float out_motor_speed[2]; // 创建一个长度为 2 的浮点数数组，用于保存输出电机速度 float current_speeds[2]; // 创建一个长度为 2 的浮点数数组，用于保存当前电机速度 void twist_callback(const void *msg_in) { const geometry_msgs__msg__Twist *twist_msg = (const geometry_msgs__msg__Twist *)msg_in; float linear_x = twist_msg->linear.x; // 获取 Twist 消息的线性 x 分量 float angular_z = twist_msg->angular.z; // 获取 Twist 消息的角度 z 分量 if (linear_x == 0 && angular_z == 0) // 如果 Twist 消息没有速度命令 { motor.updateMotorSpeed(0, 0); // 停止第一个电机 motor.updateMotorSpeed(1, 0); // 停止第二个电机 return; // 退出函数 } } // 这个函数是一个后台任务，负责设置和处理与 micro-ROS 代理的通信。 void microros_task(void *param) { // 设置 micro-ROS 代理的 IP 地址。 IPAddress agent_ip; agent_ip.fromString(\"192.168.2.105\"); // 使用 WiFi 网络和代理 IP 设置 micro-ROS 传输层。 set_microros_wifi_transports(\"fishbot\", \"12345678\", agent_ip, 8888); // 等待 2 秒，以便网络连接得到建立。 delay(2000); // 设置 micro-ROS 支持结构、节点和订阅。 allocator = rcl_get_default_allocator(); rclc_support_init(&support, 0, NULL, &allocator); rclc_node_init_default(&node, \"esp32_car\", \"\", &support); rclc_subscription_init_default( &subscriber, &node, ROSIDL_GET_MSG_TYPE_SUPPORT(geometry_msgs, msg, Twist), \"/cmd_vel\"); // 设置 micro-ROS 执行器，并将订阅添加到其中。 rclc_executor_init(&executor, &support.context, 1, &allocator); rclc_executor_add_subscription(&executor, &subscriber, &sub_msg, &twist_callback, ON_NEW_DATA); // 循环运行 micro-ROS 执行器以处理传入的消息。 while (true) { delay(100); rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } } // 这个函数根据编码器读数更新两个轮子速度。 void update_speed() { // 初始化静态变量以存储上一次更新时间和编码器读数。 static uint64_t last_update_time = millis(); static int64_t last_ticks[2]; // 获取自上次更新以来的经过时间。 uint64_t dt = millis() - last_update_time; if (dt == 0) return; // 获取当前的编码器读数并计算当前的速度。 int32_t pt[2]; pt[0] = encoders[0].getTicks() - last_ticks[0]; pt[1] = encoders[1].getTicks() - last_ticks[1]; current_speeds[0] = float(pt[0] * 0.1051566) / dt * 1000; current_speeds[1] = float(pt[1] * 0.1051566) / dt * 1000; // 更新上一次更新时间和编码器读数。 last_update_time = millis(); last_ticks[0] = encoders[0].getTicks(); last_ticks[1] = encoders[1].getTicks(); } void setup() { // 初始化串口通信，波特率为115200 Serial.begin(115200); // 将两个电机分别连接到引脚22、23和12、13上 motor.attachMotor(0, 22, 23); motor.attachMotor(1, 12, 13); // 在引脚32、33和26、25上初始化两个编码器 encoders[0].init(0, 32, 33); encoders[1].init(1, 26, 25); // 在核心0上创建一个名为\"microros_task\"的任务，栈大小为10240 xTaskCreatePinnedToCore(microros_task, \"microros_task\", 10240, NULL, 1, NULL, 0); } void loop() { // 更新电机速度 update_speed(); // 更新电机0和电机1的速度值 motor.updateMotorSpeed(0, out_motor_speed[0]); motor.updateMotorSpeed(1, out_motor_speed[1]); // 延迟10毫秒 delay(10); } 三、PID控制器代码实现 接着我们来编写PidController.h和PidController.cpp。 3.1 PidController.h #ifndef __PIDCONTROLLER_H__ // 如果没有定义__PIDCONTROLLER_H__ #define __PIDCONTROLLER_H__ // 定义__PIDCONTROLLER_H__ class PidController { // 定义一个PID控制器类 public: PidController() = default; // 默认构造函数 PidController(float kp, float ki, float kd); // 构造函数，传入kp、ki、kd public: float target_; // 目标值 float out_mix_; // 输出下限 float out_max_; // 输出上限 float kp_; // 比例系数 float ki_; // 积分系数 float kd_; // 微分系数 float last_output_; // 上一次输出值 // pid float error_sum_; // 误差累积和 float derror_; // 误差变化率 float error_pre_; // 上上次误差 float error_last_; // 上一次误差 float intergral_up_ = 2500; // 积分上限 public: float update(float control); // 更新输出值 void reset(); // 重置PID控制器 void update_pid(float kp, float ki, float kd); // 更新PID系数 void update_target(float target); // 更新目标值 void out_limit(float out_mix, float out_max); // 输出限制 }; #endif // __PIDCONTROLLER_H__ // 结束条件 定义PidController，提供五个函数。 update(control): 传入当前控制量control并返回PID控制器的输出值 reset(): 将PID控制器的状态重置为初始状态 update_pid(kp, ki, kd): 更新PID控制系数 update_target(target): 更新目标值 out_limit(out_mix, out_max): 输出限制 3.2 PidController.cpp #include \"PidController.h\" #include \"Arduino.h\" PidController::PidController(float kp, float ki, float kd) { reset(); // 初始化控制器 update_pid(kp, ki, kd); // 更新PID参数 } float PidController::update(float control) { // 计算误差及其变化率 float error = target_ - control; // 计算误差 derror_ = error_last_ - error; // 计算误差变化率 error_last_ = error; // 计算积分项并进行积分限制 error_sum_ += error; if (error_sum_ > intergral_up_) error_sum_ = intergral_up_; if (error_sum_ out_max_) output = out_max_; if (output 上面这段代码是用于实现一个PID控制器的C++代码。PID控制器是一种常用的控制器，它的输入是控制系统的误差信号，输出是控制器的控制量。PID控制器由比例项、积分项和微分项三个部分组成，这三个部分的系数可以通过调节来实现控制器的性能优化。 以下是代码中各部分的注释： PidController::PidController(float kp, float ki, float kd)：PID控制器的构造函数，用于初始化控制器状态并更新PID参数。 void PidController::update_target(float target)：用于更新控制器的目标值。 void PidController::update_pid(float kp, float ki, float kd)：用于更新控制器的PID参数。 void PidController::out_limit(float out_mix, float out_max)：用于限制控制器的控制输出范围。 float PidController::update(float control)：控制器的核心函数，用于根据当前控制量计算出下一时刻的控制量。具体实现包括以下步骤： 计算误差及其变化率； 计算积分项并进行积分限制； 计算控制输出值，并进行输出限幅； 保存上一次的控制输出值。 void PidController::reset()：用于重置控制器的状态。包括重置PID参数、目标值、控制输出范围等状态变量。 在代码实现中，float代表浮点数类型，在C++中用于表示实数。kp_、ki_、kd_分别代表PID控制器中的比例项系数、积分项系数、微分项系数。target_代表控制器的目标值，out_mix_ 和out_max_用于限制控制器的控制输出范围。error_sum_代表误差累计值，derror_代表误差变化率，error_last_代表上一次的误差值。last_output_保存上一次的控制输出值。 四、修改主程序 #include #include // 包含用于 ESP32 的 micro-ROS PlatformIO 库 #include // 包含 ESP32 的 WiFi 库 #include // 包含 ROS 客户端库 (RCL) #include // 包含用于 C 的 ROS 客户端库 (RCLC) #include // 包含 RCLC 执行程序库，用于执行订阅和发布 #include // 包含 ROS2 geometry_msgs/Twist 消息类型 #include // 包含用于计数电机编码器脉冲的 ESP32 PCNT 编码器库 #include // 包含使用 ESP32 的 MCPWM 硬件模块控制 DC 电机的 ESP32 MCPWM 电机库 #include // 包含 PID 控制器库，用于实现 PID 控制 Esp32PcntEncoder encoders[2]; // 创建一个长度为 2 的 ESP32 PCNT 编码器数组 rclc_executor_t executor; // 创建一个 RCLC 执行程序对象，用于处理订阅和发布 rclc_support_t support; // 创建一个 RCLC 支持对象，用于管理 ROS2 上下文和节点 rcl_allocator_t allocator; // 创建一个 RCL 分配器对象，用于分配内存 rcl_node_t node; // 创建一个 RCL 节点对象，用于此基于 ESP32 的机器人小车 rcl_subscription_t subscriber; // 创建一个 RCL 订阅对象，用于订阅 ROS2 消息 geometry_msgs__msg__Twist sub_msg; // 创建一个 ROS2 geometry_msgs/Twist 消息对象 Esp32McpwmMotor motor; // 创建一个 ESP32 MCPWM 电机对象，用于控制 DC 电机 float out_motor_speed[2]; // 创建一个长度为 2 的浮点数数组，用于保存输出电机速度 float current_speeds[2]; // 创建一个长度为 2 的浮点数数组，用于保存当前电机速度 PidController pid_controller[2]; // 创建PidController的两个对象 void twist_callback(const void *msg_in) { const geometry_msgs__msg__Twist *twist_msg = (const geometry_msgs__msg__Twist *)msg_in; float linear_x = twist_msg->linear.x; // 获取 Twist 消息的线性 x 分量 float angular_z = twist_msg->angular.z; // 获取 Twist 消息的角度 z 分量 if (linear_x == 0 && angular_z == 0) // 如果 Twist 消息没有速度命令 { pid_controller[0].update_target(0); // 更新控制器的目标值 pid_controller[1].update_target(0); motor.updateMotorSpeed(0, 0); // 停止第一个电机 motor.updateMotorSpeed(1, 0); // 停止第二个电机 return; // 退出函数 } // 根据线速度和角速度控制两个电机的转速 if (linear_x != 0) { pid_controller[0].update_target(linear_x * 1000); // 使用mm/s作为target pid_controller[1].update_target(linear_x * 1000); } } // 这个函数是一个后台任务，负责设置和处理与 micro-ROS 代理的通信。 void microros_task(void *param) { // 设置 micro-ROS 代理的 IP 地址。 IPAddress agent_ip; agent_ip.fromString(\"192.168.2.105\"); // 使用 WiFi 网络和代理 IP 设置 micro-ROS 传输层。 set_microros_wifi_transports(\"fishbot\", \"12345678\", agent_ip, 8888); // 等待 2 秒，以便网络连接得到建立。 delay(2000); // 设置 micro-ROS 支持结构、节点和订阅。 allocator = rcl_get_default_allocator(); rclc_support_init(&support, 0, NULL, &allocator); rclc_node_init_default(&node, \"esp32_car\", \"\", &support); rclc_subscription_init_default( &subscriber, &node, ROSIDL_GET_MSG_TYPE_SUPPORT(geometry_msgs, msg, Twist), \"/cmd_vel\"); // 设置 micro-ROS 执行器，并将订阅添加到其中。 rclc_executor_init(&executor, &support.context, 1, &allocator); rclc_executor_add_subscription(&executor, &subscriber, &sub_msg, &twist_callback, ON_NEW_DATA); // 循环运行 micro-ROS 执行器以处理传入的消息。 while (true) { delay(100); rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } } // 这个函数根据编码器读数更新两个轮子速度。 void update_speed() { // 初始化静态变量以存储上一次更新时间和编码器读数。 static uint64_t last_update_time = millis(); static int64_t last_ticks[2]; // 获取自上次更新以来的经过时间。 uint64_t dt = millis() - last_update_time; if (dt == 0) return; // 获取当前的编码器读数并计算当前的速度。 int32_t pt[2]; pt[0] = encoders[0].getTicks() - last_ticks[0]; pt[1] = encoders[1].getTicks() - last_ticks[1]; current_speeds[0] = float(pt[0] * 0.1051566) / dt * 1000; current_speeds[1] = float(pt[1] * 0.1051566) / dt * 1000; // 更新上一次更新时间和编码器读数。 last_update_time = millis(); last_ticks[0] = encoders[0].getTicks(); last_ticks[1] = encoders[1].getTicks(); } void setup() { // 初始化串口通信，波特率为115200 Serial.begin(115200); // 将两个电机分别连接到引脚22、23和12、13上 motor.attachMotor(0, 22, 23); motor.attachMotor(1, 12, 13); // 在引脚32、33和26、25上初始化两个编码器 encoders[0].init(0, 32, 33); encoders[1].init(1, 26, 25); // 初始化PID控制器的kp、ki和kd pid_controller[0].update_pid(0.625, 0.125, 0.0); pid_controller[1].update_pid(0.625, 0.125, 0.0); // 初始化PID控制器的最大输入输出，MPCNT大小范围在正负100之间 pid_controller[0].out_limit(-100, 100); pid_controller[1].out_limit(-100, 100); // 在核心0上创建一个名为\"microros_task\"的任务，栈大小为10240 xTaskCreatePinnedToCore(microros_task, \"microros_task\", 10240, NULL, 1, NULL, 0); } void loop() { // 更新电机速度 update_speed(); // 计算最新的电机输出值 out_motor_speed[0] = pid_controller[0].update(current_speeds[0]); out_motor_speed[1] = pid_controller[1].update(current_speeds[1]); // 更新电机0和电机1的速度值 motor.updateMotorSpeed(0, out_motor_speed[0]); motor.updateMotorSpeed(1, out_motor_speed[1]); // 延迟10毫秒 delay(10); } 添加PidController控制器到main函数中，关于Pid控制器的kp、ki和kd的设置，这里直接使用了比较合适的0.625和0.125，对于KD并没有设置，接下来我们下载代码进去并修改下PID进行测试。 需要注意：你要修改网络参数为你的当前环境的网络参数。 五、下载测试 下载代码，运行agent，点击RST按键。 sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 看到连接建立表示通信成功，接着用ros2 topic list ros2 topic list 看到/cmd_vel表示正常，接着我们使用teleop_twist_keyboard进行键盘控制 ros2 run teleop_twist_keyboard teleop_twist_keyboard 把速度修改为0.10左右，接着把小车放到地上，点击键盘上的i，记时10s之后点击k或者控制让机器人停下来，接着看看机器人行走距离是不是1m。 测试结果 六、PID调节实验 请自行修改PID参数进行测试，注意结合理论进行。 参数整定找最佳，从小到大顺序查； 先是比例后积分，最后再把微分加； 曲线振荡很频繁，比例度盘要放大； 曲线漂浮绕大湾，比例度盘往小扳； 曲线偏离回复慢，积分时间往下降； 曲线波动周期长，积分时间再加长； 曲线振荡频率快，先把微分降下来； 动差大来波动慢。微分时间应加长； 理想曲线两个波，前高后低四比一； 一看二调多分析，调节质量不会低； 七、总结 本节我们完成了PID控制器对两个电机速度的控制，但是仅限于前进和后退，如果想实现角速度的控制，我们还要结合两轮差速运动学模型才行。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/010-两轮差速运动学正逆解.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/010-两轮差速运动学正逆解.html","title":"两轮差速运动学正逆解","keywords":"","body":"datetime:2023/11/02 10:06 author:nzb 该项目来源于大佬的动手学ROS2 11.两轮差速机器人运动学介绍 一、两轮差速运动学模型 两轮差速模型指机器人底盘由两个驱动轮和若干支撑轮构成的底盘模型，像turtlebot和开源机器人fishbot都是两轮差速模型。 两轮差速模型通过两个驱动轮可以通过不同转速和转向，使得机器人的达到某个特定的角速度和线速度。 二、正逆解 了解了两轮差速模型，那正逆解又是怎么回事？ 正运动学：已知两个轮子的速度，求整车的角速度（弧度/秒）和线速度（米/秒） graph LR; A[左轮当前速度]-->B[正运动学]-->C[机器人当前角速度] D[右轮当前速度]-->B B-->E[机器人当前线速度] 逆运动学：已知目标角速度和线速度，求两个轮子的转速 graph LR; A[机器人目标线速度]-->C[运动学逆解] B[机器人目标角速度]-->C C-->D[左轮目标速度] C-->E[右轮目标速度] 三、轮式里程计 graph LR; A[左右轮当前速度/位置]-->B[里程计推算] B-->C[里程计-odom] 当我们知道了两个轮子之间的相对位置，同时知道了每一时刻机器人的角速度和线速度，那我们如何获取机器人的当前角度和位置呢？ 3.1 角度 影响机器人当前角度的因素只有一个，就是角速度。 某一时刻机器人转动的角度 = 这一时刻机器人的角速度*这一时刻时长 假如我们认定初始时刻机器人的角度为0,通过对机器人转动角度角度进行累加，即可获得机器人的当前角度。 上述过程其实就是对角速度进行积分得到角度。 3.2 位置 通过对角速度积分，我们得到了角度。 机器人某一时刻自身方向上的前进速度可以分解为里程计坐标系中x轴和y轴方向上的速度。 从图中可以看出： v_y = v*cos(\\theta) \\\\ v_y = v*sin(\\theta) 得到了x和y方向上的速度，乘上该速度对应的某一时刻经过的时间，即可得到这一时刻在x轴和y轴方向上的位移，对位移进行累加即可得到里程计中的x和y。 12. 实时速度计算-运动学正解 上一节了解了两轮差速运动学，本节我们线进一步的了解两轮差速正运动学的推导过程，并利用两轮差速运动学正解，来完成对小车的实时速度计算。 graph LR; A[左轮当前速度]-->B[正运动学]-->C[机器人当前角速度] D[右轮当前速度]-->B B-->E[机器人当前线速度] 一、正运动学解推导 两轮差速机器人是一种常见的移动机器人类型，由两个轮子和一个中心点组成。我们可以通过控制每个轮子的转速来实现移动，并且可以在一个平面上进行自由移动。 前面章节我们通过PID+编码器完成了FishBot底盘两个轮子单独速度的测量，但是在实际使用当中，我们把机器人当作一个整体来看，而对于这样一个整体在空间中的速度，我们一般采用X轴线速度 v 和Z轴角速度 \\omega 来描述。 需要注意的是：在ROS中，机器人的前方通常指的是机器人本体坐标系的正方向。本体坐标系是相对于机器人自身的一个坐标系，通常定义在机器人的中心位置，以机器人的前进方向为X轴，左侧为Y轴，垂直于机器人平面的方向为Z轴。 而全局坐标系中的正方向X轴指向右方，Y轴指向前方，Z轴垂直于地面。 X Y Z 机器人本体坐标系 前方 左侧 垂直于机器人平面 全局坐标系 右方 前方 垂直于地面 所以问题就变成了假设机器人在一小段时间t内，它的左右轮子线速度v_l和v_r保持不变 ，两轮之间的安装间距 l ，求机器人的线速度v ，角速度\\omega。 我们看上图来推导 因为机器人的线速度方向和轮子转动方向始终保持一致，所以机器人的线速度为做右轮线速度的平均值，即： v=(v_l+v_r)/2 我们知道 v=\\omega * r 根据上图所以有 l = r_r-r_l \\\\ = v_r/{\\omega}_r - v_l/{\\omega}_l \\\\ 同一个机器人角速度相同，所以有 {\\omega}_l = {\\omega}_r 可以求出 {\\omega} = (v_r-v_l)/l 二、正运动学代码实现 2.1 新建工程 从本节开始我们持续的在一个工程上进行开发，推荐大家建立代码仓库，并将代码用git进行管理起来。 在PlatformIO上新建fishbot_motion_control_microros工程。 添加依赖 [env:featheresp32] platform = espressif32 board = featheresp32 framework = arduino board_microros_transport = wifi board_microros_distro = humble board_build.f_cpu = 240000000L board_build.f_flash = 80000000L monitor_speed = 115200 lib_deps = https://gitee.com/ohhuo/micro_ros_platformio.git https://github.com/fishros/Esp32McpwmMotor.git https://github.com/fishros/Esp32PcntEncoder.git 接着将前面章节中pid_controller样例程序的lib下的内容和main.cpp内容复制过来，最终就目录结构如下： . ├── include │ └── README ├── lib │ ├── PidController │ │ ├── PidController.cpp │ │ └── PidController.h │ └── README ├── LICENSE ├── platformio.ini ├── src │ └── main.cpp └── test ├── my_main.cpp ├── README 2.2 添加Kinematic库 在lib下添加Kinematics文件夹，并添加Kinematics.h和Kinematics.cpp文件。 编写Kinematics.h /** * @file Kinematics.h * @author fishros@foxmail.com * @brief 机器人模型设置,编码器轮速转换,ODOM推算,线速度角速度分解 * @version V1.0.0 * @date 2022-12-10 * * @copyright Copyright www.fishros.com (c) 2022 * */ #ifndef __KINEMATICS_H__ #define __KINEMATICS_H__ #include typedef struct { uint8_t id; // 电机编号 uint16_t reducation_ratio; // 减速器减速比，轮子转一圈，电机需要转的圈数 uint16_t pulse_ration; // 脉冲比，电机转一圈所产生的脉冲数 float wheel_diameter; // 轮子的外直径，单位mm float per_pulse_distance; // 无需配置，单个脉冲轮子前进的距离，单位mm，设置时自动计算 // 单个脉冲距离=轮子转一圈所行进的距离/轮子转一圈所产生的脉冲数 // per_pulse_distance= (wheel_diameter*3.1415926)/(pulse_ration*reducation_ratio) uint32_t speed_factor; // 无需配置，计算速度时使用的速度因子，设置时自动计算，speed_factor计算方式如下 // 设 dt（单位us,1s=1000ms=10^6us）时间内的脉冲数为dtick // 速度speed = per_pulse_distance*dtick/(dt/1000/1000)=(per_pulse_distance*1000*1000)*dtick/dt // 记 speed_factor = (per_pulse_distance*1000*1000) int16_t motor_speed; // 无需配置，当前电机速度mm/s，计算时使用 int64_t last_encoder_tick; // 无需配置，上次电机的编码器读数 uint64_t last_update_time; // 无需配置，上次更新数据的时间，单位us } motor_param_t; class Kinematics { private: motor_param_t motor_param_[2]; float wheel_distance_; // 轮子间距 public: Kinematics(/* args */) = default; ~Kinematics() = default; /** * @brief 设置电机相关参数 * * @param id * @param reducation_ratio * @param pulse_ration * @param wheel_diameter */ void set_motor_param(uint8_t id, uint16_t reducation_ratio, uint16_t pulse_ration, float wheel_diameter); /** * @brief 设置运动学相关参数 * * @param wheel_distance */ void set_kinematic_param(float wheel_distance); /** * @brief 运动学逆解，输入机器人当前线速度和角速度，输出左右轮子应该达到的目标速度 * * @param line_speed * @param angle_speed * @param out_wheel1_speed * @param out_wheel2_speed */ void kinematic_inverse(float line_speed, float angle_speed, float &out_wheel1_speed, float &out_wheel2_speed); /** * @brief 运动学正解，输入左右轮子速度，输出机器人当前线速度和角速度 * * @param wheel1_speed * @param wheel2_speed * @param line_speed * @param angle_speed */ void kinematic_forward(float wheel1_speed, float wheel2_speed, float &line_speed, float &angle_speed); /** * @brief 更新轮子的tick数据 * * @param current_time * @param motor_tick1 * @param motor_tick2 */ void update_motor_ticks(uint64_t current_time, int32_t motor_tick1, int32_t motor_tick2); /** * @brief 获取轮子当前速度 * * @param id * @return float */ float motor_speed(uint8_t id); }; #endif // __KINEMATICS_H__ 这里主要定义了一个电机参数结构体，并定义了一个类，该类包含以下6个函数 函数名称 描述 set_motor_param() 设置电机相关参数 set_kinematic_param() 设置运动学相关参数 kinematic_inverse() 运动学逆解，输入机器人当前线速度和角速度，输出左右轮子应该达到的目标速度 kinematic_forward() 运动学正解，输入左右轮子速度，输出机器人当前线速度和角速度 update_motor_ticks() 更新轮子的tick数据 motor_speed() 获取轮子当前速度 2.3 Kinematics.cpp代码实现 #include \"Kinematics.h\" void Kinematics::set_motor_param(uint8_t id, uint16_t reducation_ratio, uint16_t pulse_ration, float wheel_diameter) { motor_param_[id].id = id; // 设置电机ID motor_param_[id].reducation_ratio = reducation_ratio; // 设置减速比 motor_param_[id].pulse_ration = pulse_ration; // 设置脉冲比 motor_param_[id].wheel_diameter = wheel_diameter; // 设置车轮直径 motor_param_[id].per_pulse_distance = (wheel_diameter * PI) / (reducation_ratio * pulse_ration); // 每个脉冲对应行驶距离 motor_param_[id].speed_factor = (1000 * 1000) * (wheel_diameter * PI) / (reducation_ratio * pulse_ration); // 计算速度因子 Serial.printf(\"init motor param %d: %f=%f*PI/(%d*%d) speed_factor=%d\\n\", id, motor_param_[id].per_pulse_distance, wheel_diameter, reducation_ratio, pulse_ration, motor_param_[id].speed_factor); // 打印调试信息 } void Kinematics::set_kinematic_param(float wheel_distance) { wheel_distance_ = wheel_distance; // 设置轮间距离 } void Kinematics::update_motor_ticks(uint64_t current_time, int32_t motor_tick1, int32_t motor_tick2) { uint32_t dt = current_time - motor_param_[0].last_update_time; // 计算时间差 int32_t dtick1 = motor_tick1 - motor_param_[0].last_encoder_tick; // 计算电机1脉冲差 int32_t dtick2 = motor_tick2 - motor_param_[1].last_encoder_tick; // 计算电机2脉冲差 // 轮子速度计算 motor_param_[0].motor_speed = dtick1 * (motor_param_[0].speed_factor / dt); // 计算电机1轮子速度 motor_param_[1].motor_speed = dtick2 * (motor_param_[1].speed_factor / dt); // 计算电机2轮子速度 motor_param_[0].last_encoder_tick = motor_tick1; // 更新电机1上一次的脉冲计数 motor_param_[1].last_encoder_tick = motor_tick2; // 更新电机2上一次的脉冲计数 motor_param_[0].last_update_time = current_time; // 更新电机1上一次更新时间 motor_param_[1].last_update_time = current_time; // 更新电机2上一次更新时间 } void Kinematics::kinematic_inverse(float linear_speed, float angular_speed, float &out_wheel1_speed, float &out_wheel2_speed) { } void Kinematics::kinematic_forward(float wheel1_speed, float wheel2_speed, float &linear_speed, float &angular_speed) { linear_speed = (wheel1_speed + wheel2_speed) / 2.0; // 计算线速度 angular_speed = (wheel2_speed - wheel1_speed) / wheel_distance_; // 计算角速度 } float Kinematics::motor_speed(uint8_t id) { return motor_param_[id].motor_speed; // 返回指定id的轮子速度 } 2.4 修改main.cpp #include #include // 包含用于 ESP32 的 micro-ROS PlatformIO 库 #include // 包含 ESP32 的 WiFi 库 #include // 包含 ROS 客户端库 (RCL) #include // 包含用于 C 的 ROS 客户端库 (RCLC) #include // 包含 RCLC 执行程序库，用于执行订阅和发布 #include // 包含 ROS2 geometry_msgs/Twist 消息类型 #include // 包含用于计数电机编码器脉冲的 ESP32 PCNT 编码器库 #include // 包含使用 ESP32 的 MCPWM 硬件模块控制 DC 电机的 ESP32 MCPWM 电机库 #include // 包含 PID 控制器库，用于实现 PID 控制 #include // 运动学相关实现 Esp32PcntEncoder encoders[2]; // 创建一个长度为 2 的 ESP32 PCNT 编码器数组 rclc_executor_t executor; // 创建一个 RCLC 执行程序对象，用于处理订阅和发布 rclc_support_t support; // 创建一个 RCLC 支持对象，用于管理 ROS2 上下文和节点 rcl_allocator_t allocator; // 创建一个 RCL 分配器对象，用于分配内存 rcl_node_t node; // 创建一个 RCL 节点对象，用于此基于 ESP32 的机器人小车 rcl_subscription_t subscriber; // 创建一个 RCL 订阅对象，用于订阅 ROS2 消息 geometry_msgs__msg__Twist sub_msg; // 创建一个 ROS2 geometry_msgs/Twist 消息对象 Esp32McpwmMotor motor; // 创建一个 ESP32 MCPWM 电机对象，用于控制 DC 电机 float out_motor_speed[2]; // 创建一个长度为 2 的浮点数数组，用于保存输出电机速度 PidController pid_controller[2]; // 创建PidController的两个对象 Kinematics kinematics; // 运动学相关对象 void twist_callback(const void *msg_in) { const geometry_msgs__msg__Twist *twist_msg = (const geometry_msgs__msg__Twist *)msg_in; static float target_motor_speed1, target_motor_speed2; float linear_x = twist_msg->linear.x; // 获取 Twist 消息的线性 x 分量 float angular_z = twist_msg->angular.z; // 获取 Twist 消息的角度 z 分量 kinematics.kinematic_inverse(linear_x * 1000, angular_z, target_motor_speed1, target_motor_speed2); pid_controller[0].update_target(target_motor_speed1); pid_controller[1].update_target(target_motor_speed2); } // 这个函数是一个后台任务，负责设置和处理与 micro-ROS 代理的通信。 void microros_task(void *param) { // 设置 micro-ROS 代理的 IP 地址。 IPAddress agent_ip; agent_ip.fromString(\"192.168.2.105\"); // 使用 WiFi 网络和代理 IP 设置 micro-ROS 传输层。 set_microros_wifi_transports(\"fishbot\", \"12345678\", agent_ip, 8888); // 等待 2 秒，以便网络连接得到建立。 delay(2000); // 设置 micro-ROS 支持结构、节点和订阅。 allocator = rcl_get_default_allocator(); rclc_support_init(&support, 0, NULL, &allocator); rclc_node_init_default(&node, \"esp32_car\", \"\", &support); rclc_subscription_init_default( &subscriber, &node, ROSIDL_GET_MSG_TYPE_SUPPORT(geometry_msgs, msg, Twist), \"/cmd_vel\"); // 设置 micro-ROS 执行器，并将订阅添加到其中。 rclc_executor_init(&executor, &support.context, 1, &allocator); rclc_executor_add_subscription(&executor, &subscriber, &sub_msg, &twist_callback, ON_NEW_DATA); // 循环运行 micro-ROS 执行器以处理传入的消息。 while (true) { delay(100); rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } } void setup() { // 初始化串口通信，波特率为115200 Serial.begin(115200); // 将两个电机分别连接到引脚22、23和12、13上 motor.attachMotor(0, 22, 23); motor.attachMotor(1, 12, 13); // 在引脚32、33和26、25上初始化两个编码器 encoders[0].init(0, 32, 33); encoders[1].init(1, 26, 25); // 初始化PID控制器的kp、ki和kd pid_controller[0].update_pid(0.625, 0.125, 0.0); pid_controller[1].update_pid(0.625, 0.125, 0.0); // 初始化PID控制器的最大输入输出，MPCNT大小范围在正负100之间 pid_controller[0].out_limit(-100, 100); pid_controller[1].out_limit(-100, 100); // 设置运动学参数 kinematics.set_motor_param(0, 45, 44, 65); kinematics.set_motor_param(1, 45, 44, 65); kinematics.set_kinematic_param(150); // 在核心0上创建一个名为\"microros_task\"的任务，栈大小为10240 xTaskCreatePinnedToCore(microros_task, \"microros_task\", 10240, NULL, 1, NULL, 0); } void loop() { static float out_motor_speed[2]; static uint64_t last_update_info_time = millis(); kinematics.update_motor_ticks(micros(), encoders[0].getTicks(), encoders[1].getTicks()); out_motor_speed[0] = pid_controller[0].update(kinematics.motor_speed(0)); out_motor_speed[1] = pid_controller[1].update(kinematics.motor_speed(1)); motor.updateMotorSpeed(0, out_motor_speed[0]); motor.updateMotorSpeed(1, out_motor_speed[1]); // 延迟10毫秒 delay(10); } 这里主要调用Kinematic完成相关函数的调用。 主要有下面几行 // 初始化运动学相关对象 Kinematics kinematics; // 设置运动学参数 kinematics.set_motor_param(0, 45, 44, 65); kinematics.set_motor_param(1, 45, 44, 65); kinematics.set_kinematic_param(150); // 更新电机速度 kinematics.update_motor_ticks(micros(), encoders[0].getTicks(), encoders[1].getTicks()); // 运动学逆解 kinematics.kinematic_inverse(linear_x * 1000, angular_z, target_motor_speed1, target_motor_speed2); 三、上传测试 下载代码，运行agent，点击RST按键。 sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 看到连接建立表示通信成功，接着用ros2 topic list ros2 topic list 看到/cmd_vel表示正常，接着我们使用teleop_twist_keyboard进行键盘控制 ros2 run teleop_twist_keyboard teleop_twist_keyboard 随便发送一个指令，打开串口，观察打印 速度一直在20左右徘徊，和我们设置的速度相同。 void Kinematics::kinematic_inverse(float linear_speed, float angular_speed, float &out_wheel1_speed, float &out_wheel2_speed) { // 直接返回指定速度20mm/s out_wheel1_speed = 20; out_wheel2_speed = 20; } 四、扩展-Git初体验 4.1 Git使用简介 安装 Git：如果你的系统中没有 Git，可以通过以下命令进行安装： sudo apt update sudo apt install git 配置 Git：在使用 Git 之前，你需要设置用户名和邮箱地址，这样 Git 才能正确地记录你的提交信息。使用以下命令配置 Git： arduino git config --global user.name \"Your Name\" git config --global user.email \"youremail@example.com\" 将 \"Your Name\" 替换为你的姓名，\"youremail@example.com\" 替换为你的邮箱地址。 创建一个 Git 仓库：如果你要将一个现有的项目纳入 Git 的版本控制下，可以使用以下命令将其转化为一个 Git 仓库： cd /path/to/your/project git init 将文件添加到 Git 仓库：使用以下命令将文件添加到 Git 仓库： git add filename 其中，\"filename\" 是要添加到 Git 仓库中的文件名。如果你要将所有文件添加到 Git 仓库中，可以使用以下命令： git add . 提交更改：使用以下命令将文件的更改提交到 Git 仓库中： git commit -m \"commit message\" 其中，\"commit message\" 是提交信息，需要用简短的文字描述本次提交的更改内容。 4.2 提交本节代码 根据上面的介绍我们可以使用git来将这一节的代码保存 安装 sudo apt install git 初始化仓库，配置邮箱和用户名 cd fishbot_motion_control_microros git init 提交本次所有代码 git add . git commit -m \"feat(16.12):完成运动学正解\" git log 13.目标速度控制-运动学逆解 上一节我们推导并在代码中实现了运动学正解，本节我们来学习下运动学逆解，实现给定线速度和角速度，计算出轮子达到怎样的转速才能达到这个速度。 graph LR; A[机器人目标线速度]-->C[运动学逆解] B[机器人目标角速度]-->C C-->D[左轮目标速度] C-->E[右轮目标速度] 一、逆解推导 我们直接用正解结果进行求逆解即可。 v=(v_l+v_r)/2 \\\\ {\\omega} = (v_r-v_l)/l 所以有 v_l = v-\\omega l/2 \\\\ v_r = v+\\omega l/2 二、编写代码 继续在上一节中的代码Kinematics.cpp中完善即可。 void Kinematics::kinematic_inverse(float linear_speed, float angular_speed, float &out_wheel1_speed, float &out_wheel2_speed) { out_wheel1_speed = linear_speed - (angular_speed * wheel_distance_) / 2.0; out_wheel2_speed = linear_speed + (angular_speed * wheel_distance_) / 2.0; } 三、下载测试 下载代码，运行agent，点击RST按键。 sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 看到连接建立表示通信成功，接着用ros2 topic list ros2 topic list 看到/cmd_vel表示正常，接着我们使用teleop_twist_keyboard进行键盘控制 ros2 run teleop_twist_keyboard teleop_twist_keyboard 先调整下速度，降低到0.05左右（50cm/s），然后使用i\\j\\j\\k\\,测试。 四、总结 没啥好说的，记得提交下代码 git commit -m \"feat(13.13):完成运动学逆解\" 代码提交也是有规范的，我们一起来学习下：https://fishros.org.cn/forum/topic/390 我们采用用的比较多的Angular 规范 git commit -m \"(): \" 其中 type（必选）、scope（可选）和 subject（必选） Type feat：新功能（feature）。 fix/to：修复bug，可以是QA发现的BUG，也可以是研发自己发现的BUG。 fix：产生diff并自动修复此问题。适合于一次提交直接修复问题 to：只产生diff不自动修复此问题。适合于多次提交。最终修复问题提交时使用fix docs：文档（documentation）。 style：格式（不影响代码运行的变动）。 refactor：重构（即不是新增功能，也不是修改bug的代码变动）。 perf：优化相关，比如提升性能、体验。 test：增加测试。 chore：构建过程或辅助工具的变动。 revert：回滚到上一个版本。 merge：代码合并。 sync：同步主线或分支的Bug。 scope(可选) scope用于说明 commit 影响的范围，比如电机控制层、通信层等等，视项目不同而不同。 例如在FishBot嵌入式中，可以是motors，uart等。如果你的修改影响了不止一个scope，你可以使用*代替。 subject(必选) subject是commit目的的简短描述，不超过50个字符。 结尾不加句号或其他标点符号。 举个例子 给FishBot增加了oled支持 git commit -m \"feat(13.13):完成运动学逆解\" "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/011-里程计计算-速度积分.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/011-里程计计算-速度积分.html","title":"里程计计算-速度积分","keywords":"","body":"datetime:2023/11/02 10:06 author:nzb 该项目来源于大佬的动手学ROS2 14.里程计计算-速度积分 前面两节中我们完成机器人底盘正逆解的计算，我们通过机器人的运动学逆解完成了机器人实时的角速度和线速度的测量，那我们能不能利用对线速度和角速度的积分，计算机器人当前的位置呢？答案肯定是可以的，那么本节我们就来编写代码实现机器人的里程计。 一、里程计计算原理 在某一个时间段t中，机器人的线速度为v_t ，角速度为w_t ，机器人在初始时刻的位置为 x_t,y_t 朝向为 \\theta _t ,求经过t时刻是机器人新的位置和朝向，这一过程中假设机器人仅在平面上运动。 在这一段时间内机器人前进的距离为d d = v_t*t 转过的角度为 \\theta \\theta =\\omega _t*t 则机器人新的角度为 \\theta _{t+1} \\theta _{t+1} = \\theta _{t}+\\theta 我们将机器人前进的距离根据其朝向分解为在x和y轴上的位移量，则可得出 x_{t+1} = x_t + d*cos(\\theta_{t+1}) \\\\ y_{t+1} = y_t + d*sos(\\theta_{t+1}) 有了公式，我们开始撸代码。 二、编写代码 先修改Kinematics.h头文件，增加角度范围限制，里程计更新和里程计结构体定义，完成后代码如下： /** * @file Kinematics.h * @author fishros@foxmail.com * @brief 机器人模型设置,编码器轮速转换,ODOM推算,线速度角速度分解 * @version V1.0.0 * @date 2022-12-10 * * @copyright Copyright www.fishros.com (c) 2022 * */ #ifndef __KINEMATICS_H__ #define __KINEMATICS_H__ #include typedef struct { uint8_t id; // 电机编号 uint16_t reducation_ratio; // 减速器减速比，轮子转一圈，电机需要转的圈数 uint16_t pulse_ration; // 脉冲比，电机转一圈所产生的脉冲数 float wheel_diameter; // 轮子的外直径，单位mm float per_pulse_distance; // 无需配置，单个脉冲轮子前进的距离，单位mm，设置时自动计算 // 单个脉冲距离=轮子转一圈所行进的距离/轮子转一圈所产生的脉冲数 // per_pulse_distance= (wheel_diameter*3.1415926)/(pulse_ration*reducation_ratio) uint32_t speed_factor; // 无需配置，计算速度时使用的速度因子，设置时自动计算，speed_factor计算方式如下 // 设 dt（单位us,1s=1000ms=10^6us）时间内的脉冲数为dtick // 速度speed = per_pulse_distance*dtick/(dt/1000/1000)=(per_pulse_distance*1000*1000)*dtic/dt // 记 speed_factor = (per_pulse_distance*1000*1000) int16_t motor_speed; // 无需配置，当前电机速度mm/s，计算时使用 int64_t last_encoder_tick; // 无需配置，上次电机的编码器读数 uint64_t last_update_time; // 无需配置，上次更新数据的时间，单位us } motor_param_t; /** * @brief 里程计相关信息，根据轮子速度信息和运动模型推算而来 * */ typedef struct { float x; // 坐标x float y; // 坐标y float yaw; // yaw float linear_speed; // 线速度 float angular_speed; // 角速度 } odom_t; class Kinematics { private: motor_param_t motor_param_[2]; float wheel_distance_; // 轮子间距 odom_t odom_; // 里程计数据 public: Kinematics(/* args */) = default; ~Kinematics() = default; static void TransAngleInPI(float angle,float& out_angle); /** * @brief 设置电机相关参数 * * @param id * @param reducation_ratio * @param pulse_ration * @param wheel_diameter */ void set_motor_param(uint8_t id, uint16_t reducation_ratio, uint16_t pulse_ration, float wheel_diameter); /** * @brief 设置运动学相关参数 * * @param wheel_distance */ void set_kinematic_param(float wheel_distance); /** * @brief 运动学逆解，输入机器人当前线速度和角速度，输出左右轮子应该达到的目标速度 * * @param line_speed * @param angle_speed * @param out_wheel1_speed * @param out_wheel2_speed */ void kinematic_inverse(float line_speed, float angle_speed, float &out_wheel1_speed, float &out_wheel2_speed); /** * @brief 运动学正解，输入左右轮子速度，输出机器人当前线速度和角速度 * * @param wheel1_speed * @param wheel2_speed * @param line_speed * @param angle_speed */ void kinematic_forward(float wheel1_speed, float wheel2_speed, float &line_speed, float &angle_speed); /** * @brief 更新轮子的tick数据 * * @param current_time * @param motor_tick1 * @param motor_tick2 */ void update_motor_ticks(uint64_t current_time, int32_t motor_tick1, int32_t motor_tick2); /** * @brief 获取轮子当前速度 * * @param id * @return float */ float motor_speed(uint8_t id); /** * @brief 更新机器人里程计信息 * * @param dt 间隔时间dt */ void update_bot_odom(uint32_t dt); /** * @brief 获取里程计函数 * * @return odom_t& */ odom_t &odom(); }; #endif // __KINEMATICS_H__ 接着在Kinematics.cpp中实现刚刚定义的函数，主要添加函数代码如下： void Kinematics::update_bot_odom(uint32_t dt) { static float linear_speed, angular_speed; float dt_s = (float)(dt / 1000) / 1000; this->kinematic_forward(motor_param_[0].motor_speed, motor_param_[1].motor_speed, linear_speed, angular_speed); odom_.angular_speed = angular_speed; odom_.linear_speed = linear_speed / 1000; // /1000（mm/s 转 m/s） odom_.yaw += odom_.angular_speed * dt_s; Kinematics::TransAngleInPI(odom_.yaw, odom_.yaw); /*更新x和y轴上移动的距离*/ float delta_distance = odom_.linear_speed * dt_s; // 单位m odom_.x += delta_distance * std::cos(odom_.yaw); odom_.y += delta_distance * std::sin(odom_.yaw); } void Kinematics::TransAngleInPI(float angle, float &out_angle) { if (angle > PI) { out_angle -= 2 * PI; } else if (angle 同时修改update_motor_ticks函数，在其中添加update_bot_odom。 void Kinematics::update_motor_ticks(uint64_t current_time, int32_t motor_tick1, int32_t motor_tick2) { uint32_t dt = current_time - motor_param_[0].last_update_time; // 计算时间差 int32_t dtick1 = motor_tick1 - motor_param_[0].last_encoder_tick; // 计算电机1脉冲差 int32_t dtick2 = motor_tick2 - motor_param_[1].last_encoder_tick; // 计算电机2脉冲差 // 轮子速度计算 motor_param_[0].motor_speed = dtick1 * (motor_param_[0].speed_factor / dt); // 计算电机1轮子速度 motor_param_[1].motor_speed = dtick2 * (motor_param_[1].speed_factor / dt); // 计算电机2轮子速度 motor_param_[0].last_encoder_tick = motor_tick1; // 更新电机1上一次的脉冲计数 motor_param_[1].last_encoder_tick = motor_tick2; // 更新电机2上一次的脉冲计数 motor_param_[0].last_update_time = current_time; // 更新电机1上一次更新时间 motor_param_[1].last_update_time = current_time; // 更新电机2上一次更新时间 // 更新机器人里程计 this->update_bot_odom(dt); } 修改main.cpp中加入打印里程计数据 void loop() { static float out_motor_speed[2]; static uint64_t last_update_info_time = millis(); kinematics.update_motor_ticks(micros(), encoders[0].getTicks(), encoders[1].getTicks()); out_motor_speed[0] = pid_controller[0].update(kinematics.motor_speed(0)); out_motor_speed[1] = pid_controller[1].update(kinematics.motor_speed(1)); motor.updateMotorSpeed(0, out_motor_speed[0]); motor.updateMotorSpeed(1, out_motor_speed[1]); unsigned long currentMillis = millis(); // 获取当前时间 if (currentMillis - previousMillis >= interval) { // 判断是否到达间隔时间 previousMillis = currentMillis; // 记录上一次打印的时间 float linear_speed, angle_speed; kinematics.kinematic_forward(kinematics.motor_speed(0), kinematics.motor_speed(1), linear_speed, angle_speed); Serial.printf(\"[%ld] linear:%f angle:%f\\n\", currentMillis, linear_speed, angle_speed); // 打印当前时间 Serial.printf(\"[%ld] x:%f y:%f yaml:%f\\n\", currentMillis,kinematics.odom().x, kinematics.odom().y, kinematics.odom().yaw); // 打印当前时间 } // 延迟10毫秒 delay(10); } 三、下载测试 下载代码，运行agent，点击RST按键。 sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 看到连接建立表示通信成功，接着用ros2 topic list ros2 topic list 看到/cmd_vel表示正常，接着我们使用teleop_twist_keyboard进行键盘控制 ros2 run teleop_twist_keyboard teleop_twist_keyboard 先调整下速度，降低到0.05左右（50cm/s），然后使用i\\j\\j\\k\\,测试。 可以先让机器人空转，点击i，让机器人前进用串口查看数据变化。 可以看到每次大约增加0.5左右，数据正常。 四、总结 最后记得提交代码 git add . git commit -m \"feat(13.14):完成里程计计算-速度积分\" "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/012-采用MicroROS发布里程计.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/012-采用MicroROS发布里程计.html","title":"采用MicroROS发布里程计","keywords":"","body":"datetime:2023/11/03 10:52 author:nzb 该项目来源于大佬的动手学ROS2 15.采用MicroROS发布里程计 获得了里程计数据后，下一步就是将里程计通过MicroROS话题发布到ROS 2 系统中。 一、了解接口 在 ROS 2 已有的消息接口中： nav_msgs/msg/Odometry 用于表示里程计数据，该接口内容如下： ros2 interface show nav_msgs/msg/Odometry --- # This represents an estimate of a position and velocity in free space. # The pose in this message should be specified in the coordinate frame given by header.frame_id # The twist in this message should be specified in the coordinate frame given by the child_frame_id # Includes the frame id of the pose parent. std_msgs/Header header builtin_interfaces/Time stamp int32 sec uint32 nanosec string frame_id # Frame id the pose points to. The twist is in this coordinate frame. string child_frame_id # Estimated pose that is typically relative to a fixed world frame. geometry_msgs/PoseWithCovariance pose Pose pose Point position float64 x float64 y float64 z Quaternion orientation float64 x 0 float64 y 0 float64 z 0 float64 w 1 float64[36] covariance # Estimated linear and angular velocity relative to child_frame_id. geometry_msgs/TwistWithCovariance twist Twist twist Vector3 linear float64 x float64 y float64 z Vector3 angular float64 x float64 y float64 z float64[36] covariance 注意看，除了表示位置的 pose 和表示速度的 twist ，还有 child_frame_id 这一参数，它表示里程计子坐标系名称，根据ROS 导航堆栈定义，一般用 base_link 或者 base_footprint 。 接着我们来编写代码。 二、编写代码 如何发布话题在前面的章节中我们已经学习过了，现在我们来编写代码，因为是直接在原来的代码基础上修改的，所以下面展示的代码前如果是+表示新增行，-表示删除行，没有符号表示没有修改。 Kinematics.h 首先是/lib/Kinematics/Kinematics.h，增加四元数定义和欧拉角转四元数函数，这是因为ROS中姿态的表示使用的是四元数。 +typedef struct +{ + float w; + float x; + float y; + float z; +} quaternion_t; + /** * @brief 里程计相关信息，根据轮子速度信息和运动模型推算而来 * @@ -41,6 +49,7 @@ typedef struct float x; // 坐标x float y; // 坐标y float yaw; // yaw + quaternion_t quaternion; // 姿态四元数 float linear_speed; // 线速度 float angular_speed; // 角速度 } odom_t; @@ -56,6 +65,7 @@ private: public: Kinematics(/* args */) = default; ~Kinematics() = default; + static void Euler2Quaternion(float roll, float pitch, float yaw, quaternion_t &q); static void TransAngleInPI(float angle,float& out_angle); Kinematics.cpp 接着是：lib/Kinematics/Kinematics.cpp，增加 Euler2Quaternion 函数实现，在 odom 函数中增加对 Euler2Quaternion 函数的调用。 #include \"Kinematics.h\" +// 用于将欧拉角转换为四元数。 +void Kinematics::Euler2Quaternion(float roll, float pitch, float yaw, quaternion_t &q) +{ + // 传入机器人的欧拉角 roll、pitch 和 yaw。 + // 计算欧拉角的 sin 和 cos 值，分别保存在 cr、sr、cy、sy、cp、sp 六个变量中 + // https://blog.csdn.net/xiaoma_bk/article/details/79082629 + double cr = cos(roll * 0.5); + double sr = sin(roll * 0.5); + double cy = cos(yaw * 0.5); + double sy = sin(yaw * 0.5); + double cp = cos(pitch * 0.5); + double sp = sin(pitch * 0.5); + // 计算出四元数的四个分量 q.w、q.x、q.y、q.z + q.w = cy * cp * cr + sy * sp * sr; + q.x = cy * cp * sr - sy * sp * cr; + q.y = sy * cp * sr + cy * sp * cr; + q.z = sy * cp * cr - cy * sp * sr; +} odom_t &Kinematics::odom() { + // 调用 Euler2Quaternion 函数，将机器人的欧拉角 yaw 转换为四元数 quaternion。 + Kinematics::Euler2Quaternion(0, 0, odom_.yaw, odom_.quaternion); return odom_; } main.cpp 接着修改了 /src/main.cpp ，主要添加了一个发布者，接着对时间进行同步，方便发布里程计话题时使用当前的时间。 然后对数据的各项进行设置，最后添加了里程计数据的发布，间隔 50ms 进行发布。 #include // 包含使用 ESP32 的 MCPWM 硬件模块控制 DC 电机的 ESP32 MCPWM 电机库 #include // 包含 PID 控制器库，用于实现 PID 控制 #include // 运动学相关实现 +#include +#include +rcl_publisher_t odom_publisher; // 用于发布机器人的里程计信息（Odom） +nav_msgs__msg__Odometry odom_msg; // 机器人的里程计信息 Esp32PcntEncoder encoders[2]; // 创建一个长度为 2 的 ESP32 PCNT 编码器数组 rclc_executor_t executor; // 创建一个 RCLC 执行程序对象，用于处理订阅和发布 void microros_task(void *param) { + // 使用 micro_ros_string_utilities_set 函数设置到 odom_msg.header.frame_id 中 + odom_msg.header.frame_id = micro_ros_string_utilities_set(odom_msg.header.frame_id, \"odom\"); + odom_msg.child_frame_id = micro_ros_string_utilities_set(odom_msg.child_frame_id, \"base_link\"); // 等待 2 秒，以便网络连接得到建立。 delay(2000); + rclc_publisher_init_best_effort( + &odom_publisher, + &node, + ROSIDL_GET_MSG_TYPE_SUPPORT(nav_msgs, msg, Odometry), + \"odom\"); // 设置 micro-ROS 执行器，并将订阅添加到其中。 rclc_executor_init(&executor, &support.context, 1, &allocator); rclc_executor_add_subscription(&executor, &subscriber, &sub_msg, &twist_callback, ON_NEW_DATA); // 循环运行 micro-ROS 执行器以处理传入的消息。 while (true) { + if (!rmw_uros_epoch_synchronized()) + { + rmw_uros_sync_session(1000); + // 如果时间同步成功，则将当前时间设置为MicroROS代理的时间，并输出调试信息。 + delay(10); + } delay(100); rclc_executor_spin_some(&executor, RCL_MS_TO_NS(100)); } } unsigned long previousMillis = 0; // 上一次打印的时间 -unsigned long interval = 1000; // 间隔时间，单位为毫秒 +unsigned long interval = 50; // 间隔时间，单位为毫秒 void loop() { previousMillis = currentMillis; // 记录上一次打印的时间 float linear_speed, angle_speed; kinematics.kinematic_forward(kinematics.motor_speed(0), kinematics.motor_speed(1), linear_speed, angle_speed); - Serial.printf(\"[%ld] linear:%f angle:%f\\n\", currentMillis, linear_speed, angle_speed); // 打印当前时间 - Serial.printf(\"[%ld] x:%f y:%f yaml:%f\\n\", currentMillis,kinematics.odom().x, kinematics.odom().y, kinematics.odom().yaw); // 打印当前时间 + // Serial.printf(\"[%ld] linear:%f angle:%f\\n\", currentMillis, linear_speed, angle_speed); // 打印当前时间 + // Serial.printf(\"[%ld] x:%f y:%f yaml:%f\\n\", currentMillis,kinematics.odom().x, kinematics.odom().y, kinematics.odom().yaw); // 打印当前时间 + // 用于获取当前的时间戳，并将其存储在消息的头部中 + int64_t stamp = rmw_uros_epoch_millis(); + // 获取机器人的位置和速度信息，并将其存储在一个ROS消息（odom_msg）中 + odom_t odom = kinematics.odom(); + odom_msg.header.stamp.sec = static_cast(stamp / 1000); // 秒部分 + odom_msg.header.stamp.nanosec = static_cast((stamp % 1000) * 1e6); // 纳秒部分 + odom_msg.pose.pose.position.x = odom.x; + odom_msg.pose.pose.position.y = odom.y; + odom_msg.pose.pose.orientation.w = odom.quaternion.w; + odom_msg.pose.pose.orientation.x = odom.quaternion.x; + odom_msg.pose.pose.orientation.y = odom.quaternion.y; + odom_msg.pose.pose.orientation.z = odom.quaternion.z; + + odom_msg.twist.twist.angular.z = odom.angular_speed; + odom_msg.twist.twist.linear.x = odom.linear_speed; + + rcl_publish(&odom_publisher, &odom_msg, NULL); } 这三个文件修改好，接着就可以下载代码进行测试了。 三、下载测试 下载代码，运行agent，点击RST按键。 sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 看到连接建立表示通信成功，接着用ros2 topic list ros2 topic list --- /cmd_vel /odom /parameter_events /rosout 接着我们可以查看里程计数据或其发布频率。 ros2 topic echo /odom --once # 查看数据 --- header: stamp: sec: 2093 nanosec: 40 frame_id: odom child_frame_id: base_link pose: pose: position: x: 0.0 y: 0.0 z: 0.0 orientation: x: 0.0 y: 0.0 z: 0.0 w: 1.0 covariance: - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 twist: twist: linear: x: 0.0 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0 covariance: - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 - 0.0 --- 查看数据频率 ros2 topic hz /odom --- average rate: 19.376 min: 0.047s max: 0.063s std dev: 0.00326s window: 21 average rate: 19.558 min: 0.039s max: 0.063s std dev: 0.00338s window: 41 average rate: 19.527 min: 0.039s max: 0.063s std dev: 0.00307s window: 61 average rate: 19.533 min: 0.039s max: 0.063s std dev: 0.00301s window: 81 查看数据带宽 ros2 topic bw /odom --- Subscribed to [/odom] 14.78 KB/s from 20 messages Message size mean: 0.72 KB min: 0.72 KB max: 0.72 KB 14.26 KB/s from 39 messages Message size mean: 0.72 KB min: 0.72 KB max: 0.72 KB 14.34 KB/s from 59 messages Message size mean: 0.72 KB min: 0.72 KB max: 0.72 KB 14.19 KB/s from 78 messages Message size mean: 0.72 KB min: 0.72 KB max: 0.72 KB 14.25 KB/s from 98 messages Message size mean: 0.72 KB min: 0.72 KB max: 0.72 KB 14.18 KB/s from 100 messages Message size mean: 0.72 KB min: 0.72 KB max: 0.72 KB 14.25 KB/s from 100 messages Message size mean: 0.72 KB min: 0.72 KB max: 0.72 KB 四、总结 有了控制话题和里程计话题，底盘部分就完成的差不多了，但是对于一个合格的底盘来说，其实还有很多待完善的地方，下一节我们就来说说可以怎么完善，以及完善的后的代码。 "},"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/013-项目总结与扩展-源码编译Agent.html":{"url":"ROS2/两轮差速移动机器人开发篇/第16章-移动机器人控制系统搭建/013-项目总结与扩展-源码编译Agent.html","title":"项目总结与扩展-源码编译Agent","keywords":"","body":"datetime:2023/11/03 10:52 author:nzb 该项目来源于大佬的动手学ROS2 16.项目总结与扩展 上一节我们完成后，就可以通过话题获取到机器人的里程计，也可以通过话题控制机器人移动了。对于一个移动底盘来说，这两个话题就是最关键的两个，有了这两个就可以控制底盘完成移动。但如果想让底盘更好用，可以增加OLED模块显示数据，比如电池的电压。同时我们的板子还支持IMU和超声波模块，其实都可以通过话题发布出来。 说了那么多，你可能不知道怎么做，没关系，小鱼大佬写好了所有的代码，有了前面的基础，加上代码中的详细注释，看懂他们对你来说并不难。完成代码可以直接通过git进行克隆到本地。 git clone http://github.fishros.org/https://github.com/fishros/fishbot_motion_control_microros.git 如果你的网络不错，也可以在线查看代码：https://github.dev/fishros/fishbot_motion_control_microros 该代码的结构如下： . ├── extra_packages │ └── fishbot_interfaces │ ├── CMakeLists.txt # CMake构建配置文件 │ ├── msg │ │ └── MyCustomMessage.msg # ROS消息定义 │ ├── package.xml # ROS包描述文件 │ └── srv │ └── FishBotConfig.srv # ROS服务定义 ├── include │ ├── fishbot_config.h # 头文件 │ ├── fishbot.h # 头文件 │ ├── fishlog.h # 头文件 │ └── README # 说明文档 ├── Installer # 安装器相关 ├── lib │ ├── Displays │ │ ├── fishbot_display.cpp # 显示相关源码 │ │ └── fishbot_display.h # 显示相关头文件 │ ├── FishbotUtils │ │ ├── fishbot_utils.cpp # 实用工具源码 │ │ └── fishbot_utils.h # 实用工具头文件 │ ├── Kinematics │ │ ├── Kinematics.cpp # 运动学计算源码 │ │ └── Kinematics.h # 运动学计算头文件 │ ├── MicroRosRwm │ │ ├── micro_ros_transport_serial.cpp # MicroROS串口传输源码 │ │ ├── micro_ros_transport_serial.h # MicroROS串口传输头文件 │ │ ├── micro_ros_transport_wifi_udp.cpp # MicroROS WiFi/UDP传输源码 │ │ └── micro_ros_transport_wifi_udp.h # MicroROS WiFi/UDP传输头文件 │ ├── PidController │ │ ├── PidController.cpp # PID控制器源码 │ │ └── PidController.h # PID控制器头文件 │ └── README # 说明文档 ├── LICENSE # 许可证文件 ├── partition.csv # 分区配置文件 ├── platformio.ini # PlatformIO配置文件 ├── README.md # 项目主README文件 ├── RELEASES.md # 发布说明 ├── src ├── fishbot_config.cpp # 配置相关源码 ├── fishbot.cpp # 主要功能源码 └── main.cpp # 主程序入口源码 下一章我们开始学习如何进行导航和建图。 17.拓展-源码编译Agent 本文介绍了如何拓展MicroROS的Agent，将其作为一个功能包进行源码编译，并提供了详细的步骤如下： 一、下载microros-agent 首先，我们需要下载MicroROS的Agent源码，并准备相应的依赖。以下是下载和准备的步骤： 安装必要的依赖项： sudo apt-get install -y build-essential 创建工作空间并进入源码目录： mkdir -p microros_ws/src cd microros_ws/src 下载MicroROS Agent和相关消息包的源码： git clone http://github.fishros.org/https://github.com/micro-ROS/micro-ROS-Agent.git -b humble git clone http://github.fishros.org/https://github.com/micro-ROS/micro_ros_msgs.git -b humble 二、编译运行 在成功下载源码并准备好依赖后，我们可以进行编译并运行MicroROS Agent。以下是编译和运行的步骤： 返回工作空间目录并执行编译： cd microros_ws colcon build 运行MicroROS Agent，注意可能存在串口权限问题。可以参考链接 来设置权限。运行命令如下（假设串口为/dev/ttyUSB0，波特率为921600）： ros2 run micro_ros_agent micro_ros_agent serial -b 921600 --dev /dev/ttyUSB0 -v 或者使用UDP方法： ros2 run micro_ros_agent micro_ros_agent serial udp4 --port 8888 -v6 三、总结 通过上述步骤，我们成功地拓展了MicroROS的Agent功能包，实现了源码的编译和运行。通过MicroROS Agent，我们能够在资源受限的嵌入式系统中实现强大的ROS 2通信能力。 "},"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/001-可视化雷达点云-学会驱动雷达.html":{"url":"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/001-可视化雷达点云-学会驱动雷达.html","title":"学会驱动雷达","keywords":"","body":"datetime:2023/11/08 16:27 author:nzb 该项目来源于大佬的动手学ROS2 1.可视化雷达点云-学会驱动雷达 在购买FishBot送的快速上手教程中，直接使用 Docker 来运行了雷达和直接建图，本章我们将介绍从源码的方式驱动雷达和完成建图和导航配置，本节我们来学习如何驱动雷达。 一、激光雷达介绍 激光雷达（Light Detection And Ranging）,缩写LiDAR，翻译一下叫——激光探测与测距。 1.1 激光雷达原理介绍 激光雷达的原理也很简单，就像蝙蝠的定位方法一样，蝙蝠定位大家都知道吧，像下面这样子的回声定位。 普通的单线激光雷达一般有一个发射器，一个接收器，发射器发出激光射线到前方的目标上，物品会将激光反射回来，然后激光雷达的接受器可以检测到反射的激光。 通过计算发送和反馈之间的时间间隔，乘上激光的速度，就可以计算出激光飞行的距离，该计算方法称为TOF（飞行时间法Time of flight，也称时差法）。 除了TOF之外还有其他方法进行测距，比如三角法，这里就不拓展了放一篇文章，大家自行阅读。 激光三角测距原理详述 目前市面上的激光雷达，几乎都是采用三角测距，比如思岚的： 需要注意的是虽然只有一个发射器和一个接受器，激光雷达通过电机可以进行旋转，这样就可以达到对周围环境360度测距的目的。 二、驱动雷达 目前FishBot主要配套雷达型号为EAI-X2，后续可能会引入其他雷达。 针对EAI-X2，采用的驱动为修改后的ROS2驱动: 代码仓库为：https://github.com/fishros/ydlidar_ros2 代码分支为：v1.0.0/fishbot 2.1 有线驱动-树莓派工控机直连都可以通过这种方式 将配套的雷达转接板模式调整到UART模式，拔掉EN跳线帽（可以关闭ESP8266,节省能源）， 找一根USB线，将 雷达板接入到你要驱动的电脑或者各种PI上。 创建fishbot_ws工作空间，下载源码到src目录： mkdir -p ~/fishbot_ws/src cd ~/fishbot_ws/src git clone http://github.fishros.org/https://github.com/fishros/ydlidar_ros2 -b v1.0.0/fishbot 进入到源码，修改串口编号ydlidar_ros2/params/ydlidar.yaml，一般是/dev/ttyUSB0 ydlidar_node: ros__parameters: port: /dev/ttyUSB0 frame_id: laser_frame ignore_array: \"\" 接着编译 ： cd ydlidar_ros2 colcon build 接着修改串口权限，然后运行驱动 sudo chmod 666 /dev/ttyUSB0 source install/setup.bash ros2 launch ydlidar ydlidar_launch.py --- [INFO] [launch]: All log files can be found below /home/pi/.ros/log/2023-07-21-23-13-28-893425-raspberrypi-4518 [INFO] [launch]: Default logging verbosity is set to INFO [INFO] [ydlidar_node-1]: process started with pid [4539] [INFO] [static_transform_publisher-2]: process started with pid [4541] [static_transform_publisher-2] [WARN] [1689952409.891692804] []: Old-style arguments are deprecated; see --help for new-style arguments [static_transform_publisher-2] [INFO] [1689952409.975433434] [static_tf_pub_laser]: Spinning until stopped - publishing transform [static_transform_publisher-2] translation: ('0.020000', '0.000000', '0.000000') [static_transform_publisher-2] rotation: ('0.000000', '0.000000', '0.000000', '1.000000') [static_transform_publisher-2] from 'base_link' to 'laser_frame' [ydlidar_node-1] [YDLIDAR INFO] Current ROS Driver Version: 1.4.5 [ydlidar_node-1] [YDLIDAR]:SDK Version: 1.4.5 [ydlidar_node-1] [YDLIDAR]:Lidar running correctly ! The health status: good [ydlidar_node-1] [YDLIDAR] Connection established in [/dev/ttyUSB0][115200]: [ydlidar_node-1] Firmware version: 1.5 [ydlidar_node-1] Hardware version: 1 [ydlidar_node-1] Model: S4 [ydlidar_node-1] Serial: 2020112400007024 [ydlidar_node-1] [YDLIDAR]:Fixed Size: 370 [ydlidar_node-1] [YDLIDAR]:Sample Rate: 3K [ydlidar_node-1] [YDLIDAR INFO] Current Sampling Rate : 3K [ydlidar_node-1] [YDLIDAR INFO] Now YDLIDAR is scanning ...... 最后使用ros2 topic list 就可以看到话题list了，scan就是雷达话题 ros2 topic list --- /parameter_events /rosout /scan /tf_static /ydlidar_node/transition_event 2.2 无线驱动 如果想通过源码的方式也可以，雷达板的主要作用是将雷达 数据生成一个虚拟的串口，这样就相当于有线连接了。 首先要给雷达板烧录固件，这个固件的作用就是将串口转成无线TCP,所以对于这段固件的开发，没有要学习的知识点，直接使用即可，固件烧录及配置方式如下：配置 烧录完成固件后，接着我们就可以启动服务让雷达板连接上来，在电脑上直接运行下面这段Python代码，当连接建立后，就会直接生成 一个虚拟串口，然后按照 2.1 的方式就可以直接驱动了。 #!/usr/bin/env python3 import subprocess import os import pty import socket import select import argparse import subprocess import time class LaserScanRos2(): def __init__(self) -> None: self.laser_pro = None class SocketServer(): def __init__(self,lport=8889,uart_name=\"/tmp/fishbot_laser\") -> None: self.lport = lport self.uart_name = uart_name self.laser_ros2 = LaserScanRos2() self.main() def main(self): s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) s.bind(('0.0.0.0', self.lport)) s.listen(5) master, slave = pty.openpty() if os.path.exists(self.uart_name): os.remove(self.uart_name) os.symlink(os.ttyname(slave), self.uart_name) print(f\"UART2SOCKET:{self.lport}->{self.uart_name}\") mypoll = select.poll() mypoll.register(master, select.POLLIN) try: while True: print(\"Prepare to Accept connect!\") client, client_address = s.accept() mypoll.register(client.fileno(), select.POLLIN) print(s.fileno(), client, master) print('PTY: Opened {} for {}:{}'.format( os.ttyname(slave), '0.0.0.0', self.lport)) is_connect = True try: while is_connect: fdlist = mypoll.poll(256) for fd, event in fdlist: data = os.read(fd, 256) write_fd = client.fileno() if fd == master else master if len(data) == 0: is_connect = False break os.write(write_fd, data) # print(fd, event, data) except ConnectionResetError: is_connect = False print(\"远程被迫断开链接\") finally: mypoll.unregister(client.fileno()) finally: s.close() os.close(master) os.close(slave) os.remove(self.uart_name) def main(): SocketServer() if __name__ == \"__main__\": main() 连接成功后，会生成/tmp/fishbot_laser 虚拟串口，修改雷达驱动的端口号到这个虚拟串口，确定雷达连接上，然后启动雷达驱动就可以了。 python3 test.py --- UART2SOCKET:8889->/tmp/fishbot_laser Prepare to Accept connect! 3 4 PTY: Opened /dev/pts/4 for 0.0.0.0:8889 三、可视化雷达数据 雷达驱动成功后，可以用RVIV2可视化雷达数据。在终端中输入rviz2,然后修改fixedframe为雷达驱动配置文件中的frame_id: laser_frame ，接着通过话题添加可视化模块。因为雷达也属于传感器，所以需要修改QOS部分 可靠政策为 Best Effort，具体配置如下： 最终现实效果如下 扩展：雷达固件烧录 FishBot雷达转接板介绍 Fishbot雷达转接板主要作用是将雷达的数据通过Wifi网络转发出去，以时间雷达数据的无线传输功能。 FishBot转接板的工作模式有三种 Flash模式，该模式下可以给转接板进行固件的升级和参数配置。 Uart有线模式，该模式可以用于直接通过有线方式连接树莓派等主控板。 Wifi无线模式，该模式将雷达数据通过无线方式传给上位机。 这三种工作模式可以根据板子上的标记调整跳线帽的位置进行切换。 当你第一次使用的时候需要将板子调节到Flash模式，该模式下我们可以对板子进行配置以及升级。 烧录雷达固件 将跳线帽手动改到配置模式，如果你有OLED或者FISHBOT可以将其插在雷达板的OLED接口上，等升级配置结束后再拿走即可。 接着运行配置助手 xhost + && sudo docker run -it --rm --privileged -v /dev:/dev -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=unix$DISPLAY fishros2/fishbot-tool:v1.0.0.20230108 python3 main.py 点击刷新，查看是否正确加载到端口号，如没有端口号可能是驱动占用问题，请根据教程检查：https://blog.csdn.net/qq_27865227/article/details/125538516 接着手动将设备类型切换到雷达转接板 接着下方固件烧录会自动加载出最新的固件地址，点击一键下载即可完成对雷达转接板固件的更新。 如果你想更换其他版本的固件，请到FishBot固件发布页面在对应的固件上右击，复制链接，粘贴到配置助手固件地址栏目再点击一键烧录即可。 如果你有OLED，此时屏幕应该亮起，并显示当前在配置模式，当前状态在等待配置。 如果没有OLED可以观察板子上的蓝色LED灯，长亮表示在等待配置。 如果不在配置模式可以双击板子上的BOOT按键进行模式的切换。 配置转接板 在配置模式下，点击配置助手的重新扫描配置即可出现配置选项， 这里我们需要修改三个参数。 wifi_ssid，当前机器人可以连接到的wifi用户名 wifi_pswd，wifi密码 server_ip，接收雷达数据的服务器端口地址 配置WIFI 这里你需要修改wifi_ssid和wifi_pswd为你当前环境的WIFI地址。 配置服务IP 转接板要想将数据通过网络分享给我们的计算机，那么在计算机上就需要一个程序来接收数据，所以我们要指定接收数据的服务的IP地址——当前计算机的IP。 第一步是获取当前主机的IP地址 打开一个新的终端，输入ip -4 a | grep inet看看电脑的ip地址，一般可以看到多个网卡的，此时可以忽略172(docker)和127(本地) 开头的ip地址，剩下的一般就是我们要的ip地址，比如这里的就是192.168.0.105 接着配置 配置完成后，双击BOOT按钮，切换至运行模式，即可从OLED上观察到目前的配置信息以及连接状态信息。 其中IP即转接板的IP地址，虽然wifi连接成功了，但我们的计算机不一定在网络链路上就和雷达转接板能够打通，最简单的测试方式就是手动ping 一下雷达转接板的ip地址。 如上面这样的结果表示链路是通的。 有条件的小伙伴可以尝试： 启动串口工具和tcpserver工具，手动通过串口发送数据，看看tcpserver是否可以正常接收。 "},"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/002-建图前准备1-了解ROS标准REP105.html":{"url":"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/002-建图前准备1-了解ROS标准REP105.html","title":"了解ROS标准REP105","keywords":"","body":"datetime:2023/11/08 16:27 author:nzb 该项目来源于大佬的动手学ROS2 REP-105：移动平台的坐标系框架 REP-105 是一个名为 \"Coordinate Frames for Mobile Platforms\"（移动平台的坐标系框架）的 ROS Enhancement Proposal（REP）。该提案由 Wim Meeussen 于 2010年10月27日 创建，并处于活动状态。本文将介绍 REP-105 的内容，包括其摘要、动机、规范、坐标系、坐标系之间的关系等。 一、摘要 REP-105 规定了用于 ROS 的移动平台的坐标系的命名约定和语义含义。 二、目的 开发者需要共享的坐标系约定，以更好地集成和重用驱动程序、模型和库等软件组件。这个共享的坐标系约定可为创建移动基座的驱动程序和模型的开发者提供规范。同样，创建库和应用程序的开发者可以更轻松地将其软件与兼容此规范的多种移动基座一起使用。例如， REP-105 规定了编写新的定位组件所需的坐标系。它还规定了用于引用机器人的移动基座的坐标系。 三、规范 3.1坐标系 base_link 名为 \"base_link\" 的坐标系刚性地附加在移动机器人的基座上。可以将 \"base_link\" 以任意的位置或方向附加到基座上；对于每个硬件平台，基座上提供明显参考点的位置可能不同。需要注意的是，REP 103 指定了坐标系的首选方向。 odom 名为 \"odom\" 的坐标系是一个世界固定坐标系。在 \"odom\" 坐标系中，移动平台的姿态随时间可能会漂移，但没有界限。这种漂移使得 \"odom\" 坐标系作为长期全局参考无用。然而，机器人在 \"odom\" 坐标系中的姿态保证是连续的，这意味着机器人在 \"odom\" 坐标系中的姿态始终以平稳的方式演变，没有离散的跳跃。 在典型的设置中，基于测距源（如轮式测距、视觉测距或惯性测量单元）计算了 \"odom\" 坐标系。机器人在 \"odom\" 坐标系中的姿态是基于这些测距源计算的。 \"odom\" 坐标系作为准确的短期局部参考很有用，但漂移使其成为长期参考的较差坐标系。 map 名为 \"map\" 的坐标系是一个世界固定坐标系，其Z轴指向上方。移动平台相对于 \"map\" 坐标系的姿态随时间不应显著漂移。但 \"map\" 坐标系不连续，这意味着移动平台在 \"map\" 坐标系中的姿态可以在任何时候以离散跳跃的方式发生变化。 在典型的设置中，定位组件基于传感器观测不断重新计算机器人在 \"map\" 坐标系中的姿态，从而消除漂移，但当新的传感器信息到达时会导致离散跳跃。 \"map\" 坐标系作为长期全局参考很有用，但在位置估计器中的离散跳跃使其成为局部感知和操作的较差参考坐标系。 3.2 Map约定 地图坐标系可以全局引用，也可以引用到特定应用程序位置。例如，一个应用程序特定的定位可能是根据EGM1996确定的海平面高度，使得地图坐标系中的Z位置等于海平面上方的米数。不管选择何种方式，最重要的部分是必须清楚地记录参考位置的选择，以避免混淆。 当与地球等全球参考一起定义坐标系时： 默认情况下，应将x轴对齐到东方，y轴对齐到北方，z轴在坐标系原点上方朝上。 如果没有其他参考，z轴的默认位置应该是在WGS84椭球的高度为零的位置。 如果存在特定应用程序要求，上述要求无法满足的情况应尽可能满足。 一个不能满足上述要求的应用示例是启动时没有外部参考设备（如GPS、罗盘或高度计）的机器人。但如果机器人仍具有加速度计，它可以在当前位置初始化地图，z轴朝上。 如果机器人在启动时具有罗盘航向，它还可以初始化东向x轴，北向y轴。 如果机器人在启动时具有高度计估计，它可以将高度初始化为MSL。 上述约定强烈建议在非结构化环境中使用。 结构化环境中的Map约定 在结构化环境中，将地图与环境对齐可能更有用。例如，办公楼内部通常是直线的，且具有有限的全局定位方法，因此建议将地图与建筑物对齐，尤其是 在建筑物布局预先已知的情况下。类似地，在室内环境中，建议将地图与楼层水平对齐。如果在多层楼环境中操作，每层楼应该有一个单独的坐标系。 如果存在歧义，可以回退到上述非结构化环境的约定。或者，如果对环境了解有限，则仍可以在结构化环境中使用非结构化约定。 earth 名为 \"earth\" 的坐标系是ECEF（Earth Centered Earth Fixed）坐标系的原点。如果应用程序只需要一个地图，则不需要 \"earth\" 坐标系。如果同时运行多个地图，则需要为每个机器人定制 \"map\" 、\"odom\" 和 \"base_link\" 坐标系。如果同时运行多个机器人并在它们之间桥接数据，则每个机器人的变换帧标识（frame_ids）可以保持标准状态，只需对其他机器人的变换帧标识进行重写。 如果全局引用了 \"map\" 坐标系，则从 \"earth\" 到 \"map\" 的发布者可以是静态变换发布者。否则，通常需要通过估算当前全局位置的估计值并从地图中估算当前估计姿态来计算 \"earth\" 到 \"map\" 的变换。 如果在启动时无法确定 \"map\" 坐标系的绝对位置，它可以保持未连接状态，直到可以充分评估全局位置估计为止。这与在初始化 \"map\" 坐标系的定位之前，机器人可以在 \"odom\" 坐标系中操作的方式相同。 3.3 坐标系之间的关系 我们选择树形表示将所有坐标系连接在一个机器人系统中。因此，每个坐标系都有一个父坐标系和任意数量的子坐标系。在本REP中描述的坐标系如下所示： graph LR O(odom) --> B(base_link) M(map) --> O E(earth) --> M \"map\" 坐标系是 \"odom\" 坐标系的父坐标系，而 \"odom\" 坐标系是 \"base_link\" 坐标系的父坐标系。尽管直觉可能会认为 \"map\" 和 \"odom\" 都应该附加到 \"base_link\" 坐标系，但这是不允许的，因为每个坐标系只能有一个父坐标系。 额外的中间坐标系 这个图显示了该图的最小表示。基本拓扑结构应保持不变，但可以在图中插入额外的链接以提供附加功能。 压力高度 潜在的附加坐标系示例是用于表示飞行器的压力高度。压力高度是基于大气气压共享估计的高度近似值。在飞行应用中，可以仅使用气压高度计精确地测量压力高度。它可能会随时间漂移，但仅在垂直方向上漂移。为了支持额外功能，可以在具有惯性一致性的 \" odom\" 坐标系和 \"map\" 坐标系之间插入一个 \"pressure_altitude\" 坐标系。需要一个额外的估计器来估计 \"pressure_altitude\" 与 \"map\" 之间的偏移，但这个额外的坐标系可以支持额外的功能，并且不会破坏上述抽象。 3.4 多机器人tf图的示例 graph TB odom_1(odom_1) --> base_link1(base_link1) map_1(map_1) --> odom_1 earth(earth) --> map_1 odom_2(odom_2) --> base_link2(base_link2) map_2(map_2) --> odom_2 earth --> map_2 这是一个包含两个机器人的tf树示例，它们使用不同的地图进行定位，并具有共同的 \"earth\" 坐标系。 3.5 坐标系的权限 从 \"odom\" 到 \"base_link\" 的变换由其中一个测距源计算和广播。 从 \"map\" 到 \"base_link\" 的变换由定位组件计算。然而，定位组件不广播从 \"map\" 到 \"base_link\" 的变换。相反，它首先接收从 \"odom\" 到 \"base_link\" 的变换，然后使用此信息广播从 \"map\" 到 \"odom\" 的变换。 从 \"earth\" 到 \"map\" 的变换是静态发布的，并由地图坐标系的选择进行配置。如果没有特别配置，可以使用车辆的初始位置作为地图坐标系的原点。如果地图没有进行地理参考，以支持简单的静态变换，则定位模块可以遵循与发布从 \" map\" 到 \"odom\" 的估计偏移的过程相同的程序来发布从 \"earth\" 到 \"map\" 的变换。 3.6 在地图之间的转换 当机器人行驶一段较长的距离时，预计它需要在地图之间进行转换。在室外环境中，地图坐标系是附近的一个欧几里得近似值，但由于地球的曲率，当距离较长时，这种欧几里得近似会失效。在室内环境中，可以在两个建筑之间进行转换， 其中每个建筑都有一个先前的地图，在该地图中进行导航，或者机器人位于建筑的新楼层。 当在地图之间移动时，定位坐标系的权威应该适当地重新设置 \"odom\" 坐标系的父坐标系。计算 \"map\" 到 \"odom\" 坐标系的常见方法是将 \"odom\" 到 \"base_link\" 的结果从定位修复的 \" map\" 到 \"base_link\" 中减去，当选择的 \"map\" 坐标系更改时，这将隐式地处理这一点。 \"odom\" 坐标系的一致性 在地图之间进行转换时，应不会影响里程坐标系。在积累足够的集成位置误差使数据无效之前，应该调整在 \"odom\" 坐标系中收集的数据的数据保留策略。根据机器人的里程质量不同，这些策略可能会大不相同。具有多个冗余的高分辨率编码器的轮式车辆的漂移率较低，可以在更长的时间或距离内保留数据，而仅在转弯时通过开环反馈进行反馈的履带式机器人会保留较短的时间或距离内的数据。 还有其他上下文也会影响适当的保留策略，比如机器人被外部驱动器移动，或者对静态环境的假设。例如，在电梯中的机器人的情况下，进入和退出电梯之间的环境发生了变化。 如果车辆行驶的距离足够长，以至于从 \"odom\" 坐标系的原点到车辆的距离接近最大浮点精度，可能会观察到基于浮点数据的持久化数据的性能下降。这在点云等使用32位浮点数据的浮点数据中尤为明显。如果遇到这种距离情况，可能需要定期重置 \" odom\" 坐标系的原点。如果需要厘米级的精度，则到 \"odom\" 坐标系的最大距离约为83公里。 3.7 异常情况 潜在的机器人软件范围太广，无法要求所有ROS软件遵循此REP的准则。然而，选择不同的约定应该有充分的理由并且要有良好的文档记录。 "},"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/003-建图前准备2-发布odom的TF.html":{"url":"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/003-建图前准备2-发布odom的TF.html","title":"发布odom的TF","keywords":"","body":"datetime:2023/11/08 16:27 author:nzb 该项目来源于大佬的动手学ROS2 3.建图前准备2-发布 Odom 的 TF 上一节我们简单了解了 ROS 中对移动机器人坐标系变换的规定如下： graph LR O(odom) --> B(base_link) M(map) --> O E(earth) --> M B-->L(laser/imu...) 运行建图算法时，会得到 map 到 odom 之间的TF，base_link 到 雷达或者IMU 之间的坐标关系一般使用URDF进行描述，然后使用 robot_state_publisher 进行发布，也可以使用静态TF直接发布。 而 odom 到 base_link 之间的TF就需要我们从里程计中提取并发布，本节我们主要的工作就是订阅 里程计话题 发布 odom 到 base_link 之间的 TF 变换。 关于base_link和base_footprint 的区别 在机器人领域中，\"base_link\"和\"base_footprint\"是ROS（Robot Operating System）中两个常用的坐标系（frames）名称。它们用于表示机器人的基本参考坐标系，但在某些情况下，它们可能会有一些微妙的区别。 base_link： \"base_link\"通常用于表示机器人的实际底盘或主体的坐标系。这个坐标系通常与机器人的物理结构直接相关，它可能位于机器人底盘的中心或者其他适当的位置。例如，对于一个移动机器人，\"base_link\"的原点可能位于机器人的几何中心或底盘的旋转中心，这取决于机器人的设计。 base_footprint： \"base_footprint\"则更多地被用作机器人在地面上的一个虚拟平面的参考点，通常是机器人底盘的投影点。这个坐标系通常位于机器人底盘底部，用于表示机器人与地面的接触点。它可以被认为是机器人底部的一个虚拟标记，用来执行路径规划、避障和定位等任务。 在许多情况下，\"base_link\"和\"base_footprint\"的坐标原点可能是相同的，但它们的用途和表示方式略有不同。例如，在路径规划中，可能更常用\"base_footprint\"，因为它更接近机器人在地面上的实际位置，有助于避免碰撞。而在其他情况下，如控制机器人的运动，使用\"base_link\"可能更合适，因为它更直接地与机器人的物理结构相联系。 一、创建功能包 创建fishbot工作空间和功能包fishbot_bringup mkdir -p ~/fishbot_ws/src cd ~/fishbot_ws/src ros2 pkg create --build-type ament_cmake fishbot_bringup 二、编写代码 在 src/fishbot_bringup/src/ 下新建 fishbot_bringup.cpp #include #include #include #include class TopicSubscribe01 : public rclcpp::Node { public: TopicSubscribe01(std::string name) : Node(name) { // 创建一个订阅者，订阅\"odom\"话题的nav_msgs::msg::Odometry类型消息 odom_subscribe_ = this->create_subscription( \"odom\", rclcpp::SensorDataQoS(), std::bind(&TopicSubscribe01::odom_callback, this, std::placeholders::_1)); // 创建一个tf2_ros::TransformBroadcaster用于广播坐标变换 tf_broadcaster_ = std::make_unique(this); } private: rclcpp::Subscription::SharedPtr odom_subscribe_; std::unique_ptr tf_broadcaster_; nav_msgs::msg::Odometry odom_msg_; // 回调函数，处理接收到的odom消息 void odom_callback(const nav_msgs::msg::Odometry::SharedPtr msg) { (void)msg; RCLCPP_INFO(this->get_logger(), \"接收到里程计信息->底盘坐标系 tf :(%f,%f)\", msg->pose.pose.position.x, msg->pose.pose.position.y); // 更新odom_msg_的姿态信息 odom_msg_.pose.pose.position.x = msg->pose.pose.position.x; odom_msg_.pose.pose.position.y = msg->pose.pose.position.y; odom_msg_.pose.pose.position.z = msg->pose.pose.position.z; odom_msg_.pose.pose.orientation.x = msg->pose.pose.orientation.x; odom_msg_.pose.pose.orientation.y = msg->pose.pose.orientation.y; odom_msg_.pose.pose.orientation.z = msg->pose.pose.orientation.z; odom_msg_.pose.pose.orientation.w = msg->pose.pose.orientation.w; }; public: // 发布坐标变换信息 void publish_tf() { geometry_msgs::msg::TransformStamped transform; double seconds = this->now().seconds(); transform.header.stamp = rclcpp::Time(static_cast(seconds * 1e9)); transform.header.frame_id = \"odom\"; transform.child_frame_id = \"base_footprint\"; transform.transform.translation.x = odom_msg_.pose.pose.position.x; transform.transform.translation.y = odom_msg_.pose.pose.position.y; transform.transform.translation.z = odom_msg_.pose.pose.position.z; transform.transform.rotation.x = odom_msg_.pose.pose.orientation.x; transform.transform.rotation.y = odom_msg_.pose.pose.orientation.y; transform.transform.rotation.z = odom_msg_.pose.pose.orientation.z; transform.transform.rotation.w = odom_msg_.pose.pose.orientation.w; // 广播坐标变换信息 tf_broadcaster_->sendTransform(transform); } }; int main(int argc, char **argv) { // 初始化ROS节点 rclcpp::init(argc, argv); // 创建一个TopicSubscribe01节点 auto node = std::make_shared(\"fishbot_bringup\"); // 设置循环频率 rclcpp::WallRate loop_rate(20.0); while (rclcpp::ok()) { // 处理回调函数 rclcpp::spin_some(node); // 发布坐标变换信息 node->publish_tf(); // 控制循环频率 loop_rate.sleep(); } // 关闭ROS节点 rclcpp::shutdown(); return 0; } 修改CMakeLists.txt cmake_minimum_required(VERSION 3.8) project(fishbot_bringup) if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\") add_compile_options(-Wall -Wextra -Wpedantic) endif() # find dependencies find_package(ament_cmake REQUIRED) find_package(rclcpp REQUIRED) find_package(geometry_msgs REQUIRED) find_package(nav_msgs REQUIRED) find_package(tf2 REQUIRED) find_package(tf2_ros REQUIRED) set(dependencies rclcpp geometry_msgs nav_msgs tf2 tf2_ros ) # uncomment the following section in order to fill in # further dependencies manually. # find_package( REQUIRED) add_executable(fishbot_bringup src/fishbot_bringup.cpp) target_include_directories(fishbot_bringup PUBLIC $ $) target_compile_features(fishbot_bringup PUBLIC c_std_99 cxx_std_17) # Require C99 and C++17 ament_target_dependencies(fishbot_bringup ${dependencies} ) install(TARGETS fishbot_bringup DESTINATION lib/${PROJECT_NAME}) if(BUILD_TESTING) find_package(ament_lint_auto REQUIRED) # the following line skips the linter which checks for copyrights # comment the line when a copyright and license is added to all source files set(ament_cmake_copyright_FOUND TRUE) # the following line skips cpplint (only works in a git repo) # comment the line when this package is in a git repo and when # a copyright and license is added to all source files set(ament_cmake_cpplint_FOUND TRUE) ament_lint_auto_find_test_dependencies() endif() ament_package() 三、测试运行 编译运行节点 colcon build source install/setup.bash ros2 run fishbot_bringup fishbot_bringup 接着运行MicroROS Agent，发布 odom 话题出来 ros2 run fishbot_bringup fishbot_bringup --- [INFO] [1692340618.330952225] [fishbot_bringup]: recv odom->base_footprint tf :(0.001754,0.000030) [INFO] [1692340618.379986197] [fishbot_bringup]: recv odom->base_footprint tf :(0.001754,0.000030) [INFO] [1692340618.434032295] [fishbot_bringup]: recv odom->base_footprint tf :(0.001754,0.000030) [INFO] [1692340618.480949009] [fishbot_bringup]: recv odom->base_footprint tf :(0.001754,0.000030) [INFO] [1692340618.535952833] [fishbot_bringup]: recv odom->base_footprint tf :(0.001754,0.000030) 接着我们来查看下TF ros2 run rqt_tf_tree rqt_tf_tree 结果如下 四、总结 有了 odom 到 base_link/base_footprint 之间的变换，接下来我们来搞定 base_link 到机器人各个组件之间的变换。 "},"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/004-建图前准备3-准备URDF.html":{"url":"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/004-建图前准备3-准备URDF.html","title":"准备URDF","keywords":"","body":"datetime:2023/11/08 16:27 author:nzb 该项目来源于大佬的动手学ROS2 4.建图前准备3-准备URDF 关于URDF在第八章我们已经介绍了，接下来我们直接使用它来编写URDF。 一、新建功能包 在 fishbot/src 目录下创建一个新的功能包，命名为 fishbot_description： cd ~/fishbot_ws/src ros2 pkg create --build-type ament_python fishbot_description 二、编写URDF 在 src/fishbot_description/ 目录下新建 urdf 文件夹，然后新建 fishbot_v1.0.0.urdf 文件 ，编写如下内容： 接着修改：src/fishbot_description/setup.py 文件 ，拷贝所有 URDF 到 Install 目录。 from setuptools import setup from glob import glob import os package_name = 'fishbot_description' setup( name=package_name, version='0.0.0', packages=[package_name], data_files=[ ('share/ament_index/resource_index/packages', ['resource/' + package_name]), ('share/' + package_name, ['package.xml']), (os.path.join('share', package_name, 'launch'), glob('launch/*.launch.py')), (os.path.join('share', package_name, 'urdf'), glob('urdf/**')), ], install_requires=['setuptools'], zip_safe=True, maintainer='root', maintainer_email='root@todo.todo', description='TODO: Package description', license='TODO: License declaration', tests_require=['pytest'], entry_points={ 'console_scripts': [ \"rotate_wheel= fishbot_description.rotate_wheel:main\" ], }, ) 三、编写Launch文件 在 fishbot_bringup 下新建 launch 文件夹，然后新建 fishbot_bringup.launch.py，接着编写如下内容： import os from launch import LaunchDescription from launch.substitutions import LaunchConfiguration from launch_ros.actions import Node from launch_ros.substitutions import FindPackageShare def generate_launch_description(): package_name = 'fishbot_description' urdf_name = \"fishbot_v1.0.0.urdf\" ld = LaunchDescription() pkg_share = FindPackageShare(package=package_name).find(package_name) urdf_model_path = os.path.join(pkg_share, f'urdf/{urdf_name}') robot_state_publisher_node = Node( package='robot_state_publisher', executable='robot_state_publisher', arguments=[urdf_model_path] ) joint_state_publisher_node = Node( package='joint_state_publisher', executable='joint_state_publisher', name='joint_state_publisher', arguments=[urdf_model_path], output='screen', ) fishbot_bringup_node = Node( package='fishbot_bringup', executable='fishbot_bringup', name='fishbot_bringup', output='screen', ) ld.add_action(joint_state_publisher_node) ld.add_action(robot_state_publisher_node) ld.add_action(fishbot_bringup_node) return ld 接着修改：src/fishbot_bringup/CMakeLists.txt 添加拷贝 launch 指令 install( DIRECTORY launch DESTINATION share/${PROJECT_NAME} ) 四 、编译运行测试 colcon build source install/setup.bash ros2 launch fishbot_bringup fishbot_bringup.launch.py 接着测试查看 TF ros2 run rqt_tf_tree rqt_tf_tree 最终得到下图 五、总结 有了这样一个TF结构，我们的建图前的准备工作就差不多了。 "},"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/005-使用SLAM_TOOLBOX完成建图.html":{"url":"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/slam/005-使用SLAM_TOOLBOX完成建图.html","title":"使用SLAM_TOOLBOX完成建图","keywords":"","body":"datetime:2023/11/08 16:27 author:nzb 该项目来源于大佬的动手学ROS2 5.使用SLAM_TOOLBOX完成建图 SLAM 是通过传感器获取环境信息然后进行定位和建图。在 ROS 2 中，提供了很多的 SLAM 功能包，比如 slam_toolbox，cartographer_ros 和 rtabmap_slam 等。针对二维场景，其中 slam_toolbox 开箱即用，上手较为简单，就用它类来构建我们的第一张地图。 一、安装slam-toolbox slam_toolbox 是一套用于2D SLAM的开源工具，使用 apt 可以方便的进行安装，命令如下： sudo apt install ros-$ROS_DISTRO-slam-toolbox 二、启动底盘和雷达 1.运行TF转换Launch-Bringup source install/setup.bash ros2 launch fishbot_bringup fishbot_bringup.launch.py 2.运行Agent sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged --net=host microros/micro-ros-agent:$ROS_DISTRO udp4 --port 8888 -v6 3.启动雷达 直接使用Docker： xhost + && sudo docker run -it --rm -v /dev:/dev -v /dev/shm:/dev/shm --privileged -v /tmp/.X11-unix:/tmp/.X11-unix --device /dev/snd -e DISPLAY=unix$DISPLAY -p 8889:8888 registry.cn-hangzhou.aliyuncs.com/fishros/fishbot_laser 如果不用Docker需要修改下代码，因为 ydlidar_launch.py 会发布 base_link 和 laser_frame 之间的坐标变换，这和使用URDF发布的相冲突，所以需要做一次修改再运行： def generate_launch_description(): ... return LaunchDescription([ params_declare, driver_node, #tf2_node, ----注释这一行就可以了----- ]) 确定有雷达话题后，我们就可以运行建图了。 三、运行建图 接着打开一个新的终端， 入下面的命令，启动slam_toolbox 的在线建图： ros2 launch slam_toolbox online_async_launch.py --- INFO] [launch]: All log files can be found below /home/fishros/.ros/log/2023-05-25-16-47-11-319871-fishros-VirtualBox-11288 [INFO] [launch]: Default logging verbosity is set to INFO [INFO] [async_slam_toolbox_node-1]: process started with pid [11290] [async_slam_toolbox_node-1] [INFO] [1685004431.442212575] [slam_toolbox]: Node using stack size 40000000 [async_slam_toolbox_node-1] [INFO] [1685004431.503891373] [slam_toolbox]: Using solver plugin solver_plugins::CeresSolver [async_slam_toolbox_node-1] [INFO] [1685004431.505007754] [slam_toolbox]: CeresSolver: Using SCHUR_JACOBI preconditioner. [async_slam_toolbox_node-1] Info: clipped range threshold to be within minimum and maximum range! [async_slam_toolbox_node-1] [WARN] [1685004431.658413039] [slam_toolbox]: maximum laser range setting (20.0 m) exceeds the capabilities of the used Lidar (8.0 m) [async_slam_toolbox_node-1] Registering sensor: [Custom Described Lidar] slam-toolbox 的输入有两个，第一个是订阅来自雷达的 /scan 话题，用于获取雷达数据，第二个是获取里程计坐标系 odom 到机器人坐标系 base_footprint 之间的变换。这些数据都是有时间戳的，所以在上面的命令中将 use_sim_time 参数的值设置为 True 表示使用仿真的时间，以防止因时间戳造成数据不合法。 用RVIZ2可视化图像 打开 RViz，修改 Fixed Frame 为 map，接着通过 Add/By Topic 添加 /map 话题，也可以添加 TF 和 RobotModel 等你感兴趣的话题进行显示，最终配置及效果如下图所示。 遥控机器人建图(记得减速哦) ros2 run teleop_twist_keyboard teleop_twist_keyboard 房间已经探索了差不多后，接着我们来将地图保存下来。 6.地图保存与编辑 一、 安装NAV2_MAP_SERVER sudo apt install ros-$ROS_DISTRO-nav2-map-server 二、 保存地图 ros2 run nav2_map_server map_saver_cli --help 可以看到有下面的用法 Usage: map_saver_cli [arguments] [--ros-args ROS remapping args] Arguments: -h/--help -t -f --occ --free --fmt --mode trinary(default)/scale/raw NOTE: --ros-args should be passed at the end of command line 我们的地图话题为map，文件名字我们用fishbot_map,所以有下面这个这样写的命令行。 ros2 run nav2_map_server map_saver_cli -t map -f fishbot_map 接着我们就可以得到下面的两个文件 . ├── fishbot_map.pgm └── fishbot_map.yaml 0 directories, 2 files 这两个文件就是对当前地图保存下来的文件，其中.pgm是地图的数据文件，.yaml后缀的是地图的描述文件。 三、 地图数据文件.pgm介绍 OccupancyGrid由一个.yaml格式的元数据文件，和.pgm图片格式的地图数据文件组成。从上节课建图后保存的文件也可以看出。 . ├── fishbot_map.pgm └── fishbot_map.yaml 0 directories, 2 files 打开上节课建好的地图，观察下，你应该会有几点疑问： 不是说占据栅格地图每个栅格都有一个概率吗？为什么看不出来？ 立方体内和圆柱体内和墙之外的区域为什么是灰色的？ 原因如下： 一个栅格对应到图片上其实是一个像素，每一个像素的值在0-255之间，所以将像素值和占据率之间的映射即可，而像素值反应到图像上就是颜色的深浅，1.2图对应的像素颜色如下： 建图的时候物体内和墙之外的区域机器人并没有探索到，没有数据参考就认为其值是未知的。 四、地图描述文件.yaml介绍 除了fishbot_map.pgm文件外，还有另外一个fishbot_map.yaml的文件，fishbot_map.yaml文件是地图的配置文件，该文件内容如下： image: fishbot_map.pgm mode: trinary resolution: 0.05 origin: [ -3.37, -2.88, 0 ] negate: 0 occupied_thresh: 0.65 free_thresh: 0.25 image：图像名称 mode：图像模式，默认为trinary(三进制)，还有另外两个可选项scale(缩放的)和raw(原本的值)。 resolution：分辨率，一个栅格对应的物理尺寸，单位为m。0.05则表示一个栅格为0.05m origin：地图原点位置，单位是m。 negate：是否反转图像 cooupied_thresh：占据阈值 free_thresh：空闲阈值 如何在地图上找出机器人原点的像素位置？ 1、图像的像素原点在左下角 2、左边的0,0是地图原点，右边的图是图像的像素原点 3、假如机器人地图原点是[-3.37m, -2.88m]，除上分辨率则可得到像素原点[-67.4px,-57.6px]。地图原点在x和y轴分别偏移[-67.4px,-57.6px] 就到了像素原点，反过来说，地图原点就在像素原点的[67.4px,57.6px]处。 4、转换公式 像素点转地图点：地图点 = 地图原点 + (像素点 * 分辨率) 地图点转像素点：像素点= (地图点 - 地图原点) / 分辨率 五、编辑地图 最后我们来说一下如何对地图进行编辑，地图编辑的方法有很多，你可以手动改图片，也可以通过opencv等图像处理库进行图像的去除噪点等操作。 这里介绍的是手动添加一个地图用PS或Krita 进行编辑 。 打开网址：https://www.gaituya.com/ps/ 接着点击文件打开选择我们的.pgm文件，即可看到下图。 接着将下面的正方形给补上。 保存后在文件选择导出为png格式即可，因为PS并不支持pgm格式的导出，所以我们选择png格式，幸运的是png格式的地图也是被map_server所支持的。 把导出的图片放到map文件夹下，接着我们需要修改下yaml配置文件中图片的后缀。 image: fishbot_map.png mode: trinary resolution: 0.05 origin: [-3.37, -2.88, 0] negate: 0 occupied_thresh: 0.65 free_thresh: 0.25 六、总结 到这里我们总算把地图搞定了，接下来我们一起搞定导航。 "},"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/navigation/001-Nav2安装与配置.html":{"url":"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/navigation/001-Nav2安装与配置.html","title":"Nav2安装与配置","keywords":"","body":"datetime:2023/11/09 17:27 author:nzb 该项目来源于大佬的动手学ROS2 1. Navigation 2 介绍与安装 在正式介绍 Navigation 2 前，我们先来认识一个工具——行为树。BT （Behavior Tree）即行为树，起源于游戏设计中，用于控制游戏角色的行为，比如当僵尸出现时豌豆射手就会开始射击。对于一个移动机器人来说，需要知道什么时候要进行路径规划，什么时候要执行脱困，和游戏中的角色行为相似，所以使用行为树来描述和管理机器人的行再合适不过了，Navigation 2 就是使用它进行机器人行为调度的。 下图是 Navigation 2 的系统框架图，通过它可以让你对 Navigation 2 的架构有一个初步了解。 上图中最大的圆角矩形框内是 Navigation 2 的核心部分，向内的箭头是输入部分，向外的是输出部分。可以看到输入有 TF 变换、map 数据、雷达相机等传感器数据、行为树配置和目标位置。输出则只有一个即控制话题/cmd_vel ，就像我们使用键盘控制节点控制机器人移动一样，Navigation 2 最终会发布话题控制机器人移动。 接着我们来了解下 Navigation 2 的内部，首当其充的是 BT Navigator Server 即行为树导航服务，通过输入的 XML 格式的行为树描述文件，调用下面三个服务器中中对应的模块完成对机器人的行为控制。 接着是下面的三个服务模块。右边的是 Planner Server 即规划器服务器，它的任务就是负责全局路径规划。需要注意的是，这个模块叫规划器服务器，而不是具体某个规划器的原因是路径规划算法有很多，规划器服务器可以根据配置加载不同的规划器完成规划任务，这样就有了灵活性。这一点和上一章节 ros2_control 中控制器管理器相同，可以加载不同的控制器。 中间的模块是控制器服务器，该模块负责根据全局路径，结合实时障碍物和局部代价地图完成机器人的控制。需要注意的是，它同样只是一个服务器，可以加载多种不同的控制器完成这一任务。 左边的模块是恢复器服务器，可以加载不同的恢复行为完成机器人的脱困。从箭头可以看出，BT Navigation Server 收到目标点后，由规划器服务器进行 CP（ComputePathToPose）即计算路径 ，然后由控制器服务器进行 FP（FollowPath）即路径跟随，如果遇到卡住等困境则调用规划器服务器完成脱困。这三个模块协同工作，完成了整个 Navigation 2 的导航任务。 好了，关于 Navigation 2 理论的介绍就到这里，接着我们来安装并尝试使用它完成机器人导航。通过 apt 就可以完成 Navigation 2 的安装，命令如下： sudo apt info ros-$ROS_DISTRO-navigation2 为了方便使用 Navigation 2 还提供了启动示例功能包 nav2_bringup，使用下面的指令可以安装该功能包。 sudo apt info ros-$ROS_DISTRO-nav2-bringup 接下来我们就可以配置 Navigation 2 进行导航测试了。 2. 配置 Navigation 2 参数 我们把 Navigation 2 当作一个模块，只要给它正确的数据输入，它就可以正常工作。所以在启动导航前，需要对一些参数进行调整，以适配我们的仿真机器人，这些参数主要有相关话题名称，坐标系名称和机器人描述等。 nav2_bringup 已经为我们提供了一个默认的参数，我们只需要在它的基础上进行修改即可。在功能包 fishbot_navigation2 下创建 config 目录，接着我们将 nav2_bringup 提供的默认参数复制到 config 目录下，命令如下： cp /opt/ros/$ROS_DISTRO/share/nav2_bringup/params/nav2_params.yaml src/fishbot_navigation2/config 打开参数文件，可以看到有几百行的参数，不要害怕，这是因为将所有节点参数都放到同一个文件造成的，每一个节点的参数最多只有几十行。 参数名称中带有 topic 的基本都是关于话题的配置，比如 scan_topic 表示雷达数据话题名称，odom_topic 表示里程计话题名称。参数名称中带有 frame 的基本都是关于坐标系名称的配置，比如 odom_frame_id 表示里程计坐标系名称，robot_base_frame 表示机器人基础坐标系名称。仔细观察这些参数你会发现，它们默认值和我们上一章节机器人建模和仿真时，使用的值都是相同的，比如参数文件中默认里程计话题是 odom ，默认的雷达数据话题是 scan，默认的里程计坐标系是 odom，默认机器人基坐标系是 base_link。 除了修改话题和坐标系名称以保证数据的正确获取，在进行路径规划时还需要考虑机器人的大小即半径这一参数，如果半径设置的比真实的大，会造成窄的通道机器人过不去，如果过小则容易发生碰撞，因为是在基于地图做路径规划时才会考虑这一问题，所以机器人半径这一参数是在全局代价地图节点 global_costmap 和局部代价地图节点 local_costmap 进行配置的。分别修改两个代价地图节点robot_radius参数为建模时的半径，修改完成后对应参数值如下： local_costmap: local_costmap: ros__parameters: ... robot_radius: 0.08 global_costmap: global_costmap: ros__parameters: ... robot_radius: 0.08 好了，关于导航相关的参数我们就暂时设置这么多，如果想更深入的修改参数以调整 Navigation 2 ，可以参考官方文档 中的参数修改指南。 "},"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/navigation/002-启动导航和单点与路点导航.html":{"url":"ROS2/两轮差速移动机器人开发篇/第17章-建图与导航实现/navigation/002-启动导航和单点与路点导航.html","title":"启动导航和单点与路点导航","keywords":"","body":"datetime:2023/11/09 17:27 author:nzb 该项目来源于大佬的动手学ROS2 3. 编写 Launch 并启动导航 有了参数，接着我们来编写一个 Launch 文件来传递参数并启动导航。 在编写 launch 前，需要将slam部分建立好的地图保存拷贝一份到 src/fishbot_navigation2/maps 文件夹下。 一、编写Launch 在 fishbot_navigation2 功能包下新建 launch 目录，然后再目录下新建 navigation2.launch.py，输入如下代码： import os import launch import launch_ros from ament_index_python.packages import get_package_share_directory from launch.launch_description_sources import PythonLaunchDescriptionSource def generate_launch_description(): # 获取与拼接默认路径 fishbot_navigation2_dir = get_package_share_directory( 'fishbot_navigation2') nav2_bringup_dir = get_package_share_directory('nav2_bringup') rviz_config_dir = os.path.join( nav2_bringup_dir, 'rviz', 'nav2_default_view.rviz') # 创建 Launch 配置 use_sim_time = launch.substitutions.LaunchConfiguration( 'use_sim_time', default='false') map_yaml_path = launch.substitutions.LaunchConfiguration( 'map', default=os.path.join(fishbot_navigation2_dir, 'maps', 'fishbot_map.yaml')) nav2_param_path = launch.substitutions.LaunchConfiguration( 'params_file', default=os.path.join(fishbot_navigation2_dir, 'config', 'nav2_params.yaml')) return launch.LaunchDescription([ # 声明新的 Launch 参数 launch.actions.DeclareLaunchArgument('use_sim_time', default_value=use_sim_time, description='Use simulation (Gazebo) clock if true'), launch.actions.DeclareLaunchArgument('map', default_value=map_yaml_path, description='Full path to map file to load'), launch.actions.DeclareLaunchArgument('params_file', default_value=nav2_param_path, description='Full path to param file to load'), launch.actions.IncludeLaunchDescription( PythonLaunchDescriptionSource( [nav2_bringup_dir, '/launch', '/bringup_launch.py']), # 使用 Launch 参数替换原有参数 launch_arguments={ 'map': map_yaml_path, 'use_sim_time': use_sim_time, 'params_file': nav2_param_path}.items(), ), launch_ros.actions.Node( package='rviz2', executable='rviz2', name='rviz2', arguments=['-d', rviz_config_dir], parameters=[{'use_sim_time': use_sim_time}], output='screen'), ]) 我们让这个 Launch 对外提供三个可配置的参数，是否使用仿真时间 use_sim_time，地图文件路径 map_yaml_path 和导航参数路径 nav2_param_path，默认值都已经设好了。 接着修改 CMakeLists.txt，添加 launch、config 和 maps 三个目安装到 install 目录下的指令，然后重新构建功能包完成文件拷贝。 二、启动底盘和雷达 必要步骤，不再赘述 三、启动导航 colcon build source install/setup.bash ros2 launch fishbot_navigation2 navigation2.launch.py 启动后可以看到 RViz 已经正确加载出我们建的地图了，但是此时启动终端中会报 TF 相关的错误，这是因为我们还没有设定机器人初始位置。在 RViz 的工具栏可以看到如下图所示的几个操作按钮。 2D Pose Estimate 就是用于初始化位置的工具，而 Nav2 Goal 则是设置导航目标点的工具。选中 2D Pose Estimate，然后使用鼠标左键点击地图中机器人目前所在的大概位置，不要松开左键，拖动鼠标调整机器人朝向，如果觉得设置的不够准确，可以多次设置。 设置完成后，此时终端就不再报错了，初始化位置后的地图发生了些变化，初始化完成位置之后的地图如下图所示。 可以看到，原有的障碍物边界好像变都变大了，这个其实就是代价地图的膨胀图层，膨胀图层是 Navigation 2 为了防止机器人和障碍物发生碰撞，在原有的地图基础上，将图中障碍物的周围按照一定的半径进行膨胀形成的。 因为全局路径规划和局部路径规划使用的地图并不同，所以在机器人周围障碍物在会在局部代价地图上进行膨胀。在 RViz 左侧显示部分，修改 Global Planner 配置，取消全局代价地图 Global Costmap 的显示，配置如下左图所示，接着就可以看到如下右图所示的局部代价地图及其膨胀层了。 4.进行单点与路点导航 简单了解下地图结构，我们可以使用 Nav2 Goal 按钮给定目标点，让机器人自主进行导航。点击该工具，选择一个目标位置和朝向，就可以看到规划出来的全局路径，并且机器人已经开始移动了。 如果在机器人移动的过程中，放大图像，你将看到如下图所示的一条很短的蓝色线条，这个线条就是局部路径规划的结果。 接着我们来测试指定路点的导航，路点就是指路过的点，比如你要从家前往学校可以有多个路线，但你希望可以经过某家店买些东西，就可以指定要经过这家店。使用路点导航，Navigation 2 就会在规划路径按照你指定的顺序进行导航。 通过这个插件可以取消导航任务，也可以设置多个目标点的导航，点击最下面的 Waypoint/Nav Through Poses Mode ，接着使用 Nav2 Goal 依次设置多个路点，比如下图中设置了五个路点，让机器人绕过咖啡桌再到左前方的目标点。 设置完成后，就可以开启路点导航了。如下图所示在 RViz 的左下角的窗口上有三个按钮，点击最下面一个 Start Waypoint Follwing 就可以启动路点导航。 接着就可以看到机器人依次走向每一个目标点了，行走路径如下图所示。 5.使用API进行导航 Navigation 2 对外提供了动作服务用于导航调用。动作通信是 ROS 2 四大通讯机制之一。 动作通信和其名字一样，主要用于控制场景，它的优点在于其反馈机制，当客户端发送目标给服务端后，除了等待服务端处理完成，还可以收到服务端的处理进度。启动导航后在终端中使用动作相关命令可以查看当前系统所有动作列表，命令及结果如下： ros2 action list -- /assisted_teleop /backup /compute_path_through_poses /compute_path_to_pose /drive_on_heading /follow_path /follow_waypoints /navigate_through_poses /navigate_to_pose /smooth_path /spin /wait 其中 /navigate_to_pose 就是用于处理导航到点请求的动作。继续使用命令查看该动作的具体信息。 ros2 action info /navigate_to_pose -t --- Action: /navigate_to_pose Action clients: 4 /bt_navigator [nav2_msgs/action/NavigateToPose] /waypoint_follower [nav2_msgs/action/NavigateToPose] /rviz2 [nav2_msgs/action/NavigateToPose] /rviz2 [nav2_msgs/action/NavigateToPose] Action servers: 1 /bt_navigator [nav2_msgs/action/NavigateToPose] 可以看到该动作的客户端、服务端以及消息接口情况，使用指令查看 nav2_msgs/action/NavigateToPose 接口定义，命令及结果如下： ros2 interface show nav2_msgs/action/NavigateToPose --- #goal definition geometry_msgs/PoseStamped pose std_msgs/Header header builtin_interfaces/Time stamp int32 sec uint32 nanosec string frame_id Pose pose Point position float64 x float64 y float64 z Quaternion orientation float64 x 0 float64 y 0 float64 z 0 float64 w 1 string behavior_tree --- #result definition std_msgs/Empty result --- #feedback definition geometry_msgs/PoseStamped current_pose std_msgs/Header header builtin_interfaces/Time stamp int32 sec uint32 nanosec string frame_id Pose pose Point position float64 x float64 y float64 z Quaternion orientation float64 x 0 float64 y 0 float64 z 0 float64 w 1 builtin_interfaces/Duration navigation_time int32 sec uint32 nanosec builtin_interfaces/Duration estimated_time_remaining int32 sec uint32 nanosec int16 number_of_recoveries float32 distance_remaining 从该接口定义可以看出，动作消息的接口分为目标、结果和反馈三个部分，相比服务通信接口的目标和结果多出了反馈这一部分。如果在机器人导航时仔细观察 RViz 左下角 Navigation 2 部分，你会发现它会实时的显示当前导航所花费的时间，距离目标点之间的距离，花费的时间以及脱困次数，这些数据就是来自动作服务的反馈部分。 使用命令行工具可以发送动作请求并接收反馈和结果，以请求机器人移动到地图的指定目标点为例，命令及反馈如下。 ros2 action send_goal /navigate_to_pose nav2_msgs/action/NavigateToPose \"{pose: {header: {frame_id: map}, pose: {position: {x: 2, y: 2}}}}\" --feedback --- Waiting for an action server to become available... Sending goal: pose: header: stamp: sec: 0 nanosec: 0 frame_id: map pose: position: x: 2.0 y: 2.0 z: 0.0 orientation: x: 0.0 y: 0.0 z: 0.0 w: 1.0 behavior_tree: '' Goal accepted with ID: c5c52646de774f55b4ee71ca5ed3267a ... Feedback: current_pose: header: stamp: sec: 4679 nanosec: 504000000 frame_id: map pose: position: x: 2.079677095742107 y: 1.947119186243544 z: 0.09189999999999998 orientation: x: 0.0 y: 0.0 z: 0.054114175706008266 w: 0.998534754521674 navigation_time: sec: 18 nanosec: 164000000 estimated_time_remaining: sec: 0 nanosec: 0 number_of_recoveries: 2 distance_remaining: 0.10830961167812347 Result: result: {} Goal finished with status: SUCCEEDED 上面的命令用于请求机器人移动到地图坐标系中的 xy 都为 2.0 的点，反馈结果中，Sending goal 部分表示目标，Feedback 部分是反馈，Result 部分为最终结果。 要灵活使用自然还需要学习如何用代码调用，在 Python 中 nav2_simple_commander 库已经将动作客户端代码封装到 BasicNavigator 节点中，使用该节点的对应函数就可以实现导航操作。在 src/fishbot_application/fishbot_application 下新建文件 nav_to_pose.py，然后编写如下代码： from geometry_msgs.msg import PoseStamped from nav2_simple_commander.robot_navigator import BasicNavigator, TaskResult import rclpy from rclpy.duration import Duration def main(): rclpy.init() navigator = BasicNavigator() # 等待导航启动完成 navigator.waitUntilNav2Active() # 设置目标点坐标 goal_pose = PoseStamped() goal_pose.header.frame_id = 'map' goal_pose.header.stamp = navigator.get_clock().now().to_msg() goal_pose.pose.position.x = 1.0 goal_pose.pose.position.y = 1.0 goal_pose.pose.orientation.w = 1.0 # 发送目标接收反馈结果 navigator.goToPose(goal_pose) while not navigator.isTaskComplete(): feedback = navigator.getFeedback() navigator.get_logger().info( f'预计: {Duration.from_msg(feedback.estimated_time_remaining).nanoseconds / 1e9} s 后到达') # 超时自动取消 if Duration.from_msg(feedback.navigation_time) > Duration(seconds=600.0): navigator.cancelTask() # 最终结果判断 result = navigator.getResult() if result == TaskResult.SUCCEEDED: navigator.get_logger().info('导航结果：成功') elif result == TaskResult.CANCELED: navigator.get_logger().warn('导航结果：被取消') elif result == TaskResult.FAILED: navigator.get_logger().error('导航结果：失败') else: navigator.get_logger().error('导航结果：返回状态无效') 上面的代码中有关键函数有四个，第一个是 navigator.goToPose 用于发布目标，第二个是 navigator.getFeedback() 用于获取状态反馈，第三个是 navigator.cancelTask() 用于中途取消，第四个是 navigator.getResult() 用于获取最终结果。跳转到 goToPose 的源码可以发现最终发送请求是通过 self.nav_to_pose_client.send_goal_async 函数完成的，而 nav_to_pose_client 就是在 BasicNavigator 函数中定义的动作客户端，定义代码如下： self.nav_to_pose_client = ActionClient(self, NavigateToPose, 'navigate_to_pose') 保存好代码，注册该节点并重新构建功能包，再次运行仿真和导航，初始化位姿后启动该节点，观察 RViz 中机器人运动情况，启动命令及终端打印如下。 ros2 run fishbot_application nav_to_pose --- [INFO] [1685599886.677153365] [basic_navigator]: Nav2 is ready for use! [INFO] [1685599886.707280550] [basic_navigator]: Navigating to goal: 1.0 1.0... [INFO] [1685599886.852565845] [basic_navigator]: 预计剩余: 0.0 s [INFO] [1685599891.432155882] [basic_navigator]: 预计剩余: 170.591972225 s [INFO] [1685599891.532646643] [basic_navigator]: 预计剩余: 98.418445514 s [INFO] [1685599891.635079916] [basic_navigator]: 预计剩余: 77.541805557 s [INFO] [1685599914.104374413] [basic_navigator]: 预计剩余: 1.833780316 s ... [INFO] [1685599918.156745102] [basic_navigator]: 导航结果：成功 使用 Python 可以通过调用 nav2_simple_commander 库方便的实现导航，但如果项目需要换成 C++ 也并不复杂，使用动作客户端也可以方便的调用，如何实现我并不打算再操作一遍，但我将提供给你一份详细的 C++ 调用导航服务的实现代码。 #include #include \"nav2_msgs/action/navigate_to_pose.hpp\" // 导入导航动作消息的头文件 #include \"rclcpp/rclcpp.hpp\" // 导入ROS 2的C++客户端库 #include \"rclcpp_action/rclcpp_action.hpp\" // 导入ROS 2的C++ Action客户端库 using NavigationAction = nav2_msgs::action::NavigateToPose; // 定义导航动作类型为NavigateToPose class NavToPoseClient : public rclcpp::Node { public: using NavigationActionClient = rclcpp_action::Client; // 定义导航动作客户端类型 using NavigationActionGoalHandle = rclcpp_action::ClientGoalHandle; // 定义导航动作目标句柄类型 NavToPoseClient() : Node(\"nav_to_pose_client\") { // 创建导航动作客户端 action_client_ = rclcpp_action::create_client( this, \"navigate_to_pose\"); } void sendGoal() { // 等待导航动作服务器上线，等待时间为5秒 while (!action_client_->wait_for_action_server(std::chrono::seconds(5))) { RCLCPP_INFO(get_logger(), \"等待Action服务上线。\"); } // 设置导航目标点 auto goal_msg = NavigationAction::Goal(); goal_msg.pose.header.frame_id = \"map\"; // 设置目标点的坐标系为地图坐标系 goal_msg.pose.pose.position.x = 2.0f; // 设置目标点的x坐标为2.0 goal_msg.pose.pose.position.y = 2.0f; // 设置目标点的y坐标为2.0 auto send_goal_options = rclcpp_action::Client::SendGoalOptions(); // 设置请求目标结果回调函数 send_goal_options.goal_response_callback = [this](NavigationActionGoalHandle::SharedPtr goal_handle) { if (goal_handle) { RCLCPP_INFO(get_logger(), \"目标点已被服务器接收\"); } }; // 设置移动过程反馈回调函数 send_goal_options.feedback_callback = [this]( NavigationActionGoalHandle::SharedPtr goal_handle, const std::shared_ptr feedback) { (void)goal_handle; // 假装调用，避免 warning: unused RCLCPP_INFO(this->get_logger(), \"反馈剩余距离:%f\", feedback->distance_remaining); }; // 设置执行结果回调函数 send_goal_options.result_callback = [this](const NavigationActionGoalHandle::WrappedResult& result) { if (result.code == rclcpp_action::ResultCode::SUCCEEDED) { RCLCPP_INFO(this->get_logger(), \"处理成功！\"); } }; // 发送导航目标点 action_client_->async_send_goal(goal_msg, send_goal_options); } NavigationActionClient::SharedPtr action_client_; }; int main(int argc, char** argv) { rclcpp::init(argc, argv); auto node = std::make_shared(); node->sendGoal(); rclcpp::spin(node); rclcpp::shutdown(); return 0; } "},"ROS2/ROS2常用代码模板/001-rclcpp.html":{"url":"ROS2/ROS2常用代码模板/001-rclcpp.html","title":"rclcpp","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 Rclcpp：节点和组件 创建组件 #include namespace my_pkg { class MyComponent : public rclcpp::Node { public: MyComponent(const rclcpp::NodeOptions& options) : rclcpp::Node(\"node_name\", options) { // Note: you cannot use shared_from_this() // here because the node is not fully // initialized. } }; } // namespace my_pkg #include \"rclcpp_components/register_node_macro.hpp\" RCLCPP_COMPONENTS_REGISTER_NODE(my_pkg::MyComponent) CMakeLists.txt 中的： add_library(my_component SHARED src/my_component.cpp ) ament_target_dependencies(my_component rclcpp rclcpp_components ) # Also add a node executable which simply loads the component rclcpp_components_register_node(my_component PLUGIN \"my_pkg::MyComponent\" EXECUTABLE my_node ) Executors 要在线程中运行执行器，请执行以下操作： #include #include #include rclcpp::executors::SingleThreadedExecutor executor; // Node is rclcpp::Node::SharedPtr instance executor.add_node(node); std::thread executor_thread( std::bind(&rclcpp::executors::SingleThreadedExecutor::spin, &executor)); Rclcpp：参数 需要声明参数。同时，如果你不打算稍后再次更新值，则可以获得该值： // node is an instance of rclcpp::Node // 42 is a great default for a parameter int param = node.declare_parameter(\"my_param_name\", 42); 要获取值，请执行以下操作： int param; node.get_parameter(\"my_param_name\", param); 动态参数 在 ROS2 中，所有参数都可以通过 ROS2 服务动态更新(不需要像动态重新配置那样定义重复内容)。 下面的例子适用于 eloquent 或更高版本(较早的 ROS2 版本只支持单个回调，并且有一个略有不同的 API)。有关有效类型的信息，请参阅的文档。 #include #include class MyNode : public rclcpp::Node { public: MyNode() { // Declare parameters first // Then create callback param_cb_ = this->add_on_set_parameters_callback( std::bind(&MyNode::updateCallback, this, std::placeholders::_1)); } private: // This will get called whenever a parameter gets updated rcl_interfaces::msg::SetParametersResult updateCallback( const std::vector & parameters) { rcl_interfaces::msg::SetParametersResult result; result.successful = true; for (const rclcpp::Parameter & param : parameters) { if (param.get_name() == \"my_param_name\") { if (param.get_type() != rclcpp::ParameterType::PARAMETER_STRING) { result.successful = false; result.reason = \"my_param_name must be a string\"; break; } // Optionally do something with parameter } } return result; } // Need to hold a pointer to the callback rclcpp::node_interfaces::OnSetParametersCallbackHandle::SharedPtr param_cb_; }; Rclcpp：TF2 TF2 库提供了对转换的轻松访问。以下所有示例都需要对 tf2_ros 的依赖关系。 发布TF #include std::unique_ptr broadcaster; broadcaster = std::make_unique(nodePtr); geometry_msgs::msg::TransformStamped transform; transform.header.stamp = node->now(); transform.header.frame_id = \"odom\"; transform.child_frame_id = \"base_link\"; // Fill in transform.transform.translation // Fill in transform.transform.rotation broadcaster->sendTransform(transform); 监听TF #include \"tf2_ros/transform_listener.h\" std::shared_ptr tf_buffer; std::shared_ptr tf_listener; rclcpp::Node node(\"name_of_node\"); tf_buffer.reset(new tf2_ros::Buffer(node.get_clock())); tf_listener.reset(new tf2_ros::TransformListener(*tf_buffer_)); TF变换 TF2 可以通过提供实现的包进行扩展。GEOMETRYmsgs 程序包为 msgs 提供这些。下面的示例使用 msgs::msg::PointStamed，但这应该适用于 msgs 中的任何数据类型： #include geometry_msg::msgs::PointStamped in, out; in.header.frame_id = \"source_frame\"; try { tf_buffer->transform(in, out, \"target_frame\"); } catch (const tf2::TransformException& ex) { RCLCPP_ERROR(rclcpp::get_logger(\"logger_name\"), \"Could not transform point.\"); } transform 函数还可以接受超时。然后它将等待转换可用的时间达到这个时间量: tf_buffer->transform(in, out, \"target_frame\", tf2::durationFromSec(1.0)); 获取最新TF 常见的工作方式是获得“最新”转换。在 ros2中，这可以使用 tf2::TimePointZero 来实现，但是需要使用 lookupTransform 然后调用 doTransform (基本上就是在内部进行转换) : geometry_msgs::msg::PointStamped in, out; geometry_msgs::msg::TransformStamped transform = tf_buffer->lookupTransform(\"target_frame\", in.header.frame_id, tf2::TimePointZero); tf2::doTransform(in, out, transform); rclcpp: Time rclcpp::Time 和 rclcpp::Duration 和ROS1中的用法偏差较大，但与std::chrono 的关系更为密切。ROS Discourse 可以看到与其有关的比较深入的讨论。 在移植某些ros1库时，时间戳可能会被大量用作浮点秒。从 rclcpp 获取浮点秒 rclcpp::Time: // node is instance of rclcpp::Node rclcpp::Time t = node.now(); double seconds = t.seconds(); 没有用于从浮点表示的秒开始的时间的构造函数，因此你首先需要转换为纳秒： rclcpp::Time t(static_cast(seconds * 1e9)); 确实具有双向功能： rclcpp::Duration d = rclcpp::Duration::from_seconds(1.0); double seconds = d.seconds(); rclcpp: Point Clouds sensor_msgs/PointCloud2 是一种非常常见的 ROS 消息类型，用于处理 ROS 中的感知数据。这也是实际要解释的最复杂的信息之一。 消息的复杂性源于它在单个巨型数据存储中包含任意字段这一事实。这允许 PointCloud2 消息与任何类型的云(例如，仅 XYZ 点、XYZRGB，甚至 XYZI)一起工作，但在访问云中的数据时增加了一些复杂性。 在 ROS1 中，有一个更简单的 PointCloud 消息，但这已经被删除，并将在 ROS2-G 中删除。 使用 PointCloud2 迭代器 sensor_msgs 包提供了一个 C++ PointCloud2Iterator，可用于创建、修改和访问 PointCloud2 消息。 要创建新消息： #include \"sensor_msgs/msg/point_cloud2.hpp\" #include \"sensor_msgs/point_cloud2_iterator.hpp\" sensor_msgs::msg::PointCloud2 msg; // Fill in the size of the cloud msg.height = 480; msg.width = 640; // Create the modifier to setup the fields and memory sensor_msgs::PointCloud2Modifier mod(msg); // Set the fields that our cloud will have mod.setPointCloud2FieldsByString(2, \"xyz\", \"rgb\"); // Set up memory for our points mod.resize(msg.height * msg.width); // Now create iterators for fields sensor_msgs::PointCloud2Iterator iter_x(cloud_msg, \"x\"); sensor_msgs::PointCloud2Iterator iter_y(cloud_msg, \"y\"); sensor_msgs::PointCloud2Iterator iter_z(cloud_msg, \"z\"); sensor_msgs::PointCloud2Iterator iter_r(cloud_msg, \"r\"); sensor_msgs::PointCloud2Iterator iter_g(cloud_msg, \"g\"); sensor_msgs::PointCloud2Iterator iter_b(cloud_msg, \"b\"); for (; iter_x != iter_x.end(); ++iter_x, ++iter_y, ++iter_z, ++iter_r, ++iter_g, ++iter_b) { *iter_x = 0.0; *iter_y = 0.0; *iter_z = 0.0; *iter_r = 0; *iter_g = 255; *iter_b = 0; } 使用 PCL 对于许多操作，你可能希望转换为 pcl::PointCloud 以便使用的扩展 API Point Cloud Library。 在 ROS1 ，pcl_ros 包允许你编写一个订阅者，它的回调直接接受 pcl::PointCloud，但是这个包还没有被移植到 ROS2. 无论如何，使用 pcl_conversions 包自己进行转换是非常简单的： #include \"pcl_conversions/pcl_conversions.h\" void cloud_callback(const sensor_msgs::msg::PointCloud2::SharedPtr msg) { // PCL still uses boost::shared_ptr internally pcl::PointCloud::Ptr cloud = boost::make_shared>(); // This will convert the message into a pcl::PointCloud pcl::fromROSMsg(*msg, *cloud); } 反之，你也可以反方向转换： #include \"pcl_conversions/pcl_conversions.h\" pcl::PointCloud::Ptr cloud; sensor_msgs::msg::PointCloud2 msg; pcl::toROSMsg(*cloud, msg); cloud_publisher->publish(msg); rclcpp: Workarounds 懒订阅 ROS2 还没有订阅连接回叫。此代码创建一个函数，定期调用该函数来检查我们是否需要启动或停止订阅者： #include #include class LazyPublisherEx : rclcpp::Node { public: LazyPublisherEx(const rclcpp::NodeOptions & options) : Node(\"lazy_ex\", options) { // Setup timer timer = this->create_wall_timer( std::chrono::seconds(1), std::bind(&LazyPublisher::periodic, this)); } private: void periodic() { if (pub_.get_subscription_count() > 0) { // We have a subscriber, do any setup required } else { // Subscriber has disconnected, do any shutdown } } rclcpp::Publisher::SharedPtr pub_; rclcpp::TimerBase::SharedPtr timer_; }; 在使用图像传输时也可以这样做，你只需要将 get_subscription_count 更改为 getNumSubscribers: #include #include class LazyPublisherEx : rclcpp::Node { public: LazyPublisherEx(const rclcpp::NodeOptions & options) : Node(\"lazy_ex\", options) { // Setup timer timer = this->create_wall_timer( std::chrono::seconds(1), std::bind(&LazyPublisher::periodic, this)); } private: void periodic() { if (pub_.getNumSubscribers() > 0) { // We have a subscriber, do any setup required } else { // Subscriber has disconnected, do any shutdown } } image_transport::CameraPublisher pub_; rclcpp::TimerBase::SharedPtr timer_; }; "},"ROS2/ROS2常用代码模板/002-rclpy.html":{"url":"ROS2/ROS2常用代码模板/002-rclpy.html","title":"rclpy","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 rclpy：节点基础知识 大多数节点都有发布者和订阅者，它们都是通过调用实例的函数创建的： import rclpy from rclpy.node import Node from std_msgs.msg import String class MyNode(Node): def __init__(self): super().__init__('my_node_name') self.publisher = self.create_publisher(String, 'output_topic', 10) self.subscription = self.create_subscription( String, 'input_topic', self.callback, 10) def callback(self, msg): self.get_logger().info(\"Recieved: %s\" % msg.data) self.publisher.publish(msg) if __name___ == \"__main__\": rclpy.init() my_node = MyNode() rclpy.spin(my_node) my_node.destroy_node() # cleans up pub-subs, etc rclpy.shutdown() 关闭Handle ROS1 有rospy.on_shutdown() - 但是 不等于ROS2也有 ，不过，这真的不需要，因为我们手动关闭了一些东西，而不是像 rospy 那样使用了许多全局变量: try: rclpy.spin(my_node) except KeyboardInterrupt: pass finally: my_node.on_shutdown() # do any custom cleanup my_node.destroy_node() rclpy.shutdown() rclpy：参数 # node is rclpy.node.Node instance # 42 is a great default for a parameter node.declare_parameter(\"my_param_name\", 42) # To get the value: param = node.get_parameter(\"my_param_name\").value 动态参数 在 ROS2 中，所有参数都可以通过 ROS2 服务动态更新(不需要像动态重新配置那样定义重复内容)。 from rcl_interfaces.msg import SetParametersResult import rclpy from rclpy.node import Node class MyNode(Node): def __init__(self): super().__init__('my_node_name') # Declare a parameter self.declare_parameter(\"my_param_name\", 42) # Then create callback self.set_parameters_callback(self.callback) def callback(self, parameters): result = SetParametersResult(successful=True) for p in parameters: if p.name == \"my_param_name\": if p.type_ != p.Type.INTEGER: result.successful = False result.reason = 'my_param_name must be an Integer' return result if p.value = 20\" return result # Return success, so updates are seen via get_parameter() return result 有关调用 SET_PARAMETERS 服务的示例，请参阅 ROS Answers RCLPY：TF2 TF2 库提供了对转换的轻松访问。以下所有示例都需要对 ros_Package 的依赖关系。 监听转换 import rclpy from rclpy.node import Node from tf2_ros.buffer import Buffer from tf2_ros.transform_listener import TransformListener class MyNode(Node): def __init__(self): super().__init__(\"my_node\") self.buffer = Buffer() self.listener = TransformListener(self.buffer, self) 应用变换 TF2 可以通过提供实现的包进行扩展。GEOMETRYmsgs 程序包为 msgs 提供这些。下面的示例使用 msgs.msg.PointStamed，但这应该适用于 msgs 中的任何数据类型： from geometry_msgs.msg import PointStamped from tf2_ros.buffer import Buffer from tf2_ros.transform_listener import TransformListener import tf2_geometry_msgs # Setup buffer/listener as above p1 = PointStamped() p1.header.frame_id = \"source_frame\" # fill in p1 p2 = buffer.transform(p1, \"target_frame\") 变换 在 ROS1 中，Tf 包括模块。TF2 没有类似的模块。建议使用 Transforms3d Python 包，可通过 pip 获取： sudo pip3 install transforms3d 例如，要旋转点： import numpy as np from transforms3d.quaternion import quat2mat # Create rotation matrix from quaternion R = quat2mat([w, x, y, z]) # Create a vector to rotate V = np.array([x, y, z]).reshape((3, 1)) # Rotate the vector M = np.dot(R, V) p = PointStamped() p.point.x = M[0, 0] p.point.y = M[1, 0] p.point.z = M[2, 0] rclpy: Time 要获得相当于 rospy.Time.now()的内容，你现在需要一个 ROS2 节点： import rclpy from rclpy.node import Node class MyNode(Node): def some_func(self): t = self.get_clock().now() msg.header.stamp = t.to_msg() 从持续时间转换为消息很常见： import rclpy from rclpy.duration import Duration msg.duration = Duration(seconds=1).to_msg() 计时器是从节点创建的： import rclpy from rclpy.node import Node class MyNode(Node): def __init__(self): super().__init__(\"my_node\") # Create a timer that fires every quarter second timer_period = 0.25 self.timer = self.create_timer(timer_period, self.callback) def callback(self): self.get_logger().info(\"timer has fired\") "},"ROS2/ROS2常用代码模板/003-urdf.html":{"url":"ROS2/ROS2常用代码模板/003-urdf.html","title":"urdf","keywords":"","body":"datetime:2023/09/25 10:22 author:nzb 该项目来源于大佬的动手学ROS2 Gazebo常用插件 1.雷达 详细介绍及文章： 9.5给机器人添加激光传感器 true true 5 0 0 0.075 0 0 0 360 1.000000 0.000000 6.280000 0.120000 3.5 0.015000 gaussian 0.0 0.01 ~/out:=scan sensor_msgs/LaserScan laser_link 2.IMU 详细介绍及文章： 9.4为FishBot添加IMU传感器.md / ~/out:=imu false true 100 true 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 2e-4 0.0000075 0.0000008 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 0.0 1.7e-2 0.1 0.001 3.超声波 详细介绍及文章： 9.6拓展-为Fishbot添加超声波传感器.md 0 0 0 0 0 0 true 5 5 1 -0.12 0.12 5 1 -0.01 0.01 0.02 4 0.01 gaussian 0.0 0.01 ~/out:=ultrasonic_sensor_1 sensor_msgs/Range ultrasound ultrasonic_sensor_link 4.两轮差速 详细介绍及文章： 9.3为FishBot配置两轮差速控制插件.md / cmd_vel:=cmd_vel odom:=odom 30 left_wheel_joint right_wheel_joint 0.2 0.065 20 1.0 true true true odom base_footprint 5.JointStatePublisher 待补充 6.单目相机 30.0 1.3962634 800 800 R8G8B8 0.02 300 gaussian 0.0 0.007 true 0.0 /camera image_raw camera_info camera_link 0.07 Gazebo/Blue 7.深度相机 待补充 ROS2中常用的Xacro模板 URDF默认格式是纯文本的，我们并不能在其中加入计算公式和定义，用URDF定义一个机器人模型会导致整个文件非常冗长，使用Xacro工具可以解决这个问题。 Xacro是urdf的定义和生成工具，你按照Xacro提供的方式定义可以复用的模型描述块，之后就可以直接调用这些描述，最后使用xacro指令生成最终的urdf模型了。 1.添加模板 这里提供了常用的xacro描述定义的代码块，你可以直接引入的你的工程里进行使用。 在你的功能包里新建xacro_template.xacro文件，复制粘贴下面的内容到其中。 2.使用模板生成URDF 接着你可以新建你的机器人模型描述文件，比如fishbot.urdf.xacro,之后你就可以在你的描述文件中调用提供的模板，快速的定义机器人。 比如创建一个正方体的base_link,并导入惯性矩阵。 上面w,d,h,代表长宽高，m代表质量。用于引入提供的模板。 接着我们就可以通过xacro指令将其变成正常的urdf，打开终端，进入fishbot.urdf.xacro同级目录，输入指令xacro fishbot.urdf.xacro -o fishbot.urdf ,即可生成fishbot.urdf，正常生成后的内容如下。 这就是xacro的神奇之处，将短短的三行定义根据规则生成长长的URDF，关于xacro的详细使用可以参考 http://ros.org/wiki/xacro 。 "},"Navigation2/源码分析/001-核心定义.html":{"url":"Navigation2/源码分析/001-核心定义.html","title":"核心定义","keywords":"","body":"datetime:2024/01/10 18:18 author:nzb 导航 https://github.com/ros-planning/navigation2.git 分支：humble 节点：3ed4c2d 核心定义 nav2_core ｜ Nav2核心包 navigation2 | nav2导航汇总配置 nav2_core 包含一些核心抽象类 Behavior-行为抽象类 configure：纯虚函数，配置 cleanup：纯虚函数，清理 activate：纯虚函数，激活 deactivate：纯虚函数，取消激活 Controller-控制抽象类 configure：纯虚函数，配置 cleanup：纯虚函数，清理 activate：纯虚函数，激活 deactivate：纯虚函数，取消激活 setPlan：纯虚函数，设置全局规划（目标位置） computeVelocityCommands：纯虚函数，计算最佳的位置和命令指令，依赖于已经给了全局规划（位置） setSpeedLimit：纯虚函数，设置速度限制 PlannerException-异常基类 GlobalPlanner-全局规划抽象类 configure：纯虚函数，配置 cleanup：纯虚函数，清理 activate：纯虚函数，激活 deactivate：纯虚函数，取消激活 createPlan：纯虚函数，给定起点和目标点生成规划 GoalChecker-目标到达检测抽象类 检测机器人是否到达目标位置 initialize：纯虚函数，参数初始化 reset：纯虚函数，重置 isGoalReached：纯虚函数，是否到达目标位置 getTolerances：纯虚函数，获取容差（允许误差值） ProgressChecker-机器人到目标点过程检测抽象类 检测机器人是否在去目标位置的过程 initialize：纯虚函数，参数初始化 check：纯虚函数，检查 reset：纯虚函数，重置 Smoother-平滑抽象类 configure：纯虚函数，配置 cleanup：纯虚函数，清理 activate：纯虚函数，激活 deactivate：纯虚函数，取消激活 smooth：纯虚函数，实现平滑的函数 WaypointTaskExecutor-路点任务执行抽象类 initialize：纯虚函数，参数初始化 processAtWaypoint：纯虚函数，设置定义机器人到达航路点后，想要执行的任务主体，比如搬个货架 "},"Navigation2/源码分析/002-通用插件系统管理.html":{"url":"Navigation2/源码分析/002-通用插件系统管理.html","title":"通用插件系统管理","keywords":"","body":"datetime:2024/01/10 18:18 author:nzb 导航 https://github.com/ros-planning/navigation2.git 分支：humble 节点：3ed4c2d 通用插件系统管理 nav2_bringup | 启动入口 nav2_common ｜ 公共功能包 nav2_msgs ｜ 通信相关消息定义 nav2_util | 常用工具 nav2_lifecycle_manager |节点生命周期管理器 nav2_rviz_plugins | RVIZ插件 nav2_bringup 包含launch、maps、params、rviz、urdf、world等配置文件 nav2_common HasNodeParams：检查配置参数是否有某个节点的参数配置 ParseMultiRobotPose：解析多个机器人位置 ReplaceString：修改配置文件里面的某些字符串 RewrittenYaml：重写配置文件里面的某些参数 nav2_util simple_action_server.hpp ServiceClient：ROS2服务的简单包装器模板类 invoke：调用，返回结果智能指针 invoke：调用，返回成功与否，布尔类型结果 wait_for_service：等待服务可达 getServiceName：获取服务名 service_client.hpp SimpleActionServer：ROS2动作的简单包装器模板类 SimpleActionServer：构造函数重要属性 execute_callback：执行回调 completion_callback：完成回调 handle_goal：处理请求，永远接受，除非服务未启 handle_cancel：处理取消 handle_accepted：处理接受，调用work work：函数内调用execute_callback、completion_callback、accept_pending_goal activate：激活 deactivate：取消激活 is_running：是否运行中 is_server_active：服务是否激活 is_preempt_requested：是否抢占式请求 accept_pending_goal：接受新任务 terminate_pending_goal：终止待定任务 get_current_goal：获取当前任务 get_current_goal_id：获取当前任务ID get_pending_goal：获取待定任务 is_cancel_requested：是否有取消命令到来 terminate_all：终止所有任务 terminate_current：终止当前任务 succeeded_current：设置当前任务完成 publish_feedback：发布反馈信息 string_utils.hpp strip_leading_slash：去掉前导斜线，用于topic名称切割 split：字符串分割 robot_utils.hpp getCurrentPose：获取当前位姿 transformPoseInTargetFrame：获取目标帧位姿 getTransform：获取从源坐标系到目标坐标系的变换，仅适用于在源坐标系和目标坐标系之间进行变换，不考虑时间戳信息 getTransform：获取从源坐标系到目标坐标系的变换。该函数提供了源坐标系的时间戳和目标坐标系的时间戳，会考虑源坐标系和目标坐标系之间的时间偏差，并在给定的容忍度范围内查找最近的变换。 validateTwist：校验速度指令数据是否合法 odometry_utils.hpp：里程计平滑器，订阅odom话题，使用简单的移动平均值做的平滑器 OdomSmoother：构造函数 getTwist：获取twist getTwistStamped：获取待时间戳的twist odomCallback：话题回调，调用updateState updateState：当获取到新数据的时候，使用移动平均值更新数据 occ_grid_values.hpp：占用网格，数据常量 OCC_GRID_UNKNOWN：占用未知 OCC_GRID_FREE：未占用 OCC_GRID_OCCUPIED：占用 node_utils.hpp sanitize_node_name：替换潜在节点名称中的无效字符，把不是字母数字的字符替换成_ add_namespaces：添加命名空间 generate_internal_node_name：生成内部节点名称 time_to_string：生成伪随机数字字符串 generate_internal_node：生成节点 declare_parameter_if_not_declared：声明静态 ROS2 参数并将其设置为给定值（如果尚未声明） declare_parameter_if_not_declared：如果尚未声明，则声明具有给定类型的静态 ROS2 参数 get_plugin_type_param：获取所选节点的插件类型及其插件 copy_all_parameters：将所有参数从一个节点（父节点）复制到另一个节点（子节点）的方法 node_thread.hpp：用于处理节点回调构造函数的后台线程 NodeThread(rclcpp::node_interfaces::NodeBaseInterface::SharedPtr node_base)：用于处理节点回调构造函数的后台线程 NodeThread(rclcpp::executors::SingleThreadedExecutor::SharedPtr executor)：处理执行器回调构造函数的后台线程 line_iterator.hpp：实现 Bresenham 算法的光线追踪的迭代器 LineIterator(int x0, int y0, int x1, int y1)：构造函数，接收起点和终点的坐标作为参数。 isValid()：检查迭代器是否有效，即是否仍然有点可迭代。 advance()：将迭代器前进到下一个点。 getX()：获取当前点的 X 坐标。 getY()：获取当前点的 Y 坐标。 getX0()：获取起点的 X0 坐标。 getY0()：获取起点的 Y0 坐标。 getX1()：获取终点的 X1 坐标。 getY1()：获取终点的 Y1 坐标。 lifecycle_node.hpp：生命周期节点包装器（继承于rclcpp_lifecycle::LifecycleNode），可满足常见的 Nav2 需求，例如操作参数 LifecycleNode：构造函数，调用printLifecycleNodeNotification、register_rcl_preshutdown_callback ~LifecycleNode：析构函数，调用runCleanups，移除预关闭回调 add_parameter：添加参数，声明没有整数或浮点范围限制的参数 add_parameter：添加参数，声明有浮点范围限制的参数 add_parameter：添加参数，声明有整数范围限制的参数 shared_from_this：获取当前实例的共享指针 on_error：错误回调 on_rcl_preshutdown：在我们的上下文关闭之前执行预关闭活动。请注意，这与我们的 Context 的关闭顺序有关，而不是生命周期节点状态机。 调用runCleanups、destroyBond createBond：创建与生命周期管理器的绑定连接 destroyBond：销毁与生命周期管理器的绑定连接 printLifecycleNodeNotification：打印生命周期节点的通知 register_rcl_preshutdown_callback：为该节点的 rcl 上下文注册我们的预关闭回调 回调在该节点的上下文关闭之前触发。 请注意，这与生命周期状态机没有直接关系。 添加绑定回调on_rcl_preshutdown runCleanups：清理 如果节点激活状态，调用节点的deactivate方法 如果节点未激活状态，调用节点的cleanup方法 lifecycle_service_client.hpp：生命周期服务客户端，使用nav2_util::service_client.hpp::SimpleActionServer创建 LifecycleServiceClient：构造函数，如果提供了节点指针，直接初始化一个节点，否则使用nav2_util::node_utils.hpp::generate_internal_node 自动生成一个节点 change_state：更改状态，可以设置超时时间 change_state：更改状态，不可以设置超时时间 get_state：获取状态 lifecycle_utils.hpp：生命周期工具 startup_lifecycle_nodes：按顺序将给定生命周期节点转换为 ACTIVATED 状态，接收节点名称列表 startup_lifecycle_nodes：按顺序将给定生命周期节点转换为 ACTIVATED 状态，接收以:拼接的字符串，分割后调用上面startup_lifecycle_nodes函数 reset_lifecycle_nodes：按顺序将给定生命周期节点转换为 UNCONFIGURED 状态，接收节点名称列表 reset_lifecycle_nodes：按顺序将给定生命周期节点转换为 UNCONFIGURED 状态，接收以:拼接的字符串，分割后调用上面reset_lifecycle_nodes函数 lifecycle_utils.cpp #define RETRY(fn, retries)：重试 startupLifecycleNode：使用nav2_util::lifecycle_service_client.hpp::LifecycleServiceClient.change_state 方法，状态由TRANSITION_CONFIGURE->TRANSITION_ACTIVATE resetLifecycleNode：使用nav2_util::lifecycle_service_client.hpp::LifecycleServiceClient.change_state 方法，状态由TRANSITION_DEACTIVATE->TRANSITION_CLEANUP lifecycle_bringup_commandline.cpp：nav2_util入口文件 geometry_utils.hpp：几何工具 orientationAroundZAxis：绕Z轴的四元数转换 euclidean_distance：欧氏距离(2d、3d) min_by：在迭代器中查找计算值最小的元素，比如：一组点到目标点最短距离 first_after_integrated_distance：查找迭代器中积分距离大于比较值的第一个元素 calculate_path_length：从提供的索引开始计算提供的路径的剩余长度 execution_timer.hpp：执行时间 ExecutionTimer：执行时间类，测量调用 start 和 end 之间代码的执行时间 start：开始时间 end：结束时间 elapsed_time：花费时间，返回纳秒 elapsed_time_in_seconds：花费时间，返回秒 costmap.hpp：代价地图 Costmap：代价地图类 set_static_map：设置静态代价地图 set_test_costmap：设置测试代价地图 get_costmap：获取代价地图 get_properties：获取代价地图配置参数 is_free：获取某些坐标是否没有障碍物 is_free：获取代价地图中某个索引是否没有障碍物 nav2_lifecycle_manager lifecycle_manager.hpp LifecycleManager：生命周期管理类 LifecycleManager：构造函数 声明和获取相关参数 调用registerRclPreshutdownCallback 创建节点名称/manage_nodes服务，处理函数为managerCallback 创建节点名称/is_active服务，处理函数为isActiveCallback 创建init_timer_定时器 调用createLifecycleServiceClients，遍历和创建管理的所有节点的生命周期服务客户端nav2_util::LifecycleServiceClient 如果配置了autostart_，重新创建init_timer_定时器，调用startup 实例化rclcpp::executors::SingleThreadedExecutor，启动线程nav2_util::NodeThread，运行执行器 managerCallback：管理服务回调 request->command==STARTUP：调用startup request->command==RESET：调用reset request->command==SHUTDOWN：调用shutdown request->command==PAUSE：调用pause request->command==RESUME：调用resume isActiveCallback：如果管理的所有节点都激活了，激活服务回调，返回system_active_的值 startup：启动所有管理节点 调用changeStateForAllNodes，修改节点状态TRANSITION_CONFIGURE、TRANSITION_ACTIVATE 调用createBondTimer shutdown：取消激活,清理和关闭所有管理节点 调用destroyBondTimer、shutdownAllNodes、destroyLifecycleServiceClients reset：重置所有管理节点 调用changeStateForAllNodes，修改节点状态TRANSITION_DEACTIVATE、TRANSITION_CLEANUP 注意是逆序更改节点状态，跟激活相反 pause：暂停所有管理节点 调用destroyBondTimer 调用changeStateForAllNodes，修改节点状态TRANSITION_DEACTIVATE resume：恢复所有管理节点 调用changeStateForAllNodes，修改节点状态TRANSITION_ACTIVATE 调用createBondTimer onRclPreshutdown：上下文关闭回调，调用destroyBondTimer，属性重置 createLifecycleServiceClients：创建所有管理的节点的生命周期服务客户端 shutdownAllNodes：关闭所有管理节点 调用changeStateForAllNodes，依次修改节点状态TRANSITION_DEACTIVATE、TRANSITION_CLEANUP 、TRANSITION_UNCONFIGURED_SHUTDOWN destroyLifecycleServiceClients：销毁所有管理的节点的生命周期服务客户端，遍历节点，调用nav2_util::LifecycleServiceClient的reset方法 createBondTimer：创建连接定时器，创建连接检测定时器，绑定checkBondConnections createBondConnection：连接定时器，初始化bond::Bond destroyBondTimer：销毁连接定时器，调用定时器cancel和reset checkBondConnections：支持检查连接的功能，如果出现无响应的情况，将关闭系统 遍历管理节点，调用nav2_util::LifecycleServiceClient的isBroken方法，如果有一个节点宕掉，调用reset关闭所有节点 如果配置了恢复，创建一个定时器，绑定checkBondRespawnConnection checkBondRespawnConnection：支持检查键连接的功能，如果出现无响应的情况，将恢复系统 调用nav2_util::LifecycleServiceClient的get_state方法，查看存活的节点和管理的节点数 一致的话，调用startup 不一致，查看是否恢复超时，重置超时和定时器 changeStateForNode：修改一个节点的状态 调用nav2_util::LifecycleServiceClient的change_state和get_state方法 如果是激活状态，调用createBondConnection changeStateForAllNodes：一次性修改所有节点的状态 遍历管理节点，依次调用changeStateForNode hard_change参数，如果为True，如果一个节点失败了，跳过，否则为False，一个节点转变失败，就返回失败 message：日志输出 CreateActiveDiagnostic：生成活动状态的诊断信息 registerRclPreshutdownCallback：注册上下文关闭回调，获取上下文，绑定onRclPreshutdown lifecycle_manager_client.hpp LifecycleManagerClient：生命周期管理客户端，用来向 LifecycleManager 发送请求控制导航模块的生命周期状态。 注意区分nav2_util::LifecycleServiceClient LifecycleManagerClient：构造函数 实例化节点名称/manage_nodes的nav2_util::ServiceClient客户端 实例化节点名称/is_active的nav2_util::ServiceClient客户端 startup：启动，调用callService shutdown：关闭，调用callService pause：暂停，调用callService resume：恢复，调用callService reset：重置，调用callService is_active：生命周期管理服务是否激活状态，调用nav2_util::ServiceClient的invoke callService：调用startup、shutdown等等服务，调用nav2_util::ServiceClient的invoke "},"Navigation2/源码分析/003-行为树及节点.html":{"url":"Navigation2/源码分析/003-行为树及节点.html","title":"行为树及节点","keywords":"","body":"datetime:2024/01/10 18:18 author:nzb 导航 https://github.com/ros-planning/navigation2.git 分支：humble 节点：3ed4c2d 行为树节点及其定义 nav2_behavior_tree | 行为树服务器及节点插件定义 nav2_bt_navigator | 导航行为树，单点和路点导航器，以及树xml文件 nav2_behaviors | 导航行为，包括旋转，后退，等待等行为 nav2_behavior_tree 基类或模板类 BehaviorTreeEngine：行为树引擎（行为树执行器） BehaviorTreeEngine：构造函数，入参插件列表，注册插件factory_.registerFromPlugin run：以一个特定的频率执行行为树，参数有：行为树指针，循环函数，取消函数，和循环时间 如果cancelRequested() -> tree->rootNode()->halt() tree->tickRoot() onLoop() createTreeFromText：根据字符串创建树 createTreeFromFile：根据文件创建树 haltAllActions：停止所有树节点，为了重新运行行为树，我们必须能够将所有节点重置为初始状态 BtActionServer：行为树动作服务器模板类，使用行为树执行动作的动作服务器 BtActionServer：构造函数，主要参数 plugin_lib_names_：插件列表 on_goal_received_callback_：用户提供的目标收到回调 on_loop_callback_：用户提供的循环中的回调 on_preempt_callback_：用户提供的抢占回调 on_completion_callback_：用户提供的动作完成回调 初始化节点参数 on_configure：配置函数 初始化节点client_node_ = std::make_shared 初始化节点参数global_frame -> map 初始化节点参数robot_base_frame -> base_link 初始化节点参数transform_tolerance -> 0.1 初始化服务action_server_ = std::make_shared>，绑定回调函数executeCallback 获取参数bt_loop_duration、default_server_timeout 初始化行为树引擎bt_ = std::make_unique(plugin_lib_names_) 创建黑板，设置黑板值 on_activate：激活函数，调用action_server_->activate() on_deactivate：取消激活函数，调用action_server_->deactivate() on_cleanup：清理函数，指针重置，黑板重置， 树停止bt_->haltAllActions loadBehaviorTree：加载行为树 读取xml内容 创建树bt_->createTreeFromText，递归树黑板，设置黑板相关值 创建树状态发布topic_logger_ = std::make_unique getBlackboard：获取黑板指针 getCurrentBTFilename：获取当前行为树名称 getDefaultBTFilename：获取默认行为树名称 acceptPendingGoal：接收待定任务包装，调用action_server_->accept_pending_goal() terminatePendingGoal：结束待定任务包装，调用action_server_->terminate_pending_goal() getCurrentGoal：获取当前任务包装，调用action_server_->get_current_goal() getPendingGoal：获取待定任务包装，调用action_server_->get_pending_goal() publishFeedback：发布反馈包装，调用action_server_->publish_feedback() getTree：获取树指针 haltTree：停止树 executeCallback：服务回调的执行函数 执行on_goal_received_callback_，校验任务 创建取消匿名回调on_loop和循环匿名回调is_canceling，行为树执行bt_->run(&tree_, on_loop, is_canceling, bt_loop_duration_) 行为树执行结束，调用bt_->haltAllActions(tree_.rootNode())，确保树不在执行了 执行on_completion_callback_ BtActionNode：封装行为树Action的模板类 ActionNodeBase：构造函数 获取参数bt_loop_duration、server_timeout 创建客户端，调用createActionClient，server_name为入参或节点端口配置 createActionClient：创建ros动作客户端action_client_，调用wait_for_action_server失败抛异常 providedBasicPorts：基础端口，子类必须在providedPorts里面调用该方法，该方法里面提供server_name和server_timeout端口 providedPorts：子类可重写提供的端口函数，调用providedBasicPorts on_tick：虚函数，用户重写，钩子函数 on_wait_for_result：虚函数，用户重写，钩子函数，执行中等待的时候，可能收到新的任务 on_success：虚函数，用户重写，钩子函数 on_aborted：虚函数，用户重写，钩子函数 on_cancelled：虚函数，用户重写，钩子函数 tick： 空闲调用on_tick、send_new_goal 运行中调用is_future_goal_handle_complete，小于server_timeout返回执行中，否则失败 运行中调用on_wait_for_result，如果收到新的任务，调用send_new_goal和is_future_goal_handle_complete 最后根据状态调用，on_success、on_aborted、on_cancelled、 halt：结束，调用should_cancel_goal和action_client_->async_cancel_goal should_cancel_goal：是否需要取消任务 send_new_goal：发送任务 调用action_client_->async_send_goal(goal_, send_goal_options)，其中的send_goal_options设置了result_callback 和feedback_callback，都是匿名函数修改结果和反馈 is_future_goal_handle_complete：任务是否完成 increment_recovery_count：递增黑板中的重试值 BtCancelActionNode：行为树取消Action节点模板类 BtCancelActionNode：构造函数 获取参数bt_loop_duration、server_timeout 创建客户端，调用createActionClient，server_name为入参或节点端口配置 createActionClient：创建ros动作客户端action_client_，调用wait_for_action_server失败抛异常 providedBasicPorts：基础端口，子类必须在providedPorts里面调用该方法，该方法里面提供server_name和server_timeout端口 providedPorts：子类可重写提供的端口函数，调用providedBasicPorts halt：结束 tick：执行，调用action_client_->async_cancel_goals_before，取消当前时间10ms之前指定的所有目标，避免异步通信错误 BtServiceNode：封装行为树Action的模板类，应该是BtActionNode的初版或早期版本，简化了很多 RosTopicLogger：行为树节点状态变更发布器 callback：当节点状态变更时的回调 flush：状态数据发布 应用(节点插件) nav2_bt_navigator 基类或模板类 BtNavigator：行为树导航类，继承于nav2_util::LifecycleNode，一个动作服务器，使用行为树将机器人导航到它的目标位置。重写on_configure、on_activate 、on_deactivate、on_cleanup、on_shutdown方法 BtNavigator：构造函数，初始化声明declare_parameter_if_not_declared参数，plugin_lib_names，transform_tolerance 、global_frame、robot_base_frame、odom_topic，plugin_libs来源于nav2_behavior_tree on_configure 初始化tf2_ros::TransformListener，以便节点中可以使用tf转换 初始化单点导航pose_navigator_ = nav2_bt_navigator::NavigateToPoseNavigator 初始化多点导航poses_navigator_ = nav2_bt_navigator::NavigateThroughPosesNavigator 初始化里程计平滑器nav2_util::OdomSmoother，用于获取当前速度 调用pose_navigator_和poses_navigator_的on_configure on_activate 调用pose_navigator_和poses_navigator_的on_activate 调用createBond on_deactivate 调用pose_navigator_和poses_navigator_的on_deactivate 调用destroyBond on_cleanup 调用pose_navigator_和poses_navigator_的on_cleanup pose_navigator_和poses_navigator_重置 on_shutdown 代码末尾RCLCPP_COMPONENTS_REGISTER_NODE(nav2_bt_navigator::BtNavigator) 注册组件，这充当一种入口点，允许组件的库被发现并加载到正在运行的进程中。 NavigatorMuxer：导航复用器类，一次只允许处理一个插件来控制 BT 导航器的状态。 isNavigating：是否有一个导航任务在处理 startNavigating：使用给定的导航器开始导航 stopNavigating：停止给定的导航器 Navigator：导航器接口模板类，充当所有基于导航器操作插件的基类 on_configure：设置导航器行为树和操作配置 设置属性：NavigatorMuxer的实例plugin_muxer_ 调用getDefaultBTFilepath 实例化bt_action_server_=nav2_behavior_tree::BtActionServer，绑定onGoalReceived、onLoop、onPreempt 、onCompletion，注意区分，是nav2_behavior_tree::BtActionServer不是BtNavigator 调用bt_action_server_->on_configure()方法 调用bt_action_server_->getBlackboard()方法获取黑板，设置一些参数 调用configure方法 on_activate：激活 调用bt_action_server_->on_activate() 调用activate() on_deactivate 调用bt_action_server_->on_deactivate() 调用deactivate() on_cleanup 调用bt_action_server_->on_cleanup() 调用cleanup() configure：虚函数 cleanup：虚函数 activate：虚函数 deactivate：虚函数 getName()：纯虚函数 getDefaultBTFilepath()：纯虚函数 goalReceived()：纯虚函数，动作服务器收到新目标时调用的回调，可用于检查目标是否有效并赋值 onLoop()：纯虚函数，定义在 BT 的一次迭代中发生的执行的回调，可用于发布行动反馈 onPreempt()：纯虚函数，请求抢占时调用的回调 goalCompleted()：纯虚函数，行动完成时的回调 getActionServer()：获取action_server的指针 onGoalReceived()：多路复用器导航器的中间目标接收功能 调用goalReceived 调用plugin_muxer_->startNavigating onCompletion 调用plugin_muxer_->stopNavigating 调用goalCompleted 实现或应用 NavigateToPoseNavigator：单点导航器，继承于nav2_bt_navigator::Navigator configure 初始化节点参数及黑板键goals_blackboard_id -> goal 初始化节点参数及黑板键path_blackboard_id -> path 创建navigate_to_pose动作客户端，self_client_ = rclcpp_action::create_client 订阅goal_pose话题，回调onGoalPoseReceived getDefaultBTFilepath：获取当前导航器默认的行为树配置 cleanup：清理，指针重置 goalReceived：动作服务器收到新目标时调用的回调，可用于检查目标是否有效并赋值 调用bt_action_server_->loadBehaviorTree 调用initializeGoalPose onLoop()：定义在 BT 的一次迭代中发生的执行的回调，可用于发布行动反馈 计算当前剩余距离：根据当前位置，在全局路径上找到最近的点的索引nav2_util::geometry_utils::euclidean_distance ，计算剩余路径长nav2_util::geometry_utils::calculate_path_length 计算预估剩余时间：如果当前速度大于1cm/s并且还剩10cm，则计算预估剩余时间 调用bt_action_server_->publishFeedback发布反馈 onPreempt()：请求抢占时调用的回调 调用initializeGoalPose(bt_action_server_->acceptPendingGoal());条件 如果挂起的目标请求与当前目标相同，则接受挂起的目标 如果挂起的目标有一个空的behavior_tree字段，并且当前目标是正在运行默认 BT 文件，则接受待处理的目标 否则调用bt_action_server_->terminatePendingGoal(); 请求的目标跟当前执行的不一样的xml文件，需要取消上一个目标，再发起新的目标请求 goalCompleted()：行动完成时的回调 onGoalPoseReceived：用于处理来自rviz发布的基于主题的目标的订阅和回调 self_client_->async_send_goal发送目标 getName：导航器名称，navigate_to_pose initializeGoalPose：更新行为树黑板上的目标位姿 NavigateThroughPosesNavigator：路点导航器，用于导航到一堆中间姿势的导航器，跟单点导航大差不差，继承于nav2_bt_navigator::Navigator configure 初始化节点参数及黑板键goals_blackboard_id -> goals 初始化节点参数及黑板键path_blackboard_id -> path getName：导航器名称，navigate_through_poses getDefaultBTFilepath：获取当前导航器默认的行为树配置 goalReceived：动作服务器收到新目标时调用的回调，可用于检查目标是否有效并赋值 调用bt_action_server_->loadBehaviorTree 调用initializeGoalPose onLoop()：定义在 BT 的一次迭代中发生的执行的回调，可用于发布行动反馈 计算当前剩余距离：根据当前位置，在全局路径上找到最近的点的索引nav2_util::geometry_utils::euclidean_distance ，计算剩余路径长nav2_util::geometry_utils::calculate_path_length 计算预估剩余时间：如果当前速度大于1cm/s并且还剩10cm，则计算预估剩余时间 调用bt_action_server_->publishFeedback发布反馈 onPreempt()：请求抢占时调用的回调 调用initializeGoalPose(bt_action_server_->acceptPendingGoal());条件 如果挂起的目标请求与当前目标相同，则接受挂起的目标 如果挂起的目标有一个空的behavior_tree字段，并且当前目标是正在运行默认 BT 文件，则接受待处理的目标 否则调用bt_action_server_->terminatePendingGoal(); 请求的目标跟当前执行的不一样的xml文件，需要取消上一个目标，再发起新的目标请求 goalCompleted：行动完成时的回调 initializeGoalPose：更新行为树黑板上的目标位姿数组 nav2_behaviors 基类或模板类 BehaviorServer：托管行为插件的服务器，继承于nav2_util::LifecycleNode BehaviorServer：构造函数 声明节点参数 costmap_topic->local_costmap/costmap_raw footprint_topic->local_costmap/published_footprint cycle_frequency->10.0 behavior_plugins->\"spin\", \"backup\", \"drive_on_heading\", \"wait\" 设置上面4个插件信息，例如：spin.plugin->nav2_behaviors/Spin global_frame->odom robot_base_frame->base_link transform_tolerance->0.1 on_configure 初始化transform_listener_ 实例化订阅服务实例 初始化代价地图话题nav2_costmap_2d::CostmapSubscriber订阅/local_costmap/costmap_raw 初始化小车位姿话题nav2_costmap_2d::FootprintSubscriber订阅/local_costmap/published_footprint：基于odom 多边形的多边形数据，用于碰撞检测 初始化碰撞检测nav2_costmap_2d::CostmapTopicCollisionChecker实例，需要上面2个订阅服务实例 调用loadBehaviorPlugins加载创建插件nav2_core::Behavior实例并调用插件的configure方法 on_activate 遍历插件并调用插件的activate方法 调用createBond()，创建 bond 连接，用于发布节点的健康状态 on_deactivate 遍历插件并调用插件的deactivate方法 调用destroyBond，销毁 bond 连接 on_cleanup 遍历插件并调用插件的cleanup方法 资源释放 on_shutdown TimedBehavior模板类，继承于nav2_core::Behavior，定时行为, 是一种行为模式，用于定义在特定时间间隔内执行的行为。它是基于行为树（Behavior Tree）框架的一部分，用于控制机器人或系统的行为 onRun：纯虚函数，进入主循环时会被调一次，可以用于检查等 onCycleUpdate：纯虚函数，当返回RUNNING时，execute会循环调用 onConfigure：虚函数 onCleanup：虚函数 onActionCompletion：虚函数 configure：BehaviorServer的on_configure的时候调用 创建对应的动作服务nav2_util::SimpleActionServer，绑定execute 创建cmd_vel话题发布者 调用onConfigure cleanup：资源释放，调用onCleanup activate vel_pub_->on_activate(); action_server_->activate(); deactivate vel_pub_->on_deactivate(); action_server_->deactivate(); execute：nav2_util::SimpleActionServer回调 调用onRun、onCycleUpdate、onActionCompletion等函数 stopRobot：停车，vel_pub发布速度置为0 实现和插件 Spin：旋转到目标角度插件类，继承于TimedBehavior onConfigure：初始化旋转参数 simulate_ahead_time -> 2.0 max_rotational_vel -> 1.0 min_rotational_vel -> 0.4 rotational_acc_lim -> 3.2 onRun：校验是否能拿到当前坐标和旋转的所花时间 onCycleUpdate： 是否旋转超时 更新发布已经旋转过的角度 计算旋转速度，并调用isCollisionFree模拟旋转检测是否无碰撞，最后通过vel_pub_发布速度 isCollisionFree：模拟小车旋转碰撞检测，调用collision_checker_的isCollisionFree检测是否碰撞 DriveOnHeading：插件类，继承于TimedBehavior，是使机器人以当前的航向方向行驶前进和后退。 onRun：校验速度方向和要走的距离是否相同以及是否能拿到当前坐标和执行所花时间 onCycleUpdate： 是否执行超时 更新发布已经走过的距离 计算剩余距离，并调用isCollisionFree模拟执行，检测是否无碰撞，最后通过vel_pub_发布速度 isCollisionFree：模拟小车旋转碰撞检测，调用collision_checker_的isCollisionFree检测是否碰撞 cycle_frequency_：循环频率，单位hz simulate_ahead_time_：模拟时间，单位s cycle_count / this->cycle_frequency_：时间，单位s onConfigure：初始化旋转参数 simulate_ahead_time -> 2.0 BackUp：插件类，继承于DriveOnHeading，用于处理机器人在导航过程中遇到障碍物或无法到达目标位置的情况。当机器人无法按照规划的路径前进时，BackUp 模块会尝试执行倒车操作，即使机器人后退一段距离，然后尝试重新规划路径以绕过障碍物或重新计算到达目标的路径。 onRun：校验是否能拿到当前坐标和执行所花时间，前置把距离和速度置为负 Wait：等待插件类，继承于TimedBehavior，持续反馈剩余时间，到了给定时间，返回SUCCEEDED，否则返回RUNNING，其余啥也不做，可以用于等待外设或其他交互 "},"Navigation2/源码分析/004-地图和定位.html":{"url":"Navigation2/源码分析/004-地图和定位.html","title":"地图和定位","keywords":"","body":"datetime:2024/01/10 18:18 author:nzb 导航 https://github.com/ros-planning/navigation2.git 分支：humble 节点：3ed4c2d 地图和定位 nav2_map_server ｜ 地图服务器 nav2_costmap_2d ｜ 2D代价地图 nav2_voxel_grid | 实现体素栅格的类 nav2_amcl | 自适应蒙特卡洛定位。 状态估计，输入地图、激光、里程计数据，输出机器人map和odom之间的位姿关系。 nav2_map_server 工具 loadMapYaml：加载和解析给定的地图yaml文件参数，包括地图文件名，分辨率，地图原点，空闲阈值，占据阈值，模式， loadMapFromFile：从地图文件加载地图图像以及生成占用网格 loadMapFromYaml：加载地图 YAML、地图文件中的图像以及生成占用网格nav_msgs::msg::OccupancyGrid返回 调用loadMapYaml 调用loadMapFromFile saveMapToFile：保存占据地图到文件 调用checkSaveParameters 调用tryWriteMapToFile checkSaveParameters：检查地图保存参数 tryWriteMapToFile：分类型把地图写入文件，包括Trinary、Scale和Raw for (size_t y = 0; y x(width) | (0,0) (0,1) (0,2) (0,3) ... (0, w) | (1,0) (1,1) ... | ... | ... | (h,0) ... (h, w) y(height) v data的数据排序为：[(0,0) ... (0,w) ... (h,0) ... (h, w)] 比如width * height =5 * 4的20个元素，下图是索引表 y(height) ^ | 0 1 2 3 4 | 5 6 7 8 9 | 10 11 12 13 14 | 15 16 17 18 19 |————————————————————> x(width) idx = width * (height - y - 1) + x y(height) = 0 x(width) = 0, idx = 5 * (4 - 0 -1 ) + 0 = 15 x = 1, idx = 5 * (4 - 0 -1 ) + 1 = 16 x = 2, idx = 5 * (4 - 0 -1 ) + 2 = 17 x = 3, idx = 5 * (4 - 0 -1 ) + 3 = 18 x = 4, idx = 5 * (4 - 0 -1 ) + 4 = 19 y(height) = 1 x(width) = 0, idx = 5 * (4 - 1 -1 ) + 0 = 10 x = 1, idx = 5 * (4 - 1 -1 ) + 1 = 11 x = 2, idx = 5 * (4 - 1 -1 ) + 2 = 12 x = 3, idx = 5 * (4 - 1 -1 ) + 3 = 13 x = 4, idx = 5 * (4 - 1 -1 ) + 4 = 14 ... y(height) = 3 x(width) = 0, idx = 5 * (4 - 3 -1 ) + 0 = 0 x = 1, idx = 5 * (4 - 3 -1 ) + 1 = 1 x = 2, idx = 5 * (4 - 3 -1 ) + 2 = 2 x = 3, idx = 5 * (4 - 3 -1 ) + 3 = 3 x = 4, idx = 5 * (4 - 3 -1 ) + 4 = 4 主要的类 MapServer：解析地图yaml文件以及提供一个服务和一个话题发布占据网格地图，继承于nav2_util::LifecycleNode MapServer： 初始化节点map_server 声明节点参数 yaml_filename -> rclcpp::PARAMETER_STRING topic_name -> map frame_id -> map 创建一个occ_service_的节点名称/map的服务，绑定getMapCallback 创建一个occ_pub_的map的发布话题 创建一个load_map_service_的节点名称/load_map的服务，绑定loadMapCallback on_configure： 调用loadMapResponseFromYaml 调用updateMsgHeader on_activate： occ_pub_->on_activate() occ_pub_->publish() createBond() on_deactivate： occ_pub_->on_deactivate() destroyBond() on_cleanup：属性重置 on_shutdown： loadMapResponseFromYaml：加载地图yaml和图像，以及生成包含 OccupancyGrid 的输出响应。 updateMsgHeader：更新msg头信息，更新加载时间和帧id getMapCallback：获取地图服务map的回调，返回最新的地图 loadMapCallback：更新加载地图服务load_map的回调 调用loadMapResponseFromYaml，重新加载地图 话题发布最新地图 MapSaver：提供地图保存方法和服务的类，继承于nav2_util::LifecycleNode MapSaver： 初始化节点map_saver 声明节点参数 save_map_timeout -> 2.0 free_thresh_default -> 0.25 occupied_thresh_default -> 0.65 map_subscribe_transient_local -> true saveMapTopicToFile：从地图话题读取信息并且保存到一个文件 参数校验 创建map(默认)名称的地图话题订阅 调用saveMapToFile on_configure： 获取上述节点参数 创建save_map_service_保存地图服务节点名称/save_map，绑定saveMapCallback on_activate：调用createBond() on_deactivate：调用destroyBond() on_cleanup：属性重置 on_shutdown： saveMapCallback：地图保存服务回调 初始化保存地图参数 调用saveMapTopicToFile map_saver_cli：可执行文件用于保存地图文件 parse_arguments：解析命令行参数 main：主函数 调用parse_arguments 实例化map_saver = std::make_shared() 调用map_saver->on_configure启动map_saver节点 调用map_saver->saveMapTopicToFile保存地图文件 CostmapFilterInfoServer：代价地图过滤器信息服务器，继承于nav2_util::LifecycleNode CostmapFilterInfoServer 初始化节点costmap_filter_info_server 声明节点参数 filter_info_topic -> costmap_filter_info type -> 0 mask_topic -> filter_mask base -> 0.0 multiplier -> 1.0 on_configure 创建costmap_filter_info话题publisher_ = this->create_publisher，发布代价地图过滤器信息 on_activate 调用publisher_->on_activate() 调用publisher_->publish 调用createBond() on_deactivate 调用publisher_->on_deactivate() 调用destroyBond() on_cleanup on_shutdown nav2_voxel_grid TODO，先了解工作流以及有哪些功能，具体实现需要再深入，比较难懂 什么是体素(Voxel)? 题图中是3D数据的不同表示类型: a)、点云（Point clouds）；点云是三维空间(xyz坐标)点的集合。 b)、体素网格(Voxel grids)；体素是3D空间的像素。量化的，大小固定的点云。每个单元都是固定大小和离散坐标。 c) 多边形网格(Polygon meshes)；mesh是面片的集合。 d) 多视图表示(Multi-view representations)；多视图表示是从不同模拟视点渲染的2D图像集合。 为了解释体素网格(Voxel grid),首先我们要了解占据栅格地图（Occupancy Grid Map） 画一个二维网格，每个网格单元里有实体的话就为占据状态（1），空的话就为（0）。很好理解。 而体素就是固定分辨率的三维栅格地图。 体素网格是固定分辨率的，与之对应可变分辨率的网格叫八叉树地图(Octomap)。 图左是八叉树地图(Octomap)，图右是八叉树(Octotree)。 总结： 体素网格是用固定大小的立方块作为最小单元，来表示三维物体的一种数据结构。 体素可以看成粗略版的点云。 主要的类 VoxelGrid VoxelGrid：仅支持z ~((uint32_t)0) >> 16 表示32位二进制中所有位都为1的数，然后通过右移16位操作 (>> 16) 来将高16位设置为1，低16位设置为0 ~0：得到全1 等于python的unknown_col = 0xFFFFFFFF >> 16 结果：0b00000000000000001111111111111111 resize：调整体素网格的尺寸 reset：重置体素网格 getData：返回指向表示体素网格的数据数组的指针 markVoxel：操作单个体素。它们检查边界并执行标记或检查阈值等操作 full_mask = ((uint32_t)1 ：注意：z data_[y * size_x_ + x] |= full_mask：标记或清错 markVoxelInMap：操作单个体素。它们检查边界并执行标记或检查阈值等操作 marked_bits = (*col |= full_mask) >> 16，然后调用bitsBelowThreshold clearVoxel：操作单个体素。它们检查边界并执行清除或检查阈值等操作，data_[y * size_x_ + x] &= ~(full_mask); clearVoxelInMap：检查边界并执行清除或检查阈值等操作，并重置代价地图 *col &= ~(full_mask); unknown_bits = uint16_t(*col >> 16) ^ uint16_t(*col); marked_bits = *col >> 16 bitsBelowThreshold(unknown_bits, 1) && bitsBelowThreshold(marked_bits, 1) -> costmap[index] = 0; clearVoxelColumn：清除指定索引的体素 bitsBelowThreshold：查看位数是否低于阈值 numBits：计算一个数有多少个bit位是1，使用了一种称为Brian Kernighan's Algorithm的方法，它通过反复清除 n 中的最低位的1来计算1的个数。 算法的思路是每次清除最低位的1，然后计数器增加1，直到 n 变成0。最终，函数返回整数 n 中位为1的个数。这个算法的优势在于它只需要循环次数等于 n 中位为1的个数，而不是整个32位。 getVoxel：获取指定坐标处的体素状态（静态方法） result = data[y * size_x + x] & full_mask; bits = numBits(result) known marked: 11 = 2 bits, unknown: 01 = 1 bit, known free: 00 = 0 bits markVoxelLine：用于在网格中标记或清除一条体素线的函数 实例化函数对象MarkVoxel 调用raytraceLine clearVoxelLine：用于在网格中标记或清除一条体素线的函数，实例化函数对象MarkVoxel，调用raytraceLine clearVoxelLineInMap：用于在网格中标记或清除一条体素线的函数 如果没有代价地图，调用clearVoxelLine 否则实例化函数对象ClearVoxelInMap 调用raytraceLine getVoxel：获取指定坐标处的体素状态（非静态方法） getVoxelColumn：用于获取指定 (x, y) 上的体素状态 printVoxelGrid：用于调试的打印体素网格或网格列的函数 printColumnGrid：用于调试的打印体素网格或网格列的函数 sizeX：返回体素网格的尺寸 sizeY：返回体素网格的尺寸 sizeZ：返回体素网格的尺寸 raytraceLine：模板函数，在体素网格中执行射线跟踪，沿着线标记或清除体素 实例化GridOffset、ZOffset 根据数据状况调用bresenham3D bresenham3D：Bresenham 算法在三维空间中的实现，最后调用MarkVoxel实例函数更新体素状态 sign：签名，大于0，返回1，否则返回-1 max：最大值 函数对象(类，实现可调用的方法()) MarkVoxel：标记：data_[offset] |= z_mask; ClearVoxel：清除：data_[offset] &= ~(z_mask) ClearVoxelInMap：清除并重置代价地图：类似上面的clearVoxelInMap GridOffset：更新偏移量 ZOffset：如果 offset_val 大于0，则执行左移操作 z_mask_ ；否则，执行右移操作 z_mask_ >>= 1 用于标记、清除和更新偏移量的函数对象。 nav2_costmap_2d 主要的类和节点 Layer：抽象类，用于分层成本图插件实现的抽象类 initialize： 在startup初始化处理代价地图，关键参数LayeredCostmap * parent父类指针 初始化相关属性 调用onInitialize deactivate：虚函数，停止发布 activate：虚函数，如果停止了，重新发布 reset：纯虚函数，重置代价地图 isClearable：纯虚函数，是否应在该层进行清除操作 updateBounds：纯虚函数，被LayeredCostmap调用，轮询看有多少代价地图需要更新边界 updateCosts：纯虚函数，实际更新底层成本图，仅在 UpdateBounds() 期间计算的范围内 matchSize：虚函数，实现这个以使该层与父代价地图的大小匹配 onFootprintChanged：虚函数，当footprint改变时LayeredCostmap调用，由LayeredCostmap::setFootprint()触发，重写这个以便通知footprint 改变 getName：获取代价地图名称 isCurrent：检查以确保图层中的所有数据都是最新的。 isEnabled：返回代价地图是否启用 getFootprint：便捷函数layered_costmap_->getFootprint() declareParameter：ROS参数的便捷函数 hasParameter：ROS参数的便捷函数 getFullName：ROS参数的便捷函数，std::string(name_ + \".\" + param_name); onInitialize：虚函数，initialize结尾调用，子类可以重写该函数，初始化相关操作 LayeredCostmap：实例化不同层插件并将它们聚合成一个分数 主要属性 Costmap2D primary_costmap_, combined_costmap_ primary_costmap_：是启用costmap过滤器时插件使用的底部costmap。 combined_costmap_：是最终成本图，其中插件和过滤器（如果有）产生的所有结果的合并 分离的目的是避免插件和过滤器之间工作的干扰 primay_costmap_和combined_costmap_具有相同的大小、原点和默认值。 代价地图插件数组std::vector> plugins_; 地图过滤器数组std::vector> filters_; updateMap：更新地图，如果你想在循环外更新，你可以调用该函数随时更新地图 如果配置了代价地图跟随移动，则调用primary_costmap_.updateOrigin和combined_costmap_.updateOrigin 如果没有插件和地图过滤器返回 否则遍历插件和过滤器，调用对应的updateBounds 调用combined_costmap_.worldToMapEnforceBounds确定代价地图边界大小 有没有代价地图过滤器插件 没有：调用combined_costmap_.resetMap，遍历地图插件，调用插件的updateCosts(combined_costmap_, x0, y0, xn, yn) 有 调用primary_costmap_.resetMap，遍历地图插件，调用插件的updateCosts(primary_costmap_, x0, y0, xn, yn) 调用combined_costmap_.copyWindow(primary_costmap_, x0, y0, xn, yn, x0, y0) 将处理后的代价图窗口复制到最终代价图，primary_costmap_是启用costmap过滤器时插件使用的底部costmap。 primary_costmap_ 保持不变，以供插件进一步使用 遍历地图过滤器插件，调用updateCosts(combined_costmap_, x0, y0, xn, yn)，在插件上应用过滤器，以便插件在下次 updateMap() 调用时不考虑过滤器的工作 getGlobalFrameID：获取地图帧ID resizeMap：重新设置地图的原点，大小和分辨率 调用primary_costmap_.resizeMap 调用combined_costmap_.resizeMap 遍历代价地图和地图过滤器数组，调用其matchSize方法 getUpdatedBounds：获取更新的地图边界大小 isCurrent：是否所有地图都是最新数据，迭代地图插件和过滤器插件，调用current_ && ((*plugin)->isCurrent() || !(*plugin)->isEnabled()) getCostmap：获取主地图combined_costmap_指针 isRolling：成本图是否应该与机器人一起移动 isTrackingUnknown：成本图是否追踪未知区域 getPlugins：获取代价地图插件数组指针 getFilters：获取代价地图过滤器插件数组指针 addPlugin：添加代价地图插件到对应数组 addFilter：添加代价地图过滤器插件到对应数组 isSizeLocked：返回代价地图是否锁了 getBounds：获取代价地图边界 isInitialized：代价地图是否初始化完成 setFootprint：更新足迹footprint，更新外接的和内切半径 调用nav2_costmap_2d::calculateMinAndMaxDistances获取内径和外径 调用代价地图和地图过滤器插件Layer的onFootprintChanged() getFootprint：返回最后一个footprint getCircumscribedRadius：获取外径圆，在setFootprint内更新值 getInscribedRadius：获取内径圆，在setFootprint内更新值 isOutofBounds：机器人是否超出边界，!combined_costmap_.worldToMap(robot_x, robot_y, mx, my) Costmap2D：2D代价地图，提供世界坐标系上的点及其对应的代价映射 Costmap2D：构造函数，根据参数创建，调用initMaps和resetMaps Costmap2D：拷贝构造函数，根据已有地图拷贝创建 Costmap2D：构造函数，根据占据网格数据创建 copyCostmapWindow：把传入的代价地图拷贝一份指定窗口大小的副本 copyWindow：传入的代价地图指定窗口大小，然后覆盖到当前代价地图的指定位置（大小） getCost：指定x，y返回代价地图对应的值 getCost：指定索引返回代价地图对应的值 setCost：设置指定x，y的代价 mapToWorld：代价地图坐标转换世界坐标 worldToMap：世界坐标转换代价地图坐标 worldToMapNoBounds：世界坐标转换代价地图坐标，不校验边界 worldToMapEnforceBounds：世界坐标转换代价地图坐标，校验边界 getIndex：指定x，y返回索引，my * size_x_ + mx indexToCells：索引返回x，y, my = index / size_x_; mx = index - (my * size_x_); getCharMap：返回代价地图指针 getSizeInCellsX：返回x的单元大小 getSizeInCellsY：返回y的单元大小 getSizeInMetersX：返回x方向的长度，单位m，(size_x_ - 1 + 0.5) * resolution_; getSizeInMetersY：返回x方向的长度，单位m getOriginX：返回地图原点x getOriginY：返回地图原点y getResolution：返回分辨率 setDefaultValue：设置代价地图的默认值 getDefaultValue：获取代价地图的默认值 setConvexPolygonCost：设置指定凸边形中的代价值 polygonOutlineCells：获取构成多边形轮廓的地图单元格 convexFillCells：获取填充凸多边形填充的单元格 updateOrigin：虚函数，将成本图的原点移动到新位置 saveMap：保存代价地图到pgm文件 resizeMap：重置代价地图，调用initMaps和resetMaps resetMap：重置代价地图边界，调用resetMapToValue resetMapToValue：重置代价地图代价值 cellDistance：给定世界坐标系的距离长度，返回代价地图中的距离长度 getMutex：获取可重入锁 copyMapRegion：模板函数，将源地图的区域复制到目标地图 deleteMaps：虚函数，删除地图，包括代价地图，静态地图和markers数据结构 resetMaps：虚函数，重置代价地图和静态地图到默认值 initMaps：虚函数，初始化代价地图，静态地图和markers数据结构 raytraceLine：模板函数，在体素网格中执行射线跟踪 bresenham2D：模板函数，2DBresenham 算法 sign：x > 0 ? 1.0 : -1.0 函数对象(类，实现可调用的方法()) MarkCell：代价地图赋值 PolygonOutlineCells：多边形数组，根据索引返回多边形的单元格坐标数组 CostmapLayer：代价地图插件层的基类，继承于Layer、Costmap2D CostmapLayer isDiscretized：代价地图是否是离散的 matchSize：虚函数，匹配(适配)主成本图的大小，调用Costmap2D.resizeMap传入主代价地图的相关参数 clearArea：虚函数，清除代价图中给定维度的区域，如果反转，则清除给定维度之外的所有内容 addExtraBounds：如果外部源更改了代价地图中的值，则应调用此方法，以确保代价地图也包含该区域。 updateWithTrueOverwrite：把当前代价地图的给定区域的值，更新到主代价地图master_grid上，所有值都更新 updateWithOverwrite：把当前代价地图的给定区域的值，更新到主代价地图master_grid上，除了NO_INFORMATION，其他值都更新 updateWithMax：把当前代价地图的给定区域的值，更新到主代价地图master_grid上，如果当前代价地图是NO_INFORMATION跳过，如果主代价地图为NO_INFORMATION 或主代价地图的值小于当前代价地图的值，则更新 updateWithAddition：把当前代价地图的给定区域的值，更新到主代价地图master_grid上，如果当前代价地图是NO_INFORMATION跳过，如果主代价地图为NO_INFORMATION 更新为当前代价地图的值，如果主代价地图的值加当前代价地图的值大于大于nav2_costmap_2d::INSCRIBED_INFLATED_OBSTACLE ，则更新为nav2_costmap_2d::INSCRIBED_INFLATED_OBSTACLE - 1，否则更新为两者的和 touch：更新参数中指定的边界框以包含位置 (x,y) useExtraBounds：更新参数中指定的边界框，包含来自调用的addExtraBounds边界值，如果未调用addExtraBounds则该函数啥也不做，该函数应该在updateBounds刚开始的时候调用 FootprintCollisionChecker：碰撞检测模板类，模板参数是nav2_costmap_2d::Costmap2D，在代价地图上碰撞检测检测 FootprintCollisionChecker： footprintCost：返回代价值 先检测第一个点，调用worldToMap，转换失败直接返回LETHAL_OBSTACLE 遍历footprint，调用worldToMap，转换失败直接返回LETHAL_OBSTACLE，然后调用lineCost检测线段所在的代价 如果检测到LETHAL_OBSTACLE直接返回，最后还需要闭环到第一个点直线检测，然后返回代价值 footprintCostAtPose：返回给定当前位姿的代价值 生成给定坐标的footprint 调用footprintCost获取代价值 lineCost：获取这条线的代价 根据给定的2个点，调用nav2_util::LineIterator迭代线上的点 调用pointCost获取对应点的代价，如果值为LETHAL_OBSTACLE直接返回 否则更新相关点代价和线代价 worldToMap：世界坐标转代价地图坐标，调用对应的代价地图的worldToMap pointCost：返回给的坐标的代价，调用对应的代价地图的getCost setCostmap：设置当前代价地图用于碰撞检测，设置代价地图 getCostmap：获取当前代价地图 Costmap2DPublisher：2D代价地图发布器 Costmap2DPublisher： 初始化属性，其中包括Costmap2D * costmap_指针 创建代价地图发布话题 costmap_pub_ = node->create_publisher(topic_name, custom_qos); costmap_raw_pub_ = node->create_publisher(topic_name + \"_raw\", custom_qos); costmap_update_pub_ = node->create_publisher(topic_name + \"_updates\", custom_qos); 创建获取代价地图服务，costmap_service_ = node->create_service(\"get_costmap\",...) 绑定costmap_service_callback on_configure： on_activate： costmap_pub_->on_activate(); costmap_update_pub_->on_activate(); costmap_raw_pub_->on_activate(); on_deactivate： costmap_pub_->on_deactivate(); costmap_update_pub_->on_deactivate(); costmap_raw_pub_->on_deactivate(); on_cleanup： updateBounds：更新地图边界 publishCostmap：发布话题数据 costmap_raw_pub_ 如果costmap_raw_pub有订阅者，调用prepareCostmap，然后发布costmap_raw_pub_->publish costmap_pub_和costmap_update_pub_ 如果设置了永远发布完整代价地图或分辨率，网格高宽或原点坐标发生变化，并且costmap_pub_有订阅者，调用prepareGrid，然后发布costmap_pub_->publish 或者x0_ ，并且costmap_update_pub__有订阅者，更新相关地图信息，然后发布costmap_update_pub__->publish active： prepareGrid：组装nav_msgs::msg::OccupancyGrid网格数据，通过Costmap2D * costmap_指针获取相关数据组装 prepareCostmap：组装nav2_msgs::msg::Costmap代价地图数据 costmap_service_callback：通过Costmap2D * costmap_指针获取相关数据组装返回 CostmapSubscriber：2D代价地图订阅器 CostmapSubscriber：构造函数，创建给定话题的代价地图订阅costmap_sub_ = node->create_subscription getCostmap：调用toCostmap2D()组装 toCostmap2D：将网格消息转换为costmap对象 如果Costmap2D costmap_为空赋值，不为空，看属性是否更改，如有更改，调用costmap_->resizeMap 更新代价地图的值到最新订阅到的代价地图数据 costmapCallback：订阅回调 ClearCostmapService：ROS服务用于清除代价地图 ClearCostmapService：构造函数 主要属性 Costmap2DROS & costmap_; 获取节点参数clearable_layers - 创建服务clear_except_service_ = node->create_service(\"clear_except_\" + costmap_.getName(),...) 绑定clearExceptRegionCallback 创建服务clear_around_service_ = node->create_service(\"clear_around_\" + costmap.getName(),...) 绑定clearAroundRobotCallback 创建服务clear_entire_service_ = node->create_service(\"clear_entirely_\" + costmap_.getName(),,...) 绑定clearEntireCallback clearRegion：清除用户指定区域之外(如果invert参数为true)的区域，恢复到静态地图 调用getPosition失败返回 获取所有的代价地图层layers = costmap_.getLayeredCostmap()->getPlugins() 遍历所有层调用layer->isClearable()，可清除的话，调用clearLayerRegion，传入当前机器人坐标和需要清除的距离 clearEntirely：清除所有的代价地图层，调用costmap_.resetLayers() clearExceptRegionCallback：清除给定区域之外的成本图回调，调用clearRegion，invert参数为true clearAroundRobotCallback：清除给定区域的成本图回调，调用clearRegion，invert参数为false clearEntireCallback：清除全部成本图回调，调用clearEntirely clearLayerRegion：清除给定层的代价地图 调用对应地图层的costmap->worldToMapEnforceBounds 调用对应地图层的costmap->clearArea 调用对应地图层的costmap->addExtraBounds getPosition：使用主成本图获取机器人在成本图中的位置 Costmap2DROS：costmap节点，2D Costmap的ROS包装器类，处理各种代价地图插件。 处理订阅PointCloud或LaserScan 提供障碍等相关消息。继承于nav2_util::LifecycleNode Costmap2DROS：构造函数 初始化参数： default_plugins_->{\"static_layer\", \"obstacle_layer\", \"inflation_layer\"}，依次为静态层，避障层，膨胀层 对应的插件default_types__ ->{\"nav2_costmap_2d::StaticLayer\", \"nav2_costmap_2d::ObstacleLayer\", \"nav2_costmap_2d::InflationLayer\"} clearable_layers->{\"obstacle_layer\", \"voxel_layer\", \"range_layer\"}，可清除的层，包括避障层、体素层、测距层 - | 参数 | 默认值 | 说明 | |--- | ---| --- | | always_send_full_costmap | false | | | footprint_padding | 0.01 | 足迹补偿值 | | footprint | \"[]\" | | | global_frame | map | | | height | 5 | | | width | 5 | | | lethal_cost_threshold | 100 | 障碍物阈值 | | map_topic | /map | | | observation_sources | | | | origin_x | | | | origin_y | | | | plugins | default_plugins | | | filters | | | | publish_frequency | 1.0 | | | resolution | 0.1 | | | robot_base_frame | base_link | | | robot_radius | 0.1 | | | rolling_window | false | | | track_unknown_space | false | | | transform_tolerance | 0.3 | | | trinary_costmap | true | | | unknown_cost_value | 0xff | | | update_frequency | 5.0 | | | use_maximum | false | | | clearable_layers | 上面的clearable_layers | | on_configure：配置 调用getParameters 创建主代价地图层layered_costmap_ = std::make_unique 初始化tf_buffer_ 加载配置的plugin_names_插件 创建插件实例plugin = std::shared_ptr 插件实例添加到主代价地图层layered_costmap_->addPlugin(plugin) 插件初始化plugin->initialize() 加载配置的filter_names_过滤插件 创建插件实例filter = std::shared_ptr 插件实例添加到主代价地图层layered_costmap_->addFilter(filter) 插件初始化filter->initialize() 创建话题发布和订阅 创建footprint_sub_订阅机器人足迹footprint：绑定setRobotFootprintPolygon 创建footprint_pub_发布机器人足迹published_footprint 创建costmap_publisher_ = std::make_unique发布代价地图costmap，话题名costmap，frame_id ->map 设置footprint 圆：setRobotFootprint(makeFootprintFromRadius(robot_radius_)); 多边形： 调用makeFootprintFromString(footprint_, new_footprint); 调用setRobotFootprint(new_footprint); 初始化清除代价地图服务clear_costmap_service_ = std::make_unique on_activate： 调用costmap_publisher_->on_activate() 调用footprint_pub_->on_activate() 检验tf是否正常运转 开线程更新地图，绑定mapUpdateLoop 调用start() 添加参数变更回调dynamicParametersCallback on_deactivate： 调用stop() 地图更新线程停掉，map_update_thread_->join() 调用costmap_publisher_->on_deactivate() 调用footprint_pub_->on_deactivate() on_cleanup：属性指针重置 on_shutdown： start：调用了代价地图的stop和pause之后可以调用该函数，订阅话题更新代价地图 获取默认插件和过滤插件layered_costmap_->getPlugins()和getFilters()，依次调用插件的->activate()，然后等待初始化完成 stop：停止代价地图更新并且停止话题订阅，依次调用插件的deactivate，并且相关属性切换 pause：暂停地图更新，但话题数据还是会传输 resume：恢复地图更新，知道初始化完成 updateMap：更新分层代价地图/插件地图 调用getRobotPose 调用layered_costmap_->updateMap 调用transformFootprint更新最新的footprint 调用footprint_pub_->publish发布footprint resetLayers：重置地图 重置主地图layered_costmap_->getCostmap()->resetMap 重置所有插件地图->reset() isCurrent：是否当前层地图 getRobotPose：获取小车位姿，调用nav2_util::getCurrentPose transformPoseToGlobalFrame：代价地图坐标转换成全局坐标，帧ID相等直接返回，否则调用nav2_util::transformPoseInTargetFrame getName：获取代价地图名称 getTransformTolerance：获取tf转换容差（单位秒） getCostmap：返回指向“主”成本地图的指针，该成本图接收来自所有层的更新。 getGlobalFrameID：返回主成本地图的帧ID getBaseFrameID：返回本地成本地图的帧ID getLayeredCostmap：获取单层代价地图指针 getRobotFootprintPolygon：获取机器人footprint的多边形msg，std::vector ->geometry_msgs::msg::Polygon getRobotFootprint：获取机器人footprint的配置，增补后的，可以通过配置重写或发布footprint话题修改 getUnpaddedRobotFootprint：获取机器人footprint的配置，未增补的，可以通过配置重写或发布footprint话题修改 getOrientedFootprint：获取有方向的足迹，调用getRobotPose和transformFootprint setRobotFootprint：设置机器人的足迹 调用padFootprint 调用layered_costmap_->setFootprint(padded_footprint_) setRobotFootprintPolygon：设置机器人足迹多边形，调用setRobotFootprint(toPointVector(footprint)) getTfBuffer：返回tf指针 getUseRadius：获取use_radius_参数，机器人足迹是否使用圆 getRobotRadius：获取robot_radius_，如果use_radius_ == true则有值 mapUpdateLoop：地图更新循环 start()调用后所有的插件激活，调用updateMap() 调用获取地图边界layered_costmap_->getBounds() 更新地图边界costmap_publisher_->updateBounds() 发布代价地图costmap_publisher_->publishCostmap() getParameters：获取节点参数 获取构造函数里面那些节点参数及filters地图过滤插件 设置插件信息到节点参数里面，例如：static_layer.plugin->nav2_costmap_2d::StaticLayer 获取地图过滤插件 参数校验 如果设置了footprint，调用makeFootprintFromString生成机器人足迹，否则使用圆 dynamicParametersCallback：参数变更回调函数，根据变更的参数做对应的操作 FootprintSubscriber：调用footprint话题，获取当前机器人的足迹，用于碰撞检测 FootprintSubscriber：构造函数 初始化参数，默认robot_base_frame = \"base_link\" 创建话题订阅footprint_sub_ = node->create_subscription，绑定回调footprint_callback getFootprintRaw：获取最新的footprint无方向性原始数据 调用toPointVector getFootprintInRobotFrame：获取最新的footprint有方向性数据 调用getFootprintRaw 调用nav2_util::getCurrentPose获取机器人当前位姿 调用transformFootprint footprint_callback：订阅回调 CostmapTopicCollisionChecker：通过订阅代价地图话题碰撞检测 CostmapTopicCollisionChecker：构造函数 关键参数 代价地图订阅者：CostmapSubscriber & costmap_sub_; 足迹订阅者：FootprintSubscriber & footprint_sub_; 足迹碰撞检测：FootprintCollisionChecker> collision_checker_; scorePose： fetch_costmap_and_footprint=true：调用collision_checker_.setCostmap(costmap_sub_.getCostmap()) 调用collision_checker_.worldToMap(pose.x, pose.y, cell_x, cell_y)转换坐标 碰撞检测调用collision_checker_.footprintCost(getFootprint(pose, fetch_costmap_and_footprint)) isCollisionFree：是否无碰撞，调用scorePose(pose, fetch_costmap_and_footprint) >= LETHAL_OBSTACLE，返回false getFootprint： fetch_latest_footprint=true：调用footprint_sub_.getFootprintInRobotFrame(footprint_, header) 调用transformFootprint(pose.x, pose.y, pose.theta, footprint_, footprint)返回小车所在位置的footprint costmap_2d_cloud节点 创建pub_marked发布voxel_marked_cloud话题 创建pub_unknown发布voxel_unknown_cloud话题 订阅体素网格voxel_grid话题，回调voxelCallback voxelCallback：体素网格回调 调用nav2_voxel_grid::VoxelGrid::getVoxel获取体素状态，然后调用mapToWorld3D转成世界坐标系，最后加入对应状态数组 调用pointCloud2Helper，然后调用pub_marked->publish，发布voxel_marked_cloud 调用pointCloud2Helper，然后调用pub_unknown->publish，发布voxel_unknown_cloud pointCloud2Helper：用于话题数据填充 voxel_grid 中标记点和未知点的 pointcloud2 的辅助函数 costmap_2d_marker节点 创建发布visualization_marker话题 订阅体素网格voxel_grid话题，回调voxelCallback voxelCallback：体素网格回调，调用nav2_voxel_grid::VoxelGrid::getVoxel获取体素状态，然后转成世界坐标系，最后加入数组，发布出来 Observation：以点云和源的原点形式存储观察结果数据结构类 Observation：默认无参构造 operator=：重写赋值运算符 Observation： 根据原始点和点云创建 Observation： 拷贝构造 Observation： 根据点云创建 ObservationBuffer：从传感器获取点云，将其转换为所需的帧并存储 bufferCloud：转换点云并存储起来，最后调用purgeStaleObservations getObservations：获取所有Observation数据的数组，先调用purgeStaleObservations isCurrent：数据是否是最新的 lock： unlock： resetLastUpdated：设置最新的更新时间 purgeStaleObservations：从缓存列表中清除过时的观察数据 代价地图插件 StaticLayer：静态层，继承于CostmapLayer，接收slam生成的地图，然后把代价添加到代价地图中 onInitialize：重写函数，在Layer的Initialize最后调用 调用getParameters 创建代价地图订阅map_sub_ = node->create_subscription，绑定incomingMap 如果subscribe_to_updates=true ，则创建地图更新订阅map_update_sub_ = node->create_subscription( map_topic_ + \"_updates\",...)，绑定incomingUpdate activate： deactivate：调用dyn_params_handler_.reset() reset： isClearable：是否可清除，静态地图不可清除，return false updateBounds：更新地图边界，通过该层的更新维度更新主成本图的边界 updateCosts：更新主代价地图中指定窗口的代价值 matchSize：适配主代价地图大小 getParameters：获取参数 调用declareParameter，声明设置参数，该函数会补全参数名称，类似name_ + \".\" + param_name enabled -> true subscribe_to_updates -> false map_subscribe_transient_local -> true transform_tolerance -> 0.0 map_topic -> \"\" 等等 添加参数变更函数回调dynamicParametersCallback processMap：处理来自话题的新地图数据 layered_costmap_->getCostmap()获取主代价地图 如果大小、分辨率和地图原点不匹配，直接重置，更新所有层代价地图layered_costmap_->resizeMap 或者只更新当前层代价地图resizeMap 调用interpretValue初始化静态地图数据 incomingMap：map_server的回调，用于更新代价地图 第一次接收，调用processMap，后面直接更新map_buffer_ = new_map; incomingUpdate：map_server的回调，用于更新代价地图从map_server（或SLAM）更新代价地图的回调，地图特定区域的更新 调用interpretValue转换修改代价值 interpretValue：将主题中给出的静态映射中的值解释为转换为成本图以供使用 dynamicParametersCallback：节点参数变更回调 ObstacleLayer：避障层，继承于CostmapLayer，接收激光和点云数据以填充到 2D 成本图中 onInitialize：重写的虚函数，在Layer的Initialize最后调用 调用declareParameter，声明设置参数，该函数会补全参数名称，类似name_ + \".\" + param_name name_ + \".\" + enabled -> true name_ + \".\" + footprint_clearing_enabled -> true name_ + \".\" + min_obstacle_height -> 0.0 name_ + \".\" + max_obstacle_height -> 2.0 name_ + \".\" + combination_method -> 1 name_ + \".\" + observation_sources -> \"\" 获取参数：track_unknown_space, transform_tolerance 添加参数变更回调dynamicParametersCallback 调用CostmapLayer::matchSize() 分割topics_string 设置和获取对应参数 创建观察者缓存，observation_buffers_.push_back(std::shared_ptr) marking == true -> marking_buffers_.push_back(observation_buffers_.back()) clearing == true -> clearing_buffers__.push_back(observation_buffers_.back()) data_type == \"LaserScan\" sub = std::make_shared>(...) filter = std::make_shared>(...) inf_is_valid==true, filter绑定laserScanValidInfCallback, 否则绑定laserScanCallback observation_subscribers_.push_back(sub); observation_notifiers_.push_back(filter); data_type == \"PointCloud2\" sub = std::make_shared>(...) filter = std::make_shared>(...)，filter 绑定pointCloud2Callback observation_subscribers_.push_back(sub); observation_notifiers_.push_back(filter); updateBounds：重写的虚函数，更新代价地图边界 rolling_window_ == true -> updateOrigin 调用useExtraBounds 调用getMarkingObservations 调用getClearingObservations 遍历clearing_observations，调用raytraceFreespace 遍历observations，障碍物高大于设置的最大值或小于设置的最小值或距离大于设置的最大值或小于设置的最小值，都跳过， 否则更新代价值index = getIndex(mx, my);costmap_[index] = LETHAL_OBSTACLE 调用updateFootprint updateCosts：重写的虚函数，更新主代价地图中指定窗口的代价值 combination_method == 0调用updateWithOverwrite combination_method == 1调用updateWithMax deactivate：- 遍历observation_subscribers_, 调用unsubscribe() activate：激活 遍历observation_notifiers_, 调用clear() 遍历observation_subscribers_, 调用subscribe() 调用resetBuffersLastUpdated reset：调用resetMaps(), resetBuffersLastUpdated() isClearable：return true dynamicParametersCallback：参数变更回调 resetBuffersLastUpdated：触发观察缓冲区的更新, 遍历observation_buffers_, 调用resetLastUpdated laserScanCallback：laserscan话题回调 调用transformLaserScanToPointCloud把scan转换为point cloud 调用ObservationBuffer->bufferCloud laserScanValidInfCallback：laserscan话题回调，同laserScanCallback, 只是该消息需要过滤以将 Inf 值转换为 range_max pointCloud2Callback：PointCloud2话题回调，调用ObservationBuffer->bufferCloud addStaticObservation：单元测试使用的方法 clearStaticObservations：单元测试使用的方法 getMarkingObservations：获取用于标记空间的观察结果, 遍历marking_buffers_, 调用对象的getObservations getClearingObservations：获取用于清理空间的观察结果, 遍历clearing_buffers_, 调用对象的getObservations raytraceFreespace：实现了一种光线追踪算法，用于在地图中清除障碍物，以便机器人能够在自由空间中移动。它遍历传感器的点云数据，并对每个点执行光线追踪操作，以消除障碍物并更新地图。 updateRaytraceBounds：使用光线跟踪窗口边界来处理更新代价图 updateFootprint：更新机器人足迹 VoxelLayer：体素层，继承于ObstacleLayer，采用激光和点云数据来填充环境的 3D 体素表示 onInitialize：重写虚函数，重写的虚函数，在Layer的Initialize最后调用 调用declareParameter，声明设置参数，该函数会补全参数名称，类似name_ + \".\" + param_name enabled -> true footprint_clearing_enabled -> true max_obstacle_height -> 2.0 z_voxels -> 10 origin_z -> 0 z_resolution -> 0.2 unknown_threshold -> 15 mark_threshold -> 0 combination_method -> 1 publish_voxel_map -> false publish_voxel_map == true ，创建体素层发布话题，voxel_pub_ = node->create_publisher(\"voxel_grid\",...) ，voxel_pub_->on_activate() 创建clearing_endpoints发布话题，node->create_publisher(\"clearing_endpoints\",...) ，clearing_endpoints_pub_->on_activate() 调用matchSize() 绑定参数变更回调dynamicParametersCallback updateBounds：重写虚函数，更新边界，跟父类的类似，可参考 updateOrigin：更新地图原点 调用copyMapRegion临时保存指定区域的地图信息(costmap_,voxel_map) 调用resetMaps(); 调用copyMapRegion把临时保存指定区域的地图信息拷贝回去(costmap_,voxel_map) isDiscretized：层是否是离散填充的, return true matchSize：重写虚函数 调用ObstacleLayer::matchSize() (nav2_voxel_grid::VoxelGrid)voxel_grid_.resize reset：重写虚函数 调用ObstacleLayer::reset() 调用resetMaps() isClearable：重写虚函数，return true resetMaps：重写虚函数 调用ObstacleLayer::resetMaps(), 父类ObstacleLayer以及再往上都没实现resetMaps，一直到Costmap2D才有 调用voxel_grid_.reset() raytraceFreespace：重写虚函数，跟父类的方法有一些不一样，转换了坐标，最后把发布的需要清除的点clearing_endpoints_pub_->publish worldToMap3DFloat：世界坐标转代价地图坐标 worldToMap3D：世界坐标转代价地图坐标 mapToWorld3D：代价地图坐标转世界坐标，+0.5是取的单元格中心位置 dist：3D中2点距离 getSizeInMetersZ：获取体素尺寸的高度（以米为单位） dynamicParametersCallback：参数变更回调 InflationLayer：膨胀层，继承于Layer，通过机器人的半径或足迹对成本图进行卷积的层，以防止碰撞和很大程度上简单的碰撞检查 onInitialize：重写函数，在Layer的Initialize最后调用 调用declareParameter，声明设置参数，该函数会补全参数名称，类似name_ + \".\" + param_name enabled -> true inflation_radius -> 0.55 cost_scaling_factor -> 10.0 inflate_unknown -> false inflate_around_unknown -> false 添加绑定参数变更回调dynamicParametersCallback 调用matchSize() updateBounds：重写函数，更新边界 updateCosts：重写函数，更新代价 matchSize：重写函数, *getMutex()->Costmap2D * costmap = (LayeredCostmap *)layered_costmap_->getCostmap() 获取代价地图分辨率resolution_ = costmap->getResolution() 获取单元格膨胀半径cell_inflation_radius_ = cellDistance(inflation_radius_) 调用computeCaches() isClearable：return false reset：重写函数，调用matchSize() computeCost：给一个距离计算代价值 距离为0->LETHAL_OBSTACLE distance * resolution_ -> INSCRIBED_INFLATED_OBSTACLE 否则算出一个缩放因子，计算代价值，(INSCRIBED_INFLATED_OBSTACLE - 1) * factor getMutex：返回可重入锁 onFootprintChanged：重写函数，足迹改变后的处理，*getMutex()->(LayeredCostmap *)layered_costmap_->getInscribedRadius() ->cellDistance(inflation_radius_)->computeCaches() distanceLookup：查找预先计算的距离 costLookup：查找预先计算的代价值 computeCaches：计算距离缓存，基于膨胀半径计算距离和代价缓存 缓存距离，计算每个点到原点的距离，cached_distances_[i * cache_length_ + j] = hypot(i, j) 缓存代价值，cached_costs_[i * cache_length_ + j] = computeCost(cached_distances_[i * cache_length_ + j]); 调用generateIntegerDistances generateIntegerDistances：计算距离缓存 cellDistance：计算距离缓存，(LayeredCostmap *)layered_costmap_->getCostmap()->cellDistance(world_dist) enqueue：在缓存距离里更新搜索加入新单元 dynamicParametersCallback：参数变更回调 RangeSensorLayer：传感器层，继承于CostmapLayer，接收红外/声纳/相似点测量传感器并填充到成本图中 onInitialize：重写的虚函数，在Layer的Initialize最后调用 调用to_cost(0.5), CostmapLayer::matchSize(), resetRange() 调用declareParameter，声明设置参数，该函数会补全参数名称，类似name_ + \".\" + param_name 遍历所有话题数组 如果input_sensor_type == InputSensorType::VARIABLE ->processRangeMessageFunc_ = &RangeSensorLayer::processVariableRangeMsg 如果input_sensor_type == InputSensorType::FIXED ->processRangeMessageFunc_ = &RangeSensorLayer::processFixedRangeMsg 如果input_sensor_type == InputSensorType::ALL ->processRangeMessageFunc_ = &RangeSensorLayer::processRangeMsg 依次创建订阅，range_subs_.push_back(node->create_subscription(topic_name,...) ，绑定bufferIncomingRangeMsg updateBounds：重写的虚函数，更新代价地图边界 layered_costmap_->isRolling() -> updateOrigin 调用updateCostmap() 调用resetRange() updateCosts：重写的虚函数，更新主代价地图中指定窗口的代价值 reset：调用deactivate(), resetMaps(), activate() deactivate：range_msgs_buffer_.clear() activate：range_msgs_buffer_.clear() isClearable：return true bufferIncomingRangeMsg：传感器话题回调，range_msgs_buffer_.push_back(*range_message) updateCostmap()：将所有传感器处理到从回调缓冲的成本图中，备份传感器数据，然后清除，遍历备份的传感器数据，调用processRangeMessageFunc_处理 updateCostmap(sensor_msgs::msg::Range & range_message, bool clear_sensor_cone);：使用处理后的值更新实际成本图 调用获取当前位姿tf_->transform(in, out, global_frame_, transform_tolerance_)，传感器坐标转全局坐标 调用获取目标位姿in.point.x = range_message.range;tf_->transform(in, out, global_frame_, transform_tolerance_) ，传感器坐标转全局坐标 调用worldToMapNoBounds(ox, oy, Ox, Oy) 调用touch(ox, oy, &min_x_, &min_y_, &max_x_, &max_y_) 调用worldToMap(tx, ty, aa, ab) 调用setCost(aa, ab, 233) 调用touch(tx, ty, &min_x_, &min_y_, &max_x_, &max_y_) 更新声呐锥左右边 更新单元格，除非 inflate_cone_ 设置为 100 %，否则我们仅更新范围内的单元格（部分膨胀）传感器锥体，在代价地图上投影为三角形。 调用orient2d, area 需要更新，调用mapToWorld, update_cell processRangeMsg： range_message.min_range == range_message.max_range, 调用processFixedRangeMsg 否则调用processVariableRangeMsg processFixedRangeMsg：处理固定范围传入的范围传感器数据, 调用updateCostmap(range_message, clear_sensor_cone) processVariableRangeMsg：处理可变范围的传感器数据 调用updateCostmap(range_message, clear_sensor_cone) resetRange：重置x,y的最大值和最小值 gamma：函数计算了一个与角度 theta 相关的权重因子。如果输入的角度 theta 超过了 max_angle_，则返回 0.0，否则返回一个与 theta 相关的值 delta： 函数计算了一个与角度 phi 相关的权重因子 sensor_model：传感器模型函数 get_deltas：用于计算在给定角度下，x 和 y 方向上的步进距离。其计算方式根据角度的正切值来确定，如果正切值为0，则 x 方向的步进距离为0， 否则计算出步进距离，并通过 copysign 函数根据角度的余弦值确定方向。 update_cell：更新单元格，调用worldToMap, sensor_model, to_prob(getCost(x, y)), to_cost, setCost to_prob：代价避障值转百分比 to_cost：求概率的成本值，入参p * nav2_costmap_2d::LETHAL_OBSTACLE area：计算三角形面积 orient2d：求 3 个向量 A、B、C 的叉积 DenoiseLayer：去噪层，继承于Layer，层过滤噪声引起的独立障碍物（白色成本图像素）或小障碍团体 代价地图过滤器 CostmapFilter：代价地图过滤插件基类，继承于Layer onInitialize：重写函数，在Layer的Initialize最后调用 调用declareParameter，声明设置参数，该函数会补全参数名称，类似name_ + \".\" + param_name enabled -> true filter_info_topic -> true transform_tolerance -> 0.1 创建插件开启关闭服务，enable_service_ = node->create_service(name_ + \"/toggle_filter\",...) ，绑定enableCallback getMutex：返回可重入锁 updateBounds：更新最后的机器人位姿 updateCosts：调用process activate：调用initializeFilter(filter_info_topic_) deactivate：调用resetFilter() reset：调用resetFilter()和initializeFilter(filter_info_topic_) isClearable：return false initializeFilter：纯虚函数，初始化代价图过滤器。 创建对过滤器相关主题的订阅 process：纯虚函数，一个如何使用地图数据的算法，用于计算数据填充 Costmap2D 并根据处理后的数据执行操作 resetFilter：纯虚函数，重置代价地图过滤，停掉所有的订阅 enableCallback：地图过滤开启关闭回调函数，修改标志位 transformPose：将机器人姿态从当前层转换为掩模帧，如果当前帧（掩码帧）不是global_frame则，把global_frame全局坐标转换为掩码坐标，否则直接赋值global_pose worldToMask：世界坐标转换为掩码坐标。与 Costmap2D::worldToMap() 方法类似，但直接与 OccupancyGrid-s 一起使用。 getMaskData：获取过滤器掩码中某个单元格的数据 SpeedFilter：速度过滤器，继承于CostmapFilter initializeFilter：初始化过滤以及订阅相关话题 调用declareParameter，声明设置参数，该函数会补全参数名称，类似name_ + \".\" + param_name speed_limit_topic->speed_limit 创建订阅者，filter_info_sub_ = node->create_subscription(filter_info_topic_) 绑定filterInfoCallback 创建限速发布话题，speed_limit_pub_ = node->create_publisher(speed_limit_topic,...) process：过滤处理 调用transformPose 调用worldToMask 调用getMaskData 发布限速话题speed_limit_pub_->publish(std::move(msg)) resetFilter：重置过滤相关信息，相关话题on_deactivate或数据reset isActive：该层过滤filter_mask_是否有数据 filterInfoCallback：过滤话题回调 设置是否使用绝对速度还是使用百分比 创建掩码订阅，mask_sub_ = node->create_subscription(msg->filter_mask_topic_,...) ，绑定maskCallback maskCallback：掩码话题回调，更新数据filter_mask_ KeepoutFilter：禁区过滤器，继承于CostmapFilter，读取禁区掩码并在地图中标记禁区区域，防止限制区域内的规划或控制 initializeFilter 创建订阅者，filter_info_sub_ = node->create_subscription(filter_info_topic_) 绑定filterInfoCallback process：坐标转换等，处理更新代价地图，详情看源码 resetFilter：重置过滤相关信息，相关数据reset isActive：该层过滤mask_costmap_是否有数据 filterInfoCallback：过滤话题回调 创建掩码订阅，mask_sub_ = node->create_subscription(msg->filter_mask_topic_,...) ，绑定maskCallback maskCallback：掩码回调，创建限制区域代价地图mask_costmap_ = std::make_unique(*msg); 工具 array_parser.hpp parseVVF函数，解析二维数组字符串 解析字符串二维数组，例如[[1.0, 2.0], [3.3, 4.4, 5.5], ...] input_ss.peek()：获取下一个字符，但不消费 input_ss.get()：用于从流中获取字符 碰到[，深度增加1， 碰到]深度减一，如果深度为1，内层数组已结束 碰到,、\\t和空字符串，跳过get()跳过 其他则是数字，peek()一直移，一直input_ss >> value，添加到当前层数组，直到碰到上面情况，get()出去 footprint.hpp calculateMinAndMaxDistances函数：计算(0,0)点到足迹的最大最小距离，遍历足迹数组，调用distance计算到点和distanceToLine计算到线，比较获取到最大和最小距离 makeFootprintFromString函数：根据字符串生成足迹footprint，调用parseVVF() makeFootprintFromRadius函数：根据半径生成，16个点的园 padFootprint函数：足迹增补 transformFootprint函数：转换机器人足迹，更新到机器人最新位置 toPointVector函数：转换多边形到点，geometry_msgs::msg::Polygon->std::vector costmap_math.hpp sign函数：x sign0函数：x 0.0 ? 1.0 : 0.0); distance函数：hypot(x1 - x0, y1 - y0) distanceToLine函数：点到直线距离 常量 NO_INFORMATION = 255;：未知 LETHAL_OBSTACLE = 254;致命障碍物 INSCRIBED_INFLATED_OBSTACLE = 253;：膨胀层障碍物 MAX_NON_OBSTACLE = 252;：无障碍物的阈值上限，只要低于该值都不算障碍物 FREE_SPACE = 0;：无障碍物 nav2_amcl TODO，先了解工作流以及有哪些功能，具体实现需要再深入，比较难懂 "},"Utils/docker/Docker.html":{"url":"Utils/docker/Docker.html","title":"Docker","keywords":"","body":"1、Docker基本组成 1.1、Docker Client 客户端 1.2、Docker Daemon 守护进程客户端/守护进程C/S模式我们通过客户端发送命令给守护进程，守护进程执行结果返回给客户端 1.3、Docker Image 镜像容器的基石层叠的只读文件系统 1.4、Docker Container 容器通过镜像启动 1.5、Docker Registry 仓库公有私有 1.6、示意图 2、Docker容器相关技术简介 2.1、Docker依赖的Linux内核特性 2.1.1、Namespaces命名空间 编程语言封装 -> 代码隔离 操作系统 系统资源的隔离 进程、网络、文件系统... 分为5种命名空间： PID(Process ID) 进程隔离 NET(Network) 管理网络接口 IPC(InterProcess Communication) 管理跨进程通信的访问 MNT(Mount) 管理挂载点 UTS(Unix Timesharing System) 隔离内核和版本标识 2.1.2、Control groups(cgroups)控制组 用来分配资源 资源限制 优先级设定 资源计量 资源控制 2.2、Docker容器的能力 文件系统隔离：每个容器都有自己的root文件系统 进程隔离：每个容器都运行在自己的进程环境中 网络隔离：容器间的虚拟网络接口和IP地址都是分开的 资源隔离和分组：使用cgroups将CPU和内存之类的资源独立分配给每个Docker容器 3、Docker客户端与守护进程 1、客户端与守护进程通信 2、Remote API与Docker守护进程进行通信 RESTful 风格API 3、连接方式 unix://var/run/docker.sock(默认) tcp://host:port fd://sockerfd 4、Docker守护进程的配置和操作 1、查看守护进程ps -ef | grep dockersudo docker stats 查看docker的运行状态 2、使用service命令管理sudo service docker start/stop/restart 3、Docker的启动选项 docker -d [OPTIONS] 运行相关： -d： 以守护的形式运行 -D,--debug=false -e,--exec-driver=\"native\" -g,--graph=\"/var/lib/docker\" --icc=true -l,--log-level=\"info\" --label=[] 标签区别，key-value形式：name=nzb -p,--pidfile=\"/var/run/docker.pid 服务器连接相关： -G,--group=\"docker\" -H,--host=[] 启动选项，默认 -H unix://var/run/docker.sock --tls=false --tlscacert=\"/home/sven/.docker/ca.pem\" --tlscert=\"/home/sven/.docker/cert.pem\" --tlskey=\"/home/sven/.docker/key.pem\" --tlsverify=false Remote API相关： --api-enable-cors=false 存储相关： -s,--storage-driver=\"\" --selinux-enabled=false --storage-opt=[] Registry相关： --insecure-registry=[] --registry-mirror=[] 网络设置相关： -b,--bridge=\"\" --bip=\"\" --fixed-cidr=\"\" --fixed-cidr-v6=\"\" --dns=[] --dns-search=[] --ip=0.0.0.0 --ip-forward=true --ip-masq=true --iptables=true --ipv6=false --mtu=0 4、启动配置文件 /etc/default/docker 5、Docker的远程访问 1、环境准备 另一台安装Docker的服务器 --label name=server1/2 修改Docker守护进程启动选项，区别服务器-H tcp://0.0.0.0:2375测试：curl http://host:2375/info 保证Client API与Server API 版本一致 修改客户端配置docker -H tcp:host:2375或使用环境变量DOCKER_HOSTexport DOCKER_HOST=\"tcp://host:2375\"测试：docker info 如想访问本地的docker服务：export DOCKER_HOST=\"\" 置空环境变量 如果docker开启了远程服务，如何访问本地：修改启动选项-H，可以有多个： -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock 6、Docker容器 1、基本操作 1.1、启动容器docker run IMAGE [COMMAND] [ARG]例： docker run ubuntu echo 'Hello World' 1.2、启动交互式容器docker run -i -t IMAGE /bin/bash -i --interactive=true | false 默认是false -t --tty=true | false 默认是false 1.3、查看容器docker ps [-a] [-l] -a：列出使用容器 -l：列出最新创建的容器 不指定参数则列出所有正在运行的容器 docker inspect 容器id或容器名字：查看容器详细信息 1.4、自定义容器名 docker run --name=自定义名 -i -t IMAGE /bin/bash 1.5、重新启动停止的容器 docker start [-i] 容器名 -i：以交互的方式重新启动容器 1.6、删除停止的容器 docker rm 容器名 2、守护式容器 2.1、以守护形式运行容器 docker run -i -t IMAGE /bin/bash Ctrl+P Ctrl+Q 组合键退出就会在后台运行 2.2、附加到运行中的容器 docker attach 容器名或容器id 2.3、启动守护式容器 docker run -d 镜像名 [COMMAND] [ARG...] -d：启动时使用后台的方式启用 例： docker run --name dc1 -d ubuntu /bin/sh -c \"while true; do echo hello world; sleep 1; done\" 2.4、查看容器日志 docker logs [-f] [-t] [--tail] 容器名 -f --follows=true | false 默认是false 一直跟踪并放回结果 -t --timestamps=true | false 默认是false 加上时间戳 --tail=\"all\" 返回结尾多少条的数据 2.5、查看容器内进程 docker top 容器名 2.6、在运行中的容器内启动新进程 docker exec [-d] [-i] [-t] 容器名 [COMMAND] [ARG...] 进入mysql容器： docker exec -it 容器名 bash 2.7、停止守护式容器 docker stop 容器名 或 docker kill 容器名 7、容器中部署静态网站 7.1、设置容器的端口映射 run [-P] [-p] -P,--publish-all=true | false 默认是false 将为容器暴露的所有端口进行映射 例： docker run -P -i -t ubuntu /bin/bash -p,--pulish=[] 指定映射哪些容器的端口 四种方式： containerPort docker run -p 80 -i -t ubuntu /bin/bash 随机映射 hostPort:containerPort docker run -p 8080:80 -i -t ubuntu /bin/bash ip:containerPort docker run -p 0.0.0.0:80 -i -t ubuntu /bin/bash ip:hostPort:containerPort docker run -p 0.0.0.0:8080:80 -i -t ubuntu /bin/bash 7.2、部署流程 创建映射80端口的交互式容器 安装Nginx 安装文本编辑器vim 创建静态文件 修改Nginx配置文件 运行Nginx 验证网站访问 8、查看和删除镜像 1、镜像的存储地址 docker info 查看镜像的存储地址 2、列出镜像 docker images [OPTIONS] [REPOSITORY] -a,--all=false 显示所有镜像，包括中间层镜像 -f,-filter --no-trunc=false id截断 -q,--quiet=false 只显示镜像的唯一IDREPOSITORY仓库是包含一系列的镜像，而REGISTRY仓库包含很多REPOSITORY仓库TAG例如：ubuntu:14.04ubuntu:latest 3、查看镜像 docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...] -f,--format=\"\" 4、删除镜像 docker rmi [OPTIONS] IMAGE [IMAGE...] -f,--force=false 强制删除镜像 - --no-prune=false 不会删除未打标签的镜像 例： docker rmi $(docker images -q ubuntu) 删除所有Ubuntu仓库中的所有镜像 9、获取和推送镜像 1、查找镜像 1.1、Docker Hub https://registry.hub.docker.com 1.2、docker search [OPTIONS] TERM --automated=false 是否是自动构建的镜像 --no-trunc=false -s,--stars=0 最多返回25个结果 2、拉取镜像 docker pull [OPTIONS] NAME[:TAG] -a,--all-tags=false 下载带有标签的的仓库的所有镜像 使用--registry-mirror选项加速拉取镜像速度 修改：etc/default/docker 添加：DOCKER_OPTS=\"--registry-mirror=http://MIRROR-ADDR\" 例：https://www.daocloud.io 注册获取加速地址 3、推送镜像 docker push NAME[:TAG] NAME:仓库名 TAG:标签名 10、构建镜像 1、docker commit 通过容器构建docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] CONTAINER 容器名 -a,--author=\"\" -m,--message=\"\" -p,--pause=true 构建镜像时不暂停运行的容器 2、docker build 通过Dockerfile文件构建 例： #First Dockerfile From ubuntu:14.04 MAINTAINER dormancypress \"dormancypress@outlook.com\" RUN apt-get update RUN apt-get install -y nginx EXPOSE 80 docker build [OPTIONS] PATH | URL | - --force-rm=false --no-cache=false 不使用缓存 --pull=false -q,--quite=false 不显示构建过程 --rm=true -t,--tag=\"\" 指定构建的镜像的名字 PATH | URL 构建镜像的路径，可以使用“.”表示当前文件夹 11、Dockerfile指令 1、指令格式 # Comment 注释 INSTRUCTION argument 指令 2、指令 2.1、FROM FROM FROM : 已经存在的镜像 基础镜像 必须是第一条非注释指令 2.2、MAINTAINER MAINTAINER 指定镜像的作者信息，包含镜像的所有者和联系信息相当于前面的commit命令的-a选项 2.3、RUN 指定当前镜像中运行的命令(镜像构建时运行的) -RUN (shell模式) /bin/sh -c command 例： RUN echo hello -RUN [\"executable\",\"param1\",\"param2\"] (exec模式) 例： RUN [\"/bin/bash\",\"-c\",\"echo hello\"] 2.4、EXPOSE EXPOSE [...] 指定运行该镜像的容器使用的端口（只是告诉容器使用的端口） 为了安全起见，run命令中还要指定端口 docker run -p 80 -d dormancypress/df_test1 nginx -g \"daemon off;\" 2.5、CMD容器运行时运行的指令，会被docker run 命令中的指令覆盖 CMD [\"executable\",\"param1\",\"param2\"] (exec模式) CMD command param1 param2 (shell模式) CMD [\"param1\",\"param2\"] (作为ENTERYPOINT指令的默认参数) 例：CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] 2.6、ENTERYPOINT 容器运行时运行的指令，不会被docker run 命令中的指令覆盖 ENTERYPOINT [\"executable\",\"param1\",\"param2\"] (exec模式) ENTERYPOINT command param1 param2 (shell模式) 2.7、ADD ADD ... ADD [\"\"...\"\"](适用于文件路径中有空格的情况) 2.8、COPY COPY ... COPY [\"\"...\"\"](适用于文件路径中有空格的情况) ADD vs COPY ADD包含类型tar的解压功能 如果当纯复制文件，Docker推荐使用COPY 2.9、VOLUME添加容器卷VOLUME [\"/data\"] 2.10、WORKDIR WORKDIR /path/to/workdir 一般不使用绝对路径，如果使用相对路径，会一直传递下去 2.11、ENV 设置环境变量与WORKDIR类似 ENV ENV = 2.12、USER 指定镜像会以什么用户来运行 2.13、ONBUILD 镜像触发器 当一个镜像被其他镜像作为基础镜像时执行 会在构建过程中插入指令 12、构建过程 1、构建过程 从基础镜像运行一个容器 执行一条指令，对容器做出修改 执行类似docker commit的操作，提交一个新的镜像层 在基于刚提交的镜像运行一个新容器 执行Dockerfile中的下一条指令，直至所有指令执行完毕 ps:构建中会删除中间层容器，而不会删除中间层镜像，所以可以使用中间层镜像进行调试，查找错误 2、镜像缓存 构建缓存: 构建一次后再构建就会使用构建缓存 不使用缓存 使用--no-cache选项 或 ENV REFRESH_DATE 2019-4-7 3、查看镜像构建的过程 docker history [image] --no-trunc: 不截断输出完整信息 13、容器的网络连接 1、Docker容器的网络基础 Linux虚拟网桥特点： 可设置IP地址 相当于拥有一个隐藏的虚拟网卡 docker0的地址划分： IP：172.17.42.1 子网掩码：255.255.0.0 MAC:02:42:ac:11:00:00到02:42:11:ff:ff 总共提供了65534个地址 需要使用网桥管理工具：sudo apt-get install bridge-utils 查看网桥：sudo brctl show 添加虚拟网桥：sudo brctl add br0 修改地址：sudo ifconfig docker0 192.168.200.1 netmask 255.255.255.0 修改docker0地址： sudo ifconfig docker0 192.168.200.1 netmask 255.255.255.0 更改docker守护进程的启动配置 /etc/default/docker 中添加DOCKER_OPS值 DOCKER_OPS=\"-b=br0\" 2、Docker容器的互联 2.1、运行所有容器互联（默认） 因为每次关闭重启容器IP地址都会改变所有使用--link选项可以使新启动的容器为其起别名，就不用担心IP改变 --linkdocker run --link=[CONTAINER_NAME]:[ALIAS] [IMAGE] [COMMAND] 2.2、拒绝容器间的互联 --icc=false 2.3、允许特点容器间的连接 --icc=false --iptables=true --link 3、Docker容器与外部网络的连接 3.1、ip-forward --ip-forward=true(默认) 允许数据转发 查看ip_forward的值： sysctl net.ipv4.conf.all.forwarding 3.2、iptables 什么是iptables: Iptables是Linux内核集成的包过滤防火墙系统，几乎所有的Linux发行版本都会包含IPtables的功能。 表(table):下图中的nat、mangle、raw、filter... 链(chain):代表数据处理的不同环节 规则(rule):每个链下的操作 ACCEPT、REJECT、DROP filter表中包含的链： INPUT FORWARD OUTPUT 查看iptables： sudo iptables [-t filter] -L -n -t:指定表名（默认） 3.3、允许特定IP访问容器 sudo iptables -I DOCKER -s 禁止访问ip -d 目的ip -p TCP --dport 80 -j ACCEPT 3.4、限制IP访问容器 sudo iptables -I DOCKER -s 禁止访问ip -d 目的ip -p TCP --dport 80 -j DROP 14、Docker容器的数据卷 什么是数据卷： 数据卷是经过特殊设计的目录，可以绕过联合文件系统（UFS）,为一个或多个容器提供访问。 数据卷设计的目的，在于设计的永久化，他完全独立于容器的生存周期，因此，Docker不会再容器删除时删除其挂载的数据卷， 也不会存在类似的垃圾收集机制，对容器引用的数据卷进行处理。 1、为容器添加数据卷 docker run -v ~/container_data:/data -it ubuntu /bin/bash ~/container_data： 本机目录 /data： 容器目录 2、为数据卷添加访问权限 docker run -v ~/container_data:/data:ro -it ubuntu /bin/bash ro: 只读 3、使用Dockerfile构建包含数据卷的镜像 Dockerfile指令 VOLUME[\"/data\"] 但是，利用这个镜像创建的容器构建的数据卷都是不一样的，则不能实现共享。 15、Docker的数据卷容器 1、挂载数据卷容器的方法 docker run --volumes-from [CONTAINER NAME] 即时删除了数据卷容器，挂载了这个数据卷容器的容器还是能正常使用。因为只要一个数据卷还在被使用就不会被删除。 16、Docker数据卷的备份和还原 1、数据备份方法 docker run --volumes-from [container name] -v $(pwd):/backup:wr ubuntu tar -cvf /backup/backup.tar [container data volume] $(pwd):备份文件存储的目录 /backup：容器中的目录 wr ：读写（默认） [container data volume]：需要压缩的数据卷目录 tar -cvf/backup/backup.tar [container data volume]：备份操作（压缩） 2、数据还原方法 docker run --volumes-from [container name] -v $(pwd):/backup:wr ubuntu tar -xvf /backup/backup.tar [container data volume] 17、Docker容器的跨主机连接 1、使用网桥实现跨主机容器连接 1.1、环境准备 Mac OS X + Parallels 两台Ubuntu14.04虚拟机 安装网桥管理工具： apt-get install bridge-utils ip地址： Host1:10.211.55.3 Host2:10.211.55.5 修改/etc/network/interfaces文件 auto bro iface bro inet static address 10.211.55.3 netmask 255.255.255.0 geteway 10.211.55.1 bridge_ports eth0 Docker设置 修改/etc/default/docker文件 -b指定使用自定义网桥 -b=br0 --fixed-cidr限制ip地址分配范围 IP地址划分： Host1:10.211.55.64/26 地址范围：10.211.55.65~10.211.55.126 Host2:10.211.55.128/26 地址范围：10.211.55.129~10.211.55.190 2、使用Open vSwitch实现跨主机容器连接 3、使用Weave实现跨主机容器连接 Docker 磁盘空间占用和清理 磁盘空间占用 Docker 的内置 CLI 指令docker system df，可用于查询镜像（Images）、容器（Containers）和本地卷（Local Volumes）等空间使用大户的空间占用情况。 [root@dockercon ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE kalilinux/kali-linux-docker latest c927a54ec8a4 8 days ago 1.88GB nginx latest 3f8a4339aadd 9 days ago 108MB busybox latest 6ad733544a63 2 months ago 1.13MB [root@dockercon ~]# docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 3 0 1.994GB 1.994GB (100%) Containers 0 0 0B 0B Local Volumes 0 0 0B 0B Build Cache 0B 0B 可以进一步通过-v参数查看空间占用细节 [root@dockercon ~]# docker system df -v #镜像空间使用情况 Images space usage: REPOSITORY TAG IMAGE ID CREATED ago SIZE SHARED SIZE UNIQUE SiZE CONTAINERS kalilinux/kali-linux-docker latest c927a54ec8a4 8 days ago ago 1.884GB 0B 1.884GB 0 nginx latest 3f8a4339aadd 9 days ago ago 108.5MB 0B 108.5MB 0 busybox latest 6ad733544a63 2 months ago ago 1.129MB 0B 1.129MB 0 #容器空间使用情况 Containers space usage: CONTAINER ID IMAGE COMMAND LOCAL VOLUMES SIZE CREATED ago STATUS NAMES #本地卷使用情况 Local Volumes space usage: VOLUME NAME LINKS SIZE Build cache usage: 0B 空间清理 不同状态 已使用镜像（used image） 未引用镜像（unreferenced image） 悬空镜像（dangling image） 镜像含义 指所有已被容器（包括已停止的）关联的镜像 没有被分配或使用在容器中的镜像 未配置任何 Tag （也就无法被引用）的镜像 Docker内置自动清理 通过 Docker 内置的 CLI 指令docker system prune来进行自动空间清理。 [root@dockercon ~]# docker system prune --help Usage: docker system prune [OPTIONS] Remove unused data Options: -a, --all Remove all unused images not just dangling ones --filter filter Provide filter values (e.g. 'label==') -f, --force Do not prompt for confirmation --volumes Prune volumes docker system prune 自动清理说明 该指令默认会清除所有如下资源： 已停止的容器（container） 未被任何容器所使用的卷（volume） 未被任何容器所关联的网络（network） 所有悬空镜像（image）。 该指令默认只会清除悬空镜像，未被使用的镜像不会被删除。添加-a 或 --all参数后，可以一并清除所有未使用的镜像和悬空镜像。 可以添加-f 或 --force参数用以忽略相关告警确认信息。 [root@dockercon ~]# docker system prune --help Usage: docker system prune [OPTIONS] Remove unused data Options: -a, --all Remove all unused images not just dangling ones --filter filter Provide filter values (e.g. 'label==') -f, --force Do not prompt for confirmation --volumes Prune volumes [root@dockercon ~]# docker system prune --all WARNING! This will remove: - all stopped containers - all networks not used by at least one container - all images without at least one container associated to them - all build cache Are you sure you want to continue? [y/N] y Deleted Containers: f095899e7343e160d5b32d0688a6561a1a7f6af91c42ffe966649240b58ca23f Deleted Images: untagged: busybox:latest untagged: busybox@sha256:e3789c406237e25d6139035a17981be5f1ccdae9c392d1623a02d31621a12bcc deleted: sha256:6ad733544a6317992a6fac4eb19fe1df577d4dec7529efec28a5bd0edad0fd30 deleted: sha256:0271b8eebde3fa9a6126b1f2335e170f902731ab4942f9f1914e77016540c7bb untagged: kalilinux/kali-linux-docker:latest untagged: kalilinux/kali-linux-docker@sha256:28ff9e4bf40f7399e0570394a2d3d388a7b60c748be1b0a180c14c87afad1968 deleted: sha256:c927a54ec8a46164d7046b2a6dc09b2fce52b3066317d50cf73d14fa9778ca48 untagged: alpine:latest untagged: alpine@sha256:ccba511b1d6b5f1d83825a94f9d5b05528db456d9cf14a1ea1db892c939cda64 untagged: alpine-io:latest Total reclaimed space: 5.219GB "},"Utils/docker/01-docker-history.html":{"url":"Utils/docker/01-docker-history.html","title":"docker-history","keywords":"","body":"datetime:2023/03/31 17:48 author:nzb 构建过程 1、构建过程 从基础镜像运行一个容器 执行一条指令，对容器做出修改 执行类似docker commit的操作，提交一个新的镜像层 在基于刚提交的镜像运行一个新容器 执行Dockerfile中的下一条指令，直至所有指令执行完毕 ps:构建中会删除中间层容器，而不会删除中间层镜像，所以可以使用中间层镜像进行调试，查找错误 2、镜像缓存 构建缓存: 构建一次后再构建就会使用构建缓存 不使用缓存 使用--no-cache选项 或 ENV REFRESH_DATE 2019-4-7 3、查看镜像构建的过程 docker history [image] --no-trunc: 不截断输出完整信息 只显示构建命令 docker history --format { {.CreatedBy} } --no-trunc=true e01eb2e99ca6 |sed \"s?/bin/sh\\ -c\\ \\#(nop)\\ ??g\"|sed \"s?/bin/sh\\ -c?RUN?g\" | tac 示例 ADD file:7dc8819fd3d4b84ad19fb836e5bfda64a5ffefc371166f70d4d41dff6b22d450 in / RUN [ -z \"$(apt-get indextargets)\" ] RUN set -xe && echo '#!/bin/sh' > /usr/sbin/policy-rc.d && echo 'exit 101' >> /usr/sbin/policy-rc.d && chmod +x /usr/sbin/policy-rc.d && dpkg-divert --local --rename --add /sbin/initctl && cp -a /usr/sbin/policy-rc.d /sbin/initctl && sed -i 's/^exit.*/exit 0/' /sbin/initctl && echo 'force-unsafe-io' > /etc/dpkg/dpkg.cfg.d/docker-apt-speedup && echo 'DPkg::Post-Invoke { \"rm -f /var/cache/apt/archives/*.deb /var/cache/apt/archives/partial/*.deb /var/cache/apt/*.bin || true\"; };' > /etc/apt/apt.conf.d/docker-clean && echo 'APT::Update::Post-Invoke { \"rm -f /var/cache/apt/archives/*.deb /var/cache/apt/archives/partial/*.deb /var/cache/apt/*.bin || true\"; };' >> /etc/apt/apt.conf.d/docker-clean && echo 'Dir::Cache::pkgcache \"\"; Dir::Cache::srcpkgcache \"\";' >> /etc/apt/apt.conf.d/docker-clean && echo 'Acquire::Languages \"none\";' > /etc/apt/apt.conf.d/docker-no-languages && echo 'Acquire::GzipIndexes \"true\"; Acquire::CompressionTypes::Order:: \"gz\";' > /etc/apt/apt.conf.d/docker-gzip-indexes && echo 'Apt::AutoRemove::SuggestsImportant \"false\";' > /etc/apt/apt.conf.d/docker-autoremove-suggests RUN mkdir -p /run/systemd && echo 'docker' > /run/systemd/container CMD [\"/bin/bash\"] RUN echo 'Etc/UTC' > /etc/timezone && ln -s /usr/share/zoneinfo/Etc/UTC /etc/localtime && apt-get update && apt-get install -q -y --no-install-recommends tzdata && rm -rf /var/lib/apt/lists/* RUN apt-get update && apt-get install -q -y --no-install-recommends dirmngr gnupg2 && rm -rf /var/lib/apt/lists/* RUN apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 RUN echo \"deb http://packages.ros.org/ros/ubuntu bionic main\" > /etc/apt/sources.list.d/ros1-latest.list ENV LANG=C.UTF-8 ENV LC_ALL=C.UTF-8 ENV ROS_DISTRO=melodic RUN apt-get update && apt-get install -y --no-install-recommends ros-melodic-ros-core=1.4.1-0* && rm -rf /var/lib/apt/lists/* COPY file:cbbaa0f5d6a276512315f5b4d7347e94a120cefbda9058ebb0d678847ff4837f in / ENTRYPOINT [\"/ros_entrypoint.sh\"] CMD [\"bash\"] RUN apt-get update && apt-get install --no-install-recommends -y build-essential python-rosdep python-rosinstall python-vcstools && rm -rf /var/lib/apt/lists/* RUN rosdep init && rosdep update --rosdistro $ROS_DISTRO RUN apt-get update && apt-get install -y --no-install-recommends ros-melodic-ros-base=1.4.1-0* && rm -rf /var/lib/apt/lists/* RUN apt-get update && apt-get install -y --no-install-recommends ros-melodic-robot=1.4.1-0* && rm -rf /var/lib/apt/lists/* RUN sed -i 's/ports.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g' /etc/apt/sources.list RUN apt-get update RUN apt-get install -y openssh-server RUN echo -e 'y\\n'|ssh-keygen -q -t rsa -N \"\" -f ~/.ssh/id_rsa RUN apt-get remove -y openssh-server bash RUN apt install -y python-pip RUN pip install serial -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install pyserial -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install flask -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install flask_cors -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install Twisted -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install flask_sockets -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install pyjson -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install protobuf -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install requests -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN pip install zmq -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com RUN apt install -y iftop RUN mkdir -p /config && mkdir -p /logs && mkdir -p /data && mkdir -p /walle WORKDIR /upper_computer RUN cd /upper_computer &&git pull &&git checkout dev_qys_lansi_new &&rm -rf install &&/bin/bash -c 'source \"/opt/ros/melodic/setup.bash\" &&catkin_make install' &&cp -r /upper_computer/src/upper_computer_ui/script/upper_computer_ui/dist /upper_computer/install/lib/python2.7/dist-packages/upper_computer_ui/ ENTRYPOINT [\"/upper_computer/start.sh\"] CMD [\"/bin/bash\"] CMD [\"/bin/bash\"] bash RUN cd /upper_computer &&git pull &&git checkout prd_master_alpha &&git pull &&rm -rf install &&/bin/bash -c 'source \"/opt/ros/melodic/setup.bash\" &&\\catkin_make install' ENTRYPOINT [\"/upper_computer/start.sh\"] CMD [\"/bin/bash\"] CMD [\"/bin/bash\"] bash bash bash ENV DIRPATH=/tmp/py39 WORKDIR /tmp/py39 COPY file:a37b26f8d2f91243c4ffc8eaf134fba1ff8f257488060568c5b9f6ff705ec716 in /tmp/py39 COPY file:a6cac2b37ef882b75b365dc79d169031648a6f4f1322be042b9e4edf784b7e37 in /tmp/py39 RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list RUN apt-get clean RUN apt-get update && apt-get -y upgrade RUN apt-get install -y build-essential python-dev python-setuptools python-pip python-smbus build-essential libncursesw5-dev libgdbm-dev libc6-dev zlib1g-dev libsqlite3-dev tk-dev libssl-dev openssl libffi-dev RUN tar -zxvf Python-3.9.0b4.tgz WORKDIR /tmp/py39/Python-3.9.0b4 RUN ./configure --prefix=/usr/local/python39 --with-ssl --enable-optimizations RUN make RUN make install RUN ln -s /usr/local/python39/bin/python3.9 /usr/bin/python3.9 && ln -s /usr/local/python39/bin/pip3.9 /usr/bin/pip3.9 WORKDIR /tmp/py39 RUN pip3.9 install -r requirements_py39.txt -i https://pypi.tuna.tsinghua.edu.cn/simple RUN rm -rf $DIRPATH WORKDIR /upper_computer RUN cd /upper_computer &&git pull &&git checkout prd_master_alpha &&git pull &&/bin/bash -c 'source \"/opt/ros/melodic/setup.bash\" &&\\catkin_make install' ENTRYPOINT [\"/upper_computer/start.sh\"] CMD [\"/bin/bash\"] --name test_082501 COPY file:80e64585a1026126a9ce85c15b4f1bfaf23abe894769170ce033ab4a4c768ed9 in /upper_computer/ RUN cd /upper_computer &&pip3.9 install zmq numpy serial pyserial protobuf==3.20.1 -i https://pypi.douban.com/simple &&git pull &&git checkout prd_master_alpha &&git pull &&rm -rf install &&/bin/bash -c 'source \"/opt/ros/melodic/setup.bash\" &&\\catkin_make install' ENTRYPOINT [\"/upper_computer/start.sh\"] CMD [\"/bin/bash\"] RUN pip install openpyxl==2.6.4 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com RUN pip3.9 install openpyxl==2.6.4 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com RUN cd /upper_computer &&rm -f version &&git checkout prd_master_alpha &&git pull &&git checkout phoenix_master &&git pull &&rm -rf install/ build/ devel/ &&/bin/bash -c 'source \"/opt/ros/melodic/setup.bash\" &&\\catkin_make install' ENTRYPOINT [\"/upper_computer/start.sh\"] CMD [\"/bin/bash\"] RUN pip3.9 install modbus_tk xlrd -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com RUN cd /upper_computer &&rm -f version &&git checkout prd_master_alpha &&git pull &&git checkout phoenix_master &&git pull &&rm -rf install/ build/ devel/ &&/bin/bash -c 'source \"/opt/ros/melodic/setup.bash\" &&\\catkin_make install' ENTRYPOINT [\"/upper_computer/start.sh\"] CMD [\"/bin/bash\"] "},"Utils/docker/02-container-diff.html":{"url":"Utils/docker/02-container-diff.html","title":"container-diff","keywords":"","body":"datetime:2023/03/30 10:52 author:nzb container-diff 什么是 container-diff container-diff 是一个用来分析容器镜像的工具，可以分析以下内容 Docker Image History Image file system Image size Apt packages RPM packages pip packages npm packages container-diff 命令 分析单个镜像 命令 container-diff analyze [Run default analyzers] container-diff analyze --type=history [History] container-diff analyze --type=file [File System] container-diff analyze --type=size [Size] container-diff analyze --type=rpm [RPM] container-diff analyze --type=pip [Pip] container-diff analyze --type=apt [Apt] container-diff analyze --type=node [Node] container-diff analyze --type=apt --type=node [Apt and Node] # --type= --type= --type=,... 参数 -j：JSON 格式化输出 -o --order：排序，针对 file/package，其余还是按照名称排序 -w：输出文件 -t --type：分析类型 示例： container-diff analyze registry.cn-hangzhou.aliyuncs.com/quicktron_robot/upper-computer-arm64:GitLabBase_20220621 --type=file -o -w ./result_file_0621.txt 分析多个镜像对比 命令 container-diff diff [Run default differs] container-diff diff --type=history [History] container-diff diff --type=file [File System] container-diff diff --type=size [Size] container-diff diff --type=rpm [RPM] container-diff diff --type=pip [Pip] container-diff diff --type=apt [Apt] container-diff diff --type=node [Node] 参数同上 示例 container-diff diff registry.cn-hangzhou.aliyuncs.com/quicktron_robot/upper-computer-arm64:GitLabBase_20230328 registry.cn-hangzhou.aliyuncs.com/quicktron_robot/upper-computer-arm64:GitLabBase_20220621 --type=file -o -w ./result_file_20230328_20220621.txt "},"Utils/docker/03-制作容器镜像的最佳实践.html":{"url":"Utils/docker/03-制作容器镜像的最佳实践.html","title":"制作容器镜像的最佳实践","keywords":"","body":"datetime:2023/04/04 19:48 author:nzb 制作容器镜像的最佳实践 1、概述 这篇文章主要是我日常工作中的制作镜像的实践, 同时结合我学习到的关于镜像制作的相关文章总结出来的. 包括通用的容器最佳实践, nginx, python 容器最佳实践. 最佳实践的目的一方面保证镜像是可复用的, 提升 DevOps 效率, 另一方面是为了提高安全性. 希望对各位有所帮助. 本文分为四部分内容, 分别是: 通用容器镜像最佳实践 NGINX 容器镜像最佳实践 以及 Python 容器最佳实践 2、通用容器镜像最佳实践 2.1、使用 LABEL maintainer LABEL maintainer 指令设置镜像的作者姓名和邮箱字段。示例如下: LABEL maintainer=\"cuikaidong@foxmail.com\" 2.2、复用镜像 建议尽量使用 FROM 语句复用合适的上游镜像。这可确保镜像在更新时可以轻松从上游镜像中获取安全补丁，而不必直接更新依赖项。 此外，在 FROM 指令中使用标签 tag（例如 alpine:3.13），使用户能够清楚地了解镜像所基于的上游镜像版本。 ❗ 禁止 使用 latest tag 以确保镜像不会受到 latest 上游镜像版本的重大更改的影响。 2.3、保持标签 TAGS 的兼容性 给自己的镜像打标签时，注意保持向后兼容性。例如，如果制作了一个名为 example 的镜像，并且它当前为 1.0 版，那么可以提供一个 example:1 标签。 后续要更新镜像时，只要它继续与原始镜像兼容，就可以继续标记新镜像为example:1，并且该 tag 的下游消费者将能够在不中断的情况下获得更新。 如果后续发布了不兼容的更新，那么应该切换到一个新 tag，例如 example:2。那么下游消费者可以按照自身实际情况升级到新版本，而不会因为新的不兼容镜像而造成事故。 但是任何使用 example:latest 的下游消费者都会承担引入不兼容更改的风险, 所以这也是前面我强烈建议不要使用 latest tag 的原因. 2.4、避免多个进程 建议 不要 在一个容器内启动多个服务，例如 nginx 和 后端 app。因为容器是轻量级的，可以很容易地通过 Docker Compose 或 Kubernetes 链接在一起。 Kubernetes 或基于此的 TKE 容器平台通过将相关镜像调度到单个 pod 中，轻松地对它们进行集中管理。 2.5、在封装脚本中使用 EXEC 指令 许多镜像会通过在启动应用程序之前使用封装脚本进行一些设置。如果您的镜像使用这样的脚本，那么该脚本最后应该使用 exec 启动应用程序， 以便用应用程序的进程替换该脚本的进程。如果不使用 exec ，那么容器运行时发送的信号（比如 TERM 或 SIGKILL）将转到封装脚本，而不是应用程序的进程。这不是我们所期望的。 2.6、清除临时文件 应删除在生成过程中创建的所有临时文件 。这还包括使用 ADD 指令添加的任何文件。例如，👍 我们强烈建议您在执行apt-get install 操作之后运行 rm -rf /var/lib/apt/lists/* 命令。 通过如下创建 RUN 语句，可以防止 apt-get 缓存存储在镜像层中： RUN apt-get update && apt-get install -y \\ curl \\ s3cmd=1.1.* \\ && rm -rf /var/lib/apt/lists/* 请注意，如果您改为： RUN apt-get install curl -y RUN apt-get install s3cmd -y && rm -rf /var/lib/apt/lists/* 那么，第一个 apt-get 调用会在这一层 (image layer) 中留下额外的文件，并且在稍后运行rm -rf ... 操作时，无法删除这些文件。额外的文件在最终镜像中不可见，但它们会占用空间。 另外，在一条 RUN 语句中执行多个命令可以减少镜像中的层数，从而缩短下载和安装时间。 yum 的例子如下: RUN yum -y install curl && yum -y install s3cmd && yum clean all -y 备注: RUN、COPY 和 ADD 步骤会创建镜像层。 每个层包含与前一层的差异项。 镜像层会增加最终镜像的大小。 📓 提示: 将相关命令（apt-get install）放入同一 RUN 步骤。 在同一 RUN 步骤中删除创建的文件。 避免使用 apt-get upgrade 或 yum upgrade all ，因为它会把所有包升级到最新版本 2.7、按正确的顺序放置指令 容器构建过程中, 读取 dockerfile 并从上到下运行指令。成功执行的每一条指令都会创建一个层，在下次构建此镜像或另一个镜像时可以重用该层。建议在 Dockerfile 的顶部放置很少更改的指令。这样做可以确保同一镜像的下一次构建速度非常快，因为上层更改的缓存还在, 可以复用。 例如，如果正在处理一个 dockerfile，其中包含一个用于安装正在迭代的文件的 ADD 指令，以及一个用于 apt-get install 包的 RUN 指令，那么最好将 ADD 命令放在最后： FROM alpine:3.11 RUN apt-get -y install curl && rm -rf /var/lib/apt/lists/* ADD app /app 这样，每次编辑 app 并重新运行 docker build 时，系统都会为 apt-get 命令复用缓存层，并且只为 ADD 操作生成新层。 如果反过来, dockerfile 如下： FROM alpine:3.11 ADD app /app RUN apt-get -y install curl && rm -rf /var/lib/apt/lists/* 那么，每次更改 app 然后再次运行 docker build 时，ADD 操作都会使镜像层的缓存失效，因此必须重新运行 apt-get 操作。 2.8、标记重要端口 EXPOSE 指令使容器中的端口对主机系统和其他容器可用。虽然可以指定使用 docker run -p 调用公开端口，但在dockerfile 中使用 EXPOSE 指令可以通过显式声明应用程序需要运行的端口，使人和应用程序更容易使用您的镜像： 暴露的端口将显示在 docker ps 下。 docker inspect 返回的镜像的元数据中也会显示暴露的端口。 当将一个容器链接到另一个容器时，会链接暴露的端口。 2.9、设置环境变量 👍️ 使用 ENV 指令设置环境变量是很好的实践。一个例子是设置项目的版本。这使得人们在不查看 dockerfile 的情况下很容易找到版本。 另一个例子是在公布一条可以被另一个进程使用的路径，比如 JAVA_HOME. 2.10、避免默认密码 ❗ 最好 避免设置默认密码 。许多人会扩展基础镜像，但是忘记删除或更改默认密码。如果为生产中的用户分配了一个众所周知的密码，这可能会导致安全问题。 👍️ 应该使用环境变量, secret 或其他 K8s 加密方案来配置密码 。 如果确实选择设置默认密码，请确保在容器启动时显示适当的警告消息。消息应该通知用户默认密码的值，并说明如何更改，例如设置什么环境变量。 2.11、禁用 SSHD ❗ 禁止在镜像中运行 sshd。可以使用 docker exec 命令访问本地主机上运行的容器。或者，可以使用 kubectl exec命令来访问在 K8s 或 TKE 容器平台上运行的容器。 在镜像中安装和运行 sshd 会遭受潜在攻击, 需要额外的安全补丁修复。 2.12、将 VOLUMES（卷） 用于持久数据 镜像应使用卷来存储持久数据。这样，Kubernetes 或 TKE 将网络存储挂载到运行容器的节点，如果容器移动到新节点，则存储将重新连接到该节点。 通过将卷用于所有持久化存储的需求，即使重新启动或移动容器，也会保留持久化内容。如果镜像将数据写入容器内的任意位置，则可能数据会丢失。 此外，在 Dockerfile 中显式定义卷使镜像的消费者很容易理解在运行镜像时必须定义哪些卷。 有关如何在 K8s 或 TKE 容器平台中使用卷的更多信息，请参阅 Kubernetes documentation. 2.13、使用非 root 用户运行容器进程 默认情况下，Docker 用容器内部的 root 运行容器进程。这是一个不安全的做法，因为如果攻击者设法突破容器，他们可以获得对 Docker 宿主机的 root 权限。 ❗ 注意: 如果容器中是 root，那么逃逸出来就是主机上的 root。 2.14、使用多阶段构建 多阶段构建指在Dockerfile中使用多个FROM语句，每个FROM指令都可以使用不同的基础镜像，并且是一个独立的子构建阶段。使用多阶段构建打包Java应用具有构建安全、构建速度快、镜像文件体积小等优点。 利用 多阶段构建 来创建一个用于构建工件的临时镜像，该工件将被复制到生产镜像上。临时构建镜像将与与该映像关联的原始文件、文件夹和依赖项一起丢弃。 这会产生了一个精益，生产就绪的镜像。 一个用例是使用非 Alpine 基础镜像来安装需要编译的依赖项。然后可以将 wheel 文件复制到最终镜像。 Python 示例如下: # 临时阶段 FROM python:3.6 as base COPY requirements.txt / RUN pip wheel --no-cache-dir --no-deps --wheel-dir /wheels -r requirements.txt # 最终阶段 FROM python:3.6-alpine COPY --from=base /wheels /wheels COPY --from=base requirements.txt . RUN pip install --no-cache /wheels/* # flask, gunicorn, pycrypto WORKDIR /app COPY . /app 使用前大小: 705MB, 使用后大小: 103MB 2.15、❗ 禁止在容器中存储机密信息 禁止在容器中存储机密信息, 包括: 敏感信息 数据库凭据 ssh 密钥 用户名和密码 api 令牌等 以上信息可以通过: 环境变量 ENV 传递 卷 VOLUME 挂载 2.16、避免将文件放入 /tmp 中 对于一些应用程序(如: python 的 gunicorn), 会将某些缓存信息或心跳检测信息写入 /tmp 中, 这对 /tmp 的读写性能有较高要求, 如果 /tmp 挂载的是普通磁盘, 可能导致严重的性能问题. 在某些 Linux 发行版中，/tmp 通过 tmpfs 文件系统存储在内存中。但是，Docker 容器默认情况下没有为 /tmp 打开 tmpfs ： $ docker run --rm -it ubuntu:18.04 df Filesystem 1K-blocks Used Available Use% Mounted on overlay 31263648 25656756 3995732 87% / tmpfs 65536 0 65536 0% /dev tmpfs 4026608 0 4026608 0% /sys/fs/cgroup /dev/mapper/root 31263648 25656756 3995732 87% /etc/hosts shm 65536 0 65536 0% /dev/shm 如上所示，/tmp 正在使用标准的 Docker overlay 文件系统：它由普通的块设备或计算机正在使用的硬盘驱动器支持。这可能导致性能问题 . 针对这类应用程序, 通用的解决方案是将其临时文件存储在其他地方。特别是，如果你看上面你会看到 /dev/shm 使用 shm 文件系统共享内存和内存文件系统。所以你需要做的就是使用 /dev/shm 而不是 /tmp 2.17、使用 Alpine Linux 基础镜像 (谨慎采纳) 使用基于Alpine Linux 的镜像，因为它只提供必要的包, 生成的镜像更小。 收益有: 减少了主机成本，因为使用的磁盘空间更少 更快的构建、下载和运行时间 更安全（因为包和库更少） 更快的部署 示例如下: FROM python:3.6-alpine WORKDIR /app COPY requirements.txt / RUN pip install -r /requirements.txt # flask and gunicorn COPY . /app 使用前大小: 702MB, 使用后大小: 102MB ❗ 注意: 谨慎使用 alpine, 我看到过使用 Alpine Linux 产生的一大堆问题，因为它建立在 musl libc 之上，而不是大多数 Linux 发行版使用的 GNU libc（glibc）。 问题有: 日期时间格式的错误, 由于堆栈较小导致的崩溃等等。 2.18、使用 .dockerignore 排除无关文件 要排除与构建无关的文件，请使用 .dockerignore 文件。此文件支持与 .gitignore 文件类似的排除模式。具体请参阅 .dockerignore 文件。 2.19、不要安装不必要的包 为了降低复杂性，依赖性，文件大小和构建时间，请避免安装额外的或不必要的应用程序包。例如，不需要在数据库镜像中包含文本编辑器。 2.20、解耦应用程序 每个容器应该只有一个进程。将应用程序分离到多个容器中可以更容易地水平扩展和重用容器。例如，Web 应用程序堆栈 LNMP 可能包含三个独立的容器，每个容器都有自己独特的映像，以分离的方式管理 Web 服务器, 应用程序，缓存数据库和数据库。 将每个容器限制为一个进程是一个很好的经验法则，但它不是一个硬性规则。例如，可以 使用 init 进程生成 容器 ，另外某些程序可能会自行生成其他子进程 (如: nginx)。 根据自己的经验进行判断，尽可能保持容器简洁和模块化。如果容器彼此依赖，则可以使用 容器网络 或 K8s Sidecar 来确保这些容器可以进行通信。 2.21、对多行参数进行排序 建议通过按字母顺序排序多行参数来方便后续的更改。这有助于避免重复包并使列表更容易更新。这也使 PR 更容易阅读和审查。在反斜杠（\\）之前添加空格也有帮助。 下面是来自一个示例 openjdk 图像： ... apt-get update; \\ apt-get install -y --no-install-recommends \\ dirmngr \\ gnupg \\ wget \\ ; \\ rm -rf /var/lib/apt/lists/*; \\ ... 3、NGINX 容器镜像最佳实践 如果您直接在基础硬件或虚拟机上运行 NGINX，通常需要一个 NGINX 实例来使用所有可用的 CPU。由于 NGINX 是多进程模式，通常你会启动多个 worker processes，每个工作进程都是不同的进程，以便利用所有 CPU。 但是，在容器中运行时，如果将 worker_processes 设置为 auto, 会根据容器所在宿主机的 CPU 核数启动相应进程数. 比如, 我之前在物理机上运行 NGINX 容器使用 auto 参数, 尽管 CPU limit 设置为 2, 但是 NGINX 会启动 64 (物理机 CPU 数) 个进程. 因此，👍️建议根据 实际需求或 CPU limit 的设置配置 nginx.conf, 如下: worker_processes 2; "},"Utils/docker/04-制作Python_Docker镜像的最佳实践.html":{"url":"Utils/docker/04-制作Python_Docker镜像的最佳实践.html","title":"制作Python_Docker镜像的最佳实践","keywords":"","body":"datetime:2023/04/08 17:16 author:nzb 制作 Python Docker 镜像的最佳实践 1、通用 Docker 容器镜像最佳实践 这里也再次罗列一下对 Python Docker 镜像也适用的一些通用最佳实践。 使用 LABEL maintainer 标记重要端口 设置环境变量 使用非 root 用户运行容器进程 使用 .dockerignore 排除无关文件 1.1、Python 镜像推荐设置的环境变量 Python 中推荐的常见环境变量如下： # 设置环境变量 ENV PYTHONDONTWRITEBYTECODE 1 ENV PYTHONUNBUFFERED 1 ENV PYTHONDONTWRITEBYTECODE 1: 建议构建 Docker 镜像时一直为 1, 防止 python 将 pyc 文件写入硬盘 ENV PYTHONUNBUFFERED 1: 建议构建 Docker 镜像时一直为 1, 防止 python 缓冲 (buffering) stdout 和 stderr, 以便更容易地进行容器日志记录 ❌不再建议使用 ENV DEBUG 0 环境变量，没必要。 1.2、使用非 root 用户运行容器进程 出于安全考虑，推荐运行 Python 程序前，创建 非 root 用户并切换到该用户。 # 创建一个具有明确 UID 的非 root 用户，并增加访问 /app 文件夹的权限。 RUN adduser -u 5678 --disabled-password --gecos \"\" appuser && chown -R appuser /app USER appuser 1.3、使用 .dockerignore 排除无关文件 需要排除的无关文件一般如下： **/__pycache__ **/*venv **/.classpath **/.dockerignore **/.env **/.git **/.gitignore **/.project **/.settings **/.toolstarget **/.vs **/.vscode **/*.*proj.user **/*.dbmdl **/*.jfm **/bin **/charts **/docker-compose* **/compose* **/Dockerfile* **/node_modules **/npm-debug.log **/obj **/secrets.dev.yaml **/values.dev.yaml *.db .python-version LICENSE README.md 这里选择几个说明下： **/__pycache__: python 缓存目录 **/*venv: Python 虚拟环境目录。很多 Python 开发习惯将虚拟环境目录创建在项目下，一般命名为：.venv 或 venv **/.env: Python 环境变量文件 **/.git **/.gitignore: git 相关目录和文件 **/.vscode: 编辑器、IDE 相关目录 **/charts: Helm Chart 相关文件 **/docker-compose*: docker compose 相关文件 *.db: 如果使用 sqllite 的相关数据库文件 .python-version: pyenv 的 .python-version 文件 2、不建议使用 Alpine 作为 Python 的基础镜像 为什么呢？大多数 Linux 发行版使用 GNU 版本（glibc）的标准 C 库，几乎每个 C 程序都需要这个库，包括 Python。但是 Alpine Linux 使用 musl, Alpine 禁用了 Linux wheel 支持。 理由如下： 缺少大量依赖 CPython 语言运行时的相关依赖 openssl 相关依赖 libffi 相关依赖 gcc 相关依赖 数据库驱动相关依赖 pip 相关依赖 构建可能更耗时 Alpine Linux 使用 musl，一些二进制 wheel 是针对 glibc 编译的，但是 Alpine 禁用了 Linux wheel 支持。现在大多数 Python 包都包括 PyPI 上的二进制 wheel，大大加快了安装时间。但是如果你使用 Alpine Linux，你可能需要编译你使用的每个 Python 包中的所有 C 代码。 基于 Alpine 构建的 Python 镜像反而可能更大 乍一听似乎违反常识，但是仔细一想，因为上面罗列的原因，确实会导致镜像更大的情况。 📚️Reference: Using Alpine can make Python Docker builds 50× slower (pythonspeed.com) 这里以这个 Demo FastAPI Python 程序 为例，其基于 Alpine 的 Dockerfile 地址是这个：链接 因为缺少很多依赖，所以在用 pip 安装之前，就需要尽可能全地安装相关依赖： RUN set -eux \\ && apk add --no-cache --virtual .build-deps build-base \\ openssl-dev libffi-dev gcc musl-dev python3-dev \\ && pip install --upgrade pip setuptools wheel \\ && pip install --upgrade -r /app/requirements.txt \\ && rm -rf /root/.cache/pip 这里也展示一下基于 Alpine 构建完成后的 镜像未压缩大小： 基于 Alpine 的 Python Demo 镜像大小：472 MB; 相比之下，基于 slim 的只有 189 MB 在上面代码的这一步，就占用了太多空间： 🤔 思考 : 可能上面一段可以精简，但是要判断对于哪个 Python 项目，可以精简哪些包，实在是太难了。 + apk add --no-cache --virtual .build-deps build-base openssl-dev libffi-dev gcc musl-dev python3-dev fetch https://dl-cdn.alpinelinux.org/alpine/v3.17/main/x86_64/APKINDEX.tar.gz fetch https://dl-cdn.alpinelinux.org/alpine/v3.17/community/x86_64/APKINDEX.tar.gz (1/28) Installing libgcc (12.2.1_git20220924-r4) (2/28) Installing libstdc++ (12.2.1_git20220924-r4) (3/28) Installing binutils (2.39-r2) (4/28) Installing libmagic (5.43-r0) (5/28) Installing file (5.43-r0) (6/28) Installing libgomp (12.2.1_git20220924-r4) (7/28) Installing libatomic (12.2.1_git20220924-r4) (8/28) Installing gmp (6.2.1-r2) (9/28) Installing isl25 (0.25-r0) (10/28) Installing mpfr4 (4.1.0-r0) (11/28) Installing mpc1 (1.2.1-r1) (12/28) Installing gcc (12.2.1_git20220924-r4) (13/28) Installing libstdc++-dev (12.2.1_git20220924-r4) (14/28) Installing musl-dev (1.2.3-r4) (15/28) Installing libc-dev (0.7.2-r3) (16/28) Installing g++ (12.2.1_git20220924-r4) (17/28) Installing make (4.3-r1) (18/28) Installing fortify-headers (1.1-r1) (19/28) Installing patch (2.7.6-r8) (20/28) Installing build-base (0.5-r3) (21/28) Installing pkgconf (1.9.3-r0) (22/28) Installing openssl-dev (3.0.7-r0) (23/28) Installing linux-headers (5.19.5-r0) (24/28) Installing libffi-dev (3.4.4-r0) (25/28) Installing mpdecimal (2.5.1-r1) (26/28) Installing python3 (3.10.9-r1) (27/28) Installing python3-dev (3.10.9-r1) (28/28) Installing .build-deps (20221214.074929) Executing busybox-1.35.0-r29.trigger OK: 358 MiB in 65 packages ... 3、建议使用官方的 python slim 镜像作为基础镜像 继续上面，所以我是建议：使用官方的 python slim 镜像作为基础镜像 镜像库是这个：https://hub.docker.com/_/python 并且使用 python:-slim 作为基础镜像，能用 python:-slim-bullseye 作为基础镜像更好（因为更新，相对就更安全一些）. 这个镜像不包含默认标签中的常用包，只包含运行 python 所需的最小包。这个镜像是基于 Debian 的。 使用官方 python slim 的理由还包括： 稳定性 安全升级更及时 依赖更新更及时 依赖更全 Python 版本升级更及时 镜像更小 📚️Reference: The best Docker base image for your Python application (Sep 2022) (pythonspeed.com) 4、一般情况下，Python 镜像构建不需要使用 \"多阶段构建\" 一般情况下，Python 镜像构建不需要使用 \"多阶段构建\". 理由如下： Python 没有像 Golang 一样，可以把所有依赖打成一个单一的二进制包 Python 也没有像 Java 一样，可以在 JDK 上构建，在 JRE 上运行 Python 复杂而散落的依赖关系，在 \"多阶段构建\" 时会增加复杂度 … 如果有一些特殊情况，可以尝试使用 \"多阶段构建\" 压缩镜像体积： 构建阶段需要安装编译器 Python 项目复杂，用到了其他语言代码（如 C/C++/Rust) 5、pip 小技巧 使用 pip 安装依赖时，可以添加 --no-cache-dir 减少镜像体积： # 安装 pip 依赖 COPY requirements.txt . RUN python -m pip install --no-cache-dir --upgrade -r requirements.txt 6、Python Dockerfile 最佳实践样例 FROM python:3.10-slim LABEL maintainer=\"cuikaidong@foxmail.com\" EXPOSE 8000 # Keeps Python from generating .pyc files in the container ENV PYTHONDONTWRITEBYTECODE=1 # Turns off buffering for easier container logging ENV PYTHONUNBUFFERED=1 # Install pip requirements COPY requirements.txt . RUN python -m pip install --no-cache-dir --upgrade -r requirements.txt WORKDIR /app COPY . /app # Creates a non-root user with an explicit UID and adds permission to access the /app folder RUN adduser -u 5678 --disabled-password --gecos \"\" appuser && chown -R appuser /app USER appuser CMD [\"uvicorn\", \"shortener_app.main:app\", \"--host\", \"0.0.0.0\"] 7、总结 制作 Python Docker 容器镜像的最佳实践。最佳实践的目的一方面是为了减小镜像体积，提升 DevOps 效率，另一方面是为了提高安全性. 最佳实践如下: 推荐 2 个 Python 的环境变量 ENV PYTHONDONTWRITEBYTECODE 1 ENV PYTHONUNBUFFERED 1 使用非 root 用户运行容器进程 使用 .dockerignore 排除无关文件 不建议使用 Alpine 作为 Python 的基础镜像 建议使用官方的 python slim 镜像作为基础镜像 一般情况下, Python 镜像构建不需要使用 \"多阶段构建\" pip 小技巧: --no-cache-dir "},"Utils/docker/FastDFS.html":{"url":"Utils/docker/FastDFS.html","title":"FastDFS","keywords":"","body":"datetime:2020/1/3 14:24 author:nzb 使用Docker安装FastDFS分布式文件系统 拉取镜像 docker image pull delron/fastdfs 运行tracker docker run -itd --network=host --name fastdfs-tracker -v /var/fdfs/tracker:/var/fdfs delron/fastdfs 将fastDFS tracker运行目录映射到本机的 /var/fdfs/tracker目录中。 查看是否允许起来 docker ls 停止运行 docker stop fastdfs-tracker 重新运行 docker start fastdfs-tracker 运行storage docker run -itd --network=host --name fastdfs-storage -e TRACKER_SERVER=192.168.1.218:22122 -v /var/fdfs/storage:/var/fdfs delron/fastdfs storage TRACKER_SERVER=本机的ip地址:22122 本机ip地址不要使用127.0.0.1 将fastDFS storage运行目录映射到本机的/var/fdfs/storage目录中 查看是否允许起来 docker ls 停止运行 docker stop fastdfs-storage 重新运行 docker start fastdfs-storage 注意：如果无法重新运行，可以删除/var/fdfs/storage/data目录下的fdfs_storaged.pid 文件，然后重新运行storage。 Django项目之FastDFS文件存储系统 FastDFS的Python客户端 python版本的FastDFS客户端使用说明参考：https://github.com/jefforeilly/fdfs_client-py 安装 安装fdfs_client-py-master.zip到虚拟环境中 pip install fdfs_client-py-master.zip pip install mutagen pip install requests 配置 在项目/utils目录下新建fastdfs目录，新建client.conf配置文件 # connect timeout in seconds # default value is 30s connect_timeout=30 # network timeout in seconds # default value is 30s network_timeout=60 # the base path to store log files base_path=FastDFS客户端存放日志文件的目录 # tracker_server can ocur more than once, and tracker_server format is # \"host:port\", host can be hostname or ip address tracker_server=172.17.0.1:22122 #standard log level as syslog, case insensitive, value list: ### emerg for emergency ### alert ### crit for critical ### error ### warn for warning ### notice ### info ### debug log_level=info # if use connection pool # default value is false # since V4.05 use_connection_pool = false # connections whose the idle time exceeds this time will be closed # unit: second # default value is 3600 # since V4.05 connection_pool_max_idle_time = 3600 # if load FastDFS parameters from tracker server # since V4.05 # default value is false load_fdfs_parameters_from_tracker=false # if use storage ID instead of IP address # same as tracker.conf # valid only when load_fdfs_parameters_from_tracker is false # default value is false # since V4.05 use_storage_id = false # specify storage ids filename, can use relative or absolute path # same as tracker.conf # valid only when load_fdfs_parameters_from_tracker is false # since V4.05 storage_ids_filename = storage_ids.conf #HTTP settings http.tracker_server_port=80 #use \"#include\" directive to include HTTP other settiongs ##include http.conf 注意：需要修改一下client.conf配置文件 # FastDFS客户端存放日志文件的目录 base_path= # 运行tracker服务的机器ip tracker_server=172.17.0.1:22122 自定义Django文件存储系统 Django自带文件存储系统，但是默认文件存储在本地，将文件保存到FastDFS服务器上，所以需要自定义文件存储系统。 在项目/utils/fastdfs目录中创建fdfs_storage.py文件，实现可以使用FastDFS存储文件的存储类如下 from django.conf import settings from django.core.files.storage import Storage from django.utils.deconstruct import deconstructible from fdfs_client.client import Fdfs_client @deconstructible class FastDFSStorage(Storage): def __init__(self, base_url=None, client_conf=None): \"\"\" 初始化 :param base_url: 用于构造图片完整路径使用，图片服务器的域名 :param client_conf: FastDFS客户端配置文件的路径 \"\"\" if base_url is None: base_url = settings.FDFS_URL self.base_url = base_url if client_conf is None: client_conf = settings.FDFS_CLIENT_CONF self.client_conf = client_conf def _open(self, name, mode='rb'): \"\"\" 用不到打开文件，所以省略 \"\"\" pass def _save(self, name, content): \"\"\" 在FastDFS中保存文件 :param name: 传入的文件名 :param content: 文件内容 :return: 保存到数据库中的FastDFS的文件名 \"\"\" client = Fdfs_client(self.client_conf) ret = client.upload_by_buffer(content.read()) if ret.get(\"Status\") != \"Upload successed.\": raise Exception(\"upload file failed\") file_name = ret.get(\"Remote file_id\") return file_name def url(self, name): \"\"\" 返回文件的完整URL路径 :param name: 数据库中保存的文件名 :return: 完整的URL \"\"\" return self.base_url + name def exists(self, name): \"\"\" 判断文件是否存在，FastDFS可以自行解决文件的重名问题 所以此处返回False，告诉Django上传的都是新文件 :param name: 文件名 :return: False \"\"\" return False 说明: 自定义文件存储系统的方法如下： 1）需要继承自django.core.files.storage.Storage，如 from django.core.files.storage import Storage class FastDFSStorage(Storage): ... 2）支持Django不带任何参数来实例化存储类，也就是说任何设置都应该从django.conf.settings中获取 from django.conf import settings from django.core.files.storage import Storage class FastDFSStorage(Storage): def __init__(self, base_url=None, client_conf=None): if base_url is None: base_url = settings.FDFS_URL self.base_url = base_url if client_conf is None: client_conf = settings.FDFS_CLIENT_CONF self.client_conf = client_conf 3）存储类中必须实现_open()和_save()方法，以及任何后续使用中可能用到的其他方法。 _open(name, mode='rb') 被Storage.open()调用，在打开文件时被使用。 _save(name, content) 被Storage.save()调用，name是传入的文件名，content是Django接收到的文件内容，该方法需要将content文件内容保存。 Django会将该方法的返回值保存到数据库中对应的文件字段，也就是说该方法应该返回要保存在数据库中的文件名称信息。 exists(name) 如果名为name的文件在文件系统中存在，则返回True，否则返回False。 url(name) 返回文件的完整访问URL delete(name) 删除name的文件 listdir(path) 列出指定路径的内容 size(name) 返回name文件的总大小 注意，并不是这些方法全部都要实现，可以省略用不到的方法。 4）需要为存储类添加django.utils.deconstruct.deconstructible装饰器 在Django配置中设置自定义文件存储类 在settings.py文件中添加设置 # django文件存储 DEFAULT_FILE_STORAGE = '项目名.utils.fastdfs.fdfs_storage.FastDFSStorage' # FastDFS FDFS_URL = 'http://域名:端口' FDFS_CLIENT_CONF = os.path.join(BASE_DIR, 'utils/fastdfs/client.conf') 添加image域名 在/etc/hosts中添加访问FastDFS storage服务器的域名 127.0.0.1 xx域名 "},"Utils/Git基本命令.html":{"url":"Utils/Git基本命令.html","title":"Git","keywords":"","body":"Git常用命令 帮助信息 git help 显示常用的git 和使用简短说明 git help -a 显示所有的命令 git help -g 查看使用手册 git help 命令 / git 命令 help 查看某命令的使用说明, F键下一页，B键上一页，Q退出 git 配置（全局配置） 所有的配置都会保存到当前用户目录下的: .gitconfig 文件中 git config --global user.name '名称' 配置用户名 git config --global user.email '邮箱名' 配置邮箱 git config --list 查看配置信息 git config --unset --global user.name '名称' 重置信息 git config --global corlor.ui true 初始化项目 git init 初始化项目 查看状态 git status 状态： untracked:未跟踪的文件 modified: 修改后未添加提交的文件 添加文件 git add .或具体文件 添加当前文件夹的文件或具体文件 提交文件 git commit -m '提交信息' 提交 git commit -am '提交信息' 添加提交 查看提交日志 git log --oneline --decorate --all -10 --graph --author='作者' --index='文件名' --before='2019-3-1/1 week' --oneline:一行显示提交日志 --decorate:显示详细 --all:显示在所有分支上的提交 -10:显示数量 --graph:显示分支信息 --author:指定作者 --grep:搜索某文件 --before:某时间之前 查看文件修改前和修改后的区别 git diff 文件名 查看文件修改的区别，不指明文件则所以修改文件的区别 Git跟踪rename文件/移动文件 git mv 原文件名 新文件名 重命名/移动文件夹或文件名 git add . git commit -m '信息' 删除文件 git rm 文件名1 文件名2 。。。 git rm -r 文件夹名 递归删除 恢复文件 git checkout HEAD^ -- 需要恢复的文件名 HEAD:最近的一次提交 HEAD^:最近的一次提交的上一次提交 HEAD^^:最近的一次提交的上两次提交 HEAD^^...:最近的一次提交的上n次提交 --:当前分支 恢复提交 git revert 提交号 重置提交指针 git reset 选项 提交号 --soft:软重置，不会影响工作区和暂存区的东西 --hard:工作区和暂存区直接重置到指定的状态 --mixed: 默认，会把暂存区重置到指定的状态，并把指针指到当前位置 git status 先看一下add 中的文件 git reset HEAD 如果后面什么都不跟的话 就是上一次add 里面的全部撤销了 - HEAD^ 表示上一个版本，即上一次的commit，也可以写成HEAD~1 - 如果进行两次的commit，想要都撤回，可以使用HEAD~2 git reset HEAD XXX/XXX/XXX.java 就是对某个文件进行撤销了 查看/创建/切换分支 git branch -a 查看分支 git branch -r 查看远程分支 git branch 分支名 创建分支 git checkout 分支名 切换分支 查看两个分支之间的区别 git diff master..branch1 文件名 查看两个分支（文件）之间的区别，a表示两点左边的分支，b表示右边的分支 合并分支 git checkout master git merge 分支名 解决合并冲突 手动解决冲突 Git用>>>>>>标记出不同分支的内容 重命名/删除分支 git branch -m 原分支名 新分支名 git branch -d 分支名 保存修改进度 git stash save '描述信息' git stash list 查看工作进度信息 git stash show -p 工作进度代号 查看工作进度和现在的区别 git apply 工作进度代号 恢复工作进度 git shash drop 工作进度代号 删除工作进度 git apply pop 工作进度代号 恢复工作进度同时删除 添加别名 git config --global alias.co(别名) checkout(命令) 或 编辑当前用户文件夹下的.bash_profile文件 alias gco='git checkout' 保存退出 source ~/.bash_profile或重启终端 全局忽略跟踪文件 git config --global core.excludesfile ~/.gitignore_global 告诉git全局范围中忽略的文件包含在.gitignore_global文件中 编辑.gitignore_global需要忽略的文件 项目级忽略文件 在项目根目录下创建.gitignore文件 在.gitignore文件下添加忽略文件 如果你不想推什么文件到git 可以运行这个命令： git update-index --assume-unchanged xxx/xxx.py 忽略已被跟踪的文件 忽略规则只针对还没有被git跟踪的文件及文件夹有效。若需要忽略规则对已被跟踪的文件及文件夹有效，则需要取消对文件或文件夹的跟踪 git rm -r --cached ：取消对文件夹及文件夹下的所有子文件夹、文件的跟踪，文件夹及文件夹下的所有子文件夹、文件的状态将从跟踪状态变为未跟踪状态 git rm --cached ：取消对文件的跟踪，文件的跟踪状态将变为未跟踪状态 取消对文件或文件夹的跟踪之后，.gitignore文件中的忽略规则将会对取消了跟踪状态的文件或文件夹生效 创建远程版本库 git remote add origin 远程版本库url地址 git remote -v 查看远程库信息 git remote rm 移除远程库 推送版本库 git push [-u] origin 分支名 -u:跟踪远程分支的变化 修改远程仓库地址 1.修改命令 git remote origin set-url [url] 2.先删后加 git remote rm origin git remote add origin [url] 3.直接修改config文件 克隆版本库到本地 git clone 远程版本库url地址 目录名 克隆到指定目录下 更新本地版本库 git fetch 拉取版本库 git merge origin/master 合并 或 git pull = git fetch + git merge 第一种比较安全 基于版本库开发自己的版本库，fork到自己账户然后克隆到本地 git fork 远程版本库url地址 添加pull request git pull request 添加贡献者 GitHub中的setting中的collaborator添加贡献者 详情图 git submodule常用命令 添加子模块 git submodule add 是子模块在当前仓库中的相对路径 初始化子模块 git submodule update --init --recursive 更新子模块 git submodule update --remote 切换子模块分支 cd git checkout cd .. git add git commit -m \"Update submodule\" 删除子模块 git submodule deinit git rm rm -rf .git/modules/ 切换全部子项目分支 git submodule foreach -q 'git checkout ' 递归克隆包含子项目的仓库 git clone --recurse-submodules "},"Utils/Nginx/Nginx基础.html":{"url":"Utils/Nginx/Nginx基础.html","title":"Nginx基础","keywords":"","body":"datetime:2019/9/5 16:14 author:nzb Nginx的配置 安装Nginx。 yum -y install nginx 修改全局配置文件（/etc/nginx/nginx.conf）。 # 配置用户 user root; # 工作进程数(建议跟CPU的核数量一致) worker_processes auto; # 错误日志 error_log /var/log/nginx/error.log; # 进程文件 pid /run/nginx.pid; # 包含其他的配置 include /usr/share/nginx/modules/*.conf; # 工作模式(多路IO复用方式)和连接上限 events { use epoll; worker_connections 1024;(单进程的并发量, 总并发=进程数*单个进程的并发量) } # HTTP服务器相关配置 http { # 日志格式 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # 访问日志 access_log /var/log/nginx/access.log main; # 开启高效文件传输模式 sendfile on; # 用sendfile传输文件时有利于改善性能 tcp_nopush on; # 禁用Nagle来解决交互性问题 tcp_nodelay on; # 客户端保持连接时间 keepalive_timeout 30; types_hash_max_size 2048; # 包含MIME类型的配置 include /etc/nginx/mime.types; # 默认使用二进制流格式 default_type application/octet-stream; # 包含其他配置文件 include /etc/nginx/conf.d/*.conf; # 包含项目的Nginx配置文件 include /root/project/conf/*.conf; } 编辑局部配置文件（/root/project/conf/nginx.conf）。 server { # 默认端口 listen 80; # 域名解析 server_name _; # 网站根目录 root /root/project/www; # 缓存图片文件 location ~ \\.(jpeg|jpg|png)${ # 缓存文件类型 # 缓存时间为1day expires 1d; # h:小时, d:天 } access_log /root/project/logs/access.log; error_log /root/project/logs/error.log; # 默认访问页 location / { include uwsgi_params; uwsgi_pass 172.18.61.250:8000; index index.html index.htm; } location /static/ { alias /root/project/stat/; expires 30d; } } server { listen 443; server_name _; ssl on; access_log /root/project/logs/access.log; error_log /root/project/logs/error.log; ssl_certificate /root/project/conf/cert/214915882850706.pem; ssl_certificate_key /root/project/conf/cert/214915882850706.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { include uwsgi_params; uwsgi_pass 172.18.61.250:8000; } location /static/ { alias /root/project/static/; expires 30d; } } 到此为止，我们可以启动Nginx来访问我们的应用程序，HTTP和HTTPS都是没有问题的，如果Nginx已经运行，在修改配置文件后，我们可以用下面的命令重新启动Nginx。 重启Nginx服务器。 nginx -s reload 或 systemctl restart nginx 说明：可以对Django项目使用python manage.py collectstatic命令将静态资源收集到指定目录下，要做到这点只需要在项目的配置文件settings.py中添加STATIC_ROOT配置即可。 负载均衡配置 下面的配置中我们使用Nginx实现负载均衡，为另外的三个Nginx服务器（通过Docker创建）提供反向代理服务。 docker run -d -p 801:80 --name nginx1 nginx:latest docker run -d -p 802:80 --name nginx2 nginx:latest docker run -d -p 803:80 --name nginx3 nginx:latest user root; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid; include /usr/share/nginx/modules/*.conf; events { worker_connections 1024; } # 为HTTP服务配置负载均衡 http { upstream fangtx { # 分发：IP：端口 weight权重 max_fails失败次数 fail_timeout分发失败超时时间 server 172.18.61.250:801 weight=4; server 172.18.61.250:802 weight=2; server 172.18.61.250:803 weight=2; # 配置同一用户访问同一个web服务器(解决session丢失问题导致无法登陆和验证码验证(生成和验证不在同一台服务器)) ip_hash; } server { listen 80 default_server; listen [::]:80 default_server; listen 443 ssl; listen [::]:443 ssl; ssl on; access_log /root/project/logs/access.log; error_log /root/project/logs/error.log; ssl_certificate /root/project/conf/cert/214915882850706.pem; ssl_certificate_key /root/project/conf/cert/214915882850706.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_buffering off; proxy_pass http://fangtx; # 跟上面的upstream后的值一样 } } } 说明：Nginx在配置负载均衡时，默认使用WRR（加权轮询算法），除此之外还支持ip_hash、fair（需要安装upstream_fair模块）和url_hash算法。此外，在配置upstream模块时可以指定服务器的状态值，包括：backup（备份机器，其他服务器不可用时才将请求分配到该机器）、down、fail_timeout（请求失败达到max_fails后的暂停服务时间）、max_fails（允许请求失败的次数）和weight（轮询的权重）。 Keepalived 当使用Nginx进行负载均衡配置时，要考虑负载均衡服务器宕机的情况。为此可以使用Keepalived来实现负载均衡主机和备机的热切换，从而保证系统的高可用性。Keepalived的配置还是比较复杂，通常由专门做运维的人进行配置，一个基本的配置可以参照《Keepalived的配置和使用》。 "},"Utils/Nginx/Nginx进阶.html":{"url":"Utils/Nginx/Nginx进阶.html","title":"Nginx进阶","keywords":"","body":"datetime:2022-01-08 14:34:00 author:nzb Nginx 该文档由 html2text 生成，二次编辑的 简介 高性能 web服务器 反向代理服务器 占用内存少 高并发处理強 正向代理和反向代理 正向代理 以代理服务器来接受 Internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 Internet 上请求连接的客户端 反向代理 正向代理类似一个跳板机，代理访问外部资源，比如：我是一个用户，我访问不了某网站，但是我能访问一个代理服务器，这个代理服务器，他能访问那个我不能访问的网站 ，于是我先连上代理服务器，告诉它我需要那个无法访问网站的内容，代理服务器去取回来，然后返回给我。例子：VPN 配置文件详解 # ： 表示配置文件中默认关闭 # user nobody; 配置worker进程用户，主进程master是root，nobody也是一个Linux用户，一般用于启动程序，没有密码 worker_processes auto; 工作进程数，根据硬件调整，通常等于CPU数量或者2倍于CPU数量(建议跟CPU的核数量一致) error_log /var/log/nginx/error.log; 配置全局错误日志级类型，【debug | info | notice | warn | error | crit 】，默认是error # error_log /var/log/nginx/error.log notice; # error_log /var/log/nginx/error.log info; pid /run/nginx.pid; 配置进程pid文件 events events { use epoll; # 配置工作模式(多路IO复用方式)和连接上限 worker_connections 1024; # 单进程的并发量，最大：65535 ​总并发=进程数*单个进程的并发量 单个进程的并发量：655535 } http HTTP服务器相关配置，利用它的反向代理功能提供负载均衡支持 http { include /etc/nginx/mime.types; # 配置Nginx支持哪些多媒体类型，可以在conf/mime.types查看支持哪些多媒体文件 default_type application/octet-stream; # 默认使用二进制流格式，流类型，可以理解为支持任意类型 # 配置日志格式，main是一个变量名 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; # 配置access.log日志及存放路径，并使用上面定义的main日志格式 sendfile on; # 开启高效文件传输模式 tcp_nopush on; # 用sendfile传输文件时有利于改善性能 tcp_nodelay on; # 禁用Nagle来解决交互性问题 keepalive_timeout 30; # 客户端保持连接时间，单位秒 gzip on; # 开启gzip压缩输出 include /etc/nginx/conf.d/*.conf; # 包含其他配置文件，里面文件包含server虚拟主机 include /root/project/conf/*.conf; # 包含项目的Nginx配置文件 server{ # 配置虚拟主机，一个http里面可以有多个(server_name和listen不能完全一样)，可以写在conf.d目录下，包含进来 listen 80; # 配置监听端口，默认端口80 server_name localhost; # 配置服务名，域名解析 root /root/project/www; # 网站根目录 charset koi8-r; # 配置字符集 access_log /root/project/logs/access.log main; # 配置本虚拟主机的访问日志 error_log /root/project/logs/error.log main; location / { # 默认访问页，默认的匹配斜杠“/”（根路径）的请求，当访问路径中有斜杠/，会被location匹配到并进行处理 include uwsgi_params; uwsgi_pass 172.18.61.250:8000; index index.html index.htm; } location / test { # test会拼接到root路径之后 root /opt/www; # root后面的值就是：/test中的“/”（根路径） index index.html index.htm; } error_page 404; # 配置404页面 # error_page 500 502 503 504 /50x.html; # 配置50x错误页面 location /50x.html { # 精准匹配 root html; } } } 主要应用 静态网站部署 包括HTML，js，css，图片等 负载均衡 硬件负载均衡 比如：F5、深信服、Array等 优点是有厂商专业的技术服务团队提供支持，性能稳定 缺点是费用昂贵，对于规模较小的网络应用成本太高 软件负载均衡 比如：Nginx、LVS、HAProxy等 优点是免费开源，成本低廉 主配置 http { # 为HTTP服务配置负载均衡 upstream www.example.com { # 分发：IP：端口 weight 权重 max_fails失败次数 fail_timeout分发失败超时时间 server 172.18.61.250:801 weight=4; server 172.18.61.250:802 weight=2; server 172.18.61.250:803 weight=2; ip_hash; } # 配置同一用户访问同一个web服务器(解决session丢失问题导致无法登陆和验证码验证(生成和验证不在同一台服务器)) server { listen 80 default_server; listen [::]:80 default_server; listen 443 ssl; listen [::]:443 ssl; ssl on; access_log /root/project/logs/access.log; error_log /root/project/logs/error.log; ssl_certificate root/project/conf/cert/214915882850706.pem; ssl_certificate_key /root/project/conf/cert/214915882850706.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_buffering off; proxy_pass http://www.example.com; # 跟上面的upstream后的值一样 } } } 其他配置 配置1：备份服务器 # 可以用于更新代码 upstream www.example.com { server 172.18.61.250:801; server 172.18.61.250:803 backup; # 其他所有的非backup服务器down掉的时候，才请求backup服务器 } 配置2 upstream www.example.com { server 172.18.61.250:801; server 172.18.61.250:803 down; # down表示当前的服务器是down状态，不参与负载均衡，基本没什么用 } 负载均衡策略 轮询（默认） # 注意：这里的轮询并不是每个请求轮流分配到不同的后端服务器，与ip_hash类似，但是按照访问url的hash结果来分配请求， # 使得每个url定向到同一个后端服务器，主要应用与后端服务器为缓存时的场景下，如果后端服务器down掉，将自动删除。 # 每台服务器交替访问，需要保证服务器的性能一样，否则会出现请求堆积导致宕机。 upstream www.example.com { server 172.18.61.250:801; server 172.18.61.250:802; server 172.18.61.250:803; } 权重 # 每个请求按一定比例分发到不同的后端服务器，weight值越大访问的比例越大，用于后端服务器性能不均的情况。权重按服务器性能给。 upstream www.example.com { # 分发：IP：端口 weight 权重 max_fails失败次数 fail_timeout分发失败超时时间 server 172.18.61.250:801 weight=4; server 172.18.61.250:802 weight=2; server 172.18.61.250:803 weight=2; ip_hash; } # 配置同一用户访问同一个web服务器(解决session丢失问题导致无法登陆和验证码验证(生成和验证不在同一台服务器)) # 注意：不是说4个请求一次性给第一个，而是给一个后第二个请求给第二个，第三个给第三个，等等 最少连接数 # web请求会被转移到连接数最少的服务器上，当不知道服务器性能时，不过可能导致请求堆积，因为最少连接的应该性能差。 upstream www.example.com { least_conn; server 172.18.61.250:801; server 172.18.61.250:802; server 172.18.61.250:803; } ip_hash # ip_hash也叫ip绑定，每个请求按访问ip的hash值分配，这样每个访问客户端会固定访问一个后端服务器，可以解决会话session丢失的问题。但是模完的数相同（hash碰撞），也会导致请求堆积。 # 算法：hash（\"124.207.55.82\"）% 3 # 客户端ip # 3：3台服务器 upstream www.example.com { server 172.18.61.250:801 weight=4; server 172.18.61.250:802 weight=2; server 172.18.61.250:803 weight=2; ip_hash; } # 配置同一用户访问同一个web服务器(解决session丢失问题导致无法登陆和验证码验证(生成和验证不在同一台服务器)) 静态代理 图片、css、html、js等交给Nginx处理 实现 方式一：在nginx.conf的location中配置静态资源的后缀，进行拦截 例如：当访问静态资源，则从Linux服务器/opt/static目录下获取（举例）location ~.*\\\\.(gif|jpg|png|js|css)$ { root /opt/static; } ~：正则匹配开始 .：任意字符 *：​任意次数一个或多个 \\：转义字符 $：匹配结尾​ 方式二：在nginx.conf的location中配置静态资源所在目录，进行拦截 例如：当访问静态资源，则从Linux服务器/opt/static目录下获取（举例）常用 location ~.*/(css|js|img|images) { # 不匹配以什么结尾，匹配目录 root /opt/static; } 动静分离 动态资源：如Django项目 静态资源：如图片、css、js等由Nginx服务器完成，选择Nginx是因为Nginx效率高 虚拟主机 例如：58同城 虚拟主机，就是把一台物理服务器划分成多个“虚拟”的服务器，这样我们的一台物理服务器就可以做多个服务器来使用，从而可以配置多个网站。 实现 方法一：基于端口的虚拟主机（一般不用，了解） 基于端口的虚拟主机配置，使用端口来区分 浏览器使用同一个域名 + 端口 或 同一个 ip地址 + 端口访问 server { listen 8080; server_name www.example1.com; location / { proxy_pass http://www.myweb.com; } } server { listen 9090; server_name www.example1.com; location / { proxy_pass http://www.myweb1.com; } } 方法二：基于域名的虚拟主机（掌握） 基于域名的虚拟主机是最常见的一种虚拟主机 server { listen 80; server_name www.example1.com; location / { proxy_pass http://www.myweb.com; } } server { listen 80; server_name www.example2.com; location / { proxy_pass http://www.myweb2.com; } } "},"InterviewPreparation/":{"url":"InterviewPreparation/","title":"目录","keywords":"","body":"datetime:2020/10/27 15:46 author:nzb 该目录主要是各个时间段的面试资料以及个人认为的经典题（错题集） 基础 工欲善其事，必先利其器，基础是最重要的。强推：技术面试必备基础知识源地址 技术面试必备基础知识 操作系统 网络 数据库 系统设计 数据结构与算法 算法 线性表 栈 队列 特殊矩阵压缩存储 串 树与二叉树 Python 常用数据结构和算法 错题集 Python 的内存管理机制及调优手段？ 内存管理机制: 引用计数、垃圾回收（引用计数（降到 0）、标记清除、分代回收）、内存池 调优手段：手动垃圾回收、调高垃圾回收阈值、避免循环引用 回调函数，如何通信的? 闭包延迟 单例模式 迭代器和生成器 Python的魔法方法 文件操作 遍历目录与子目录 字符串相关 数字字符串转整形 | 数字字符串排序 | 正则表达式 进程线程协程 进程和线程 | 多进程多线程以及协程的理解 | Python异步使用场景有那些 | 多线程竞争 | Python的线程同步 | 锁及其分类 | 同步、异步、阻塞、非阻塞 | 僵尸进程和孤儿进程及怎么避免僵尸进程？ 网络编程 TCP、UDP | 浏览器通过 WSGI 请求动态资源的过程 | 浏览器访问www.baidu.com的过程 | Post和Get请求的区别 | cookie和session的区别 | 三次握手和四次挥手 HTTPS和HTTP的区别 | 使用Socket套接字需要传入哪些参数 | HTTP常见请求头 | OSI七层模型和TCP/IP四层模型以及五层模型 | url的形式 | 什么是WSGI和uwsgi以及uWSGI 爬虫相关 数据库 历史记录 2020/10/27 "},"InterviewPreparation/TechnicalInterviews/TechnicalInterviews.html":{"url":"InterviewPreparation/TechnicalInterviews/TechnicalInterviews.html","title":"技术面试必备基础知识","keywords":"","body":"datetime:2022-03-08 17:19 author:nzb 技术面试必备基础知识 传送门 操作系统 计算机操作系统 概述 基本特征 1. 并发 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。 并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。 操作系统通过引入进程和线程，使得程序能够并发运行。 2. 共享 共享是指系统中的资源可以被多个并发进程共同使用。 有两种共享方式：互斥共享和同时共享。 互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。 3. 虚拟 虚拟技术把一个物理实体转换为多个逻辑实体。 主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。 多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。 * 虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。 4. 异步 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。 基本功能 1. 进程管理 2. 内存管理 3. 文件管理 4. 设备管理 系统调用 如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。 宏内核和微内核 1. 宏内核 2. 微内核 中断分类 1. 外中断 由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断（Ctril + c）等。 2. 异常 由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。 3. 陷入 在用户程序中使用系统调用。 进程管理 进程与线程 1. 进程 进程是资源分配的基本单位。 2. 线程 线程是独立调度的基本单位。一个进程中可以有多个线程，它们共享进程资源。 3. 区别 Ⅰ 拥有资源 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 Ⅱ 调度 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 Ⅲ 系统开销 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 Ⅳ 通信方面 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 应该注意以下内容： 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 进程调度算法 1. 批处理系统 没有太多的用户操作 1.1 先来先服务 first-come first-serverd（FCFS） 非抢占式的调度算法，按照请求的顺序进行调度。 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 1.2 短作业优先 shortest job first（SJF） 非抢占式的调度算法，按估计运行时间最短的顺序进行调度。 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 1.3 最短剩余时间优先 shortest remaining time next（SRTN） 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 2. 交互式系统 有大量的用户交互操作 2.1 时间片轮转 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法的效率和时间片的大小有很大关系： 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 2.2 优先级调度 为每个进程分配一个优先级，按优先级进行调度。 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 2.3 多级反馈队列 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 3. 实时系统 实时系统要求一个请求在一个确定时间内得到响应。 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。 进程同步 1. 临界区 对临界资源进行访问的那段代码称为临界区。 2. 同步与互斥 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量 4. 管程 经典同步问题 1. 哲学家进餐问题 2. 读者-写者问题 进程通信 进程同步与进程通信很容易混淆，它们的区别在于： 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 1. 管道 管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。 它具有以下限制： 只支持半双工通信（单向交替传输）； 只能在父子进程或者兄弟进程中使用。 2. FIFO 命名管道，去除了管道只能在父子进程中使用的限制。常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 3. 消息队列 相比于 FIFO，消息队列具有以下优点： 可独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 4. 信号量 一个计数器，用于为多个进程提供对共享数据对象的访问。 5. 共享存储 允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。 需要使用信号量用来同步对共享存储的访问。 多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。 6. 套接字 用于不同机器间的进程通信 死锁 必要条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 处理方法 鸵鸟策略 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。 当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。 死锁检测与死锁恢复 不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。 1. 每种类型一个资源的死锁检测 2. 每种类型多个资源的死锁检测 3. 死锁恢复 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 死锁预防 在程序运行之前预防发生死锁。 1. 破坏互斥条件 例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。 2. 破坏占有和等待条件 一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。 3. 破坏不可抢占条件 4. 破坏环路等待 给资源统一编号，进程只能按编号顺序来请求资源。 死锁避免 1. 安全状态 2. 单个资源的银行家算法 3. 多个资源的银行家算法 内存管理 虚拟内存 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。 分页系统地址映射 内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。 页面置换算法 页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。 1. 最佳 OPT, Optimal replacement algorithm 所选择被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。 是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 2. 最近最久未使用 LRU, Least Recently Used 在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。 3. 最近未使用 NRU, Not Recently Used 每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类： R=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1 当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。 NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。 4. 先进先出 FIFO, First In First Out 选择换出的页面是最先进入的页面。 该算法会将那些经常被访问的页面换出，导致缺页率升高。 5. 第二次机会算法 FIFO 改进版 当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。 6. 时钟 第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。 分段 段页式 分页与分段的比较 设备管理 磁盘结构 盘面（Platter）：一个磁盘有多个盘面； 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道； 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小； 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）； 制动手臂（Actuator arm）：用于在磁道之间移动磁头； 主轴（Spindle）：使整个盘面转动。 磁盘调度算法 读写一个磁盘块的时数据影响因素有： 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上） 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上） 实际的数据传输时间 其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。 1. 先来先服务 FCFS, First Come First Served 优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。 2. 最短寻道时间优先 SSTF, Shortest Seek Time First * 优先调度与当前磁头所在磁道距离最近的磁道。虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。 3. 电梯算法 电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。 链接 Linux 网络 计算机网络 概述 网络的网络 ISP 互联网服务提供商 ISP 主机之间的通信方式 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方 对等（P2P）：不区分客户和服务器 电路交换与分组交换 1. 电路交换 用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。 2. 分组交换 每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响，因此在同一条传输线路上允许同时传输多个分组，也就是说分组交换不需要占用传输线路。 时延 总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延 1. 排队时延 分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。 2. 处理时延 主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。 3. 传输时延 主机或路由器传输数据帧所需要的时间。 4. 传播时延 电磁波在信道中传播所需要花费的时间，电磁波传播的速度接近光速。 计算机网络体系结构 1. 五层协议 应用层 ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。 传输层 ：运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报 。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层 ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 物理层 ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 2. OSI 其中表示层和会话层用途如下： 表示层 ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。 会话层 ：建立及管理会话。 五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。 3. TCP/IP 它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。 TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。 4. 数据在各层之间的传递过程 在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。 路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层。 物理层 通信方式 根据信息在传输线上的传送方向，分为以下三种通信方式： 单工通信：单向传输 半双工通信：双向交替传输 全双工通信：双向同时传输 带通调制 模拟信号是连续的信号，数字信号是离散的信号。带通调制把数字信号转换为模拟信号。 链路层 包含协议 CSMA/CD 协议 PPP 协议 基本问题 1. 封装成帧 将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。 2. 透明传输 透明表示一个实际存在的事物看起来好像不存在一样。 透明传输的内容是转义字符，用户察觉不到转义字符的存在。 3. 差错检测 目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。 信道分类 1. 广播信道 一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。 所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。 主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。 信道复用技术 1. 频分复用 频分复用的所有主机在相同的时间占用不同的频率带宽资源。 会一直占用一部分信道资源，利用率都不高。 2. 时分复用 时分复用的所有主机在不同的时间占用相同的频率带宽资源。 会一直占用一部分信道资源，利用率都不高。 3. 统计时分复用 是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据集集中起来组成统计时分复用帧然后发送。 4. 波分复用 光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。 5. 码分复用 CSMA/CD 协议 多点接入、载波监听、碰撞检测 多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上。 载波监听 ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。 碰撞检测 ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。 2. 点对点信道 一对一通信。 因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。 PPP 协议 PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。 PPP 的帧格式 F 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500 MAC 地址 MAC 地址是链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。 一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。 局域网 局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。 主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。 可以按照网络拓扑结构对局域网进行分类： 以太网 以太网是一种星型拓扑结构局域网。 早期使用集线器进行连接，如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。 目前以太网使用交换机替代了集线器，交换机是一种链路层设备，它不会发生碰撞，能根据 MAC 地址进行存储转发。 以太网帧格式： 类型 ：标记上层使用的协议； 数据 ：长度在 46-1500 之间，如果太小则需要填充； FCS ：帧检验序列，使用的是 CRC 检验方法； 交换机 交换机具有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。 虚拟局域网 虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息。 网络层 包含协议 IP 协议 ARP 地址解析协议 ICMP 网际控制报文协议 IGMP 网际组管理协议 RIP、OSPF 内部网关协议 BGP 外部网关协议 概述 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP 数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 IP 地址编址方式 1. 分类 由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {, } 2. 子网划分 通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。 IP 地址 ::= {, , } 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 注意，外部网络看不到子网的存在。 3. 无分类 地址解析协议 ARP ARP 实现由 IP 地址得到 MAC 地址。 网际控制报文协议 ICMP ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。 ICMP 报文分为差错报告报文和询问报文。 1. Ping 主要用来测试两台主机之间的连通性。 Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。 2. Traceroute 用来跟踪一个分组从源点到终点的路径 虚拟专用网 VPN 一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。 有三个专用地址块： 10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 网络地址转换 NAT 路由器的结构 路由器从功能上可以划分为 路由选择 分组转发。 分组转发结构由三个部分组成 交换结构 一组输入端口 一组输出端口。 路由器分组转发流程 路由选择协议 可以把路由选择协议划分为两大类： 自治系统内部的路由选择：RIP 和 OSPF 自治系统间的路由选择：BGP 1. 内部网关协议 RIP RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。 RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。 2. 内部网关协议 OSPF 开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。 3. 外部网关协议 BGP 边界网关协议 传输层 包含协议 TCP 传输控制协议 UDP 用户数据报协议` UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 TCP 的四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 TCP 可靠传输 TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。 TCP 滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。 TCP 流量控制 流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 TCP 拥塞控制 如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。 发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 1. 慢开始与拥塞避免 2. 快重传与快恢复 应用层 包含协议 FTP 文本传输协议 HTTP 超文本传输协议 DHCP 动态主机配置协议 TELNET 远程登录协议 SMTP 邮件发送协议 POP3、IMAP 邮件读取协议` 域名系统 DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。 这里的分布式数据库是指，每个站点只保留它自己的那部分数据。 域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。 文件传送协议 FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件： 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式： 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 动态主机配置协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。 远程登录协议 TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。 邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. SMTP 2. POP3 3. IMAP 常用端口 Web 页面请求过程 1. DHCP 配置主机信息 2. ARP 解析 MAC 地址 3. DNS 解析域名 4. HTTP 请求页面 HTTP 一 、基础概念 请求和响应报文 URL 统一资源定位符 二、HTTP 方法 GET 获取资源 HEAD 获取报文首部 POST 传输实体主体 PUT 上传文件 PATCH 对资源进行部分修改 DELETE 删除文件 OPTIONS 查询支持的方法 CONNECT 要求在与代理服务器通信时建立隧道 TRACE 追踪路径 三、HTTP 状态码 1XX 信息 2XX 成功 3XX 重定向 4XX 客户端错误 5XX 服务器错误 四、HTTP 首部 有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。 通用首部字段 e.g：Date 创建报文的日期时间 请求首部字段 e.g： Accept 用户代理可处理的媒体类型 Authorization Web 认证信息 User-Agent HTTP 客户端程序的信息 响应首部字段 e.g：Location 令客户端重定向至指定 URI 实体首部字段 e.g： Content-Type 实体主体的媒体类型 Allow 资源可支持的 HTTP 方法 五、具体应用 连接管理 1. 短连接与长连接 从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close； 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。 2. 流水线 在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。 Cookie 缓存 内容协商 内容编码 范围请求 分块传输编码 多部分对象集合 虚拟主机 通信数据转发 1. 代理 使用代理的主要目的是： 缓存 负载均衡 网络访问控制 访问日志记录 2. 网关 3. 隧道 六、HTTPS HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。 通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。 加密 1. 对称密钥加密 对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。 优点：运算速度快； 缺点：无法安全地将密钥传输给通信方。 2.非对称密钥加密 非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。 优点：可以更安全地将公开密钥传输给通信发送方； 缺点：运算速度慢。 3. HTTPS 采用的加密方式 HTTPS 采用混合的加密机制，正是利用了上面提到的方案： 使用非对称密钥加密方式，传输对称密钥加密方式所需要的 Secret Key，从而保证安全性; 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率。（下图中的 Session Key 就是 Secret Key） 认证 数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。 完整性保护 HTTPS 的缺点 因为需要进行加密解密等过程，因此速度会更慢； 需要支付证书授权的高额费用。 七、HTTP/2.0 HTTP/1.x 缺陷 二进制分帧层 服务端推送 HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。 首部压缩 八、HTTP/1.1 新特性 九、GET 和 POST 比较 作用 GET 用于获取资源，而 POST 用于传输实体主体。 参数 GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参数支持标准字符集。 安全 安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。 GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 安全的方法除了 GET 之外还有：HEAD、OPTIONS。 不安全的方法除了 POST 之外还有 PUT、DELETE。 幂等性 幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。 所有的安全方法也都是幂等的。 在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。 可缓存 XMLHttpRequest XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。 Socket 一、I/O 模型 一个输入操作通常包括两个阶段： 1、等待数据准备好 2、从内核向进程复制数据 阻塞式 I/O 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回 CPU 利用率会比较高 非阻塞式 I/O 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling） CPU 利用率比较低 I/O 复用 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O 信号驱动 I/O 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高 异步 I/O 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O 五大 I/O 模型比较 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。 异步 I/O：第二阶段应用进程不会阻塞。 同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。 非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。 二、I/O 复用 select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。 select select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。 poll poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态。 比较 1. 功能 select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。 select 会修改描述符，而 poll 不会； select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制； poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。 2. 速度 select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。 3. 可移植性 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。 epoll epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。 工作模式 epoll 的描述符事件有两种触发模式：LT（level trigger）和 ET（edge trigger）。 1. LT 模式 当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 2. ET 模式 和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。 很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 应用场景 很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。 1. select 应用场景 select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。 select 可移植性更好，几乎被所有主流平台所支持。 2. poll 应用场景 poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 3. epoll 应用场景 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。 通俗举例 数据库 数据库系统原理 一、事务 概念 满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 ACID 1. 原子性（Atomicity） 2. 一致性（Consistency） 3. 隔离性（Isolation） 4. 持久性（Durability） AUTOCOMMIT MySQL 默认采用自动提交模式。也就是说，如果不显式使用START TRANSACTION语句来开始一个事务，那么每个查询操作都会被当做一个事务并自动提交。 二、并发一致性问题 丢失修改 读脏数据 不可重复读 幻影读 三、封锁 封锁粒度 MySQL 中提供了两种封锁粒度：行级锁以及表级锁。 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。 在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 封锁类型 1. 读写锁 互斥锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定： 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 2. 意向锁 封锁协议 1. 三级封锁协议 一级封锁协议 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。 解决丢失修改问题。 因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 解决读脏数据问题。 因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 三级封锁协议 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 解决不可重复读的问题。 因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 2. 两段锁协议 MySQL 隐式与显示锁定 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB 也可以使用特定的语句进行显示锁定： SELECT ... LOCK In SHARE MODE; 加 S 锁 SELECT ... FOR UPDATE; 加 X 锁 四、隔离级别 未提交读（READ UNCOMMITTED） 事务中的修改，即使没有提交，对其它事务也是可见的。 提交读（READ COMMITTED） 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读（REPEATABLE READ） 保证在同一个事务中多次读取同一数据的结果是一样的。 可串行化（SERIALIZABLE） 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。 该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。 五、多版本并发控制 多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 基本思想 版本号 系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号 TRX_ID ：事务开始时的系统版本号。 Undo 日志 ReadView 快照读与当前读 1. 快照读 MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。 2. 当前读 MVCC 其它会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。 在进行 SELECT 操作时，可以强制指定进行加锁操作。以下第一个语句需要加 S 锁，第二个需要加 X 锁。 SELECT * FROM table WHERE ? lock in share mode; SELECT * FROM table WHERE ? for update; 六、Next-Key Locks 使用 MVCC + Next-Key Locks 可以解决幻读问题 Record Locks 锁定一个记录上的索引，而不是记录本身。 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Locks 锁定索引之间的间隙，但是不包含索引本身。 Next-Key Locks 它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间，例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间： (-∞, 10] (10, 11] (11, 13] (13, 20] (20, +∞) 七、关系数据库设计理论 函数依赖 异常 范式 八、ER 图 实体的三种联系 三个组成部分：实体、属性、联系 包含一对一，一对多，多对多三种。 如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B； 如果是一对一，画两个带箭头的线段； 如果是多对多，画两个不带箭头的线段。 表示出现多次的关系 联系的多向性 表示子类 用一个三角形和两条线来连接类和子类，与子类有关的属性和联系都连到子类上，而与父类和子类都有关的连到父类上。 SQL 语法 SQL 练习 MySQL 一、索引 B+ Tree 原理 MySQL 索引 1. B+Tree 索引 是大多数 MySQL 存储引擎的默认索引类型。 因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。 因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。 InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。 2. 哈希索引 哈希索引能以 O(1) 时间进行查找，但是失去了有序性： 无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 3. 全文索引 MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。 查找条件使用 MATCH AGAINST，而不是普通的 WHERE。 全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。 InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。 4. 空间数据索引 MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。 必须使用 GIS 相关的函数来维护数据。 索引优化 1. 独立的列 在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。 例如下面的查询不能使用 actor_id 列的索引： SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 2. 联合索引（多列索引） 在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。 SELECT film_id, actor_ id FROM sakila.film_actorWHERE actor_id = 1 AND film_id = 1; 3. 索引列的顺序 让选择性最强的索引列放在前面。 索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。 例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。 SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity, COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity, COUNT(*) FROM payment; staff_id_selectivity: 0.0001 customer_id_selectivity: 0.0373 COUNT(*): 16049 4. 前缀索引 对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。 前缀长度的选取需要根据索引选择性来确定。 5. 覆盖索引 索引包含所有需要查询的字段的值。 具有以下优点： 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。 索引的优点 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。 索引的使用条件 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效； 对于中到大型的表，索引就非常有效； 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。 索引失效 没有遵循最左匹配原则。 键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 一些关键字会导致索引失效，例如 or， ！= ， not in，is null ,is not unll like查询是以%开头 隐式转换会导致索引失效。 索引列是表达式的一部分，或者是函数的参数 二、查询性能优化 使用 Explain 进行分析 Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。 比较重要的字段有： select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 优化数据访问 1. 减少请求的数据量 只返回必要的列：最好不要使用 SELECT * 语句。 只返回必要的行：使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 2. 减少服务器端扫描的行数 最有效的方式是使用索引来覆盖查询。 重构查询方式 1. 切分大查询 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。 DELETE FROM messages WHERE create 0 2. 分解大连接查询 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有： 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。 SELECT * FROM tag JOIN tag_post ON tag_post.tag_id=[tag.id](http://tag.id/) JOIN post ON tag_post.post_id=[post.id](http://post.id/) WHERE tag.tag='mysql'; SELECT * FROM tag WHERE tag='mysql'; SELECT * FROM tag_post WHERE tag_id=1234; SELECT * FROM post WHERE [post.id](http://post.id/) IN (123,456,567,9098,8904); 三、存储引擎 InnoDB MyISAM 比较 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。 外键：InnoDB 支持外键。 备份：InnoDB 支持在线热备份。 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。 其它特性：MyISAM 支持压缩表和空间数据索引。 四、数据类型 整型 浮点数 字符串 时间和日期 五、切分 水平切分 水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。 当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而减缓单个数据库的压力。 垂直切分 垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。 在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。 Sharding 策略 哈希取模：hash(key) % N； 范围：可以是 ID 范围也可以是时间范围； 映射表：使用单独的一个数据库来存储映射关系。 Sharding 存在的问题 1. 事务问题 使用分布式事务来解决，比如 XA 接口。 2. 连接 可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。 3. ID 唯一性 使用全局唯一 ID（GUID） 为每个分片指定一个 ID 范围 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法) 六、复制 主从复制 主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。 binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。 读写分离 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。 读写分离能提高性能的原因在于： 主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。 读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。 参考资料 Redis 一、概述 Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。 键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。 Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。 二、数据类型 STRING set get del LIST rpush lrange list-key 0 -1 lindex list-key 1 lpop SET sadd smembers sismember srem HASH hset hash-key sub-key1 value1 hgetall hdel hash-key sub-key2 hget hash-key sub-key1 ZSET zadd zset-key 728 member1 zrange zset-key 0 -1 withscores zrangebyscore zset- key 0 800 withscores zrem 三、数据结构 字典 dictht 是一个散列表结构，使用拉链法解决哈希冲突。 跳跃表 是有序集合的底层实现之一。 跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。 与红黑树等平衡树相比，跳跃表具有以下优点： 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。 四、使用场景 计数器 可以对 String 进行自增自减运算，从而实现计数器功能。 Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。 缓存 将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 查找表 查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。 例如 DNS 记录就很适合使用 Redis 进行存储。 消息队列 List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息 不过最好使用 Kafka、RabbitMQ 等消息中间件。 会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。 当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。 分布式锁实现 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。 可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 其它 Set 可以实现交集、并集等操作，从而实现共同好友等功能。 ZSet 可以实现有序性操作，从而实现排行榜等功能。 五、Redis 与 Memcached 数据类型 Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。 数据持久化 Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。 分布式 Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。 Redis Cluster 实现了分布式的支持。 内存管理机制 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。 Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。 六、键的过期时间 Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。 对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。 七、数据淘汰策略 可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。 Redis 具体有 6 种淘汰策略： 作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。 使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。 Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。 八、持久化 Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。 RDB 持久化 将某个时间点的所有数据都存放到硬盘上。 可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。 如果系统发生故障，将会丢失最后一次创建快照之后的数据。 如果数据量很大，保存快照的时间会很长。 AOF 持久化 将写命令添加到 AOF 文件（Append Only File）的末尾。 使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项： always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。 九、事务 一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。 事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。 Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。 十、事件 Redis 服务器是一个事件驱动程序。 文件事件 时间事件 事件的调度与执行 十一、复制 连接过程 主从链 十二、Sentinel Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。 十三、分片 分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。 假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。 根据执行分片的位置，可以分为三种分片方式： 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。 十四、一个简单的论坛系统分析 文章信息 点赞功能 对文章进行排序 系统设计 系统设计基础 一、性能 性能指标 1. 响应时间 指某个请求从发出到接收到响应消耗的时间。 2. 吞吐量 系统在单位时间内可以处理的请求数量，通常使用每秒的请求数来衡量。 3. 并发用户数 指系统能同时处理的并发用户请求数量。 性能优化 1. 集群 将多台服务器组成集群，使用负载均衡将请求转发到集群中，避免单一服务器的负载压力过大导致性能降低。 2. 缓存 缓存能够提高性能的原因如下： 缓存数据通常位于内存等介质中，这种介质对于读操作特别快； 缓存数据可以位于靠近用户的地理位置上； 可以将计算结果进行缓存，从而避免重复计算。 3. 异步 某些流程可以将操作转换为消息，将消息发送到消息队列之后立即返回，之后这个操作会被异步处理。 二、伸缩性 指不断向集群中添加服务器来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。 伸缩性与性能 如果系统存在性能问题，那么单个用户的请求总是很慢的； 如果系统存在伸缩性问题，那么单个用户的请求可能会很快，但是在并发数很高的情况下系统会很慢。 实现伸缩性 应用服务器只要不具有状态，那么就可以很容易地通过负载均衡器向集群中添加新的服务器。 关系型数据库的伸缩性通过 Sharding 来实现，将数据按一定的规则分布到不同的节点上，从而解决单台存储服务器的存储空间限制。 对于非关系型数据库，它们天生就是为海量数据而诞生，对伸缩性的支持特别好。 三、扩展性 指的是添加新功能时对现有系统的其它应用无影响，这就要求不同应用具备低耦合的特点。 实现可扩展主要有两种方式： 使用消息队列进行解耦，应用之间通过消息传递进行通信； 使用分布式服务将业务和可复用的服务分离开来，业务使用分布式服务框架调用可复用的服务。新增的产品可以通过调用可复用的服务来实现业务逻辑，对其它产品没有影响。 四、可用性 冗余 保证高可用的主要手段是使用冗余，当某个服务器故障时就请求其它服务器。 应用服务器的冗余比较容易实现，只要保证应用服务器不具有状态，那么某个应用服务器故障时，负载均衡器将该应用服务器原先的用户请求转发到另一个应用服务器上，不会对用户有任何影响。 存储服务器的冗余需要使用主从复制来实现，当主服务器故障时，需要提升从服务器为主服务器，这个过程称为切换。 监控 对 CPU、内存、磁盘、网络等系统负载信息进行监控，当某个信息达到一定阈值时通知运维人员，从而在系统发生故障之前及时发现问题。 服务降级 服务降级是系统为了应对大量的请求，主动关闭部分功能，从而保证核心功能可用。 五、安全性 要求系统在应对各种攻击手段时能够有可靠的应对措施。 分布式 一、分布式锁 在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。 阻塞锁通常使用互斥量来实现： 互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态； 互斥量为 1 表示未锁定状态。 1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。 数据库的唯一索引 获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否处于锁定状态。 存在以下几个问题： 锁没有失效时间，解锁失败的话其它进程无法再获得该锁； 只能是非阻塞锁，插入失败直接就报错了，无法重试； 不可重入，已经获得锁的进程也必须重新获取锁。 Redis 的 SETNX 指令 使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。 SETNX 指令和数据库的唯一索引类似，保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。 EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。 Redis 的 RedLock 算法 使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。 尝试从 N 个互相独立 Redis 实例获取锁； 计算获取锁消耗的时间，只有时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，才认为获取锁成功； 如果获取锁失败，就到每个实例上释放锁。 Zookeeper 的有序节点 1. Zookeeper 抽象模型 Zookeeper 提供了一种树形结构的命名空间，/app1/p_1 节点的父节点为 /app1。 2. 节点类型 永久节点：不会因为会话结束或者超时而消失； 临时节点：如果会话结束或者超时就会消失； 有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，以此类推。 3. 监听器 为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。 4. 分布式锁实现 创建一个锁目录 /lock； 当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点； 客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁； 执行业务代码，完成后，删除对应的子节点。 5. 会话超时 如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。可以看到，这种实现方式不会出现数据库的唯一索引实现方式释放锁失败的问题。 6. 羊群效应 一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应，一只羊动起来，其它羊也会一哄而上），而我们只希望它的后一个子节点收到通知。 二、分布式事务 指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。 分布式锁和分布式事务区别： 锁问题的关键在于进程操作的互斥关系，例如多个进程同时修改账户的余额，如果没有互斥关系则会导致该账户的余额不正确。 而事务问题的关键则在于事务涉及的一系列操作需要满足 ACID 特性，例如要满足原子性操作则需要这些操作要么都执行，要么都不执行。例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。 2PC 两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。 1. 运行过程 1.1 准备阶段 协调者询问参与者事务是否执行成功，参与者发回事务执行结果。询问可以看成一种投票，需要参与者都同意才能执行。 1.2 提交阶段 如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。 需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。 2. 存在的问题 2.1 同步阻塞 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞等待状态，无法进行其它操作。 2.2 单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在提交阶段发生故障，所有参与者会一直同步阻塞等待，无法完成其它操作。 2.3 数据不一致 在提交阶段，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。 2.4 太过保守 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。 本地消息表 本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 三、CAP 分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。 一致性 一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。 对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。 可用性 可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。 在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。 分区容忍性 网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。 权衡 在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，CAP 理论实际上是要在可用性和一致性之间做权衡。 可用性和一致性往往是冲突的，很难使它们同时满足。在多个节点之间进行数据同步时， 为了保证一致性（CP），不能访问未同步完成的节点，也就失去了部分可用性； 为了保证可用性（AP），允许读取所有节点的数据，但是数据可能不一致。 四、BASE BASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。 BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 基本可用 指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。 例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。 软状态 指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。 最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。 ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。 在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。 五、Paxos 用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。 主要有三类节点： 提议者（Proposer）：提议一个值； 接受者（Acceptor）：对每个提议进行投票； 告知者（Learner）：被告知投票的结果，不参与投票过程。 执行过程 规定一个提议包含两个字段：[n, v]，其中 n 为序号（具有唯一性），v 为提议值。 1. Prepare 阶段 2. Accept 阶段 3. Learn 阶段 约束条件 1. 正确性 指只有一个提议值会生效。 因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。 2. 可终止性 指最后总会有一个提议生效。 Paxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。 六、Raft Raft 也是分布式一致性协议，主要是用来竞选主节点。 单个 Candidate 的竞选 多个 Candidate 竞选 数据同步 集群 一、负载均衡 集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。 负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。 负载均衡器可以用来实现高可用以及伸缩性： 高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点 负载均衡器运行过程包含两个部分： 根据负载均衡算法得到转发的节点 进行转发 负载均衡算法 1. 轮询（Round Robin） 轮询算法把每个请求轮流发送到每个服务器上。该算法比较适合每个服务器的性能差不多的场景。 2. 加权轮询（Weighted Round Robbin） 加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。 3. 最少连接（least Connections） 由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。 最少连接算法就是将请求发送给当前最少连接数的服务器上。 4. 加权最少连接（Weighted Least Connection） 在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。 5. 随机算法（Random） 把请求随机发送到服务器上。 和轮询算法类似，该算法比较适合服务器性能差不多的场景。 6. 源地址哈希法 (IP Hash) 源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。 可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session） 转发实现 1. HTTP 重定向 HTTP 重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。 缺点： 需要两次请求，因此访问延迟比较高； HTTP 负载均衡器处理能力有限，会限制集群的规模。 该负载均衡转发的缺点比较明显，实际场景中很少使用它。 2. DNS 域名解析 在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。 优点： DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。 缺点： 由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。 大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址。 3. 反向代理服务器 反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。 在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。 优点： 与其它功能集成在一起，部署简单。 缺点： 所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。 4. 网络层 在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的 IP 地址，并修改请求数据包的目的 IP 地址，最后进行转发。 源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。 优点： 在内核进程中进行处理，性能比较高。 缺点： 和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。 5. 链路层 在链路层根据负载均衡算法计算源服务器的 MAC 地址，并修改请求数据包的目的 MAC 地址，并进行转发。 通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，从而不需要修改 IP 地址就可以进行转发。也正因为 IP 地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。 这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。 这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux Virtual Server）。 二、集群下的 Session 管理 一个用户的 Session 信息如果存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器，由于服务器没有用户的 Session 信息，那么该用户就需要重新进行登录等操作。 Sticky Session 需要配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的 Session 存放在该服务器中。 缺点： 当服务器宕机时，将丢失该服务器上的所有 Session。 Session Replication 在服务器之间进行 Session 同步操作，每个服务器都有所有用户的 Session 信息，因此用户可以向任何一个服务器进行请求。 缺点： 占用过多内存； 同步过程占用网络带宽以及服务器处理器时间。 Session Server 使用一个单独的服务器存储 Session 数据，可以使用传统的 MySQL，也使用 Redis 或者 Memcached 这种内存型数据库。 优点： 为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。 缺点： 需要去实现存取 Session 的代码。 攻击技术 一、跨站脚本攻击 跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。 危害 窃取用户的 Cookie 伪造虚假的输入表单骗取个人信息 显示伪造的文章或者图片 防范手段 1. 设置 Cookie 为 HttpOnly 设置了 HttpOnly 的 Cookie 可以防止 JavaScript 脚本调用，就无法通过 document.cookie 获取用户 Cookie 信息。 2. 过滤特殊字符 例如将 转义为 &gt;，从而避免 HTML 和 Jascript 代码的运行。 二、跨站请求伪造 跨站请求伪造（Cross-site request forgery，CSRF），是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去执行。 XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户浏览器的信任。 防范手段 1. 检查 Referer 首部字段 Referer 首部字段位于 HTTP 报文中，用于标识请求来源的地址。检查这个首部字段并要求请求来源的地址在同一个域名下，可以极大的防止 CSRF 攻击。 这种办法简单易行，工作量低，仅需要在关键访问处增加一步校验。但这种办法也有其局限性，因其完全依赖浏览器发送正确的 Referer 字段。虽然 HTTP 协议对此字段的内容有明确的规定，但并无法保证来访的浏览器的具体实现，亦无法保证浏览器没有安全漏洞影响到此字段。并且也存在攻击者攻击某些浏览器，篡改其 Referer 字段的可能。 2. 添加校验 Token 在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验。例如服务器生成随机数并附加在表单中，并要求客户端传回这个随机数。 3. 输入验证码 因为 CSRF 攻击是在用户无意识的情况下发生的，所以要求用户输入验证码可以让用户知道自己正在做的操作。 三、SQL 注入攻击 服务器上的数据库运行非法的 SQL 语句，主要通过拼接来完成。 防范手段 1. 对传入的参数进行编码转义 2. 单引号转换 将传入的参数中的单引号转换为连续两个单引号，PHP 中的 Magic quote 可以完成这个功能。 四、拒绝服务攻击 拒绝服务攻击（denial-of-service attack，DoS），亦称洪水攻击，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。 分布式拒绝服务攻击（distributed denial-of-service attack，DDoS），指攻击者使用两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击。 缓存 一、缓存特征 命中率 当某个请求能够通过访问缓存而得到响应时，称为缓存命中。 缓存命中率越高，缓存的利用率也就越高。 最大空间 缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。 当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。 淘汰策略 FIFO（First In First Out）：先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。 LRU（Least Recently Used）：最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。 LFU（Least Frequently Used）：最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。 二、缓存位置 浏览器 当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。 ISP 网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。 反向代理 反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。 本地缓存 使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。 分布式缓存 使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。 相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。 数据库缓存 MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。 CPU 多级缓存 CPU 为了解决运算速度与主存 IO 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。 三、CDN 内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。 CDN 主要有以下优点： 更快地将数据分发给用户； 通过部署多台服务器，从而提高系统整体的带宽性能； 多台服务器可以看成是一种冗余机制，从而具有高可用性。 四、缓存问题 缓存穿透 指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。 解决方案： 对这些不存在的数据缓存一个空数据； 对这类请求进行过滤。 缓存雪崩 指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。 在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。 解决方案： 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现； 分散设置缓存时间 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。 使用分布式缓存 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。 缓存预热 缓存一致性 缓存一致性要求数据更新的同时缓存数据也能够实时更新。 解决方案： 在数据更新的同时立即去更新缓存； 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。 要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。 缓存 “无底洞” 现象 指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。 产生原因 缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。 解决方案： 优化批量数据操作命令； 减少网络通信次数； 降低接入成本，使用长连接 / 连接池，NIO 等。 五、数据分布 哈希分布 哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。 传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。 顺序分布 将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如 User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，...，6001 ~ 7000。 顺序分布相比于哈希分布的主要优点如下： 能保持数据原有的顺序； 并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。 六、一致性哈希 Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。 七、LRU 消息队列 一、消息模型 点对点 消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。 发布/订阅 消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。 发布与订阅模式和观察者模式有以下不同： 观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，生产者与消费者不知道对方的存在，它们之间通过频道进行通信。 观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，生产者向频道发送一个消息之后，就不需要关心消费者何时去订阅这个消息，可以立即返回。 二、使用场景 异步处理 发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。 例如在注册流程中通常需要发送验证邮件来确保注册用户身份的合法性，可以使用消息队列使发送验证邮件的操作异步处理，用户在填写完注册信息之后就可以完成注册，而将发送验证邮件这一消息发送到消息队列中。 只有在业务流程允许异步处理的情况下才能这么做，例如上面的注册流程中，如果要求用户对验证邮件进行点击之后才能完成注册的话，就不能再使用消息队列。 流量削锋 在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。 可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。 应用解耦 如果模块之间不直接进行调用，模块之间耦合度就会很低，那么修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。 通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。 三、可靠性 发送端的可靠性 发送端完成操作后一定能将消息成功发送到消息队列中。 实现方法：在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。 接收端的可靠性 接收端能够从消息队列成功消费一次消息。 两种实现方法： 保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的。 保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。 "},"InterviewPreparation/TechnicalInterviews/01-操作系统.html":{"url":"InterviewPreparation/TechnicalInterviews/01-操作系统.html","title":"操作系统","keywords":"","body":"datetime:2022-03-08 17:19 author:nzb 技术面试必备基础知识 传送门 操作系统 计算机操作系统 概述 基本特征 1. 并发 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。 并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。 操作系统通过引入进程和线程，使得程序能够并发运行。 2. 共享 共享是指系统中的资源可以被多个并发进程共同使用。 有两种共享方式：互斥共享和同时共享。 互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。 3. 虚拟 虚拟技术把一个物理实体转换为多个逻辑实体。 主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。 多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。 * 虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。 4. 异步 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。 基本功能 1. 进程管理 2. 内存管理 3. 文件管理 4. 设备管理 系统调用 如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。 宏内核和微内核 1. 宏内核 2. 微内核 中断分类 1. 外中断 由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断（Ctril + c）等。 2. 异常 由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。 3. 陷入 在用户程序中使用系统调用。 进程管理 进程与线程 1. 进程 进程是资源分配的基本单位。 2. 线程 线程是独立调度的基本单位。一个进程中可以有多个线程，它们共享进程资源。 3. 区别 Ⅰ 拥有资源 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 Ⅱ 调度 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 Ⅲ 系统开销 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 Ⅳ 通信方面 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 应该注意以下内容： 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 进程调度算法 1. 批处理系统 没有太多的用户操作 1.1 先来先服务 first-come first-serverd（FCFS） 非抢占式的调度算法，按照请求的顺序进行调度。 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 1.2 短作业优先 shortest job first（SJF） 非抢占式的调度算法，按估计运行时间最短的顺序进行调度。 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 1.3 最短剩余时间优先 shortest remaining time next（SRTN） 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 2. 交互式系统 有大量的用户交互操作 2.1 时间片轮转 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法的效率和时间片的大小有很大关系： 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 2.2 优先级调度 为每个进程分配一个优先级，按优先级进行调度。 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 2.3 多级反馈队列 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 3. 实时系统 实时系统要求一个请求在一个确定时间内得到响应。 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。 进程同步 1. 临界区 对临界资源进行访问的那段代码称为临界区。 2. 同步与互斥 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量 4. 管程 经典同步问题 1. 哲学家进餐问题 2. 读者-写者问题 进程通信 进程同步与进程通信很容易混淆，它们的区别在于： 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 1. 管道(匿名管道) 管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。 它具有以下限制： 只支持半双工通信（单向交替传输）； 只能在父子进程或者兄弟进程中使用。 2. FIFO(有名管道) 命名管道，去除了管道只能在父子进程中使用的限制。常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 3. 信号 信号一般用于一些异常情况下的进程间通信，是一种异步通信，它的数据结构一般就是一个数字。 在Linux操作系统中，为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过kill -l命令，查看所有的信号。 运行在shell终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如 Ctrl+C产生 SIGINT 信号，表示终止该进程； Ctrl+Z产生 SIGTSTP 信号，表示停止该进程，但还未结束； 如果进程在后台运行，可以通过kill命令的方式给进程发送信号，但前提需要知道运行中的进程PID号，例如： kill -9 1050，表示给PID为1050的进程发送SIGKILL 信号，用来立即结束该进程（例如：在任务管理器右键结束进程）； 所以，信号事件的来源主要有硬件来源(如键盘Cltr+C)和软件来源(如kill命令)。 信号是进程间通信机制中唯一的异步通信机制 进程需要为信号设置相应的监听处理，当收到特定信号时，执行相应的操作，类似很多编程语言里的通知机制。 4. 消息队列 相比于 FIFO，消息队列具有以下优点： 可独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 5. 信号量 一个计数器，用于为多个进程提供对共享数据对象的访问。 6. 共享存储 允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。 需要使用信号量用来同步对共享存储的访问。 多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。 7. 套接字 用于不同机器间的进程通信 死锁 必要条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 处理方法 鸵鸟策略 因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。 当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。 死锁检测与死锁恢复 不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。 1. 每种类型一个资源的死锁检测 2. 每种类型多个资源的死锁检测 3. 死锁恢复 利用抢占恢复 利用回滚恢复 通过杀死进程恢复 死锁预防 在程序运行之前预防发生死锁。 1. 破坏互斥条件 例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。 2. 破坏占有和等待条件 一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。 3. 破坏不可抢占条件 4. 破坏环路等待 给资源统一编号，进程只能按编号顺序来请求资源。 死锁避免 1. 安全状态 2. 单个资源的银行家算法 3. 多个资源的银行家算法 内存管理 虚拟内存 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。 分页系统地址映射 内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。 页面置换算法 页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。 1. 最佳 OPT, Optimal replacement algorithm 所选择被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。 是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 2. 最近最久未使用 LRU, Least Recently Used 在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。 3. 最近未使用 NRU, Not Recently Used 每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类： R=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1 当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。 NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。 4. 先进先出 FIFO, First In First Out 选择换出的页面是最先进入的页面。 该算法会将那些经常被访问的页面换出，导致缺页率升高。 5. 第二次机会算法 FIFO 改进版 当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。 6. 时钟 第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。 分段 段页式 分页与分段的比较 设备管理 磁盘结构 盘面（Platter）：一个磁盘有多个盘面； 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道； 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小； 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）； 制动手臂（Actuator arm）：用于在磁道之间移动磁头； 主轴（Spindle）：使整个盘面转动。 磁盘调度算法 读写一个磁盘块的时数据影响因素有： 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上） 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上） 实际的数据传输时间 其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。 1. 先来先服务 FCFS, First Come First Served 优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。 2. 最短寻道时间优先 SSTF, Shortest Seek Time First * 优先调度与当前磁头所在磁道距离最近的磁道。虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。 3. 电梯算法 电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。 链接 Linux "},"InterviewPreparation/TechnicalInterviews/02-网络.html":{"url":"InterviewPreparation/TechnicalInterviews/02-网络.html","title":"网络","keywords":"","body":"datetime:2022-03-08 17:19 author:nzb 技术面试必备基础知识 传送门 网络 计算机网络 概述 网络的网络 ISP 互联网服务提供商 ISP 主机之间的通信方式 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方 对等（P2P）：不区分客户和服务器 电路交换与分组交换 1. 电路交换 用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。 2. 分组交换 每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响，因此在同一条传输线路上允许同时传输多个分组，也就是说分组交换不需要占用传输线路。 时延 总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延 1. 排队时延 分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。 2. 处理时延 主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。 3. 传输时延 主机或路由器传输数据帧所需要的时间。 4. 传播时延 电磁波在信道中传播所需要花费的时间，电磁波传播的速度接近光速。 计算机网络体系结构 1. 五层协议 应用层 ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。 传输层 ：运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报 。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层 ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 物理层 ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 2. OSI 其中表示层和会话层用途如下： 表示层 ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。 会话层 ：建立及管理会话。 五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。 3. TCP/IP 它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。 TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。 4. 数据在各层之间的传递过程 在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。 路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层。 物理层 通信方式 根据信息在传输线上的传送方向，分为以下三种通信方式： 单工通信：单向传输 半双工通信：双向交替传输 全双工通信：双向同时传输 带通调制 模拟信号是连续的信号，数字信号是离散的信号。带通调制把数字信号转换为模拟信号。 链路层 包含协议 CSMA/CD 协议 PPP 协议 基本问题 1. 封装成帧 将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。 2. 透明传输 透明表示一个实际存在的事物看起来好像不存在一样。 透明传输的内容是转义字符，用户察觉不到转义字符的存在。 3. 差错检测 目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。 信道分类 1. 广播信道 一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。 所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。 主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。 信道复用技术 1. 频分复用 频分复用的所有主机在相同的时间占用不同的频率带宽资源。 会一直占用一部分信道资源，利用率都不高。 2. 时分复用 时分复用的所有主机在不同的时间占用相同的频率带宽资源。 会一直占用一部分信道资源，利用率都不高。 3. 统计时分复用 是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据集集中起来组成统计时分复用帧然后发送。 4. 波分复用 光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。 5. 码分复用 CSMA/CD 协议 多点接入、载波监听、碰撞检测 多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上。 载波监听 ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。 碰撞检测 ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。 2. 点对点信道 一对一通信。 因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。 PPP 协议 PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。 PPP 的帧格式 F 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500 MAC 地址 MAC 地址是链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。 一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。 局域网 局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。 主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。 可以按照网络拓扑结构对局域网进行分类： 以太网 以太网是一种星型拓扑结构局域网。 早期使用集线器进行连接，如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。 目前以太网使用交换机替代了集线器，交换机是一种链路层设备，它不会发生碰撞，能根据 MAC 地址进行存储转发。 以太网帧格式： 类型 ：标记上层使用的协议； 数据 ：长度在 46-1500 之间，如果太小则需要填充； FCS ：帧检验序列，使用的是 CRC 检验方法； 交换机 交换机具有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。 虚拟局域网 虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息。 网络层 包含协议 IP 协议 ARP 地址解析协议 ICMP 网际控制报文协议 IGMP 网际组管理协议 RIP、OSPF 内部网关协议 BGP 外部网关协议 概述 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP 数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 IP 地址编址方式 1. 分类 由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {, } 2. 子网划分 通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。 IP 地址 ::= {, , } 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 注意，外部网络看不到子网的存在。 3. 无分类 地址解析协议 ARP ARP 实现由 IP 地址得到 MAC 地址。 网际控制报文协议 ICMP ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。 ICMP 报文分为差错报告报文和询问报文。 1. Ping 主要用来测试两台主机之间的连通性。 Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。 2. Traceroute 用来跟踪一个分组从源点到终点的路径 虚拟专用网 VPN 一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。 有三个专用地址块： 10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 网络地址转换 NAT 路由器的结构 路由器从功能上可以划分为 路由选择 分组转发。 分组转发结构由三个部分组成 交换结构 一组输入端口 一组输出端口。 路由器分组转发流程 路由选择协议 可以把路由选择协议划分为两大类： 自治系统内部的路由选择：RIP 和 OSPF 自治系统间的路由选择：BGP 1. 内部网关协议 RIP RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。 RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。 2. 内部网关协议 OSPF 开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。 3. 外部网关协议 BGP 边界网关协议 传输层 包含协议 TCP 传输控制协议 UDP 用户数据报协议` UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 TCP 的四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 TCP 可靠传输 TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。 TCP 滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。 TCP 流量控制 流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 TCP 拥塞控制 如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。 发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 1. 慢开始与拥塞避免 2. 快重传与快恢复 应用层 包含协议 FTP 文本传输协议 HTTP 超文本传输协议 DHCP 动态主机配置协议 TELNET 远程登录协议 SMTP 邮件发送协议 POP3、IMAP 邮件读取协议` 域名系统 DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。 这里的分布式数据库是指，每个站点只保留它自己的那部分数据。 域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。 文件传送协议 FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件： 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式： 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 动态主机配置协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。 远程登录协议 TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。 邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. SMTP 2. POP3 3. IMAP 常用端口 Web 页面请求过程 1. DHCP 配置主机信息 2. ARP 解析 MAC 地址 3. DNS 解析域名 4. HTTP 请求页面 HTTP 一 、基础概念 请求和响应报文 URL 统一资源定位符 二、HTTP 方法 GET 获取资源 HEAD 获取报文首部 POST 传输实体主体 PUT 上传文件 PATCH 对资源进行部分修改 DELETE 删除文件 OPTIONS 查询支持的方法 CONNECT 要求在与代理服务器通信时建立隧道 TRACE 追踪路径 三、HTTP 状态码 1XX 信息 2XX 成功 3XX 重定向 4XX 客户端错误 5XX 服务器错误 四、HTTP 首部 有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。 通用首部字段 e.g：Date 创建报文的日期时间 请求首部字段 e.g： Accept 用户代理可处理的媒体类型 Authorization Web 认证信息 User-Agent HTTP 客户端程序的信息 响应首部字段 e.g：Location 令客户端重定向至指定 URI 实体首部字段 e.g： Content-Type 实体主体的媒体类型 Allow 资源可支持的 HTTP 方法 五、具体应用 连接管理 1. 短连接与长连接 从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close； 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。 2. 流水线 在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。 Cookie 缓存 内容协商 内容编码 范围请求 分块传输编码 多部分对象集合 虚拟主机 通信数据转发 1. 代理 使用代理的主要目的是： 缓存 负载均衡 网络访问控制 访问日志记录 2. 网关 3. 隧道 六、HTTPS HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。 通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。 加密 1. 对称密钥加密 对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。 优点：运算速度快； 缺点：无法安全地将密钥传输给通信方。 2.非对称密钥加密 非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。 优点：可以更安全地将公开密钥传输给通信发送方； 缺点：运算速度慢。 3. HTTPS 采用的加密方式 HTTPS 采用混合的加密机制，正是利用了上面提到的方案： 使用非对称密钥加密方式，传输对称密钥加密方式所需要的 Secret Key，从而保证安全性; 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率。（下图中的 Session Key 就是 Secret Key） 认证 数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。 完整性保护 HTTPS 的缺点 因为需要进行加密解密等过程，因此速度会更慢； 需要支付证书授权的高额费用。 七、HTTP/2.0 HTTP/1.x 缺陷 二进制分帧层 服务端推送 HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。 首部压缩 八、HTTP/1.1 新特性 九、GET 和 POST 比较 作用 GET 用于获取资源，而 POST 用于传输实体主体。 参数 GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参数支持标准字符集。 安全 安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。 GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 安全的方法除了 GET 之外还有：HEAD、OPTIONS。 不安全的方法除了 POST 之外还有 PUT、DELETE。 幂等性 幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。 所有的安全方法也都是幂等的。 在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。 可缓存 XMLHttpRequest XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。 Socket 一、I/O 模型 一个输入操作通常包括两个阶段： 1、等待数据准备好 2、从内核向进程复制数据 阻塞式 I/O 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回 CPU 利用率会比较高 非阻塞式 I/O 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling） CPU 利用率比较低 I/O 复用 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O 信号驱动 I/O 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高 异步 I/O 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O 五大 I/O 模型比较 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。 异步 I/O：第二阶段应用进程不会阻塞。 同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。 非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。 二、I/O 复用 select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。 select select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。 poll poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态。 比较 1. 功能 select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。 select 会修改描述符，而 poll 不会； select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制； poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。 2. 速度 select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。 3. 可移植性 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。 epoll epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。 工作模式 epoll 的描述符事件有两种触发模式：LT（level trigger）和 ET（edge trigger）。 1. LT 模式 当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 2. ET 模式 和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。 很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 应用场景 很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。 1. select 应用场景 select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。 select 可移植性更好，几乎被所有主流平台所支持。 2. poll 应用场景 poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 3. epoll 应用场景 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。 通俗举例 "},"InterviewPreparation/TechnicalInterviews/03-数据库.html":{"url":"InterviewPreparation/TechnicalInterviews/03-数据库.html","title":"数据库","keywords":"","body":"datetime:2022-03-08 17:19 author:nzb 技术面试必备基础知识 传送门 数据库 数据库系统原理 一、事务 概念 满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 ACID 1. 原子性（Atomicity） 2. 一致性（Consistency） 3. 隔离性（Isolation） 4. 持久性（Durability） AUTOCOMMIT MySQL 默认采用自动提交模式。也就是说，如果不显式使用START TRANSACTION语句来开始一个事务，那么每个查询操作都会被当做一个事务并自动提交。 二、并发一致性问题 丢失修改 读脏数据 不可重复读 幻影读 三、封锁 封锁粒度 MySQL 中提供了两种封锁粒度：行级锁以及表级锁。 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。 在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 封锁类型 1. 读写锁 互斥锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定： 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 2. 意向锁 封锁协议 1. 三级封锁协议 一级封锁协议 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。 解决丢失修改问题。 因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 解决读脏数据问题。 因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 三级封锁协议 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 解决不可重复读的问题。 因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 2. 两段锁协议 MySQL 隐式与显示锁定 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB 也可以使用特定的语句进行显示锁定： SELECT ... LOCK In SHARE MODE; 加 S 锁 SELECT ... FOR UPDATE; 加 X 锁 四、隔离级别 未提交读（READ UNCOMMITTED） 事务中的修改，即使没有提交，对其它事务也是可见的。 提交读（READ COMMITTED） 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读（REPEATABLE READ） 保证在同一个事务中多次读取同一数据的结果是一样的。 可串行化（SERIALIZABLE） 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。 该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。 五、多版本并发控制 多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 基本思想 版本号 系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号 TRX_ID ：事务开始时的系统版本号。 Undo 日志 ReadView 快照读与当前读 1. 快照读 MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。 2. 当前读 MVCC 其它会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。 在进行 SELECT 操作时，可以强制指定进行加锁操作。以下第一个语句需要加 S 锁，第二个需要加 X 锁。 SELECT * FROM table WHERE ? lock in share mode; SELECT * FROM table WHERE ? for update; 六、Next-Key Locks 使用 MVCC + Next-Key Locks 可以解决幻读问题 Record Locks 锁定一个记录上的索引，而不是记录本身。 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Locks 锁定索引之间的间隙，但是不包含索引本身。 Next-Key Locks 它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间，例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间： (-∞, 10] (10, 11] (11, 13] (13, 20] (20, +∞) 七、关系数据库设计理论 函数依赖 异常 范式 八、ER 图 实体的三种联系 三个组成部分：实体、属性、联系 包含一对一，一对多，多对多三种。 如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B； 如果是一对一，画两个带箭头的线段； 如果是多对多，画两个不带箭头的线段。 表示出现多次的关系 联系的多向性 表示子类 用一个三角形和两条线来连接类和子类，与子类有关的属性和联系都连到子类上，而与父类和子类都有关的连到父类上。 SQL 语法 SQL 练习 MySQL 一、索引 B+ Tree 原理 MySQL 索引 1. B+Tree 索引 是大多数 MySQL 存储引擎的默认索引类型。 因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。 因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。 InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。 2. 哈希索引 哈希索引能以 O(1) 时间进行查找，但是失去了有序性： 无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 3. 全文索引 MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。 查找条件使用 MATCH AGAINST，而不是普通的 WHERE。 全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。 InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。 4. 空间数据索引 MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。 必须使用 GIS 相关的函数来维护数据。 索引优化 1. 独立的列 在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。 例如下面的查询不能使用 actor_id 列的索引： SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 2. 联合索引（多列索引） 在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。 SELECT film_id, actor_ id FROM sakila.film_actorWHERE actor_id = 1 AND film_id = 1; 3. 索引列的顺序 让选择性最强的索引列放在前面。 索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。 例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。 SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity, COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity, COUNT(*) FROM payment; staff_id_selectivity: 0.0001 customer_id_selectivity: 0.0373 COUNT(*): 16049 4. 前缀索引 对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。 前缀长度的选取需要根据索引选择性来确定。 5. 覆盖索引 索引包含所有需要查询的字段的值。 具有以下优点： 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。 索引的优点 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。 索引的使用条件 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效； 对于中到大型的表，索引就非常有效； 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。 索引失效 没有遵循最左匹配原则。 键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 一些关键字会导致索引失效，例如 or， ！= ， not in，is null ,is not unll like查询是以%开头 隐式转换会导致索引失效。 索引列是表达式的一部分，或者是函数的参数 二、查询性能优化 使用 Explain 进行分析 Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。 比较重要的字段有： select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 优化数据访问 1. 减少请求的数据量 只返回必要的列：最好不要使用 SELECT * 语句。 只返回必要的行：使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 2. 减少服务器端扫描的行数 最有效的方式是使用索引来覆盖查询。 重构查询方式 1. 切分大查询 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。 DELETE FROM messages WHERE create 0 2. 分解大连接查询 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有： 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。 SELECT * FROM tag JOIN tag_post ON tag_post.tag_id=[tag.id](http://tag.id/) JOIN post ON tag_post.post_id=[post.id](http://post.id/) WHERE tag.tag='mysql'; SELECT * FROM tag WHERE tag='mysql'; SELECT * FROM tag_post WHERE tag_id=1234; SELECT * FROM post WHERE [post.id](http://post.id/) IN (123,456,567,9098,8904); 三、存储引擎 InnoDB MyISAM 比较 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。 外键：InnoDB 支持外键。 备份：InnoDB 支持在线热备份。 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。 其它特性：MyISAM 支持压缩表和空间数据索引。 四、数据类型 整型 浮点数 字符串 时间和日期 五、切分 水平切分 水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。 当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而减缓单个数据库的压力。 垂直切分 垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。 在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。 Sharding 策略 哈希取模：hash(key) % N； 范围：可以是 ID 范围也可以是时间范围； 映射表：使用单独的一个数据库来存储映射关系。 Sharding 存在的问题 1. 事务问题 使用分布式事务来解决，比如 XA 接口。 2. 连接 可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。 3. ID 唯一性 使用全局唯一 ID（GUID） 为每个分片指定一个 ID 范围 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法) 六、复制 主从复制 主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。 binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。 读写分离 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。 读写分离能提高性能的原因在于： 主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。 读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。 参考资料 Redis 一、概述 Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。 键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。 Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。 二、数据类型 STRING set get del LIST rpush lrange list-key 0 -1 lindex list-key 1 lpop SET sadd smembers sismember srem HASH hset hash-key sub-key1 value1 hgetall hdel hash-key sub-key2 hget hash-key sub-key1 ZSET zadd zset-key 728 member1 zrange zset-key 0 -1 withscores zrangebyscore zset- key 0 800 withscores zrem 三、数据结构 字典 dictht 是一个散列表结构，使用拉链法解决哈希冲突。 跳跃表 是有序集合的底层实现之一。 跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。 与红黑树等平衡树相比，跳跃表具有以下优点： 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。 四、使用场景 计数器 可以对 String 进行自增自减运算，从而实现计数器功能。 Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。 缓存 将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 查找表 查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。 例如 DNS 记录就很适合使用 Redis 进行存储。 消息队列 List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息 不过最好使用 Kafka、RabbitMQ 等消息中间件。 会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。 当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。 分布式锁实现 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。 可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 其它 Set 可以实现交集、并集等操作，从而实现共同好友等功能。 ZSet 可以实现有序性操作，从而实现排行榜等功能。 五、Redis 与 Memcached 数据类型 Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。 数据持久化 Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。 分布式 Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。 Redis Cluster 实现了分布式的支持。 内存管理机制 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。 Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。 六、键的过期时间 Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。 对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。 七、数据淘汰策略 可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。 Redis 具体有 6 种淘汰策略： 作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。 使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。 Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。 八、持久化 Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。 RDB 持久化 将某个时间点的所有数据都存放到硬盘上。 可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。 如果系统发生故障，将会丢失最后一次创建快照之后的数据。 如果数据量很大，保存快照的时间会很长。 AOF 持久化 将写命令添加到 AOF 文件（Append Only File）的末尾。 使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项： always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。 九、事务 一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。 事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。 Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。 十、事件 Redis 服务器是一个事件驱动程序。 文件事件 时间事件 事件的调度与执行 十一、复制 连接过程 主从链 十二、Sentinel Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。 十三、分片 分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。 假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。 根据执行分片的位置，可以分为三种分片方式： 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。 十四、一个简单的论坛系统分析 文章信息 点赞功能 对文章进行排序 "},"InterviewPreparation/TechnicalInterviews/04-系统设计.html":{"url":"InterviewPreparation/TechnicalInterviews/04-系统设计.html","title":"系统设计","keywords":"","body":"datetime:2022-03-08 17:19 author:nzb 技术面试必备基础知识 传送门 系统设计 系统设计基础 一、性能 性能指标 1. 响应时间 指某个请求从发出到接收到响应消耗的时间。 2. 吞吐量 系统在单位时间内可以处理的请求数量，通常使用每秒的请求数来衡量。 3. 并发用户数 指系统能同时处理的并发用户请求数量。 性能优化 1. 集群 将多台服务器组成集群，使用负载均衡将请求转发到集群中，避免单一服务器的负载压力过大导致性能降低。 2. 缓存 缓存能够提高性能的原因如下： 缓存数据通常位于内存等介质中，这种介质对于读操作特别快； 缓存数据可以位于靠近用户的地理位置上； 可以将计算结果进行缓存，从而避免重复计算。 3. 异步 某些流程可以将操作转换为消息，将消息发送到消息队列之后立即返回，之后这个操作会被异步处理。 二、伸缩性 指不断向集群中添加服务器来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。 伸缩性与性能 如果系统存在性能问题，那么单个用户的请求总是很慢的； 如果系统存在伸缩性问题，那么单个用户的请求可能会很快，但是在并发数很高的情况下系统会很慢。 实现伸缩性 应用服务器只要不具有状态，那么就可以很容易地通过负载均衡器向集群中添加新的服务器。 关系型数据库的伸缩性通过 Sharding 来实现，将数据按一定的规则分布到不同的节点上，从而解决单台存储服务器的存储空间限制。 对于非关系型数据库，它们天生就是为海量数据而诞生，对伸缩性的支持特别好。 三、扩展性 指的是添加新功能时对现有系统的其它应用无影响，这就要求不同应用具备低耦合的特点。 实现可扩展主要有两种方式： 使用消息队列进行解耦，应用之间通过消息传递进行通信； 使用分布式服务将业务和可复用的服务分离开来，业务使用分布式服务框架调用可复用的服务。新增的产品可以通过调用可复用的服务来实现业务逻辑，对其它产品没有影响。 四、可用性 冗余 保证高可用的主要手段是使用冗余，当某个服务器故障时就请求其它服务器。 应用服务器的冗余比较容易实现，只要保证应用服务器不具有状态，那么某个应用服务器故障时，负载均衡器将该应用服务器原先的用户请求转发到另一个应用服务器上，不会对用户有任何影响。 存储服务器的冗余需要使用主从复制来实现，当主服务器故障时，需要提升从服务器为主服务器，这个过程称为切换。 监控 对 CPU、内存、磁盘、网络等系统负载信息进行监控，当某个信息达到一定阈值时通知运维人员，从而在系统发生故障之前及时发现问题。 服务降级 服务降级是系统为了应对大量的请求，主动关闭部分功能，从而保证核心功能可用。 五、安全性 要求系统在应对各种攻击手段时能够有可靠的应对措施。 分布式 一、分布式锁 在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。 阻塞锁通常使用互斥量来实现： 互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态； 互斥量为 1 表示未锁定状态。 1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。 数据库的唯一索引 获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否处于锁定状态。 存在以下几个问题： 锁没有失效时间，解锁失败的话其它进程无法再获得该锁； 只能是非阻塞锁，插入失败直接就报错了，无法重试； 不可重入，已经获得锁的进程也必须重新获取锁。 Redis 的 SETNX 指令 使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。 SETNX 指令和数据库的唯一索引类似，保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。 EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。 Redis 的 RedLock 算法 使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。 尝试从 N 个互相独立 Redis 实例获取锁； 计算获取锁消耗的时间，只有时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，才认为获取锁成功； 如果获取锁失败，就到每个实例上释放锁。 Zookeeper 的有序节点 1. Zookeeper 抽象模型 Zookeeper 提供了一种树形结构的命名空间，/app1/p_1 节点的父节点为 /app1。 2. 节点类型 永久节点：不会因为会话结束或者超时而消失； 临时节点：如果会话结束或者超时就会消失； 有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，以此类推。 3. 监听器 为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。 4. 分布式锁实现 创建一个锁目录 /lock； 当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点； 客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁； 执行业务代码，完成后，删除对应的子节点。 5. 会话超时 如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。可以看到，这种实现方式不会出现数据库的唯一索引实现方式释放锁失败的问题。 6. 羊群效应 一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应，一只羊动起来，其它羊也会一哄而上），而我们只希望它的后一个子节点收到通知。 二、分布式事务 指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。 分布式锁和分布式事务区别： 锁问题的关键在于进程操作的互斥关系，例如多个进程同时修改账户的余额，如果没有互斥关系则会导致该账户的余额不正确。 而事务问题的关键则在于事务涉及的一系列操作需要满足 ACID 特性，例如要满足原子性操作则需要这些操作要么都执行，要么都不执行。例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。 2PC 两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。 1. 运行过程 1.1 准备阶段 协调者询问参与者事务是否执行成功，参与者发回事务执行结果。询问可以看成一种投票，需要参与者都同意才能执行。 1.2 提交阶段 如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。 需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。 2. 存在的问题 2.1 同步阻塞 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞等待状态，无法进行其它操作。 2.2 单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在提交阶段发生故障，所有参与者会一直同步阻塞等待，无法完成其它操作。 2.3 数据不一致 在提交阶段，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。 2.4 太过保守 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。 本地消息表 本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 三、CAP 分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。 一致性 一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。 对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。 可用性 可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。 在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。 分区容忍性 网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。 在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。 权衡 在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，CAP 理论实际上是要在可用性和一致性之间做权衡。 可用性和一致性往往是冲突的，很难使它们同时满足。在多个节点之间进行数据同步时， 为了保证一致性（CP），不能访问未同步完成的节点，也就失去了部分可用性； 为了保证可用性（AP），允许读取所有节点的数据，但是数据可能不一致。 四、BASE BASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。 BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 基本可用 指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。 例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。 软状态 指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。 最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。 ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。 在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。 五、Paxos 用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。 主要有三类节点： 提议者（Proposer）：提议一个值； 接受者（Acceptor）：对每个提议进行投票； 告知者（Learner）：被告知投票的结果，不参与投票过程。 执行过程 规定一个提议包含两个字段：[n, v]，其中 n 为序号（具有唯一性），v 为提议值。 1. Prepare 阶段 2. Accept 阶段 3. Learn 阶段 约束条件 1. 正确性 指只有一个提议值会生效。 因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。 2. 可终止性 指最后总会有一个提议生效。 Paxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。 六、Raft Raft 也是分布式一致性协议，主要是用来竞选主节点。 单个 Candidate 的竞选 多个 Candidate 竞选 数据同步 集群 一、负载均衡 集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。 负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。 负载均衡器可以用来实现高可用以及伸缩性： 高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点 负载均衡器运行过程包含两个部分： 根据负载均衡算法得到转发的节点 进行转发 负载均衡算法 1. 轮询（Round Robin） 轮询算法把每个请求轮流发送到每个服务器上。该算法比较适合每个服务器的性能差不多的场景。 2. 加权轮询（Weighted Round Robbin） 加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。 3. 最少连接（least Connections） 由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。 最少连接算法就是将请求发送给当前最少连接数的服务器上。 4. 加权最少连接（Weighted Least Connection） 在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。 5. 随机算法（Random） 把请求随机发送到服务器上。 和轮询算法类似，该算法比较适合服务器性能差不多的场景。 6. 源地址哈希法 (IP Hash) 源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。 可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session） 转发实现 1. HTTP 重定向 HTTP 重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。 缺点： 需要两次请求，因此访问延迟比较高； HTTP 负载均衡器处理能力有限，会限制集群的规模。 该负载均衡转发的缺点比较明显，实际场景中很少使用它。 2. DNS 域名解析 在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。 优点： DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。 缺点： 由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。 大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址。 3. 反向代理服务器 反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。 在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。 优点： 与其它功能集成在一起，部署简单。 缺点： 所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。 4. 网络层 在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的 IP 地址，并修改请求数据包的目的 IP 地址，最后进行转发。 源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。 优点： 在内核进程中进行处理，性能比较高。 缺点： 和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。 5. 链路层 在链路层根据负载均衡算法计算源服务器的 MAC 地址，并修改请求数据包的目的 MAC 地址，并进行转发。 通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，从而不需要修改 IP 地址就可以进行转发。也正因为 IP 地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。 这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。 这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux Virtual Server）。 二、集群下的 Session 管理 一个用户的 Session 信息如果存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器，由于服务器没有用户的 Session 信息，那么该用户就需要重新进行登录等操作。 Sticky Session 需要配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的 Session 存放在该服务器中。 缺点： 当服务器宕机时，将丢失该服务器上的所有 Session。 Session Replication 在服务器之间进行 Session 同步操作，每个服务器都有所有用户的 Session 信息，因此用户可以向任何一个服务器进行请求。 缺点： 占用过多内存； 同步过程占用网络带宽以及服务器处理器时间。 Session Server 使用一个单独的服务器存储 Session 数据，可以使用传统的 MySQL，也使用 Redis 或者 Memcached 这种内存型数据库。 优点： 为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。 缺点： 需要去实现存取 Session 的代码。 攻击技术 一、跨站脚本攻击 跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。 危害 窃取用户的 Cookie 伪造虚假的输入表单骗取个人信息 显示伪造的文章或者图片 防范手段 1. 设置 Cookie 为 HttpOnly 设置了 HttpOnly 的 Cookie 可以防止 JavaScript 脚本调用，就无法通过 document.cookie 获取用户 Cookie 信息。 2. 过滤特殊字符 例如将 转义为 &gt;，从而避免 HTML 和 Jascript 代码的运行。 二、跨站请求伪造 跨站请求伪造（Cross-site request forgery，CSRF），是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去执行。 XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户浏览器的信任。 防范手段 1. 检查 Referer 首部字段 Referer 首部字段位于 HTTP 报文中，用于标识请求来源的地址。检查这个首部字段并要求请求来源的地址在同一个域名下，可以极大的防止 CSRF 攻击。 这种办法简单易行，工作量低，仅需要在关键访问处增加一步校验。但这种办法也有其局限性，因其完全依赖浏览器发送正确的 Referer 字段。虽然 HTTP 协议对此字段的内容有明确的规定，但并无法保证来访的浏览器的具体实现，亦无法保证浏览器没有安全漏洞影响到此字段。并且也存在攻击者攻击某些浏览器，篡改其 Referer 字段的可能。 2. 添加校验 Token 在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验。例如服务器生成随机数并附加在表单中，并要求客户端传回这个随机数。 3. 输入验证码 因为 CSRF 攻击是在用户无意识的情况下发生的，所以要求用户输入验证码可以让用户知道自己正在做的操作。 三、SQL 注入攻击 服务器上的数据库运行非法的 SQL 语句，主要通过拼接来完成。 防范手段 1. 对传入的参数进行编码转义 2. 单引号转换 将传入的参数中的单引号转换为连续两个单引号，PHP 中的 Magic quote 可以完成这个功能。 四、拒绝服务攻击 拒绝服务攻击（denial-of-service attack，DoS），亦称洪水攻击，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。 分布式拒绝服务攻击（distributed denial-of-service attack，DDoS），指攻击者使用两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击。 缓存 一、缓存特征 命中率 当某个请求能够通过访问缓存而得到响应时，称为缓存命中。 缓存命中率越高，缓存的利用率也就越高。 最大空间 缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。 当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。 淘汰策略 FIFO（First In First Out）：先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。 LRU（Least Recently Used）：最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。 LFU（Least Frequently Used）：最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。 二、缓存位置 浏览器 当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。 ISP 网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。 反向代理 反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。 本地缓存 使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。 分布式缓存 使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。 相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。 数据库缓存 MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。 CPU 多级缓存 CPU 为了解决运算速度与主存 IO 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。 三、CDN 内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。 CDN 主要有以下优点： 更快地将数据分发给用户； 通过部署多台服务器，从而提高系统整体的带宽性能； 多台服务器可以看成是一种冗余机制，从而具有高可用性。 四、缓存问题 缓存穿透 指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。 解决方案： 对这些不存在的数据缓存一个空数据； 对这类请求进行过滤。 缓存雪崩 指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。 在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。 解决方案： 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现； 分散设置缓存时间 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。 使用分布式缓存 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。 缓存预热 缓存一致性 缓存一致性要求数据更新的同时缓存数据也能够实时更新。 解决方案： 在数据更新的同时立即去更新缓存； 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。 要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。 缓存 “无底洞” 现象 指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。 产生原因 缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。 解决方案： 优化批量数据操作命令； 减少网络通信次数； 降低接入成本，使用长连接 / 连接池，NIO 等。 五、数据分布 哈希分布 哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。 传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。 顺序分布 将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如 User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，...，6001 ~ 7000。 顺序分布相比于哈希分布的主要优点如下： 能保持数据原有的顺序； 并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。 六、一致性哈希 Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。 七、LRU 消息队列 一、消息模型 点对点 消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。 发布/订阅 消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。 发布与订阅模式和观察者模式有以下不同： 观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，生产者与消费者不知道对方的存在，它们之间通过频道进行通信。 观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，生产者向频道发送一个消息之后，就不需要关心消费者何时去订阅这个消息，可以立即返回。 二、使用场景 异步处理 发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。 例如在注册流程中通常需要发送验证邮件来确保注册用户身份的合法性，可以使用消息队列使发送验证邮件的操作异步处理，用户在填写完注册信息之后就可以完成注册，而将发送验证邮件这一消息发送到消息队列中。 只有在业务流程允许异步处理的情况下才能这么做，例如上面的注册流程中，如果要求用户对验证邮件进行点击之后才能完成注册的话，就不能再使用消息队列。 流量削锋 在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。 可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。 应用解耦 如果模块之间不直接进行调用，模块之间耦合度就会很低，那么修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。 通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。 三、可靠性 发送端的可靠性 发送端完成操作后一定能将消息成功发送到消息队列中。 实现方法：在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。 接收端的可靠性 接收端能够从消息队列成功消费一次消息。 两种实现方法： 保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的。 保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。 "},"InterviewPreparation/DataStructuresAlgorithms/DataStructuresAlgorithms.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/DataStructuresAlgorithms.html","title":"数据结构与算法","keywords":"","body":"datetime:2022-04-09 17:46 author:nzb 数据结构与算法 绪论 基本概念 数据 数据元素、数据项 数据对象、数据结构 数据类型、抽象数据类型（ADT） 数据结构三要素 逻辑结构 集合 线性结构 树形结构 图状结构（网状结构） 物理结构（存储结构） 顺序存储 物理内存中是连续的 非顺序存储 物理内存中是分散的 链式存储 索引存储 散列存储 数据的运算 学习建议 概念多，比较无聊。抓大放小，重要的是形成框架，不必纠结细节概念。 算法 程序 = 数据结构 + 算法 数据结构是要处理的信息 算法是处理信息的步骤 算法的五个特性 有穷性 有穷时间内能执行完 算法是有穷的 程序可以是无穷的 确定性 相同的输入只会产生相同的输出 可行性 可以用已有的基本操作实现算法 输入 丢给算法处理的数据 输出 算法处理的结果 “好”算法的特质 正确性 能正确解决问题 可读性 对算法的描述能让其他人也看得懂 健壮性 算法能处理一些异常状况 高效率与低储存量需求 即算法执行省时、省内存 时间复杂度、空间复杂度 时间复杂度和空间复杂度 时间和空间增长的趋势 时间复杂度 时间开销与问题规模 n 之间的关系 如何计算 找到一个基本操作（最深层循环） 分析该基本操作的执行次数 x 与问题规模 n 的关系 x = f(n) x 的数量级 O (x) 就是算法时间复杂度 T(n) 大 O 表示法（Big O）：，T (n) = O ( f(n) ) T(n)：算法的渐进时间复杂度 f(n)：代码执行次数 O：正比例关系 常用技巧 加法法则：O (f(n)) + O(g(n)) = O (max(f(n),g(n))) 乘法法则：O(f(n)) x O(g(n)) = O(f(n) x g(n)) 记忆技巧：常对幂指阶 常见的时间复杂度量级 x 轴：输入问题的量级；y 轴：时间的复杂度 O (1) O (logN) 设想需要 K 次循环 i 就会大于等于 n；则2^k = n；k = log2n O (n) 解释 int i =1：执行一次 i 所以复杂度：O (1 + 3N) = O (N)；因为 Big O 计算的是 N 接近于无限大的情况下，所以常量 1 和 倍数 3 都没意义了 O (nlogN) O (n^2) 因为 n 趋近于无限大，所以 n 相对于 n ^2 就是一个常量 O (nm) 三种复杂度 最坏时间复杂度 考虑输入数据“最好”的情况 平均时间复杂度 考虑所有输入数据都等概率出现的情况 最好时间复杂度 考虑输入数据“最好”的情况 空间复杂度 空间开销（内存开销）与问题规模 n 之间的关系 如何计算 普通程序 找到所占空间大小与问题规模相关的变量 分析所占空间 x 与问题规模 n 的关系 x = f(n) x 的数量级 O (x) 就是算法空间复杂度 S(n) 递归程序 找到递归调用的深度 x 与问题规模 n 的关系 x = f(n) x 的数量级 O (x) 就是算法空间复杂度 S(n) 注：有的算法各层函数所需的存储空间不同，分析方法略有区别 常用技巧 加法法则：O (f(n)) + O(g(n)) = O (max(f(n),g(n))) 乘法法则：O(f(n)) x O(g(n)) = O(f(n) x g(n)) 记忆技巧：常对幂指阶 O (1) 需要的空间是一个常数量 O (n) 经过 for 循环，数组里面就会有值，如果往数组里面添加越多的数据，则需要更多的空间内存等 O (n^2) 矩阵（二维数组） 其他复杂度指标 线性表 定义 逻辑结构 值的注意的特性 数据元素同类型、有限、有序 重要术语 表长、空表 表头、表尾 前驱、后继 数据元素的位序（从 1 开始） 类似索引 基本操作 运算 创销、增删改查（所有数据结构适用的记忆思路） 判空、判长、打印输出（还可以根据实际需求增加其他基本操作） 其他值的注意的点 理解什么时候要传入参数的引用“&” 值传递还是引用传递 函数命名要有可读性 存储/物理结构 顺序表（顺序存储） 存储结构 逻辑上相邻的数据元素物理上也相邻 实现方式 静态分配 使用“静态数组”实现 大小一旦确定就无法改变 动态分配 使用“动态数组”实现 顺序表存满时，可再用 malloc 动态扩展顺序表的最大容量 需要将数据元素复制到新的存储区域，并用 free 函数释放原区域 特点 随机访问 能在 O(1) 时间内找到第 i 个元素 存储密度高 扩展容量不方便 插入、删除元素不方便 基本操作 插入 插入位置之后的元素都要后移 时间复杂度 最好 O(1) 插入末尾，数据不动 最坏 O (n) 插入表头，数据后移 平均 O(n) 删除 删除位置之后的元素都要前移 时间复杂度 最好 O(1) 删除末尾，数据不动 最坏 O (n) 删除表头，数据前移 平均 O(n) 查找 按位查找 获取表 L 中第 i 个位置的元素的值 用数组下标即可得到第 i 个元素 L.data[i - 1] 时间复杂度 最好、最坏、平均时间复杂度都是 O(1) 按值查找 在顺序表 L 中查找第一个元素值等于 e 的元素，并返回其位序 从第一个元素开始依次往后检索 时间复杂度 最好 O(1) 第一个位置 最坏 O(n) 最坏一个位置 平均 O(n) 每个位置的概率相同 代码要点 注意位序 i 和数组下标的区别 位序是第几个元素，从 1 开始，下标是从 0 开始 判断位序 i 的合法性 链表（链式存储） 单链表 定义 用“链式存储”（存储结构）实现了“线性结构”（逻辑结构） 一个结点存储一个数据元素 各结点间先后关系用一个指针表示 两种实现 不带头结点 空表判断：L == NULL，写代码不方便 带头结点 空表判断：L -> next == NULL，写代码方便 头指针 L 加上下一个结点不带数据只带下一个结点的指针域 基本操作 插入 按位序插入 循环遍历找到第 i -1 的节点，然后插入 带头结点 当前指针指向，从 0 开始，表示第几个节点 不带头结点 当前指针指向，从 1 开始，表示第几个节点 指定结点的后插操作 在 p 结点后插入元素 e s 为插入的结点 s -> data = e s-> next = p->next p->next = s 指定结点的前插操作 知道头指针 依次遍历找到 p 结点，然后插入即可，时间复杂度 O(n) 不知道头指针 在 p 结点后插入元素 e s 为插入的结点 s -> next = p -> next s -> data = p -> data p -> data = e p -> next = s 删除 按位序删除 和插入操作类似 指定结点的删除 删除指定结点 p 需要改变前驱结点的 next 指针 方法1：传入头指针，循环找 p 的前驱结点 方法2：类似结点前插入 p -> data = p -> next -> data p -> next = p -> next -> next 指定结点是最后一个结点时，需要特殊处理，因为q -> next = NULL，没有 data 查找 注意带头和不带头以及最后一个结点（就是 p 指针为 NULL） 按位查找 注意与“顺序表”对比 单链表不具备“随机访问”的特性，只能依次扫描 按值查找 求单链表长度 Key 三种基本操作的时间复杂度都是 O(n) 注意边界条件的处理 建立 尾插法 头插法 链表的逆置 双链表 初始化 头结点的 prior、next 都指向 NULL 插入（后插） 注意新插入结点、前驱结点、后继结点的指针修改 边界情况：新插入结点在最后一个位置，需特殊处理 删除（后删） 注意删除结点的前驱结点、后继结点的指针修改 边界情况：如果被删除结点是最后一个数据结点，需特殊处理 遍历 从一个给定结点开始，向后遍历、向前遍历的实现（循环的终止条件） 链表不具备随机存取特性，查找操作只能通过顺序遍历实现 循环链表 循环单链表 判断循环单链表是否为空：L -> next == L 判断结点 p 是否为循环单链表的表尾结点：p -> next == L，p指针下一个是否指向头指针 循环双链表 判断循环双链表是否为空：L -> next == L 判断结点 p 是否为循环双链表的表尾结点：p -> next == L，p指针下一个是否指向头指针 静态链表 用数组的方式实现的链表 优点：增、删操作不需要大量移动元素 缺点：不能随机存取，只能从头结点开始依次往后查找；容量固定不可变 适用场景 不支持指针的低级语言 数据元素数量固定不变的场景（如操作系统的文件分配表 FAT） 使用 随机存取就是直接存取，可以通过下标直接访问的那种数据结构，与存储位置无关，例如数组。 非随机存取就是顺序存取了，不能通过下标访问了，只能按照存储顺序存取，与存储位置有关，例如链表。 栈（Stack） 定义 一种操作受限的线性表，只能在栈顶插入、删除 特性：后进先出（FIFO） 术语：栈顶、栈底、空栈 基本操作 创、销 增、删（元素进栈、出栈，只能在栈顶操作） 增 删 查（获得栈顶元素，但不删除） 判空 S.top = -1 栈顶指针为-1 顺序栈 顺序存储 用静态数组实现 ，并需要记录栈顶指针 基本操作 创、增、删、查 销：清空、回收 只需要 top = -1 都是 O(1) 时间复杂度 两种实现 初始化 top = -1 指向栈顶元素 入栈 S.data[++S.top] = x 是先栈顶指针加一后赋值，不能先赋值在加一，这样会覆盖元素 出栈 x = S.data[S.top--] 是先赋值后栈顶指针减一 获得栈顶元素 x = S.data[S.top] 栈空/满栈条件？ 到达栈顶：s.top = MaxSize -1 初始化 top = 0 指向栈顶元素的后一位，接下来可以插入元素的位置 入栈 S.data[S.top++] = x 先赋值在加一 出栈 x = S.data[--S.top]] 是先栈顶指针减一后赋值 获得栈顶元素 x = S.data[S.top-1] 栈空/满栈条件？ 到达栈顶：s.top = MaxSize 共享栈 两个栈共享同一片内存空间，两个栈从两边往中间增长 初始化 0 号栈栈顶指针初始时 top0 = -1；1 号栈栈顶指针初始时 top1 = MaxSize 栈满条件 top0 + 1 = top1 链栈 跟单链表类似，只是只能在头部操作 用链式方式实现的栈 两种实现方式 带头结点 不带头结点（推荐） 基本操作 创（初始化） 增（进栈） 删（出栈） 查（获取栈顶元素） 如何判空、判满？ 栈的应用 括号匹配 依次扫描所有字符，遇到左括号入栈，遇到右括号则弹出栈顶元素检查是否匹配 匹配失败情况 左括号单身 栈非空 右括号单身 栈已空 左右括号不匹配 表达式求值 概念 运算符、操作数、界限符 三种表达式 中缀表达式（人算） 运算符在操作数中间 后缀表达式（机算，常用） 运算符在操作数后面 一个中缀表达式可以对应多个后缀、前缀表达式 前缀表达式（机算，不常用） 运算符在操作数前面 后缀表达式 中缀转后缀 按“左优先”原则确定运算符的运算次序 一个中缀表达式只对应一个后缀表达式（确保算法的“确定性”） 根据上面确定的次序，依次将各个运算符和与之相邻的两个操作数按 的规则合体 后缀转中缀 从左往右扫描，每遇到一个运算符，就 将 变为 (左操作数 运算符 右操作数)的形式 计算 从左往右扫描，遇到操作数入栈，遇到运算符则弹出两个栈顶元素运算后入栈（注意：先弹出的元素是“右操作数”） 前缀表达式 中缀转前缀 按“右优先”原则确定运算符的运算次序 根据上面确定的次序，依次将各个运算符和与之相邻的两个操作数按 的规则合体 计算 从右往左扫描，遇到操作数入栈，遇到运算符则弹出两个栈顶元素运算后入栈（注意：先弹出的元素是“左操作数”） 递归 栈中的每一个元素对应内存中的一块区域里面的数据不跟其他元素冲突 队列 定义 一种操作受限的线性表，只能在队尾插入、在队头删除 特性：先进先出（FIFO） 术语：队头、队尾、空队列、队头元素、队尾元素 基本操作 创、销 增、删（入队、出队、只能在规定的一段进行） 查（获得队头元素，但不删除） 判空 队列的顺序实现 实现思路 用静态数组存放数据 元素，设置队头/队尾（front、rear）指针 循环队列：用模运算（取余）将存储空间在逻辑上变为“环状” Q.rear = (Q.rear + 1) % MaxSize 重要考点 如何初始化、入队、出队 如何判空、判满 如何计算队列的长度 分析思路 确定 front、rear 指针的指向 rear 指向队尾元素后一个位置 rear 指向队尾元素 确定判空判满的方法 牺牲一个存储单元 增加 size 变量记录队列长度 增加 tag = 0/1 用于标记最近的一次操作是出队/入队 队列的链式实现 区别 带头结点 不带头结点 基本操作 创（初始化） 增（入队） 注意第一个元素入队 删（出队） 注意 最后一个元出队 查（获取队头元素） 判空 判满？不存在的，可以无限加（内存足够） 队列变种 双端队列 允许从两端插入、两端删除的队列 输入受限的双端队列 允许从两端删除、从一端插入的队列 输出受限的双端队列 允许从两端插入、从一端删除的队列 队列应用 树的层次遍历 图的广度优先遍历 操作系统的应用 CPU资源的分配：多个进程运行（浏览器、QQ、微信） 打印数据缓冲区 特殊矩阵压缩存储 对称矩阵 特点 对方阵中的任意一个元素，有 a(i,j) = a(j,i) 压缩 只存储主对角线 + 下三角区（或主对角线 + 上三角区） 三角矩阵 特点 上三角区全为常数（下三角矩阵）；或下三角区全为常数（上三角矩阵） 压缩 按行优先/列优先规则依次存储非 常量区域，并在最后一个位置存放常量 c 三对角矩阵（带状矩阵） 特点 当 |i - j| > 1时，有 a (i,j) = 0（1 压缩 按行优先/列优先规则依次存储带状区域 稀疏矩阵 特点 非零元素个数远小于零元素个数 压缩 只存储非零元素 顺序存储 顺序存储三元组（行，列，值） 链式存储 十字链表法 串 字符串 定义 串，即字符串（string）是由零个或多个字符组成的有限序列 术语：串长、空串、空格串、子串、主串、字符在主串中的位置、子串在主串中的位置 串 V.S 线性表 串的数据对象限定为字符集 串的基本操作大多以“子串”为操作对象 基本操作 定位操作 比较操作 字符集编码 每个字符在计算机中对应一个二进制数，比较字符的大小其实就是比较二进制数的大小 存储结构 顺序存储和链式存储跟线性表一样 顺序存储 静态数组 动态数组 链式存储 可让每个结点存多个字符，没有字符的位置使用“#” 或 “\\0”补足 静态数组 基本操作 求子串 串的比较 求串在主串中的位置 子串匹配算法 朴素模式匹配算法 串的模式匹配：在主串中找到与模式串相同的子串，并返回其所在的位置 朴素模式匹配算法（简单模式匹配算法）思想 将主串中与模式串长度相同的子串搞出来，挨个与模式串对比 当子串与模式串某个对应字符不匹配时，就立即放弃当前子串，转而检索下一个子串 若模式串长度为 m，主串长度为 n，则直到匹配成功/匹配失败最多需要（n - m + 1）* m次比较 最坏时间复杂度：O(nm) 最坏情况：每个子串的前 m- 1个字符都和模式串匹配，只有第 m 个字符不匹配 比较好的情况：每个子串的第 1 个字符就与模式串不匹配 KMP 算法 粗劣分析算法性能 KMP 算法优化 二者比较 朴素模式匹配算法的缺点：当某些子串与模式串能部分匹配时，主串的扫描指针 i 经常回溯，导致时间开销增加。最坏时间复杂度 O(nm) KMP 算法：当子串和模式串不匹配时，主串指针 i 不回溯，模式串指针 j = next[j] 如果不会经常出现子串与模式串部分匹配的时候，KMP 算法性能也不会比朴素算法好多少 算法平均时间复杂度：O(n + m) next 数组手算方法：当第 j 个字符匹配失败，由前 1~j - 1 个字符组成的串记为 S，则：next[j] = S 的最长相等前后缀长度 + 1 特别的：next[1] = 0, next[2] = 1 链表和数组的区别 数组静态分配内存，链表动态分配内存； 数组在内存中连续，链表不连续是分散的； 数组元素在栈区，链表元素在堆区； 数组利用下标定位，时间复杂度为O(1)，链表定位元素时间复杂度O(n)； 链表也没有下标的概念，只能通过头节点指针，从每一个节点，依次往下找，因为下个节点的位置信息只能通过上个节点知晓。 数组插入或删除元素的时间复杂度O(n)，链表的时间复杂度O(1)。 链表只需要知道操作位置的指针 树与二叉树 定义 树（Tree）是 n（n>=0)个结点的有限集。n=0 时称为空树。在任意一颗非空树中： 1）有且仅有一个特定的称为根（Root）的结点； 2）当 n>1 时，其余结点可分为 m(m>0) 个互不相交的有限集T1、T2、......、Tn，其中每一个集合本身又是一棵树，并且称为根的子树。 此外，树的定义还需要强调以下两点： 1）n>0 时根结点是唯一的，不可能存在多个根结点，数据结构中的树只能有一个根结点。 2）m>0 时，子树的个数没有限制，但它们一定是互不相交的。 示例树： 结点的度 一个结点拥有的子树数目称为结点的度。叶子节点的度为 0 。 叶子节点：没有子节点的节点 所有节点中的最大的度称为树的 度，树中的节点树即为树中所有节点的度之和加一：即：树中的节点树 = 树中所有节点的度之和 + 1 结点关系 结点子树的根结点为该结点的孩子结点。相应该结点称为孩子结点的双亲结点。 上图中，A 为 B 的双亲结点，B 为 A 的孩子结点。 同一个双亲结点的孩子结点之间互称兄弟结点。 上图中，结点 B 与结点 C 互为兄弟结点。 结点层次和树的深度 从根开始定义起，根为第一层，根的孩子为第二层，以此类推。 树中结点的最大层次数称为树的深度或高度。上图所示树的深度为4。 二叉树 定义 二叉树是 n(n>=0) 个结点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根结点和两棵互不相交的、分别称为根结点的左子树和右子树组成。 二叉树特点 1）每个结点最多有两颗子树，所以二叉树中不存在度大于2的结点。 2）左子树和右子树是有顺序的，次序不能任意颠倒。 3）即使树中某结点只有一棵子树，也要区分它是左子树还是右子树。 4）非空二叉树只有一个根节点。 二叉树性质 1）在二叉树的第 i 层上最多有 2^(i-1) 个节点 。（i>=1） 2）二叉树中如果深度为 k ,那么最多有 2^k-1个节点。(k>=1） 3）n0 = n2 + 1： 度为0的节点（叶子节点）总是比度为 2 的节点多一个。 n0 表示度数为 0 的节点数，n2 表示度数为2的节点数。 4）在完全二叉树中，具有n个节点的完全二叉树的深度为[log2n]+1，其中[log2n]是向下取整。 具有 n 个节点的二叉树的深度至少为 [log2n]+1，其中 [log2n] 是向下取整。 5）若对含 n 个结点的完全二叉树从上到下且从左至右进行 1 至 n 的编号，则对完全二叉树中任意一个编号为 i 的结点有如下特性： (1) 若 i=1，则该结点是二叉树的根，无双亲, 否则，编号为 [i/2] 的结点为其双亲结点; (2) 若 2i>n，则该结点无左子树， 否则，编号为 2i 的结点为其左子树结点； (3) 若 2i+1>n，则该结点无右子树， 否则，编号为 2i+1 的结点为其右子树结点。 斜树 斜树：所有的结点都只有左子树的二叉树叫左斜树。所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。 满二叉树 满二叉树：在一棵二叉树中。如果所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 满二叉树的特点有： 1）第 k 层上有 2 ^ (k - 1) 个节点。 2）深度为 m 的满二叉树有 2 ^m - 1个节点 3）非叶子结点的度一定是2。 完全二叉树 完全二叉树：对一颗具有 n 个结点的二叉树按层编号，如果编号为 i(1 除最后一层外，每一层的节点数都达到了最大值，在最后一层上只缺少右边的若干个节点。 满二叉树一定是完全二叉树，但反过来不一定成立。 二叉树的存储结构 顺序存储 二叉树的顺序存储结构就是使用一维数组存储二叉树中的结点，并且结点的存储位置，就是数组的下标索引。 二叉树为完全二叉树 一棵完全二叉树采用顺序存储方式，当二叉树为完全二叉树时，结点数刚好填满数组。 二叉树不为完全二叉树 其中浅色结点表示结点不存在，其中，∧表示数组中此位置没有存储结点。此时可以发现，顺序存储结构中已经出现了空间浪费的情况。 右斜树 对于这种右斜树极端情况，采用顺序存储的方式是十分浪费空间的。 因此，顺序存储一般适用于完全二叉树。 二叉链表 链式存储：由二叉树定义可知，二叉树的每个结点最多有两个子节点。因此，可以将结点数据结构定义为一个数据和两个指针域。 采用一种链表结构存储二叉树，这种链表称为二叉链表。 二叉树遍历 二叉树的遍历一个重点考查的知识点。 定义 二叉树的遍历：是指从二叉树的根结点出发，按照某种次序依次访问二叉树中的所有结点，使得每个结点被访问一次，且仅被访问一次。 二叉树的访问次序可以分为四种 前序遍历 中序遍历 后序遍历 层序遍历 前序遍历 根 - 左 - 右 前序遍历通俗的说就是从二叉树的根结点出发，当第一次到达结点时就输出结点数据，按照先向左在向右的方向访问。 上图所示二叉树的前序遍历输出为：ABDHIEJCFG 中序遍历 左 - 根 - 右 中序遍历就是从二叉树的根结点出发，当第二次到达结点时就输出结点数据，按照先向左在向右的方向访问。 上图所示二叉树的前序遍历输出为：HDIBJEAFCG 后序遍历 左 - 右 - 根 后序遍历就是从二叉树的根结点出发，当第三次到达结点时就输出结点数据，按照先向左在向右的方向访问。 上图所示二叉树的前序遍历输出为：HIDJEBFGCA 层次遍历 层次遍历就是按照树的层次自上而下的遍历二叉树。针对上图所示二叉树的层次遍历结果为：ABCDEFGHIJ 遍历常考考点 1）已知前序遍历序列和中序遍历序列，确定一棵二叉树。 例题：若一棵二叉树的前序遍历为ABCDEF，中序遍历为CBAEDF，请画出这棵二叉树。 分析：前序遍历第一个输出结点为根结点，故A为根结点。早中序遍历中根结点处于左右子树结点中间，故结点A的左子树中结点有CB，右子树中结点有EDF。 按照同样的分析方法，对A的左右子树进行划分，最后得出二叉树的形态如下图所示 2）已知后序遍历序列和中序遍历序列，确定一棵二叉树。 后序遍历中最后访问的为根结点，因此可以按照上述同样的方法，找到根结点后分成两棵子树，进而继续找到子树的根结点，一步步确定二叉树的形态。 注：已知前序遍历序列和后序遍历序列，不可以唯一确定一棵二叉树。 "},"InterviewPreparation/DataStructuresAlgorithms/01-算法.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/01-算法.html","title":"算法","keywords":"","body":"datetime:2022-04-09 17:46 author:nzb 数据结构与算法 Python 常用数据结构和算法 绪论 基本概念 数据 数据元素、数据项 数据对象、数据结构 数据类型、抽象数据类型（ADT） 数据结构三要素 逻辑结构 集合 线性结构 树形结构 图状结构（网状结构） 物理结构（存储结构） 顺序存储 物理内存中是连续的 非顺序存储 物理内存中是分散的 链式存储 索引存储 散列存储 数据的运算 学习建议 概念多，比较无聊。抓大放小，重要的是形成框架，不必纠结细节概念。 算法 程序 = 数据结构 + 算法 数据结构是要处理的信息 算法是处理信息的步骤 算法的五个特性 有穷性 有穷时间内能执行完 算法是有穷的 程序可以是无穷的 确定性 相同的输入只会产生相同的输出 可行性 可以用已有的基本操作实现算法 输入 丢给算法处理的数据 输出 算法处理的结果 “好”算法的特质 正确性 能正确解决问题 可读性 对算法的描述能让其他人也看得懂 健壮性 算法能处理一些异常状况 高效率与低储存量需求 即算法执行省时、省内存 时间复杂度、空间复杂度 时间复杂度和空间复杂度 时间和空间增长的趋势 时间复杂度 时间开销与问题规模 n 之间的关系 如何计算 找到一个基本操作（最深层循环） 分析该基本操作的执行次数 x 与问题规模 n 的关系 x = f(n) x 的数量级 O (x) 就是算法时间复杂度 T(n) 大 O 表示法（Big O）：，T (n) = O ( f(n) ) T(n)：算法的渐进时间复杂度 f(n)：代码执行次数 O：正比例关系 常用技巧 加法法则：O (f(n)) + O(g(n)) = O (max(f(n),g(n))) 乘法法则：O(f(n)) x O(g(n)) = O(f(n) x g(n)) 记忆技巧：常对幂指阶 常见的时间复杂度量级 x 轴：输入问题的量级；y 轴：时间的复杂度 O (1) O (logN) 设想需要 K 次循环 i 就会大于等于 n；则2^k = n；k = log2n O (n) 解释 int i =1：执行一次 i 所以复杂度：O (1 + 3N) = O (N)；因为 Big O 计算的是 N 接近于无限大的情况下，所以常量 1 和 倍数 3 都没意义了 O (nlogN) O (n^2) 因为 n 趋近于无限大，所以 n 相对于 n ^2 就是一个常量 O (nm) 三种复杂度 最坏时间复杂度 考虑输入数据“最好”的情况 平均时间复杂度 考虑所有输入数据都等概率出现的情况 最好时间复杂度 考虑输入数据“最好”的情况 空间复杂度 空间开销（内存开销）与问题规模 n 之间的关系 如何计算 普通程序 找到所占空间大小与问题规模相关的变量 分析所占空间 x 与问题规模 n 的关系 x = f(n) x 的数量级 O (x) 就是算法空间复杂度 S(n) 递归程序 找到递归调用的深度 x 与问题规模 n 的关系 x = f(n) x 的数量级 O (x) 就是算法空间复杂度 S(n) 注：有的算法各层函数所需的存储空间不同，分析方法略有区别 常用技巧 加法法则：O (f(n)) + O(g(n)) = O (max(f(n),g(n))) 乘法法则：O(f(n)) x O(g(n)) = O(f(n) x g(n)) 记忆技巧：常对幂指阶 O (1) 需要的空间是一个常数量 O (n) 经过 for 循环，数组里面就会有值，如果往数组里面添加越多的数据，则需要更多的空间内存等 O (n^2) 矩阵（二维数组） 其他复杂度指标 "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/01-选择、冒泡和插入排序.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/01-选择、冒泡和插入排序.html","title":"选择、冒泡和插入排序","keywords":"","body":"datetime:2023-06-03 15:30 author:nzb 认识复杂度和简单的排序算法 数据结构运行流程利器pythontutor 认识时间复杂度 常数时间的操作 一个操作如果和样本的数据量没有关系，每次都是固定时间内完成的操作，叫做常数操作。 例如：列表取某一位的值就是常数操作，因为列表是一块连续的内存，可以通过偏移量取到，而链表取某一位值是，需要遍历下一个数据，它的内存不是连续的，而是用指针指向另一块内存 时间复杂度为一个算法流程中，常数操作数量的一个指标。常用O(读作big O)来表示。具体来说，先要对一个算法流程非常熟悉，然后去写出这个算法流程中，发生了多少常数操作，进而总结出常数操作数量的表达式。 在表达式中，只要高阶项，不要低阶项，也不要高阶项的系数，剩下的部分如果为f(N)，那么时间复杂度为O(f(N))。 评价一个算法流程的好坏，先看时间复杂度的指标，然后再分析不同数据样本下的实际运行时间，也就是“常数项时间”，也就是用实际跑一遍程序对比。 算法流程按照最差情况来估计时间复杂度 选择排序、冒泡排序细节的讲解与复杂度分析 时间复杂度O(N^2) 额外空间复杂度O(1) 选择排序 import random data = list(range(20)) random.shuffle(data) print(data) # 额外空间，i、min_idx、j，有限数量，所以O(1) for i in range(len(data)): min_idx = i for j in range(i + 1, len(data)): if data[j] 冒泡排序 import random data = list(range(20)) random.shuffle(data) print(data) \"\"\" 5 7 6 2 4 1 第1次循环：5 6 2 4 7 0~N-1范围做比较，确定 N-1 位置的值， 第2次循环：5 2 4 6 7 0~N-2范围做比较，确定 N-2 位置的值， 第3次循环：5 2 4 6 7 0~N-3范围做比较，确定 N-3 位置的值， 第4次循环：2 4 5 6 7 0~N-4范围做比较，确定 N-4 位置的值， 第5次循环：2 4 5 6 7 0~N-5范围做比较，确定 N-5 位置的值， 等差数列：aN^2 + bN + c，留高阶项：O(N^2) \"\"\" # 额外空间，i、j，有限数量，所以O(1) for i in range(1, len(data)): # 循环次数 for j in range(len(data) - i): # 循环索引 if data[j] > data[j + 1]: data[j], data[j + 1] = data[j + 1], data[j] print(data) 插入排序细节的讲解与复杂度分析 [3, 2, 5, 4, 2, 3, 1] 下标0~0：有序 下标0~1：2比3少，则0和1位置交换，再往前看，没数了，则 0~1有序了，即：[2, 3, 5, 4, 2, 3, 1] 下标0~2：5不比3小，则不看了0~2有序了，即：[2, 3, 5, 4, 2, 3, 1] 下标0~3：4比3小，4和3位置交换，再往前看，4不比3小，则不看了，0~3有序了，即：[2, 3, 4, 5, 2, 3, 1] 下标0~4：2比5小，2和5位置交换[2, 3, 4, 2, 5, 3, 1]，再往前看，2比4小，交换[2, 3, 2, 4, 5, 3, 1]，再往前看，2比3小，交换[2, 2, 3, 4, 5, 3, 1] ，再往前看，2不比2小，则不看了，0~4有序了，即：[2, 2, 3, 4, 5, 3, 1] 下标0~5：3比5小，3和5位置交换[2, 2, 3, 4, 3, 5, 1]，再往前看，3比4小，交换[2, 2, 3, 3, 4, 5, 1]，再往前看，再往前看，3不比3小，则不看了，0~5 有序了，即：[2, 2, 3, 3, 4, 5, 1] 下标0~6：1一直会往前看，并交换，直到不比前面小或前面没数了，则0~6有序了，即：[1, 2, 2, 3, 3, 4, 5] 总结：插入排序的时间复杂度跟数据状况的不同而不同 [7, 6, 5, 4, 3, 2, 1]：交换次数(等差数列)：1+2+3+4...，时间复杂度：O(N^2) [1, 2, 3, 4, 5, 6, 7] ：每次看一下，不用交换，时间复杂度：O(N) 推算一个算法的时间复杂度表现，都是按最差情况下的时间复杂度，及插入排序为：O(N^2) data = [3, 2, 5, 4, 2, 3, 1] print(data) for i in range(len(data)): # for j in range(i - 1, -1, -1): # 包括 i-1，不包括 -1 for j in range(i)[::-1]: # 包括0，不包括 i if data[j] > data[j + 1]: # j+1 == i data[j], data[j + 1] = data[j + 1], data[j] else: break print(data) 二分法的详解与扩展 1）在一个有序数组中，找某个数是否存在，时间复杂度，O(logN)， logN以二为底，即log2^N的缩写 比如17个数，需要对半到8个数，然后再对半到4个数，然后再对半到2个数，再对半到1个数，总共砍4次，即log2^16=4 比如8个数，需要对半到4个数，然后再对半到2个数，再对半到1个数，总共砍3次，即log2^8=3 比如4个数，需要对半到2个数，再对半到1个数，总共砍2次，即log2^4=2 data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] def bin_search(d, search_data): start, end = 0, len(d) - 1 while start > 1也可以写成 // 2, 为什么不用上面那个，因为 start + end 可能内存溢出，而 end 和 start 不会溢出，end - start 也不会 mid = start + ((end - start) >> 1) # print(start, end, mid, data[mid]) if d[mid] > search_data: end = mid - 1 elif d[mid] 2）在一个有序数组中，找>=某个数最左侧的位置 # ix = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 6] def bin_search(d, search_data): start, end = 0, len(d) - 1 idx = -1 while start > 1也可以写成 // 2, 为什么不用上面那个，因为 start + end 可能内存溢出，而 end 和 start 不会溢出，end - start 也不会 mid = start + ((end - start) >> 1) # print(start, end, mid, data[mid]) if d[mid] >= search_data: idx = mid end = mid - 1 else: start = mid + 1 return idx print(bin_search(data, 3)) 3）局部最小值问题(使用二分法查找，不一定有序才能二分) # ix = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] data = [9, 6, 5, 4, 2, 1, 3, 6, 7, 8, 9] def bin_search(d): start, end = 0, len(d) - 1 # 处理特殊情况头和尾 if d[start] > 1也可以写成 // 2, 为什么不用上面那个，因为 start + end 可能内存溢出，而 end 和 start 不会溢出，end - start 也不会 mid = start + ((end - start) >> 1) # print(start, end, mid, data[mid]) if d[mid - 1] 对数器的概念和使用 1，有一个你想要测的方法a 2，实现复杂度不好但是容易实现的方法b 3，实现一个随机样本产生器 4，把方法a和方法b跑相同的随机样本，看看得到的结果是否一样。 5，如果有一个随机样本使得比对结果不一致，打印样本进行人工干预，改对方法a或者方法b 6，当样本数量很多时比对测试依然正确，可以确定方法a已经正确。 比如使用冒泡、插入排序等与Python自带的sort对比 额外知识点异或运算 相同为0，不同为1，也可以理解为无进位相加，例：1010 ^ 0110 = 1100 异或性质 0 ^ N = N；N ^ N = 0 满足交换律和结合律：a^b = b^a；(a^b)^c = a^(b^c) 根据上面性质可以不用额外变量交换2个值，前提条件：这2个值在内存里面是2块独立的区域，否则会把值重置为0，及上面的性质：N ^ N = 0 a, b = 1, 2 a = a ^ b b = a ^ b # b = a ^ b ^ b, 结合律：b=a a = a ^ b # a= a ^ b; b = a; a = a ^ b ^ a，结合律：a=b 同一块内存交换 a = [[5]] * 3 a[0][0] = a[0][0] ^ a[1][0] a[1][0] = a[0][0] ^ a[1][0] a[0][0] = a[0][0] ^ a[1][0] # a = [[0], [0], [0]] 异或题目1 一个整型数组中，已知只有一个数出现了奇数次，其他都出现了偶数次，找出出现了奇数次的数？要求时间复杂度 O(N)，空间复杂度O(1) data = [1, 2, 1, 2, 3, 4, 4, 5, 7, 8, 9, 9, 8, 7, 6, 6] eor = 0 for i in data: eor ^= i print(eor) 一个整型数组中，已知只有两个数出现了奇数次，其他都出现了偶数次，找出出现了两次奇数次的数？要求时间复杂度 O(N)，空间复杂度O(1) data = [1, 2, 1, 2, 3, 4, 4, 5, 7, 8, 9, 9, 8, 7, 6, 6] eor = 0 for i in data: eor ^= i \"\"\" eor = a ^ b; eor != 0 eor 必然有一个位置是1 eor: 1010111100 ~eor: 0101000011 ~eor+1: 0101000100 eor & (~eor+1): 0000000100 提取出最右侧的1 \"\"\" right_one = eor & (~eor + 1) # 提取出最右侧的1 only_one = 0 for j in data: # & 2个为1，才为1，否则为0 # if (right_one & j) == 0: # 筛选出那一位为0，与一下就为0了，例：101 & 010 = 000 if (right_one & j) == right_one: # 筛选出那一位也为1的值，例：110 & 010 = 010 # print(bin(j)[2:], bin(right_one)[2:]) only_one ^= j # a 或 b print(only_one) print(only_one ^ eor) "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/02-归并、快速排序.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/02-归并、快速排序.html","title":"归并、快速排序","keywords":"","body":"datetime:2023-06-03 15:30 author:nzb 认识O(NlogN)的排序 剖析递归行为和递归行为时间复杂度的估算 用递归方法找一个数组中的最大值，系统上到底是怎么做的？ master公式：T(N) = a*T(N/b) + O(N^d) 解释 T(N)：母问题的数据量是N级别的，数据量规模为N aT(N/b)：子问题的规模都是N/b，子问题的规模都是等量的，a是子问题调用次数 O(N^d)：除了子问题的调用之外，剩下的时间复杂度 这样一类的递归都可以使用 master公式来算时间复杂度 结论 log(b,a) > d -> 复杂度为O(N^log(b,a)) log(b,a) = d -> 复杂度为O(N^d * logN) log(b,a) -> 复杂度为O(N^d) 算法的复杂度与Master定理 示例(求最大值) # idx= [0, 1, 2, 3, 4, 5] data = [3, 2, 5, 6, 7, 4] \"\"\" 正常解法，重头遍历到尾，找最大值，时间复杂度 O(N) 用递归找最大值，递归结构图 p(0, 5)：0~5找最大值 / \\ p(0, 2) p(3, 5) / \\ / \\ p(0, 1) p(2, 2) p(3, 4) p(5, 5) / \\ / \\ p(0, 0) p(1, 1) p(3, 3) p(4, 4) 多叉树后序遍历，每个节点都需要子节点汇总得到结果才能得出最大值 \"\"\" # master公式：T(N) = 2 * T(N/2) + O(1) # a = 2, b = 2, d=0 # log(2, 2) > 0，所以时间复杂度：O(N^log(2,2) = O(N) 等价于重头遍历到尾，找最大值 def max_value(d, left, right): if left == right: # O(1) return d[left] mid = left + ((right - left) >> 1) left_d = max_value(d, left, mid) # T(N/2) right_d = max_value(d, mid + 1, right) # T(N/2) return max(left_d, right_d) print(max_value(data, 0, len(data) - 1)) 示例2：假设一个数组 前面1/3调用一次递归获取最大值，中间1/3调用一次递归获取最大值，后面1/3调用一次递归获取最大值，最后获取最大值，符合master公式：T(N) = 3 * T(N/3) + O(1) 左边2/3调用一次递归获取最大值，右边2/3调用一次递归获取最大值，最后获取最大值，虽然有重叠部分，但是也符合master公式：T(N) = 2 * T(N/(3/2)) + O(1) 左边1/3调用一次递归获取最大值，右边2/3调用一次递归获取最大值，最后获取最大值，不符合master公式，因为子问题规模不等 前面1/3调用一次递归获取最大值，中间1/3调用一次递归获取最大值，后面1/3调用一次递归获取最大值，最后再打印一遍数据，然后获取最大值，符合master公式：T(N) = 3 * T(N/3) + O(N) 归并排序 整体就是一个简单递归，左边排好序、右边排好序、让其整体有序 让其整体有序的过程里用了排外序方法 利用master公式来求解时间复杂度，master公式：T(N) = 2 * T(N/2) + O(N)，log(2, 2) = 1，所以时间复杂度：O(N * logN) 归并排序的实质 时间复杂度：O(N * logN)，额外空间复杂度O(N) # idx= [0, 1, 2, 3, 4, 5] data = [3, 2, 1, 5, 6, 2] def merge_sort(arr): if len(arr) > 1 # len(arr) // 2 left = merge_sort(arr[:mid]) # T(N/2) right = merge_sort(arr[mid:]) # T(N/2) return merge(left, right) # mid = len(arr) >> 1 # len(arr) // 2 # return merge(merge_sort(arr[:mid]), merge_sort(arr[mid:])) def merge(left, right): tmp = [] # 数据排序到新数据，left和right，要么left要么right，拷贝到tmp，最后一次拷贝是整个数组长度，所以O(N) while left and right: # 遍历一遍 O(N) if left[0] 归并排序实质，归并排序是如何做到时间复杂度从 O(N^2)到 O(N*logN)? 冒泡、选择排序，浪费了大量的比较行为，比如选择排序，0~N-1范围上，比较了N次才知道了放到0位置，只搞定了一个数，0~N-2范围上，比较了N-1次才搞定一个数，以此类推，每一轮的比较都是独立的，浪费了多次比较才搞定一个数 归并排序没有浪费比较行为，左侧部分有序，右侧部分有序，接下来比较是左侧部分的指针和右侧部分的指针，依次从左到右，左侧跟右侧的比，这个比较行为信息没有浪费， 变成了一个整体有序的部分，下一回轮到这个大部分继续跟另一个大部分继续merge出来一个更长的有序部分，依次往下传递，所以时间复杂度更优 归并排序的扩展 小和问题：在一个数组中，每一个数左边比当前数小的数累加起来，叫做这个数组的小和。求一个数组的小和。 例子:[1,3,4,2,5] 1左边比1小的数，没有; 3左边比3小的数，1; 4左边比4小的数，1、3; 2左边比2小的数，1; 5左边比5小的数，1、3、4、2; 所以小和为1+1+3+1+1+3+4+2=16 暴力解法：O(N^2) 转换思路，求一个数前面的小和，比如对于1来说，右边有多少个数比1大，就产生多少个数乘以1的小和，右边有多少个数比3大，就产生多少个数乘以3的小和 1: 4 * 1 3: 2 * 3 4: 4 * 1 2: 2 * 1 def small_sum(arr): if len(arr) > 1 # len(arr) // 2 left, left_sum = small_sum(arr[:mid]) right, right_sum = small_sum(arr[mid:]) # 左组在排序的时候求小和，右组在排序的时候求小和，左组和右组合并的时候也要求小和 return merge(left, right, left_sum + right_sum) def merge(left, right, total_sum): result = [] i, j = 0, 0 while i {left[i]}\") result.append(left[i]) i += 1 else: # 跟普通归并排序不同的点，左组的数和右组的数相等的时候，需要先拷贝右组的数，并且不产生小和，否则不知道右组有多少个小和：[1,1,1,2,2,3,4,5] [1,1,2,3,4,4,5,5] result.append(right[j]) j += 1 # 归并排序，排序不可少，不然不清楚右边有多少个数比左边大 result.extend(left[i:]) result.extend(right[j:]) return result, total_sum # 示例 data = [1, 3, 4, 2, 5] sorted_arr, small_sum = small_sum(data) print(\"排序后的数组:\", sorted_arr) print(\"小和:\", small_sum) # 排序后的数组: [1, 2, 3, 4, 5] # 小和: 16 逆序对问题：在一个数组中，左边的数如果比右边的数大，则这两个数构成一个逆序对，请打印所有逆序对(请找到逆序对)。 例子:[3,2,4,5,0] 3,2 3,0 2,0 4,0 5,0 def reverse_pair(arr): if len(arr) > 1 # len(arr) // 2 left, left_cnt = reverse_pair(arr[:mid]) right, right_cnt = reverse_pair(arr[mid:]) # 左组在排序的时候求逆序对数，右组在排序的时候求逆序对数，左组和右组合并的时候也要求逆序对数 return merge(left, right, left_cnt + right_cnt) def merge(left, right, total_cnt): result = [] i, j = 0, 0 while i {right[j]}\") result.append(right[j]) j += 1 # 归并排序，排序不可少，不然不清楚左边有多少个数比右边大 result.extend(left[i:]) result.extend(right[j:]) return result, total_cnt # 示例 data = [3, 2, 4, 5, 0] print(f\"排序前的数组:{data}\") sorted_arr, small_sum = reverse_pair(data) print(\"排序后的数组:\", sorted_arr) print(\"逆序对数:\", small_sum) # 排序后的数组: [0, 2, 3, 4, 5] # 小和: 5 快速排序 荷兰国旗问题 问题一 给定一个数组arr，和一个数num，请把小于等于num的数放在数组的左边，大于num的数放在数组的右边。要求额外空间复杂度O(1)，时间复杂度O(N) \"\"\" | num, 小于等于区不动, i++ 流程： arr[i] = 3 num，小于等于区不动, i++ | num，小于等于区不动, i++ | num | 问题二(荷兰国旗问题) 给定一个数组arr，和一个数num，请把小于num的数放在数组的左边，等于num的数放在数组的中间，大于num的数放在数组的右边。要求额外空间复杂度O(1)，时间复杂度O(N) \"\"\" | | 区 | i位置，指向3 | 1、[i] num, 把当前数[i]和大于区的前一个数做交换，大于区往左扩，i原地不变 流程： arr[i] = 3 区 | i位置，指向5 | arr[i] = 5 = num | | 区 | i位置，指向6 | arr[i] = 6 > num，把当前数[i]和大于区的前一个数做交换，大于区往左扩，i原地不变，为什么不变，因为它是右边过来的没作比较过 | | 区 | i位置，指向0 | arr[i] = 0 区 | i位置，指向3 | arr[i] = 3 区 | i位置，指向4 | arr[i] = 4 区 | i位置，指向5 | arr[i] = 5 = num | | 区 | i位置，指向2 | arr[i] = 2 区 | i位置，指向6 arr[i] = 6 > num | | 区 | i位置，指向9 arr[i] = 9 > num, 自己跟自己换，大于区左扩，大于区域和i相等时停止 | | 区 | i位置，指向9 \"\"\" 快排1.0->不改进的快速排序(每次搞定一个数) 1）把数组范围中的最后一个数作为划分值，然后把数组通过分成三个部分：左侧划分值 2）对左侧范围和右侧范围，递归执行 分析 1）划分值越靠近两侧，复杂度越高；划分值越靠近中间，复杂度越低 2）可以轻而易举的举出最差的例子，所以不改进的快速排序时间复杂度为O(N^2) 为什么是 O(N^2)？ 例子：[1, 2, 3, 4, 5, 6, 7, 8, 9] 拿9做划分值，只搞定了9，只有左区域，没有右区域，partition=9 拿8做划分值，只搞定了8，只有左区域，没有右区域，partition=8 拿7做划分值，只搞定了7，只有左区域，没有右区域，partition=7 ...等差数列，所以最差情况，时间复杂度是O(N^2) 最好时间复杂度O(NlogN)，划分值刚好打在中间，[...] p [...] master公式：T(N) = 2T(N/2) + O(N)，时间复杂度：O(N*logN) 划分值打在偏左(右)或就在两侧，所以最差情况，时间复杂度是O(N^2) \"\"\" [4, 3, 5, 6, 5, 0, 1, 7, 8, 5] 以 5 划分值(搞定一个5) [4, 3, 5, 5, 0, 1, 5, 7, 8, 6] 左侧再以 1 为划分值递归(搞定一个1) [0, 1, 3, 5, 5, 4 5, 7, 8, 6] 右侧再以 6 为划分值递归(搞定一个6) [0, 1, 3, 5, 5, 4 5, 6, 7, 8] 再以 4 和 8 为划分值递归(搞定一个4和8) [0, 1, 3, 4, 5, 5 5, 6, 7, 8] 再以 5 和 8 为划分值递归(搞定一个5和8) \"\"\" 快排2.0->不改进的快速排序(每次搞定一批数) 1）把数组范围中的最后一个数作为划分值，然后把数组通过荷兰国旗问题分成三个部分：左侧划分值 2）对左侧范围和右侧范围，递归执行 分析同1.0版本 \"\"\" [4, 3, 5, 6, 5, 0, 1, 7, 8, 5] 以 5 划分值 [4, 3, 0, 1, 5, 5, 5, 7, 8, 6] 左侧再以 1 为划分值递归 右侧再以 6 为划分值递归 [0, 1, 4, 3, 5, 5, 5, 6, 7, 8] 左侧再以 0 和 6 为划分值递归 右侧再以 3 和 8 为划分值递归 [0, 1, 3, 4, 5, 5, 5, 6, 7, 8] \"\"\" 快排3.0->随机快速排序（改进的快速排序） 1）在数组范围中，等概率随机选一个数作为划分值，然后把数组通过荷兰国旗问题分成三个部分： 左侧划分值 2）对左侧范围和右侧范围，递归执行 3）时间复杂度为O(N*logN)，空间复杂度，最坏O(N)(划分值在两次或一侧数据量特别少)，最好O(logN)(刚好随机到中间位置，二叉树结构的递归)，概率累加后为：O(logN) 4）分析 随机可能打出最差情况，O(N^2) 打在1/5处，T(N) = T(N/5) + T(4N/5) + O(N) 打在1/3处，T(N) = T(N/3) + T(2N/3) + O(N) 打在1/2处，T(N) = 2T(N/2) + O(N) 打在4/5处，T(N) = T(4N/5) + T(N/5) + O(N) ... 每一种都是等概率事件，每一种权重只占 1/N，把所有公式概率累加，再求数学上的长期期望，得出时间复杂度：O(N*logN) # 使用 https://pythontutor.com/ 查看流程，便于理解 import random def quick_sort(arr, low, high): if low pivot: # 把当前数[i]和大于区的前一个数做交换，大于区往左扩，i原地不变，为什么不变，因为它是右边过来的没作比较过 arr[i], arr[gt] = arr[gt], arr[i] gt -= 1 else: i += 1 return lt, gt # 示例 data = [4, 3, 5, 6, 5, 0, 1, 7, 8, 5] quick_sort(data, 0, len(data) - 1) print(data) "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/03-堆、桶排序以及排序总结.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/03-堆、桶排序以及排序总结.html","title":"堆和桶排序以及排序总结","keywords":"","body":"datetime:2023-07-04 19:30 author:nzb 堆、桶排序及排序总结 堆 1、堆结构就是用数组实现的完全二叉树结构 2、完全二叉树中如果每棵子树的最大值都在顶部就是大根堆 大根堆：每一颗子树的最大值就是头结点的值 3、完全二叉树中如果每棵子树的最小值都在顶部就是小根堆 小根堆：每一颗子树的最小值就是头结点的值 4、堆结构的heapInsert与heapify操作 5、堆结构的增大和减少 6、优先级队列结构，就是堆结构 \"\"\" idx = [0,1,2,3,4,5,6] arr = [3,5,2,7,1,9,6] 0 / \\ 1 2 / \\ / \\ 3 4 5 6 size = 7 i位置 左孩子：2 * i + 1 右孩子：2 * i + 2 父：(i - 1) // 2 \"\"\" heapinsert：调整时间复杂度，往上走高度，O(logN) def heap_insert(arr: list, index: int): \"\"\"某个数现在在index位置，继续往上移\"\"\" parent_idx = max((index - 1) >> 1, 0) # \">> 1\" == \"// 2\" while arr[index] > arr[parent_idx]: # 到头结点，arr[0] > arr[0] 肯定不满足 arr[index], arr[parent_idx] = arr[parent_idx], arr[index] index = parent_idx parent_idx = max((index - 1) >> 1, 0) heapify：调整时间复杂度，往下走高度，O(logN) def heapify(arr: list, index: int, heap_size: int): \"\"\"某个数在index位置，能否往下移动\"\"\" left = 2 * index + 1 # 左孩子下标 while left arr[left] else left # 父与孩子之间，哪个大，如果较大的子节点的值不大于当前节点的值，则堆调整完成 if arr[largest] 堆排序 堆排序远远没有堆结构重要、堆排序远远没有堆结构重要、堆排序远远没有堆结构重要 1、先让整个数组都变成大根堆结构，建立堆的过程: 1、从上到下的方法，时间复杂度为O(N*logN) 2、从下到上的方法，时间复杂度为O(N) 2、把堆的最大值和堆末尾的值交换，然后减少堆的大小之后，再去调整堆，一直周而复始，时间复杂度为O(N*logN) 3、堆的大小减小成0之后，排序完成 # 大根堆调整 def heap_insert(arr: list, index: int): \"\"\"某个数现在在index位置，继续往上移\"\"\" parent_idx = max((index - 1) >> 1, 0) # \">> 1\" == \"// 2\" while arr[index] > arr[parent_idx]: # 到头结点，arr[0] > arr[0] 肯定不满足 arr[index], arr[parent_idx] = arr[parent_idx], arr[index] index, parent_idx = parent_idx, max((index - 1) >> 1, 0) # 大根堆调整 def heapify(arr: list, index: int, heap_size: int): \"\"\"某个数在index位置，能否往下移动\"\"\" left = 2 * index + 1 # 左孩子下标 while left arr[left] else left # 父与孩子之间，哪个大，如果较大的子节点的值不大于当前节点的值，则堆调整完成 if arr[largest] 0: # 时间复杂度 0(N) heap_size -= 1 arr[0], arr[heap_size] = arr[heap_size], arr[0] # 空间复杂度： O(1) # 重新生成大根堆 heapify(arr, 0, heap_size) # 时间复杂度： O(logN) data = [4, 6, 5, 2, 3, 1, 8, 7, 9, 10, 15, 13] heap_sort(data) print(data) # 小根堆调整 def heap_insert(arr: list, index: int): parent_idx = max(0, (index - 1) >> 1) while arr[index] > 1) def heapify(arr: list, index: int, heap_size: int): left_idx = 2 * index + 1 while left_idx = arr[index]: break arr[index], arr[smallest_idx] = arr[smallest_idx], arr[index] index, left_idx = smallest_idx, 2 * index + 1 堆排序扩展题目 已知一个几乎有序的数组，几乎有序是指，如果把数组排好顺序的话，每个元素移动的距离可以不超过k，并且k相对于数组来说比较小。请选择一个合适的排序算法针对这个数据进行排序。 解决思路：利用小根堆，把数组前k+1，个数建立成小根堆，然后加一个，弹出最小的，因为每个元素移动的距离不超过k import heapq def heapq_sort_distance_less_k(arr: list, k: int): # pq = [] # # 建立小根堆，heapq 默认就是小根堆 # min_val = min(len(arr), k + 1) # 怕给的 K 过大 # # 为什么建立大小为 k 的小根堆，因为每个元素移动的距离不超过k，所以第k+1，肯定不会是最小值，如果是最小值，移到到根部就超过了k # for i in range(min_val): # 移动不超过 k # heapq.heappush(pq, arr[i]) min_val = min(len(arr), k + 1) # 怕给的 K 过大 pq = arr[:min_val] heapq.heapify(pq) x = 0 for y in range(min_val, len(arr)): heapq.heappush(pq, arr[y]) # 添加一个 arr[x] = heapq.heappop(pq) # 弹出一个 x += 1 # 没数了，把最后的堆，pop完 while pq: arr[x] = heapq.heappop(pq) x += 1 data = [4, 6, 5, 2, 3, 1, 8, 7, 9, 10, 15, 13] heapq_sort_distance_less_k(data, 5) print(data) 一个数据流中，随时可以取得中位数 解决思路：大跟堆和小根堆配合 第一个数入大根堆 后续数字是否小于等于( 是：入大根丢 否：入小根堆 看大根堆和小根堆的大小，如果大小差值到达2，如果是，大小较大的堆弹出，进入大小较小的堆 import heapq def middle_num(data: list): if not data: return hq_min = [] hq_max = [] for num in data: if not hq_max or num hq_min_len: heapq.heappush(hq_min, -heapq.heappop(hq_max)) # 取出来后记得取反 else: heapq.heappush(hq_max, -heapq.heappop(hq_min)) if (len(hq_max) + len(hq_min)) % 2 == 0: return (-hq_max[0] + hq_min[0]) / 2 else: return -heapq.heappop(hq_max) if len(hq_max) > len(hq_min) else heapq.heappop(hq_min) print(middle_num([])) print(middle_num([1])) print(middle_num([1, 2, 3, 4, 5, 6, 7])) print(middle_num([1, 2, 3, 4, 5, 6, 7, 8])) # None # 1 # 4 # 4.5 注意 使用系统给的堆功能，相当于黑盒你只能给它一个数，它给你弹出一个数，内部它会维护堆结构你不能够，它已经维持好的堆结构，你想给它内部的某个位置变值，它的调整代价很高，只能每个值去扫一下看看需要heap_insert还是heapify，手写堆支持，如果你自己有这种需求，需要你自己手写 比较器的使用 1）比较器的实质就是重载比较运算符 2）比较器可以很好的应用在特殊标准的排序上 3）比较器可以很好的应用在根据特殊标准排序的结构上 # -*-: encoding: utf8 -*- from filecmp import cmp class Demo(): def __init__(self, age): self.age = age def __gt__(self, other): \"\"\">\"\"\" return self.age > other.age def __ge__(self, other): \"\"\">=\"\"\" return self.age >= other.age def __lt__(self, other): \"\"\" ins2) print(ins1 >= ins2) print(ins1 桶排序 之前讲的所有排序都是基于比较的排序 不基于比较的排序一定要根据数据状况来定制的 桶排序思想下的排序 1）计数排序：每个词频统计下，计数一下 一个数组，里面都是员工的整数年龄，员工年龄16~200，16岁以下 2）基数排序 排序总结 同样的值的个体之间，如果不因为排序而改变相对次序，就是这个排序是有稳定性的，否则没有 不具备稳定性的排序： 选择排序：[3,3,3,1,3,3,3]，第一个位置的3跟1交换就破坏了稳定性 快速排序：partition的时候会交换位置就做不到了 堆排序：[5,4,4]，插入一个6，会跟第二个4做交换，就不具备稳定性 具备稳定性的排序： 冒泡排序：[6,5,4,5,3,4,6]，如何做到，当2个数相等的时候，不做交换，比如两两比较到最后[5,4,5,3,4,6,6], 6和6不交换就做到了稳定性 插入排序：[3,2,2]，往前看的时候，如果相等的时候，也不做交换，就可以做到稳定性 归并排序：左边和右边相等的时候，先拷贝左边的，但是小和问题，当相等的时候是先拷贝右边的，这就丧失了稳定性 一切桶排序思想下的排序 目前没有找到时间复杂度为O(NlogN)，额外空间复杂度为O(1)，又稳定的排序 时间复杂度 空间复杂度 稳定性 选择 O(N^2) O(1) × 冒泡 O(N^2) O(1) √ 插入 O(N^2) O(1) √ 归并 O(NlogN) O(N) √ 随机快排 O(NlogN) O(logN) x 堆排 O(NlogN) O(1) x 一般选择随机快排，虽然归并、快排和堆排都是O(NlogN)，但是经过实验的检验，它的常数项是最低的 如果有空间的限制，用堆排 需要稳定性，用归并 常见的坑 1、归并排序的额外空间复杂度可以变成O(1)，但是非常难，不需要掌握，有兴趣可以搜归并排序内部缓存法，那为什么不用堆排序？ 2、“原地归并排序”的帖子都是垃圾，会让归并排序的时间复杂度变成O(N^2)，那为什么不用插入？ 3、快速排序可以做到稳定性问题，但是非常难，不需要掌握，可以搜“01 stable sort”，空间复杂度变为O(N)，那为什么不用归并？ 4、所有的改进都不重要，因为目前没有找到时间复杂度为O(NlogN)，额外空间复杂度为O(1)，又稳定的排序 5、有一道题目，是奇数放在数组左边，偶数放在数组右边，还要求原始的相对次序不变，时间复杂度O(N)，空间复杂度O(1)，碰到这个问题，可以怼面试官。 工程上对排序的改进 充分利用O(N*logN)和O(N^2)排序各自的优势 稳定性的考虑 改进版本排序，比如一个大样本的排序，大样本的时候用随机快排，partition到小样本的时候用插入排序，而不再继续partition "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/04-链表.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/04-链表.html","title":"链表","keywords":"","body":"datetime:2023-07-04 19:30 author:nzb 链表 哈希表的简单介绍 1）哈希表在使用层面上可以理解为一种集合结构 2）如果只有key，没有伴随数据value，可以使用HashSet结构（C++中叫unOrderedSet） 3）如果既有key，又有伴随数据value，可以使用HashMap结构（C++中叫UnOrderedMap） 4）有无伴随数据，是HashMap和HashSet唯一的区别，底层的实际结构是一回事 5）使用哈希表增（put）、删（remove）、改（put）和查（get）的操作，可以认为时间复杂度为O(1)，但是常数时间比较大 6）放入哈希表的东西，如果是基础类型，内部按值传递，内存占用就是这个东西的大小 7）放入哈希表的东西，如果不是基础类型，内部按引用传递，内存占用是这个东西内存地址的大小 有序表的简单介绍 1）有序表在使用层面上可以理解为一种集合结构 2）如果只有key，没有伴随数据value，可以使用TreeSet结构（C++中叫OrderedSet） 3）如果既有key，又有伴随数据value，可以使用TreeMap结构（C++中叫orderedMap） 4）有无伴随数据，是TreeSet和TreeMap唯一的区别，底层的实际结构是一回事 5）有序表和哈希表的区别是，有序表把key按照顺序组织起来，而哈希表完全不组织 5）红黑树、AVL树、size-balance-tree和跳表等都属于有序表结构，只是底层具体实现不同 6）放入哈希表的东西，如果是基础类型，内部按值传递，内存占用就是这个东西的大小 7）放入哈希表的东西，如果不是基础类型，必须提供比较器，内部按引用传递，内存占用是这个东西内存地址的大小 8）不管是什么底层具体实现，只要是有序表，都有以下固定的基本功能和固定的时间复杂度 单双链表节点结构 // 定义节点结构c++ template struct Node { T data; // 数据 Node* next; // 指向下一个节点的指针 // 构造函数 Node(T val) : data(val), next(nullptr) {} }; // python class Node: def __init__(self, data): self.data = data self.next = None 由以上结构的节点依次连接起来所形成的链叫单链表结构。 // 定义节点结构c++ template struct Node { T data; // 数据 Node* next; // 指向下一个节点的指针 Node* prev; // 指向前一个节点的指针 // 构造函数 Node(T val) : data(val), next(nullptr), prev(nullptr) {} }; // python class Node: def __init__(self, data): self.data = data self.next = None self.prev = None 由以上结构的节点依次连接起来所形成的链叫双链表结构。 面试时链表解题的方法论 1）对于笔试，不用太在乎空间复杂度，一切为了时间复杂度 2）对于面试，时间复杂度依然放在第一位，但是一定要找到空间最省的方法 重要技巧： 1）额外数据结构记录（哈希表等） 2）快慢指针 反转单向和双向链表 【题目】 分别实现反转单向链表和反转双向链表的函数 【要求】 如果链表长度为N，时间复杂度要求为O(N)，额外空间复杂度要求为O(1) 单链表 class Node: def __init__(self, data): self.data = data self.next = None def reverse_linked_list(head: Node): prev = None cur = head while cur is not None: next_node = cur.next cur.next = prev prev = cur cur = next_node return prev # 主函数 if __name__ == \"__main__\": head = Node(1) head.next = Node(2) head.next.next = Node(3) head.next.next.next = Node(4) head = reverse_linked_list(head) 双链表 class Node: def __init__(self, data): self.data = data self.next = None self.prev = None def reverse_doubly_linked_list(head: Node): tmp = None cur = head while cur is not None: next_node = cur.next cur.next = tmp cur.prev = next_node tmp = cur cur = next_node return tmp # 主函数 if __name__ == \"__main__\": head = Node(1) head.next = Node(2) head.next.prev = head head.next.next = Node(3) head.next.next.prev = head.next head.next.next.next = Node(4) head.next.next.next.prev = head.next.next head = reverse_doubly_linked_list(head) 打印两个有序链表的公共部分 【题目】 给定两个有序链表的头指针head1和head2，打印两个链表的公共部分。 【要求】 如果两个链表的长度之和为N，时间复杂度要求为O(N)，额外空间复杂度要求为O(1) class Node: def __init__(self, data): self.data = data self.next = None def print_common_part(head1: Node, head2: Node): while head1 is not None and head2 is not None: # 谁小谁移动 if head1.data head2.data: head2 = head2.next else: # 相等打印，共同移动 print(f\"data->{head1.data}\") head1 = head1.next head2 = head2.next # 主函数 if __name__ == \"__main__\": # 示例 # 创建两个有序链表 head1 = Node(1) head1.next = Node(2) head1.next.next = Node(3) head1.next.next.next = Node(6) head2 = Node(2) head2.next = Node(4) head2.next.next = Node(6) head2.next.next.next = Node(8) print(\"Common Part: \", end=\"\") print_common_part(head1, head2) 判断一个链表是否为回文结构 【题目】给定一个单链表的头节点head，请判断该链表是否为回文结构。 【例子】1->2->1，返回true； 1->2->2->1，返回true；15->6->15，返回true；1->2->3，返回false。 【例子】如果链表长度为N，时间复杂度达到O(N)，额外空间复杂度达到O(1)。 笔试：利用栈，遍历一遍依次放到栈里面，如何重新遍历链表，遍历一个，栈弹出一个，对比一样不一样，知道遍历结束 面试：快慢指针，一定到自己coding 快指针走到终点的时候，慢指针来到中点位置，头和尾用一个应用记住 中点往下遍历的时候，逆序，慢指针指向空 头和尾同时往中间走，每一步比对，任何一个走到空停 返回结果之前，把后半部分逆序回去，再返回是否回文 快一次走两步，慢针一次走一步，这件事儿你一定要自己去coding，为啥呢？ 因为根据实际题目出现的需求，有可能快慢指针是需要做定制的，比如说我有一种需求，是12321，当奇数的时候，我希望快指针走完的时候，慢指针正好压中唯一的终点。123321，我如果是偶数个，我希望快指针在走完的时候，慢指针压中的是终点中的前一个。那么这样一种情况我就需要根据长度为奇数和长度为偶数去分析它写出正确的算法没错吧？ 如果另外一道题目，它跟你说的是，我希望在奇数个的时候，我的快指针走完的时候慢指针来到唯一终点的位置，但是如果我是偶数个，我希望在我快指针走完的时候，慢指针来到的是终点的下一个终点的位置， 那你会知道，如果这道题目它的需求是这个的话，你的逻辑会有小的不同， 这只是边界条件而已，它跟算法无关，那么你必须通过自己coding的方式把它写熟了， 还有一种例子是这样的，比如说我做这样一种定制就是 我在奇数个的时候，我总是希望我的快指针走完的时候，我慢针来到终点的前一个点的位置。 而我偶数个的时候呢，我希望快指针走完的时候，慢指针能来到我前一个终点的 再前一个位置， 他只是慢指针提前走个一两步或者快指针提前走个一两步就可以完成这样的小的差别的定制 但是你必须把它写熟，因为如果你在面市场，或者在笔试的过程中卡住， 你可能要卡很久，所以你在线下先把它给写熟了， 尤其是链表长度为一个的时候，链表长度为两个的时候，链表长度为三个的时候很特殊的小数据情况下， 你也得对。 class Node: def __init__(self, data): self.data = data self.next = None # 笔试 # def is_palindrome(head: Node): # stack = [] # cur = head # while cur is not None: # stack.append(cur.data) # cur = cur.next # while head: # if head.data != stack.pop(): # return False # head = head.next # return True # 面试 def is_palindrome(head: Node): def reverse_list(head2: Node): prev = None cur = head2 while cur: next = cur.next cur.next = prev prev = cur cur = next return prev if not head or not head.next: return True slow, fast = head, head # 使用快慢指针找到链表中点 while fast.next and fast.next.next: slow = slow.next # mid fast = fast.next.next # end # 反转后半部分链表 second_half = reverse_list(slow.next) # 比较前半部分和反转后的后半部分是否相等 while second_half: if second_half.data != head.data: return False second_half = second_half.next head = head.next return True # 主函数 if __name__ == \"__main__\": head = Node(1) head.next = Node(2) head.next.next = Node(3) head.next.next.next = Node(2) head.next.next.next.next = Node(1) print(\"Is Palindrome:\", is_palindrome(head)) 将单向链表按某值划分成左边小、中间相等、右边大的形式 【题目】给定一个单链表的头节点head，节点的值类型是整型，再给定一个整数pivot。实现一个调整链表的函数，将链表调整为左部分都是值小于pivot的节点，中间部分都是值等于pivot的节点，右部分都是值大于pivot的节点。 【进阶】在实现原问题功能的基础上增加如下的要求 【要求】调整后所有小于pivot的节点之间的相对顺序和调整前一样 【要求】调整后所有等于pivot的节点之间的相对顺序和调整前一样 【要求】调整后所有大于pivot的节点之间的相对顺序和调整前一样 【要求】时间复杂度请达到O(N)，额外空间复杂度请达到O(1)。 笔试方法：申请一个列表，遍历链表，把每个节点放进去，归并排序，然后遍历一个一个链接起来 面试方法： class Node: def __init__(self, data): self.data = data self.next = None def adjust_linked_list(head: Node, pivot: int) -> Node: lt_head = lt_tail = None eq_head = eq_tail = None gt_head = gt_tail = None cur = head # 分别将节点连接到对应的链表上 while cur is not None: next_node = cur.next # 必须设置下个节点为None，不然无限循环下去 cur.next = None if cur.data 4 -> 3 -> 2 -> 5 -> 2 head = Node(1) head.next = Node(4) head.next.next = Node(3) head.next.next.next = Node(2) head.next.next.next.next = Node(5) head.next.next.next.next.next = Node(2) print(\"Original linked list:\") display_linked_list(head) pivot_value = 3 new_head = adjust_linked_list(head, pivot_value) print(f\"After adjusting with pivot {pivot_value}:\") display_linked_list(new_head) 复制含有随机指针节点的链表 【题目】一种特殊的单链表节点类描述如下 rand指针是单链表节点结构中新增的指针，rand可能指向链表中的任意一个节点，也可能指向null。 给定一个由Node节点类型组成的无环单链表的头节点head，请实现一个函数完成这个链表的复制，并返回复制的新链表的头节点。 【要求】时间复杂度O(N)，额外空间复杂度O(1) class Node: def __init__(self, data, next=None, rand=None): self.data = data self.next = next self.rand = rand # 笔试（使用哈希表（字典）） def copy_linked_list_with_random_pointer_dict(head: Node): tmp = {} cur = head while cur is not None: tmp[cur] = Node(cur.data) cur = cur.next cur = head while cur is not None: tmp.get(cur).next = tmp.get(cur.next) tmp.get(cur).rand = tmp.get(cur.rand) cur = cur.next return tmp.get(head) # 面试 def copy_linked_list_with_random_pointer(head: Node): if head is None: return None # 复制节点 cur = head while cur: next_node = cur.next cur.next = Node(cur.data) # 复制的节点的下一个节点就是，原始节点的下一个节点 cur.next.next = next_node cur = next_node # 处理random节点 cur = head while cur: if cur.rand: cur.next.rand = cur.rand.next cur = cur.next.next # 分割(画个简易图容易理解) new_head = head.next cur = head while cur: next_node = cur.next # 可能是原始节点也可能是复制节点 cur.next = next_node.next if next_node else None cur = next_node return new_head def display_linked_list(head): current = head while current: rand_data = current.rand.data if current.rand else None print(f\"Data: {current.data}, Rand: {rand_data}\") current = current.next # 示例 # 创建链表：1 -> 2 -> 3 -> 4 -> 5 head = Node(1) head.next = Node(2) head.next.next = Node(3) head.next.next.next = Node(4) head.next.next.next.next = Node(5) # 设置随机指针 head.rand = head.next.next # 1 -> 3 head.next.rand = head.next.next.next.next # 2 -> 5 head.next.next.rand = head # 3 -> 1 head.next.next.next.rand = head.next.next # 4 -> 3 head.next.next.next.next.rand = head.next # 5 -> 2 print(\"Original linked list:\") display_linked_list(head) # new_head = copy_linked_list_with_random_pointer_dict(head) new_head = copy_linked_list_with_random_pointer(head) print(\"Copied linked list:\") display_linked_list(new_head) 两个单链表相交的一系列问题 【题目】给定两个可能有环也可能无环的单链表，头节点head1和head2。请实现一个函数，如果两个链表相交，请返回相交的 第一个节点。如果不相交，返回null 【要求】如果两个链表长度之和为N，时间复杂度请达到O(N)，额外空间复杂度请达到O(1)。 无环的链表一定会走到空，有环的一定不会，因为单链表只有一个next 笔试：使用集合，遍历链表，查看是否在集合里，不存在放入集合（注意是节点，不是值），存在当前节点就是入环节点 面试：快慢指针 第一步：判断链表有环无环，快指针和慢指针相遇的时候，快指针回到开头，然后再同时走，相等的时候就是入环节点 分类 链表1和链表2都无环 不相交：平行 相交，两条链表最后节点一定是公共节点 解决方法： 遍历链表1到最后一个节点记住end1和length1 遍历链表2到最后一个节点记住end2和length2 如果end1和end2内存地址相同吗 相同：相交，长链表先走长度差值abs(length1 - length2)，然后一起走，这样两条链表一定会在相交节点相遇 不同：平行 其中一个链表有环，另一个无环，不可能相交，因为单链表只有一个next 两个都有环 各自成环，不想交，类似66 1个入环节点，2个链表的入环节点是同一个 2个入环节点 解决方法(区分)： 第一步：如果loop1 == loop2就是第2种情况，然后如何求这种情况的相交节点，走无环链表的思路，跟有没有环没关系（相当于在入环节点切割，不看环的部分） 第二步：让loop1继续往下走，在转回自己之前，能遇到loop2就是情况3，返回loop1和loop2都行，否则就是情况1，不相交 2个都有环，1个入环节点 head1 \\ head2 \\ / \\/ | | |————| | | |————| 2个都有环，2个入环节点 head1 head2 \\ / \\ / |————| | | |————| class Node: def __init__(self, data, next=None, rand=None): self.data = data self.next = next self.rand = rand def get_loop_node(head: Node): \"\"\"返回入环节点\"\"\" if head is None or head.next is None or head.next.next is None: return None slow, fast = head.next, head.next.next # 快慢指针都走了一步 while slow != fast: # 相遇跳出 if not fast.next or not fast.next.next: # 快指针走完了，无环 return None slow, fast = slow.next, fast.next.next fast = head while fast != slow: slow, fast = slow.next, fast.next return slow def no_loop_linked_list(head1: Node, head2: Node): \"\"\"2个链表都无环\"\"\" cur1 = head1 cur2 = head2 n = 0 while cur1: n += 1 cur1 = cur1.next while cur2: n -= 1 cur2 = cur2.next if cur1 != cur2: # 最后一个节点不相等，一定不想交 return None cur1, cur2 = (head1, head2) if n > 0 else (head2, head1) # cur1表示长链表， cur2表示短链表 n = abs(n) # 长链表先走差值 while n > 0: n -= 1 cur1 = cur1.next while cur1 != cur2: cur1, cur2 = cur1.next, cur2.next return cur1 def both_loop_linked_list(head1: Node, loop1: Node, head2: Node, loop2: Node): \"\"\" 2个链表都有环 3种情况 :param head1: :param loop1: :param head2: :param loop2: :return: \"\"\" # 第二种情况 if loop1 == loop2: cur1, cur2 = head1, head2 n = 0 while cur1 != loop1: n += 1 cur1 = cur1.next while cur2 != loop2: n -= 1 cur2 = cur2.next cur1, cur2 = (head1, head2) if n > 0 else (head2, head1) n = abs(n) while n > 0: n -= 1 cur1 = cur1.next while cur1 != cur2: cur1, cur2 = cur2.next, cur2.next return cur1 else: cur1 = loop1.next while cur1 != loop1: # 第三种情况 if cur1 == loop2: return loop1 # or loop2 cur1 = cur1.next # 第1中情况，66 return None def get_intersect_node(head1: Node, head2: Node): if not head1 or not head2: return None loop1 = get_loop_node(head1) loop2 = get_loop_node(head2) if not loop1 and not loop2: # 2个都无环 return no_loop_linked_list(head1, head2) elif loop1 and loop2: # 2个都有环 return both_loop_linked_list(head1, loop1, head2, loop2) else: # 其中一个有环，一定不相交 return None # 创建链表: 1 -> 2 -> 3 -> 4 head1 = Node(1) head1.next = Node(2) head1.next.next = Node(3) head1.next.next.next = Node(4) # 创建链表: 1 -> 2 -> 3 -> 4 head2 = Node(1) head2.next = Node(2) head2.next.next = Node(3) head2.next.next.next = Node(4) print(f\"2个无环平行{get_intersect_node(head1, head2)}\") # 创建链表: 1 -> 2 -> 3 -> 4 -> 5 head1 = Node(1) head1.next = Node(2) head1.next.next = Node(3) head1.next.next.next = Node(4) head1.next.next.next.next = Node(5) # 创建链表: 2 -> 1 -> 3 -> 4 head2 = Node(2) head2.next = Node(1) head2.next.next = head1.next.next head2.next.next.next = head1.next.next.next print(f\"2个无环，相交的节点值：{get_intersect_node(head1, head2).data}\") # 创建链表: 1 -> 2 -> 3 -> 4 -> 3 (有环) head1 = Node(1) head1.next = Node(2) head1.next.next = Node(3) head1.next.next.next = Node(4) head1.next.next.next.next = head1.next.next # 创建链表: 2 -> 1 -> 3 -> 4 head2 = Node(2) head2.next = Node(1) head2.next.next = Node(3) head2.next.next.next = Node(4) print(f\"1个有环，1个无环，一定不相交：{get_intersect_node(head1, head2)}\") # 创建链表: 1 -> 2 -> 3 -> 4 -> 3 (有环) head1 = Node(1) head1.next = Node(2) head1.next.next = Node(3) head1.next.next.next = Node(4) head1.next.next.next.next = head1.next.next # 创建链表: 2 -> 1 -> 3 -> 4 -> 1 (有环) head2 = Node(2) head2.next = Node(1) head2.next.next = Node(3) head2.next.next.next = Node(4) head2.next.next.next = head2.next print(f\"2个都有环，第一种情况66：{get_intersect_node(head1, head2)}\") # 创建链表: 1 -> 2 -> 3 -> 4 -> 3 (有环) head1 = Node(1) head1.next = Node(2) head1.next.next = Node(3) head1.next.next.next = Node(4) head1.next.next.next.next = head1.next.next # 创建链表: 5 -> 2 -> 3 -> 4 -> 3 (有环) head2 = Node(5) head2.next = head1.next print(f\"2个都有环，第二种情况1个入环节点，相交值：{get_intersect_node(head1, head2).data}\") # 创建链表: 1 -> 2 -> 3 -> 4 -> 2 (有环) head1 = Node(1) head1.next = Node(2) head1.next.next = Node(3) head1.next.next.next = Node(4) head1.next.next.next.next = head1.next # 创建链表: 5 -> 4 -> 2 -> 3 -> 4 (有环) head2 = Node(5) head2.next = head1.next.next.next print(f\"2个都有环，第三种情况2个入环节点，相交值：{get_intersect_node(head1, head2).data}\") "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/05-二叉树.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/05-二叉树.html","title":"二叉树","keywords":"","body":"datetime:2024-01-16 14:48 author:nzb 二叉树 二叉树节点结构 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right class TreeNode { public: int val; TreeNode* left; TreeNode* right; TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} }; 用递归和非递归两种方式实现二叉树的先序、中序、后序遍历 递归 最容易的方法 递归序 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def fn(head: TreeNode): # 1 第一次来到这个节点的时候 if not head: return # 1 第一次来到这个节点的时候 # 去递归该节点的左树 fn(head.left) # 2 第二次来到这个节点的时候 # 2 第二次来到这个节点的时候 # 去递归该节点的右树 fn(head.right) # 3 第三次来到这个节点的时候 # 3 第三次来到这个节点的时候 # 到这才能确定这个节点结束了 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 # 按上面的流程，上树的递归序为 # 1 2 4 4 4 # 2 5 5 5 2 # 1 3 6 6 6 # 3 7 7 7 3 1 # 递归方法每个节点都能回到3次，只是可能某一次啥也没做 先序遍历(左头右)->递归序第一次打印 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def tree_traverse(root: TreeNode): if root: print(root.val, end=\" \") tree_traverse(root.left) tree_traverse(root.right) # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) # 打印可视化二叉树 tree_traverse(root) 中序遍历(头左右)->递归序第二次打印 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def tree_traverse(root: TreeNode): if root: tree_traverse(root.left) print(root.val, end=\" \") tree_traverse(root.right) # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) # 打印可视化二叉树 tree_traverse(root) 后续遍历(左右头)->递归序第三次打印 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def tree_traverse(root: TreeNode): if root: tree_traverse(root.left) tree_traverse(root.right) print(root.val, end=\" \") # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) # 打印可视化二叉树 tree_traverse(root) 非递归 递归是系统帮你压栈，非递归就是不让系统给你压栈 先序遍历 准备一个栈 把根节点压入栈 步骤 从栈中弹出一个节点记为cur 打印或处理cur 先压右再压左(如果有)，压的顺序右左，弹的顺序就是左右 周而复始 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def pre_tree_traverse(root: TreeNode): if not root: return stack = [root] while stack: cur = stack.pop() print(cur.val, end=\" \") if cur.right: stack.append(cur.right) if cur.left: stack.append(cur.left) # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) # 打印可视化二叉树 pre_tree_traverse(root) 中序遍历 准备1个栈 把根节点压入栈 步骤 每颗子树，整棵树左边界进栈 依次弹出节点的过程中，打印并对弹出节点的右树重复以上步骤 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def in_tree_traverse(root: TreeNode): if not root: return stack = [] while stack or root: if root: # 不停的把左边界进栈 stack.append(root) root = root.left else: # 最后左边界走完了，为空，走该分支，弹出节点，打印，然后root指到右节点，然后又一直走左边界，即第一个分支 cur = stack.pop() print(cur.val, end=\" \") root = cur.right # 为什么可以这样，因为整棵树可以被左边界(右边界)分解 # 1 2 4 是一个左边界 # 5 是一个左边界 # 3 6 是一个左边界 # 7 是一个左边界 # 把左边界放入栈，压的顺序头->左，弹出顺序左->头，一个节点弹出的时候让他的右树周而复始 # 左头右 # | # v # 左头右 # | # v # 左头右 # | # v # 左头右 # ...没有右的概念 # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) # 打印可视化二叉树 in_tree_traverse(root) 后序遍历 前序遍历变化而来 准备2个栈 把根节点压入栈 步骤 从栈中弹出一个节点记为cur 把cur放到收集栈里面 先压左再压右(如果有)，压的顺序左右，弹的顺序就是右左，然后压入收集栈的顺序是右左，收集栈的弹出顺序是左右头(后序遍历) 周而复始 最后依次弹出收集栈的节点打印 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def post_tree_traverse(root: TreeNode): if not root: return stack = [root] stack_tmp = [] while stack: cur = stack.pop() stack_tmp.append(cur) # 不打印，压收集栈 if cur.left: stack.append(cur.left) if cur.right: stack.append(cur.right) while stack_tmp: print(stack_tmp.pop().val, end=\" \") # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) # 打印可视化二叉树 post_tree_traverse(root) 如何完成二叉树的深度优先遍历(就是先序遍历) 如何完成二叉树的宽度优先遍历(层序遍历)(常见题目：求一棵二叉树的宽度) 宽度遍历用队列 步骤 头部进，尾部出 弹出打印，先左再右 周而复始 from collections import deque class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def width_tree_traverse(root: TreeNode): if not root: return dq = deque([root]) while dq: cur = dq.popleft() print(cur.val, end=\" \") if cur.left: dq.append(cur.left) if cur.right: dq.append(cur.right) # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) # 打印可视化二叉树 width_tree_traverse(root) 求一棵二叉树的最大宽度 from collections import deque class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def tree_width(root): if not root: return 0 max_width = 0 dq = deque([(root, 0)]) # 使用队列存储节点和节点在当前层的位置(索引) while dq: level_size = len(dq) # 该层有多少节点 _, level_start = dq[0] # 开始位置，该层第一个节点的位置 position = 0 # 结束位置 for _ in range(level_size): # 遍历该层节点，依次抛出 node, position = dq.popleft() if node.left: dq.append((node.left, 2 * position)) if node.right: dq.append((node.right, 2 * position + 1)) max_width = max(max_width, position - level_start + 1) return max_width # 利用队列进行层序遍历，队列中存储节点和节点在当前层的位置（这里用 position 表示）。 # 在每一层的遍历中，记录当前层的开始位置 level_start 和结束位置 position，计算当前层的宽度，并更新最大宽度 max_width。 # 将下一层的节点及其位置入队，节点位置的计算规则是左子节点为当前位置的2倍，右子节点为当前位置的2倍加1。 # 最终返回最大宽度。 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 # (1, 0) # level_start = 0, position = 0, width = 1 # (2, 0)(3, 1) # level_start = 0, 依次弹出后position = 1, width = 2 # (4, 0)(5, 1)(6, 2)(7, 3) # level_start = 0, 依次弹出后position = 3, width = 4 # max_width = 4 # 1 # / \\ # 2 3 # \\ # 7 # (1, 0) # level_start = 0, position = 0, width = 1 # (2, 0)(3, 1) # level_start = 0, 依次弹出后position = 1, width = 2 # (7, 3) # level_start = 3, 依次弹出后position = 3, width = 1 # max_width = 2 # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) # 打印可视化二叉树 print(tree_width(root)) 如何判断一颗二叉树是否是搜索二叉树？ 什么是搜索二叉树，就是对于一棵树来说，他的左树节点都比他小，右树节点都比他大 在标准的搜索二叉树中，节点值通常是唯一的，没有重复值的 # 5 # / \\ # 3 7 # / \\ / \\ # 2 4 6 8 # / # 1 思路：用中序遍历，每次处理的时候看是否依次升序 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def is_bst(root: TreeNode): if not root: return True stack = [] min_val = float(\"-inf\") while stack or root: if root: stack.append(root) root = root.left else: cur = stack.pop() # 打印改成比较处理 if cur.val > min_val: min_val = cur.val else: return False root = cur.right return True # # 递归方法 # prev_val = float(\"-inf\") # # # def is_bst(root: TreeNode): # global prev_val # if not root: # return True # is_left_bst = is_bst(root.left) # if not is_left_bst: # return False # if root.val > prev_val: # prev_val = root.val # else: # return False # # return is_bst(root.right) # 示例：创建一个二叉树 # 5 # / \\ # 3 7 # / \\ / \\ # 2 4 6 8 # / # 1 root = TreeNode(5) root.left = TreeNode(3) root.right = TreeNode(7) root.left.left = TreeNode(2) root.left.right = TreeNode(4) root.right.left = TreeNode(6) root.right.right = TreeNode(8) root.left.left.left = TreeNode(1) print(is_bst(root)) 递归套路 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def is_bst(root: TreeNode): if not root: # 空树是搜索二叉树，最小值和最大值都为空 return True, float('inf'), float('-inf') # 递归判断左子树 left_bst, left_min, left_max = is_bst(root.left) # 递归判断右子树 right_bst, right_min, right_max = is_bst(root.right) # 判断当前节点是否满足搜索二叉树的性质 current_bst = left_bst and right_bst and (left_max 如何判断一颗二叉树是完全二叉树？ 什么是完全二叉树，之前的堆数据结构就是完全二叉树 每一层都满节点，即使是不满的最后一层，也是从左到右依次不满 思路：二叉树按宽度遍历 任意节点有右节点，没有左节点，直接返回false 在第一个条件不违规的情况下，如果遇到了第一个左右节点不全的节点，那么接下来所有节点必须是叶子节点 from collections import deque class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def is_cbt(root: TreeNode): if not root: return True dq = deque([root]) leaf_flag = False while dq: cur = dq.popleft() # print(cur.val, end=\" \") # 1、有右无左，不是 # 2、或者孩子不全，之后的节点不是叶子节点，不是 if (not cur.left and cur.right) or (leaf_flag and (cur.left or cur.right)): return False if cur.left: dq.append(cur.left) if cur.right: dq.append(cur.right) # 左右节点不全 if not cur.left or not cur.right: leaf_flag = True return True # 示例：创建一个二叉树 # 1 # / \\ # 2 3 # / \\ / \\ # 4 5 6 7 # /\\ / \\ / # 8 9 10 11 12 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) root.right.left = TreeNode(6) root.right.right = TreeNode(7) root.left.left.left = TreeNode(8) root.left.left.right = TreeNode(9) root.left.right.left = TreeNode(10) root.left.right.right = TreeNode(11) root.right.left.left = TreeNode(12) print(is_cbt(root)) 如何判断一颗二叉树是否是满二叉树？ 思路 一个函数统计二叉树最大深度L 一个函数统计二叉树节点个数N 满二叉树满足N = 2 ** L - 1 递归套路 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def is_full_tree(root: TreeNode): height, nodes = process(root) # 满二叉树节点数的计算方式 return nodes == (1 如何判断一颗二叉树是否是平衡二叉树？（二叉树题目套路） 平衡二叉树是指任何一颗子树来说，它左树的高度和它右树的高度差不能超过1 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def is_balanced(root: TreeNode): # base case(空树的返回) if not root: return True, 0 left_balanced, left_height = is_balanced(root.left) # 递归计算左子树的平衡性和高度 right_balanced, right_height = is_balanced(root.right) # 递归计算右子树的平衡性和高度 # 计算当前树的高度（取左右子树中较高的一个，并加上当前层） height = max(left_height, right_height) + 1 # 判断当前树是否平衡（左右子树高度差不超过1，并且左右子树也分别是平衡的） is_balance = abs(left_height - right_height) 二叉树递归套路(树形DP) 树形dp套路使用前提： 如果题目求解目标是S规则，则求解流程可以定成以每一个节点为头节点的子树在S规则下的每一个答案，并且最终答案一定在其中 二叉树递归套路可以解决一切树形DP(树上做动态规划)，难度在于罗列可能性，可以向左树要信息，可以向右树要信息 树形dp套路 第一步： 以某个节点X为头节点的子树中，分析答案有哪些可能性，并且这种分析是以X的左子树、X的右子树和X整棵树的角度来考虑可能性的 第二步： 根据第一步的可能性分析，列出所有需要的信息 第三步： 合并第二步的信息，对左树和右树提出同样的要求，并写出信息结构 第四步： 设计递归函数，递归函数是处理以X为头节点的情况下的答案。包括设计递归的basecase，默认直接得到左树和右树的所有信息，以及把可能性做整合，并且要返回第三步的信息结构这四个小步骤 树形DP的基本思想是，我们从叶子节点（底部）开始，计算和存储每个节点的状态，然后逐渐向上汇总这些状态，直到根节点，得到最终的解。这通常包括计算某种最优值、最长路径、最小代价等。 不能用该套路解的，比如求一棵树的中位数 比如看一个是否是平衡二叉树，假设一颗子树X，可能性包括以下 X左树得是平衡二叉树 X右树也得是平衡二叉树 X 左树和右树的高度差不能超过1( 因此需要左右树的是否平衡和高度信息 再比如看一棵树是否是搜索二叉树，满足以下 左树是搜索二叉树 右树是搜索二叉树 左树的最大值小于当前节点值 右树的最小值大于当前节点值 需要(因为递归不能区分最大最小，因此都返回) 左树：是否搜索二叉树，最大值 右树：是否搜索二叉树，最小值 返回值：是否搜索二叉树，最小值，最大值 二叉树节点间的最大距离问题 从二叉树的节点a出发，可以向上或者向下走，但沿途的节点只能经过一次，到达节点b时路径上的节点个数叫作a到b的距离，那么二叉树任何两个节点之间都有距离，求整棵树上的最大距离。 # 1 # / \\ # 2 3 # / \\ # 4 5 比如4~5：3 比如4~3:4 解题的一个常用标准：头结点参与不参与 解题思路，考虑x(头结点)参与不参与，来罗列可能性 x不参与：左子树最大距离或右子树最大距离 x参与：左子树的高(离x最远) + 右子树的高 + 1(x自己) max(左子树最大距离, 右子树最大距离, 左子树的高 + 右子树的高 + 1) 需要的信息：最大距离和高度 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right class Info: def __init__(self, dis, height): self.dis = dis self.height = height def get_max_distance(head: TreeNode): if not head: # base case return Info(0, 0) # 左右子树要信息 left_info = get_max_distance(head.left) right_info = get_max_distance(head.right) # 信息整合 can_yu = left_info.height + right_info.height + 1 max_dis = max(left_info.dis, right_info.dis, can_yu) height = max(left_info.height, right_info.height) + 1 return Info(max_dis, height) # 1 # / \\ # 2 3 # / \\ # 4 5 root = TreeNode(1) root.left = TreeNode(2, left=TreeNode(4), right=TreeNode(5)) root.right = TreeNode(3) print(get_max_distance(root).dis) 派对的最大快乐值 员工信息的定义如下: class Employee { public int happy; // 这名员工可以带来的快乐值 List subordinates; // 这名员工有哪些直接下级 } 公司的每个员工都符合 Employee 类的描述。整个公司的人员结构可以看作是一棵标准的、没有环的多叉树。树的头节点是公司唯一的老板。除老板之外的每个员工都有唯一的直接上级。叶节点是没有任何下属的基层员工(subordinates列表为空) ，除基层员工外，每个员工都有一个或多个直接下级。这个公司现在要办party，你可以决定哪些员工来，哪些员工不来。但是要遵循如下规则。 1.如果某个员工来了，那么这个员工的所有直接下级都不能来 2.派对的整体快乐值是所有到场员工快乐值的累加 3.你的目标是让派对的整体快乐值尽量大 给定一棵多叉树的头节点boss，请返回派对的最大快乐值。 x / | \\ a b c /|\\ /|\\ /|\\ 解题思路，列出可能性 x参与：x快乐值 + a整棵树在a不来的最大值 + b整棵树在b不来的最大值 + c整棵树在c不来的最大值 x不参与：0 + max(a来最大值, a不来的最大值) + max(a来的最大值, a不来的最大值) + max(a来的最大值, a不来的最大值) 向每颗树要它来的最大值和不来的时候的最大值 class Employee: def __init__(self, happy, next_employees): self.happy = happy self.next_employees = next_employees class Info: def __init__(self, come, no_come): self.come_max_happy = come self.no_come_max_happy = no_come def get_max_happy(x: Employee): if not x.next_employees: # base case, 基层员工 return Info(x.happy, 0) lai = x.happy # x来的情况下，整棵树的最大快乐值 bu_lai = 0 # x不来的情况下，整棵树的最大快乐值 for it in x.next_employees: next_info = get_max_happy(it) lai += next_info.no_come_max_happy bu_lai += max(next_info.come_max_happy, next_info.no_come_max_happy) # x不来时，下级可以来也不来 return Info(lai, bu_lai) # 10 # / | \\ # 3 20 40 # / | | \\ # 60 3 5 6 root = Employee(10, next_employees=[Employee(3, [Employee(60, [])]), Employee(20, [Employee(3, [])]), Employee(40, [Employee(5, []), Employee(6, [])])]) res = get_max_happy(root) print(max(res.come_max_happy, res.no_come_max_happy)) 给定两个二叉树的节点node1和node2，找到他们的最低公共祖先节点 递归套路 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def lowest_common_ancestor(root: TreeNode, node1: TreeNode, node2: TreeNode): \"\"\"LCA\"\"\" # 当前节点为空，返回空 # 或者如果当前节点是其中之一，直接返回当前节点 if not root or root == node1 or root == node2: # base case return root left = lowest_common_ancestor(root.left, node1, node2) right = lowest_common_ancestor(root.right, node1, node2) # 节点1和节点2，不互为公共祖先的情况 if left and right: return root # 如果只有左子树包含 node1 或 node2，则返回左子树的结果，否则返回右子树的结果 # 叶子节点，返回空 return left if left else right # 创建一棵二叉树 # 3 # / \\ # 5 1 # / \\ / \\ # 6 2 0 8 # / \\ # 7 4 root = TreeNode(3) root.left = TreeNode(5, left=TreeNode(6), right=TreeNode(2, left=TreeNode(7), right=TreeNode(4))) root.right = TreeNode(1, left=TreeNode(0), right=TreeNode(8)) # 找到节点值为5和4的最低公共祖先 node1 = root.left # 5 node2 = root.left.right.right # 4 lca = lowest_common_ancestor(root, node1, node2) if lca: print(\"节点 {} 和节点 {} 的最低公共祖先是节点 {}\".format(node1.val, node2.val, lca.val)) else: print(\"找不到节点 {} 和节点 {} 的最低公共祖先\".format(node1.val, node2.val)) # 找到节点值为5和8的最低公共祖先 node1 = root.left # 5 node2 = root.right.right # 8 lca = lowest_common_ancestor(root, node1, node2) if lca: print(\"节点 {} 和节点 {} 的最低公共祖先是节点 {}\".format(node1.val, node2.val, lca.val)) else: print(\"找不到节点 {} 和节点 {} 的最低公共祖先\".format(node1.val, node2.val)) 剖析一下，一共两种情况 情况一：节点1和节点2互为最低公共祖先 情况二：节点1和节点2不互为最低公共祖先 # 创建一棵二叉树 # 3 (左返回5，右返回空，所以公共祖先是5) # 返回5 / \\ # (base case) 5 1 (子树返回空，返回空) # / \\ / \\ # 6 2 0 8 (0和8，左右节点都返回空，返回空) # / \\ # 7 4 情况一：节点5和节点4 来到节点3，节点不等于空或5或4，base case跳过 3向左树5要答案，来到5，满足base case, 返回5 3向右树1要答案，来到1，不等于空或5或4，1继续向左右子树要答案，0和8，不等于空或5或4，各自都向子树要答案，左右子树都返回空，则一直往上返回空 3的左返回5，右返回空，所以公共祖先是5(即函数的最后一行条件) 意思就是，如果一颗子树既没有node1，也没有node2，一定会返回空 情况二：节点6和节点4 # 创建一棵二叉树 # 3 存在左节点，代码最后一行，因此返回5 # 返回5 / \\ (子树返回空，返回空) #左右同时存在，返回当前节点5 5 1 # 返回6 / \\ 返回4 # (base case) 6 2 存在右节点，代码最后一行，因此返回4 # 返回空 / \\ 返回4 # 7 4 (base case) 在二叉树中找到一个节点的后继节点 后继节点：中序遍历得到一个序列，获取到对应节点的下一个节点 前继节点：中序遍历得到一个序列，获取到对应节点的上一个节点 时间复杂度O(N) 【题目】 现在有一种新的二叉树节点类型如下: class Node: def __init__(self, value): self.value = value self.left = None self.right = None self.parent = None 该结构比普通二叉树节点结构多了一个指向父节点的parent指针。 假设有一棵Node类型的节点组成的二叉树，树中每个节点的parent指针都正确地指向自己的父节点，头节点的parent指向null。 只给一个在二叉树中的某个节点node，请实现返回node的后继节点的函数，假设到后继节点k步，要去时间复杂度O(k)。 思路 x有右树，则它右树的最左节点 x没有右树，一直往上看，看是不是它父节点的左节点，如果是，则父节点就是x的后继 还需要考虑最右节点，它的后继节点为空 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right self.parent = None def find_successor(node: TreeNode): if not node: return # 如果有右子树，则返回右子树的最左边的节点 if node.right: return find_left_most(node.right) # 如果没有右子树，一直往上 while node.parent: # 如果当前节点是父节点的左子树，则父节点即为后继节点 if node.parent.left == node: return node.parent node = node.parent # 树中的最后一个节点，没有后继节点 return None def find_left_most(node: TreeNode): while node.left: node = node.left return node # 创建节点 # 5 # / \\ # 3 8 # / \\ / \\ # 1 4 7 9 root = TreeNode(5) root.left = TreeNode(3) root.right = TreeNode(8) root.left.left = TreeNode(1) root.left.right = TreeNode(4) root.right.left = TreeNode(7) root.right.right = TreeNode(9) # 设置父节点指针 root.left.parent = root root.right.parent = root root.left.left.parent = root.left root.left.right.parent = root.left root.right.left.parent = root.right root.right.right.parent = root.right successor_node = find_successor(root) # 节点5 # 输出后继节点的值 if successor_node: print(\"后继节点的值:\", successor_node.val) else: print(\"节点3是树中的最后一个节点，没有后继节点。\") successor_node = find_successor(root.left.right) # 节点4 # 输出后继节点的值 if successor_node: print(\"后继节点的值:\", successor_node.val) else: print(\"节点3是树中的最后一个节点，没有后继节点。\") successor_node = find_successor(root.right.right) # 节点9 # 输出后继节点的值 if successor_node: print(\"后继节点的值:\", successor_node.val) else: print(\"节点3是树中的最后一个节点，没有后继节点。\") 二叉树的序列化和反序列化 就是内存里的一棵树如何变成字符串形式，又如何从字符串形式变成内存里的树 可用先序遍历、中序遍历、后续遍历、层序遍历 节点结束用_，空用# 5 / \\ null 8 / \\ 9 null / \\ null null 先序遍历：5_#_8_9_#_#_#_ class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def serializer(root: TreeNode): if not root: return \"#_\" serializer_res = str(root.val) + \"_\" serializer_res += serializer(root.left) serializer_res += serializer(root.right) return serializer_res def deserializer(node_str: str): def build_tree(data: list): node_val = data.pop(0) if node_val == \"#\": return None node = TreeNode(int(node_val)) node.left = build_tree(data) node.right = build_tree(data) return node node_data = node_str.split(\"_\") return build_tree(node_data) # 示例用法 # 创建一棵二叉树 # 5 # / \\ # null 8 # / \\ # 9 null # / \\ # null null root = TreeNode(5) root.right = TreeNode(8) root.right.left = TreeNode(9) # 序列化 serialized_tree = serializer(root) print(\"序列化后的字符串:\", serialized_tree) # # 反序列化 deserialized_tree = deserializer(serialized_tree) 5 / \\ 8 null / \\ null 9 / \\ null null 先序遍历：5_8_#_9_#_#_#_ 折纸问题 请把一段纸条竖着放在桌子上，然后从纸条的下边向上方对折1次，压出折痕后展开。 此时折痕是凹下去的，即折痕突起的方向指向纸条的背面。如果从纸条的下边向上方连续对折2次，压出折痕后展开，此时有三条折痕，从上到下依次是下折痕、下折痕和上折痕。 给定一个输入参数N，代表纸条都从下边向上方连续对折N次。请从上到下打印所有折痕的方向。 例如:N=1时，打印: down N=2时，打印: down down up def print_all_folds(n: int): print_folds(1, n, True) # 头结点是凹 def print_folds(n: int, depth: int, down: bool): \"\"\" 递归函数 :param n: 第几层 :param depth: 层数 :param down: 凹：down = True 凸：down = False :return: \"\"\" if n > depth: return print_folds(n + 1, depth, True) # 左子树的头结点都是凹 print(\"凹\" if down else \"凸\", end=\" \") print_folds(n + 1, depth, False) # 右子树的头节点都是凸 # 创建节点 # 凹 # / \\ # 凹 凸 # / \\ / \\ # 凹 凸 凹 凸 print_all_folds(3) "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/06-图.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/06-图.html","title":"图","keywords":"","body":"datetime:2024-01-19 14:37 author:nzb 图 图是一种常见的数据结构，用于表示一组对象之间的关系。在图的存储方式中，两种常见的方法是邻接表和邻接矩阵。 邻接表 在邻接表中，图的每个顶点都有一个关联的链表，链表中存储了与该顶点相邻的其他顶点。 对于有向图或无向图，每个顶点对应一个链表，链表中的元素表示与该顶点直接相邻的顶点。 对于有权图，链表中通常包含边的权重。 邻接表对稀疏图更为节省空间，因为它只存储实际存在的边。 邻接矩阵 在邻接矩阵中，图的关系被表示为一个二维数组（矩阵）。 对于无向图，矩阵是对称的；对于有向图，矩阵不一定对称。 矩阵中的元素表示两个顶点之间是否存在边，以及可能包含边的权重。 对于稠密图，邻接矩阵通常更为高效，因为它直接表示所有可能的边。 无向图是一种特殊的有向图 选择邻接表还是邻接矩阵取决于图的特性以及使用场景。邻接表适用于稀疏图，而邻接矩阵适用于稠密图。 邻接表可直接查出一个点后续有多少个邻居点 邻接矩阵可直接查出每条边 A B | \\ / | 3\\/2 7| /\\ | / \\ C--5-- D # 邻接表 A: C(7), D(3) B: C(2) C: A(7), B(2), D(5) D: A(3), C(5) # 邻接矩阵 0 1 2 3 A B C D 0 A 0 +∞ 7 3 1 B +∞ 0 2 +∞ 2 C 7 2 0 5 3 D 3 +∞ 5 0 数据结构 import typing class Node: def __init__(self, value: typing.Any): self.value = value # 无向图的入度和出度相等 self.node_in: int = 0 # 点的入度 self.node_out: int = 0 # 点的出度 self.next_nodes: typing.List[Node] = list() # 指向的邻居，只关心发散出去的 self.edges: typing.List[Edge] = list() # 有哪些边属于该点 class Edge: def __init__(self, weight: int, from_node: Node, to_node: Node): self.weight: int = weight self.from_node: Node = from_node self.to_node: Node = to_node # 实现 __hash__ 方法 def __hash__(self): # 可以根据对象的属性生成一个唯一的哈希值 return hash((self.from_node, self.to_node, self.weight)) def __lt__(self, other): return self.weight other.weight class Graph: def __init__(self): self.nodes: typing.Dict[int, Node] = dict() # key: 点编号，node点实例 self.edges: typing.Set[Edge] = set() def create_graph(graph_data: list): graph = Graph() for it in graph_data: weight = it[0] from_node = it[1] to_node = it[2] if from_node not in graph.nodes: graph.nodes[from_node] = Node(from_node) if to_node not in graph.nodes: graph.nodes[to_node] = Node(to_node) from_node_ins = graph.nodes.get(from_node) to_node_ins = graph.nodes.get(to_node) edge = Edge(weight, from_node_ins, to_node_ins) from_node_ins.next_nodes.append(to_node_ins) from_node_ins.node_out += 1 to_node_ins.node_in += 1 from_node_ins.edges.append(edge) graph.edges.add(edge) return graph data = [ [5, 0, 1], # 权重5,0指向1 [3, 1, 2], [7, 0, 2] ] res = create_graph(data) print(res) 图的宽度优先遍历 跟二叉树的宽度优先遍历的区别就是，二叉树没有环，而图有，要解决的就是不进入环，出不来的问题 1，利用队列实现 2，从源节点开始依次按照宽度进队列，然后弹出 3，每弹出一个点，把该节点所有没有进过队列的邻接点放入队列 4，直到队列变空 5，注意处理有环图 from collections import deque # A------E # | \\ / # | \\/ # | B # | /\\ # | / \\ # C------D data = [ [5, \"A\", \"E\"], # A -> E [5, \"A\", \"B\"], [5, \"A\", \"C\"], [5, \"B\", \"C\"], [5, \"B\", \"A\"], [5, \"B\", \"E\"], [5, \"B\", \"D\"], [5, \"C\", \"A\"], [5, \"C\", \"B\"], [5, \"C\", \"D\"], [5, \"D\", \"C\"], [5, \"D\", \"B\"], [5, \"D\", \"E\"], [5, \"E\", \"A\"], [5, \"E\", \"B\"], [5, \"E\", \"D\"], ] res = create_graph(data) def dfs_width(node: Node): if not node: return dq = deque([node]) # 用于处理有环的图，如果无环可以不用加这个 # 实际上，为了更快，可以把哈希表换成数组，因为现实中，城市编号不会特别大，数据的速度比哈希表的常数时间快 node_set = set() node_set.add(node) while dq: cur = dq.popleft() # 打印或处理（定制） print(cur.value, end=\" \") for next_node in cur.next_nodes: if next_node not in node_set: node_set.add(next_node) dq.append(next_node) dfs_width(res.nodes[\"A\"]) 广度优先遍历 1，利用栈实现 2，从源节点开始把节点按照深度放入栈，然后弹出 3，每弹出一个点，把该节点下一个没有进过栈的邻接点放入栈，弹出的节点先重新入栈 4，直到栈变空 5，就是一条路走到底 6，注意处理有环图 # A # / | \\ # / | \\ # / | \\ # B----C----E # | / # | / # | / # D data = [ [5, \"A\", \"B\"], [5, \"A\", \"E\"], # A -> E [5, \"A\", \"C\"], [5, \"B\", \"C\"], [5, \"B\", \"A\"], [5, \"C\", \"A\"], [5, \"C\", \"B\"], [5, \"C\", \"D\"], [5, \"C\", \"E\"], [5, \"D\", \"C\"], [5, \"D\", \"E\"], [5, \"E\", \"A\"], [5, \"E\", \"C\"], [5, \"E\", \"D\"], ] res = create_graph(data) \"\"\" A 先加入栈，处理，栈不为空 弹出A，A的下一个节点有B,C,E，不妨处理B，集合不含B，重新把A入栈，然后B入栈，集合加入B，处理B，break跳出，不再看C,E 弹出B, ->A,C，A已经在集合里面跳过，来到C，B重新入栈，C入栈，处理C，break 弹出C, ->A,B,D,E，A,B已经在集合跳过，来到D, C重新入栈，D入栈，处理D，break 弹出D, ->C,E，C跳过，来到E, D,E入栈，处理E，break 弹出E, ->A,C,D都在集合里跳过 弹出D 弹出C 弹出B 弹出A \"\"\" def dfs_scope(node: Node): if not node: return stack = [node] # 用于处理有环的图，如果无环可以不用加这个 # 实际上，为了更快，可以把哈希表换成数组，因为现实中，城市编号不会特别大，数据的速度比哈希表的常数时间快 node_set = set() node_set.add(node) # 打印或替换成其他处理函数 print(node.value, end=\" \") while stack: cur = stack.pop() for next_node in cur.next_nodes: # 如果有一条没走完，它会在继续重新入栈，继续往下走 # 一路上走到黑 if next_node not in node_set: stack.append(cur) stack.append(next_node) node_set.add(next_node) # 打印或替换成其他处理函数 print(next_node.value, end=\" \") break dfs_scope(res.nodes[\"A\"]) 拓扑排序算法 适用范围：要求有向图，且有入度为0的节点，且没有环 比如程序编译依赖包关系 ----------- | | | V A -> B -> C -> D | ^ | | ----------- # ----------- # | | # | V # A -> B -> C -> D # | ^ # | | # ----------- data = [ [5, \"A\", \"B\"], [5, \"B\", \"C\"], [5, \"C\", \"D\"], [5, \"A\", \"C\"], [5, \"B\", \"D\"], ] graph = create_graph(data) from collections import deque def topology_sort(graph: Graph): node_map = dict() # node: 剩余入度 dq0 = deque() # 入度为0的点 for node in graph.nodes.values(): node_map[node] = node.node_in if node.node_in == 0: dq0.append(node) res = [] # 拓扑排序的结果 while dq0: cur = dq0.popleft() res.append(cur) # 擦除当前节点的影响 for next_node in cur.next_nodes: node_map[next_node] -= 1 if node_map[next_node] == 0: dq0.append(next_node) return res for i in topology_sort(graph): print(i.value) 最小生成树 使用并查集，查询和合并的速度是常数级别 # 7 10万 # A------B--------E # | \\ | # | \\ | # 2|100\\ |1000 # | \\ | # C------D # 4 # 集合查询、合并 # 刚开始：{A}, {B}, {C}, {D}, {E} # 加上2这条边：这条边的from(A)和to(B)不在一个集合里，所以加上，然后A,C合并：{A, C}, {B}, {D}, {E} # 加上4这条边：这条边的from(C)和to(D)不在一个集合里，所以加上，然后A,C合并：{A, C, D}, {B}, {E} # 加上7这条边：这条边的from(A)和to(B)不在一个集合里，所以加上，然后A,C合并：{A, C, D, B}, {E} # 加上100这条边：这条边的from(A)和to(D)在一个集合里，所以这条边不要，{A, C, D, B}, {E} # 加上1000这条边：这条边的from(B)和to(D)在一个集合里，所以这条边不要，{A, C, D, B}, {E} # 加上10万这条边：这条边的from(B)和to(E)不在一个集合里，所以加上，然后A,C合并：{A, C, D, B, E} # 差不多这样的结构 import typing class UnionFind: def __init__(self, nodes: typing.List[Node]): self.node_map = {} for node in nodes: self.node_map[node] = {node} def find(self, from_node: Node, to_node: Node): return self.node_map.get(from_node) == self.node_map.get(to_node) def union(self, from_node: Node, to_node: Node): from_set = self.node_map.get(from_node) to_set = self.node_map.get(to_node) if from_set is not None and to_set is not None and from_set != to_set: for node in to_set: from_set.add(node) self.node_map[node] = from_set # 被合并的集合里面的节点需要指向，最新的集合地址 # 3 # A------B # | \\ / | # 100| 7\\/5 | # | /\\ |2 # | / \\ | # C------D # 1000 # 保证连通性的同时，权值最小 # 3 # A------B # /| # /5| # / |2 # / | # C D kruskal算法 适用范围：要求无向图 kruskal算法以边的角度出发 把边排序，依次选择最小的边，看这条边加上，看有没有形成环 没有，要这条边 有，不要这条边 因此需要一种检测有没有形成环的功能(并查集) # 7 10万 # A------B--------E # | \\ | # | \\ | # 2|100\\ |1000 # | \\ | # C------D # 4 data = [ [7, \"A\", \"B\"], [100000, \"B\", \"E\"], [2, \"A\", \"C\"], [100, \"A\", \"D\"], [1000, \"B\", \"D\"], [4, \"C\", \"D\"], ] graph = create_graph(data) import typing import heapq def kruskalMST(graph: Graph): union_find = UnionFind(list(graph.nodes.values())) # 优先级队列(小根堆)，该方法需要Edge实现比较魔术函数 hq = [] for value in graph.edges: # M条边 heapq.heappush(hq, value) # O(logM) result: typing.List[Edge] = [] while hq: # M条边 cur_edge = heapq.heappop(hq) # O(logM) if not union_find.find(cur_edge.from_node, cur_edge.to_node): # 查 result.append(cur_edge) union_find.union(cur_edge.from_node, cur_edge.to_node) # 合并 return result res = kruskalMST(graph) for it in res: print(it.weight) prim算法 适用范围：要求无向图 # 7 10万 # A------B--------E # | \\ | # | \\ | # 2|100\\ |1000 # | \\ | # C------D # 4 data = [ [7, \"A\", \"B\"], [100000, \"B\", \"E\"], [2, \"A\", \"C\"], [100, \"A\", \"D\"], [1000, \"B\", \"D\"], [4, \"C\", \"D\"], ] graph = create_graph(data) import typing import heapq def primMST(graph: Graph): hq = [] node_set: typing.Set[Node] = set() # 是否是新点 result: typing.List[Edge] = [] # 依次挑选的边 # 用于处理森林的情况，比如多个不连通的图，各自生成最小生成树 for node in graph.nodes.values(): # 新的一个点，联通的图的话，这里开始就行 if node not in node_set: node_set.add(node) for edge in node.edges: # 该点所有的边加入到优先级队列中 heapq.heappush(hq, edge) while hq: edge = heapq.heappop(hq) # 弹出最小的边 to_node = edge.to_node # 可能是新的点 if to_node not in node_set: # 如果边的to节点不在集合里面，就是新点 node_set.add(to_node) result.append(edge) # 加入结果中 for edge in to_node.edges: heapq.heappush(hq, edge) # 一条边可能会重复加入，但是不会影响结果，应该已经在集合里面了，最多增加常数时间 return result res = primMST(graph) for it in res: print(it.weight) Dijkstra算法 适用范围：没有权值为负数的边 # D # / | \\ # / | \\ # / | \\ # 9/ |7 \\16 # / | \\ # A--15--C--14--E # \\ | / # 3\\ |2 /200 # \\ | / # \\ | / # \\ | / # B \"\"\" # 先生成一张表：A到各个点的距离，初始位正无穷 A B C D E A 0 +∞ +∞ +∞ +∞ 每一次在表里选距离最短的点A 然后看从这个点出发的边，能不能把这张表的记录变得更小 A -> B(3) A B C D E A 0 3 +∞ +∞ +∞ A -> B(15) A B C D E A 0 3 15 +∞ +∞ A -> D(9) A B C D E A 0 3 15 9 +∞ (不动了) 在剩下的记录中找距离最短的点B B(3) -> A(3), 到A, 3+3 > 0, 跳过 B(3) -> C(2), 到C, 3+2 E(200), 到C, 3+200 A(15), 到A, 5+15 > 0, 跳过 C(5) -> B(2), 到C, 5+2 > 3, 跳过 C(5) -> E(14), 到C, 5+14 D(7), 到C, 5+7 > 9, 跳过 A B C D E A 0 3 5 9 19 (不动了)(不动了)(不动了) 以此类推 \"\"\" # D # / | \\ # / | \\ # / | \\ # 9/ |7 \\16 # / | \\ # A--15--C--14--E # \\ | / # 3\\ |2 /200 # \\ | / # \\ | / # \\ | / # B data = [ [3, \"A\", \"B\"], [9, \"A\", \"D\"], [15, \"A\", \"C\"], [3, \"B\", \"A\"], [2, \"B\", \"C\"], [200, \"B\", \"E\"], [15, \"C\", \"A\"], [2, \"C\", \"B\"], [14, \"C\", \"E\"], [7, \"C\", \"D\"], [9, \"D\", \"A\"], [7, \"D\", \"C\"], [16, \"D\", \"E\"], [16, \"E\", \"D\"], [14, \"E\", \"C\"], [200, \"E\", \"B\"] ] graph = create_graph(data) def get_min_distance_and_unselected_node(node_map: dict, select_set: set): min_node = None min_dist = float(\"inf\") for node, dist in node_map.items(): if node not in select_set and dist 堆结构改写Dijkstra算法 指标不变，只是加快了常数时间 import typing class Node: def __init__(self, value: typing.Any): self.value = value # 无向图的入度和出度相等 self.node_in: int = 0 # 点的入度 self.node_out: int = 0 # 点的出度 self.next_nodes: typing.List[Node] = list() # 指向的邻居，只关心发散出去的 self.edges: typing.List[Edge] = list() # 有哪些边属于该点 class Edge: def __init__(self, weight: int, from_node: Node, to_node: Node): self.weight: int = weight self.from_node: Node = from_node self.to_node: Node = to_node # 实现 __hash__ 方法 def __hash__(self): # 可以根据对象的属性生成一个唯一的哈希值 return hash((self.from_node, self.to_node, self.weight)) def __lt__(self, other): return self.weight other.weight class Graph: def __init__(self): self.nodes: typing.Dict[int, Node] = dict() # key: 点编号，node点实例 self.edges: typing.Set[Edge] = set() def create_graph(graph_data: list): graph = Graph() for it in graph_data: weight = it[0] from_node = it[1] to_node = it[2] if from_node not in graph.nodes: graph.nodes[from_node] = Node(from_node) if to_node not in graph.nodes: graph.nodes[to_node] = Node(to_node) from_node_ins = graph.nodes.get(from_node) to_node_ins = graph.nodes.get(to_node) edge = Edge(weight, from_node_ins, to_node_ins) from_node_ins.next_nodes.append(to_node_ins) from_node_ins.node_out += 1 to_node_ins.node_in += 1 from_node_ins.edges.append(edge) graph.edges.add(edge) return graph class NodeRecord: def __init__(self, node: Node, distance: int): self.node = node self.distance = distance class NodeHeap: def __init__(self, node_size: int): self.nodes: typing.List[Node] = [None] * node_size # 堆 self.heap_index_map: typing.Dict[Node, int] = dict() # 在堆上的位置索引 self.distance_map: typing.Dict[Node, int] = dict() self.size = 0 def add_or_update_or_ignore(self, node: Node, distance: int): # 在堆上，更新 if self._in_heap(node): self.distance_map.update({node: min(self.distance_map[node], distance)}) # 更新最小距离 # 变小了，可能经历一个往上的过程 self._heap_insert(self.heap_index_map[node]) # 没进来过 if not self._is_entered(node): self.nodes[self.size] = node # 新增 self.heap_index_map[node] = self.size self.distance_map[node] = distance # 可能经历一个往上的过程 self._heap_insert(self.size) self.size += 1 # 已经弹出过的，-1的忽略 def is_empty(self): return self.size == 0 def pop(self) -> NodeRecord: node_record = NodeRecord(self.nodes[0], self.distance_map[self.nodes[0]]) self._swap(0, self.size - 1) # 最后一个元素放到堆顶 self.heap_index_map[self.nodes[self.size - 1]] = -1 # 因为上面交换到最后一个元素，然后弹出了，所以置为-1 self.distance_map.pop(self.nodes[self.size - 1]) # 删掉对应节点距离信息 self.nodes[self.size - 1] = None # 最后一个位置释放掉 self.size -= 1 self._heapify(0, self.size) return node_record def _is_entered(self, node: Node) -> bool: \"\"\" node是否进过堆 :param node: :return: 进过返回对应索引或-1，否则未进入 -1 代办进来过，但处理完了 \"\"\" # return self.heap_index_map.get(node) # 索引为0 会被当成False return node in self.heap_index_map def _in_heap(self, node: Node) -> bool: \"\"\" 在不在堆上 进来过，并且不等于-1 -1 表示(弹出了)不在堆上 :param node: :return: \"\"\" return self._is_entered(node) and self.heap_index_map.get(node, -1) != -1 def _swap(self, index1: int, index2: int): \"\"\" 调整堆 :param index1: :param index2: :return: \"\"\" # 索引对换更新 self.heap_index_map.update({self.nodes[index1]: index2, self.nodes[index2]: index1}) # self.heap_index_map[self.nodes[index1]], self.heap_index_map[self.nodes[index2]] = index2, index1 # 堆元素对换 self.nodes[index1], self.nodes[index2] = self.nodes[index2], self.nodes[index1] # 小根堆调整 def _heap_insert(self, index: int): \"\"\" 根据距离往上调整 :param index: :return: \"\"\" parent_idx = max(0, (index - 1) >> 1) while self.distance_map[self.nodes[index]] > 1) def _heapify(self, index: int, size: int): left = 2 * index + 1 while left = self.distance_map[self.nodes[index]]: break self._swap(index, smallest) index, left = smallest, 2 * index + 1 def dijkstra_heap(head: Node, size: int): \"\"\" 利用小根堆改进dijkstra算法 从head出发，所有head能到到达的节点，生成到达每个节点的最小路径记录并返回 :param head: :param size: :return: \"\"\" node_heap = NodeHeap(size) node_heap.add_or_update_or_ignore(head, 0) result: typing.Dict[Node, int] = dict() while not node_heap.is_empty(): cur = node_heap.pop() for edge in cur.node.edges: node_heap.add_or_update_or_ignore(edge.to_node, cur.distance + edge.weight) result[cur.node] = cur.distance return result # D # / | \\ # / | \\ # / | \\ # 9/ |7 \\16 # / | \\ # A--15--C--14--E # \\ | / # 3\\ |2 /200 # \\ | / # \\ | / # \\ | / # B data = [ [3, \"A\", \"B\"], [9, \"A\", \"D\"], [15, \"A\", \"C\"], [3, \"B\", \"A\"], [2, \"B\", \"C\"], [200, \"B\", \"E\"], [15, \"C\", \"A\"], [2, \"C\", \"B\"], [14, \"C\", \"E\"], [7, \"C\", \"D\"], [9, \"D\", \"A\"], [7, \"D\", \"C\"], [16, \"D\", \"E\"], [16, \"E\", \"D\"], [14, \"E\", \"C\"], [200, \"E\", \"B\"] ] graph = create_graph(data) data = dijkstra_heap(graph.nodes[\"A\"], size=len(graph.nodes)) for k, v in data.items(): print(k.value, v) "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/07-前缀树和贪心算法.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/07-前缀树和贪心算法.html","title":"前缀树和贪心算法","keywords":"","body":"datetime:2024/1/21 14:18 author:nzb 前缀树和贪心算法 前缀树 前缀树（Trie），也称为字典树或单词查找树，是一种树形数据结构，通常用于存储动态集合或关联数组，其中键通常是字符串。它的主要优势在于高效地支持字符串的插入、删除和查找操作，尤其适用于需要快速搜索和匹配前缀的场景。 例子: 一个字符串类型的数组arr1，另一个字符串类型的数组arr2。 arr2中有哪些字符，是arr1中出现的？请打印。 arr2中有哪些字符，是作为arr1中某个字符串前缀出现的？请打印。 arr2中有哪些字符，是作为arr1中某个字符串前缀出现的？请打印arr2中出现次数最大的前缀。 \"\"\" [\"abc\", \"ab\", \"bc\", \"bck\"] O代表节点，字符在路上 p代表走过的个数，pass e代表结束，end O p=4,e=0 / \\ / \\ a b / \\ / \\ O p=2,e=0 O p=2,e=0 / | b | / c O p=2,e=1 | | | | O p=2,e=1 c | | | | k O p=1,e=1 | | O p=1,e=1 1、问有没有加入过 \"bc\" 字符串：从头结点开始查，结尾看节点的end，还能看出加过几次 2、加入过的字符串有多少以\"ab\"作为前缀的：遍历\"ab\"，从头结点开始，看pass值 \"\"\" class TrieNode: def __init__(self): self.pass_num: int = 0 self.end_num: int = 0 self.children: dict = {} # 代表路 class Trie: def __init__(self): self.root = TrieNode() def insert(self, word: str): if not word: return node = self.root node.pass_num += 1 for char in word: # 不存在路，新建 if char not in node.children: node.children[char] = TrieNode() node = node.children[char] node.pass_num += 1 # 路加1 node.end_num += 1 def delete(self, word: str): if self.search(word): node = self.root node.pass_num -= 1 for char in word: parent = node node = node.children[char] node.pass_num -= 1 if node.pass_num == 0: # 如果pass都为0了，说明后续没了，删掉后面的路 parent.children.pop(char) return node.end_num -= 1 def search(self, word: str): if not word: return False node = self.root for char in word: if char not in node.children: # return False, 0 return False node = node.children[char] # return True, node.end_num # 多少次 return True if node.end_num != 0 else False def starts_with_prefix(self, prefix: str): if not prefix: return False node = self.root for char in prefix: if char not in node.children: # return False, 0 return False node = node.children[char] # return True, node.pass_num # 多少次 return True ins = Trie() for item in [\"abc\", \"ab\", \"ab\", \"bc\", \"bck\", \"bc\"]: # 增 ins.insert(item) # # 查 # print(ins.search(\"bc\")) # print(ins.search(\"bk\")) # # 查前缀 # print(ins.starts_with_prefix(\"bc\")) # print(ins.starts_with_prefix(\"ab\")) # print(ins.starts_with_prefix(\"bk\")) # 删除 print(ins.search(\"ab\")) print(ins.search(\"abc\")) print(ins.starts_with_prefix(\"ab\"), end=\"\\n\\n\") ins.delete(\"ab\") print(ins.search(\"ab\")) print(ins.search(\"abc\")) print(ins.starts_with_prefix(\"ab\"), end=\"\\n\\n\") ins.delete(\"ab\") print(ins.search(\"ab\")) print(ins.search(\"abc\")) print(ins.starts_with_prefix(\"ab\")) 贪心算法 贪心策略代码一般都很短 在某一个标准下，优先考虑最满足标准的样本，最后考虑最不满足标准的样本，最终得到一个答案的算法，叫作贪心算法。 也就是说，不从整体最优上加以考虑，所做出的是在某种意义上的局部最优解。 局部最优 -?-> 整体最优 贪心算法是一种在每一步选择中都采取在当前状态下最好或最优（局部最优）的选择，从而希望能够导致全局最好或最优（全局最优）的结果。 贪心算法不回溯，一旦做出了某个决策，就不再改变。这种策略通常适用于一些最优化问题，例如最小生成树、最短路径、任务调度等。 贪心算法的一般步骤： 问题建模： 将问题抽象成一组子问题。 确定选择策略： 对于每个子问题，确定一个局部最优解的选择策略。 迭代求解： 通过迭代地做出局部最优选择，最终得到全局最优解或近似最优解。 贪心算法的特点： 局部最优性： 贪心算法每一步选择都是当前状态下的局部最优解。 不回溯： 一旦做出决策，就不再改变。 不保证全局最优： 贪心算法不保证总是能够得到全局最优解，但在一些问题中能够产生接近最优解的结果。 应用场景： 最小生成树问题： Kruskal算法、Prim算法。 最短路径问题： Dijkstra算法。 任务调度问题： 按照某个标准选择任务执行的顺序，例如最早截止时间优先（Earliest Deadline First，EDF），例如：会议室使用。 会议室是问题：比如会议室空闲时间：早上6.00到下午6.00 按最早时间开始排，如果有个会议室早上6.00到下午5.00的，就只能安排一个会议，此方案不行 按会议最短时间开始排，会议1(6.00-12.00)，会议2(11.00-2.00)，会议3(1.00-6.00)，只能安排会议2，此方案不行 只能按最早截止时间优先 贪心算法的在笔试时的解题套路 1，实现一个不依靠贪心策略的解法X，可以用最暴力的尝试 2，脑补出贪心策略A、贪心策略B、贪心策略C... 3，用解法X和对数器，去验证每一个贪心策略，用实验的方式得知哪个贪心策略正确 4，不要去纠结贪心策略的证明 从头到尾展示最正统的贪心策略求解过程 例子：给定一个字符串类型的数组strs，找到一种拼接方式，使得把所有字符串拼起来之后形成的字符串具有最小的字典序。 证明贪心策略可能是件非常腌心的事情。平时当然推荐你搞清楚所有的来龙去脉，但是笔试时用对数器的方式！ - 看左神视频1:18:43 贪心策略在实现时，经常使用到的技巧： 1，根据某标准建立一个比较器来排序 2，根据某标准建立一个比较器来组成堆 会议室问题 一些项目要占用一个会议室宣讲，会议室不能同时容纳两个项目的宣讲。给你每一个项目开始的时间和结束的时间(给你一个数组，里面是一个个具体的项目)， 你来安排宣讲的日程，要求会议室进行的宣讲的场次最多。返回这个最多的宣讲场次。 from collections import namedtuple import typing program = namedtuple(\"Program\", [\"name\", \"start\", \"end\"]) # 项目或会议 def best_arrange(data: typing.List[program], time_point: int): data = sorted(data, key=lambda x: x.end) cnt = 0 for item in data: if time_point 金条切分 一块金条切成两半，是需要花费和长度数值一样的铜板的。比如长度为20的金条，不管切成长度多大的两半，都要花费20个铜板。 一群人想整分整块金条，怎么分最省铜板? 例如,给定数组{10,20,30}，代表一共三个人，整块金条长度为10+20+30=60。金条要分成10,20,30三个部分。 如果先把长度60的金条分成10和50，花费60； 再把长度50的金条分成20和30，花费50；一共花费110铜板。但是如果先把长度60的金条分成30和30，花费60；再把长度30金条分成10和20，花费30；一共花费90铜板。 输入一个数组，返回分割的最小代价。 import typing import heapq def less_money(data: typing.List[int]): hq = [] for it in data: heapq.heappush(hq, it) sum_total = 0 while len(hq) > 1: tmp = heapq.heappop(hq) + heapq.heappop(hq) sum_total += tmp heapq.heappush(hq, tmp) return sum_total print(less_money([10, 20, 30])) 获得的最大钱数 输入： 正数数组costs 正数数组profits 正数k 正数m 含义： costs[i]表示i号项目的花费 profits[i]表示i号项目在扣除花费之后还能挣到的钱(利润) k表示你只能串行的最多做k个项目 m表示你初始的资金 说明： 你每做完一个项目，马上获得的收益，可以支持你去做下一个项目。输出： 你最后获得的最大钱数。 解题思路 先把项目按照花费加入小根堆 然后根据启动资金，解锁项目，解锁出来的按照利润加入到大根堆 消费大根堆 import heapq import heapq_max # pip install heapq_max def find_max_profit(costs: list, profits: list, k: int, m: int): \"\"\" :param costs: 花费 :param profits: 利润 :param k: 你只能串行的最多做k个项目 :param m: 表示你初始的资金 :return: \"\"\" min_hq = [] for it in zip(costs, profits): heapq.heappush(min_hq, it) max_hq = [] for i in range(k): while min_hq and min_hq[0][0] n皇后问题 def n_queens(n: int): if n 表示第i行的皇后，放在第几列 return process(0, records, n) def process(i: int, records: list, n: int): \"\"\" :param i:目前第i行 :param records: 潜台词：只要进入该函数，records[0...i-1] 上的皇后，任意两个皇后都不共行，不共列，不共斜线 :param n:一共多少行， n * n :return: \"\"\" # base case if i == n: # 终止行，如果到这说明有符合的一种摆放 # print(records) return 1 cnt = 0 for j in range(n): # 遍历尝试每一列 if is_valid(records, i, j): records[i] = j cnt += process(i + 1, records, n) return cnt def is_valid(records: list, i: int, j: int): \"\"\" 是否不共行，不共列，不共斜线 :param records: :param i: 第i行 :param j: 第j列 :return: \"\"\" # 肯定不共行 # records[0...i-1]需要看，[i...]不需要，因为当前在i行 for row in range(i): # 之前某个x行皇后 if records[row] == j or abs(i - row) == abs(j - records[row]): return False return True print(n_queens(4)) # 2 最优解就是上面这个，时间复杂度O(N^N)，每行N种选择，一共N行 但是可以做常数时间优化，但是指标没法优化，利用位运算加速，非常优雅 import time # 位运算求解 def n_queens2(n: int): if n 0b11111 return process2(limit, 0, 0, 0) # limit 可以限制在哪些位可以放皇后，limit永远不变 def process2(limit: int, col_limit: int, left_limit: int, right_limit: int): \"\"\" 例如： 11111 第二位放： 00100 列限制： 00100 左限制： 01000（左移） 右限制： 00010（右移） 求或： 01110 :param limit: 限制 :param col_limit: 列限制 :param left_limit: 左限制 :param right_limit: 右限制 :return: \"\"\" # base case if col_limit == limit: # 每次都在在某一列放一个皇后，如果放到跟limit一样，说明存在一种放法 return 1 cnt = 0 can_put_bit = limit & ~(col_limit | left_limit | right_limit) # 求哪些位可以放 while can_put_bit != 0: most_right_one = can_put_bit & (~can_put_bit + 1) can_put_bit -= most_right_one # 等于 can_put_bit & (can_put_bit - 1) cnt += process2(limit, col_limit | most_right_one, (left_limit | most_right_one) > 1) return cnt for i in range(10, 15): start = time.time() n_queens(i) print(f\"n = {i}, n_queens cost {int((time.time() - start) * 1e3)}ms\") start = time.time() n_queens2(i) print(f\"n = {i}, n_queens2 cost {int((time.time() - start) * 1e3)}ms\") print(\"\\n\") # n = 10, n_queens cost 574ms # n = 10, n_queens2 cost 39ms # # n = 11, n_queens cost 2525ms # n = 11, n_queens2 cost 133ms # # n = 12, n_queens cost 13443ms # n = 12, n_queens2 cost 736ms # # n = 13, n_queens cost 90491ms # n = 13, n_queens2 cost 3976ms "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/08-暴力递归.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础/08-暴力递归.html","title":"暴力递归","keywords":"","body":"datetime:2024/1/29 16:50 author:nzb 暴力递归 暴力递归就是尝试 1，把问题转化为规模缩小了的同类问题的子问题 2，有明确的不需要继续进行递归的条件(base case) 3，有当得到了子问题的结果之后的决策过程 4，不记录每一个子问题的解 一定要学会怎么去尝试，因为这是动态规划的基础，这一内容我们将在提升班讲述 汉诺塔问题 打印n层汉诺塔从最左边移动到最右边的全部过程(大的不能在小的上面) 2 1 | 3 | | | --- | | | | | ----- | | | | | ------- | | 假设1~i的圆盘，要从from杆->to杆，还有一个other的杆 假设函数fn(i, from, to, other)分以下步骤 1~i-1从from->other：调用fn(i-1, from, other, to) i从from->to：因为1~i-1都移到other，所以可以把i移到to了，直接打印 1~i-1从other->to：移回去，调用fn(i-1, other, to, from) def hanoi(n: int): if n > 0: move_tower_of_hanoi(n, \"左\", \"右\", \"中\") def move_tower_of_hanoi(i: int, start: str, end: str, other: str): if i == 1: # base case, 就是那个杆就剩一个的时候，直接移到 end 上 print(f\"Move 1 from {start} to {end}\") else: move_tower_of_hanoi(i - 1, start, other, end) # i-1 都移到 other 了，i 移到 end, 打印 print(f\"Move {i} from {start} to {end}\") move_tower_of_hanoi(i - 1, other, end, start) hanoi(3) 打印一个字符串的全部子序列，包括空字符串 def print_subsets(word: str, i=0, current_subset=\"\"): if i == len(word): # base case 到最后一个字符下一个索引，到底了 print(\"Subset:\", current_subset) return # 包含当前字符的情况 print_subsets(word, i + 1, current_subset + word[i]) # 不包含当前字符的情况 print_subsets(word, i + 1, current_subset) # 示例 print_subsets('abc') 打印一个字符串的全部排列 def print_permutations(word: str, current: str = \"\"): if not word: # base case 不剩字符了，打印 print(current) return for i in range(len(word)): remaining_chars = word[:i] + word[i + 1:] # 去掉当前字符，还剩哪些字符 print_permutations(remaining_chars, current + word[i]) # 示例 print_permutations('abc') 打印一个字符串的全部排列，要求不要出现重复的排列 def print_unique_permutations(s, current=\"\"): if not s: print(current) return for i in range(len(s)): if i > 0 and s[i] == s[i - 1]: continue remaining_chars = s[:i] + s[i + 1:] print_unique_permutations(remaining_chars, current + s[i]) # 示例 input_string = \"aab\" sorted_input = ''.join(sorted(input_string)) # 对输入字符串排序 print_unique_permutations(sorted_input) 拿牌问题 给定一个整型数组arr，代表数值不同的纸牌排成一条线。玩家A和玩家B依次拿走每张纸牌，规定玩家A先拿，玩家B后拿，但是每个玩家每次只能拿走最左或最右的纸牌，玩家A和玩家B都绝顶聪明。请返回最后获胜者的分数。 【举例】 arr=[1,2,100,4] 开始时，玩家A只能拿走1或4。如果开始时玩家A拿走1，则排列变为[2,100,4]，接下来玩家 B可以拿走2或4，然后继续轮到玩家A... 如果开始时玩家A拿走4，则排列变为[1,2,100] ，接下来玩家B可以拿走1或100，然后继续轮到玩家A... 玩家A作为绝顶聪明的人不会先拿4，因为拿4之后，玩家B将拿走100。所以玩家A会先拿1，让排列变为[2,100,4] ，接下来玩家B不管怎么选，100都会被玩家A拿走。玩家A会获胜，分数为101。所以返回101。 arr=[1,100,2]开始时，玩家A不管拿1还是2，玩家B作为绝顶聪明的人，都会把100拿走。玩家B会获胜，分数为100。所以返回100。 解题思路： 先手函数：先手拿在L到R上返回最大分数，first(arr, L, R) base case：L==R, return arr[L] 拿左：arr[L] + second(arr, L+1, R) 拿右：arr[R] + second(arr, L, R-1) 作为聪明人：max(拿左分数，拿右分数) 后手函数：sec(arr,L, R) base case：L==R, return 0，只有一个数了，但是被别人拿走了，就没了，返回0 别人拿走了L，first(arr, L+1, R) 别人拿走了R，first(arr, L, R-1) 但是这是对方决定的，别人会给最差的情况，所以min(拿左分数，拿右分数) def win(arr): if not arr: return 0 return max(first(arr, 0, len(arr) - 1), second(arr, 0, len(arr) - 1)) def first(arr, left, right): if left == right: return arr[left] return max(arr[left] + second(arr, left + 1, right), arr[right] + second(arr, left, right - 1)) def second(arr, left, right): if left == right: return 0 return min(first(arr, left + 1, right), first(arr, left, right - 1)) print(win([1, 2, 100, 4])) 给你一个栈，请你逆序这个栈，不能申请额外的数据结构，只能使用递归函数。如何实现? def reverse_stack(stack): \"\"\" 逆序栈 bottom = get_stack_bottom() = 3, reverse_stack bottom = get_stack_bottom() = 2, reverse_stack bottom = get_stack_bottom() = 1, reverse_stack stack为空, return bottom = 1 压回去 bottom = 2 压回去 bottom = 3 压回去 :param stack: :return: \"\"\" if not stack: return bottom = get_stack_bottom(stack) reverse_stack(stack) stack.append(bottom) def get_stack_bottom(stack): \"\"\" 获取栈底元素 [3, 2, 1] fn(1) result=1, last = fn(2) fn(2) result=2, last = fn(3) fn(3) result=3, 栈为空，返回 回到 fn(2) 的 last=fn(3)=3, 把result=2, 压回栈，返回 last = 3 回到fn(1) 的 last=fn(2)=3, 把result=1, 压回栈，返回 last = 3 最后结果 3 :param stack: :return: \"\"\" result = stack.pop() if not stack: return result last = get_stack_bottom(stack) stack.append(result) return last data = [3, 2, 1] reverse_stack(data) print(data) 数字字符串转换 规定1和A对应、2和B对应、3和C对应... 那么一个数字字符串比如\"111\"，就可以转化为\"AAA\"、\"KA\"和\"AK\"。给定一个只有数字字符组成的字符串str，返回有多少种转化结果。 0~i-1位置是确定下来，在i往后有多少种 i==0：如果是0那接下来有0种，比如0111，0字符没有对应的字母，所以往后都没对应的01、011、0111字母字符 1 3 ：单独i位置做转换，一定没法做的转换是i 和i+1一起做转换 i == 1： 单独i位置做转换 i 和i+1一起做转换，i+2之后做转换 i == 2 单独i位置做转换 i + i+1 i 和i+1一起做转换，i+2之后做转换 def transform(word, i=0): if i == len(word): # base case 走到底了 return 1 if word[i] == \"0\": return 0 elif word[i] == \"1\": cnt = transform(word, i + 1) # 单独 i 作转换，后续还有多少种 if i + 1 背包价值问题 给定两个长度都为N的数组weights和values，weights[i]和values[i]分别代表i号物品的重量和价值。给定一个正数bag，表示一个载重bag的袋子，你装的物品不能超过这个重量。 返回你能装下最多的价值是多少？ def bag_value(weights, values, bag, i=0, already_weight=0): if already_weight > bag: # 超重，因为加上了i位置货物导致超重，所以需要减去i上一个的i-1位置的货物价值 return -values[i - 1] if i == len(weights): # 没货了，比如weight为空 return 0 i_no_need = bag_value(weights, values, bag, i + 1, already_weight) # i货不要 # i货要，这里加了价值，但是加了以后，超重了，所以上面需要减掉 i_need = values[i] + bag_value(weights, values, bag, i + 1, already_weight + weights[i]) return max(i_need, i_no_need) weights_data = [1, 2, 3] values_data = [1, 2, 3] print(bag_value(weights_data, values_data, 3)) "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/01-哈希函数和哈希表.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/01-哈希函数和哈希表.html","title":"哈希函数和哈希表","keywords":"","body":"datetime:2024/02/04 10:54 author:nzb 哈希函数与哈希表 不用深入研究，底层的数学挺难的 掌握哈希函数的特点和用法就行了 认识哈希函数和哈希表的实现 哈希函数的特点 1、输入域是无穷的，输出域是相对有限的 函数out = fn(in) 输入域in： 标准是无穷的∞，（当也可以有限），什么叫无穷的，比如可以接收任意长度的字符串 输出域out：比如一个S域 （输出域很大但一定是有穷尽的） md5的返回值范围：0~2^64-1 sha1的返回值范围：0~2^128-1 种子码： ea089d31f 这是一个16进制的数 每一位的范围是 0~9+a~f 16个状态 MD5算法和SHA1算法返回的是某一个字符串，字符串的每一位字符有16种情况, 代表一个16进制的数,这个16进制数的范围，如果是MD5，那么这个16进制数的范围在 0~2^64-1， 如果是SHa1，那么这个16进制数的范围在 0~2^128-1 , 对于md5码来说他会返回一个长度为16的字符串,一个位表示16种状态，正好是2^64(=16^16)；如果是SHA1返回的字符串,字符串长度就是32，每一位有16种状态， 一共是2^128(=16^32)种情况 2、一个哈希函数，如果相同的输入参数，一定会返回相同的输出值 same in ==> same out 哈希函数内部没有任何随机的成分 3、由于输入是无限的，输出是有限的，则会有不同的输入对应相同的输出 dif in ==> same out 哈希碰撞 产生的原因 4、离散性、均匀性 离散性是指相似输入会导致完全不一样的输出，也就是说不会存在输入相邻的两个数，输出相邻两个数的情况，比如一个圆，会分散开，不会靠在一起； 均匀性是指所有产生的哈希值完全均匀的分布在整个域中，也就是给出大量相似数据，并计算哈希值，哈希值一定是均匀分布在整个域上的，不会大量聚集在某一处。 在一个圆的域，随便框一个区域点的数量是差不多的 实例应用上基本原理 in1 --f--> out1 --%m--> m1 in2 --f--> out2 --%m--> m2 in3 --f--> out3 --%m--> m3 in4 --f--> out4 --%m--> m4 m的范围是0~m-1之间 out在S域范围内，S域范围太大了，模m可以将范围缩小，输出能再S域上均匀分布，模完m也能在`0~m-1`上均匀分布 哈希函数的使用示例 题目描述： 有一个大文件，这个文件里面都是无符号的整数，每个整数的范围0~2^32-1 (== 0~42亿); 这样的数在这个大文件中有40亿个 如果只给你1G的内存,返回出现次数最多的数是哪一个? 传统使用哈希表解决该问题 设计一个哈希表，key（int）是大文件中的某一个数，value（int）表示这个数出现的次数用1G内存设计一个哈希表，统计每个数出现的次数，最后返回 特殊情况预测： 假设大文件中40亿个数都不一样，那么哈希表需要存储40亿条记录，每条记录(两个int，(key,value))是8个字节(假设没有索引空间浪费)最差情况需要320亿个字节的存储空间， 即32GB >> 1GB所以该种设计存在内存爆掉的情况 哈希函数和哈希表解法 第一步 有40亿个数，a1,a2,a3,a4……an 然后给每一个数调用一下哈希函数，产生一个输出, 即每个数的哈希值 为 b1,b2,b3……bn 然后给每一个数模100,得到 m1,m2,m3……mn 第二步 通过此过程可以知道：取模后的数m在0~99之间 这个过程可以看做将一个大文件中的内容，分配到一些小文件里面去 假设a1这个数调用哈希函数，得到的函数值模上100,得到m1=17，那么我们将a1分配在17号文件上 同理假设a2这个数调用哈希函数，得到的函数值模上100,得到m2=3，那么我们将a2分配在3号文件上 …… …… …… 第三步 根据刚才的分析，假设不同的数有40亿种，依据哈希函数的性质，我们可以认为0~99号文件中，每个文件含有不同种类的原始的数。 每个小文件中，原始数的种类数是差不多的（由哈希函数的离散性和均分性可得),可能不是正好均分，但是也差不多。 根据哈希函数的特性：相同的数一定会发送到相同的小文件中，此过程将不同种类的数几乎均匀分配到100个小文件中去 第四步 接下来，对于每一个小文件，使用哈希表进行统计此时，每一个小文件最多使用的存储空间是32GB/100， 这样内存是不会爆的 这样下来，每一个小文件中会出现一个次数出现最多的数, (相同的数肯定只出现在1个文件中，哈希函数的第二个特性) 第五步 对每个小文件出现次数最多的数进行统计，然后将这个小文件的内存空间释放掉，统计下一个小文件的情况。 我们将统计出的每个小文件中出现次数最多的数再进行比较，最终会得到一个出现次数最多的数。 总结： 利用哈希函数，让我们在数的种类上做到均分,然后我们再对每一个小文件进行分别的统计,统计完一个小文件，我们将小文件的内存释放掉，去统计下一个小文件,周而复始，我们将会统计完，最后通过比较，输出出现次数最多的数 哈希表 哈希表也叫散列表，哈希表是一种数据结构，它提供了快速的插入操作和查找操作，无论哈希表总中有多少条数据，插入和查找的时间复杂度都是为O(1)，所以哈希表的查找速度非常快。 哈希表的实现原理：先定义一个哈希表，假设该哈希表有17个空间（0~16）。将所要存储的字符串过一遍哈希函数，得到哈希值out1；然后将哈希值out1除以17取模， 假设模为7，那么将这个字符串用单向链表(也有可能是有序数组) 的方式串联在7号空间上，不怕存在碰撞，因为是用单向链表串起来。因为哈希函数的均匀性，所以每个空间后面串联的结点数也是均匀的。 如果哈希表的每个空间中都串联了大量结点，这样会严重影响查找速度（因为要遍历结点）。所以当链的长度到达一个值k后，将哈希表扩容一倍（34个空间）。 扩容过程的时间复杂度是O(logN)，当k的值越大，时间复杂度越趋近于O(1). 如果有N每次扩容需要重新算一遍前面的数的哈希值，需要O(N)，所以总扩容时间复杂度O(NlogN)，单次扩容代价实际是O(logN)，可以把链的长度k定为10，遍历10次很快，可以认为是O(1) ，还可以减小扩容代价，所以可以认为逼近O(N) 设计RandomPool结构 【题目】 设计一种结构，在该结构中有如下三个功能: insert(key):将某个key加入到该结构，做到不重复加入 delete(key):将原本在结构中的某个key移除 get_random(): 等概率随机返回结构中的任何一个key。 【要求】insert、delete和get_random方法的时间复杂度都是O(1) 解题思路 针对insert我们可以实现一个字典一个列表同步操作，一个插入(key, index)，另外一个插入key，然后使用size计数即可，保持同步。 针对get_random，虽然Hash表返回的是近似等概率的，但是不是严格等概率的，所有我们利用随机数得到一个索引然后取key。 针对delete操作，我们确实可以直接在(key, index)进行操作，但是这样我们在使用get_random函数之后它会产生空洞了(空洞会影响随机数生成)，所以一种思路就是我们可以借助列表最后一个元素 进行赋值给需要删除的key，这样就可以消除空洞。 import random class RandomPool: def __init__(self): self.key_index = {} self.index_key = [] def insert(self, key): if key not in self.key_index: self.key_index[key] = len(self.index_key) self.index_key.append(key) def delete(self, key): if key in self.key_index: index = self.key_index[key] # 需要删除的键的索引 last_key = self.index_key[-1] # 最后一个键 # 交换和删除最后一个键 self.index_key[index], self.index_key[-1] = self.index_key[-1], self.index_key[index] self.key_index[last_key] = index # 最后一个key代替到要删除的位置 # 删除对应键和索引 self.key_index.pop(key) self.index_key.pop() def get_random(self): if self.index_key: index = random.randint(0, len(self.index_key) - 1) return self.index_key[index] 详解布隆过滤器 布隆过滤器（Bloom Filter）实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。 优点： 可以高效地进行查询，可以用来告诉你“某样东西一定不存在或者可能存在” 可以高效的进行插入（但是不能删除） 相比于传统的List、Set、Map等数据结构，它占用空间更少，因为其本身并不存储任何数据（重点） 适用于海量数据的查找（亿量级） 缺点： 不能提供删除操作 存在失误概率：将白名单中的内容误认为是黑名单中的（反之则不可能失误）。 例如：网络爬虫程序，为了不去爬相同的URL页面，需要记录下所有爬过的URL（极大数据量），在爬一个新的网页时，判断是否已经爬过。 实现原理 定义一个m长度的位图(bitmap)。 将每个URL分别通过K个不同的哈希函数，并除以m取模，将得到的所有值都在位图上表示出来。（例如得到1，2，4，6……那么位图的1，2，4，6……空间上都涂黑。如果已经涂黑了则不进行操作）。 当查验一个URL是否在表上时，先将该URL通过K个哈希函数，并除以m取模，如果得到的所有值都在哈希表上被涂黑了，那么这个URL在表上。（例如得到1，2，4，6……但位图第6位空间未被涂黑，说明此URL不在表上）。 重点在于如何确定m和K的值(都向上取整)。 m = -{n * lnP \\over (ln2)^2} (其中n为样本量，P为预计失误率，ln以e为底) K = ln2 * {n \\over m} (其中n为样本量，m为空间，可以多申请一些，比如26G，申请28G或32G) P = (1- e ^{-n*K \\over m}) ^ K (其中P为实际失误率) 当m(位图)过小，容易描满，就会出现失误率，白的误判为黑的，失误率与m的关系图，随着m的增大，失误率下降趋势，最后逐渐缓慢逼近0 当K(哈希函数)过多时，也容易全部描黑，失误率和K的关系图，随着K的增大，失误率先下降，然后到达一个K值后最低，之前随着K值增大，失误率逐渐增大 # python int 类型的大小是可变的 # 假设 4 bytes arr = [0] * 10 # (4 * 8bit) * 10 = 320 bits i = 178 # 想取178bit的状态 arr_index = i // 32 # 定位在数组哪一个数上 bit_index = i % 32 # 第几位 # 提取状态 # arr[arr_index] >> bit_index 178 移到最右边 # & 1 提取状态 status = (arr[arr_index] >> bit_index) & 1 # 修改状态为1 arr[arr_index] |= 1 详解一致性哈希原理 逻辑服务器(查数据库的程序)对数据分布无要求，但数据服务器如何组织需要讨论。 可以利用哈希函数，再模上数据服务器个数，得到存到哪个数据服务器中，这样可以有效保证了每个数据服务器存储数据量的平均性。 为了保证数据服务器的负载均衡，哈希函数的key应该选择高频、中频、低频较为均匀的数据类型，而不是发布不均匀的，比如性别，国家等 逻辑端可以自由增加机器，但数据服务器增加时，经典方法需要改变模值，数据迁移的代价是全量的。 因此需要用到一致性哈希。将哈希的输出值域想象成一个环，设有3台机器，则有对应的三个哈希值。找到最近的哪个大于等于输入信息对应的哈希值的机器（顺时针最近的那台），如果没有则为机器1. 易知，如果增加机器/减少机器，数据迁移的代价很小。 问题1：机器不能做到将数据均分 问题2：增加/减少机器后，即使原先负载均衡，加入后也不均衡 解决方法（一致性哈希） 一致性哈希算法是对2^32取模 圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1,也就是说0点左侧的第一个点代表2^32-1 我们把这个由2的32次方个点组成的圆环称为hash环。 三台服务器肯定有自己的IP地址，我们使用它们各自的IP地址进行哈希计算，使用哈希后的结果对2^32取模 一致性哈希的优点： 假设，服务器B出现了故障，我们现在需要将服务器B移除，那么，我们将上图中的服务器B从hash环上移除即可，移除服务器B以后示意图如下。 在服务器B未移除时，数据3应该被缓存到服务器B中，可是当服务器B移除以后，按照之前描述的一致性哈希算法的规则，数据3应该被缓存到服务器C中， 因为从数据3的位置出发，沿顺时针方向遇到的第一个缓存服务器节点就是服务器C，也就是说，如果服务器B出现故障被移除时，数据3的缓存位置会发生改变 但是，数据4仍然会被缓存到服务器C中，数据1与数据2仍然会被缓存到服务器A中，这与服务器B移除之前并没有任何区别，这就是一致性哈希算法的优点， 如果使用之前的hash算法，服务器数量发生改变时，所有服务器的所有缓存在同一时间失效了，而使用一致性哈希算法时，服务器的数量如果发生改变， 并不是所有缓存都会失效，而是只有部分缓存会失效，前端的缓存仍然能分担整个系统的压力，而不至于所有压力都在同一时间集中到后端服务器上。 存在的问题：服务器分布不均匀，造成服务器忙闲负载不同。 解决方法：虚拟节点计数 给每个机器分配1000个字符串，让这1000个字符串去抢环。通过设置不同比例的字符串抢环，若增加机器，则从已有机器中按比例抢数据(比如每台服务器10%)， 还能管理负载，即给稍微弱点的机器分配少点的节点，比如1号服务器性能好，可以分配2000个字符串，3号性能差，分配800个字符串 “虚拟节点”是”实际节点”（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。 从上图可以看出，A、B、C三台服务器分别虚拟出了一个虚拟节点，当然，如果你需要，也可以虚拟出更多的虚拟节点。引入虚拟节点的概念后，缓存的分布就均衡多了， 上图中，1号、3号数据被缓存在服务器A中，5号、4号数据被缓存在服务器B中，6号、2号数据被缓存在服务器C中，如果你还不放心，可以虚拟出更多的虚拟节点， 以便减小hash环偏斜所带来的影响，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。 去掉节点 m1服务器 {a1, a2, a3, ... a1000}字符串虚拟节点 m2服务器 {b1, b2, b3, ... b500, ... b1000}字符串虚拟节点 m3服务器 {c1, c2, c3, ... c1000}字符串虚拟节点 环上的顺序：a1 -> b1 -> c1 -> a2 -> b2 -> c2 -> ... -> b500 -> ... -> a1000 -> b1000 -> c1000 -> a1 比如去掉去掉b500，就需要把它管理的数据给a1000 岛问题 【题目】 一个矩阵中只有0和1两种值，每个位置都可以和自己的上、下、左、右四个位置相连，如果有一片1连在一起，这个部分叫做一个岛，求一个矩阵中有多少个岛? 【举例】 001010 111010 100100 000000 这个矩阵中有三个岛 【解题思路】遍历矩阵，若当前数值为1，则以当前元素为感染源，进行感染，并计数+1。感染过程即：递归查询当前元素的上下左右是否为1，若为1，则将数值改为2，否则直接返回。 def count_islands(data): if len(data) == 0: return 0 row = len(data) column = len(data[0]) cnt = 0 for i in range(row): for j in range(column): if data[i][j] == 1: cnt += 1 infect(data, i, j, row, column) return cnt def infect(data, i, j, row, column): if i = row or j = column or data[i][j] != 1: return # i, j 都不越界 data[i][j] = 2 # 感染 infect(data, i + 1, j, row, column) infect(data, i - 1, j, row, column) infect(data, i, j + 1, row, column) infect(data, i, j - 1, row, column) data = [[0, 0, 1, 0, 1, 0], [1, 1, 1, 0, 1, 0], [1, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0]] print(count_islands(data)) 时间复杂度，O(N*M)，大遍历阶段1次，感染阶段最多4次，上下左右各调用一次（如果给感染后会直接返回），所以每个位置被调用有限次数，不用思考这个位置调用几次，思考这个位置被调用几次 【进阶】如何设计一个并行算法解决这个问题，比如世界地图（面试中如果遇到并行算法的问题，由于代码会很复杂，往往只需要讲清楚算法，不需要写代码） 【解决思路】利用并查集 假设这个岛很大，需要多个CPU去计算。如下图，把岛分割成左右两边用两个cpu去计算，先分别统计分割完后每个矩阵中岛的个数， 和边界上的1是由谁感染（感染完是2，应该是统计2是由谁感染来的，图中用的是1，所以就描述1。且图中只分成了两份，只统计中间的边界，当分成很多份时，四个边界都统计）。 从上到下第一条绿色线划出来的两个1分别是会由图中圈出的A和C两个1感染成2，第二条绿色线的1会由B和C感染，第三条绿色线的1也会由B和C感染。 这时候就要用并查集了，先把要去重的两个矩阵的岛的个数相加，左边是2，右边是1，所以是3。然后把边界上的每对1各自的感染源全部放入并查集初始化， A、B、C分别在一个集合里，然后每对1分别看两个感染源是不是同一个。第一对的感染源是A和C，不是同一个集合，岛的总数量-1，变成2，把A和C所在的集合合并。 看第二对1，感染源是B、C，不是同一个集合，岛的总数量-1，变成1，把B和C所在的集合合并。最后看第三对1，感染源是B、C，是同一个集合，岛的总数量不变。 至此边界上所有对1都统计完了，这两个矩阵合并的岛的数量结果就是1。 并查集 什么是并查集 对于一个集合S={a1, a2, ..., an-1, an}，我们还可以对集合S进一步划分: S1,S2,...,Sm-1,Sm，我们希望能够快速确定S中的两两元素是否属于S的同一子集。 举个栗子，S={0，1, 2, 3, 4, 5, 6}，如果我们按照一定的规则对集合S进行划分，假设划分后为S1={1, 2, 4}，S2={3, 6}，S3={0, 5} ，任意给定两个元素，我们如何确定它们是否属于同一子集？某些合并子集后，又如何确定两两关系？基于此类问题便出现了并查集这种数据结构。 并查集有两个基本操作： is_same_set: 查找两个元素是否属于同一个集合 union：合并两个子集为一个新的集合 经典结构实现并查集的不足之处 链表实现并查集，union方法会很快，可以达到O(1)，但是 is_same_set 需要遍历链表，做不到O(1) 哈希表实现并查集 is_same_set 方法会很快，可以达到O(1)，但是union方法需要把一张表里的所有元素重新加到另一张表里去，做不到O(1) is_same_set方法和union方法做到几乎都是O(1)的结构 数据结构使用一个向上指的图： 初始时每个元素自己外部包一层，有个指针指向自己。 调用 is_same_set 方法时，两个元素都通过指针往上走，一直走到不能再往上所找到的点，叫做集合的代表元素，如果两个元素找到的集合代表元素相同，则两个元素属于同一个集合。 - 调用union方法时，首先用is_same_set方法判定是否是同一个集合，如果不是，则两个元素向上走，找到各自集合的代表元素，之后比较两个集合元素个数的多少，少的那个集合的集合代表元素的指针指向多的那个集合的集合代表元素，这样就完成了union 路径压缩：并查集向上找集合代表元素过程的优化 如果 is_same_set 方法只做查找操作，那么由于union的频繁使用，链会越来越长，这样查找的效率就会越来越低。is_same_set 方法在查找的过程中，每找到一个集合代表元素， 就把发起查找的元素的指针重新指向它的集合代表元素，这样就可以做到扁平化，如果这个元素下次再发起查找，那么往上走一步就可以找到集合代表元素。 并查集的时间复杂度 数学证明太复杂，单说结论：假设样本有N个，find_head函数调用次数如果逼近或超过O(N)，因为路径压缩扁平化，单次平均调用find_head的时间复杂度为O(1)，所以整体的时间复杂度也是O(1)。 代码实现 python __author__ = 'nzb' __date__ = '2024/1/13 16:23' __doc__ = '' class Element: # 数据包装一层 def __init__(self, value): self.value = value class UnionFindSet(object): def __init__(self, data_set): self.element_map = dict() self.father_map = dict() # key 某个元素 value 该元素的父 self.size_map = dict() # key 某个集合的代表元素， value 该集合的大小 for val in data_set: ele = Element(val) self.element_map[val] = ele self.father_map[ele] = ele self.size_map[ele] = 1 # 给定一个ele, 往上一直找，把代表元素返回 def _find_head(self, element): path = [] while element != self.father_map.get(element): # 当前元素为最顶部 path.append(element) element = self.father_map.get(element) while path: self.father_map[path.pop()] = element # 把沿路的所有元素指向最上面的元素，扁平化 return element def is_same_set(self, first, second): if first in self.element_map and second in self.element_map: return self._find_head(self.element_map.get(first)) == self._find_head(self.element_map.get(second)) return False def union(self, first, second): if first in self.element_map and second in self.element_map: fir_ele = self._find_head(self.element_map.get(first)) sec_ele = self._find_head(self.element_map.get(second)) if fir_ele != sec_ele: big_ele = fir_ele if self.size_map.get(fir_ele) >= self.size_map.get(sec_ele) else sec_ele small_ele = sec_ele if big_ele == fir_ele else fir_ele self.father_map[small_ele] = big_ele # 小的头部指向长 self.size_map[big_ele] = self.size_map.get(fir_ele) + self.size_map.get(small_ele) # 更新长度 self.size_map.pop(small_ele) # 移除 c++ class Element { public: Element(string value) { this->m_Value = value; } public: string m_Value; }; class UnionFindSet { public: UnionFindSet(list str) //初始化并查集的时候需要用户把所有的元素都传进来，这里采用了list的方式，也可以用其他方式 { for (auto value : str) { Element *temp = new Element(value); elementMap.insert(make_pair(value, temp)); fatherMap.insert(make_pair(temp, temp)); //初始时自己的父就是自己 sizeMap.insert(make_pair(temp, 1)); //初始时每个元素都是自己集合的代表元素，每个集合元素个数都是1 } } ~UnionFindSet() //由于并查集内部自己在用户传入的元素外包了一层，即用new在堆区开辟了空间，等并查集调用自己的析构函数时需要释放这些空间 { Element* temp = nullptr; for (auto element : elementMap) { temp = element.second; elementMap.erase(element.first); delete temp; temp = nullptr; } } public: bool isSameSet(string str1, string str2) { if (elementMap.count(str1) != 0 && elementMap.count(str2) != 0) { return findHead(elementMap.at(str1)) == findHead(elementMap.at(str2)); } return false; } void unionSet(string str1, string str2) { if (elementMap.count(str1) != 0 && elementMap.count(str2) != 0) { Element* small = nullptr; Element* big = nullptr; Element* head1 = findHead(elementMap.at(str1)); Element* head2 = findHead(elementMap.at(str2)); if (head1 != head2) { big = sizeMap.at(head1) > sizeMap.at(head2) ? head1 : head2; small = big == head1 ? head2 : head1; fatherMap.at(small) = big; sizeMap.at(big) += sizeMap.at(small); sizeMap.erase(small); } } } private: Element* findHead(Element* element) { Element* temp = element; stack path; while (temp != fatherMap.at(temp)) { path.push(temp); element = fatherMap.at(temp); } while (!path.empty()) { fatherMap.at(path.top()) = temp; path.pop(); } return temp; } private: unordered_map elementMap; //key代表用户传入的元素，value代表外面包了一层的元素 unordered_map fatherMap; //key代表元素，value代表这个元素的父节点 unordered_map sizeMap; //key代表一个集合的代表元素，value代表这个集合中有多少个元素 }; "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/02-字符串匹配算法.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/02-字符串匹配算法.html","title":"字符串匹配算法","keywords":"","body":"datetime:2024/2/24 16:49 author:nzb 字符串匹配算法 KMP算法 字符串str1和str2，str1是否包含str2，如果包含返回str2在str1中开始的位置。如何做到时间复杂度O(N)完成？ 问题引入：首先我们来看一个例子，现在有两个字符串A和B，问你在str1中是否有str2，为了方便叙述，我们先给定两个字符串的值 A=\"abcaabababaa\" B=\"abab\" 暴力解法 首先我们能想到规定头指针，并依次向后比较的暴力方法 从主串s的第一个字符开始，与模式串m的第一个字符比较，若相等，则继续逐个比较后序字符； 否则从主串下一个字符起，重新和模式串的第一个字符开始比较 在暴力匹配中，每趟匹配失败都是模式后移一位再从头开始比较，这种频繁的重复比较相当于模式串在不断地进行自我比较，这是低效的根源。 KMP算法 在讲KMP算法之前我们需要先介绍最长前缀和后缀匹配长度 1、前缀和后缀最长匹配长度 前缀：指除了最后一个字符以外，字符串所有头部子串(以头部字符开始) 后缀：指除了第一个字符(当前字符)以外，字符串所有尾部子串(以尾部字符结束) 下面以字符abbabbk为例进行说明k字符为例： 长度为1时：前缀：a, 后缀：b, 最长匹配长度为0 长度为2时：前缀：ab, 后缀：bb, 最长匹配长度为0 长度为3时：前缀：abb, 后缀：abb, 最长匹配长度为3 长度为4时：前缀：abba, 后缀：babb, 最长匹配长度为0 长度为5时：前缀：abbab, 后缀：bbabb, 最长匹配长度为0 长度为6时：就是整个子串，不考虑 所以k字符的最长前缀和后缀匹配长度为3 2、next数组 基于前缀和后缀最长匹配长度的计算，我们需要算出m字符串每一个字符之前对应的信息，将这些信息用数组next[]存储起来 以aabaabs为例：next[]={-1, 0, 1, 0, 1, 2, 3} 元素还有另外一层作用就是要调到元素的索引，比如长度为3，索引是0~2，下一个元素索引就是3 人为规定，第一个元素长度为-1，第二个元素长度为0 3、KMP算法 图解： 当str1和str2匹配到第11位时出现了不相等的情况，此时str1的i指针不动，str2的j指针指向该字符对应最长匹配长度的下一位即j=5 再将此时i和j指向的字符进行比较 我们可以将该过程理解为将str2往右移i-j位，str2在j之前的字符已经匹配，不用再进行比较。 该过程的实质是： 1、将str2推到j位置开头，并从可能不相等的位置往下走 2、str1从0开始到j之前不存在任何一个位置能配出str2，注意是整个str2 为啥不存在呢，跟next数组含义有关，利用反证法证明 str1 = i ............... k ........... | j........... x str2 = 0 ..匹配长度....|................| ....匹配长度.. y 假设 j~x 是最长前缀和后缀匹配长度 假设中间任意一个位置k，能配出整个str2，注意是整个 那么从k出发到x之前这一段，必须跟str2等量的区域(或前缀)一样才行，为什么，因为从str1和str2一路相等，到x和y位置才不等的 那就说明k~x之前的字符串等于str2的等量的前缀，那就找到了一个更长的匹配长度，跟next数据冲突了 只要理解了这两个实质，该算法就基本上理解了。 示例 index 0123456 78 9 10 11 12 13 14 15 16 str1 = abbsabb tc a b b s a b b e str2 = abbsabb tc a b b s a b b w 比对到16，e != w 继续，此时str2 最长前缀为7，str2 回退到位置 7，str1位置还是16，相当于从str1的位置9和str2开始比对，此时，e != t 继续，此时str2 最长前缀为3，str2 回退到位置 3，str1位置还是16，相当于从str1的位置13和str2开始比对，此时，e != s 继续，此时str2 最长前缀为0，str2 回退到位置 0，str1位置还是16，相当于从str1的位置16和str2开始比对，此时，e != a 此时不能往前退了，str1位置加1，从17位置开始和str2开头开始比对 代码 def kmp(str1, str2): if not str1 or not str2 or len(str1) 0: cn = next_arr[cn] else: next_arr[idx] = 0 return next_arr 时间复杂度 暴力解法的时间复杂度为：O(m*n)，其中m为str2的长度，n为str1的长度 KMP算法的时间复杂度为：O(m+n)，其中m为计算next数组的时间复杂度，n为KMP进行匹配时的时间复杂度 Manacher 算法 又称“马拉车算法”，主要用于求解最长回文子串的长度 经典最长回文子串长度求法 从字符串的每个字符开始，向左右两边扩，算出以每个字符为中心的回文子串的长度，然后取最大值。 但是用这种方法只能算出奇回文子串的长度，无法算出偶回文子串的长度，如下图所示，这是一个长度为 4 的回文串，但用上面的方法没办法算出它的长度，因为上面的方法是以一个字符为中心算长度，但是偶回文子串的中心并不是一个字符。 为了可以计算出偶回文子串的长度，我们可以对字符串做一些变化，把 “abba” 变成 “#a#b#b#a#” ，然后按照上面的方面再计算一次，就可以算出来了，最大值除以 2 向下取整就是最长回文串的长度。 这里是在原字符串的每个字符前后加了特殊符号 “#”，但其实这个特殊符号加什么都行，只是为了方便，就算原字符串中本来就有 “#” 也不会有影响，因为我们可以发现在比较的时候原字符只会与原字符进行比较，特殊字符只与特殊字符比较。 整个过程的时间复杂度为 O(N^2)，例子#1#1#1#1#1#1#1#1#，遍历走一遍，然后比较走到某一端 Manacher 算法 与 KMP 有点类似，就是对经典的算法做一个加速 几个重要的概念 以字符串#a#b#b#a#b#b#a#为例 回文半径：从中心字符到回文子串结束的距离，如回文子串 #a# 的回文半径就是 2，#a#b#b#a# 的回文半径是5 回文半径数组 pArr：与 KMP 的 next 数组有点类似，回文半径数组存放的是每个字符对应回文子串的半径 最右回文右边界 R：之前所有的回文子串的最右的边界 最右回文右边界的中心 C：即最右回文有边界对应的回文串的中心位置 Manacher算法流程 主要是计算回文半径数组 pArr，分为两种情况 1）下一个字符的位置 i 不在 R 里，这种情况 R 直接暴力往右扩，且以这个字符为中心的回文子串的长度至少为 1 2）下一个字符的位置 i 在 R 里，找到 i 相对于 C 的对称点 j，这时又分为三种情况，记 R 相对于 C 的字符为 L，[L...j...C...i...R]即为以 C 为中心最长回文子串 ① j 为中心的整个回文子串（下面称 j 回文子串）在 [L......R] 里，那么 i 为中心的回文子串（下面称 i 回文子串）半径与以 j 回文子串半径相等 ② j 回文子串部分在 [L......R]里，那么 i 回文子串半径为 R - i ③ j 回文子串的左边界正好等于 L，那么 i 回文子串半径至少为 R - i，然后继续往外扩 证明，主要证 2）部分，前面2中不用试就知道答案，第3种情况需要去试才知道会不会更长 ①如示例：[L..x(..j..)y..C..p(..i..)q..R]，j 左右的小括号区域（下面称为 j 区域）代表 j 回文子串 ，因为 L 到 R 是以 C 为中心的最长回文子串，所以 i 左右的小括号区域 （下面称为 i 区域）与 j 区域一定是互相逆序的，又因为 j 区域是回文子串，所以 i 区域也是回文子串。那么如何确定它是最大呢？ 我们假设 x 是以 j 回文子串前一个字符，y 是后一个字符，p、q同理分别为以 i 回文子串前一个和后一个字符，我们假设刚才的回文子串不是最大， 那么p 和 q 必是相等的，按照回文串的性质，p和y相等(因为L~R关于C对称)，q和x 相等，则x 和 y 一定是相等的，但是 j 回文子串是不包括 x 和 y 的， 也就是说 x 和 y 不可能相等，即 p 和 q 不可能相等，假设不成立，所以 i 回文子串半径一定与 j 回文子串半径相等。 ② j 回文子串不全在 [L...R] 里，部分超出，如示例：..(x[L..j..L'y)..C..pR'..i..R]q..，找到 L 相对于 j 的对称点 L' ，由回文串的性质可知，[L..j..L'] 一定是回文子串， 所以与之对应 [R'..i..R] 也是回文串，所以 i 回文子串的半径最小是 R - i。那有没有可能更大呢？不可能。 x 是 L 的前一个字符， y 是 L' 的后一个字符，p 是 R' 的前一个字符，q 是 R 后一个字符。i 回文子串半径要想更大，就需要 p 和 q 相等， 我们现在已知 x 和 y 都属于 j 回文子串，所以 x 和 y 相等，y 和 p 相等，即 x 和 p 相等，因为以 C 为中心的最长回文子串的左右边界是 L 和 R， 所以 x 和 q 是不可能相等的，结合起来就是 p 不可能等于 q，所以 i 的回文子串半径最大为 R - i。 ③ j 回文子串的左边界正好等于 L，如示例：[(L..j...)..C.p(...i..R)]q，首先我们可以肯定 i 回文子串至少是 R - i，至于能不能继续扩大，就需要看 p 能不能等于 q， 从图中可以看出，与前面两种情况不同，p 等不等于 q，并不会破坏 j 回文子串和以 C 为中心的回文子串，所以 p 是可以等于 q 的，如果 p 等于 q， 那么 R 往右扩， i 回文子串半径 +1，直到不能继续向右为止。 时间复杂度O(n) 具体分析过程，可以看左神的视频讲解 def manacher(str_data): if not str_data: return 0 # 用特殊字符拼接 str_new = \"#\" + \"#\".join(list(str_data)) + \"#\" p_arr = [1] * len(str_new) # 回文半径数组 c = -1 # 中心 r = -1 # 回文右边界的再往右一个位置 最右的有效区是R-1位置 max_val = float(\"-inf\") # 扩出来的最大值 for i in range(len(str_new)): # 每个位置都求回文半径 # p_arr[i] 表示至少的回文区域，就是我们不用验证就知道有多少的区域 # 2 * c - i 就是 j 的位置，也就是i关于 c 对称的位置，则 p_arr[2*c-i]就是j和i的回文半径 \"\"\" * 同时满足上面的两类情况 * 1）如果 R i，即 i 在 R 里，那么 * 为什么取两者的较小值呢？ * 首先三种情况： * 如果 j 回文子串完全在 C 回文子串里，那么 i 回文子串半径就是 p_arr[2 * C - i]，因为包含所以 R - i >= p_arr[2 * C - i]，即至少不用验证 min(p_arr[j], R - i)，选 p_arr[2 * C - i] * 如果 j 回文子串在部分在 C 回文子串里，那么 i 回文子串半径就是 R - i，因为C的回文到R，所以 R - i i else 1 \"\"\" 主要针对 R -1: if str_new[i + p_arr[i]] == str_new[i - p_arr[i]]: p_arr[i] += 1 else: break if (i + p_arr[i]) > r: r = i + p_arr[i] c = i max_val = max(max_val, p_arr[i]) # max 中包括是 # 字符的半径，max - 1正好是原回文串的长度 # #1#2#1#，回文半径2#1#，长度是4，除去拼接的#实际是121，长度为3 # #a#b#b#a#，回文半径#b#a#，长度5，除去拼接的#实际是abba，长度为4 return max_val - 1 print(manacher(\"121\")) print(manacher(\"abba\")) 注意，manacher能解决回文串的问题，但不仅于此，回文半径数组的信息能帮你解决好多回文问题，解决回文字符串只是它的一种形式 "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/03-滑动窗口-单调栈-非常重要.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/03-滑动窗口-单调栈-非常重要.html","title":"滑动窗口-单调栈","keywords":"","body":"datetime:2024/2/28 10:24 author:nzb 滑动窗口-单调栈 非常重要，非常重要，非常重要 滑动窗口 窗口只能右边界或左边界向右滑的情况下，维持窗口内部最大值或者最小值快速更新的结构 窗口内最大值与最小值更新结构的原理与实现 由一个代表题目，引出一种结构(滑动窗口) 【题目】 有一个整型数组arr和一个大小为w的窗口从数组的最左边滑到最右边，窗口每次向右边滑一个位置。 例如，数组为[4,3,5,4,3,3,6,7]，窗口大小为3时: [4 3 5]4 3 3 6 7 窗口中最大值为5 4[3 5 4]3 3 6 7 窗口中最大值为5 4 3[5 4 3]3 6 7 窗口中最大值为5 4 3 5[4 3 3]6 7 窗口中最大值为4 4 3 5 4[3 3 6]7 窗口中最大值为6 4 3 5 4 3[3 6 7] 窗口中最大值为7 如果数组长度为n，窗口大小为w，则一共产生n-w+1个窗口的最大值。 请实现一个函数。 输入:整型数组arr，窗口大小为w。 输出:一个长度为n-w+1的数组res，res[i]表示每一种窗口状态下的以本题为例，结果应该返回{5,5,5,4,6,7}。 from collections import deque def get_max_window(arr, w): if not arr or w = w - 1: # 到达窗口要求，更新窗口最大值 res[idx] = arr[dq[0]] idx += 1 return res print(get_max_window([4, 3, 5, 4, 3, 3, 6, 7], 3)) 给定一个数组arr,给出数组中窗口的边界L和R，用最小代价求出数组L到R位置中的元素最大值(或最小值)。 思路分析 借用一个双端队列(头尾都可以进出)，队列只存储数组中元素的索引，不断滑动更新窗口，调正双端队列中元素的值，使其永远保证从大到小的顺序(单调栈)(最大值，最小值的话保证从小到大的顺序)。 如果数组的右指针向右移动，则将元素按照添加条件(双端队列为空或小于尾部元素)添加到双端队列尾部。 这个如果待添加的元素>=双端队列尾部的值，则不断弹出队列尾部元素(弹出的元素，永远的丢弃了)，直到满足由大到小的条件，注意相等也要弹出 如果数组的左指针向右移动，则检查队列头索引与当前左指针是否一致，如果一致则弹出。 任何一个时刻，窗口最大的值都是双端队列的头部元素 复杂度： - 时间复杂度：O(N)，注意虽然是两层循环，但元素只从滑动窗口尾部进，从头部清除，只是顺序扫描了一遍，每个元素都只进出队列一次，总的平均代价O(1)。 - 空间复杂度：O(N) ，这里利用两个滑动窗口分别保存最大值和最小值。 双端队列维持的是什么信息 比如[6, 5, 4, 3] 5 7，双端队列为[0, 1, 2, 3]，如果目前窗口不再往右扩，而只移动L，维持了谁会依次成为最大值这个信息 如果R再右移下，为啥4位置的5进来以后，前面的5,4,3都要弹出，因为下标比他们晚过期，值还比他们大，他们再也不可能成为最大值，相等也一样，因为下标晚，意味着过期晚 from collections import deque class WindowMax(object): \"\"\"黑盒，用户自己调\"\"\" def __init__(self, arr): self.L = -1 self.R = 0 self.arr = arr self.dq = deque() def add_num_from_right(self): if self.R == len(self.arr): return while self.dq and self.arr[self.dq[-1]] = self.R - 1: # 窗口形成，不移除 return self.L += 1 if self.dq[0] == self.L: self.dq.popleft() def get_max(self): if not self.dq: return self.arr[self.dq[0]] return None 单调栈 在数组中想找到一个数，左边和右边比这个数小(或大)、且离这个数最近的位置。如果对每一个数都想求这样的信息，能不能整体代价达到O(N)？需要使用到单调栈结构单调栈结构的原理和实现 如果你要找左边右边最近比你大的，栈的顺序从下往上应该是大->小 如果你要找左边右边最近比你小的，栈的顺序从下往上应该是小->大 idx = 0 1 2 3 4 5 6 arr = 5 4 3 6 1 2 0 对于无重复的数组 0索引入栈, [0] 4，1索引入栈，[0, 1] 3，2索引入栈，[0, 1, 2] 6>3，不满足单调栈结构，弹出索引2，右边比他大的是6，左边比他大的的栈的下一个元素4，[0, 1] 6>4，不满足单调栈结构，继续弹出索引1，右边比他大的是6，左边比他大的的栈的下一个元素5，[0] 6>4，不满足单调栈结构，继续弹出索引0，右边比他大的是6，左边比他大的的栈的下一个元素没有，[] 索引3入栈，[3] 1：索引4入栈，[3,4] 2>1：弹出索引4，左->6，右->2，索引5入栈，[3, 5] 0：索引6入栈，[3, 5, 6] 遍历完后，此时栈里元素还有[3,5,6]，进入清算阶段， 分别弹出，左->下一个元素(索引3没有)，右无 idx = 0 1 2 3 4 5 6 7 arr = 5 4 3 4 5 3 5 6 对于有重复的数组 ，单个索引变成一个索引链表(或索引数组) 0索引入栈，[0] 4，1索引入栈，[0, 1] 3，2索引入栈，[0, 1, 2] 4>3，弹出索引2结算，右边->4，左边->4，索引3入栈，因为相等跟1压在一起，[[0], [1,3]] 5>4，依次弹出[1,3], 1位置，左->下一个元素最右的0位置的5，右->4位置的5，接着3位置，左->下一个元素最右的0位置的5，右->4位置的5，4入栈压一起，[[0, 4]] 3，5索引入栈，[[0, 4], 5] 5>3，不满足单调栈结构，继续弹出索引5，右边->下一个元素最右的4位置的5，左边->5，索引6入栈压一起，[[0, 4, 6]] 6>5：依次弹出[0, 4, 6], 左->无，右->6，7入栈，[[7]] 遍历完后，此时栈里元素还有[[7]]，进入清算阶段， 分别弹出，左->没有，右->没有 由于每个数都是进栈一次出栈一次，所以复杂度为O(N)。 import typing class MonotonousStack(object): @staticmethod def get_near_less_no_repeat(arr): \"\"\"获取左右比他小的元素，无重复值\"\"\" res = [[typing.Any, typing.Any] for _ in range(len(arr))] # 左，右 stack = [] for i in range(len(arr)): while stack and arr[stack[-1]] > arr[i]: # 保持单调性，不满足的时候弹出，结算弹出元素 idx = stack.pop() left_less = stack[-1] if stack else None res[idx][0] = left_less res[idx][1] = i stack.append(i) # 清算 while stack: idx = stack.pop() left_less = stack[-1] if stack else None res[idx][0] = left_less res[idx][1] = None return res @staticmethod def get_near_less_repeat(arr): \"\"\"获取左右比他小的元素，有重复值\"\"\" res = [[typing.Any, typing.Any] for _ in range(len(arr))] # 左，右 stack = [] # [[0,1], [2]] for i in range(len(arr)): while stack and arr[stack[-1][-1]] > arr[i]: # 保持单调性，不满足的时候弹出，结算弹出元素 idx_list = stack.pop() # 取最后一个元素索引 # 取位于下面位置的列表中，最晚加入的那个索引 left_less = stack[-1][-1] if stack else None for idx in idx_list: res[idx][0] = left_less res[idx][1] = i if stack and arr[stack[-1][-1]] == arr[i]: stack[-1].append(i) else: stack.append([i]) # 清算栈内元素 while stack: idx_list = stack.pop() # 清算索引元素 # 取位于下面位置的列表中，最晚加入的那个索引 left_less = stack[-1][-1] if stack else None for idx in idx_list: res[idx][0] = left_less res[idx][1] = None return res print(MonotonousStack().get_near_less_no_repeat([5, 4, 3, 6, 1, 2, 0])) print(MonotonousStack().get_near_less_repeat([5, 4, 3, 4, 5, 3, 5, 6])) # [[None, 1], [None, 2], [None, 4], [2, 4], [None, 6], [4, 6], [None, None]] # [[None, 1], [None, 2], [None, None], [2, 5], [3, 5], [None, None], [5, None], [6, None]] 单调栈题目 定义：正数数组中累积和与最小值的乘积，假设叫做指标A。给定一个数组，请返回子数组中，指标A最大的值。 [5, 3, 2, 1, 6, 7, 8, 4] 遍历每个元素，以当前元素为最小值，往左右两边扩，不能比当前元素小的范围 比如 5可能为[5] 3可能为[5, 3], [3] 2可能为[5, 3, 2], [3, 2], [2] 等等，就是单调栈，找到左右两边最近比他小的就是不能扩进去的位置 TODO 有问题 def get_sub_arr_max(arr): size = len(arr) sums = [0] for i in range(1, size): sums.append(arr[i - 1] + arr[i]) max_val = float(\"-inf\") stack = [] for i in range(size): while stack and arr[stack[-1]] >= arr[i]: idx = stack.pop() prev_sum = sums[i - 1] - sums[stack[-1]] if stack else sums[i - 1] max_val = max(max_val, prev_sum * arr[idx]) stack.append(i) while stack: idx = stack.pop() prev_sum = sums[-1] - sums[stack[-1]] if stack else sums[-1] max_val = max(max_val, prev_sum * arr[idx]) return max_val data = [5, 3, 2, 1, 6, 7, 8, 4] print(get_sub_arr_max(data)) "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/04-Morris遍历.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/04-Morris遍历.html","title":"Morris遍历","keywords":"","body":"datetime:2024/2/28 19:02 author:nzb Morris遍历 面试用，笔试尽量用其他，出错率比较高 一种遍历二叉树的方式，并且时间复杂度O(N)，额外空间复杂度O(1) 通过利用原树中大量空闲指针(叶子节点左右节点都是空)的方式，达到节省空间的目的 如果规定不能改变数据结构，则不能用Morris遍历 Morris遍历细节 假设来到当前节点cur，开始时cur来到头节点位置 1）如果cur没有左孩子，cur向右移动(cur = cur.right) 2）如果cur有左孩子，找到左子树上最右的节点mostRight： a.如果mostRight的右指针指向空，让其指向cur，然后cur向左移动(cur = cur.left) b.如果mostRight的右指针指向cur，让其指向null，然后cur向右移动(cur = cur.right) 3）cur为空时遍历停止 Morris遍历的实质 建立一种机制，对于没有左子树的节点只到达一次，对于有左子树的节点会到达两次，递归版本每个节点一定会到达三次 1 / \\ 2 3 /\\ /\\ 4 5 6 7 cur=1, most_right=5, most_right.right->1 cur=2, most_right=4, most_right.right->2 cur=4, 无左树, cur = cur.right->2 cur=2, most_right=4, 因为most_right.right->cur 所以重置most_right.right->None, cur = cur.right cur=5, 无左树, cur = cur.right->1 cur=1, most_right=5, 因为most_right.right->cur 所以重置most_right.right->None, cur = cur.right cur=3, most_right=6, most_right.right->3 cur=6 , 无左树, cur = cur.right->3 cur=3, most_right=3, 因为most_right.right->cur 所以重置most_right.right->None, cur = cur.right cur=7 左右都为空停 Morris遍历顺序：1 2 4 2 5 1 3 6 3 7 Morris遍历 class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left: TreeNode = left self.right: TreeNode = right # Morris遍历 def morris(head: TreeNode): if not head: return cur = head while cur: most_right = cur.left # 有左子树 if most_right: # 留在最右节点 # 2个停止条件，1、右节点为空，2、右节点是当前节点(第二次到达) while most_right.right and most_right.right != cur: most_right = most_right.right if not most_right.right: # 左子树最右节点, 第一次来到cur most_right.right = cur cur = cur.left continue else: # 第二次，most_right.right == cur, 重置右节点，最后移到右子树 most_right.right = None # 如果左子树为空，直接移到右子树 cur = cur.right 先序遍历 # 先序遍历 def morris_pre(head: TreeNode): \"\"\" 先序遍历 只到达一次，直接打印 到达两次的，第一次到达的时候打印 :param head: :return: \"\"\" if not head: return cur = head while cur: most_right = cur.left # 有左子树 if most_right: # 留在最右节点 # 2个停止条件，1、右节点为空，2、右节点是当前节点(第二次到达) while most_right.right and most_right.right != cur: most_right = most_right.right if not most_right.right: # 左子树最右节点, 第一次来到cur print(cur.val, end=\" \") most_right.right = cur cur = cur.left continue else: # 第二次，most_right.right == cur, 重置右节点 most_right.right = None else: print(cur.val, end=\" \") # 如果左子树为空，直接移到右子树 cur = cur.right # 创建二叉树 \"\"\" 1 / \\ 2 3 / \\ 4 5 \"\"\" root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) morris_pre(root) # 1 2 4 5 3 中序遍历 # 中序遍历 def morris_in(head: TreeNode): \"\"\" 中序遍历 只到达一次，直接打印 到达两次的，第二次到达的时候打印 :param head: :return: \"\"\" if not head: return cur = head while cur: most_right = cur.left # 有左子树 if most_right: # 留在最右节点 # 2个停止条件，1、右节点为空，2、右节点是当前节点(第二次到达) while most_right.right and most_right.right != cur: most_right = most_right.right if not most_right.right: # 左子树最右节点, 第一次来到cur most_right.right = cur cur = cur.left continue else: # 第二次，most_right.right == cur, 重置右节点 most_right.right = None print(cur.val, end=\" \") # 没有左子树只到达一次，有左子树但是，第二次的时候也会到达这，因为上面else没有continue，这里就是到达2次的第二次 # 如果左子树为空，直接移到右子树 cur = cur.right # 创建二叉树 \"\"\" 1 / \\ 2 3 / \\ 4 5 \"\"\" root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) morris_in(root) # 4 2 5 1 3 后序遍历 # 后序遍历 def morris_pos(head: TreeNode): \"\"\" 后序遍历 到达两次的，第二次到达的时候逆序打印左树右边界 最后，单独打印整棵树的右边界(逆序) :param head: :return: \"\"\" if not head: return cur = head while cur: most_right = cur.left # 有左子树 if most_right: # 留在最右节点 # 2个停止条件，1、右节点为空，2、右节点是当前节点(第二次到达) while most_right.right and most_right.right != cur: most_right = most_right.right if not most_right.right: # 左子树最右节点, 第一次来到cur most_right.right = cur cur = cur.left continue else: # 第二次，most_right.right == cur, 重置右节点 most_right.right = None print_node(cur.left) # 第二次到达的时候逆序打印左树右边界, 注意不能重置之前，不然右边界会回去 # 如果左子树为空，直接移到右子树 cur = cur.right # 单独打印整棵树右边界 print_node(head) def print_node(head: TreeNode): tail = reverse(head) # 逆序 cur = tail while cur: # 打印 print(cur.val, end=\" \") cur = cur.right # 逆序回去 reverse(tail) def reverse(head: TreeNode): \"\"\"逆序右边界\"\"\" cur = head prev = None while cur: right = cur.right cur.right = prev prev = cur cur = right return prev # 创建二叉树 \"\"\" 1 / \\ 2 3 / \\ 4 5 \"\"\" root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) morris_pos(root) # 4 5 2 3 1 是否搜索二叉树 # 搜索二叉树 def is_bst(head: TreeNode): if not head: return True cur = head prev_val = float(\"-inf\") while cur: most_right = cur.left # 有左子树 if most_right: # 留在最右节点 # 2个停止条件，1、右节点为空，2、右节点是当前节点(第二次到达) while most_right.right and most_right.right != cur: most_right = most_right.right if not most_right.right: # 左子树最右节点, 第一次来到cur most_right.right = cur cur = cur.left continue else: # 第二次，most_right.right == cur, 重置右节点，最后移到右子树 most_right.right = None # 如果左子树为空，直接移到右子树 if cur.val Morris遍历时间复杂度的证明 总结 Morris遍历的解决了最本质的问题，所以很多问题都是以Morris遍历为最优解 如何判断使用Morris遍历作为最优解还是使用二叉树递归套路作为最优解 如果你的方法必须做第三次的数据强整合，就需要二叉树的递归套路 否则使用Morris遍历 "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/05-大数据题目-资源限制类.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/05-大数据题目-资源限制类.html","title":"大数据题目-资源限制类","keywords":"","body":"datetime:2024/2/29 17:38 author:nzb 大数据题目(资源限制类) 大数据题目的解题技巧 1）哈希函数可以把数据按照种类均匀分流 2）布隆过滤器用于集合的建立与查询，并可以节省大量空间 3）一致性哈希解决数据服务器的负载管理问题 4）利用并查集结构做岛问题的并行计算 5）位图解决某一范围上数字的出现情况，并可以节省大量空间 6）利用分段统计思想、并进一步节省大量空间 7）利用堆、外排序来做多个处理单元的结果合并 之前的课已经介绍过前4个内容，本节内容为介绍解决大数据题目的后3个技巧 在面试时需要咨询面试官是否接受失误率，有没有空间限制等，这一点很重要 题目一 32位无符号整数的范围是0~4,294,967,295(0~2^32-1, 即42.9亿)，现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然存在没出现过的数。可以使用最多1GB的内存，怎么找到所有未出现过的数？ 【进阶】内存限制为 10MB(或3KB)，但是只用找到一个没出现过的数即可 解决方法 用哈希分流，但是需要内存很大 用位图(bitmap), 区间统计(分段统计思想) 基础解决思路 0-2^32-1这个数中只出现40亿个。一个字节8bit，也就是一个字节可以表示8个数。用01表示出现过没有就行。如果我们准备一个2的32次方的bit的数组需要多少空间，2^32 / 8 byte ≈ 512MB，一位表示一个数出现没出现过 进阶解决思路(不管给多少空间，用此办法都可以) 首先3000B // 4 =700，也就是能申请长度700的无符号整型(一个整型4B)数组 ）上找到一个离2的次方最接近的一个数，也就是 2^9 = 512 离得最近 （为什么要2的次方，因为0~2^32 次方个数能够按照这个数整除分割。也就是2^32 / 2^9 = 8388608）。 申请一个数组长度为512的数组。然后每一个位置上表示的含义是：40亿的数字按照512的大小均分，分成了8388608份， 那么0~8388608 这些数就放在第一个位置上 8388608 ~ 8388608x2是第二个位置表示的值 怎么统计这个范围的数出现了几次？用这个数除以8388608，比如 1 // 8388608 = 0，那么1这个数就是属于这个数组中的0号位置，就把0号位置的次数加1 然后统计第一个位置上这个数出现的次数是不是8388608个。如果不是，说明一定在这个范围内有一个数字没有出现，然后再把8388608按照512的大小继续进行均分， 重复上面的操作，一定可以找出那个没有出现的数字。 如果只给3个变量(有限几个变量)，怎么找出？把40亿进行二分，少数字那边继续二分找，最多过32次文件。同样的原理。 题目二 有一个包含100亿个URL的大文件，假设每个URL占用64B，请找出其中所有重复的URL 首先可以使用布隆过滤器，但是利用它会有失误率。 如果不能有失误率，则用哈希函数进行分流的方法。 先对大文件中的数据用哈希函数求出哈希值，分配到小文件当中。如果该小文件不能满足题目的内存限制要求，就对小文件中的数据再次进行哈希，放入到直到满足题目要求的文件中即可。主要的就是利用多次哈希。 【补充】某搜索公司一天的用户搜索词汇是海量的(百亿数据量)，请设计一种求出每天热门Top100词汇的可行办法 ①哈希分流。首先把包含百亿数据量的词汇文件分流到不同机器上；如果每一台机器上分到的数据量依然很大，再用哈希函数把每台机器的分流文件拆成更小文件处理； ②处理每一个小文件时，通过哈希表做一个词频统计，哈希表记录完成后，再遍历哈希表，每个小文件都有一个大根堆，维持排名 ③把每个小文件大根堆堆顶拿出来，单独组装放到一个100的大根堆(总堆)，然后一次弹出，然后看来自于哪，删除，把下一个元素放到总堆里面 ④不同机器之间使用总堆进行外排序，最终求出整个百亿数据量中的Top 100。 题目三 32位无符号整数的范围是0~4294967295，现在有40亿个无符号整数，可以使用最多1GB的内存，找出所有出现了两次的数。 1）用哈希函数再取模分类到小文件的方式 2）可以利用位图，建立一个bit数组。每两个bit代表一个数字的出现次数的情况。 如果是00，代表1一次都没有出现； 如果是01，代表出现了1次； 如果是10，代表出现了两次； 如果是11，代表出现了三次或三次以上。 最后遍历数组，找出哪个数对应的bit位是10的，那么就说明它出现了两次。 但是，因为我们是用两个bit位代表一个数字的出现次数，假设用一个bit位的时候，数组的大小为：2^32 / 8 / 1024 = 524288KB = 512MB，因为是两bit位，则再乘2，超过了1G。那么如何解决？ 【补充】可以使用最多10MB(3KB)的内存，怎么找到这40亿个整数的中位数？ 分段统计思想，将数分为各个区间，然后区间内统计词频，可以知道中位数在哪个区间中，然后再将该区间在分段求解。 同样地，因为是最多3K内存，可以设置一个长度512的数组对2的32次方个数进行划分。在数组中对每个下标代表的数进行统计。如：下标0代表的数是0~8388608。 因为要找出40亿个数的中位数，那么要找出第20亿个数是哪个。如果下标0中出现的数有1亿个，那么中位数绝对不可能出现在下标0代表的某个数中。 假设统计0到170下标的数有19亿个，到171下标的数有23亿个，那么中位数肯定就是在171下标代表的某个数中。找到171下标中第一亿个数就是中位数。 题目四 有10GB大文件里面存放着无序有符号的整数，给你5GB空间，如何把这个无序变成有序。（腾讯面试题） 思路：（先分桶再排序） 1）用小根堆（每一个元素有数值，频次两个属性）来作为媒介遍历每一个文件段（5GB可以申请可以存储多大的小根堆），每一个小段进入小根堆后，输出小根堆到文件就可以了，然后总结果就是依次排序。 可以申请多大的小根堆, 一个整型4字节，一条数据8字节(包括数据和频次)，假设堆还有其他占用，就位16字节，则堆长度为5 * 2 ^ 30 / 16 = 5 * 2 ^ 26向下取整2^27 无符号数的范围是-2^31 ~ 2^31-1，假设一个范围是2^27, 则2^32 // 2^27 =等分成2^5份小范围 利用小根堆统计最低范围出现的状况，比如第一个范围是-2^31 ~ -2^31+2^27-1, 第二个范围是-2^31+2^27 ~ -2^31+2^27 * 2 -1... 每次过完一个范围的数，根据频次输出到文件，再搞定下一个范围的数，因为范围是小到大，并且利用了小根堆，所以总体有序 2）最优解：用大根堆(数值，频次) 大根堆的长度用5GB算出，并且定义一个Y值 简单例子 总共有10个数，创建一个只存放3个数的大根堆。然后依次遍历这十个数，比堆顶小进堆，比堆顶大就忽略，这个大根堆里面存放的是10个数中最小的3个数。 然后输出有序的最小的3个数。此时记录排完序的3个数中最大的那个数Y 清空大根堆后，继续去遍历这10个数，但是小于Y的就不要遍历了， 然后找出最小的3个数，然后输出 一直重复就可以了。 "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/06-位运算.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/06-位运算.html","title":"位运算","keywords":"","body":"datetime:2024/03/01 14:15 author:nzb 位运算 题目一 给定两个有符号32位整数a和b，返回a和b中较大的。 【要求】不用做任何比较判断。 def flip(n): \"\"\" :param n: 0 or 1 :return: \"\"\" return n ^ 1 def sign(n): \"\"\" 取符号位 负数-> 1 正数-> 0 :param n: :return: \"\"\" # n >> 31 取符号位 return flip(n >> 31 & 1) def get_max1(a, b): c = a - b # 可能会溢出 sc_a = sign(c) # a - b 为负， sc_a 为0， 否则为1 sc_b = flip(sc_a) # 取反，如果sc_a == 0, sc_b==1, 否则sc_a==1, sc_b==0 # sc_a==0, scb必为1，sc_a==1，sc_b必为0 # 把 if else做成了互斥条件相加的条件 return a * sc_a + b * sc_b def get_max2(a, b): c = a - b sa = sign(a) sb = sign(b) sc = sign(c) diff_s_ab = sa ^ sb # a和b符号一样为0，不一样为1 same_s_ab = flip(diff_s_ab) # 跟diff_s_ab互斥，符号一样为1，不一样为0 # 什么时候a比较大 # 1、a和b符号相同，a - b不会溢出，a - b > 0 # 2、a和b符号不同，并且 a > 0 return_a = diff_s_ab * sa + same_s_ab * sc # 加号两边互斥，有一个中都返回a return_b = flip(return_a) return a * return_a + b * return_b print(get_max1(1, 2)) print(get_max1(-4, 8)) print(get_max2(1, 2)) print(get_max2(-4, 8)) 题目二 判断一个32位正数是不是2的幂、4的幂 2的幂的特点，2,4,6,8...，就是二进制数中某一位为1，只有唯一的1 方法1：x取最右的1后等于0 方法2：x & x - 1 == 0 4的幂前提是2的幂 条件1：2的幂 条件2：偶数为1，比如1(2^0), 4(2^2), 16(2^4), 64(2^6)->01, 100, 10000, 1000000, 偶数位为1, 并且唯一个1 def is_2_power(n): \"\"\"只有唯一一个1\"\"\" # 取出最右的1，与一下看还是不是原来的数 return n & (~n + 1) == n # n - 1打乱，比如 00100 减一后是 00011 # return n & (n - 1) == 0 print(is_2_power(16)) print(is_2_power(3)) def is_4_power(n): \"\"\"只有唯一一个1, 2的幂保证了，后面的看在不在偶数位上\"\"\" # 0x5是0b101 return n & (n - 1) == 0 and n & 0x55555555 != 0 print(is_4_power(64)) print(is_4_power(63)) 题目三 给定两个有符号32位整数a和b，不能使用算术运算符，分别实现a和b的加、减、乘、除运算 【要求】如果给定a、b执行加减乘除的运算结果就会导致数据的溢出，那么你实现的函数不必对此负责，除此之外请保证计算过程不发生溢出 加法 15 -> 01111 11 -> 01011 ------------- ^ -> 00100 # 无进位新加 & 10110 # & 10010 & 01000 ------------- ^ -> 11010 & 00000 # 当没有进位信息的时候就是结果 # 需要保证用户给的a加b的结果不会溢出 def add(a, b): while b != 0: tmp = a & b a = a ^ b b = tmp 减法 def neg_num(n): \"\"\"相反数\"\"\" return add(~n, 1) def minus(a, b): return add(a, neg_num(b)) # print(minus(3, 2)) 乘法 运算 27 34 ---- 108 81 ---- 918 二进制类似 011010 a 010110 b -------- 000000 ==0, a > 1 011010 !=0, add(res, a), a>1 011010 !=0, add(res, a), a>1 000000 ==0, a > 1 011010 !=0, add(res, a), a>1 ----------- 0111111100 累加 def multi(a, b): res = 0 while b != 0: if b & 1 != 0: res = add(res, a) a >= 1 return res print(multi(3, 5)) print(multi(-3, 5)) print(multi(-3, -5)) # 计算不出来 print(multi(3, -5)) # 计算不出来 除法 a 0110111 b 0000011 a 能不能减去 b 存在问题，TODO ```python def is_neg(n): return n def div(a, b): x = neg_num(a) if is_neg(a) else a y = neg_num(b) if is_neg(b) else b res = 0 for i in range(32)[::-1]: if (x >> i) >= y: # 为啥是x右移，因为y左移可能溢出 res |= (1 "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/07-暴力递归到动态规划.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/07-暴力递归到动态规划.html","title":"暴力递归到动态规划","keywords":"","body":"datetime:2024/3/2 15:49 author:nzb 暴力递归到动态规划 动态规划就是暴力尝试减少重复计算的技巧而已，这种技巧就是一个大型套路 先写出用尝试的思路解决问题的递归函数，而不用操心时间复杂度 这个过程是无可替代的，没有套路的，只能依靠个人智慧，或者足够多的经验 但是怎么把尝试的版本，优化成动态规划，是有固定套路的，大体步骤如下 1)找到什么可变参数可以代表一个递归状态，也就是哪些参数一旦确定，返回值就确定了 2)把可变参数的所有组合映射成一张表，有 1 个可变参数就是一维表，2 个可变参数就是二维表，...... 3)最终答案要的是表中的哪个位置，在表中标出 4)根据递归过程的 base case，把这张表的最简单、不需要依赖其他位置的那些位置填好值 5)根据递归过程非base case的部分，也就是分析表中的普遍位置需要怎么计算得到，那么这张表的填写顺序也就确定了 6)填好表，返回最终答案在表中位置的值 尝试 -> 记忆化搜索(dp) -> 严格表结构动态规划(dp) -> 精致版的严格表结构动态规划(dp) 某些问题记忆化搜索动态规划和严格表结构动态规划有相同的时间复杂度 严格表结构动态规划可能还有进一步优化技巧，熟悉位置依赖(比如斜率优化等) 关键在于尝试 记忆化搜索就是加缓存 尝试 尝试如同人生，千奇百怪 尝试模型：从左往右尝试(硬币问题，比如题目六)，范围尝试(拿牌问题，比如题目三) 优化方式需要掌握3~4种就行了 尝试的时候需要重点注意两点 每一个可变参数自己的维度 1个参数一维表，2个参数二维表...，参数少越好 维度：最好是0维参数 本节所有的可变参数都是整型，这种参数叫做0维参数，就是一个点，它的值的变化范围好估计 如果有个参数是数组，它的维度就是一维参数，变化范围太大，比如2个元素的数组可能是[0,0], [0,1], [1, 0], [1,1] 可变参数个数：尽可能少，尽量0维参数 题目一 机K器MP人算达法到扩指展定题位目置二方法数 【题目】 假设有排成一行的 N 个位置，记为 1~N，N 一定大于或等于2。开始时机器人在其中的M位置上(M 一定是 1~N 中的一个)，机器人可以往左走或者往右走，如果机器人来到1位置，那么下一步只能往右来到 2 位置;如果机器人来到 N 位置，那么下一步只能往左来到N-1位置。规定机器人必须走 K 步，最终能来到 P 位置(P 也一定是1~N 中的一个)的方法有多少种。给定四个参数 N、M、K、P，返回方法数。 【举例】 N=5,M=2,K=3,P=3，上面的参数代表所有位置为 1 2 3 4 5。机器人最开始在2 位置上，必须经过3步，最后到达 3 位置。走的方法只有如下 3 种: 1)从2到1，从1到2，从2到3 2)从2到3，从3到2，从2到3 3)从2到3，从3到4，从4到3所以返回方法数 3。 N=3,M=1,K=3,P=3，上面的参数代表所有位置为 1 2 3。机器人最开始在 1 位置上，必须经过3 步，最后到达3位置。怎么走也不可能，所以返回方法数 0。 暴力尝试 def walk_ways(n, m, k, p): return process(n, p, k, m) def process(n, p, rest, cur): \"\"\" 暴力尝试 :param n: 一共 1~N 这么多位置， 固定参数 :param p: 最终的目标是E， 固定参数 :param rest: 还剩多少不要走， 可变参数 :param cur: 当前位置， 可变参数 :return: 返回方法数 \"\"\" if rest == 0: # base case return 1 if cur == p else 0 if cur == 1: # 1 位置只能往右走到2 return process(n, p, rest - 1, 2) elif cur == n: # N 位置只能往左走到N-1 return process(n, p, rest - 1, n - 1) # 中间的位置可以往左或往右走，走向左、走向右是截然不同的方法，所以总方法数要都算上 return process(n, p, rest - 1, cur - 1) + process(n, p, rest - 1, cur + 1) print(walk_ways(5, 2, 4, 4)) 记忆化搜索动态规划 \"\"\" 一旦可变参数确定，结果就确定了 例如：1 2 3 4 5，当前在2，走4步，最终要到4，递归过程 f(4,2) 最终需要的答案,(剩余步数，当前位置) / \\ f(3,1) f(3,3) |(只能右走) / \\ f(2,2) f(2,2) f(2,4) f(2,2)重复了，每次都要重新展开去计算，多了很多重复解 因此可以使用缓存记录f(2,2)的结果，下次遇到直接拿结果，而不去展开计算 \"\"\" # 优化，记忆化搜索版本 def walk_ways2(n, m, k, p): # 2个可变参数 -> 二维表 # 表开多大，看暴力尝试里面2个可变参数大小 # rest都是减一，所以 0~K # cur 一定在 1~N dp = [[-1 for _ in range(n + 1)] for _ in range(k + 1)] # 缓存结构 return process2(n, p, k, m, dp) def process2(n, p, rest, cur, dp): \"\"\" 记忆化搜索动态规划 :param n: 一共 1~N 这么多位置， 固定参数 :param p: 最终的目标是p， 固定参数 :param rest: 还剩多少不要走， 可变参数 :param cur: 当前位置， 可变参数 :return: 返回方法数 \"\"\" # 缓存命中 if dp[rest][cur] != -1: # != -1, 计算过 return dp[rest][cur] # 缓存没命中 if rest == 0: # base case dp[rest][cur] = 1 if cur == p else 0 return dp[rest][cur] # rest > 0 还有路可走 if cur == 1: # 1 位置只能往右走到2 dp[rest][cur] = process2(n, p, rest - 1, 2, dp) elif cur == n: # N 位置只能往左走到N-1 dp[rest][cur] = process2(n, p, rest - 1, n - 1, dp) else: # 中间的位置可以往左或往右走 dp[rest][cur] = process2(n, p, rest - 1, cur - 1, dp) + process2(n, p, rest - 1, cur + 1, dp) return dp[rest][cur] print(walk_ways2(5, 2, 4, 4)) 严格表结构动态规划 严格表结构只字未提之前的规划是是什么含义，只根据递归结构分析出，通过位置依赖信息来确定 N=5, P=4, M=2, k=4，画表 0 1 2 3 4 5 0 0 0 0 0 1 0 1 2 3 4 ☆ 行为rest，列为cur 主函数调用的就是，最终要的位置f(4,2)，当前位置在2，走4步的结果，即表中星号 然后看base case哪些可以直接得到答案的 cur == P == 4 ? 1 : 0，所以第一行数据如上 继续看递归 cur 可能等于0吗，不可能，因为cur 在1~N范围，所以第一列不可能 0 1 2 3 4 5 0 x 0 0 0 1 0 1 x 2 x 3 x 4 x ☆ 继续看递归 cur == 1，process2(N, E, rest - 1, 2, dp)，依赖 rest-1 位置的东西，右上角的值拷贝过来就行了 同理，cur == 1，process2(N, E, rest - 1, N - 1, dp)，依赖 rest-1 位置的东西，右上角的值拷贝过来就行了 0 1 2 3 4 5 0 x 0 0 0 1 0 1 x ↗ ↖ 2 x ↗ ↖ 3 x ↗ ↖ 4 x ↗ ☆ ↖ 继续看递归，中间位置，依赖左上角+右上角的位置 0 1 2 3 4 5 0 x 0 0 0 1 0 1 x ↗ . . ↖ 2 x ↗ ↖↗ ↖ 3 x ↗ ↖ 4 x ↗ ☆ ↖ 依次填满表，就可以知道星号位置的数 0 1 2 3 4 5 0 x 0 0 0 1 0 1 x 0 0 1 0 1 2 x 0 1 0 2 0 3 x 1 0 3 0 2 4 x 0 4 def walk_ways3(n, m, k, p): \"\"\" 严格表结构 :param n: 1~n位置 :param m: 当前位置 :param k: 走k步 :param p: 目标位置 :return: \"\"\" if n n or p n: return 0 dp = [[0 for _ in range(n + 1)] for _ in range(k + 1)] # [[cur], [], rest] dp[0][p] = 1 # base case, 剩余0步，刚好当前位置在p for i in range(1, k + 1): for j in range(1, n + 1): if j == 1: # 第一个位置 dp[i][j] = dp[i - 1][2] # 右上角 elif j == n: dp[i][j] = dp[i - 1][n - 1] # 左上角 else: dp[i][j] = dp[i - 1][j - 1] + dp[i - 1][j + 1] # 主函数要的是f(4,2), 当前在2，走4步的结果 return dp[k][m] print(walk_ways3(5, 2, 4, 4)) 时间复杂度 暴力尝试时间复杂度，可以看出二叉树，树高K步，所以最差为 O(2^K) 记忆化搜索动态规划时间复杂度和严格表结构动态规划时间复杂度一样，dp表为KN的规模，最差为 O(KN) 题目二 组合最少硬币数 【题目】给定数组 arr，arr 中所有的值都为正数可能重复。每个值代表一枚货币，再给定一个整数 aim，代表要找的钱数，求组成aim的最少货币数。 【举例】 arr=[2,7,3,5,3], aim=10：7+3=10, 所以结果为0 暴力尝试 # 暴力尝试：尝试模型从左往右 def coins_min(arr, aim): return process(arr, 0, aim) def process(arr, idx, rest): \"\"\" :param arr: 硬币数组，固定参数 :param idx: 索引 :param rest: 剩余多少还有组成 :return: 可以组成的数最少硬币数 \"\"\" if rest 0 if idx == len(arr): # 没硬币可选，rest > 0 return -1 # rest > 0, 还有硬币 # 用和不用当前硬币去最小的那个，但是有个-1会干扰求最小值 # return min(process(arr, idx + 1, rest), 1 + process(arr, idx + 1, rest - arr[idx])) # 优化 p1 = process(arr, idx + 1, rest) p2_next = process(arr, idx + 1, rest - arr[idx]) # 可能性2的后续 if p1 == -1 and p2_next == -1: # 怎么做选择都是错的，所以返回-1 # 比如[2,3,100,200], aim=5, 如果你没有要2和3,到100的时候，要和不要都是错的 return -1 elif p1 == -1: return 1 + p2_next elif p2_next == -1: return p1 else: # 2个都不是-1，做决策 return min(p1, p2_next + 1) print(coins_min([2, 7, 3, 5, 3], 10)) \"\"\" arr=[2,3,100] aim=5 f(0,5) # (idx, aim) 不要2/ \\要2 f(1,5) f(1,3) 不要3/ \\要3 x3/ \\要3 f(2,5) f(2,2) f(2,3) f(2,0) / \\ / \\ f(3,5) f(3,-95) f(3,3) f(3,-97) f(2,0)会返回 0，2位置往后的货币要搞定0块钱 f(2,5): 因为下面2个状态都是-1，所以当前状态也返回-1 f(3,5)3往后没有硬币，没法再搞定5块钱了，所以返回-1，无论怎么样拆解都是无效的 f(3,-95) 没法搞定-95，所以返回-1 f(2,2)也一样，返回-1 所以f(1,5)因为f(2,5)和f(2,2)所以也返回-1 f(2,3)同理返回-1 f(1,3)因为f(2,3)返回-1，f(2,0)返回0，所以返回0 f(0,5) = f(1,3) +1 + f(2,0) + 1 = 2 \"\"\" 记忆化搜索动态规划 def coins_min2(arr, aim): # 0 表示有效解，-1表示无效解，-2表示算没算过 dp = [[-2 for _ in range(aim + 1)] for _ in range(len(arr) + 1)] return process2(arr, 0, aim, dp) def process2(arr, idx, rest, dp): \"\"\" :param arr: 硬币数组，固定参数 :param idx: 索引 :param rest: 剩余多少还有组成 :return: 可以组成的数最少硬币数 \"\"\" if rest 0 elif idx == len(arr): # 没硬币可选，rest > 0 dp[idx][rest] = -1 else: p1 = process2(arr, idx + 1, rest, dp) p2_next = process2(arr, idx + 1, rest - arr[idx], dp) # 可能性2的后续 if p1 == -1 and p2_next == -1: # 怎么做选择都是错的，所以返回-1 # 比如[2,3,100,200], aim=5, 如果你没有要2和3,到100的时候，要和不要都是错的 dp[idx][rest] = -1 elif p1 == -1: dp[idx][rest] = 1 + p2_next elif p2_next == -1: dp[idx][rest] = p1 else: # 2个都不是-1，做决策 dp[idx][rest] = min(p1, p2_next + 1) return dp[idx][rest] print(coins_min2([2, 7, 3, 5, 3], 10)) import random def generate_random_arr(length, max_val): return [random.randint(1, max_val) for _ in range(length)] def main(): # 对数器 length = 10 max_val = 10 times = 10000 for _ in range(times): arr = generate_random_arr(length, max_val) aim = random.randint(1, max_val) * 3 if coins_min(arr, aim) != coins_min2(arr, aim): print(\"oops\") print(\"wonderful\") main() 严格表结构动态规划 arr=[2,3,5,7,2], aim=10 0 1 2 3 4 5 6 7 8 9 10 0 0 ☆ 1 0 2 0 ? 3 0 ② ① 4 0 5 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 行为索引，列为aim，主函数f(0, 10)，求星星位置 base case rest：默认为-1，不用理 rest==0：列为0 idx==5：无硬币可选，-1 继续看递归，分析普遍位置 表中问号位置有process(arr, idx + 1, rest)①和process(arr, idx + 1, rest - arr[idx])②决定 任意一个位置都依赖它下边和左下角的位置，所以填写顺序应该是从左往右，从下往上的顺序填写 def coins_min3(arr, aim): length = len(arr) dp = [[0 for _ in range(aim + 1)] for _ in range(length + 1)] # base case for row in range(length + 1): # rest == 0 dp[row][0] = 0 for col in range(1, aim + 1): # idx == 5, 从1开始，因为 0 位置已经确认为0 dp[length][col] = -1 # 从下往上，从左往右填写 for idx in range(length - 1, -1, -1): # 下往上, length位置不用了，上面填写了base case for rest in range(1, aim + 1): # 左往右，0位置不用了, 上面填写了base case # 递归挪过来改 p1 = dp[idx + 1][rest] p2_next = -1 # 可能越界 if rest - arr[idx] >= 0: p2_next = dp[idx + 1][rest - arr[idx]] if p1 == -1 and p2_next == -1: dp[idx][rest] = -1 elif p1 == -1: dp[idx][rest] = 1 + p2_next elif p2_next == -1: dp[idx][rest] = p1 else: # 2个都不是-1，做决策 dp[idx][rest] = min(p1, p2_next + 1) return dp[0][aim] print(coins_min3([2, 7, 3, 5, 3], 10)) import random def generate_random_arr(length, max_val): return [random.randint(1, max_val) for _ in range(length)] def main(): length = 10 max_val = 10 times = 10000 for _ in range(times): arr = generate_random_arr(length, max_val) aim = random.randint(1, max_val) * 3 if coins_min(arr, aim) != coins_min2(arr, aim) or coins_min2(arr, aim) != coins_min3(arr, aim): print(\"oops\") print(\"wonderful\") main() 题目三 基础里面的拿牌问题 给定一个整型数组arr，代表数值不同的纸牌排成一条线。玩家A和玩家B依次拿走每张纸牌，规定玩家A先拿，玩家B后拿，但是每个玩家每次只能拿走最左或最右的纸牌，玩家A和玩家B都绝顶聪明。请返回最后获胜者的分数。 【举例】 arr=[1,2,100,4] 开始时，玩家A只能拿走1或4。如果开始时玩家A拿走1，则排列变为[2,100,4]，接下来玩家 B可以拿走2或4，然后继续轮到玩家A... 如果开始时玩家A拿走4，则排列变为[1,2,100] ，接下来玩家B可以拿走1或100，然后继续轮到玩家A... 玩家A作为绝顶聪明的人不会先拿4，因为拿4之后，玩家B将拿走100。所以玩家A会先拿1，让排列变为[2,100,4] ，接下来玩家B不管怎么选，100都会被玩家A拿走。玩家A会获胜，分数为101。所以返回101。 arr=[1,100,2]开始时，玩家A不管拿1还是2，玩家B作为绝顶聪明的人，都会把100拿走。玩家B会获胜，分数为100。所以返回100。 暴力尝试 看基础部分 记忆化搜索动态规划 # 记忆化搜索，f函数做缓存，2个可变参数 def win1(arr): if not arr: return 0 dp = [[0 for _ in range(len(arr) + 1)] for _ in range(len(arr) + 1)] return max(first1(arr, 0, len(arr) - 1, dp), second1(arr, 0, len(arr) - 1, dp)) def first1(arr, left, right, dp): if left == right: dp[left][right] = arr[left] else: dp[left][right] = max(arr[left] + second1(arr, left + 1, right, dp), arr[right] + second1(arr, left, right - 1, dp)) return dp[left][right] def second1(arr, left, right, dp): if left == right: dp[left][right] = 0 else: dp[left][right] = min(first1(arr, left + 1, right, dp), first1(arr, left, right - 1, dp)) return dp[left][right] print(win1([1, 2, 100, 4])) import random def generate_random_arr(length, max_val): return [random.randint(1, max_val) for _ in range(length)] def main(): length = 10 max_val = 10 times = 10000 for _ in range(times): arr = generate_random_arr(length, max_val) if win(arr) != win1(arr): print(\"oops\") print(\"wonderful\") main() 严格表结构动态规划 范围上尝试，做严格表结构特别简单，后续还有例子 画表，arr=[3, 100, 4, 50] first 先手函数，变化范围i~j，行为i, 列为j i \\ j 0 1 2 3 0 3 ① ☆ 1 x 100 ② 2 x x 4 ③ 3 x x x 50 second 后手函数，变化范围i~j，行为i, 列为j i \\ j 0 1 2 3 0 0 ④ ☆ 1 x 0 ⑤ 2 x x 0 ⑥ 3 x x x 0 主函数需要first(0, len(arr)-1)和second(0, len(arr)-1)，即图中星号 注意范围上尝试的改法，i是左边界，j是右边界，i是永远不会大于j的，所以图中左下角不可能有值 first的base case, 等于arr[i]的值，所以填写，跟原题意没关系了 second的base case, 等于0，所以填写，跟原题意没关系了 分析普遍位置依赖 first依赖second，比如星号位置(0,3)依赖做second对称点的星号，依赖second中的(1,3)和(0, 2) 同理second依赖first，比如星号位置(0,3)依赖做first对称点的星号，依赖first中的(1,3)和(0, 2) 那么①②③这条线可以由second得到，④⑤⑥条线可以由first得到，交替推得到 def win2(arr): length = len(arr) f_dp = [[0 for _ in range(length)] for _ in range(length)] s_dp = [[0 for _ in range(length)] for _ in range(length)] for i in range(length): f_dp[i][i] = arr[i] row = 0 col = 1 # base case, 对角线有了从1开始 while col 题目四 象棋中马的跳法 【题目】请同学们自行搜索或者想象一个象棋的棋盘，然后把整个棋盘放入第一象限，棋盘的最左下角是(0,0)位置。那么整个棋盘就是横坐标上9条线、纵坐标上10条线的一个区域。 给你三个参数，x，y，k，返回如果“马”从(0,0) 位置出发，必须走k步，最后落在(x,y)上的方法数有多少种？ 任意一个(x,y) 位置的马的跳法有如下 8 种 暴力尝试 import time def get_ways(x, y, step): \"\"\" 题目是从 (0,0) 位置出发到 (x,y) 也可以理解成从 (x,y) 到 (0,0) :param x: 目标点x :param y: 目标点y :param step: 剩余步数 :return: \"\"\" return walk(x, y, step) def walk(x, y, step): if x 8 or y 9: # base case 棋盘越界 return 0 if step == 0: # base case 走到目标点 return 1 if x == 0 and y == 0 else 0 return walk(x - 1, y + 2, step - 1) + walk(x - 1, y - 2, step - 1) + walk(x + 1, y + 2, step - 1) + walk(x + 1, y - 2, step - 1) + walk(x - 2, y + 1, step - 1) + walk(x - 2, y - 1, step - 1) + walk(x + 2, y + 1, step - 1) + walk(x + 2, y - 1, step - 1) start_time = time.time() print(get_ways(7, 7, 10)) # 515813 print(time.time() - start_time) # 28.875813007354736 记忆化搜索动态规划 def get_ways_dp(x, y, step): dp = [[[-1 for _ in range(step + 1)] for _ in range(10)] for _ in range(9)] return walk_dp(x, y, step, dp) def walk_dp(x, y, step, dp): if x 8 or y 9: # base case 棋盘越界 return 0 if dp[x][y][step] != -1: return dp[x][y][step] if step == 0: # base case 走到目标点 dp[x][y][step] = 1 if x == 0 and y == 0 else 0 else: dp[x][y][step] = walk_dp(x - 1, y + 2, step - 1, dp) + walk_dp(x - 1, y - 2, step - 1, dp) + walk_dp(x + 1, y + 2, step - 1, dp) + walk_dp(x + 1, y - 2, step - 1, dp) + walk_dp(x - 2, y + 1, step - 1, dp) + walk_dp(x - 2, y - 1, step - 1, dp) + walk_dp(x + 2, y + 1, step - 1, dp) + walk_dp(x + 2, y - 1, step - 1, dp) return dp[x][y][step] start_time = time.time() print(get_ways_dp(7, 7, 10)) # 515813 print(time.time() - start_time) # 0.0010004043579101562 严格表结构动态规划 def table_dp(x, y, step): if x 8 or y 9 or step 8 or col 9: # base case 棋盘越界 return 0 return dp[row][col][height] # 画图，观察填写顺序，从下往上填写 # 0层是base case, 从1层开始，1层依赖0层，2层依赖1层，以此类推 for h in range(1, step + 1): for r in range(9): for c in range(10): dp[r][c][h] += get_value(dp, r - 1, c + 2, h - 1) dp[r][c][h] += get_value(dp, r - 1, c - 2, h - 1) dp[r][c][h] += get_value(dp, r + 1, c + 2, h - 1) dp[r][c][h] += get_value(dp, r + 1, c - 2, h - 1) dp[r][c][h] += get_value(dp, r - 2, c + 1, h - 1) dp[r][c][h] += get_value(dp, r - 2, c - 1, h - 1) dp[r][c][h] += get_value(dp, r + 2, c + 1, h - 1) dp[r][c][h] += get_value(dp, r + 2, c - 1, h - 1) return dp[x][y][step] start_time = time.time() print(table_dp(7, 7, 10)) # 515813 print(time.time() - start_time) # 0.0019991397857666016 题目五 Bob的生存概率 【题目】给定五个参数n,m,i,j,k。表示在一个N*M的区域，Bob处在(i,j)点，每次Bob等概率的向上、下、左、右四个方向移动一步，Bob必须走K步。 如果走完之后，Bob还停留在这个区域上，就算Bob存活，否则就算Bob死亡。请求解Bob的生存概率，返回字符串表示分数的方式。 暴力尝试 def bob(n, m, i, j, k): # 不考虑会死，总共的方法数，4^k次方 # 生存方法数 / 总方法数 live = walk(n, m, i, j, k) return live def walk(n, m, row, col, rest): \"\"\" 从 row,col 位置出发，走rest步之后，方法数 :param n: :param m: :param row: bob当前位置 :param col: bob当前位置 :param rest: 剩余步数 :return: \"\"\" # 越界 bob die if row n or col m: return 0 if rest == 0: return 1 return walk(n, m, row, col + 1, rest - 1) + walk(n, m, row, col - 1, rest - 1) + walk(n, m, row - 1, col, rest - 1) + walk(n, m, row + 1, col, rest - 1) start_time = time.time() print(bob(20, 20, 5, 6, 13)) # 65427362 print(time.time() - start_time) # 20.048412322998047 记忆化搜索动态规划 def memory_dp(n, m, i, j, k): # 不考虑会死，总共的方法数，4^k次方 # 生存方法数 / 总方法数 dp = [[[-1 for _ in range(k + 1)] for _ in range(m + 1)] for _ in range(n + 1)] live = walk_dp(n, m, i, j, k, dp) return live def walk_dp(n, m, row, col, rest, dp): \"\"\" 从 row,col 位置出发，走rest步之后，方法数 :param n: :param m: :param row: bob当前位置 :param col: bob当前位置 :param rest: 剩余步数 :return: \"\"\" # 越界 bob die if row n or col m: return 0 if dp[row][col][rest] != -1: return dp[row][col][rest] if rest == 0: dp[row][col][rest] = 1 else: dp[row][col][rest] = walk_dp(n, m, row, col + 1, rest - 1, dp) + walk_dp(n, m, row, col - 1, rest - 1, dp) + walk_dp(n, m, row - 1, col, rest - 1, dp) + walk_dp(n, m, row + 1, col, rest - 1, dp) return dp[row][col][rest] start_time = time.time() print(memory_dp(20, 20, 5, 6, 13)) # 65427362 print(time.time() - start_time) # 0.0009343624114990234 严格表结构动态规划 def table_dp(n, m, i, j, k): dp = [[[0 for _ in range(k + 1)] for _ in range(m + 1)] for _ in range(n + 1)] # 第0层都是1，剩余0步，并且还在范围内，就存活 for x in range(n + 1): for y in range(m + 1): dp[x][y][0] = 1 # 越界 bob die def get_value(dp, row, col, heght): if row n or col m: return 0 return dp[row][col][heght] for h in range(1, k + 1): for row in range(n + 1): for col in range(m + 1): dp[row][col][h] += get_value(dp, row, col + 1, h - 1) dp[row][col][h] += get_value(dp, row, col - 1, h - 1) dp[row][col][h] += get_value(dp, row - 1, col, h - 1) dp[row][col][h] += get_value(dp, row + 1, col, h - 1) return dp[i][j][k] start_time = time.time() print(table_dp(20, 20, 5, 6, 13)) # 65427362 print(time.time() - start_time) # 0.008075237274169922 题目六 换钱的最少货币数(找零钱方法数) 【题目】给定数组 arr，arr 中所有的值都为正数且不重复。每个值代表一种面值的货币，每种面值的货币可以使用任意张，再给定一个整数 aim，代表要找的钱数，求组成aim的方法数。 【举例】 arr=[5,2,3]，aim=10：2张5，5张2，2,3,5各一张，2张3和一张2。 arr=[5,2,3]，aim=0：不用任何货币就可以组成 0 元，返回 0。 arr=[3,5]，aim=2：根本无法组成 2 元，钱不能找开的情况下默认返回-1。 暴力尝试 def way1(arr, aim): \"\"\"从左往右尝试模型\"\"\" return process(arr, 0, aim) # 0开始可以使用 def process(arr, idx, rest): if idx == len(arr): # base case，无货币可选 return 1 if rest == 0 else 0 ways = 0 piece = 0 # arr[idx] 当使用0张，1张。。。往后，不要超过rest的钱数，都能返回多少方法数 \"\"\" arr = [3, 5, 10, 1] aim=1000 求 fn(0,1000) 面值3: 使用0张，求f(1, 1000) 面值3: 使用1张，求f(1, 997) 面值3: 使用2张，求f(1, 994) ... 面值3: 使用333张，求f(1, 1) 以上相加 不能使用334，超了 求 f(1, 1000) 面值5: 使用0张，求f(2, 1000) ... 再相加 \"\"\" while piece * arr[idx] 记忆化搜索动态规划 def way2(arr, aim): if not arr: return 0 dp = [[0 for _ in range(aim + 1)] for _ in range(len(arr) + 1)] return process2(arr, 0, aim, dp) def process2(arr, idx, rest, dp): if idx == len(arr): # base case，无货币可选 dp[idx][rest] = 1 if rest == 0 else 0 else: ways = 0 piece = 0 # arr[idx] 当使用0张，1张。。。往后，不要超过rest的钱数，都能返回多少方法数 while piece * arr[idx] 严格表结构动态规划 arr = [3,5,1,2], aim=10，画表 0 1 2 3 4 5 6 7 8 9 10 0 ?3 ☆ 1 ② ① O ?2 2 ① ?1 O 3 ⑤ ④ ③ ② ① O 4 1 0 0 0 0 0 0 0 0 0 0 行为idx, 列为aim 求fn(0,aim)，表中星号 看base case, idx=4,aim=0 为1，其余为0 看普遍位置 ?1由下一行的O,①,②,③...相加得到，数字表示使用的张数 ?2由下一行的O,①相加得到，数字表示使用的张数 ?3由下一行的O,①,②相加得到，数字表示使用的张数 普遍位置不是下一行全部累加，而是根据张数挑选位置累加 整体从下往上填写，同一行顺序无所谓 def way3(arr, aim): if not arr: return 0 length = len(arr) dp = [[0 for _ in range(aim + 1)] for _ in range(length + 1)] dp[length][0] = 1 # base case # 从下往上顺序填写 for idx in range(length - 1, -1, -1): for rest in range(aim + 1): # 暴力尝试的代码拷过来改 ways = 0 piece = 0 # arr[idx] 当使用0张，1张。。。往后，不要超过rest的钱数，都能返回多少方法数 while piece * arr[idx] 优化精简版严格表结构动态规划 如果不优化，时间复杂度O(N*aim)，每一次求一个格子的时候有枚举行为，最夸张的时候就说货币为1的时候，上表中的?1，他需要O,①,②,③...相加得到，时间复杂度O(aim) ，因此时间复杂度为O(N*aim) * O(aim) = O(N*aim^2) 假设i号货币为3， 0 1 ... ... ... ... ... 200 ... ... ... 0 1 ... x ? ... ... d c b a ... ? = a + b + c + d + ... 注意观察x位置x = b + c + d + ... 所以? = x + a 通过观察才能得出的斜率优化，枚举行为(使用0张，1张，2张...)被临近位置代替观察出来的，不用给优化找理由 def way4(arr, aim): if not arr: return 0 length = len(arr) dp = [[0 for _ in range(aim + 1)] for _ in range(length + 1)] dp[length][0] = 1 # base case # 从下往上顺序填写 for idx in range(length - 1, -1, -1): for rest in range(aim + 1): dp[idx][rest] = dp[idx + 1][rest] # 下方格子 if rest - arr[idx] >= 0: # 本行减去一个面值的格子，别越界 dp[idx][rest] += dp[idx][rest - arr[idx]] return dp[0][aim] # 主函数f(0,aim) print(way4([5, 2, 3], 10)) import random def generate_random_arr(length, max_val): return [random.randint(1, max_val) for _ in range(length)] def main(): # 对数器 length = 6 max_val = 10 times = 10000 for _ in range(times): arr = generate_random_arr(length, max_val) aim = random.randint(1, max_val) * 3 if way1(arr, aim) != way2(arr, aim) or way2(arr, aim) != way3(arr, aim) or way3(arr, aim) != way4(arr, aim): print(\"oops\") print(\"wonderful\") main() 题目七 换钱的最少货币数 【题目】给定数组 arr，arr 中所有的值都为正数且不重复。每个值代表一种面值的货币，每种面值的货币可以使用任意张，再给定一个整数 aim，代表要找的钱数，求组成aim的最少货币数。 【举例】 arr=[5,2,3]，aim=20：4 张 5 元可以组成 20 元，其他的找钱方案都要使用更多张的货币，所以返回4。 arr=[5,2,3]，aim=0：不用任何货币就可以组成 0 元，返回 0。 arr=[3,5]，aim=2：根本无法组成 2 元，钱不能找开的情况下默认返回-1。 "},"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/08-有序表.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/Algorithm/基础提升/08-有序表.html","title":"有序表","keywords":"","body":"datetime:2024/3/05 14:31 author:nzb 有序表 红黑树(平衡搜索二叉树BST) AVL树(平衡搜索二叉树BST) SB树(平衡搜索二叉树BST)，比较好改 跳表(单链表) 搜索二叉树 构造 通过新建节点，大于头节点放右边，小于放左边，暂时不考虑平衡性。直至放下 一般默认搜索二叉树是没有重复的节点的，如果有重复数据，可以在每个节点加功能项，比如计数或字符串数组保存相关信息 查找：找小于等于6离它最近的 4 / \\ 2 8 \\ /\\ 3 7 9 / 5 首先来到头结点，4 6, 8的右树肯定都比6大，所以来到左树 来到7, 7>6 来到5, 5 删除：删除前需要先查找 删除的节点没有左右孩子，直接删(找到当前节点，记下父节点，然后把父节点指为空) 删除的节点左右孩子不双全(直接把父节点指向孩子) 删除的节点都有左右孩子：可以用左树最右节点代替或者右树最左节点代替 ... / 3 / \\ 2 7 / \\ /\\ 1 2.5 6 ... / \\... 4 \\... 假如需要删除3,3上面还有节点 可以用左树最右节点代替或者右树最左节点代替 比如：用4替代 4剥离出来，4的右孩子给6,6的左树指向4的右孩子(因为4是6的左树,所以4的右树也小于6) 然后把4替换到3 ... / 4 / \\ 2 7 / \\ /\\ 1 2.5 6 ... / \\... /... 红黑树，AVL树，SB树的增删改查都是以上这些 上面的操作没有平衡性，做不到O(logN)，比如用户给1,2,3,4,5,6就变成O(N)，棒状结构，查的时候就像单链表一样 1 \\ 2 \\ 3 \\ 4 \\ ... 何为具有平衡性的树? 狭义的平衡二叉树需要节点的左右高度差小于等于1 广义可以是左右数节点相差不大或者左右树高度相差不大即可 树的左旋：头节点倒向左边 ①：节点 ⑴：子树 ① / \\ ② ③ / \\ / \\ ⑷ ⑸ ⑹ ⑺ ①左旋后 ③ / \\ ① ⑺ / \\ ② ⑹ / \\ ⑷ ⑸ 反过来③右旋后是不是变回去，平衡了 树的右旋：头节点导向右边 ①：节点 ⑴：子树 ① / \\ ② ③ / \\ / \\ ⑷ ⑸ ⑹ ⑺ ①右旋后 ② / \\ ⑷ ① / \\ ⑸ ③ / \\ ⑹ ⑺ 反过来②左旋后是不是变回去，平衡了 —————————————————————————————————————— | | | | | ————————————————————————— | | | | | | | | | | | ————————— | | | | | 搜索 | | | | | | 二叉树 | | | | | | | | | | | ————————— | | | | 有左旋右旋的操作 | | | | | | | ————————————————————————— | | AVL树/红黑树/SB树 | | | —————————————————————————————————————— 首先是搜索二叉树，其次提供了左旋右旋的操作，在此基础上每颗树根据自己的平衡标准，利用左旋右旋做平衡 AVL树 增加，删除导致不平衡 其为狭义平衡化 增删改查就是上面的搜索二叉树的操作 增加操作后，检查时机，会往上查一下每个节点是否有平衡性 删除操作后，检查时机，会往上查一下每个节点是否有平衡性 但有个特殊情况，就是如果节点有左右孩子，应该从哪里开始查，比如上面删除3，就要从6开始查 具体如何看平衡性被破坏 6节点的左子树3节点高度比右子树7节点大2，左子树3节点的左子树1节点高度大于右子树4节点，这种情况成为左左(LL)(左孩子的左子树深度大), 右旋调整。 6节点的左子树2节点高度比右子树7节点大2，左子树2节点的左子树1节点高度小于右子树4节点，这种情况成为左右(LR)。 保持平衡性：想办法让4做头部，步骤： 2节点左旋，然后4节点右旋 2节点的左子树1节点高度比右子树5节点小2，右子树5节点的左子树3节点高度大于右子树6节点，这种情况成为右左(RL)。 保持平衡性：想办法让3做头部，步骤：5节点右旋，然后3节点左旋 2节点的左子树1节点高度比右子树4节点小2，右子树4节点的左子树3节点高度小于右子树6节点，这种情况成为右右(RR)，左旋调整。 往上调整时间复杂度：往上走的节点数log(N)个，每个节点调整代价O(1)，所以时间复杂度为O(logN) 如何判断是什么类型 // 检查调整函数 private void rebalance(AVLNode node) { while (node != null) { Node parent = node.parent; int leftHeight = (node.left == null) ? -1 : ((AVLNode) node.left).height; int rightHeight = (node.right == null) ? -1 : ((AVLNode) node.right).height; int nodeBalance = rightHeight - leftHeight; // rebalance (-2 means left subtree outgrow, 2 means right subtree) if (nodeBalance == 2) { // 右树比左树高 if (node.right.right != null) { // RR型 node = (AVLNode)avlRotateLeft(node); // 内部有更新高度 break; } else { // RL型 node = (AVLNode)doubleRotateRightLeft(node); // 内部有更新高度 break; } } else if (nodeBalance == -2) { if (node.left.left != null) { // LL型 node = (AVLNode)avlRotateRight(node); // 内部有更新高度 break; } else { // LR型 node = (AVLNode)doubleRotateLeftRight(node); // 内部有更新高度 break; } } else { updateHeight(node); // 更新高度，插入或删除时平衡性没破坏，但是也要更新高度 } node = (AVLNode)parent; //往上走 } } 介绍SB树及其实现 平衡性 每棵子树的大小，不小于其兄弟的子树大小，既每棵叔叔树的大小，不小于其任何侄子树的大小 A / \\ B C / \\ /\\ D E F G /\\ /\\ /\\ /\\ ............... [B] >= max([F], [G]) [C] >= max([D], [E]) 跟AVL树一样有4种类型，LL, LR, RR, RL 具体实现与调整细节 LL：左孩子的左孩子的大小比右孩子大 L R 是节点，A B C D 都是子树 T / \\ L R / \\ /\\ A B C D 假设来到T, 它的平衡性被破坏了，是因为 [A] >= [R] 它的调整过程叫m(T), m(T)有以下构成 1、先做右旋 L / \\ A T /\\ B R /\\ C D 2、往下检查哪个节点孩子变了，T变化了，执行m(T)继续递归 3、往下检查哪个节点孩子变了，L变化了，执行m(L)继续递归 RR：右孩子的右孩子的大小比左孩子大，即[D] > [A]，调整跟LL类似，先左旋，继续递归 LR：左孩子的右孩子的大小比左孩子大，[B] > [R] L R B是节点，A C D E F 都是子树 T / \\ L R / \\ /\\ A B C D / \\ E F 调整 m(T)，调整步骤如下 1、L左旋 2、T右旋 3、谁的孩子变化了，递归m(L) 4、谁的孩子变化了，递归m(T) 5、谁的孩子变化了，递归m(B) 和AVL树一样，想办法把B改为大头部 B左旋，再右旋 B / \\ L T / \\ / \\ A E F R / \\ C D // 检查调整函数 private SBTNode matain(SBTNode cur) { if (cur == null) { return null; } if (cur.l != null && cur.l.l != null && cur.r != null && cur.l.l.size > cur.r.size) { // LL型 cur = rightRotate(cur); cur.r = matain(cur.r); cur = matain(cur); } else if (cur.l != null && cur.l.r != null && cur.r != null && cur.l.r.size > cur.r.size) { // LR cur.l = leftRotate(cur.l); cur = rightRotate(cur); cur.l = matain(cur.l); cur.r = matain(cur.r); cur = matain(cur); } else if (cur.r != null && cur.r.r != null && cur.l != null && cur.r.r.size > cur.l.size) { // RR cur = leftRotate(cur); cur.l = matain(cur.l); cur = matain(cur); } else if (cur.r != null && cur.r.l != null && cur.l != null && cur.r.l.size > cur.l.size) { // RL cur.r = rightRotate(cur.r); cur = leftRotate(cur); cur.l = matain(cur.l); cur.r = matain(cur.r); cur = matain(cur); } return cur; } 红黑树 最复杂, 现在不怎么用，SB树和AVL树比它好，面试官要你手撕，怼他 平衡标准 新增操作：标准为5个情况 删除操作：标准为8个情况 平衡标准是什么 每个节点不是红就是黑 头结点和叶节点(最底层的空节点，不是没有左右孩子的节点)，必须为黑 任何2个红节点不能相邻 最重要一点：对于任何一个子树来说，从cur当前头部到它叶节点的每一条路径，要求黑节点数量一样 如果我从一个节点出发，往下走，怎么样最长，那一定是：红->黑->红->黑...交替 最短的路就是全黑 当然实际中不同的红黑树情况是不一样的，所以我们这里来分析一种极端的情况： 大家想，如果一棵红黑树有红有黑，它里面如果有一条全黑的路径，那这条全黑的路径一定就是最短路径； 如果有一条是一黑一红，一黑一红...，这样黑红相间的，那他就是最长的路径。 然后它们里面的黑色结点个数又是相同的的，所以最长路径最多是最短路径的两倍，不可能超过最短路径两倍。 所以这样红黑树的高度就能够保持在一个相对平衡的范围内，当然他就没有AVL树那么严格 介绍SkipList及其实现 跳表有着和红黑树、SBT树相同的功能，都能实现在O(log(N))内实现对数据的增删改查操作。但跳表不是以二叉树为原型的 平衡性： 利用随机函数打破输入规律 具体实现与调整细节 记该结构为SkipList，该结构中可以包含有很多结点（SkipListNode），每个结点代表一个被添加到该结构的数据项。 当实例化SkipList时，该对象就会自带一个SkipListNode （不代表任何数据项的头结点）。 public static class SkipListNode, V> { public K key; public V val; public ArrayList> nextNodes; public SkipListNode(K k, V v) { key = k; val = v; nextNodes = new ArrayList>(); } 刚开始有一个默认节点，该key是全局最小(无穷小)，用户给的任何数据都没他小，有一条往外指向空的指针 添加数据 当你向其中添加数据之前，首先会抛硬币，将第一次出现正面朝上时硬币被抛出的次数作为该数据的层数（level，最小为1）， 接着将数据和其层数封装成一个SkipListNode添加到SkipList 中，其他节点抛完硬币就不会再变了 结构初始化时，其头结点的层数为0，但每次添加数据后都会更新头结点(默认节点)的层数为所添数据中层数最大的。 例子1 3-> 3-> 2-> 2-> 2-> 1-> 1-> 1-> 1-> 0-> 0-> 0-> 0-> 默认 3 4 5 来了一个4，层数为2层，如何加进去 默认不需要扩充，永远从最高层开始 最高层开始找到小于等于4最右的节点(默认节点)，也就找到大于4最左的节点(5) 但是4没有到第三层，什么也不做，默认节点本层往下跳，来到第二层 找到小于等于4的最右节点(3节点) 但是4没有到第二层，什么也不做，3节点本层往下跳，来到第一层 找到小于等于4的最右节点(3节点) 4有一层，则3节点的第一层指向4,4的第一层指向5，3节点继续往下跳，来到第零层 找到小于等于4的最右节点(3节点) 4有第零层，则3节点的第零层指向4,4的第零层指向5，结束 例子2 5---------------------->5---------------------->5-> 4---------------------->4---------------->4---->4-> 3---------------->3---->3---------->3---->3---->3-> 2---->2---------->2---->2---------->2---->2---->2-> 1---->1---->1---->1---->1---------->1---->1---->1-> 0---->0---->0---->0---->0---->0---->0---->0---->0-> 默认 3 10 15 20 30 40 50 100 - 增加节点 假设加入2层的70 默认节点，不用扩充，永远从最高层第5层开始，找到小于等于70的节点(20节点第5层)，加速一下子把3,10,15跨过去了，但是70没有第5层，往下跳 来到20第4层，找到小于等于70的节点(50节点第4层)，加速跨过去30,40，但是70没有第4层，往下跳 50来到第3层，找到小于等于70的节点(还是50节点自己)，70没有第3层，往下跳 50来到第2层，找到小于等于70的节点(还是50节点自己)，70没有第2层，往下跳 50来到第1层，找到小于等于70的节点(还是50节点自己)，70有第1层，50第1层指向70第1层，70第1层指向100第1层 50来到第0层，找到小于等于70的节点(还是50节点自己)，70有第0层，50第0层指向70第0层，70第0层指向100第0层 5---------------------->5---------------------------->5-> 4---------------------->4---------------->4---------->4-> 3---------------->3---->3---------->3---->3---------->3-> 2---->2---------->2---->2---------->2---->2---------->2-> 1---->1---->1---->1---->1---------->1---->1---->1---->1-> 0---->0---->0---->0---->0---->0---->0---->0---->0---->0-> 默认 3 10 15 20 30 40 50 70 100 - 查询节点 假设找70节点 肯定不能从第0层开始 从最高层找小于等于70最右的节点(20节点)，它不是70，往下跳到第4层 第4层找小于等于70最右的节点(50节点)，它不是70 50往下跳到第3层,100 > 70 50往下跳到第2层，还是100 50往下跳到第1层，70，找到了 - 删除节点 删除的时候先查询节点，然后把前面的节点指向删除节点后的节点 时间复杂度 利用随机概率生成，0.5的概率为0，0.5的概率为1 假如N个节点 第0层肯定N个 第1层肯定N/2个 第2层差不多N/4个 相当于一颗完全二叉树 总结 AVL树，红黑树，SB树相同点和不同点 相同点 增删改查一样 检查时机一样 调整的方法一样（左旋，右旋） 不同点 具体到每个节点的时候，所判断的违规条件不一样 AVL维持的是高度信息 SB树维持的是节点个数信息 红黑树维持的他自己的标准信息 "},"InterviewPreparation/DataStructuresAlgorithms/02-线性表.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/02-线性表.html","title":"线性表","keywords":"","body":"datetime:2022-04-09 17:46 author:nzb 数据结构与算法 绪论 基本概念 数据 数据元素、数据项 数据对象、数据结构 数据类型、抽象数据类型（ADT） 数据结构三要素 逻辑结构 集合 线性结构 树形结构 图状结构（网状结构） 物理结构（存储结构） 顺序存储 物理内存中是连续的 非顺序存储 物理内存中是分散的 链式存储 索引存储 散列存储 数据的运算 学习建议 概念多，比较无聊。抓大放小，重要的是形成框架，不必纠结细节概念。 线性表 定义 逻辑结构 值的注意的特性 数据元素同类型、有限、有序 重要术语 表长、空表 表头、表尾 前驱、后继 数据元素的位序（从 1 开始） 类似索引 基本操作 运算 创销、增删改查（所有数据结构适用的记忆思路） 判空、判长、打印输出（还可以根据实际需求增加其他基本操作） 其他值的注意的点 理解什么时候要传入参数的引用“&” 值传递还是引用传递 函数命名要有可读性 存储/物理结构 顺序表（顺序存储） 存储结构 逻辑上相邻的数据元素物理上也相邻 实现方式 静态分配 使用“静态数组”实现 大小一旦确定就无法改变 动态分配 使用“动态数组”实现 顺序表存满时，可再用 malloc 动态扩展顺序表的最大容量 需要将数据元素复制到新的存储区域，并用 free 函数释放原区域 特点 随机访问 能在 O(1) 时间内找到第 i 个元素 存储密度高 扩展容量不方便 插入、删除元素不方便 基本操作 插入 插入位置之后的元素都要后移 时间复杂度 最好 O(1) 插入末尾，数据不动 最坏 O (n) 插入表头，数据后移 平均 O(n) 删除 删除位置之后的元素都要前移 时间复杂度 最好 O(1) 删除末尾，数据不动 最坏 O (n) 删除表头，数据前移 平均 O(n) 查找 按位查找 获取表 L 中第 i 个位置的元素的值 用数组下标即可得到第 i 个元素 L.data[i - 1] 时间复杂度 最好、最坏、平均时间复杂度都是 O(1) 按值查找 在顺序表 L 中查找第一个元素值等于 e 的元素，并返回其位序 从第一个元素开始依次往后检索 时间复杂度 最好 O(1) 第一个位置 最坏 O(n) 最坏一个位置 平均 O(n) 每个位置的概率相同 代码要点 注意位序 i 和数组下标的区别 位序是第几个元素，从 1 开始，下标是从 0 开始 判断位序 i 的合法性 链表（链式存储） 单链表 定义 用“链式存储”（存储结构）实现了“线性结构”（逻辑结构） 一个结点存储一个数据元素 各结点间先后关系用一个指针表示 两种实现 不带头结点 空表判断：L == NULL，写代码不方便 带头结点 空表判断：L -> next == NULL，写代码方便 头指针 L 加上下一个结点不带数据只带下一个结点的指针域 基本操作 插入 按位序插入 循环遍历找到第 i -1 的节点，然后插入 带头结点 当前指针指向，从 0 开始，表示第几个节点 不带头结点 当前指针指向，从 1 开始，表示第几个节点 指定结点的后插操作 在 p 结点后插入元素 e s 为插入的结点 s -> data = e s-> next = p->next p->next = s 指定结点的前插操作 知道头指针 依次遍历找到 p 结点，然后插入即可，时间复杂度 O(n) 不知道头指针 在 p 结点后插入元素 e s 为插入的结点 s -> next = p -> next s -> data = p -> data p -> data = e p -> next = s 删除 按位序删除 和插入操作类似 指定结点的删除 删除指定结点 p 需要改变前驱结点的 next 指针 方法1：传入头指针，循环找 p 的前驱结点 方法2：类似结点前插入 p -> data = p -> next -> data p -> next = p -> next -> next 指定结点是最后一个结点时，需要特殊处理，因为q -> next = NULL，没有 data 查找 注意带头和不带头以及最后一个结点（就是 p 指针为 NULL） 按位查找 注意与“顺序表”对比 单链表不具备“随机访问”的特性，只能依次扫描 按值查找 求单链表长度 Key 三种基本操作的时间复杂度都是 O(n) 注意边界条件的处理 建立 尾插法 头插法 链表的逆置 双链表 初始化 头结点的 prior、next 都指向 NULL 插入（后插） 注意新插入结点、前驱结点、后继结点的指针修改 边界情况：新插入结点在最后一个位置，需特殊处理 删除（后删） 注意删除结点的前驱结点、后继结点的指针修改 边界情况：如果被删除结点是最后一个数据结点，需特殊处理 遍历 从一个给定结点开始，向后遍历、向前遍历的实现（循环的终止条件） 链表不具备随机存取特性，查找操作只能通过顺序遍历实现 循环链表 循环单链表 判断循环单链表是否为空：L -> next == L 判断结点 p 是否为循环单链表的表尾结点：p -> next == L，p指针下一个是否指向头指针 循环双链表 判断循环双链表是否为空：L -> next == L 判断结点 p 是否为循环双链表的表尾结点：p -> next == L，p指针下一个是否指向头指针 静态链表 用数组的方式实现的链表 优点：增、删操作不需要大量移动元素 缺点：不能随机存取，只能从头结点开始依次往后查找；容量固定不可变 适用场景 不支持指针的低级语言 数据元素数量固定不变的场景（如操作系统的文件分配表 FAT） 使用 随机存取就是直接存取，可以通过下标直接访问的那种数据结构，与存储位置无关，例如数组。 非随机存取就是顺序存取了，不能通过下标访问了，只能按照存储顺序存取，与存储位置有关，例如链表。 "},"InterviewPreparation/DataStructuresAlgorithms/03-栈.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/03-栈.html","title":"栈","keywords":"","body":"datetime:2022-04-09 17:46 author:nzb 数据结构与算法 绪论 基本概念 数据 数据元素、数据项 数据对象、数据结构 数据类型、抽象数据类型（ADT） 数据结构三要素 逻辑结构 集合 线性结构 树形结构 图状结构（网状结构） 物理结构（存储结构） 顺序存储 物理内存中是连续的 非顺序存储 物理内存中是分散的 链式存储 索引存储 散列存储 数据的运算 学习建议 概念多，比较无聊。抓大放小，重要的是形成框架，不必纠结细节概念。 栈（Stack） 定义 一种操作受限的线性表，只能在栈顶插入、删除 特性：后进先出（FIFO） 术语：栈顶、栈底、空栈 基本操作 创、销 增、删（元素进栈、出栈，只能在栈顶操作） 增 删 查（获得栈顶元素，但不删除） 判空 S.top = -1 栈顶指针为-1 顺序栈 顺序存储 用静态数组实现 ，并需要记录栈顶指针 基本操作 创、增、删、查 销：清空、回收 只需要 top = -1 都是 O(1) 时间复杂度 两种实现 初始化 top = -1 指向栈顶元素 入栈 S.data[++S.top] = x 是先栈顶指针加一后赋值，不能先赋值在加一，这样会覆盖元素 出栈 x = S.data[S.top--] 是先赋值后栈顶指针减一 获得栈顶元素 x = S.data[S.top] 栈空/满栈条件？ 到达栈顶：s.top = MaxSize -1 初始化 top = 0 指向栈顶元素的后一位，接下来可以插入元素的位置 入栈 S.data[S.top++] = x 先赋值在加一 出栈 x = S.data[--S.top]] 是先栈顶指针减一后赋值 获得栈顶元素 x = S.data[S.top-1] 栈空/满栈条件？ 到达栈顶：s.top = MaxSize 共享栈 两个栈共享同一片内存空间，两个栈从两边往中间增长 初始化 0 号栈栈顶指针初始时 top0 = -1；1 号栈栈顶指针初始时 top1 = MaxSize 栈满条件 top0 + 1 = top1 链栈 跟单链表类似，只是只能在头部操作 用链式方式实现的栈 两种实现方式 带头结点 不带头结点（推荐） 基本操作 创（初始化） 增（进栈） 删（出栈） 查（获取栈顶元素） 如何判空、判满？ 栈的应用 括号匹配 依次扫描所有字符，遇到左括号入栈，遇到右括号则弹出栈顶元素检查是否匹配 匹配失败情况 左括号单身 栈非空 右括号单身 栈已空 左右括号不匹配 表达式求值 概念 运算符、操作数、界限符 三种表达式 中缀表达式（人算） 运算符在操作数中间 后缀表达式（机算，常用） 运算符在操作数后面 一个中缀表达式可以对应多个后缀、前缀表达式 前缀表达式（机算，不常用） 运算符在操作数前面 后缀表达式 中缀转后缀 按“左优先”原则确定运算符的运算次序 一个中缀表达式只对应一个后缀表达式（确保算法的“确定性”） 根据上面确定的次序，依次将各个运算符和与之相邻的两个操作数按 的规则合体 后缀转中缀 从左往右扫描，每遇到一个运算符，就 将 变为 (左操作数 运算符 右操作数)的形式 计算 从左往右扫描，遇到操作数入栈，遇到运算符则弹出两个栈顶元素运算后入栈（注意：先弹出的元素是“右操作数”） 前缀表达式 中缀转前缀 按“右优先”原则确定运算符的运算次序 根据上面确定的次序，依次将各个运算符和与之相邻的两个操作数按 的规则合体 计算 从右往左扫描，遇到操作数入栈，遇到运算符则弹出两个栈顶元素运算后入栈（注意：先弹出的元素是“左操作数”） 递归 栈中的每一个元素对应内存中的一块区域里面的数据不跟其他元素冲突 "},"InterviewPreparation/DataStructuresAlgorithms/04-队列.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/04-队列.html","title":"队列","keywords":"","body":"datetime:2022-04-09 17:46 author:nzb 数据结构与算法 绪论 基本概念 数据 数据元素、数据项 数据对象、数据结构 数据类型、抽象数据类型（ADT） 数据结构三要素 逻辑结构 集合 线性结构 树形结构 图状结构（网状结构） 物理结构（存储结构） 顺序存储 物理内存中是连续的 非顺序存储 物理内存中是分散的 链式存储 索引存储 散列存储 数据的运算 学习建议 概念多，比较无聊。抓大放小，重要的是形成框架，不必纠结细节概念。 队列 定义 一种操作受限的线性表，只能在队尾插入、在队头删除 特性：先进先出（FIFO） 术语：队头、队尾、空队列、队头元素、队尾元素 基本操作 创、销 增、删（入队、出队、只能在规定的一段进行） 查（获得队头元素，但不删除） 判空 队列的顺序实现 实现思路 用静态数组存放数据 元素，设置队头/队尾（front、rear）指针 循环队列：用模运算（取余）将存储空间在逻辑上变为“环状” Q.rear = (Q.rear + 1) % MaxSize 重要考点 如何初始化、入队、出队 如何判空、判满 如何计算队列的长度 分析思路 确定 front、rear 指针的指向 rear 指向队尾元素后一个位置 rear 指向队尾元素 确定判空判满的方法 牺牲一个存储单元 增加 size 变量记录队列长度 增加 tag = 0/1 用于标记最近的一次操作是出队/入队 队列的链式实现 区别 带头结点 不带头结点 基本操作 创（初始化） 增（入队） 注意第一个元素入队 删（出队） 注意 最后一个元出队 查（获取队头元素） 判空 判满？不存在的，可以无限加（内存足够） 队列变种 双端队列 允许从两端插入、两端删除的队列 输入受限的双端队列 允许从两端删除、从一端插入的队列 输出受限的双端队列 允许从两端插入、从一端删除的队列 队列应用 树的层次遍历 图的广度优先遍历 操作系统的应用 CPU资源的分配：多个进程运行（浏览器、QQ、微信） 打印数据缓冲区 "},"InterviewPreparation/DataStructuresAlgorithms/05-特殊矩阵压缩存储.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/05-特殊矩阵压缩存储.html","title":"特殊矩阵压缩存储","keywords":"","body":"datetime:2022-04-09 17:46 author:nzb 数据结构与算法 绪论 基本概念 数据 数据元素、数据项 数据对象、数据结构 数据类型、抽象数据类型（ADT） 数据结构三要素 逻辑结构 集合 线性结构 树形结构 图状结构（网状结构） 物理结构（存储结构） 顺序存储 物理内存中是连续的 非顺序存储 物理内存中是分散的 链式存储 索引存储 散列存储 数据的运算 学习建议 概念多，比较无聊。抓大放小，重要的是形成框架，不必纠结细节概念。 特殊矩阵压缩存储 对称矩阵 特点 对方阵中的任意一个元素，有 a(i,j) = a(j,i) 压缩 只存储主对角线 + 下三角区（或主对角线 + 上三角区） 三角矩阵 特点 上三角区全为常数（下三角矩阵）；或下三角区全为常数（上三角矩阵） 压缩 按行优先/列优先规则依次存储非 常量区域，并在最后一个位置存放常量 c 三对角矩阵（带状矩阵） 特点 当 |i - j| > 1时，有 a (i,j) = 0（1 压缩 按行优先/列优先规则依次存储带状区域 稀疏矩阵 特点 非零元素个数远小于零元素个数 压缩 只存储非零元素 顺序存储 顺序存储三元组（行，列，值） 链式存储 十字链表法 "},"InterviewPreparation/DataStructuresAlgorithms/06-串.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/06-串.html","title":"串","keywords":"","body":"datetime:2022-04-09 17:46 author:nzb 数据结构与算法 绪论 基本概念 数据 数据元素、数据项 数据对象、数据结构 数据类型、抽象数据类型（ADT） 数据结构三要素 逻辑结构 集合 线性结构 树形结构 图状结构（网状结构） 物理结构（存储结构） 顺序存储 物理内存中是连续的 非顺序存储 物理内存中是分散的 链式存储 索引存储 散列存储 数据的运算 学习建议 概念多，比较无聊。抓大放小，重要的是形成框架，不必纠结细节概念。 串 字符串 定义 串，即字符串（string）是由零个或多个字符组成的有限序列 术语：串长、空串、空格串、子串、主串、字符在主串中的位置、子串在主串中的位置 串 V.S 线性表 串的数据对象限定为字符集 串的基本操作大多以“子串”为操作对象 基本操作 定位操作 比较操作 字符集编码 每个字符在计算机中对应一个二进制数，比较字符的大小其实就是比较二进制数的大小 存储结构 顺序存储和链式存储跟线性表一样 顺序存储 静态数组 动态数组 链式存储 可让每个结点存多个字符，没有字符的位置使用“#” 或 “\\0”补足 静态数组 基本操作 求子串 串的比较 求串在主串中的位置 子串匹配算法 朴素模式匹配算法 串的模式匹配：在主串中找到与模式串相同的子串，并返回其所在的位置 朴素模式匹配算法（简单模式匹配算法）思想 将主串中与模式串长度相同的子串搞出来，挨个与模式串对比 当子串与模式串某个对应字符不匹配时，就立即放弃当前子串，转而检索下一个子串 若模式串长度为 m，主串长度为 n，则直到匹配成功/匹配失败最多需要（n - m + 1）* m次比较 最坏时间复杂度：O(nm) 最坏情况：每个子串的前 m- 1个字符都和模式串匹配，只有第 m 个字符不匹配 比较好的情况：每个子串的第 1 个字符就与模式串不匹配 KMP 算法 粗劣分析算法性能 KMP 算法优化 二者比较 朴素模式匹配算法的缺点：当某些子串与模式串能部分匹配时，主串的扫描指针 i 经常回溯，导致时间开销增加。最坏时间复杂度 O(nm) KMP 算法：当子串和模式串不匹配时，主串指针 i 不回溯，模式串指针 j = next[j] 如果不会经常出现子串与模式串部分匹配的时候，KMP 算法性能也不会比朴素算法好多少 算法平均时间复杂度：O(n + m) next 数组手算方法：当第 j 个字符匹配失败，由前 1~j - 1 个字符组成的串记为 S，则：next[j] = S 的最长相等前后缀长度 + 1 特别的：next[1] = 0, next[2] = 1 "},"InterviewPreparation/DataStructuresAlgorithms/07-树与二叉树.html":{"url":"InterviewPreparation/DataStructuresAlgorithms/07-树与二叉树.html","title":"树与二叉树","keywords":"","body":"datetime:2022-04-09 17:46 author:nzb 数据结构与算法 绪论 基本概念 数据 数据元素、数据项 数据对象、数据结构 数据类型、抽象数据类型（ADT） 数据结构三要素 逻辑结构 集合 线性结构 树形结构 图状结构（网状结构） 物理结构（存储结构） 顺序存储 物理内存中是连续的 非顺序存储 物理内存中是分散的 链式存储 索引存储 散列存储 数据的运算 学习建议 概念多，比较无聊。抓大放小，重要的是形成框架，不必纠结细节概念。 链表和数组的区别 数组静态分配内存，链表动态分配内存； 数组在内存中连续，链表不连续是分散的； 数组元素在栈区，链表元素在堆区； 数组利用下标定位，时间复杂度为O(1)，链表定位元素时间复杂度O(n)； 链表也没有下标的概念，只能通过头节点指针，从每一个节点，依次往下找，因为下个节点的位置信息只能通过上个节点知晓。 数组插入或删除元素的时间复杂度O(n)，链表的时间复杂度O(1)。 链表只需要知道操作位置的指针 树与二叉树 定义 树（Tree）是 n（n>=0)个结点的有限集。n=0 时称为空树。在任意一颗非空树中： 1）有且仅有一个特定的称为根（Root）的结点； 2）当 n>1 时，其余结点可分为 m(m>0) 个互不相交的有限集T1、T2、......、Tn，其中每一个集合本身又是一棵树，并且称为根的子树。 此外，树的定义还需要强调以下两点： 1）n>0 时根结点是唯一的，不可能存在多个根结点，数据结构中的树只能有一个根结点。 2）m>0 时，子树的个数没有限制，但它们一定是互不相交的。 示例树： 结点的度 一个结点拥有的子树数目称为结点的度。叶子节点的度为 0 。 叶子节点：没有子节点的节点 所有节点中的最大的度称为树的 度，树中的节点树即为树中所有节点的度之和加一：即：树中的节点树 = 树中所有节点的度之和 + 1 结点关系 结点子树的根结点为该结点的孩子结点。相应该结点称为孩子结点的双亲结点。 上图中，A 为 B 的双亲结点，B 为 A 的孩子结点。 同一个双亲结点的孩子结点之间互称兄弟结点。 上图中，结点 B 与结点 C 互为兄弟结点。 结点层次和树的深度 从根开始定义起，根为第一层，根的孩子为第二层，以此类推。 树中结点的最大层次数称为树的深度或高度。上图所示树的深度为4。 二叉树 定义 二叉树是 n(n>=0) 个结点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根结点和两棵互不相交的、分别称为根结点的左子树和右子树组成。 二叉树特点 1）每个结点最多有两颗子树，所以二叉树中不存在度大于2的结点。 2）左子树和右子树是有顺序的，次序不能任意颠倒。 3）即使树中某结点只有一棵子树，也要区分它是左子树还是右子树。 4）非空二叉树只有一个根节点。 二叉树性质 1）在二叉树的第 i 层上最多有 2^(i-1) 个节点 。（i>=1） 2）二叉树中如果深度为 k ,那么最多有 2^k-1个节点。(k>=1） 3）n0 = n2 + 1： 度为0的节点（叶子节点）总是比度为 2 的节点多一个。 n0 表示度数为 0 的节点数，n2 表示度数为2的节点数。 4）在完全二叉树中，具有n个节点的完全二叉树的深度为[log2n]+1，其中[log2n]是向下取整。 具有 n 个节点的二叉树的深度至少为 [log2n]+1，其中 [log2n] 是向下取整。 5）若对含 n 个结点的完全二叉树从上到下且从左至右进行 1 至 n 的编号，则对完全二叉树中任意一个编号为 i 的结点有如下特性： (1) 若 i=1，则该结点是二叉树的根，无双亲, 否则，编号为 [i/2] 的结点为其双亲结点; (2) 若 2i>n，则该结点无左子树， 否则，编号为 2i 的结点为其左子树结点； (3) 若 2i+1>n，则该结点无右子树， 否则，编号为 2i+1 的结点为其右子树结点。 斜树 斜树：所有的结点都只有左子树的二叉树叫左斜树。所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。 满二叉树 满二叉树：在一棵二叉树中。如果所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 满二叉树的特点有： 1）第 k 层上有 2 ^ (k - 1) 个节点。 2）深度为 m 的满二叉树有 2 ^m - 1个节点 3）非叶子结点的度一定是2。 完全二叉树 完全二叉树：对一颗具有 n 个结点的二叉树按层编号，如果编号为 i(1 除最后一层外，每一层的节点数都达到了最大值，在最后一层上只缺少右边的若干个节点。 满二叉树一定是完全二叉树，但反过来不一定成立。 二叉树的存储结构 顺序存储 二叉树的顺序存储结构就是使用一维数组存储二叉树中的结点，并且结点的存储位置，就是数组的下标索引。 二叉树为完全二叉树 一棵完全二叉树采用顺序存储方式，当二叉树为完全二叉树时，结点数刚好填满数组。 二叉树不为完全二叉树 其中浅色结点表示结点不存在，其中，∧表示数组中此位置没有存储结点。此时可以发现，顺序存储结构中已经出现了空间浪费的情况。 右斜树 对于这种右斜树极端情况，采用顺序存储的方式是十分浪费空间的。 因此，顺序存储一般适用于完全二叉树。 二叉链表 链式存储：由二叉树定义可知，二叉树的每个结点最多有两个子节点。因此，可以将结点数据结构定义为一个数据和两个指针域。 采用一种链表结构存储二叉树，这种链表称为二叉链表。 二叉树遍历 二叉树的遍历一个重点考查的知识点。 定义 二叉树的遍历：是指从二叉树的根结点出发，按照某种次序依次访问二叉树中的所有结点，使得每个结点被访问一次，且仅被访问一次。 二叉树的访问次序可以分为四种 前序遍历 中序遍历 后序遍历 层序遍历 前序遍历 根 - 左 - 右 前序遍历通俗的说就是从二叉树的根结点出发，当第一次到达结点时就输出结点数据，按照先向左在向右的方向访问。 上图所示二叉树的前序遍历输出为：ABDHIEJCFG 中序遍历 左 - 根 - 右 中序遍历就是从二叉树的根结点出发，当第二次到达结点时就输出结点数据，按照先向左在向右的方向访问。 上图所示二叉树的前序遍历输出为：HDIBJEAFCG 后序遍历 左 - 右 - 根 后序遍历就是从二叉树的根结点出发，当第三次到达结点时就输出结点数据，按照先向左在向右的方向访问。 上图所示二叉树的前序遍历输出为：HIDJEBFGCA 层次遍历 层次遍历就是按照树的层次自上而下的遍历二叉树。针对上图所示二叉树的层次遍历结果为：ABCDEFGHIJ 遍历常考考点 1）已知前序遍历序列和中序遍历序列，确定一棵二叉树。 例题：若一棵二叉树的前序遍历为ABCDEF，中序遍历为CBAEDF，请画出这棵二叉树。 分析：前序遍历第一个输出结点为根结点，故A为根结点。早中序遍历中根结点处于左右子树结点中间，故结点A的左子树中结点有CB，右子树中结点有EDF。 按照同样的分析方法，对A的左右子树进行划分，最后得出二叉树的形态如下图所示 2）已知后序遍历序列和中序遍历序列，确定一棵二叉树。 后序遍历中最后访问的为根结点，因此可以按照上述同样的方法，找到根结点后分成两棵子树，进而继续找到子树的根结点，一步步确定二叉树的形态。 注：已知前序遍历序列和后序遍历序列，不可以唯一确定一棵二叉树。 "},"InterviewPreparation/ClassicQuestion/20201027/":{"url":"InterviewPreparation/ClassicQuestion/20201027/","title":"2020","keywords":"","body":"datetime:2020/10/27 16:58 author:nzb 文件操作 现在要处理一个大小为 10 G 的文件，但是内存只有 4 G，如果在只修改 get_lines 函数而其他代码保持不变的情况下，应该如何实现？需要考虑的问题都有那些？ def get_lines(): with open('file.txt', 'rb') as f: for i in f: yield i 遍历目录与子目录 抓取.pyc文件 第一种 import os def get_files(dir, suffix): res = [] for root, dirs, files in os.walk(dir): for filename in files: name, suf = os.path.splitext(filename) if suf == suffix: res.append(os.path.join(root, filename)) print(res) get_files(\"./\", '.pyc') 第二种 import os def pick(obj): if obj.endswith(\".pyc\"): print(obj) def scan_path(ph): file_list = os.listdir(ph) for obj in file_list: if os.path.isfile(obj): pick(obj) elif os.path.isdir(obj): scan_path(obj) if __name__ == '__main__': path = input('输入目录') scan_path(path) 第三种 from glob import iglob def func(fp, postfix): for i in iglob(f\"{fp}/**/*{postfix}\", recursive=True): print(i) if __name__ == \"__main__\": postfix = \".pyc\" func(\"K:\\Python_script\", postfix) 数字字符串转整形 字符串 \"123\" 转换成 123 ，不使用内置api，例如 int() 第一种 def atoi(s): num = 0 for v in s: for j in range(10): if v == str(j): num = num * 10 + j return num 第二种 def atoi(s): num = 0 for v in s: num = num * 10 + ord(v) - ord('0') return num 第三种 def atoi(s): num = 0 for v in s: t = \"%s * 1\" % v n = eval(t) num = num * 10 + n return num 第四种 from functools import reduce def atoi(s): return reduce(lambda num, v: num * 10 + ord(v) - ord('0'), s, 0) 数字字符串排序 让所有奇数都在偶数前面，而且奇数升序排列，偶数降序排序，如字符串'1982376455',变成'1355798642' print(\"\".join(sorted('1982376455', key=lambda x: int(x) % 2 == 0 and 20 - int(x) or int(x)))) # 分解 int(x) % 2 == 0 and 20 - int(x) # 这是排序偶数，降序排序 int(x) # 剩下的奇数升序排序 python函数重载机制？ 函数重载主要是为了解决两个问题。 1。可变参数类型。 2。可变参数个数。 另外，一个基本的设计原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同 的，此时才使用函数重载，如果两个函数的功能其实不同，那么不应当使用重载，而应当使用一个名字 不同的函数。 好吧，那么对于情况 1 ，函数功能相同，但是参数类型不同，python 如何处理？答案是根本不需要处 理，因为 python 可以接受任何类型的参数，如果函数的功能相同，那么不同的参数类型在 python 中 很可能是相同的代码，没有必要做成两个不同函数。 那么对于情况 2 ，函数功能相同，但参数个数不同，python 如何处理？大家知道，答案就是缺省参 数。对那些缺少的参数设定为缺省参数即可解决问题。因为你假设函数功能相同，那么那些缺少的参数 终归是需要用的。 好了，鉴于情况 1 跟 情况 2 都有了解决方案，python 自然就不需要函数重载了。 回调函数，如何通信的? 回调函数是把函数的指针(地址)作为参数传递给另一个函数，将整个函数当作一个对象，赋值给调用的函数。 闭包延迟 详情 下面这段代码的输出结果将是什么？请解释。 def multipliers(): return [lambda x: i * x for i in range(4)] print([m(2) for m in multipliers()]) 上面代码的输出结果是 [6,6,6,6]，不是我们想的 [0,2,4,6] 上述问题产生的原因是python闭包的延迟绑定。这意味着内部函数被调用时，参数的值在闭包内进行查找。 因此，当任何由multipliers()返回的函数被调用时,i的值将在附近的范围进行查找。 那时，不管返回的函数是否被调用，for循环已经完成，i被赋予了最终的值3. def multipliers(): for i in range(4): yield lambda x: i * x 你如何修改上面的 multipliers 的定义产生想要的结果？ def multipliers(): return [lambda x, i=i: i * x for i in range(4)] 单例模式 装饰器 from functools import wraps def singleton(cls): _instance = {} @wraps(cls) def wrapper(*args, **kwargs): if cls not in _instance: _instance[cls] = cls(*args, **kwargs) return _instance[cls] return wrapper 使用基类 class SingletonMeta(object): def __new__(cls, *args, **kwargs): if not hasattr(cls, \"__instance\"): setattr(cls, \"__instance\", super().__new__(cls, *args, **kwargs)) return getattr(cls, \"__instance\") class Foo(SingletonMeta): pass 使用元类 class SingletonMeta(type): \"\"\"自定义元类\"\"\" def __call__(cls, *args, **kwargs): if not hasattr(cls, \"__instance\"): setattr(cls, \"__instance\", super().__call__(*args, **kwargs)) return getattr(cls, \"__instance\") class Foo(metaclass=SingletonMeta): pass 请用一行代码实现将 1-N 的整数列表以 3 为单位分组 N = 100 print([[x for x in range(1, 100)][i:i + 3] for i in range(0, 100, 3)]) Python的魔法方法 魔法方法就是可以给你的类增加魔力的特殊方法，如果你的对象实现（重载）了这些方法中的某一个，那么这个方法就会在特殊的情况下被Python所调用， 你可以定义自己想要的行为，而这一切都是自动发生的，它们经常是两个下划线包围来命名的（比如 __init__ , __len__ ), Python的魔法方法是非常强的所以了解其使大用方法也变得尤为重要! __init__： 构造器，当一个实例被创建的时候初始化的方法，但是它并不是实例化调用的第一个方法。__new__：才是实例化对象调用的第一个方法，它只取下 cls 参数，并把其他参数传给 __init___。 __new__： 很少使用，但是也有它适合的场景，尤其是当类继承自一个像元祖或者字符串这样不经常改变的类型的时候。 __call__： 让一个类的实例像函数一样被调用 __getitem__： 定义获取容器中指定元素的行为，相当于 self[key] __getattr__： 定义当用户试图访问一个不存在属性的时候的行为。 __setattr__： 定义当一个属性被设置的时候的行为 __getattribute___： 定义当一个属性被访问的时候的行为 __new__在 py2 和 py3 的区别 py2 __init__ 有形参和args和kwargs，实例化传不传实参都支持 > super(AgvStatusMonitor, cls).__new__(cls) - `super(AgvStatusMonitor, cls).__new__(cls, *args, **kwargs)` py3 实例化实例时 __init__传参数（也可不传参数）：super(AgvStatusMonitor, cls).__new__(cls) 或 super(AgvStatusMonitor, cls).__new__(cls, *args, **kwargs) __init__不传参数（传参数报错）：super(AgvStatusMonitor, cls).__new__(cls, *args, **kwargs) 多进程多线程以及协程的理解 这个问题被问的概念相当之大， 进程：一个运行的程序（代码）就是一个进程，没有运行的代码叫程序，进程是系统资源分配的最小单 位，进程拥有自己独立的内存空间，所有进程间数据不共享，开销大。 线程: cpu调度执行的最小单位，也叫执行路径，不能独立存在，依赖进程存在，一个进程至少有一个线 程，叫主线程，而多个线程共享内存（数据共享，共享全局变量),从而极大地提高了程序的运行效率。 协程: 是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。 协程调度时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和 栈，直接操中栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。 协程 python asyncio的原理？asyncio 这个库就是使用 python 的 yield 这个可以打断保存当前函数的上下文的机制， 封装好了 selector 摆脱掉了复杂的回调关系 单线程+异步 I/O Python异步使用场景有那些 1、 不涉及共享资源，获对共享资源只读，即非互斥操作 2、 没有时序上的严格关系 3、 不需要原子操作，或可以通过其他方式控制原子性 4、 常用于IO操作等耗时操作，因为比较影响客户体验和使用性能 5、 不影响主线程逻辑 多线程竞争 线程是非独立的，同一个进程里线程是数据共享的，当各个线程访问数据资源时会出现竞争状态即：数据几乎同步会被多个线程占用，造成数据混乱，即所谓的线程不安全 那么怎么解决多线程竞争问题？---锁 锁的好处： 确保了某段关键代码（共享数据资源）只能由一个线程从头到尾完整地执行能解决多线程资源竞争下的原子操作问题。 锁的坏处： 阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了 锁的致命问题: 死锁 Python的线程同步 setDaemon(False) 当一个进程启动之后，会默认产生一个主线程，因为线程是程序执行的最小单位，当设置多线程时，主线程会创建多个子线程，在 Python 中， 默认情况下就是 setDaemon(False) ,主线程执行完自己的任务以后，就退出了，此时子线程会继续执行自己的任务，直到自己的任务结束。 import threading import time def thread(): time.sleep(2) print('---子线程结束---') def main(): t1 = threading.Thread(target=thread) t1.start() print('---主线程--结束') if __name__ == '__main__': main() # 执行结果 # ---主线程 - -结束 # ---子线程结束 - -- setDaemon（True) 当我们使用 setDaemon(True) 时，这是子线程为守护线程，主线程一旦执行结束，则全部子线程被强制终止 import threading import time def thread(): time.sleep(2) print('---子线程结束 - --') def main(): t1 = threading.Thread(target=thread) t1.setDaemon(True) # 设置子线程守护主线程 t1.start() print('---主线程结束---') if __name__ == '__main__': main() # 执行结果 # ---主线程结束 - -- # 只有主线程结束，子线程来不及执行就被强制结束 join（线程同步) join 所完成的工作就是线程同步，即主线程任务结束以后，进入堵塞状态，一直等待所有的子线程结束以后，主线程再终止。 当设置守护线程时，含义是主线程对于子线程等待 timeout 的时间将会杀死该子线程，最后退出程序，所以说，如果有 10 个子线程， 全部的等待时间就是每个 timeout 的累加和，简单的来说，就是给每个子线程一个 timeout 的时间，让他去执行，时间一到，不管任务有没有完成，直接杀死。 没有设置守护线程时，主线程将会等待timeout的累加和这样的一段时间，时间一到，主线程结束，但是并没有杀死子线程，子线程依然可以继续执行，直到子线程全部结束，程序退出。 import threading import time def thread(): time.sleep(2) print('---子线程结束---') def main(): t1 = threading.Thread(target=thread) t1.setDaemon(True) t1.start() t1.join(timeout=1) # 1 线程同步，主线程堵塞1s 然后主线程结束，子线程继续执行 # 2 如果不设置timeout参数就等子线程结束主线程再结束 # 3 如果设置了setDaemon=True和timeout=1主线程等待1s后会强制杀死子线程，然后主线程结束 print('---主线程结束---') if __name__ == '__main___': main() 锁及其分类 定义：锁(Lock)是 python 提供的对线程控制的对象。 分类：互斥锁，可重入锁，死锁 死锁 若干子线程在系统资源竞争时，都在等待对方对某部分资源解除占用状态，结果是谁也不愿先解锁，互相干等着，程序无法执行下去，这就是死锁。 GIL锁 全局解释器锁（互斥锁） 作用： 限制多线程同时执行，保证同一时间只有一个线程执行，所以cython里的多线程其实是伪多线程！ 所以python里常常使用协程技术来代替多线程，协程是一种更轻量级的线程。 进程和线程的切换时由系统决定，而协程由我们程序员自己决定，而模块gevent下切换是遇到了耗时操作时才会切换 三者的关系：进程里有线程，线程里有协程。 多线程交互访问数据，怎么避免重读？ 创建一个已访问数据列表，用于存储已经访问过的数据，并加上互斥锁，在多线程访问数据的时候先查看数据是否在已访问的列表中，若已存在就直接跳过。 什么是线程安全，什么是互斥锁？ 每个对象都对应于一个可称为’互斥锁‘的标记，这个标记用来保证在任一时刻，只能有一个线程访问该对象。 同一进程中的多线程之间是共享系统资源的，多个线程同时对一个对象进行操作，一个线程操作尚未结束，另一线程已经对其进行操作， 导致最终结果出现错误，此时需要对被操作对象添加互斥锁，保证每个线程对该对象的操作都得到正确的结果。 同步、异步、阻塞、非阻塞 同步： 多个任务之间有先后顺序执行，一个执行完下个才能执行。 异步： 多个任务之间没有先后顺序，可以同时执行，有时候一个任务可能要在必要的时候获取另一个同时执行的任务的结果，这个就叫回调！ 阻塞： 如果卡住了调用者，调用者不能继续往下执行，就是说调用者阻塞了。 非阻塞： 如果不会卡住，可以继续执行，就是说非阻塞的。 同步异步相对于多任务而言，阻塞非阻塞相对于代码执行而言。 僵尸进程和孤儿进程及怎么避免僵尸进程？ 孤儿进程： 父进程退出，子进程还在运行的这些子进程都是孤儿进程，孤儿进程将被 init 进程（进程号为 1 ）所收养，并由 init 进程对他们完成状态收集工作。 僵尸进程： 进程使用fork 创建子进程，如果子进程退出，而父进程并没有调用 wait 获 waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。 避免僵尸进程的方法： 1.fork 两次用孙子进程去完成子进程的任务 2.用 wait() 函数使父进程阻塞 3.使用信号量，在 signal handler 中调用 waitpid , 这样父进程不用阻塞 IO密集型和CPU密集型区别？ IO密集型：系统运行，大部分的状况是CPU在等 I/O（硬盘/内存）的读/写。 CPU密集型：大部分时间用来做计算，逻辑判断等 CPU 动作的程序称之 CPU 密集型。 python中进程与线程的使用场景？ 多进程适合在 CPU 密集操作（ cpu 操作指令比较多，如位多的的浮点运算）。 多线程适合在 IO 密性型操作（读写数据操作比多的的，比如爬虫） 线程是并发还是并行，进程是并发还是并行？ 并发是指一个处理器同时处理多个任务。 并行是指多个处理器或者是多核的处理器同时处理多个不同的任务。 线程是并发，进程是并行; 进程之间互相独立，是系统分配资源的最小单位，同一个进程中的所有线程共享资源。 TCP和UDP 详情 TCP 套接字：是使用 TCP 协议提供的传输服务来实现网络通信的编程接口。 UDP 套接字：一种非常轻便的传输协议，也称做用户数据报协议，简称 UDP。 TCP 和 UDP 都是提供端到端传输服务的协议。 二者的差别：就如同打电话和发短信的区别， 后者不对传输的可靠性和可达性做出任何承诺从而避免了 TCP 中握手和重传的开销， 所以在强调性能和而不是数据完整性的场景中（例如传输网络音视频数据），UDP 可能是更好的选择。 可能大家会注意到一个现象，就是在观看网络视频时，有时会出现卡顿，有时会出现花屏， 这无非就是部分数据传丢或传错造成的。 浏览器通过WSGI请求动态资源的过程? 浏览器发送的请求被 Nginx 监听到，Nginx 根据请求的 URL 的 PATH 或者后缀把请求静态资源的分发到静态资源的目录， 别的请求根据配置好的转发到相应端口。 实现了 WSGI 的程序会监听某个端口，监听到 Nginx 转发过来的请求接收后 (一般用 socket 的 recv 来接收 HTTP 的报文)以后把请求的报文封装成 environ 的字典对象， 然后再提供一个 startresponse 的方法。把这两个对象当成参数传入某个方法比如 wsgiapp(environ, start_response) 或者实现了 __call(self, environ, start_response) 方法的某个实例。这个实例再调用 start_response 返回给实现了 WSGI 的中间件，再由中间件返回给 Nginx。 Django 项目中有个 wsgi.py 的文件，里面设置了 DJANGO_SETTINGS_MODULE 为项目的配置文件，如何获取 wsgi 的APP。 浏览器访问www.baidu.com的过程 (1) 浏览器获取输入的域名 www.baidu.com (2) 浏览器向 DNS 请求解析 www.baidu.com 的 IP 地址 (3) 域名系统 DNS 解析出百度服务器的 IP 地址-通过网关出去 (4) 浏览器与该服务器建立 TCP 连接(默认端口号 80 ) (5) 浏览器发出 HTTP 请求，请求百度首页 (6) 服务器通过 HTTP 响应把首页文件发送给浏览器 (7) TCP 连接释放 (8) 浏览器将首页文件进行解析，并将 Web 页显示给用户。 Post和Get请求的区别 GET： 1.请求参数在请求行中，在url后。 2.请求的url长度有限制的 3.不太安全 4.发送一次TCP数据包 POST： 1.请求参数在请求体中 2.请求的url长度没有限制的 3.相对安全 4.发送两次TCP数据包 cookie和session的区别 cookie： 客户端技术，数据保存在客户端，数据不够安全，只能存储 4kb 数据 单个 cookie 保存的数据不超过4K，浏览器限制一个站点最多保存 20 个 cookie session：服务器端技术，数据保存在服务器，数据相对安全，用户看不到数据只能看到 sessionid， 数据存储根据服务器的容量而定 session 会在一定时间内保存在服务器上，当访问增多，会较占用服务器的性能，考虑到减轻服务器性能，应使用 cookie 可以考虑将登陆信息等重要信息存放在 session，其他信息如果需要保留，可以放在 cookie 中 三次握手和四次挥手 三次握手主要有两个目的：信息对等和防止超时。 信息对等 两台机器通信时都需要确认四个信息： 自己发报文的能力 自己收报文的能力 对方发报文的能力 对方收报文的通知 握手 第一次握手：第一次握手 A 机器向 B 机器发送 SYN 数据包，此时只有 B 机器能确认自己收报文的能力和对方发报文的能力。 第二次握手：每二次握手后 B 响应 A 机器的 SYN 数据包，此时 A 机器就能确认：自己发报文的能力、自己收报文的能力、对方发报文的能力、对方收报文的能力 第三次握手：每三次握手后 A 应答 B 机器的 SYN + ACK 数据包，此时 B 机器就能确认：自己发报文的能力、对方收报文的能力 防止超时 三次握手除了保证信息对等也是了防止请求超时导致脏连接。TTL网络报文的生存往往会超过TCP请求超时时间，如果两次握手就能创建连接，传输数据并释放连接后，第一个超时的连接请求才到达B机器，B机器 会以为是 A 创建新连接的请求，然后确认同意创建连接。因为A机器的状态不是SYN_SENT，所以会直接丢弃了B的确认数据，导致 B 机器单方面的创建连接完毕。 四次挥手 一次 客户端发送关闭数据包 服务端收到关闭连接请求后，通知应用程序处理完剩下的数据 二次 服务端响应客户端的关闭连接请求，说需要处理完剩下的数据，然后再发消息给你 客户端收到应答后继续等待 三次 服务端处理完剩下的数据后，主动向客户端发送数据包 客户端收到应答后，发送数据包 四次 服务端收到数据包后关闭连接 客户端 TIME_WAIT 状态等待 2MSL 后，关闭连接 什么是2MSL：MSL是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”， 2MSL即两倍的MSL 为什么要有TIME_WAIT 确认被动关闭（机器B）能够顺利进入CLOSED状态 假如A机器发送最后一个ACK后，但由于网络原因ACK包未能到达 B 机器，此时 B机器通常会认为 A机器 没有收到 FIN+ACK报文，会重发一次FIN+ACK报文。如果 A机器 发送最后一个ACK后，自私的关闭连接进入 CLOSED状态，就可能导致 B 无法收到ACK报文，无法正常关闭。 HTTPS和HTTP的区别 1、https 协议需要到 ca 申请证书，一般免费证书较少，因而需要一定费用。 2、http 是超文本传输协议，信息是明文传输，https 则是具有安全性的 ssl 加密传输协议。 3、http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。 4、http 的连接很简单，是无状态的；HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 http 协议安全。 使用Socket套接字需要传入哪些参数 Address Family 和 Type，分别表示套接字应用场景和类型。 family 的值可以是 AF_UNIX(Unix 域，用于同一台机器上的进程间通讯)，也可以是 AF_INET（对于 IPV4 协议的 TCP 和 UDP） type 参数， 流套接字(SOCK_STREAM) 数据报文套接字(SOCK_DGRAM) 原始套接字(SOCK_RAW) HTTP常见请求头 请求头 说明 Accept 浏览器可接受的MIME类型 Accept-Charset 浏览器可接受的字符集 Accept-Encoding 浏览器能够进行解码的数据编码方式，比如gzip。Servlet能够向支持gzip的浏览器返回经gzip编码的HTML页面。许多情形下这可以减少5到10倍的下载时间 Accept-Language 浏览器所希望的语言种类，当服务器能够提供一种以上的语言版本时要用到 Authorization 授权信息，通常出现在对服务器发送的WWW-Authenticate头的应答中 Connection 表示是否需要持久连接。如果Servlet看到这里的值为“Keep-Alive”，或者看到请求使用的是HTTP 1.1（HTTP 1.1默认进行持久连接），它就可以利用持久连接的优点，当页面包含多个元素时（例如Applet，图片），显著地减少下载所需要的时间。要实现这一点，Servlet需要在应答中发送一个Content-Length头，最简单的实现方法是先把内容写入ByteArrayOutputStream，然后在正式写出内容之前计算它的大小 Content-Length 表示请求消息正文的长度 Cookie 这是最重要的请求头信息之一 From 请求发送者的email地址，由一些特殊的Web客户程序使用，浏览器不会用到它 Host 初始URL中的主机和端口 If-Modified-Since 只有当所请求的内容在指定的日期之后又经过修改才返回它，否则返回304“Not Modified”应答 Pragma 指定“no-cache”值表示服务器必须返回一个刷新后的文档，即使它是代理服务器而且已经有了页面的本地拷贝 Referer 包含一个URL，用户从该URL代表的页面出发访问当前请求的页面 User-Agent 浏览器类型，如果Servlet返回的内容与浏览器类型有关则该值非常有用 UA-Pixels，UA-Color，UA-OS，UA-CPU 由某些版本的IE浏览器所发送的非标准的请求头，表示屏幕大小、颜色深度、操作系统和CPU类型 OSI七层模型和TCP/IP四层模型以及五层模型 OSI 7、应用层（Application）：为用户的应用程序提供网络服务 6、表示层（Presentation）：将信息表示为一定形式和格式的数据流 5、会话层（Session）：负责通信主机之间会话的建立、管理和拆除，协调通信双方的会话 4、传输层（Transport）：负责通信主机间端到端的连接 3、网络层（Network）：负责将分组从源机送到目的机，包括寻址和最优路径选择等 2、数据链路层（Data Link）：提供可靠的帧传递，实现差错控制、流控等等 1、物理层（Physical）：提供透明的比特流（01流）传递 TCP/IP 4、应用层（Application）：为用户提供所需要的各种服务 3、传输层（Transport）：为应用层实体提供端到端的通信功能，保证了数据包的顺序传送及数据的完整性 2、网际层（Internet）：主要解决主机到主机的通信问题 1、网络接口层（Network Access）：负责监视数据在主机和网络之间的交换 url的形式 URL由三部分组成：资源类型、存放资源的主机域名、资源文件名。 也可认为由4部分组成：协议、主机、端口、路径 什么是WSGI和uwsgi以及uWSGI? WSGI：web 服务网关接口，是一套协议。用于接收用户请求并将请求进行初次封装，然后将请求交给 web 框架。 实现 wsgi 协议的模块： wsgiref：本质上就是编写一 socket 服务端，用于接收用户请求（django) werkzeug：本质上就是编写一个 socket 服务端，用于接收用户请求(flask) uwsgi：是实现了 wsgi 协议的一个模块，模块本质：一个 socket 服务器 uWSGI：是一个 web 服务器，它实现了WSGI协议、uwsgi、http等协议。 三种区别 WSGI 是一种通信协议。 uwsgi 是一种线路协议而不是通信协议，在此常用于在 uWSGI 服务器与其他网络服务器的数据通信。 uWSGI 是实现了 uwsgi 和 WSGI 两种协议的 Web 服务器。 Nginx nginx 是一个开源的高性能的HTTP服务器和反向代理： 1.作为web服务器，它处理静态文件和索引文件效果非常高 2.它的设计非常注重效率，最大支持5万个并发连接，但只占用很少的内存空间 3.稳定性高，配置简洁。 4.强大的反向代理和负载均衡功能，平衡集群中各个服务器的负载压力应用 同源策略 协议相同 域名相同 端口相同 只要有一项不同就会出现跨域 Django请求生命周期 1.wsgi ,请求封装后交给web框架（Flask，Django) 2.中间件，对请求进行校验或在请求对象中添加其他相关数据，例如：csrf,request.session 3.路由匹配 根据浏览器发送的不同url去匹配不同的视图函数 4.视图函数，在视图函数中进行业务逻辑的处理，可能涉及到：orm，templates 5.中间件，对响应的数据进行处理 6.wsgi，将响应的内容发送给浏览器 scrapy和scrapy-redis有什么区别？为什么选择redis数据库？ - 1) scrapy 是一个 Python 爬虫框架，爬取效率极高，具有高度定制性，但是不支持分布式。 而 scrapy-redis 一套基于 redis 数据库、运行在 scrapy 框架之上的组件，可以让 scrapy 支持分布式策略， Slave 端共享 Master 端 redis 数据库里的 item 队列、请求队列和请求指纹集合。 2)为什么选择 redis 数据库，因为 redis 支持主从同步，而且数据都是缓存在内存中的，所以基于 redis 的分布式爬虫，对请求和数据的高频读取效率非常高。 分布式爬虫主要解决什么问题？ 1、ip 2、带宽 3、cpu 4、io scrapy的去重与过滤器的使用 InnoDB和MyISAM以及MEMORY的区别 InnoDB：支持事务（提交、回滚）、支持外键、支持奔溃修复和并发控制，适合频繁更新和删除 清空整个表时：一行一行删除，效率慢 MyISAM：插入数据快，空间内存使用比较低，适合只插入和读取的相关业务 清空整个表时：重建表 MEMORY：所有数据都存在内存中，数据的处理速度快，但安全性不高，只适合相对较小的数据库表 drop,delete与truncate的区别 drop 直接删掉表；truncate 删除表中数据，再插入时自增长 id 又从 1 开始；delete 删除表中数据，可以加where字句 1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。 truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。 并且在删除的过程中不会激活与表有关的删除触发器，执行速度快。 2.表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。 drop语句将表所占用的空间全释放掉。 3.一般而言，drop>truncate>delete 4.应用范围。truncate只能对table，delete可以是table和view 5.truncate和delete只删除数据，而drop则删除整个表（结构和数据) 6.truncate与不带where的delete：只删除数据，而不删除表的结构（定义）drop语句将删除表的结构被依赖的约束(constrain), 触发器（trigger)索引(index) ;依赖于该表的存储过程/函数将被保留，但其状态会变为:invalid. 索引的工作原理及其种类 数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询，更新数据库表中数据。索引的实现通常使用B树以其变种B+树。 在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。 为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间（因为索引也要随之变动） 悲观锁和乐观锁 悲观锁：就是很悲观，每次去拿数据的时候认为别人会修改，所以每次拿数据的时候都会上锁，这样只要别人想要这个数据就会block直到它拿到锁， 传统的关系型数据库就有很多这样机制的锁：行锁、表锁、读锁、写锁等，都是在操作之前上锁 乐观锁：就是很乐观，每次去拿数据的时候认为别人不会修改，所以每次拿数据的时候都不会上锁，但是在更新的时候会去判断一下在此期间有没有别人更新这个数据， 可以使用版本号等机制，乐观锁适用于多读的应用类型，可以提高吞吐量 存储函数与存储过程的区别 语法 存储函数不能有输出参数，因为存储函数本身就是输出参数，而存储过程可以有输出参数 可以直接对存储函数进行调用，不需要使用 call 存储函数必须包含一条 return 语句，而这条语句不允许包含于存储过程中 Redis宕机怎么解决? 宕机:服务器停止服务 如果只有一台 redis，肯定会造成数据丢失，无法挽救 多台redis或者是redis集群，宕机则需要分为在主从模式下区分来看： slave从redis宕机，配置主从复制的时候才配置从的redis，从的会从主的redis中读取主的redis的操作日志1，在redis中从库重新启动后会自动加入到主从架构中，自动完成同步数据; 如果从数据库实现了持久化，此时千万不要立马重启服务，否则可能会造成数据丢失，正确的操作如下：在slave数据上执行SLAVEOF ON ONE,来断开主从关系并把slave升级为主库，此时重新启动主数据 库，执行SLAVEOF，把它设置为从库，连接到主的redis上面做主从复制，自动备份数据。 以上过程很容易配置错误，可以使用redis提供的哨兵机制来简化上面的操作。简单的方法:redis的哨兵(sentinel)的功能 值传递和引用传递 def fn(k, v, d={}): d[k] = v print(d) fn('1', 1) fn('2', 2) fn('3', 3, {}) # 结果 {'1': 1} # 直接将键值对传递给字典 {'1': 1, '2': 2} # 因为字典在内存中是可变对象类型，指向了同一个地址，传递了新的键值对后相当于给字典添加的新键值对 {'3': 3} # 给了一个新的字典，所以不是原来默认参数的字典 copy和deepcopy 复制不可变类型 数值、字符串、元组 不管是 copy 还是 deepcopy，都是同一个地址，和 “=” 赋值一样，id() 后的值都相同 复制可变类型 列表、字典 第一种：复制的对象中无复杂对象，原来的值改变不会影响浅复制的值，同时浅复制的值改变不会影响原来的值，两者 id 值不同 第二种：复制的对象中有复杂对象（例如：一个列表中的一个元素是列表） copy：改变原来的值中的复杂对象的值，会影响浅复制的值 deepcopy：完全独立复制，包括内层列表或字典 排序 正数从小到大，负数从大到小 a = [-8, 5, 7, -5, -1, 6, -2, 3, 4, -3, 9] sorted(a, key=lambda x: (x 数字相同，按字符串排序 a = [['op', 55], ['ef', 30], ['ab', 10], ['gh', 55], ['cd', 20], ['xy', 55]] sorted(a, key=lambda x: x[1] and x[0]) # 或 sorted(a, key=lambda x: (x[1], x[0])) int(\"1.4\") 和 int(1.4) 结果 int(\"1.4\")：报错 int(1.4)：1 "}}